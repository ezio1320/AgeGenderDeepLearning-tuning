I0528 22:21:56.756867 16530 caffe.cpp:218] Using GPUs 0
I0528 22:21:56.876126 16530 caffe.cpp:223] GPU 0: Tesla K40m
I0528 22:21:57.358535 16530 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1284
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 200000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "pre-resnet-34"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "34_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0528 22:21:57.358860 16530 solver.cpp:87] Creating training net from net file: 34_train_val_test_fold_is_0.prototxt
I0528 22:21:57.362021 16530 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 34_train_val_test_fold_is_0.prototxt
I0528 22:21:57.362043 16530 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 22:21:57.362411 16530 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0528 22:21:57.362524 16530 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0528 22:21:57.363484 16530 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-34"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/age_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv2"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv2"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv2"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_256_3_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_256_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_3_scale1"
  type: "Scale"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_3_relu1"
  type: "ReLU"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_bn1"
}
layer {
  name: "layer_256_3_conv1"
  type: "Convolution"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_3_bn2"
  type: "BatchNorm"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_3_scale2"
  type: "Scale"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_3_relu2"
  type: "ReLU"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
}
layer {
  name: "layer_256_3_conv2"
  type: "Convolution"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_3_sum"
  type: "Eltwise"
  bottom: "layer_256_3_conv2"
  bottom: "layer_256_2_sum"
  top: "layer_256_3_sum"
}
layer {
  name: "layer_256_4_bn1"
  type: "BatchNorm"
  bottom: "layer_256_3_sum"
  top: "layer_256_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_4_scale1"
  type: "Scale"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_4_relu1"
  type: "ReLU"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_bn1"
}
layer {
  name: "layer_256_4_conv1"
  type: "Convolution"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_4_bn2"
  type: "BatchNorm"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_4_scale2"
  type: "Scale"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_4_relu2"
  type: "ReLU"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
}
layer {
  name: "layer_256_4_conv2"
  type: "Convolution"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_4_sum"
  type: "Eltwise"
  bottom: "layer_256_4_conv2"
  bottom: "layer_256_3_sum"
  top: "layer_256_4_sum"
}
layer {
  name: "layer_256_5_bn1"
  type: "BatchNorm"
  bottom: "layer_256_4_sum"
  top: "layer_256_5_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_5_scale1"
  type: "Scale"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_5_relu1"
  type: "ReLU"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_bn1"
}
layer {
  name: "layer_256_5_conv1"
  type: "Convolution"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_5_bn2"
  type: "BatchNorm"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_5_scale2"
  type: "Scale"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_5_relu2"
  type: "ReLU"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
}
layer {
  name: "layer_256_5_conv2"
  type: "Convolution"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_5_sum"
  type: "Eltwise"
  bottom: "layer_256_5_conv2"
  bottom: "layer_256_4_sum"
  top: "layer_256_5_sum"
}
layer {
  name: "layer_256_6_bn1"
  type: "BatchNorm"
  bottom: "layer_256_5_sum"
  top: "layer_256_6_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_6_scale1"
  type: "Scale"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_6_relu1"
  type: "ReLU"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_bn1"
}
layer {
  name: "layer_256_6_conv1"
  type: "Convolution"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_6_bn2"
  type: "BatchNorm"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_6_scale2"
  type: "Scale"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_6_relu2"
  type: "ReLU"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
}
layer {
  name: "layer_256_6_conv2"
  type: "Convolution"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_6_sum"
  type: "Eltwise"
  bottom: "layer_256_6_conv2"
  bottom: "layer_256_5_sum"
  top: "layer_256_6_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_6_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_51
I0528 22:21:57.364348 16530 layer_factory.hpp:77] Creating layer data
I0528 22:21:57.365059 16530 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/age_train_lmdb
I0528 22:21:57.365134 16530 net.cpp:84] Creating Layer data
I0528 22:21:57.365156 16530 net.cpp:380] data -> data
I0528 22:21:57.365190 16530 net.cpp:380] data -> label
I0528 22:21:57.365211 16530 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 22:21:57.369307 16530 data_layer.cpp:45] output data size: 50,3,224,224
I0528 22:21:57.440415 16530 net.cpp:122] Setting up data
I0528 22:21:57.440490 16530 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 22:21:57.440500 16530 net.cpp:129] Top shape: 50 (50)
I0528 22:21:57.440505 16530 net.cpp:137] Memory required for data: 30105800
I0528 22:21:57.440529 16530 layer_factory.hpp:77] Creating layer data_bn
I0528 22:21:57.440551 16530 net.cpp:84] Creating Layer data_bn
I0528 22:21:57.440558 16530 net.cpp:406] data_bn <- data
I0528 22:21:57.440577 16530 net.cpp:380] data_bn -> data_bn
I0528 22:21:57.441665 16530 net.cpp:122] Setting up data_bn
I0528 22:21:57.441699 16530 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 22:21:57.441705 16530 net.cpp:137] Memory required for data: 60211400
I0528 22:21:57.441730 16530 layer_factory.hpp:77] Creating layer data_scale
I0528 22:21:57.441746 16530 net.cpp:84] Creating Layer data_scale
I0528 22:21:57.441751 16530 net.cpp:406] data_scale <- data_bn
I0528 22:21:57.441758 16530 net.cpp:367] data_scale -> data_bn (in-place)
I0528 22:21:57.441820 16530 layer_factory.hpp:77] Creating layer data_scale
I0528 22:21:57.442035 16530 net.cpp:122] Setting up data_scale
I0528 22:21:57.442070 16530 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 22:21:57.442075 16530 net.cpp:137] Memory required for data: 90317000
I0528 22:21:57.442096 16530 layer_factory.hpp:77] Creating layer conv1
I0528 22:21:57.442124 16530 net.cpp:84] Creating Layer conv1
I0528 22:21:57.442143 16530 net.cpp:406] conv1 <- data_bn
I0528 22:21:57.442152 16530 net.cpp:380] conv1 -> conv1
I0528 22:21:57.624514 16530 net.cpp:122] Setting up conv1
I0528 22:21:57.624574 16530 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 22:21:57.624581 16530 net.cpp:137] Memory required for data: 250880200
I0528 22:21:57.624593 16530 layer_factory.hpp:77] Creating layer conv1_bn
I0528 22:21:57.624608 16530 net.cpp:84] Creating Layer conv1_bn
I0528 22:21:57.624615 16530 net.cpp:406] conv1_bn <- conv1
I0528 22:21:57.624624 16530 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 22:21:57.624785 16530 net.cpp:122] Setting up conv1_bn
I0528 22:21:57.624797 16530 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 22:21:57.624802 16530 net.cpp:137] Memory required for data: 411443400
I0528 22:21:57.624815 16530 layer_factory.hpp:77] Creating layer conv1_scale
I0528 22:21:57.624825 16530 net.cpp:84] Creating Layer conv1_scale
I0528 22:21:57.624830 16530 net.cpp:406] conv1_scale <- conv1
I0528 22:21:57.624835 16530 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 22:21:57.624886 16530 layer_factory.hpp:77] Creating layer conv1_scale
I0528 22:21:57.625025 16530 net.cpp:122] Setting up conv1_scale
I0528 22:21:57.625046 16530 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 22:21:57.625049 16530 net.cpp:137] Memory required for data: 572006600
I0528 22:21:57.625067 16530 layer_factory.hpp:77] Creating layer conv1_relu
I0528 22:21:57.625087 16530 net.cpp:84] Creating Layer conv1_relu
I0528 22:21:57.625092 16530 net.cpp:406] conv1_relu <- conv1
I0528 22:21:57.625110 16530 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 22:21:57.625838 16530 net.cpp:122] Setting up conv1_relu
I0528 22:21:57.625869 16530 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 22:21:57.625874 16530 net.cpp:137] Memory required for data: 732569800
I0528 22:21:57.625879 16530 layer_factory.hpp:77] Creating layer conv1_pool
I0528 22:21:57.625886 16530 net.cpp:84] Creating Layer conv1_pool
I0528 22:21:57.625891 16530 net.cpp:406] conv1_pool <- conv1
I0528 22:21:57.625910 16530 net.cpp:380] conv1_pool -> conv1_pool
I0528 22:21:57.625967 16530 net.cpp:122] Setting up conv1_pool
I0528 22:21:57.625977 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.625980 16530 net.cpp:137] Memory required for data: 772710600
I0528 22:21:57.625984 16530 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 22:21:57.625994 16530 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 22:21:57.625999 16530 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 22:21:57.626005 16530 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 22:21:57.626013 16530 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 22:21:57.626057 16530 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 22:21:57.626065 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.626070 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.626073 16530 net.cpp:137] Memory required for data: 852992200
I0528 22:21:57.626077 16530 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 22:21:57.626091 16530 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 22:21:57.626096 16530 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 22:21:57.626112 16530 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 22:21:57.628764 16530 net.cpp:122] Setting up layer_64_1_conv1
I0528 22:21:57.628796 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.628801 16530 net.cpp:137] Memory required for data: 893133000
I0528 22:21:57.628808 16530 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 22:21:57.628824 16530 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 22:21:57.628839 16530 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 22:21:57.628846 16530 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 22:21:57.631287 16530 net.cpp:122] Setting up layer_64_1_bn2
I0528 22:21:57.631306 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.631322 16530 net.cpp:137] Memory required for data: 933273800
I0528 22:21:57.631331 16530 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 22:21:57.631340 16530 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 22:21:57.631345 16530 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 22:21:57.631366 16530 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 22:21:57.631410 16530 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 22:21:57.634160 16530 net.cpp:122] Setting up layer_64_1_scale2
I0528 22:21:57.634188 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.634193 16530 net.cpp:137] Memory required for data: 973414600
I0528 22:21:57.634204 16530 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 22:21:57.634212 16530 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 22:21:57.634217 16530 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 22:21:57.634238 16530 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 22:21:57.634395 16530 net.cpp:122] Setting up layer_64_1_relu2
I0528 22:21:57.634419 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.634435 16530 net.cpp:137] Memory required for data: 1013555400
I0528 22:21:57.634439 16530 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 22:21:57.634461 16530 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 22:21:57.634466 16530 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 22:21:57.634472 16530 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 22:21:57.636970 16530 net.cpp:122] Setting up layer_64_1_conv2
I0528 22:21:57.637001 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637006 16530 net.cpp:137] Memory required for data: 1053696200
I0528 22:21:57.637012 16530 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 22:21:57.637024 16530 net.cpp:84] Creating Layer layer_64_1_sum
I0528 22:21:57.637044 16530 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 22:21:57.637050 16530 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 22:21:57.637058 16530 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 22:21:57.637094 16530 net.cpp:122] Setting up layer_64_1_sum
I0528 22:21:57.637102 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637106 16530 net.cpp:137] Memory required for data: 1093837000
I0528 22:21:57.637110 16530 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:57.637122 16530 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:57.637140 16530 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 22:21:57.637146 16530 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 22:21:57.637153 16530 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 22:21:57.637202 16530 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:57.637210 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637214 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637218 16530 net.cpp:137] Memory required for data: 1174118600
I0528 22:21:57.637223 16530 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 22:21:57.637233 16530 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 22:21:57.637238 16530 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 22:21:57.637255 16530 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 22:21:57.637481 16530 net.cpp:122] Setting up layer_64_2_bn1
I0528 22:21:57.637492 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637526 16530 net.cpp:137] Memory required for data: 1214259400
I0528 22:21:57.637553 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 22:21:57.637562 16530 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 22:21:57.637567 16530 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 22:21:57.637575 16530 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 22:21:57.637619 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 22:21:57.637754 16530 net.cpp:122] Setting up layer_64_2_scale1
I0528 22:21:57.637766 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.637781 16530 net.cpp:137] Memory required for data: 1254400200
I0528 22:21:57.637789 16530 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 22:21:57.637795 16530 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 22:21:57.637799 16530 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 22:21:57.637816 16530 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 22:21:57.638018 16530 net.cpp:122] Setting up layer_64_2_relu1
I0528 22:21:57.638031 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.638046 16530 net.cpp:137] Memory required for data: 1294541000
I0528 22:21:57.638051 16530 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 22:21:57.638082 16530 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 22:21:57.638087 16530 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 22:21:57.638108 16530 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 22:21:57.640750 16530 net.cpp:122] Setting up layer_64_2_conv1
I0528 22:21:57.640784 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.640790 16530 net.cpp:137] Memory required for data: 1334681800
I0528 22:21:57.640796 16530 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 22:21:57.640805 16530 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 22:21:57.640825 16530 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 22:21:57.640835 16530 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 22:21:57.641037 16530 net.cpp:122] Setting up layer_64_2_bn2
I0528 22:21:57.641058 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.641073 16530 net.cpp:137] Memory required for data: 1374822600
I0528 22:21:57.641084 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 22:21:57.641093 16530 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 22:21:57.641098 16530 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 22:21:57.641103 16530 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 22:21:57.641167 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 22:21:57.641290 16530 net.cpp:122] Setting up layer_64_2_scale2
I0528 22:21:57.641302 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.641306 16530 net.cpp:137] Memory required for data: 1414963400
I0528 22:21:57.641314 16530 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 22:21:57.641319 16530 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 22:21:57.641324 16530 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 22:21:57.641331 16530 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 22:21:57.642024 16530 net.cpp:122] Setting up layer_64_2_relu2
I0528 22:21:57.642051 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.642056 16530 net.cpp:137] Memory required for data: 1455104200
I0528 22:21:57.642060 16530 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 22:21:57.642074 16530 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 22:21:57.642081 16530 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 22:21:57.642089 16530 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 22:21:57.645097 16530 net.cpp:122] Setting up layer_64_2_conv2
I0528 22:21:57.645133 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645141 16530 net.cpp:137] Memory required for data: 1495245000
I0528 22:21:57.645148 16530 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 22:21:57.645164 16530 net.cpp:84] Creating Layer layer_64_2_sum
I0528 22:21:57.645177 16530 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 22:21:57.645184 16530 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 22:21:57.645191 16530 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 22:21:57.645220 16530 net.cpp:122] Setting up layer_64_2_sum
I0528 22:21:57.645229 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645233 16530 net.cpp:137] Memory required for data: 1535385800
I0528 22:21:57.645237 16530 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:57.645243 16530 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:57.645247 16530 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0528 22:21:57.645252 16530 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 22:21:57.645261 16530 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 22:21:57.645294 16530 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:57.645303 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645308 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645310 16530 net.cpp:137] Memory required for data: 1615667400
I0528 22:21:57.645325 16530 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0528 22:21:57.645335 16530 net.cpp:84] Creating Layer layer_64_3_bn1
I0528 22:21:57.645339 16530 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 22:21:57.645345 16530 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0528 22:21:57.645578 16530 net.cpp:122] Setting up layer_64_3_bn1
I0528 22:21:57.645589 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645604 16530 net.cpp:137] Memory required for data: 1655808200
I0528 22:21:57.645617 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 22:21:57.645627 16530 net.cpp:84] Creating Layer layer_64_3_scale1
I0528 22:21:57.645633 16530 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0528 22:21:57.645638 16530 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0528 22:21:57.645681 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 22:21:57.645819 16530 net.cpp:122] Setting up layer_64_3_scale1
I0528 22:21:57.645831 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.645846 16530 net.cpp:137] Memory required for data: 1695949000
I0528 22:21:57.645853 16530 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0528 22:21:57.645874 16530 net.cpp:84] Creating Layer layer_64_3_relu1
I0528 22:21:57.645879 16530 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0528 22:21:57.645884 16530 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0528 22:21:57.646082 16530 net.cpp:122] Setting up layer_64_3_relu1
I0528 22:21:57.646108 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.646113 16530 net.cpp:137] Memory required for data: 1736089800
I0528 22:21:57.646126 16530 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0528 22:21:57.646139 16530 net.cpp:84] Creating Layer layer_64_3_conv1
I0528 22:21:57.646144 16530 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0528 22:21:57.646152 16530 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0528 22:21:57.648671 16530 net.cpp:122] Setting up layer_64_3_conv1
I0528 22:21:57.648691 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.648707 16530 net.cpp:137] Memory required for data: 1776230600
I0528 22:21:57.648713 16530 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0528 22:21:57.648725 16530 net.cpp:84] Creating Layer layer_64_3_bn2
I0528 22:21:57.648730 16530 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0528 22:21:57.648752 16530 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0528 22:21:57.648965 16530 net.cpp:122] Setting up layer_64_3_bn2
I0528 22:21:57.648984 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.649005 16530 net.cpp:137] Memory required for data: 1816371400
I0528 22:21:57.649032 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 22:21:57.649040 16530 net.cpp:84] Creating Layer layer_64_3_scale2
I0528 22:21:57.649045 16530 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0528 22:21:57.649050 16530 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0528 22:21:57.649106 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 22:21:57.649286 16530 net.cpp:122] Setting up layer_64_3_scale2
I0528 22:21:57.649309 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.649325 16530 net.cpp:137] Memory required for data: 1856512200
I0528 22:21:57.649332 16530 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0528 22:21:57.649340 16530 net.cpp:84] Creating Layer layer_64_3_relu2
I0528 22:21:57.649345 16530 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0528 22:21:57.649381 16530 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0528 22:21:57.649581 16530 net.cpp:122] Setting up layer_64_3_relu2
I0528 22:21:57.649616 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.649621 16530 net.cpp:137] Memory required for data: 1896653000
I0528 22:21:57.649634 16530 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0528 22:21:57.649646 16530 net.cpp:84] Creating Layer layer_64_3_conv2
I0528 22:21:57.649652 16530 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0528 22:21:57.649660 16530 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0528 22:21:57.652310 16530 net.cpp:122] Setting up layer_64_3_conv2
I0528 22:21:57.652331 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.652346 16530 net.cpp:137] Memory required for data: 1936793800
I0528 22:21:57.652353 16530 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0528 22:21:57.652362 16530 net.cpp:84] Creating Layer layer_64_3_sum
I0528 22:21:57.652367 16530 net.cpp:406] layer_64_3_sum <- layer_64_3_conv2
I0528 22:21:57.652374 16530 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 22:21:57.652379 16530 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0528 22:21:57.652405 16530 net.cpp:122] Setting up layer_64_3_sum
I0528 22:21:57.652415 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.652420 16530 net.cpp:137] Memory required for data: 1976934600
I0528 22:21:57.652422 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 22:21:57.652429 16530 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 22:21:57.652433 16530 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0528 22:21:57.652441 16530 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 22:21:57.652673 16530 net.cpp:122] Setting up layer_128_1_bn1
I0528 22:21:57.652683 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.652698 16530 net.cpp:137] Memory required for data: 2017075400
I0528 22:21:57.652705 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 22:21:57.652714 16530 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 22:21:57.652717 16530 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 22:21:57.652729 16530 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 22:21:57.652797 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 22:21:57.652956 16530 net.cpp:122] Setting up layer_128_1_scale1
I0528 22:21:57.652966 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.652981 16530 net.cpp:137] Memory required for data: 2057216200
I0528 22:21:57.652998 16530 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 22:21:57.653005 16530 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 22:21:57.653022 16530 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 22:21:57.653029 16530 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 22:21:57.653728 16530 net.cpp:122] Setting up layer_128_1_relu1
I0528 22:21:57.653755 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.653760 16530 net.cpp:137] Memory required for data: 2097357000
I0528 22:21:57.653775 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:57.653789 16530 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:57.653795 16530 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 22:21:57.653802 16530 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 22:21:57.653810 16530 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 22:21:57.653853 16530 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:57.653863 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.653867 16530 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 22:21:57.653872 16530 net.cpp:137] Memory required for data: 2177638600
I0528 22:21:57.653874 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 22:21:57.653885 16530 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 22:21:57.653894 16530 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 22:21:57.653901 16530 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 22:21:57.658872 16530 net.cpp:122] Setting up layer_128_1_conv1
I0528 22:21:57.658906 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.658912 16530 net.cpp:137] Memory required for data: 2197709000
I0528 22:21:57.658918 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 22:21:57.658927 16530 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 22:21:57.658932 16530 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 22:21:57.658964 16530 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 22:21:57.659760 16530 net.cpp:122] Setting up layer_128_1_bn2
I0528 22:21:57.659790 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.659795 16530 net.cpp:137] Memory required for data: 2217779400
I0528 22:21:57.659803 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 22:21:57.659813 16530 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 22:21:57.659832 16530 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 22:21:57.659838 16530 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 22:21:57.659883 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 22:21:57.660014 16530 net.cpp:122] Setting up layer_128_1_scale2
I0528 22:21:57.660027 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.660042 16530 net.cpp:137] Memory required for data: 2237849800
I0528 22:21:57.660048 16530 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 22:21:57.660054 16530 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 22:21:57.660058 16530 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 22:21:57.660064 16530 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 22:21:57.660338 16530 net.cpp:122] Setting up layer_128_1_relu2
I0528 22:21:57.660377 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.660392 16530 net.cpp:137] Memory required for data: 2257920200
I0528 22:21:57.660396 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 22:21:57.660408 16530 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 22:21:57.660413 16530 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 22:21:57.660423 16530 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 22:21:57.665783 16530 net.cpp:122] Setting up layer_128_1_conv2
I0528 22:21:57.665803 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.665819 16530 net.cpp:137] Memory required for data: 2277990600
I0528 22:21:57.665825 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 22:21:57.665838 16530 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 22:21:57.665860 16530 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 22:21:57.665871 16530 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 22:21:57.669450 16530 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 22:21:57.669489 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.669495 16530 net.cpp:137] Memory required for data: 2298061000
I0528 22:21:57.669502 16530 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 22:21:57.669510 16530 net.cpp:84] Creating Layer layer_128_1_sum
I0528 22:21:57.669515 16530 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 22:21:57.669534 16530 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 22:21:57.669541 16530 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 22:21:57.669574 16530 net.cpp:122] Setting up layer_128_1_sum
I0528 22:21:57.669581 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.669585 16530 net.cpp:137] Memory required for data: 2318131400
I0528 22:21:57.669589 16530 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:57.669595 16530 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:57.669598 16530 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 22:21:57.669606 16530 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 22:21:57.669615 16530 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 22:21:57.669651 16530 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:57.669659 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.669664 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.669667 16530 net.cpp:137] Memory required for data: 2358272200
I0528 22:21:57.669672 16530 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 22:21:57.669677 16530 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 22:21:57.669682 16530 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 22:21:57.669688 16530 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 22:21:57.669910 16530 net.cpp:122] Setting up layer_128_2_bn1
I0528 22:21:57.669942 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.669947 16530 net.cpp:137] Memory required for data: 2378342600
I0528 22:21:57.669966 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 22:21:57.669984 16530 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 22:21:57.669989 16530 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 22:21:57.670006 16530 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 22:21:57.670075 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 22:21:57.670215 16530 net.cpp:122] Setting up layer_128_2_scale1
I0528 22:21:57.670230 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.670245 16530 net.cpp:137] Memory required for data: 2398413000
I0528 22:21:57.670253 16530 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 22:21:57.670259 16530 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 22:21:57.670264 16530 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 22:21:57.670310 16530 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 22:21:57.670538 16530 net.cpp:122] Setting up layer_128_2_relu1
I0528 22:21:57.670552 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.670567 16530 net.cpp:137] Memory required for data: 2418483400
I0528 22:21:57.670572 16530 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 22:21:57.670594 16530 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 22:21:57.670610 16530 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 22:21:57.670630 16530 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 22:21:57.676522 16530 net.cpp:122] Setting up layer_128_2_conv1
I0528 22:21:57.676558 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.676563 16530 net.cpp:137] Memory required for data: 2438553800
I0528 22:21:57.676569 16530 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 22:21:57.676580 16530 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 22:21:57.676604 16530 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 22:21:57.676620 16530 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 22:21:57.676825 16530 net.cpp:122] Setting up layer_128_2_bn2
I0528 22:21:57.676836 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.676851 16530 net.cpp:137] Memory required for data: 2458624200
I0528 22:21:57.676894 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 22:21:57.676903 16530 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 22:21:57.676908 16530 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 22:21:57.676914 16530 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 22:21:57.676971 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 22:21:57.677110 16530 net.cpp:122] Setting up layer_128_2_scale2
I0528 22:21:57.677144 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.677160 16530 net.cpp:137] Memory required for data: 2478694600
I0528 22:21:57.677165 16530 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 22:21:57.677172 16530 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 22:21:57.677176 16530 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 22:21:57.677184 16530 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 22:21:57.677891 16530 net.cpp:122] Setting up layer_128_2_relu2
I0528 22:21:57.677907 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.677923 16530 net.cpp:137] Memory required for data: 2498765000
I0528 22:21:57.677927 16530 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 22:21:57.677939 16530 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 22:21:57.677956 16530 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 22:21:57.677966 16530 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 22:21:57.683425 16530 net.cpp:122] Setting up layer_128_2_conv2
I0528 22:21:57.683457 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.683462 16530 net.cpp:137] Memory required for data: 2518835400
I0528 22:21:57.683468 16530 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 22:21:57.683478 16530 net.cpp:84] Creating Layer layer_128_2_sum
I0528 22:21:57.683500 16530 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 22:21:57.683506 16530 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 22:21:57.683512 16530 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 22:21:57.683544 16530 net.cpp:122] Setting up layer_128_2_sum
I0528 22:21:57.683552 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.683555 16530 net.cpp:137] Memory required for data: 2538905800
I0528 22:21:57.683559 16530 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:57.683565 16530 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:57.683569 16530 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0528 22:21:57.683578 16530 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 22:21:57.683584 16530 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 22:21:57.683619 16530 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:57.683632 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.683636 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.683640 16530 net.cpp:137] Memory required for data: 2579046600
I0528 22:21:57.683643 16530 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0528 22:21:57.683661 16530 net.cpp:84] Creating Layer layer_128_3_bn1
I0528 22:21:57.683665 16530 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 22:21:57.683673 16530 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0528 22:21:57.683914 16530 net.cpp:122] Setting up layer_128_3_bn1
I0528 22:21:57.683925 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.683959 16530 net.cpp:137] Memory required for data: 2599117000
I0528 22:21:57.683989 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 22:21:57.683998 16530 net.cpp:84] Creating Layer layer_128_3_scale1
I0528 22:21:57.684003 16530 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0528 22:21:57.684010 16530 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0528 22:21:57.684077 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 22:21:57.684250 16530 net.cpp:122] Setting up layer_128_3_scale1
I0528 22:21:57.684264 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.684279 16530 net.cpp:137] Memory required for data: 2619187400
I0528 22:21:57.684298 16530 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0528 22:21:57.684304 16530 net.cpp:84] Creating Layer layer_128_3_relu1
I0528 22:21:57.684329 16530 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0528 22:21:57.684335 16530 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0528 22:21:57.685040 16530 net.cpp:122] Setting up layer_128_3_relu1
I0528 22:21:57.685070 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.685075 16530 net.cpp:137] Memory required for data: 2639257800
I0528 22:21:57.685080 16530 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0528 22:21:57.685091 16530 net.cpp:84] Creating Layer layer_128_3_conv1
I0528 22:21:57.685097 16530 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0528 22:21:57.685104 16530 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0528 22:21:57.691282 16530 net.cpp:122] Setting up layer_128_3_conv1
I0528 22:21:57.691315 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.691320 16530 net.cpp:137] Memory required for data: 2659328200
I0528 22:21:57.691328 16530 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0528 22:21:57.691346 16530 net.cpp:84] Creating Layer layer_128_3_bn2
I0528 22:21:57.691352 16530 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0528 22:21:57.691359 16530 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0528 22:21:57.691586 16530 net.cpp:122] Setting up layer_128_3_bn2
I0528 22:21:57.691597 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.691612 16530 net.cpp:137] Memory required for data: 2679398600
I0528 22:21:57.691622 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 22:21:57.691630 16530 net.cpp:84] Creating Layer layer_128_3_scale2
I0528 22:21:57.691635 16530 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0528 22:21:57.691642 16530 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0528 22:21:57.691685 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 22:21:57.691817 16530 net.cpp:122] Setting up layer_128_3_scale2
I0528 22:21:57.691829 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.691844 16530 net.cpp:137] Memory required for data: 2699469000
I0528 22:21:57.691861 16530 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0528 22:21:57.691870 16530 net.cpp:84] Creating Layer layer_128_3_relu2
I0528 22:21:57.691874 16530 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0528 22:21:57.691880 16530 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0528 22:21:57.692092 16530 net.cpp:122] Setting up layer_128_3_relu2
I0528 22:21:57.692136 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.692154 16530 net.cpp:137] Memory required for data: 2719539400
I0528 22:21:57.692169 16530 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0528 22:21:57.692200 16530 net.cpp:84] Creating Layer layer_128_3_conv2
I0528 22:21:57.692206 16530 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0528 22:21:57.692214 16530 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0528 22:21:57.698088 16530 net.cpp:122] Setting up layer_128_3_conv2
I0528 22:21:57.698124 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698132 16530 net.cpp:137] Memory required for data: 2739609800
I0528 22:21:57.698144 16530 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0528 22:21:57.698160 16530 net.cpp:84] Creating Layer layer_128_3_sum
I0528 22:21:57.698165 16530 net.cpp:406] layer_128_3_sum <- layer_128_3_conv2
I0528 22:21:57.698171 16530 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 22:21:57.698176 16530 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0528 22:21:57.698210 16530 net.cpp:122] Setting up layer_128_3_sum
I0528 22:21:57.698225 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698230 16530 net.cpp:137] Memory required for data: 2759680200
I0528 22:21:57.698233 16530 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:57.698240 16530 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:57.698243 16530 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0528 22:21:57.698251 16530 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 22:21:57.698258 16530 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 22:21:57.698297 16530 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:57.698317 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698321 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698324 16530 net.cpp:137] Memory required for data: 2799821000
I0528 22:21:57.698328 16530 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0528 22:21:57.698334 16530 net.cpp:84] Creating Layer layer_128_4_bn1
I0528 22:21:57.698338 16530 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 22:21:57.698348 16530 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0528 22:21:57.698602 16530 net.cpp:122] Setting up layer_128_4_bn1
I0528 22:21:57.698613 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698628 16530 net.cpp:137] Memory required for data: 2819891400
I0528 22:21:57.698647 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 22:21:57.698657 16530 net.cpp:84] Creating Layer layer_128_4_scale1
I0528 22:21:57.698662 16530 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0528 22:21:57.698668 16530 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0528 22:21:57.698724 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 22:21:57.698859 16530 net.cpp:122] Setting up layer_128_4_scale1
I0528 22:21:57.698870 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.698885 16530 net.cpp:137] Memory required for data: 2839961800
I0528 22:21:57.698892 16530 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0528 22:21:57.698899 16530 net.cpp:84] Creating Layer layer_128_4_relu1
I0528 22:21:57.698904 16530 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0528 22:21:57.698909 16530 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0528 22:21:57.699641 16530 net.cpp:122] Setting up layer_128_4_relu1
I0528 22:21:57.699674 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.699679 16530 net.cpp:137] Memory required for data: 2860032200
I0528 22:21:57.699683 16530 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0528 22:21:57.699695 16530 net.cpp:84] Creating Layer layer_128_4_conv1
I0528 22:21:57.699713 16530 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0528 22:21:57.699721 16530 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0528 22:21:57.705215 16530 net.cpp:122] Setting up layer_128_4_conv1
I0528 22:21:57.705246 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.705251 16530 net.cpp:137] Memory required for data: 2880102600
I0528 22:21:57.705257 16530 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0528 22:21:57.705268 16530 net.cpp:84] Creating Layer layer_128_4_bn2
I0528 22:21:57.705286 16530 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0528 22:21:57.705296 16530 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0528 22:21:57.705509 16530 net.cpp:122] Setting up layer_128_4_bn2
I0528 22:21:57.705539 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.705554 16530 net.cpp:137] Memory required for data: 2900173000
I0528 22:21:57.705574 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 22:21:57.705581 16530 net.cpp:84] Creating Layer layer_128_4_scale2
I0528 22:21:57.705597 16530 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0528 22:21:57.705610 16530 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0528 22:21:57.705667 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 22:21:57.705816 16530 net.cpp:122] Setting up layer_128_4_scale2
I0528 22:21:57.705852 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.705857 16530 net.cpp:137] Memory required for data: 2920243400
I0528 22:21:57.705873 16530 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0528 22:21:57.705879 16530 net.cpp:84] Creating Layer layer_128_4_relu2
I0528 22:21:57.705901 16530 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0528 22:21:57.705907 16530 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0528 22:21:57.706609 16530 net.cpp:122] Setting up layer_128_4_relu2
I0528 22:21:57.706639 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.706643 16530 net.cpp:137] Memory required for data: 2940313800
I0528 22:21:57.706647 16530 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0528 22:21:57.706661 16530 net.cpp:84] Creating Layer layer_128_4_conv2
I0528 22:21:57.706683 16530 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0528 22:21:57.706692 16530 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0528 22:21:57.712563 16530 net.cpp:122] Setting up layer_128_4_conv2
I0528 22:21:57.712596 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.712601 16530 net.cpp:137] Memory required for data: 2960384200
I0528 22:21:57.712608 16530 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0528 22:21:57.712615 16530 net.cpp:84] Creating Layer layer_128_4_sum
I0528 22:21:57.712620 16530 net.cpp:406] layer_128_4_sum <- layer_128_4_conv2
I0528 22:21:57.712641 16530 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 22:21:57.712648 16530 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0528 22:21:57.712687 16530 net.cpp:122] Setting up layer_128_4_sum
I0528 22:21:57.712694 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.712698 16530 net.cpp:137] Memory required for data: 2980454600
I0528 22:21:57.712702 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 22:21:57.712710 16530 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 22:21:57.712714 16530 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0528 22:21:57.712720 16530 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 22:21:57.712957 16530 net.cpp:122] Setting up layer_256_1_bn1
I0528 22:21:57.712968 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.712983 16530 net.cpp:137] Memory required for data: 3000525000
I0528 22:21:57.712993 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 22:21:57.713001 16530 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 22:21:57.713027 16530 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 22:21:57.713034 16530 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 22:21:57.713091 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 22:21:57.713294 16530 net.cpp:122] Setting up layer_256_1_scale1
I0528 22:21:57.713310 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.713325 16530 net.cpp:137] Memory required for data: 3020595400
I0528 22:21:57.713330 16530 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 22:21:57.713340 16530 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 22:21:57.713343 16530 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 22:21:57.713359 16530 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 22:21:57.714071 16530 net.cpp:122] Setting up layer_256_1_relu1
I0528 22:21:57.714105 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.714126 16530 net.cpp:137] Memory required for data: 3040665800
I0528 22:21:57.714131 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:57.714138 16530 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:57.714143 16530 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 22:21:57.714165 16530 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 22:21:57.714174 16530 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 22:21:57.714227 16530 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:57.714236 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.714241 16530 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 22:21:57.714243 16530 net.cpp:137] Memory required for data: 3080806600
I0528 22:21:57.714247 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 22:21:57.714258 16530 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 22:21:57.714264 16530 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 22:21:57.714272 16530 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 22:21:57.724531 16530 net.cpp:122] Setting up layer_256_1_conv1
I0528 22:21:57.724563 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.724568 16530 net.cpp:137] Memory required for data: 3090841800
I0528 22:21:57.724575 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 22:21:57.724584 16530 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 22:21:57.724597 16530 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 22:21:57.724620 16530 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 22:21:57.724846 16530 net.cpp:122] Setting up layer_256_1_bn2
I0528 22:21:57.724869 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.724884 16530 net.cpp:137] Memory required for data: 3100877000
I0528 22:21:57.724892 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 22:21:57.724900 16530 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 22:21:57.724903 16530 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 22:21:57.724911 16530 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 22:21:57.724967 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 22:21:57.725100 16530 net.cpp:122] Setting up layer_256_1_scale2
I0528 22:21:57.725131 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.725138 16530 net.cpp:137] Memory required for data: 3110912200
I0528 22:21:57.725145 16530 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 22:21:57.725188 16530 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 22:21:57.725204 16530 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 22:21:57.725210 16530 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 22:21:57.725925 16530 net.cpp:122] Setting up layer_256_1_relu2
I0528 22:21:57.725942 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.725958 16530 net.cpp:137] Memory required for data: 3120947400
I0528 22:21:57.725962 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 22:21:57.725983 16530 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 22:21:57.725989 16530 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 22:21:57.725997 16530 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 22:21:57.743281 16530 net.cpp:122] Setting up layer_256_1_conv2
I0528 22:21:57.743314 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.743319 16530 net.cpp:137] Memory required for data: 3130982600
I0528 22:21:57.743325 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 22:21:57.743338 16530 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 22:21:57.743360 16530 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 22:21:57.743379 16530 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 22:21:57.746256 16530 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 22:21:57.746287 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.746294 16530 net.cpp:137] Memory required for data: 3141017800
I0528 22:21:57.746299 16530 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 22:21:57.746306 16530 net.cpp:84] Creating Layer layer_256_1_sum
I0528 22:21:57.746311 16530 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 22:21:57.746335 16530 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 22:21:57.746343 16530 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 22:21:57.746378 16530 net.cpp:122] Setting up layer_256_1_sum
I0528 22:21:57.746388 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.746392 16530 net.cpp:137] Memory required for data: 3151053000
I0528 22:21:57.746397 16530 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:57.746402 16530 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:57.746407 16530 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 22:21:57.746412 16530 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 22:21:57.746418 16530 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 22:21:57.746462 16530 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:57.746470 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.746475 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.746479 16530 net.cpp:137] Memory required for data: 3171123400
I0528 22:21:57.746481 16530 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 22:21:57.746490 16530 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 22:21:57.746505 16530 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 22:21:57.746511 16530 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 22:21:57.746754 16530 net.cpp:122] Setting up layer_256_2_bn1
I0528 22:21:57.746765 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.746780 16530 net.cpp:137] Memory required for data: 3181158600
I0528 22:21:57.746790 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 22:21:57.746798 16530 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 22:21:57.746803 16530 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 22:21:57.746831 16530 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 22:21:57.746879 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 22:21:57.747047 16530 net.cpp:122] Setting up layer_256_2_scale1
I0528 22:21:57.747071 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.747084 16530 net.cpp:137] Memory required for data: 3191193800
I0528 22:21:57.747090 16530 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 22:21:57.747110 16530 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 22:21:57.747122 16530 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 22:21:57.747131 16530 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 22:21:57.747851 16530 net.cpp:122] Setting up layer_256_2_relu1
I0528 22:21:57.747867 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.747884 16530 net.cpp:137] Memory required for data: 3201229000
I0528 22:21:57.747887 16530 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 22:21:57.747900 16530 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 22:21:57.747905 16530 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 22:21:57.747915 16530 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 22:21:57.765206 16530 net.cpp:122] Setting up layer_256_2_conv1
I0528 22:21:57.765239 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.765244 16530 net.cpp:137] Memory required for data: 3211264200
I0528 22:21:57.765260 16530 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 22:21:57.765278 16530 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 22:21:57.765295 16530 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 22:21:57.765305 16530 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 22:21:57.765525 16530 net.cpp:122] Setting up layer_256_2_bn2
I0528 22:21:57.765537 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.765552 16530 net.cpp:137] Memory required for data: 3221299400
I0528 22:21:57.765571 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 22:21:57.765590 16530 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 22:21:57.765595 16530 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 22:21:57.765604 16530 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 22:21:57.765648 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 22:21:57.765796 16530 net.cpp:122] Setting up layer_256_2_scale2
I0528 22:21:57.765810 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.765825 16530 net.cpp:137] Memory required for data: 3231334600
I0528 22:21:57.765842 16530 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 22:21:57.765848 16530 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 22:21:57.765852 16530 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 22:21:57.765879 16530 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 22:21:57.766605 16530 net.cpp:122] Setting up layer_256_2_relu2
I0528 22:21:57.766635 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.766640 16530 net.cpp:137] Memory required for data: 3241369800
I0528 22:21:57.766644 16530 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 22:21:57.766659 16530 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 22:21:57.766680 16530 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 22:21:57.766690 16530 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 22:21:57.784387 16530 net.cpp:122] Setting up layer_256_2_conv2
I0528 22:21:57.784421 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.784426 16530 net.cpp:137] Memory required for data: 3251405000
I0528 22:21:57.784432 16530 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 22:21:57.784440 16530 net.cpp:84] Creating Layer layer_256_2_sum
I0528 22:21:57.784446 16530 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 22:21:57.784466 16530 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 22:21:57.784472 16530 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 22:21:57.784509 16530 net.cpp:122] Setting up layer_256_2_sum
I0528 22:21:57.784518 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.784521 16530 net.cpp:137] Memory required for data: 3261440200
I0528 22:21:57.784525 16530 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:57.784531 16530 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:57.784535 16530 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0528 22:21:57.784543 16530 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 22:21:57.784550 16530 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 22:21:57.784590 16530 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:57.784598 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.784603 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.784606 16530 net.cpp:137] Memory required for data: 3281510600
I0528 22:21:57.784610 16530 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0528 22:21:57.784616 16530 net.cpp:84] Creating Layer layer_256_3_bn1
I0528 22:21:57.784621 16530 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 22:21:57.784643 16530 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0528 22:21:57.784912 16530 net.cpp:122] Setting up layer_256_3_bn1
I0528 22:21:57.784924 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.784939 16530 net.cpp:137] Memory required for data: 3291545800
I0528 22:21:57.784946 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 22:21:57.784965 16530 net.cpp:84] Creating Layer layer_256_3_scale1
I0528 22:21:57.784981 16530 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0528 22:21:57.784987 16530 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0528 22:21:57.785037 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 22:21:57.785205 16530 net.cpp:122] Setting up layer_256_3_scale1
I0528 22:21:57.785230 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.785245 16530 net.cpp:137] Memory required for data: 3301581000
I0528 22:21:57.785253 16530 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0528 22:21:57.785269 16530 net.cpp:84] Creating Layer layer_256_3_relu1
I0528 22:21:57.785274 16530 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0528 22:21:57.785281 16530 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0528 22:21:57.785503 16530 net.cpp:122] Setting up layer_256_3_relu1
I0528 22:21:57.785516 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.785532 16530 net.cpp:137] Memory required for data: 3311616200
I0528 22:21:57.785537 16530 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0528 22:21:57.785558 16530 net.cpp:84] Creating Layer layer_256_3_conv1
I0528 22:21:57.785584 16530 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0528 22:21:57.785606 16530 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0528 22:21:57.803310 16530 net.cpp:122] Setting up layer_256_3_conv1
I0528 22:21:57.803341 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.803346 16530 net.cpp:137] Memory required for data: 3321651400
I0528 22:21:57.803352 16530 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0528 22:21:57.803361 16530 net.cpp:84] Creating Layer layer_256_3_bn2
I0528 22:21:57.803367 16530 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0528 22:21:57.803387 16530 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0528 22:21:57.803609 16530 net.cpp:122] Setting up layer_256_3_bn2
I0528 22:21:57.803622 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.803637 16530 net.cpp:137] Memory required for data: 3331686600
I0528 22:21:57.803644 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 22:21:57.803670 16530 net.cpp:84] Creating Layer layer_256_3_scale2
I0528 22:21:57.803688 16530 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0528 22:21:57.803694 16530 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0528 22:21:57.803741 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 22:21:57.803891 16530 net.cpp:122] Setting up layer_256_3_scale2
I0528 22:21:57.803902 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.803917 16530 net.cpp:137] Memory required for data: 3341721800
I0528 22:21:57.803935 16530 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0528 22:21:57.803941 16530 net.cpp:84] Creating Layer layer_256_3_relu2
I0528 22:21:57.803946 16530 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0528 22:21:57.803970 16530 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0528 22:21:57.804697 16530 net.cpp:122] Setting up layer_256_3_relu2
I0528 22:21:57.804728 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.804733 16530 net.cpp:137] Memory required for data: 3351757000
I0528 22:21:57.804736 16530 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0528 22:21:57.804749 16530 net.cpp:84] Creating Layer layer_256_3_conv2
I0528 22:21:57.804754 16530 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0528 22:21:57.804777 16530 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0528 22:21:57.822068 16530 net.cpp:122] Setting up layer_256_3_conv2
I0528 22:21:57.822105 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822123 16530 net.cpp:137] Memory required for data: 3361792200
I0528 22:21:57.822154 16530 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0528 22:21:57.822162 16530 net.cpp:84] Creating Layer layer_256_3_sum
I0528 22:21:57.822167 16530 net.cpp:406] layer_256_3_sum <- layer_256_3_conv2
I0528 22:21:57.822172 16530 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 22:21:57.822180 16530 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0528 22:21:57.822214 16530 net.cpp:122] Setting up layer_256_3_sum
I0528 22:21:57.822221 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822226 16530 net.cpp:137] Memory required for data: 3371827400
I0528 22:21:57.822229 16530 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:57.822237 16530 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:57.822240 16530 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0528 22:21:57.822245 16530 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 22:21:57.822252 16530 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 22:21:57.822294 16530 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:57.822302 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822306 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822309 16530 net.cpp:137] Memory required for data: 3391897800
I0528 22:21:57.822314 16530 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0528 22:21:57.822332 16530 net.cpp:84] Creating Layer layer_256_4_bn1
I0528 22:21:57.822337 16530 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 22:21:57.822343 16530 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0528 22:21:57.822602 16530 net.cpp:122] Setting up layer_256_4_bn1
I0528 22:21:57.822613 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822628 16530 net.cpp:137] Memory required for data: 3401933000
I0528 22:21:57.822636 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 22:21:57.822654 16530 net.cpp:84] Creating Layer layer_256_4_scale1
I0528 22:21:57.822670 16530 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0528 22:21:57.822676 16530 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0528 22:21:57.822737 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 22:21:57.822901 16530 net.cpp:122] Setting up layer_256_4_scale1
I0528 22:21:57.822911 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.822927 16530 net.cpp:137] Memory required for data: 3411968200
I0528 22:21:57.822944 16530 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0528 22:21:57.822952 16530 net.cpp:84] Creating Layer layer_256_4_relu1
I0528 22:21:57.822955 16530 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0528 22:21:57.822963 16530 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0528 22:21:57.824008 16530 net.cpp:122] Setting up layer_256_4_relu1
I0528 22:21:57.824039 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.824044 16530 net.cpp:137] Memory required for data: 3422003400
I0528 22:21:57.824049 16530 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0528 22:21:57.824061 16530 net.cpp:84] Creating Layer layer_256_4_conv1
I0528 22:21:57.824084 16530 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0528 22:21:57.824095 16530 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0528 22:21:57.842869 16530 net.cpp:122] Setting up layer_256_4_conv1
I0528 22:21:57.842902 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.842908 16530 net.cpp:137] Memory required for data: 3432038600
I0528 22:21:57.842914 16530 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0528 22:21:57.842923 16530 net.cpp:84] Creating Layer layer_256_4_bn2
I0528 22:21:57.842936 16530 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0528 22:21:57.842962 16530 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0528 22:21:57.843217 16530 net.cpp:122] Setting up layer_256_4_bn2
I0528 22:21:57.843231 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.843247 16530 net.cpp:137] Memory required for data: 3442073800
I0528 22:21:57.843257 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 22:21:57.843266 16530 net.cpp:84] Creating Layer layer_256_4_scale2
I0528 22:21:57.843297 16530 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0528 22:21:57.843303 16530 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0528 22:21:57.843353 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 22:21:57.843507 16530 net.cpp:122] Setting up layer_256_4_scale2
I0528 22:21:57.843518 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.843533 16530 net.cpp:137] Memory required for data: 3452109000
I0528 22:21:57.843550 16530 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0528 22:21:57.843570 16530 net.cpp:84] Creating Layer layer_256_4_relu2
I0528 22:21:57.843576 16530 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0528 22:21:57.843581 16530 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0528 22:21:57.843822 16530 net.cpp:122] Setting up layer_256_4_relu2
I0528 22:21:57.843849 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.843865 16530 net.cpp:137] Memory required for data: 3462144200
I0528 22:21:57.843869 16530 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0528 22:21:57.843893 16530 net.cpp:84] Creating Layer layer_256_4_conv2
I0528 22:21:57.843897 16530 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0528 22:21:57.843904 16530 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0528 22:21:57.861632 16530 net.cpp:122] Setting up layer_256_4_conv2
I0528 22:21:57.861663 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.861670 16530 net.cpp:137] Memory required for data: 3472179400
I0528 22:21:57.861675 16530 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0528 22:21:57.861685 16530 net.cpp:84] Creating Layer layer_256_4_sum
I0528 22:21:57.861690 16530 net.cpp:406] layer_256_4_sum <- layer_256_4_conv2
I0528 22:21:57.861709 16530 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 22:21:57.861716 16530 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0528 22:21:57.861752 16530 net.cpp:122] Setting up layer_256_4_sum
I0528 22:21:57.861760 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.861764 16530 net.cpp:137] Memory required for data: 3482214600
I0528 22:21:57.861768 16530 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:57.861774 16530 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:57.861778 16530 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0528 22:21:57.861786 16530 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 22:21:57.861793 16530 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 22:21:57.861835 16530 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:57.861841 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.861846 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.861850 16530 net.cpp:137] Memory required for data: 3502285000
I0528 22:21:57.861852 16530 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0528 22:21:57.861861 16530 net.cpp:84] Creating Layer layer_256_5_bn1
I0528 22:21:57.861876 16530 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 22:21:57.861884 16530 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0528 22:21:57.862167 16530 net.cpp:122] Setting up layer_256_5_bn1
I0528 22:21:57.862182 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.862202 16530 net.cpp:137] Memory required for data: 3512320200
I0528 22:21:57.862227 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 22:21:57.862268 16530 net.cpp:84] Creating Layer layer_256_5_scale1
I0528 22:21:57.862273 16530 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0528 22:21:57.862279 16530 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0528 22:21:57.862344 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 22:21:57.862519 16530 net.cpp:122] Setting up layer_256_5_scale1
I0528 22:21:57.862531 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.862546 16530 net.cpp:137] Memory required for data: 3522355400
I0528 22:21:57.862553 16530 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0528 22:21:57.862560 16530 net.cpp:84] Creating Layer layer_256_5_relu1
I0528 22:21:57.862565 16530 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0528 22:21:57.862579 16530 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0528 22:21:57.863288 16530 net.cpp:122] Setting up layer_256_5_relu1
I0528 22:21:57.863322 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.863327 16530 net.cpp:137] Memory required for data: 3532390600
I0528 22:21:57.863330 16530 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0528 22:21:57.863343 16530 net.cpp:84] Creating Layer layer_256_5_conv1
I0528 22:21:57.863364 16530 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0528 22:21:57.863373 16530 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0528 22:21:57.881188 16530 net.cpp:122] Setting up layer_256_5_conv1
I0528 22:21:57.881220 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.881225 16530 net.cpp:137] Memory required for data: 3542425800
I0528 22:21:57.881232 16530 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0528 22:21:57.881244 16530 net.cpp:84] Creating Layer layer_256_5_bn2
I0528 22:21:57.881264 16530 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0528 22:21:57.881273 16530 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0528 22:21:57.881510 16530 net.cpp:122] Setting up layer_256_5_bn2
I0528 22:21:57.881531 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.881546 16530 net.cpp:137] Memory required for data: 3552461000
I0528 22:21:57.881554 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 22:21:57.881563 16530 net.cpp:84] Creating Layer layer_256_5_scale2
I0528 22:21:57.881569 16530 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0528 22:21:57.881585 16530 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0528 22:21:57.881647 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 22:21:57.881813 16530 net.cpp:122] Setting up layer_256_5_scale2
I0528 22:21:57.881824 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.881839 16530 net.cpp:137] Memory required for data: 3562496200
I0528 22:21:57.881855 16530 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0528 22:21:57.881860 16530 net.cpp:84] Creating Layer layer_256_5_relu2
I0528 22:21:57.881886 16530 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0528 22:21:57.881894 16530 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0528 22:21:57.882575 16530 net.cpp:122] Setting up layer_256_5_relu2
I0528 22:21:57.882593 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.882609 16530 net.cpp:137] Memory required for data: 3572531400
I0528 22:21:57.882613 16530 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0528 22:21:57.882625 16530 net.cpp:84] Creating Layer layer_256_5_conv2
I0528 22:21:57.882632 16530 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0528 22:21:57.882655 16530 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0528 22:21:57.900337 16530 net.cpp:122] Setting up layer_256_5_conv2
I0528 22:21:57.900369 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.900375 16530 net.cpp:137] Memory required for data: 3582566600
I0528 22:21:57.900382 16530 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0528 22:21:57.900400 16530 net.cpp:84] Creating Layer layer_256_5_sum
I0528 22:21:57.900408 16530 net.cpp:406] layer_256_5_sum <- layer_256_5_conv2
I0528 22:21:57.900413 16530 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 22:21:57.900418 16530 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0528 22:21:57.900450 16530 net.cpp:122] Setting up layer_256_5_sum
I0528 22:21:57.900461 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.900465 16530 net.cpp:137] Memory required for data: 3592601800
I0528 22:21:57.900468 16530 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:57.900475 16530 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:57.900480 16530 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0528 22:21:57.900486 16530 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 22:21:57.900493 16530 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 22:21:57.900534 16530 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:57.900542 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.900547 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.900549 16530 net.cpp:137] Memory required for data: 3612672200
I0528 22:21:57.900564 16530 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0528 22:21:57.900589 16530 net.cpp:84] Creating Layer layer_256_6_bn1
I0528 22:21:57.900594 16530 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 22:21:57.900601 16530 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0528 22:21:57.900879 16530 net.cpp:122] Setting up layer_256_6_bn1
I0528 22:21:57.900890 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.900894 16530 net.cpp:137] Memory required for data: 3622707400
I0528 22:21:57.900902 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 22:21:57.900910 16530 net.cpp:84] Creating Layer layer_256_6_scale1
I0528 22:21:57.900914 16530 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0528 22:21:57.900920 16530 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0528 22:21:57.900995 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 22:21:57.901188 16530 net.cpp:122] Setting up layer_256_6_scale1
I0528 22:21:57.901214 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.901229 16530 net.cpp:137] Memory required for data: 3632742600
I0528 22:21:57.901237 16530 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0528 22:21:57.901243 16530 net.cpp:84] Creating Layer layer_256_6_relu1
I0528 22:21:57.901258 16530 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0528 22:21:57.901288 16530 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0528 22:21:57.901521 16530 net.cpp:122] Setting up layer_256_6_relu1
I0528 22:21:57.901545 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.901559 16530 net.cpp:137] Memory required for data: 3642777800
I0528 22:21:57.901563 16530 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0528 22:21:57.901576 16530 net.cpp:84] Creating Layer layer_256_6_conv1
I0528 22:21:57.901581 16530 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0528 22:21:57.901589 16530 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0528 22:21:57.919338 16530 net.cpp:122] Setting up layer_256_6_conv1
I0528 22:21:57.919358 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.919374 16530 net.cpp:137] Memory required for data: 3652813000
I0528 22:21:57.919380 16530 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0528 22:21:57.919390 16530 net.cpp:84] Creating Layer layer_256_6_bn2
I0528 22:21:57.919395 16530 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0528 22:21:57.919416 16530 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0528 22:21:57.919657 16530 net.cpp:122] Setting up layer_256_6_bn2
I0528 22:21:57.919685 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.919708 16530 net.cpp:137] Memory required for data: 3662848200
I0528 22:21:57.919716 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 22:21:57.919726 16530 net.cpp:84] Creating Layer layer_256_6_scale2
I0528 22:21:57.919731 16530 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0528 22:21:57.919737 16530 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0528 22:21:57.919800 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 22:21:57.919966 16530 net.cpp:122] Setting up layer_256_6_scale2
I0528 22:21:57.919977 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.919992 16530 net.cpp:137] Memory required for data: 3672883400
I0528 22:21:57.920011 16530 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0528 22:21:57.920017 16530 net.cpp:84] Creating Layer layer_256_6_relu2
I0528 22:21:57.920022 16530 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0528 22:21:57.920039 16530 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0528 22:21:57.920747 16530 net.cpp:122] Setting up layer_256_6_relu2
I0528 22:21:57.920766 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.920783 16530 net.cpp:137] Memory required for data: 3682918600
I0528 22:21:57.920786 16530 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0528 22:21:57.920799 16530 net.cpp:84] Creating Layer layer_256_6_conv2
I0528 22:21:57.920804 16530 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0528 22:21:57.920814 16530 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0528 22:21:57.938094 16530 net.cpp:122] Setting up layer_256_6_conv2
I0528 22:21:57.938130 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.938138 16530 net.cpp:137] Memory required for data: 3692953800
I0528 22:21:57.938144 16530 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0528 22:21:57.938153 16530 net.cpp:84] Creating Layer layer_256_6_sum
I0528 22:21:57.938171 16530 net.cpp:406] layer_256_6_sum <- layer_256_6_conv2
I0528 22:21:57.938177 16530 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 22:21:57.938184 16530 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0528 22:21:57.938220 16530 net.cpp:122] Setting up layer_256_6_sum
I0528 22:21:57.938228 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.938231 16530 net.cpp:137] Memory required for data: 3702989000
I0528 22:21:57.938235 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 22:21:57.938244 16530 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 22:21:57.938248 16530 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0528 22:21:57.938254 16530 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 22:21:57.938513 16530 net.cpp:122] Setting up layer_512_1_bn1
I0528 22:21:57.938535 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.938539 16530 net.cpp:137] Memory required for data: 3713024200
I0528 22:21:57.938560 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 22:21:57.938578 16530 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 22:21:57.938583 16530 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 22:21:57.938601 16530 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 22:21:57.938673 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 22:21:57.938880 16530 net.cpp:122] Setting up layer_512_1_scale1
I0528 22:21:57.938891 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.938906 16530 net.cpp:137] Memory required for data: 3723059400
I0528 22:21:57.938913 16530 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 22:21:57.938920 16530 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 22:21:57.938925 16530 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 22:21:57.938942 16530 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 22:21:57.939630 16530 net.cpp:122] Setting up layer_512_1_relu1
I0528 22:21:57.939666 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.939677 16530 net.cpp:137] Memory required for data: 3733094600
I0528 22:21:57.939682 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:57.939688 16530 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:57.939712 16530 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 22:21:57.939718 16530 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 22:21:57.939726 16530 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 22:21:57.939779 16530 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:57.939787 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.939792 16530 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 22:21:57.939795 16530 net.cpp:137] Memory required for data: 3753165000
I0528 22:21:57.939800 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 22:21:57.939810 16530 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 22:21:57.939815 16530 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 22:21:57.939822 16530 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 22:21:57.973913 16530 net.cpp:122] Setting up layer_512_1_conv1
I0528 22:21:57.973947 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:57.973953 16530 net.cpp:137] Memory required for data: 3758182600
I0528 22:21:57.973958 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 22:21:57.973965 16530 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 22:21:57.973970 16530 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 22:21:57.973994 16530 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 22:21:57.974269 16530 net.cpp:122] Setting up layer_512_1_bn2
I0528 22:21:57.974284 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:57.974300 16530 net.cpp:137] Memory required for data: 3763200200
I0528 22:21:57.974308 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 22:21:57.974329 16530 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 22:21:57.974350 16530 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 22:21:57.974357 16530 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 22:21:57.974406 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 22:21:57.974602 16530 net.cpp:122] Setting up layer_512_1_scale2
I0528 22:21:57.974614 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:57.974628 16530 net.cpp:137] Memory required for data: 3768217800
I0528 22:21:57.974635 16530 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 22:21:57.974642 16530 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 22:21:57.974647 16530 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 22:21:57.974653 16530 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 22:21:57.974875 16530 net.cpp:122] Setting up layer_512_1_relu2
I0528 22:21:57.974889 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:57.974905 16530 net.cpp:137] Memory required for data: 3773235400
I0528 22:21:57.974908 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 22:21:57.974942 16530 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 22:21:57.974948 16530 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 22:21:57.974957 16530 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 22:21:58.043330 16530 net.cpp:122] Setting up layer_512_1_conv2
I0528 22:21:58.043375 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.043380 16530 net.cpp:137] Memory required for data: 3778253000
I0528 22:21:58.043393 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 22:21:58.043426 16530 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 22:21:58.043440 16530 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 22:21:58.043457 16530 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 22:21:58.049031 16530 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 22:21:58.049062 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.049067 16530 net.cpp:137] Memory required for data: 3783270600
I0528 22:21:58.049074 16530 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 22:21:58.049083 16530 net.cpp:84] Creating Layer layer_512_1_sum
I0528 22:21:58.049088 16530 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 22:21:58.049108 16530 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 22:21:58.049120 16530 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 22:21:58.049180 16530 net.cpp:122] Setting up layer_512_1_sum
I0528 22:21:58.049188 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.049192 16530 net.cpp:137] Memory required for data: 3788288200
I0528 22:21:58.049196 16530 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.049207 16530 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.049213 16530 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 22:21:58.049221 16530 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 22:21:58.049228 16530 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 22:21:58.049274 16530 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.049296 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.049301 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.049305 16530 net.cpp:137] Memory required for data: 3798323400
I0528 22:21:58.049309 16530 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 22:21:58.049335 16530 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 22:21:58.049340 16530 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 22:21:58.049348 16530 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 22:21:58.049721 16530 net.cpp:122] Setting up layer_512_2_bn1
I0528 22:21:58.049742 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.049757 16530 net.cpp:137] Memory required for data: 3803341000
I0528 22:21:58.049765 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 22:21:58.049773 16530 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 22:21:58.049778 16530 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 22:21:58.049796 16530 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 22:21:58.049860 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 22:21:58.050051 16530 net.cpp:122] Setting up layer_512_2_scale1
I0528 22:21:58.050062 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.050077 16530 net.cpp:137] Memory required for data: 3808358600
I0528 22:21:58.050096 16530 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 22:21:58.050127 16530 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 22:21:58.050150 16530 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 22:21:58.050159 16530 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 22:21:58.050431 16530 net.cpp:122] Setting up layer_512_2_relu1
I0528 22:21:58.050456 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.050460 16530 net.cpp:137] Memory required for data: 3813376200
I0528 22:21:58.050474 16530 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 22:21:58.050487 16530 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 22:21:58.050514 16530 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 22:21:58.050524 16530 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 22:21:58.116076 16530 net.cpp:122] Setting up layer_512_2_conv1
I0528 22:21:58.116109 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.116120 16530 net.cpp:137] Memory required for data: 3818393800
I0528 22:21:58.116133 16530 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 22:21:58.116153 16530 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 22:21:58.116159 16530 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 22:21:58.116165 16530 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.116416 16530 net.cpp:122] Setting up layer_512_2_bn2
I0528 22:21:58.116428 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.116443 16530 net.cpp:137] Memory required for data: 3823411400
I0528 22:21:58.116464 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 22:21:58.116473 16530 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 22:21:58.116478 16530 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 22:21:58.116485 16530 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.116545 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 22:21:58.116709 16530 net.cpp:122] Setting up layer_512_2_scale2
I0528 22:21:58.116732 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.116747 16530 net.cpp:137] Memory required for data: 3828429000
I0528 22:21:58.116753 16530 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 22:21:58.116771 16530 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 22:21:58.116776 16530 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 22:21:58.116792 16530 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.117553 16530 net.cpp:122] Setting up layer_512_2_relu2
I0528 22:21:58.117583 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.117588 16530 net.cpp:137] Memory required for data: 3833446600
I0528 22:21:58.117594 16530 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 22:21:58.117606 16530 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 22:21:58.117630 16530 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 22:21:58.117640 16530 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 22:21:58.183189 16530 net.cpp:122] Setting up layer_512_2_conv2
I0528 22:21:58.183223 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.183228 16530 net.cpp:137] Memory required for data: 3838464200
I0528 22:21:58.183233 16530 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 22:21:58.183243 16530 net.cpp:84] Creating Layer layer_512_2_sum
I0528 22:21:58.183248 16530 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 22:21:58.183269 16530 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 22:21:58.183275 16530 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 22:21:58.183315 16530 net.cpp:122] Setting up layer_512_2_sum
I0528 22:21:58.183323 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.183326 16530 net.cpp:137] Memory required for data: 3843481800
I0528 22:21:58.183331 16530 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.183338 16530 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.183342 16530 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0528 22:21:58.183349 16530 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 22:21:58.183357 16530 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 22:21:58.183400 16530 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.183410 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.183415 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.183418 16530 net.cpp:137] Memory required for data: 3853517000
I0528 22:21:58.183423 16530 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0528 22:21:58.183429 16530 net.cpp:84] Creating Layer layer_512_3_bn1
I0528 22:21:58.183432 16530 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 22:21:58.183451 16530 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0528 22:21:58.183737 16530 net.cpp:122] Setting up layer_512_3_bn1
I0528 22:21:58.183758 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.183773 16530 net.cpp:137] Memory required for data: 3858534600
I0528 22:21:58.183794 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 22:21:58.183814 16530 net.cpp:84] Creating Layer layer_512_3_scale1
I0528 22:21:58.183818 16530 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0528 22:21:58.183837 16530 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0528 22:21:58.183887 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 22:21:58.184110 16530 net.cpp:122] Setting up layer_512_3_scale1
I0528 22:21:58.184154 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.184159 16530 net.cpp:137] Memory required for data: 3863552200
I0528 22:21:58.184175 16530 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0528 22:21:58.184181 16530 net.cpp:84] Creating Layer layer_512_3_relu1
I0528 22:21:58.184204 16530 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0528 22:21:58.184222 16530 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0528 22:21:58.184489 16530 net.cpp:122] Setting up layer_512_3_relu1
I0528 22:21:58.184502 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.184518 16530 net.cpp:137] Memory required for data: 3868569800
I0528 22:21:58.184533 16530 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0528 22:21:58.184556 16530 net.cpp:84] Creating Layer layer_512_3_conv1
I0528 22:21:58.184561 16530 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0528 22:21:58.184571 16530 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0528 22:21:58.250109 16530 net.cpp:122] Setting up layer_512_3_conv1
I0528 22:21:58.250147 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.250154 16530 net.cpp:137] Memory required for data: 3873587400
I0528 22:21:58.250159 16530 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0528 22:21:58.250172 16530 net.cpp:84] Creating Layer layer_512_3_bn2
I0528 22:21:58.250193 16530 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0528 22:21:58.250201 16530 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.250459 16530 net.cpp:122] Setting up layer_512_3_bn2
I0528 22:21:58.250470 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.250485 16530 net.cpp:137] Memory required for data: 3878605000
I0528 22:21:58.250505 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 22:21:58.250514 16530 net.cpp:84] Creating Layer layer_512_3_scale2
I0528 22:21:58.250529 16530 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0528 22:21:58.250535 16530 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.250598 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 22:21:58.250766 16530 net.cpp:122] Setting up layer_512_3_scale2
I0528 22:21:58.250789 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.250804 16530 net.cpp:137] Memory required for data: 3883622600
I0528 22:21:58.250811 16530 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0528 22:21:58.250828 16530 net.cpp:84] Creating Layer layer_512_3_relu2
I0528 22:21:58.250833 16530 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0528 22:21:58.250865 16530 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.251109 16530 net.cpp:122] Setting up layer_512_3_relu2
I0528 22:21:58.251155 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.251173 16530 net.cpp:137] Memory required for data: 3888640200
I0528 22:21:58.251176 16530 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0528 22:21:58.251201 16530 net.cpp:84] Creating Layer layer_512_3_conv2
I0528 22:21:58.251217 16530 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0528 22:21:58.251242 16530 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0528 22:21:58.317234 16530 net.cpp:122] Setting up layer_512_3_conv2
I0528 22:21:58.317266 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.317282 16530 net.cpp:137] Memory required for data: 3893657800
I0528 22:21:58.317315 16530 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0528 22:21:58.317323 16530 net.cpp:84] Creating Layer layer_512_3_sum
I0528 22:21:58.317328 16530 net.cpp:406] layer_512_3_sum <- layer_512_3_conv2
I0528 22:21:58.317334 16530 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 22:21:58.317342 16530 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0528 22:21:58.317379 16530 net.cpp:122] Setting up layer_512_3_sum
I0528 22:21:58.317390 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.317394 16530 net.cpp:137] Memory required for data: 3898675400
I0528 22:21:58.317397 16530 layer_factory.hpp:77] Creating layer last_bn
I0528 22:21:58.317404 16530 net.cpp:84] Creating Layer last_bn
I0528 22:21:58.317409 16530 net.cpp:406] last_bn <- layer_512_3_sum
I0528 22:21:58.317420 16530 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0528 22:21:58.317680 16530 net.cpp:122] Setting up last_bn
I0528 22:21:58.317692 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.317706 16530 net.cpp:137] Memory required for data: 3903693000
I0528 22:21:58.317714 16530 layer_factory.hpp:77] Creating layer last_scale
I0528 22:21:58.317736 16530 net.cpp:84] Creating Layer last_scale
I0528 22:21:58.317761 16530 net.cpp:406] last_scale <- layer_512_3_sum
I0528 22:21:58.317769 16530 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0528 22:21:58.317819 16530 layer_factory.hpp:77] Creating layer last_scale
I0528 22:21:58.318050 16530 net.cpp:122] Setting up last_scale
I0528 22:21:58.318063 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.318078 16530 net.cpp:137] Memory required for data: 3908710600
I0528 22:21:58.318084 16530 layer_factory.hpp:77] Creating layer last_relu
I0528 22:21:58.318099 16530 net.cpp:84] Creating Layer last_relu
I0528 22:21:58.318123 16530 net.cpp:406] last_relu <- layer_512_3_sum
I0528 22:21:58.318161 16530 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0528 22:21:58.318894 16530 net.cpp:122] Setting up last_relu
I0528 22:21:58.318910 16530 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 22:21:58.318927 16530 net.cpp:137] Memory required for data: 3913728200
I0528 22:21:58.318930 16530 layer_factory.hpp:77] Creating layer global_pool
I0528 22:21:58.318938 16530 net.cpp:84] Creating Layer global_pool
I0528 22:21:58.318943 16530 net.cpp:406] global_pool <- layer_512_3_sum
I0528 22:21:58.318956 16530 net.cpp:380] global_pool -> global_pool
I0528 22:21:58.319244 16530 net.cpp:122] Setting up global_pool
I0528 22:21:58.319262 16530 net.cpp:129] Top shape: 50 512 1 1 (25600)
I0528 22:21:58.319278 16530 net.cpp:137] Memory required for data: 3913830600
I0528 22:21:58.319293 16530 layer_factory.hpp:77] Creating layer score
I0528 22:21:58.319306 16530 net.cpp:84] Creating Layer score
I0528 22:21:58.319326 16530 net.cpp:406] score <- global_pool
I0528 22:21:58.319339 16530 net.cpp:380] score -> score
I0528 22:21:58.319579 16530 net.cpp:122] Setting up score
I0528 22:21:58.319591 16530 net.cpp:129] Top shape: 50 8 (400)
I0528 22:21:58.319605 16530 net.cpp:137] Memory required for data: 3913832200
I0528 22:21:58.319623 16530 layer_factory.hpp:77] Creating layer loss
I0528 22:21:58.319633 16530 net.cpp:84] Creating Layer loss
I0528 22:21:58.319658 16530 net.cpp:406] loss <- score
I0528 22:21:58.319674 16530 net.cpp:406] loss <- label
I0528 22:21:58.319682 16530 net.cpp:380] loss -> loss
I0528 22:21:58.319700 16530 layer_factory.hpp:77] Creating layer loss
I0528 22:21:58.320569 16530 net.cpp:122] Setting up loss
I0528 22:21:58.320587 16530 net.cpp:129] Top shape: (1)
I0528 22:21:58.320605 16530 net.cpp:132]     with loss weight 1
I0528 22:21:58.320644 16530 net.cpp:137] Memory required for data: 3913832204
I0528 22:21:58.320649 16530 net.cpp:198] loss needs backward computation.
I0528 22:21:58.320654 16530 net.cpp:198] score needs backward computation.
I0528 22:21:58.320658 16530 net.cpp:198] global_pool needs backward computation.
I0528 22:21:58.320667 16530 net.cpp:198] last_relu needs backward computation.
I0528 22:21:58.320679 16530 net.cpp:198] last_scale needs backward computation.
I0528 22:21:58.320683 16530 net.cpp:198] last_bn needs backward computation.
I0528 22:21:58.320686 16530 net.cpp:198] layer_512_3_sum needs backward computation.
I0528 22:21:58.320690 16530 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0528 22:21:58.320698 16530 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0528 22:21:58.320703 16530 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0528 22:21:58.320706 16530 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0528 22:21:58.320709 16530 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0528 22:21:58.320713 16530 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0528 22:21:58.320718 16530 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0528 22:21:58.320720 16530 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0528 22:21:58.320724 16530 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0528 22:21:58.320729 16530 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 22:21:58.320734 16530 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 22:21:58.320736 16530 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 22:21:58.320740 16530 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 22:21:58.320744 16530 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 22:21:58.320747 16530 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 22:21:58.320751 16530 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 22:21:58.320755 16530 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 22:21:58.320758 16530 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 22:21:58.320773 16530 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 22:21:58.320777 16530 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 22:21:58.320782 16530 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 22:21:58.320786 16530 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 22:21:58.320791 16530 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 22:21:58.320796 16530 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 22:21:58.320799 16530 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 22:21:58.320803 16530 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 22:21:58.320808 16530 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 22:21:58.320812 16530 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 22:21:58.320816 16530 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 22:21:58.320821 16530 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 22:21:58.320825 16530 net.cpp:198] layer_256_6_sum needs backward computation.
I0528 22:21:58.320830 16530 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0528 22:21:58.320835 16530 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0528 22:21:58.320840 16530 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0528 22:21:58.320843 16530 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0528 22:21:58.320848 16530 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0528 22:21:58.320853 16530 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0528 22:21:58.320858 16530 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0528 22:21:58.320873 16530 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0528 22:21:58.320878 16530 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0528 22:21:58.320883 16530 net.cpp:198] layer_256_5_sum needs backward computation.
I0528 22:21:58.320888 16530 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0528 22:21:58.320904 16530 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0528 22:21:58.320910 16530 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0528 22:21:58.320919 16530 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0528 22:21:58.320922 16530 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0528 22:21:58.320929 16530 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0528 22:21:58.320933 16530 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0528 22:21:58.320937 16530 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0528 22:21:58.320942 16530 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0528 22:21:58.320946 16530 net.cpp:198] layer_256_4_sum needs backward computation.
I0528 22:21:58.320953 16530 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0528 22:21:58.320958 16530 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0528 22:21:58.320962 16530 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0528 22:21:58.320966 16530 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0528 22:21:58.320971 16530 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0528 22:21:58.320976 16530 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0528 22:21:58.320981 16530 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0528 22:21:58.320998 16530 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0528 22:21:58.321002 16530 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0528 22:21:58.321007 16530 net.cpp:198] layer_256_3_sum needs backward computation.
I0528 22:21:58.321012 16530 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0528 22:21:58.321029 16530 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0528 22:21:58.321034 16530 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0528 22:21:58.321038 16530 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0528 22:21:58.321043 16530 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0528 22:21:58.321049 16530 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0528 22:21:58.321053 16530 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0528 22:21:58.321058 16530 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0528 22:21:58.321063 16530 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0528 22:21:58.321069 16530 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 22:21:58.321074 16530 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 22:21:58.321079 16530 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 22:21:58.321084 16530 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 22:21:58.321089 16530 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 22:21:58.321091 16530 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 22:21:58.321097 16530 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 22:21:58.321101 16530 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 22:21:58.321105 16530 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 22:21:58.321110 16530 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 22:21:58.321122 16530 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 22:21:58.321143 16530 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 22:21:58.321149 16530 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 22:21:58.321154 16530 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 22:21:58.321158 16530 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 22:21:58.321164 16530 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 22:21:58.321168 16530 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 22:21:58.321173 16530 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 22:21:58.321177 16530 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 22:21:58.321190 16530 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 22:21:58.321197 16530 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 22:21:58.321202 16530 net.cpp:198] layer_128_4_sum needs backward computation.
I0528 22:21:58.321219 16530 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0528 22:21:58.321236 16530 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0528 22:21:58.321240 16530 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0528 22:21:58.321257 16530 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0528 22:21:58.321262 16530 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0528 22:21:58.321282 16530 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0528 22:21:58.321287 16530 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0528 22:21:58.321291 16530 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0528 22:21:58.321297 16530 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0528 22:21:58.321302 16530 net.cpp:198] layer_128_3_sum needs backward computation.
I0528 22:21:58.321307 16530 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0528 22:21:58.321312 16530 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0528 22:21:58.321317 16530 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0528 22:21:58.321323 16530 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0528 22:21:58.321328 16530 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0528 22:21:58.321333 16530 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0528 22:21:58.321337 16530 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0528 22:21:58.321342 16530 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0528 22:21:58.321347 16530 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0528 22:21:58.321364 16530 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 22:21:58.321370 16530 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 22:21:58.321375 16530 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 22:21:58.321379 16530 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 22:21:58.321394 16530 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 22:21:58.321398 16530 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 22:21:58.321404 16530 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 22:21:58.321408 16530 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 22:21:58.321414 16530 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 22:21:58.321419 16530 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 22:21:58.321424 16530 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 22:21:58.321429 16530 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 22:21:58.321434 16530 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 22:21:58.321439 16530 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 22:21:58.321444 16530 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 22:21:58.321449 16530 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 22:21:58.321454 16530 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 22:21:58.321457 16530 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 22:21:58.321461 16530 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 22:21:58.321466 16530 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 22:21:58.321481 16530 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 22:21:58.321485 16530 net.cpp:198] layer_64_3_sum needs backward computation.
I0528 22:21:58.321491 16530 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0528 22:21:58.321496 16530 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0528 22:21:58.321503 16530 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0528 22:21:58.321523 16530 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0528 22:21:58.321529 16530 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0528 22:21:58.321534 16530 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0528 22:21:58.321539 16530 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0528 22:21:58.321544 16530 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0528 22:21:58.321548 16530 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0528 22:21:58.321553 16530 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 22:21:58.321561 16530 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 22:21:58.321568 16530 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 22:21:58.321573 16530 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 22:21:58.321578 16530 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 22:21:58.321583 16530 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 22:21:58.321588 16530 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 22:21:58.321593 16530 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 22:21:58.321597 16530 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 22:21:58.321614 16530 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 22:21:58.321617 16530 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 22:21:58.321622 16530 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 22:21:58.321627 16530 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 22:21:58.321643 16530 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 22:21:58.321648 16530 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 22:21:58.321653 16530 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 22:21:58.321657 16530 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 22:21:58.321662 16530 net.cpp:198] conv1_pool needs backward computation.
I0528 22:21:58.321668 16530 net.cpp:198] conv1_relu needs backward computation.
I0528 22:21:58.321673 16530 net.cpp:198] conv1_scale needs backward computation.
I0528 22:21:58.321677 16530 net.cpp:198] conv1_bn needs backward computation.
I0528 22:21:58.321681 16530 net.cpp:198] conv1 needs backward computation.
I0528 22:21:58.321687 16530 net.cpp:198] data_scale needs backward computation.
I0528 22:21:58.321702 16530 net.cpp:200] data_bn does not need backward computation.
I0528 22:21:58.321707 16530 net.cpp:200] data does not need backward computation.
I0528 22:21:58.321710 16530 net.cpp:242] This network produces output loss
I0528 22:21:58.321851 16530 net.cpp:255] Network initialization done.
I0528 22:21:58.326236 16530 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 34_train_val_test_fold_is_0.prototxt
I0528 22:21:58.326269 16530 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 22:21:58.326280 16530 solver.cpp:172] Creating test net (#0) specified by net file: 34_train_val_test_fold_is_0.prototxt
I0528 22:21:58.326477 16530 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0528 22:21:58.327514 16530 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-34"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/age_val_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv2"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv2"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv2"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_256_3_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_256_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_3_scale1"
  type: "Scale"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_3_relu1"
  type: "ReLU"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_bn1"
}
layer {
  name: "layer_256_3_conv1"
  type: "Convolution"
  bottom: "layer_256_3_bn1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_3_bn2"
  type: "BatchNorm"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_3_scale2"
  type: "Scale"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_3_relu2"
  type: "ReLU"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv1"
}
layer {
  name: "layer_256_3_conv2"
  type: "Convolution"
  bottom: "layer_256_3_conv1"
  top: "layer_256_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_3_sum"
  type: "Eltwise"
  bottom: "layer_256_3_conv2"
  bottom: "layer_256_2_sum"
  top: "layer_256_3_sum"
}
layer {
  name: "layer_256_4_bn1"
  type: "BatchNorm"
  bottom: "layer_256_3_sum"
  top: "layer_256_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_4_scale1"
  type: "Scale"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_4_relu1"
  type: "ReLU"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_bn1"
}
layer {
  name: "layer_256_4_conv1"
  type: "Convolution"
  bottom: "layer_256_4_bn1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_4_bn2"
  type: "BatchNorm"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_4_scale2"
  type: "Scale"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_4_relu2"
  type: "ReLU"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv1"
}
layer {
  name: "layer_256_4_conv2"
  type: "Convolution"
  bottom: "layer_256_4_conv1"
  top: "layer_256_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_4_sum"
  type: "Eltwise"
  bottom: "layer_256_4_conv2"
  bottom: "layer_256_3_sum"
  top: "layer_256_4_sum"
}
layer {
  name: "layer_256_5_bn1"
  type: "BatchNorm"
  bottom: "layer_256_4_sum"
  top: "layer_256_5_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_5_scale1"
  type: "Scale"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_5_relu1"
  type: "ReLU"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_bn1"
}
layer {
  name: "layer_256_5_conv1"
  type: "Convolution"
  bottom: "layer_256_5_bn1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_5_bn2"
  type: "BatchNorm"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_5_scale2"
  type: "Scale"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_5_relu2"
  type: "ReLU"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv1"
}
layer {
  name: "layer_256_5_conv2"
  type: "Convolution"
  bottom: "layer_256_5_conv1"
  top: "layer_256_5_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_5_sum"
  type: "Eltwise"
  bottom: "layer_256_5_conv2"
  bottom: "layer_256_4_sum"
  top: "layer_256_5_sum"
}
layer {
  name: "layer_256_6_bn1"
  type: "BatchNorm"
  bottom: "layer_256_5_sum"
  top: "layer_256_6_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_6_scale1"
  type: "Scale"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_6_relu1"
  type: "ReLU"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_bn1"
}
layer {
  name: "layer_256_6_conv1"
  type: "Convolution"
  bottom: "layer_256_6_bn1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_6_bn2"
  type: "BatchNorm"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_6_scale2"
  type: "Scale"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_6_relu2"
  type: "ReLU"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv1"
}
layer {
  name: "layer_256_6_conv2"
  type: "Convolution"
  bottom: "layer_256_6_conv1"
  top: "layer_256_6_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_6_sum"
  type: "Eltwise"
  bottom: "layer_256_6_conv2"
  bottom: "layer_256_5_sum"
  top: "layer_256_6_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_6_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
I0528 22:21:58.328275 16530 layer_factory.hpp:77] Creating layer data
I0528 22:21:58.328377 16530 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/age_val_lmdb
I0528 22:21:58.328397 16530 net.cpp:84] Creating Layer data
I0528 22:21:58.328415 16530 net.cpp:380] data -> data
I0528 22:21:58.328425 16530 net.cpp:380] data -> label
I0528 22:21:58.328438 16530 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 22:21:58.331405 16530 data_layer.cpp:45] output data size: 20,3,224,224
I0528 22:21:58.361747 16530 net.cpp:122] Setting up data
I0528 22:21:58.361811 16530 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 22:21:58.361821 16530 net.cpp:129] Top shape: 20 (20)
I0528 22:21:58.361829 16530 net.cpp:137] Memory required for data: 12042320
I0528 22:21:58.361851 16530 layer_factory.hpp:77] Creating layer label_data_1_split
I0528 22:21:58.361870 16530 net.cpp:84] Creating Layer label_data_1_split
I0528 22:21:58.361881 16530 net.cpp:406] label_data_1_split <- label
I0528 22:21:58.361891 16530 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0528 22:21:58.361903 16530 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0528 22:21:58.362097 16530 net.cpp:122] Setting up label_data_1_split
I0528 22:21:58.362138 16530 net.cpp:129] Top shape: 20 (20)
I0528 22:21:58.362156 16530 net.cpp:129] Top shape: 20 (20)
I0528 22:21:58.362160 16530 net.cpp:137] Memory required for data: 12042480
I0528 22:21:58.362165 16530 layer_factory.hpp:77] Creating layer data_bn
I0528 22:21:58.362195 16530 net.cpp:84] Creating Layer data_bn
I0528 22:21:58.362201 16530 net.cpp:406] data_bn <- data
I0528 22:21:58.362208 16530 net.cpp:380] data_bn -> data_bn
I0528 22:21:58.362624 16530 net.cpp:122] Setting up data_bn
I0528 22:21:58.362638 16530 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 22:21:58.362654 16530 net.cpp:137] Memory required for data: 24084720
I0528 22:21:58.362670 16530 layer_factory.hpp:77] Creating layer data_scale
I0528 22:21:58.362680 16530 net.cpp:84] Creating Layer data_scale
I0528 22:21:58.362685 16530 net.cpp:406] data_scale <- data_bn
I0528 22:21:58.362692 16530 net.cpp:367] data_scale -> data_bn (in-place)
I0528 22:21:58.362753 16530 layer_factory.hpp:77] Creating layer data_scale
I0528 22:21:58.363626 16530 net.cpp:122] Setting up data_scale
I0528 22:21:58.363646 16530 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 22:21:58.363662 16530 net.cpp:137] Memory required for data: 36126960
I0528 22:21:58.363672 16530 layer_factory.hpp:77] Creating layer conv1
I0528 22:21:58.363688 16530 net.cpp:84] Creating Layer conv1
I0528 22:21:58.363693 16530 net.cpp:406] conv1 <- data_bn
I0528 22:21:58.363701 16530 net.cpp:380] conv1 -> conv1
I0528 22:21:58.366940 16530 net.cpp:122] Setting up conv1
I0528 22:21:58.366977 16530 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 22:21:58.366983 16530 net.cpp:137] Memory required for data: 100352240
I0528 22:21:58.366991 16530 layer_factory.hpp:77] Creating layer conv1_bn
I0528 22:21:58.367000 16530 net.cpp:84] Creating Layer conv1_bn
I0528 22:21:58.367017 16530 net.cpp:406] conv1_bn <- conv1
I0528 22:21:58.367024 16530 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 22:21:58.367326 16530 net.cpp:122] Setting up conv1_bn
I0528 22:21:58.367341 16530 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 22:21:58.367357 16530 net.cpp:137] Memory required for data: 164577520
I0528 22:21:58.367386 16530 layer_factory.hpp:77] Creating layer conv1_scale
I0528 22:21:58.367405 16530 net.cpp:84] Creating Layer conv1_scale
I0528 22:21:58.367410 16530 net.cpp:406] conv1_scale <- conv1
I0528 22:21:58.367416 16530 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 22:21:58.367472 16530 layer_factory.hpp:77] Creating layer conv1_scale
I0528 22:21:58.367682 16530 net.cpp:122] Setting up conv1_scale
I0528 22:21:58.367704 16530 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 22:21:58.367720 16530 net.cpp:137] Memory required for data: 228802800
I0528 22:21:58.367727 16530 layer_factory.hpp:77] Creating layer conv1_relu
I0528 22:21:58.367733 16530 net.cpp:84] Creating Layer conv1_relu
I0528 22:21:58.367738 16530 net.cpp:406] conv1_relu <- conv1
I0528 22:21:58.367744 16530 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 22:21:58.367946 16530 net.cpp:122] Setting up conv1_relu
I0528 22:21:58.367982 16530 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 22:21:58.367986 16530 net.cpp:137] Memory required for data: 293028080
I0528 22:21:58.367990 16530 layer_factory.hpp:77] Creating layer conv1_pool
I0528 22:21:58.368010 16530 net.cpp:84] Creating Layer conv1_pool
I0528 22:21:58.368015 16530 net.cpp:406] conv1_pool <- conv1
I0528 22:21:58.368021 16530 net.cpp:380] conv1_pool -> conv1_pool
I0528 22:21:58.368088 16530 net.cpp:122] Setting up conv1_pool
I0528 22:21:58.368103 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.368108 16530 net.cpp:137] Memory required for data: 309084400
I0528 22:21:58.368111 16530 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 22:21:58.368122 16530 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 22:21:58.368152 16530 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 22:21:58.368160 16530 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 22:21:58.368168 16530 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 22:21:58.368218 16530 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 22:21:58.368227 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.368232 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.368237 16530 net.cpp:137] Memory required for data: 341197040
I0528 22:21:58.368240 16530 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 22:21:58.368252 16530 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 22:21:58.368257 16530 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 22:21:58.368264 16530 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 22:21:58.370854 16530 net.cpp:122] Setting up layer_64_1_conv1
I0528 22:21:58.370887 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.370892 16530 net.cpp:137] Memory required for data: 357253360
I0528 22:21:58.370898 16530 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 22:21:58.370906 16530 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 22:21:58.370923 16530 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 22:21:58.370931 16530 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 22:21:58.371227 16530 net.cpp:122] Setting up layer_64_1_bn2
I0528 22:21:58.371250 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.371265 16530 net.cpp:137] Memory required for data: 373309680
I0528 22:21:58.371274 16530 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 22:21:58.371282 16530 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 22:21:58.371299 16530 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 22:21:58.371306 16530 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 22:21:58.371372 16530 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 22:21:58.371559 16530 net.cpp:122] Setting up layer_64_1_scale2
I0528 22:21:58.371570 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.371587 16530 net.cpp:137] Memory required for data: 389366000
I0528 22:21:58.371609 16530 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 22:21:58.371634 16530 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 22:21:58.371657 16530 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 22:21:58.371665 16530 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 22:21:58.372340 16530 net.cpp:122] Setting up layer_64_1_relu2
I0528 22:21:58.372370 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.372375 16530 net.cpp:137] Memory required for data: 405422320
I0528 22:21:58.372380 16530 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 22:21:58.372391 16530 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 22:21:58.372406 16530 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 22:21:58.372416 16530 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 22:21:58.375157 16530 net.cpp:122] Setting up layer_64_1_conv2
I0528 22:21:58.375211 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.375217 16530 net.cpp:137] Memory required for data: 421478640
I0528 22:21:58.375223 16530 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 22:21:58.375238 16530 net.cpp:84] Creating Layer layer_64_1_sum
I0528 22:21:58.375243 16530 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 22:21:58.375250 16530 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 22:21:58.375268 16530 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 22:21:58.375308 16530 net.cpp:122] Setting up layer_64_1_sum
I0528 22:21:58.375315 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.375319 16530 net.cpp:137] Memory required for data: 437534960
I0528 22:21:58.375324 16530 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:58.375331 16530 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:58.375335 16530 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 22:21:58.375342 16530 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 22:21:58.375349 16530 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 22:21:58.375396 16530 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 22:21:58.375403 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.375408 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.375411 16530 net.cpp:137] Memory required for data: 469647600
I0528 22:21:58.375416 16530 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 22:21:58.375422 16530 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 22:21:58.375427 16530 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 22:21:58.375433 16530 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 22:21:58.375736 16530 net.cpp:122] Setting up layer_64_2_bn1
I0528 22:21:58.375747 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.375762 16530 net.cpp:137] Memory required for data: 485703920
I0528 22:21:58.375771 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 22:21:58.375778 16530 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 22:21:58.375783 16530 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 22:21:58.375789 16530 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 22:21:58.375854 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 22:21:58.376032 16530 net.cpp:122] Setting up layer_64_2_scale1
I0528 22:21:58.376055 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.376070 16530 net.cpp:137] Memory required for data: 501760240
I0528 22:21:58.376076 16530 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 22:21:58.376093 16530 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 22:21:58.376109 16530 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 22:21:58.376121 16530 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 22:21:58.376811 16530 net.cpp:122] Setting up layer_64_2_relu1
I0528 22:21:58.376838 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.376848 16530 net.cpp:137] Memory required for data: 517816560
I0528 22:21:58.376871 16530 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 22:21:58.376893 16530 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 22:21:58.376899 16530 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 22:21:58.376906 16530 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 22:21:58.379483 16530 net.cpp:122] Setting up layer_64_2_conv1
I0528 22:21:58.379514 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.379519 16530 net.cpp:137] Memory required for data: 533872880
I0528 22:21:58.379525 16530 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 22:21:58.379534 16530 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 22:21:58.379550 16530 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 22:21:58.379559 16530 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 22:21:58.379845 16530 net.cpp:122] Setting up layer_64_2_bn2
I0528 22:21:58.379855 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.379871 16530 net.cpp:137] Memory required for data: 549929200
I0528 22:21:58.379879 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 22:21:58.379886 16530 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 22:21:58.379891 16530 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 22:21:58.379897 16530 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 22:21:58.379961 16530 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 22:21:58.380151 16530 net.cpp:122] Setting up layer_64_2_scale2
I0528 22:21:58.380177 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.380179 16530 net.cpp:137] Memory required for data: 565985520
I0528 22:21:58.380198 16530 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 22:21:58.380215 16530 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 22:21:58.380220 16530 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 22:21:58.380226 16530 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 22:21:58.380484 16530 net.cpp:122] Setting up layer_64_2_relu2
I0528 22:21:58.380509 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.380513 16530 net.cpp:137] Memory required for data: 582041840
I0528 22:21:58.380528 16530 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 22:21:58.380548 16530 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 22:21:58.380553 16530 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 22:21:58.380571 16530 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 22:21:58.383160 16530 net.cpp:122] Setting up layer_64_2_conv2
I0528 22:21:58.383193 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.383198 16530 net.cpp:137] Memory required for data: 598098160
I0528 22:21:58.383203 16530 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 22:21:58.383210 16530 net.cpp:84] Creating Layer layer_64_2_sum
I0528 22:21:58.383227 16530 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 22:21:58.383234 16530 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 22:21:58.383250 16530 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 22:21:58.383292 16530 net.cpp:122] Setting up layer_64_2_sum
I0528 22:21:58.383301 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.383306 16530 net.cpp:137] Memory required for data: 614154480
I0528 22:21:58.383308 16530 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:58.383314 16530 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:58.383318 16530 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0528 22:21:58.383325 16530 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 22:21:58.383332 16530 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 22:21:58.383378 16530 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0528 22:21:58.383390 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.383406 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.383410 16530 net.cpp:137] Memory required for data: 646267120
I0528 22:21:58.383414 16530 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0528 22:21:58.383421 16530 net.cpp:84] Creating Layer layer_64_3_bn1
I0528 22:21:58.383425 16530 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 22:21:58.383432 16530 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0528 22:21:58.383759 16530 net.cpp:122] Setting up layer_64_3_bn1
I0528 22:21:58.383776 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.383791 16530 net.cpp:137] Memory required for data: 662323440
I0528 22:21:58.383805 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 22:21:58.383824 16530 net.cpp:84] Creating Layer layer_64_3_scale1
I0528 22:21:58.383829 16530 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0528 22:21:58.383836 16530 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0528 22:21:58.383893 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 22:21:58.384093 16530 net.cpp:122] Setting up layer_64_3_scale1
I0528 22:21:58.384104 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.384130 16530 net.cpp:137] Memory required for data: 678379760
I0528 22:21:58.384160 16530 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0528 22:21:58.384167 16530 net.cpp:84] Creating Layer layer_64_3_relu1
I0528 22:21:58.384172 16530 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0528 22:21:58.384177 16530 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0528 22:21:58.384863 16530 net.cpp:122] Setting up layer_64_3_relu1
I0528 22:21:58.384891 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.384896 16530 net.cpp:137] Memory required for data: 694436080
I0528 22:21:58.384899 16530 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0528 22:21:58.384912 16530 net.cpp:84] Creating Layer layer_64_3_conv1
I0528 22:21:58.384917 16530 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0528 22:21:58.384923 16530 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0528 22:21:58.388231 16530 net.cpp:122] Setting up layer_64_3_conv1
I0528 22:21:58.388262 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.388267 16530 net.cpp:137] Memory required for data: 710492400
I0528 22:21:58.388274 16530 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0528 22:21:58.388283 16530 net.cpp:84] Creating Layer layer_64_3_bn2
I0528 22:21:58.388298 16530 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0528 22:21:58.388306 16530 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0528 22:21:58.388609 16530 net.cpp:122] Setting up layer_64_3_bn2
I0528 22:21:58.388620 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.388635 16530 net.cpp:137] Memory required for data: 726548720
I0528 22:21:58.388644 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 22:21:58.388654 16530 net.cpp:84] Creating Layer layer_64_3_scale2
I0528 22:21:58.388659 16530 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0528 22:21:58.388665 16530 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0528 22:21:58.388749 16530 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 22:21:58.388931 16530 net.cpp:122] Setting up layer_64_3_scale2
I0528 22:21:58.388952 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.388968 16530 net.cpp:137] Memory required for data: 742605040
I0528 22:21:58.388984 16530 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0528 22:21:58.388991 16530 net.cpp:84] Creating Layer layer_64_3_relu2
I0528 22:21:58.389016 16530 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0528 22:21:58.389024 16530 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0528 22:21:58.389747 16530 net.cpp:122] Setting up layer_64_3_relu2
I0528 22:21:58.389777 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.389782 16530 net.cpp:137] Memory required for data: 758661360
I0528 22:21:58.389798 16530 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0528 22:21:58.389820 16530 net.cpp:84] Creating Layer layer_64_3_conv2
I0528 22:21:58.389837 16530 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0528 22:21:58.389847 16530 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0528 22:21:58.393395 16530 net.cpp:122] Setting up layer_64_3_conv2
I0528 22:21:58.393427 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.393432 16530 net.cpp:137] Memory required for data: 774717680
I0528 22:21:58.393438 16530 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0528 22:21:58.393448 16530 net.cpp:84] Creating Layer layer_64_3_sum
I0528 22:21:58.393463 16530 net.cpp:406] layer_64_3_sum <- layer_64_3_conv2
I0528 22:21:58.393471 16530 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 22:21:58.393487 16530 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0528 22:21:58.393525 16530 net.cpp:122] Setting up layer_64_3_sum
I0528 22:21:58.393537 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.393543 16530 net.cpp:137] Memory required for data: 790774000
I0528 22:21:58.393546 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 22:21:58.393553 16530 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 22:21:58.393558 16530 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0528 22:21:58.393565 16530 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 22:21:58.393895 16530 net.cpp:122] Setting up layer_128_1_bn1
I0528 22:21:58.393906 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.393921 16530 net.cpp:137] Memory required for data: 806830320
I0528 22:21:58.393929 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 22:21:58.393937 16530 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 22:21:58.393944 16530 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 22:21:58.393950 16530 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 22:21:58.394006 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 22:21:58.394202 16530 net.cpp:122] Setting up layer_128_1_scale1
I0528 22:21:58.394227 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.394243 16530 net.cpp:137] Memory required for data: 822886640
I0528 22:21:58.394250 16530 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 22:21:58.394258 16530 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 22:21:58.394263 16530 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 22:21:58.394269 16530 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 22:21:58.394491 16530 net.cpp:122] Setting up layer_128_1_relu1
I0528 22:21:58.394528 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.394532 16530 net.cpp:137] Memory required for data: 838942960
I0528 22:21:58.394547 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:58.394554 16530 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:58.394560 16530 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 22:21:58.394567 16530 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 22:21:58.394575 16530 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 22:21:58.394642 16530 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 22:21:58.394651 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.394656 16530 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 22:21:58.394659 16530 net.cpp:137] Memory required for data: 871055600
I0528 22:21:58.394664 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 22:21:58.394675 16530 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 22:21:58.394680 16530 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 22:21:58.394687 16530 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 22:21:58.398463 16530 net.cpp:122] Setting up layer_128_1_conv1
I0528 22:21:58.398501 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.398507 16530 net.cpp:137] Memory required for data: 879083760
I0528 22:21:58.398514 16530 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 22:21:58.398522 16530 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 22:21:58.398537 16530 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 22:21:58.398545 16530 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 22:21:58.398823 16530 net.cpp:122] Setting up layer_128_1_bn2
I0528 22:21:58.398834 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.398849 16530 net.cpp:137] Memory required for data: 887111920
I0528 22:21:58.398870 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 22:21:58.398885 16530 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 22:21:58.398890 16530 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 22:21:58.398895 16530 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 22:21:58.398960 16530 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 22:21:58.399152 16530 net.cpp:122] Setting up layer_128_1_scale2
I0528 22:21:58.399178 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.399183 16530 net.cpp:137] Memory required for data: 895140080
I0528 22:21:58.399200 16530 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 22:21:58.399209 16530 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 22:21:58.399214 16530 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 22:21:58.399240 16530 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 22:21:58.399925 16530 net.cpp:122] Setting up layer_128_1_relu2
I0528 22:21:58.399952 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.399957 16530 net.cpp:137] Memory required for data: 903168240
I0528 22:21:58.399961 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 22:21:58.399976 16530 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 22:21:58.399981 16530 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 22:21:58.399989 16530 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 22:21:58.405704 16530 net.cpp:122] Setting up layer_128_1_conv2
I0528 22:21:58.405725 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.405740 16530 net.cpp:137] Memory required for data: 911196400
I0528 22:21:58.405746 16530 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 22:21:58.405761 16530 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 22:21:58.405766 16530 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 22:21:58.405776 16530 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 22:21:58.408810 16530 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 22:21:58.408841 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.408846 16530 net.cpp:137] Memory required for data: 919224560
I0528 22:21:58.408852 16530 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 22:21:58.408864 16530 net.cpp:84] Creating Layer layer_128_1_sum
I0528 22:21:58.408879 16530 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 22:21:58.408885 16530 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 22:21:58.408901 16530 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 22:21:58.408941 16530 net.cpp:122] Setting up layer_128_1_sum
I0528 22:21:58.408951 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.408954 16530 net.cpp:137] Memory required for data: 927252720
I0528 22:21:58.408958 16530 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:58.408964 16530 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:58.408968 16530 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 22:21:58.408973 16530 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 22:21:58.408995 16530 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 22:21:58.409050 16530 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 22:21:58.409061 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.409067 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.409071 16530 net.cpp:137] Memory required for data: 943309040
I0528 22:21:58.409075 16530 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 22:21:58.409083 16530 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 22:21:58.409087 16530 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 22:21:58.409093 16530 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 22:21:58.409466 16530 net.cpp:122] Setting up layer_128_2_bn1
I0528 22:21:58.409493 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.409498 16530 net.cpp:137] Memory required for data: 951337200
I0528 22:21:58.409507 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 22:21:58.409514 16530 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 22:21:58.409518 16530 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 22:21:58.409524 16530 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 22:21:58.409584 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 22:21:58.409782 16530 net.cpp:122] Setting up layer_128_2_scale1
I0528 22:21:58.409795 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.409807 16530 net.cpp:137] Memory required for data: 959365360
I0528 22:21:58.409816 16530 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 22:21:58.409832 16530 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 22:21:58.409837 16530 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 22:21:58.409843 16530 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 22:21:58.410523 16530 net.cpp:122] Setting up layer_128_2_relu1
I0528 22:21:58.410552 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.410557 16530 net.cpp:137] Memory required for data: 967393520
I0528 22:21:58.410562 16530 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 22:21:58.410596 16530 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 22:21:58.410603 16530 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 22:21:58.410612 16530 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 22:21:58.416635 16530 net.cpp:122] Setting up layer_128_2_conv1
I0528 22:21:58.416668 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.416674 16530 net.cpp:137] Memory required for data: 975421680
I0528 22:21:58.416681 16530 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 22:21:58.416688 16530 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 22:21:58.416703 16530 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 22:21:58.416724 16530 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 22:21:58.417009 16530 net.cpp:122] Setting up layer_128_2_bn2
I0528 22:21:58.417032 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.417048 16530 net.cpp:137] Memory required for data: 983449840
I0528 22:21:58.417068 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 22:21:58.417078 16530 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 22:21:58.417083 16530 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 22:21:58.417088 16530 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 22:21:58.417166 16530 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 22:21:58.417369 16530 net.cpp:122] Setting up layer_128_2_scale2
I0528 22:21:58.417393 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.417408 16530 net.cpp:137] Memory required for data: 991478000
I0528 22:21:58.417414 16530 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 22:21:58.417421 16530 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 22:21:58.417430 16530 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 22:21:58.417443 16530 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 22:21:58.417656 16530 net.cpp:122] Setting up layer_128_2_relu2
I0528 22:21:58.417682 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.417697 16530 net.cpp:137] Memory required for data: 999506160
I0528 22:21:58.417701 16530 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 22:21:58.417713 16530 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 22:21:58.417718 16530 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 22:21:58.417727 16530 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 22:21:58.424077 16530 net.cpp:122] Setting up layer_128_2_conv2
I0528 22:21:58.424109 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.424119 16530 net.cpp:137] Memory required for data: 1007534320
I0528 22:21:58.424129 16530 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 22:21:58.424146 16530 net.cpp:84] Creating Layer layer_128_2_sum
I0528 22:21:58.424152 16530 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 22:21:58.424159 16530 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 22:21:58.424165 16530 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 22:21:58.424204 16530 net.cpp:122] Setting up layer_128_2_sum
I0528 22:21:58.424212 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.424216 16530 net.cpp:137] Memory required for data: 1015562480
I0528 22:21:58.424221 16530 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:58.424226 16530 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:58.424230 16530 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0528 22:21:58.424237 16530 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 22:21:58.424245 16530 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 22:21:58.424304 16530 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0528 22:21:58.424324 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.424329 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.424334 16530 net.cpp:137] Memory required for data: 1031618800
I0528 22:21:58.424337 16530 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0528 22:21:58.424346 16530 net.cpp:84] Creating Layer layer_128_3_bn1
I0528 22:21:58.424351 16530 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 22:21:58.424360 16530 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0528 22:21:58.424684 16530 net.cpp:122] Setting up layer_128_3_bn1
I0528 22:21:58.424695 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.424710 16530 net.cpp:137] Memory required for data: 1039646960
I0528 22:21:58.424720 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 22:21:58.424726 16530 net.cpp:84] Creating Layer layer_128_3_scale1
I0528 22:21:58.424731 16530 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0528 22:21:58.424737 16530 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0528 22:21:58.424795 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 22:21:58.424989 16530 net.cpp:122] Setting up layer_128_3_scale1
I0528 22:21:58.425001 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.425015 16530 net.cpp:137] Memory required for data: 1047675120
I0528 22:21:58.425034 16530 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0528 22:21:58.425045 16530 net.cpp:84] Creating Layer layer_128_3_relu1
I0528 22:21:58.425050 16530 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0528 22:21:58.425055 16530 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0528 22:21:58.425299 16530 net.cpp:122] Setting up layer_128_3_relu1
I0528 22:21:58.425329 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.425350 16530 net.cpp:137] Memory required for data: 1055703280
I0528 22:21:58.425362 16530 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0528 22:21:58.425374 16530 net.cpp:84] Creating Layer layer_128_3_conv1
I0528 22:21:58.425379 16530 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0528 22:21:58.425386 16530 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0528 22:21:58.431406 16530 net.cpp:122] Setting up layer_128_3_conv1
I0528 22:21:58.431437 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.431442 16530 net.cpp:137] Memory required for data: 1063731440
I0528 22:21:58.431448 16530 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0528 22:21:58.431458 16530 net.cpp:84] Creating Layer layer_128_3_bn2
I0528 22:21:58.431484 16530 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0528 22:21:58.431491 16530 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0528 22:21:58.431788 16530 net.cpp:122] Setting up layer_128_3_bn2
I0528 22:21:58.431800 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.431815 16530 net.cpp:137] Memory required for data: 1071759600
I0528 22:21:58.431823 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 22:21:58.431843 16530 net.cpp:84] Creating Layer layer_128_3_scale2
I0528 22:21:58.431859 16530 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0528 22:21:58.431865 16530 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0528 22:21:58.431922 16530 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 22:21:58.432166 16530 net.cpp:122] Setting up layer_128_3_scale2
I0528 22:21:58.432190 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.432206 16530 net.cpp:137] Memory required for data: 1079787760
I0528 22:21:58.432214 16530 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0528 22:21:58.432238 16530 net.cpp:84] Creating Layer layer_128_3_relu2
I0528 22:21:58.432243 16530 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0528 22:21:58.432251 16530 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0528 22:21:58.432956 16530 net.cpp:122] Setting up layer_128_3_relu2
I0528 22:21:58.432972 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.432986 16530 net.cpp:137] Memory required for data: 1087815920
I0528 22:21:58.432991 16530 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0528 22:21:58.433014 16530 net.cpp:84] Creating Layer layer_128_3_conv2
I0528 22:21:58.433019 16530 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0528 22:21:58.433027 16530 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0528 22:21:58.439175 16530 net.cpp:122] Setting up layer_128_3_conv2
I0528 22:21:58.439205 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.439210 16530 net.cpp:137] Memory required for data: 1095844080
I0528 22:21:58.439218 16530 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0528 22:21:58.439226 16530 net.cpp:84] Creating Layer layer_128_3_sum
I0528 22:21:58.439242 16530 net.cpp:406] layer_128_3_sum <- layer_128_3_conv2
I0528 22:21:58.439249 16530 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 22:21:58.439254 16530 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0528 22:21:58.439296 16530 net.cpp:122] Setting up layer_128_3_sum
I0528 22:21:58.439303 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.439307 16530 net.cpp:137] Memory required for data: 1103872240
I0528 22:21:58.439311 16530 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:58.439317 16530 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:58.439322 16530 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0528 22:21:58.439327 16530 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 22:21:58.439337 16530 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 22:21:58.439388 16530 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0528 22:21:58.439410 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.439426 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.439430 16530 net.cpp:137] Memory required for data: 1119928560
I0528 22:21:58.439435 16530 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0528 22:21:58.439443 16530 net.cpp:84] Creating Layer layer_128_4_bn1
I0528 22:21:58.439448 16530 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 22:21:58.439456 16530 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0528 22:21:58.439788 16530 net.cpp:122] Setting up layer_128_4_bn1
I0528 22:21:58.439800 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.439815 16530 net.cpp:137] Memory required for data: 1127956720
I0528 22:21:58.439823 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 22:21:58.439831 16530 net.cpp:84] Creating Layer layer_128_4_scale1
I0528 22:21:58.439836 16530 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0528 22:21:58.439841 16530 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0528 22:21:58.439911 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 22:21:58.440155 16530 net.cpp:122] Setting up layer_128_4_scale1
I0528 22:21:58.440181 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.440186 16530 net.cpp:137] Memory required for data: 1135984880
I0528 22:21:58.440203 16530 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0528 22:21:58.440222 16530 net.cpp:84] Creating Layer layer_128_4_relu1
I0528 22:21:58.440228 16530 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0528 22:21:58.440234 16530 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0528 22:21:58.440497 16530 net.cpp:122] Setting up layer_128_4_relu1
I0528 22:21:58.440522 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.440536 16530 net.cpp:137] Memory required for data: 1144013040
I0528 22:21:58.440541 16530 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0528 22:21:58.440557 16530 net.cpp:84] Creating Layer layer_128_4_conv1
I0528 22:21:58.440572 16530 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0528 22:21:58.440579 16530 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0528 22:21:58.447016 16530 net.cpp:122] Setting up layer_128_4_conv1
I0528 22:21:58.447048 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.447054 16530 net.cpp:137] Memory required for data: 1152041200
I0528 22:21:58.447069 16530 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0528 22:21:58.447089 16530 net.cpp:84] Creating Layer layer_128_4_bn2
I0528 22:21:58.447094 16530 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0528 22:21:58.447103 16530 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0528 22:21:58.447445 16530 net.cpp:122] Setting up layer_128_4_bn2
I0528 22:21:58.447460 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.447475 16530 net.cpp:137] Memory required for data: 1160069360
I0528 22:21:58.447495 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 22:21:58.447513 16530 net.cpp:84] Creating Layer layer_128_4_scale2
I0528 22:21:58.447527 16530 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0528 22:21:58.447533 16530 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0528 22:21:58.447592 16530 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 22:21:58.447774 16530 net.cpp:122] Setting up layer_128_4_scale2
I0528 22:21:58.447798 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.447813 16530 net.cpp:137] Memory required for data: 1168097520
I0528 22:21:58.447831 16530 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0528 22:21:58.447839 16530 net.cpp:84] Creating Layer layer_128_4_relu2
I0528 22:21:58.447842 16530 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0528 22:21:58.447850 16530 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0528 22:21:58.448086 16530 net.cpp:122] Setting up layer_128_4_relu2
I0528 22:21:58.448119 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.448137 16530 net.cpp:137] Memory required for data: 1176125680
I0528 22:21:58.448143 16530 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0528 22:21:58.448155 16530 net.cpp:84] Creating Layer layer_128_4_conv2
I0528 22:21:58.448160 16530 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0528 22:21:58.448180 16530 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0528 22:21:58.454509 16530 net.cpp:122] Setting up layer_128_4_conv2
I0528 22:21:58.454531 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.454538 16530 net.cpp:137] Memory required for data: 1184153840
I0528 22:21:58.454562 16530 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0528 22:21:58.454571 16530 net.cpp:84] Creating Layer layer_128_4_sum
I0528 22:21:58.454581 16530 net.cpp:406] layer_128_4_sum <- layer_128_4_conv2
I0528 22:21:58.454586 16530 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 22:21:58.454591 16530 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0528 22:21:58.454633 16530 net.cpp:122] Setting up layer_128_4_sum
I0528 22:21:58.454649 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.454653 16530 net.cpp:137] Memory required for data: 1192182000
I0528 22:21:58.454658 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 22:21:58.454666 16530 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 22:21:58.454670 16530 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0528 22:21:58.454676 16530 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 22:21:58.455000 16530 net.cpp:122] Setting up layer_256_1_bn1
I0528 22:21:58.455010 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.455024 16530 net.cpp:137] Memory required for data: 1200210160
I0528 22:21:58.455032 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 22:21:58.455039 16530 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 22:21:58.455055 16530 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 22:21:58.455061 16530 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 22:21:58.455127 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 22:21:58.455358 16530 net.cpp:122] Setting up layer_256_1_scale1
I0528 22:21:58.455370 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.455384 16530 net.cpp:137] Memory required for data: 1208238320
I0528 22:21:58.455401 16530 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 22:21:58.455410 16530 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 22:21:58.455415 16530 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 22:21:58.455420 16530 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 22:21:58.456126 16530 net.cpp:122] Setting up layer_256_1_relu1
I0528 22:21:58.456154 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.456159 16530 net.cpp:137] Memory required for data: 1216266480
I0528 22:21:58.456164 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:58.456171 16530 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:58.456176 16530 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 22:21:58.456195 16530 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 22:21:58.456204 16530 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 22:21:58.456269 16530 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 22:21:58.456295 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.456300 16530 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 22:21:58.456313 16530 net.cpp:137] Memory required for data: 1232322800
I0528 22:21:58.456317 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 22:21:58.456341 16530 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 22:21:58.456374 16530 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 22:21:58.456393 16530 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 22:21:58.466756 16530 net.cpp:122] Setting up layer_256_1_conv1
I0528 22:21:58.466786 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.466792 16530 net.cpp:137] Memory required for data: 1236336880
I0528 22:21:58.466799 16530 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 22:21:58.466806 16530 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 22:21:58.466811 16530 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 22:21:58.466831 16530 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 22:21:58.467062 16530 net.cpp:122] Setting up layer_256_1_bn2
I0528 22:21:58.467074 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.467078 16530 net.cpp:137] Memory required for data: 1240350960
I0528 22:21:58.467087 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 22:21:58.467094 16530 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 22:21:58.467098 16530 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 22:21:58.467123 16530 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 22:21:58.467170 16530 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 22:21:58.467272 16530 net.cpp:122] Setting up layer_256_1_scale2
I0528 22:21:58.467293 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.467296 16530 net.cpp:137] Memory required for data: 1244365040
I0528 22:21:58.467303 16530 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 22:21:58.467308 16530 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 22:21:58.467314 16530 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 22:21:58.467320 16530 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 22:21:58.467545 16530 net.cpp:122] Setting up layer_256_1_relu2
I0528 22:21:58.467558 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.467572 16530 net.cpp:137] Memory required for data: 1248379120
I0528 22:21:58.467576 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 22:21:58.467587 16530 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 22:21:58.467592 16530 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 22:21:58.467602 16530 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 22:21:58.486351 16530 net.cpp:122] Setting up layer_256_1_conv2
I0528 22:21:58.486372 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.486378 16530 net.cpp:137] Memory required for data: 1252393200
I0528 22:21:58.486395 16530 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 22:21:58.486414 16530 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 22:21:58.486421 16530 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 22:21:58.486430 16530 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 22:21:58.489030 16530 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 22:21:58.489063 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489068 16530 net.cpp:137] Memory required for data: 1256407280
I0528 22:21:58.489073 16530 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 22:21:58.489086 16530 net.cpp:84] Creating Layer layer_256_1_sum
I0528 22:21:58.489091 16530 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 22:21:58.489097 16530 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 22:21:58.489104 16530 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 22:21:58.489150 16530 net.cpp:122] Setting up layer_256_1_sum
I0528 22:21:58.489161 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489166 16530 net.cpp:137] Memory required for data: 1260421360
I0528 22:21:58.489169 16530 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:58.489184 16530 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:58.489194 16530 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 22:21:58.489209 16530 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 22:21:58.489218 16530 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 22:21:58.489255 16530 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 22:21:58.489264 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489269 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489271 16530 net.cpp:137] Memory required for data: 1268449520
I0528 22:21:58.489275 16530 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 22:21:58.489284 16530 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 22:21:58.489289 16530 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 22:21:58.489295 16530 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 22:21:58.489529 16530 net.cpp:122] Setting up layer_256_2_bn1
I0528 22:21:58.489540 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489554 16530 net.cpp:137] Memory required for data: 1272463600
I0528 22:21:58.489563 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 22:21:58.489572 16530 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 22:21:58.489575 16530 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 22:21:58.489581 16530 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 22:21:58.489635 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 22:21:58.489759 16530 net.cpp:122] Setting up layer_256_2_scale1
I0528 22:21:58.489769 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.489784 16530 net.cpp:137] Memory required for data: 1276477680
I0528 22:21:58.489790 16530 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 22:21:58.489807 16530 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 22:21:58.489811 16530 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 22:21:58.489816 16530 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 22:21:58.490054 16530 net.cpp:122] Setting up layer_256_2_relu1
I0528 22:21:58.490068 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.490072 16530 net.cpp:137] Memory required for data: 1280491760
I0528 22:21:58.490077 16530 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 22:21:58.490088 16530 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 22:21:58.490093 16530 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 22:21:58.490100 16530 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 22:21:58.508898 16530 net.cpp:122] Setting up layer_256_2_conv1
I0528 22:21:58.508920 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.508925 16530 net.cpp:137] Memory required for data: 1284505840
I0528 22:21:58.508944 16530 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 22:21:58.508956 16530 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 22:21:58.508962 16530 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 22:21:58.508968 16530 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 22:21:58.509184 16530 net.cpp:122] Setting up layer_256_2_bn2
I0528 22:21:58.509197 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.509213 16530 net.cpp:137] Memory required for data: 1288519920
I0528 22:21:58.509222 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 22:21:58.509230 16530 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 22:21:58.509235 16530 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 22:21:58.509241 16530 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 22:21:58.509306 16530 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 22:21:58.509423 16530 net.cpp:122] Setting up layer_256_2_scale2
I0528 22:21:58.509443 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.509459 16530 net.cpp:137] Memory required for data: 1292534000
I0528 22:21:58.509480 16530 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 22:21:58.509495 16530 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 22:21:58.509500 16530 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 22:21:58.509519 16530 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 22:21:58.510212 16530 net.cpp:122] Setting up layer_256_2_relu2
I0528 22:21:58.510242 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.510247 16530 net.cpp:137] Memory required for data: 1296548080
I0528 22:21:58.510251 16530 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 22:21:58.510265 16530 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 22:21:58.510272 16530 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 22:21:58.510280 16530 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 22:21:58.527616 16530 net.cpp:122] Setting up layer_256_2_conv2
I0528 22:21:58.527647 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.527652 16530 net.cpp:137] Memory required for data: 1300562160
I0528 22:21:58.527658 16530 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 22:21:58.527665 16530 net.cpp:84] Creating Layer layer_256_2_sum
I0528 22:21:58.527684 16530 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 22:21:58.527690 16530 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 22:21:58.527710 16530 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 22:21:58.527740 16530 net.cpp:122] Setting up layer_256_2_sum
I0528 22:21:58.527748 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.527752 16530 net.cpp:137] Memory required for data: 1304576240
I0528 22:21:58.527756 16530 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:58.527762 16530 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:58.527766 16530 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0528 22:21:58.527772 16530 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 22:21:58.527779 16530 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 22:21:58.527815 16530 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0528 22:21:58.527822 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.527827 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.527830 16530 net.cpp:137] Memory required for data: 1312604400
I0528 22:21:58.527833 16530 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0528 22:21:58.527842 16530 net.cpp:84] Creating Layer layer_256_3_bn1
I0528 22:21:58.527846 16530 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 22:21:58.527851 16530 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0528 22:21:58.528086 16530 net.cpp:122] Setting up layer_256_3_bn1
I0528 22:21:58.528097 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.528112 16530 net.cpp:137] Memory required for data: 1316618480
I0528 22:21:58.528144 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 22:21:58.528152 16530 net.cpp:84] Creating Layer layer_256_3_scale1
I0528 22:21:58.528157 16530 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0528 22:21:58.528168 16530 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0528 22:21:58.528223 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 22:21:58.528358 16530 net.cpp:122] Setting up layer_256_3_scale1
I0528 22:21:58.528381 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.528386 16530 net.cpp:137] Memory required for data: 1320632560
I0528 22:21:58.528393 16530 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0528 22:21:58.528399 16530 net.cpp:84] Creating Layer layer_256_3_relu1
I0528 22:21:58.528403 16530 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0528 22:21:58.528409 16530 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0528 22:21:58.529114 16530 net.cpp:122] Setting up layer_256_3_relu1
I0528 22:21:58.529155 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.529161 16530 net.cpp:137] Memory required for data: 1324646640
I0528 22:21:58.529165 16530 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0528 22:21:58.529178 16530 net.cpp:84] Creating Layer layer_256_3_conv1
I0528 22:21:58.529193 16530 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0528 22:21:58.529214 16530 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0528 22:21:58.546936 16530 net.cpp:122] Setting up layer_256_3_conv1
I0528 22:21:58.546967 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.546973 16530 net.cpp:137] Memory required for data: 1328660720
I0528 22:21:58.546979 16530 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0528 22:21:58.546988 16530 net.cpp:84] Creating Layer layer_256_3_bn2
I0528 22:21:58.547004 16530 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0528 22:21:58.547025 16530 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0528 22:21:58.547242 16530 net.cpp:122] Setting up layer_256_3_bn2
I0528 22:21:58.547256 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.547272 16530 net.cpp:137] Memory required for data: 1332674800
I0528 22:21:58.547281 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 22:21:58.547313 16530 net.cpp:84] Creating Layer layer_256_3_scale2
I0528 22:21:58.547329 16530 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0528 22:21:58.547338 16530 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0528 22:21:58.547380 16530 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 22:21:58.547502 16530 net.cpp:122] Setting up layer_256_3_scale2
I0528 22:21:58.547523 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.547538 16530 net.cpp:137] Memory required for data: 1336688880
I0528 22:21:58.547555 16530 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0528 22:21:58.547561 16530 net.cpp:84] Creating Layer layer_256_3_relu2
I0528 22:21:58.547566 16530 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0528 22:21:58.547571 16530 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0528 22:21:58.548295 16530 net.cpp:122] Setting up layer_256_3_relu2
I0528 22:21:58.548326 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.548331 16530 net.cpp:137] Memory required for data: 1340702960
I0528 22:21:58.548334 16530 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0528 22:21:58.548346 16530 net.cpp:84] Creating Layer layer_256_3_conv2
I0528 22:21:58.548362 16530 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0528 22:21:58.548369 16530 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0528 22:21:58.566128 16530 net.cpp:122] Setting up layer_256_3_conv2
I0528 22:21:58.566162 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566167 16530 net.cpp:137] Memory required for data: 1344717040
I0528 22:21:58.566193 16530 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0528 22:21:58.566215 16530 net.cpp:84] Creating Layer layer_256_3_sum
I0528 22:21:58.566228 16530 net.cpp:406] layer_256_3_sum <- layer_256_3_conv2
I0528 22:21:58.566234 16530 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 22:21:58.566241 16530 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0528 22:21:58.566269 16530 net.cpp:122] Setting up layer_256_3_sum
I0528 22:21:58.566277 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566282 16530 net.cpp:137] Memory required for data: 1348731120
I0528 22:21:58.566285 16530 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:58.566292 16530 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:58.566295 16530 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0528 22:21:58.566301 16530 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 22:21:58.566313 16530 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 22:21:58.566364 16530 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0528 22:21:58.566375 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566380 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566382 16530 net.cpp:137] Memory required for data: 1356759280
I0528 22:21:58.566395 16530 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0528 22:21:58.566404 16530 net.cpp:84] Creating Layer layer_256_4_bn1
I0528 22:21:58.566409 16530 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 22:21:58.566416 16530 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0528 22:21:58.566638 16530 net.cpp:122] Setting up layer_256_4_bn1
I0528 22:21:58.566649 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566664 16530 net.cpp:137] Memory required for data: 1360773360
I0528 22:21:58.566684 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 22:21:58.566709 16530 net.cpp:84] Creating Layer layer_256_4_scale1
I0528 22:21:58.566715 16530 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0528 22:21:58.566720 16530 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0528 22:21:58.566764 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 22:21:58.566905 16530 net.cpp:122] Setting up layer_256_4_scale1
I0528 22:21:58.566915 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.566931 16530 net.cpp:137] Memory required for data: 1364787440
I0528 22:21:58.566937 16530 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0528 22:21:58.566947 16530 net.cpp:84] Creating Layer layer_256_4_relu1
I0528 22:21:58.566952 16530 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0528 22:21:58.566968 16530 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0528 22:21:58.567744 16530 net.cpp:122] Setting up layer_256_4_relu1
I0528 22:21:58.567764 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.567780 16530 net.cpp:137] Memory required for data: 1368801520
I0528 22:21:58.567785 16530 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0528 22:21:58.567795 16530 net.cpp:84] Creating Layer layer_256_4_conv1
I0528 22:21:58.567811 16530 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0528 22:21:58.567829 16530 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0528 22:21:58.585124 16530 net.cpp:122] Setting up layer_256_4_conv1
I0528 22:21:58.585158 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.585163 16530 net.cpp:137] Memory required for data: 1372815600
I0528 22:21:58.585170 16530 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0528 22:21:58.585176 16530 net.cpp:84] Creating Layer layer_256_4_bn2
I0528 22:21:58.585192 16530 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0528 22:21:58.585213 16530 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0528 22:21:58.585425 16530 net.cpp:122] Setting up layer_256_4_bn2
I0528 22:21:58.585436 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.585451 16530 net.cpp:137] Memory required for data: 1376829680
I0528 22:21:58.585459 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 22:21:58.585469 16530 net.cpp:84] Creating Layer layer_256_4_scale2
I0528 22:21:58.585474 16530 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0528 22:21:58.585494 16530 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0528 22:21:58.585546 16530 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 22:21:58.585681 16530 net.cpp:122] Setting up layer_256_4_scale2
I0528 22:21:58.585703 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.585707 16530 net.cpp:137] Memory required for data: 1380843760
I0528 22:21:58.585724 16530 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0528 22:21:58.585731 16530 net.cpp:84] Creating Layer layer_256_4_relu2
I0528 22:21:58.585736 16530 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0528 22:21:58.585755 16530 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0528 22:21:58.586508 16530 net.cpp:122] Setting up layer_256_4_relu2
I0528 22:21:58.586527 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.586544 16530 net.cpp:137] Memory required for data: 1384857840
I0528 22:21:58.586547 16530 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0528 22:21:58.586560 16530 net.cpp:84] Creating Layer layer_256_4_conv2
I0528 22:21:58.586566 16530 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0528 22:21:58.586573 16530 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0528 22:21:58.604305 16530 net.cpp:122] Setting up layer_256_4_conv2
I0528 22:21:58.604336 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.604342 16530 net.cpp:137] Memory required for data: 1388871920
I0528 22:21:58.604347 16530 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0528 22:21:58.604356 16530 net.cpp:84] Creating Layer layer_256_4_sum
I0528 22:21:58.604370 16530 net.cpp:406] layer_256_4_sum <- layer_256_4_conv2
I0528 22:21:58.604377 16530 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 22:21:58.604396 16530 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0528 22:21:58.604425 16530 net.cpp:122] Setting up layer_256_4_sum
I0528 22:21:58.604435 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.604439 16530 net.cpp:137] Memory required for data: 1392886000
I0528 22:21:58.604444 16530 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:58.604449 16530 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:58.604454 16530 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0528 22:21:58.604460 16530 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 22:21:58.604467 16530 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 22:21:58.604506 16530 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0528 22:21:58.604514 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.604518 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.604522 16530 net.cpp:137] Memory required for data: 1400914160
I0528 22:21:58.604526 16530 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0528 22:21:58.604533 16530 net.cpp:84] Creating Layer layer_256_5_bn1
I0528 22:21:58.604538 16530 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 22:21:58.604544 16530 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0528 22:21:58.604774 16530 net.cpp:122] Setting up layer_256_5_bn1
I0528 22:21:58.604784 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.604800 16530 net.cpp:137] Memory required for data: 1404928240
I0528 22:21:58.604820 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 22:21:58.604840 16530 net.cpp:84] Creating Layer layer_256_5_scale1
I0528 22:21:58.604845 16530 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0528 22:21:58.604863 16530 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0528 22:21:58.604918 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 22:21:58.605057 16530 net.cpp:122] Setting up layer_256_5_scale1
I0528 22:21:58.605080 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.605084 16530 net.cpp:137] Memory required for data: 1408942320
I0528 22:21:58.605092 16530 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0528 22:21:58.605098 16530 net.cpp:84] Creating Layer layer_256_5_relu1
I0528 22:21:58.605101 16530 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0528 22:21:58.605108 16530 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0528 22:21:58.605372 16530 net.cpp:122] Setting up layer_256_5_relu1
I0528 22:21:58.605402 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.605407 16530 net.cpp:137] Memory required for data: 1412956400
I0528 22:21:58.605443 16530 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0528 22:21:58.605465 16530 net.cpp:84] Creating Layer layer_256_5_conv1
I0528 22:21:58.605470 16530 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0528 22:21:58.605480 16530 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0528 22:21:58.623214 16530 net.cpp:122] Setting up layer_256_5_conv1
I0528 22:21:58.623245 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.623250 16530 net.cpp:137] Memory required for data: 1416970480
I0528 22:21:58.623256 16530 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0528 22:21:58.623266 16530 net.cpp:84] Creating Layer layer_256_5_bn2
I0528 22:21:58.623282 16530 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0528 22:21:58.623289 16530 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0528 22:21:58.623502 16530 net.cpp:122] Setting up layer_256_5_bn2
I0528 22:21:58.623524 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.623539 16530 net.cpp:137] Memory required for data: 1420984560
I0528 22:21:58.623550 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 22:21:58.623558 16530 net.cpp:84] Creating Layer layer_256_5_scale2
I0528 22:21:58.623564 16530 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0528 22:21:58.623569 16530 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0528 22:21:58.623631 16530 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 22:21:58.623770 16530 net.cpp:122] Setting up layer_256_5_scale2
I0528 22:21:58.623781 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.623795 16530 net.cpp:137] Memory required for data: 1424998640
I0528 22:21:58.623802 16530 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0528 22:21:58.623819 16530 net.cpp:84] Creating Layer layer_256_5_relu2
I0528 22:21:58.623824 16530 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0528 22:21:58.623831 16530 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0528 22:21:58.624514 16530 net.cpp:122] Setting up layer_256_5_relu2
I0528 22:21:58.624533 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.624552 16530 net.cpp:137] Memory required for data: 1429012720
I0528 22:21:58.624555 16530 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0528 22:21:58.624567 16530 net.cpp:84] Creating Layer layer_256_5_conv2
I0528 22:21:58.624583 16530 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0528 22:21:58.624605 16530 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0528 22:21:58.641958 16530 net.cpp:122] Setting up layer_256_5_conv2
I0528 22:21:58.641995 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642000 16530 net.cpp:137] Memory required for data: 1433026800
I0528 22:21:58.642007 16530 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0528 22:21:58.642029 16530 net.cpp:84] Creating Layer layer_256_5_sum
I0528 22:21:58.642033 16530 net.cpp:406] layer_256_5_sum <- layer_256_5_conv2
I0528 22:21:58.642050 16530 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 22:21:58.642057 16530 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0528 22:21:58.642088 16530 net.cpp:122] Setting up layer_256_5_sum
I0528 22:21:58.642096 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642101 16530 net.cpp:137] Memory required for data: 1437040880
I0528 22:21:58.642104 16530 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:58.642145 16530 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:58.642155 16530 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0528 22:21:58.642163 16530 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 22:21:58.642172 16530 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 22:21:58.642213 16530 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0528 22:21:58.642230 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642242 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642246 16530 net.cpp:137] Memory required for data: 1445069040
I0528 22:21:58.642251 16530 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0528 22:21:58.642268 16530 net.cpp:84] Creating Layer layer_256_6_bn1
I0528 22:21:58.642274 16530 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 22:21:58.642282 16530 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0528 22:21:58.642519 16530 net.cpp:122] Setting up layer_256_6_bn1
I0528 22:21:58.642530 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642545 16530 net.cpp:137] Memory required for data: 1449083120
I0528 22:21:58.642565 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 22:21:58.642571 16530 net.cpp:84] Creating Layer layer_256_6_scale1
I0528 22:21:58.642577 16530 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0528 22:21:58.642583 16530 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0528 22:21:58.642629 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 22:21:58.642745 16530 net.cpp:122] Setting up layer_256_6_scale1
I0528 22:21:58.642779 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.642783 16530 net.cpp:137] Memory required for data: 1453097200
I0528 22:21:58.642802 16530 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0528 22:21:58.642809 16530 net.cpp:84] Creating Layer layer_256_6_relu1
I0528 22:21:58.642813 16530 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0528 22:21:58.642819 16530 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0528 22:21:58.643564 16530 net.cpp:122] Setting up layer_256_6_relu1
I0528 22:21:58.643596 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.643601 16530 net.cpp:137] Memory required for data: 1457111280
I0528 22:21:58.643606 16530 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0528 22:21:58.643618 16530 net.cpp:84] Creating Layer layer_256_6_conv1
I0528 22:21:58.643623 16530 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0528 22:21:58.643631 16530 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0528 22:21:58.661399 16530 net.cpp:122] Setting up layer_256_6_conv1
I0528 22:21:58.661432 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.661438 16530 net.cpp:137] Memory required for data: 1461125360
I0528 22:21:58.661444 16530 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0528 22:21:58.661451 16530 net.cpp:84] Creating Layer layer_256_6_bn2
I0528 22:21:58.661466 16530 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0528 22:21:58.661480 16530 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0528 22:21:58.661701 16530 net.cpp:122] Setting up layer_256_6_bn2
I0528 22:21:58.661713 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.661728 16530 net.cpp:137] Memory required for data: 1465139440
I0528 22:21:58.661736 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 22:21:58.661744 16530 net.cpp:84] Creating Layer layer_256_6_scale2
I0528 22:21:58.661749 16530 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0528 22:21:58.661756 16530 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0528 22:21:58.661823 16530 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 22:21:58.661970 16530 net.cpp:122] Setting up layer_256_6_scale2
I0528 22:21:58.661981 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.661996 16530 net.cpp:137] Memory required for data: 1469153520
I0528 22:21:58.662003 16530 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0528 22:21:58.662014 16530 net.cpp:84] Creating Layer layer_256_6_relu2
I0528 22:21:58.662030 16530 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0528 22:21:58.662048 16530 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0528 22:21:58.662292 16530 net.cpp:122] Setting up layer_256_6_relu2
I0528 22:21:58.662317 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.662331 16530 net.cpp:137] Memory required for data: 1473167600
I0528 22:21:58.662336 16530 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0528 22:21:58.662359 16530 net.cpp:84] Creating Layer layer_256_6_conv2
I0528 22:21:58.662365 16530 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0528 22:21:58.662374 16530 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0528 22:21:58.680572 16530 net.cpp:122] Setting up layer_256_6_conv2
I0528 22:21:58.680604 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.680609 16530 net.cpp:137] Memory required for data: 1477181680
I0528 22:21:58.680615 16530 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0528 22:21:58.680622 16530 net.cpp:84] Creating Layer layer_256_6_sum
I0528 22:21:58.680640 16530 net.cpp:406] layer_256_6_sum <- layer_256_6_conv2
I0528 22:21:58.680646 16530 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 22:21:58.680665 16530 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0528 22:21:58.680696 16530 net.cpp:122] Setting up layer_256_6_sum
I0528 22:21:58.680704 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.680711 16530 net.cpp:137] Memory required for data: 1481195760
I0528 22:21:58.680714 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 22:21:58.680721 16530 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 22:21:58.680726 16530 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0528 22:21:58.680732 16530 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 22:21:58.680965 16530 net.cpp:122] Setting up layer_512_1_bn1
I0528 22:21:58.680987 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.680992 16530 net.cpp:137] Memory required for data: 1485209840
I0528 22:21:58.681011 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 22:21:58.681020 16530 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 22:21:58.681023 16530 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 22:21:58.681032 16530 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 22:21:58.681088 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 22:21:58.681228 16530 net.cpp:122] Setting up layer_512_1_scale1
I0528 22:21:58.681257 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.681262 16530 net.cpp:137] Memory required for data: 1489223920
I0528 22:21:58.681278 16530 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 22:21:58.681296 16530 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 22:21:58.681301 16530 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 22:21:58.681318 16530 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 22:21:58.682025 16530 net.cpp:122] Setting up layer_512_1_relu1
I0528 22:21:58.682052 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.682057 16530 net.cpp:137] Memory required for data: 1493238000
I0528 22:21:58.682061 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:58.682070 16530 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:58.682085 16530 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 22:21:58.682092 16530 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 22:21:58.682111 16530 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 22:21:58.682183 16530 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 22:21:58.682196 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.682201 16530 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 22:21:58.682205 16530 net.cpp:137] Memory required for data: 1501266160
I0528 22:21:58.682209 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 22:21:58.682220 16530 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 22:21:58.682225 16530 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 22:21:58.682250 16530 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 22:21:58.717557 16530 net.cpp:122] Setting up layer_512_1_conv1
I0528 22:21:58.717592 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.717597 16530 net.cpp:137] Memory required for data: 1503273200
I0528 22:21:58.717603 16530 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 22:21:58.717612 16530 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 22:21:58.717629 16530 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 22:21:58.717638 16530 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 22:21:58.717890 16530 net.cpp:122] Setting up layer_512_1_bn2
I0528 22:21:58.717902 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.717917 16530 net.cpp:137] Memory required for data: 1505280240
I0528 22:21:58.717936 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 22:21:58.717947 16530 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 22:21:58.717952 16530 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 22:21:58.717969 16530 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 22:21:58.718021 16530 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 22:21:58.718216 16530 net.cpp:122] Setting up layer_512_1_scale2
I0528 22:21:58.718231 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.718247 16530 net.cpp:137] Memory required for data: 1507287280
I0528 22:21:58.718255 16530 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 22:21:58.718262 16530 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 22:21:58.718272 16530 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 22:21:58.718291 16530 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 22:21:58.719024 16530 net.cpp:122] Setting up layer_512_1_relu2
I0528 22:21:58.719056 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.719061 16530 net.cpp:137] Memory required for data: 1509294320
I0528 22:21:58.719065 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 22:21:58.719080 16530 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 22:21:58.719087 16530 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 22:21:58.719105 16530 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 22:21:58.784677 16530 net.cpp:122] Setting up layer_512_1_conv2
I0528 22:21:58.784713 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.784718 16530 net.cpp:137] Memory required for data: 1511301360
I0528 22:21:58.784723 16530 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 22:21:58.784737 16530 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 22:21:58.784757 16530 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 22:21:58.784765 16530 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 22:21:58.789997 16530 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 22:21:58.790029 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790035 16530 net.cpp:137] Memory required for data: 1513308400
I0528 22:21:58.790040 16530 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 22:21:58.790047 16530 net.cpp:84] Creating Layer layer_512_1_sum
I0528 22:21:58.790052 16530 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 22:21:58.790076 16530 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 22:21:58.790084 16530 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 22:21:58.790145 16530 net.cpp:122] Setting up layer_512_1_sum
I0528 22:21:58.790159 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790163 16530 net.cpp:137] Memory required for data: 1515315440
I0528 22:21:58.790168 16530 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.790174 16530 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.790179 16530 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 22:21:58.790196 16530 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 22:21:58.790205 16530 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 22:21:58.790248 16530 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 22:21:58.790256 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790261 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790264 16530 net.cpp:137] Memory required for data: 1519329520
I0528 22:21:58.790268 16530 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 22:21:58.790277 16530 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 22:21:58.790282 16530 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 22:21:58.790288 16530 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 22:21:58.790562 16530 net.cpp:122] Setting up layer_512_2_bn1
I0528 22:21:58.790576 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790592 16530 net.cpp:137] Memory required for data: 1521336560
I0528 22:21:58.790613 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 22:21:58.790632 16530 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 22:21:58.790637 16530 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 22:21:58.790643 16530 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 22:21:58.790709 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 22:21:58.790863 16530 net.cpp:122] Setting up layer_512_2_scale1
I0528 22:21:58.790875 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.790890 16530 net.cpp:137] Memory required for data: 1523343600
I0528 22:21:58.790897 16530 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 22:21:58.790905 16530 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 22:21:58.790910 16530 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 22:21:58.790927 16530 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 22:21:58.791625 16530 net.cpp:122] Setting up layer_512_2_relu1
I0528 22:21:58.791656 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.791661 16530 net.cpp:137] Memory required for data: 1525350640
I0528 22:21:58.791666 16530 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 22:21:58.791678 16530 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 22:21:58.791702 16530 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 22:21:58.791712 16530 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 22:21:58.861416 16530 net.cpp:122] Setting up layer_512_2_conv1
I0528 22:21:58.861454 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.861460 16530 net.cpp:137] Memory required for data: 1527357680
I0528 22:21:58.861466 16530 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 22:21:58.861475 16530 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 22:21:58.861480 16530 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 22:21:58.861502 16530 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.861734 16530 net.cpp:122] Setting up layer_512_2_bn2
I0528 22:21:58.861747 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.861760 16530 net.cpp:137] Memory required for data: 1529364720
I0528 22:21:58.861769 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 22:21:58.861776 16530 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 22:21:58.861781 16530 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 22:21:58.861794 16530 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.861884 16530 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 22:21:58.862052 16530 net.cpp:122] Setting up layer_512_2_scale2
I0528 22:21:58.862076 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.862079 16530 net.cpp:137] Memory required for data: 1531371760
I0528 22:21:58.862097 16530 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 22:21:58.862108 16530 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 22:21:58.862143 16530 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 22:21:58.862174 16530 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 22:21:58.862407 16530 net.cpp:122] Setting up layer_512_2_relu2
I0528 22:21:58.862421 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.862437 16530 net.cpp:137] Memory required for data: 1533378800
I0528 22:21:58.862442 16530 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 22:21:58.862453 16530 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 22:21:58.862459 16530 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 22:21:58.862468 16530 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 22:21:58.930515 16530 net.cpp:122] Setting up layer_512_2_conv2
I0528 22:21:58.930557 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.930562 16530 net.cpp:137] Memory required for data: 1535385840
I0528 22:21:58.930577 16530 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 22:21:58.930603 16530 net.cpp:84] Creating Layer layer_512_2_sum
I0528 22:21:58.930627 16530 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 22:21:58.930634 16530 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 22:21:58.930644 16530 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 22:21:58.930678 16530 net.cpp:122] Setting up layer_512_2_sum
I0528 22:21:58.930687 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.930691 16530 net.cpp:137] Memory required for data: 1537392880
I0528 22:21:58.930696 16530 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.930706 16530 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.930711 16530 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0528 22:21:58.930716 16530 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 22:21:58.930723 16530 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 22:21:58.930764 16530 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0528 22:21:58.930771 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.930776 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.930779 16530 net.cpp:137] Memory required for data: 1541406960
I0528 22:21:58.930784 16530 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0528 22:21:58.930794 16530 net.cpp:84] Creating Layer layer_512_3_bn1
I0528 22:21:58.930799 16530 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 22:21:58.930804 16530 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0528 22:21:58.931161 16530 net.cpp:122] Setting up layer_512_3_bn1
I0528 22:21:58.931176 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.931192 16530 net.cpp:137] Memory required for data: 1543414000
I0528 22:21:58.931200 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 22:21:58.931211 16530 net.cpp:84] Creating Layer layer_512_3_scale1
I0528 22:21:58.931244 16530 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0528 22:21:58.931252 16530 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0528 22:21:58.931319 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 22:21:58.931485 16530 net.cpp:122] Setting up layer_512_3_scale1
I0528 22:21:58.931496 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.931512 16530 net.cpp:137] Memory required for data: 1545421040
I0528 22:21:58.931519 16530 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0528 22:21:58.931537 16530 net.cpp:84] Creating Layer layer_512_3_relu1
I0528 22:21:58.931545 16530 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0528 22:21:58.931563 16530 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0528 22:21:58.932430 16530 net.cpp:122] Setting up layer_512_3_relu1
I0528 22:21:58.932466 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.932477 16530 net.cpp:137] Memory required for data: 1547428080
I0528 22:21:58.932482 16530 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0528 22:21:58.932497 16530 net.cpp:84] Creating Layer layer_512_3_conv1
I0528 22:21:58.932502 16530 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0528 22:21:58.932510 16530 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0528 22:21:58.998188 16530 net.cpp:122] Setting up layer_512_3_conv1
I0528 22:21:58.998222 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.998227 16530 net.cpp:137] Memory required for data: 1549435120
I0528 22:21:58.998234 16530 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0528 22:21:58.998245 16530 net.cpp:84] Creating Layer layer_512_3_bn2
I0528 22:21:58.998268 16530 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0528 22:21:58.998277 16530 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.998540 16530 net.cpp:122] Setting up layer_512_3_bn2
I0528 22:21:58.998553 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.998567 16530 net.cpp:137] Memory required for data: 1551442160
I0528 22:21:58.998576 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 22:21:58.998585 16530 net.cpp:84] Creating Layer layer_512_3_scale2
I0528 22:21:58.998612 16530 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0528 22:21:58.998643 16530 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.998709 16530 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 22:21:58.998874 16530 net.cpp:122] Setting up layer_512_3_scale2
I0528 22:21:58.998886 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.998901 16530 net.cpp:137] Memory required for data: 1553449200
I0528 22:21:58.998919 16530 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0528 22:21:58.998927 16530 net.cpp:84] Creating Layer layer_512_3_relu2
I0528 22:21:58.998932 16530 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0528 22:21:58.998937 16530 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0528 22:21:58.999640 16530 net.cpp:122] Setting up layer_512_3_relu2
I0528 22:21:58.999675 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:58.999680 16530 net.cpp:137] Memory required for data: 1555456240
I0528 22:21:58.999685 16530 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0528 22:21:58.999698 16530 net.cpp:84] Creating Layer layer_512_3_conv2
I0528 22:21:58.999716 16530 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0528 22:21:58.999724 16530 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0528 22:21:59.065426 16530 net.cpp:122] Setting up layer_512_3_conv2
I0528 22:21:59.065461 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:59.065467 16530 net.cpp:137] Memory required for data: 1557463280
I0528 22:21:59.065474 16530 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0528 22:21:59.065482 16530 net.cpp:84] Creating Layer layer_512_3_sum
I0528 22:21:59.065505 16530 net.cpp:406] layer_512_3_sum <- layer_512_3_conv2
I0528 22:21:59.065511 16530 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 22:21:59.065528 16530 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0528 22:21:59.065563 16530 net.cpp:122] Setting up layer_512_3_sum
I0528 22:21:59.065572 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:59.065575 16530 net.cpp:137] Memory required for data: 1559470320
I0528 22:21:59.065580 16530 layer_factory.hpp:77] Creating layer last_bn
I0528 22:21:59.065592 16530 net.cpp:84] Creating Layer last_bn
I0528 22:21:59.065596 16530 net.cpp:406] last_bn <- layer_512_3_sum
I0528 22:21:59.065601 16530 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0528 22:21:59.065870 16530 net.cpp:122] Setting up last_bn
I0528 22:21:59.065881 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:59.065896 16530 net.cpp:137] Memory required for data: 1561477360
I0528 22:21:59.065904 16530 layer_factory.hpp:77] Creating layer last_scale
I0528 22:21:59.065920 16530 net.cpp:84] Creating Layer last_scale
I0528 22:21:59.065946 16530 net.cpp:406] last_scale <- layer_512_3_sum
I0528 22:21:59.065966 16530 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0528 22:21:59.066020 16530 layer_factory.hpp:77] Creating layer last_scale
I0528 22:21:59.066226 16530 net.cpp:122] Setting up last_scale
I0528 22:21:59.066256 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:59.066262 16530 net.cpp:137] Memory required for data: 1563484400
I0528 22:21:59.066268 16530 layer_factory.hpp:77] Creating layer last_relu
I0528 22:21:59.066285 16530 net.cpp:84] Creating Layer last_relu
I0528 22:21:59.066313 16530 net.cpp:406] last_relu <- layer_512_3_sum
I0528 22:21:59.066330 16530 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0528 22:21:59.066604 16530 net.cpp:122] Setting up last_relu
I0528 22:21:59.066632 16530 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 22:21:59.066635 16530 net.cpp:137] Memory required for data: 1565491440
I0528 22:21:59.066640 16530 layer_factory.hpp:77] Creating layer global_pool
I0528 22:21:59.066658 16530 net.cpp:84] Creating Layer global_pool
I0528 22:21:59.066663 16530 net.cpp:406] global_pool <- layer_512_3_sum
I0528 22:21:59.066684 16530 net.cpp:380] global_pool -> global_pool
I0528 22:21:59.067459 16530 net.cpp:122] Setting up global_pool
I0528 22:21:59.067489 16530 net.cpp:129] Top shape: 20 512 1 1 (10240)
I0528 22:21:59.067494 16530 net.cpp:137] Memory required for data: 1565532400
I0528 22:21:59.067498 16530 layer_factory.hpp:77] Creating layer score
I0528 22:21:59.067508 16530 net.cpp:84] Creating Layer score
I0528 22:21:59.067513 16530 net.cpp:406] score <- global_pool
I0528 22:21:59.067558 16530 net.cpp:380] score -> score
I0528 22:21:59.067790 16530 net.cpp:122] Setting up score
I0528 22:21:59.067802 16530 net.cpp:129] Top shape: 20 8 (160)
I0528 22:21:59.067817 16530 net.cpp:137] Memory required for data: 1565533040
I0528 22:21:59.067824 16530 layer_factory.hpp:77] Creating layer score_score_0_split
I0528 22:21:59.067847 16530 net.cpp:84] Creating Layer score_score_0_split
I0528 22:21:59.067873 16530 net.cpp:406] score_score_0_split <- score
I0528 22:21:59.067880 16530 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0528 22:21:59.067900 16530 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0528 22:21:59.067955 16530 net.cpp:122] Setting up score_score_0_split
I0528 22:21:59.067973 16530 net.cpp:129] Top shape: 20 8 (160)
I0528 22:21:59.067978 16530 net.cpp:129] Top shape: 20 8 (160)
I0528 22:21:59.067981 16530 net.cpp:137] Memory required for data: 1565534320
I0528 22:21:59.067986 16530 layer_factory.hpp:77] Creating layer loss
I0528 22:21:59.067993 16530 net.cpp:84] Creating Layer loss
I0528 22:21:59.067998 16530 net.cpp:406] loss <- score_score_0_split_0
I0528 22:21:59.068003 16530 net.cpp:406] loss <- label_data_1_split_0
I0528 22:21:59.068008 16530 net.cpp:380] loss -> loss
I0528 22:21:59.068017 16530 layer_factory.hpp:77] Creating layer loss
I0528 22:21:59.068398 16530 net.cpp:122] Setting up loss
I0528 22:21:59.068415 16530 net.cpp:129] Top shape: (1)
I0528 22:21:59.068431 16530 net.cpp:132]     with loss weight 1
I0528 22:21:59.068480 16530 net.cpp:137] Memory required for data: 1565534324
I0528 22:21:59.068485 16530 layer_factory.hpp:77] Creating layer accuracy
I0528 22:21:59.068512 16530 net.cpp:84] Creating Layer accuracy
I0528 22:21:59.068518 16530 net.cpp:406] accuracy <- score_score_0_split_1
I0528 22:21:59.068524 16530 net.cpp:406] accuracy <- label_data_1_split_1
I0528 22:21:59.068532 16530 net.cpp:380] accuracy -> accuracy
I0528 22:21:59.068548 16530 net.cpp:122] Setting up accuracy
I0528 22:21:59.068554 16530 net.cpp:129] Top shape: (1)
I0528 22:21:59.068557 16530 net.cpp:137] Memory required for data: 1565534328
I0528 22:21:59.068562 16530 net.cpp:200] accuracy does not need backward computation.
I0528 22:21:59.068567 16530 net.cpp:198] loss needs backward computation.
I0528 22:21:59.068570 16530 net.cpp:198] score_score_0_split needs backward computation.
I0528 22:21:59.068579 16530 net.cpp:198] score needs backward computation.
I0528 22:21:59.068590 16530 net.cpp:198] global_pool needs backward computation.
I0528 22:21:59.068594 16530 net.cpp:198] last_relu needs backward computation.
I0528 22:21:59.068598 16530 net.cpp:198] last_scale needs backward computation.
I0528 22:21:59.068601 16530 net.cpp:198] last_bn needs backward computation.
I0528 22:21:59.068605 16530 net.cpp:198] layer_512_3_sum needs backward computation.
I0528 22:21:59.068609 16530 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0528 22:21:59.068614 16530 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0528 22:21:59.068616 16530 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0528 22:21:59.068620 16530 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0528 22:21:59.068624 16530 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0528 22:21:59.068627 16530 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0528 22:21:59.068630 16530 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0528 22:21:59.068634 16530 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0528 22:21:59.068639 16530 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0528 22:21:59.068642 16530 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 22:21:59.068647 16530 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 22:21:59.068651 16530 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 22:21:59.068655 16530 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 22:21:59.068658 16530 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 22:21:59.068663 16530 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 22:21:59.068668 16530 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 22:21:59.068673 16530 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 22:21:59.068677 16530 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 22:21:59.068693 16530 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 22:21:59.068697 16530 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 22:21:59.068703 16530 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 22:21:59.068712 16530 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 22:21:59.068718 16530 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 22:21:59.068722 16530 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 22:21:59.068727 16530 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 22:21:59.068730 16530 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 22:21:59.068735 16530 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 22:21:59.068740 16530 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 22:21:59.068744 16530 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 22:21:59.068749 16530 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 22:21:59.068754 16530 net.cpp:198] layer_256_6_sum needs backward computation.
I0528 22:21:59.068763 16530 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0528 22:21:59.068769 16530 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0528 22:21:59.068774 16530 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0528 22:21:59.068778 16530 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0528 22:21:59.068794 16530 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0528 22:21:59.068800 16530 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0528 22:21:59.068805 16530 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0528 22:21:59.068810 16530 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0528 22:21:59.068825 16530 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0528 22:21:59.068830 16530 net.cpp:198] layer_256_5_sum needs backward computation.
I0528 22:21:59.068843 16530 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0528 22:21:59.068850 16530 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0528 22:21:59.068853 16530 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0528 22:21:59.068859 16530 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0528 22:21:59.068864 16530 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0528 22:21:59.068871 16530 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0528 22:21:59.068876 16530 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0528 22:21:59.068881 16530 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0528 22:21:59.068886 16530 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0528 22:21:59.068891 16530 net.cpp:198] layer_256_4_sum needs backward computation.
I0528 22:21:59.068907 16530 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0528 22:21:59.068912 16530 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0528 22:21:59.068917 16530 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0528 22:21:59.068922 16530 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0528 22:21:59.068938 16530 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0528 22:21:59.068943 16530 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0528 22:21:59.068946 16530 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0528 22:21:59.068951 16530 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0528 22:21:59.068956 16530 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0528 22:21:59.068960 16530 net.cpp:198] layer_256_3_sum needs backward computation.
I0528 22:21:59.068966 16530 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0528 22:21:59.068971 16530 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0528 22:21:59.068975 16530 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0528 22:21:59.068981 16530 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0528 22:21:59.068986 16530 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0528 22:21:59.068992 16530 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0528 22:21:59.068996 16530 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0528 22:21:59.069001 16530 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0528 22:21:59.069005 16530 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0528 22:21:59.069010 16530 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 22:21:59.069016 16530 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 22:21:59.069032 16530 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 22:21:59.069037 16530 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 22:21:59.069042 16530 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 22:21:59.069047 16530 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 22:21:59.069062 16530 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 22:21:59.069068 16530 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 22:21:59.069072 16530 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 22:21:59.069077 16530 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 22:21:59.069082 16530 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 22:21:59.069089 16530 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 22:21:59.069094 16530 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 22:21:59.069100 16530 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 22:21:59.069104 16530 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 22:21:59.069109 16530 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 22:21:59.069114 16530 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 22:21:59.069133 16530 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 22:21:59.069145 16530 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 22:21:59.069150 16530 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 22:21:59.069155 16530 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 22:21:59.069159 16530 net.cpp:198] layer_128_4_sum needs backward computation.
I0528 22:21:59.069166 16530 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0528 22:21:59.069175 16530 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0528 22:21:59.069180 16530 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0528 22:21:59.069185 16530 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0528 22:21:59.069190 16530 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0528 22:21:59.069193 16530 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0528 22:21:59.069200 16530 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0528 22:21:59.069205 16530 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0528 22:21:59.069211 16530 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0528 22:21:59.069216 16530 net.cpp:198] layer_128_3_sum needs backward computation.
I0528 22:21:59.069221 16530 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0528 22:21:59.069226 16530 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0528 22:21:59.069231 16530 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0528 22:21:59.069236 16530 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0528 22:21:59.069242 16530 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0528 22:21:59.069247 16530 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0528 22:21:59.069252 16530 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0528 22:21:59.069257 16530 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0528 22:21:59.069263 16530 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0528 22:21:59.069268 16530 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 22:21:59.069272 16530 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 22:21:59.069278 16530 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 22:21:59.069283 16530 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 22:21:59.069288 16530 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 22:21:59.069291 16530 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 22:21:59.069296 16530 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 22:21:59.069300 16530 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 22:21:59.069306 16530 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 22:21:59.069311 16530 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 22:21:59.069317 16530 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 22:21:59.069322 16530 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 22:21:59.069327 16530 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 22:21:59.069334 16530 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 22:21:59.069337 16530 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 22:21:59.069341 16530 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 22:21:59.069356 16530 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 22:21:59.069363 16530 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 22:21:59.069368 16530 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 22:21:59.069375 16530 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 22:21:59.069378 16530 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 22:21:59.069382 16530 net.cpp:198] layer_64_3_sum needs backward computation.
I0528 22:21:59.069391 16530 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0528 22:21:59.069401 16530 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0528 22:21:59.069406 16530 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0528 22:21:59.069411 16530 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0528 22:21:59.069414 16530 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0528 22:21:59.069420 16530 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0528 22:21:59.069425 16530 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0528 22:21:59.069430 16530 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0528 22:21:59.069437 16530 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0528 22:21:59.069440 16530 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 22:21:59.069447 16530 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 22:21:59.069453 16530 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 22:21:59.069458 16530 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 22:21:59.069464 16530 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 22:21:59.069469 16530 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 22:21:59.069474 16530 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 22:21:59.069479 16530 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 22:21:59.069483 16530 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 22:21:59.069489 16530 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 22:21:59.069494 16530 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 22:21:59.069499 16530 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 22:21:59.069505 16530 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 22:21:59.069511 16530 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 22:21:59.069515 16530 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 22:21:59.069519 16530 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 22:21:59.069525 16530 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 22:21:59.069530 16530 net.cpp:198] conv1_pool needs backward computation.
I0528 22:21:59.069535 16530 net.cpp:198] conv1_relu needs backward computation.
I0528 22:21:59.069538 16530 net.cpp:198] conv1_scale needs backward computation.
I0528 22:21:59.069543 16530 net.cpp:198] conv1_bn needs backward computation.
I0528 22:21:59.069547 16530 net.cpp:198] conv1 needs backward computation.
I0528 22:21:59.069551 16530 net.cpp:198] data_scale needs backward computation.
I0528 22:21:59.069555 16530 net.cpp:200] data_bn does not need backward computation.
I0528 22:21:59.069561 16530 net.cpp:200] label_data_1_split does not need backward computation.
I0528 22:21:59.069566 16530 net.cpp:200] data does not need backward computation.
I0528 22:21:59.069568 16530 net.cpp:242] This network produces output accuracy
I0528 22:21:59.069576 16530 net.cpp:242] This network produces output loss
I0528 22:21:59.069674 16530 net.cpp:255] Network initialization done.
I0528 22:21:59.070513 16530 solver.cpp:56] Solver scaffolding done.
I0528 22:21:59.077967 16530 caffe.cpp:248] Starting Optimization
I0528 22:21:59.077996 16530 solver.cpp:272] Solving Pre-ResNet-34
I0528 22:21:59.078001 16530 solver.cpp:273] Learning Rate Policy: poly
I0528 22:21:59.095044 16530 solver.cpp:330] Iteration 0, Testing net (#0)
I0528 22:23:04.414969 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:24:10.052063 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:24:51.813231 16530 solver.cpp:397]     Test net output #0: accuracy = 0.122196
I0528 22:24:51.813393 16530 solver.cpp:397]     Test net output #1: loss = 87.336 (* 1 = 87.336 loss)
I0528 22:24:52.955828 16530 solver.cpp:218] Iteration 0 (0 iter/s, 173.877s/100 iters), loss = 2.07944
I0528 22:24:52.955886 16530 solver.cpp:237]     Train net output #0: loss = 2.07944 (* 1 = 2.07944 loss)
I0528 22:24:52.955914 16530 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0528 22:26:46.952406 16530 solver.cpp:218] Iteration 100 (0.877228 iter/s, 113.995s/100 iters), loss = 1.45572
I0528 22:26:46.952710 16530 solver.cpp:237]     Train net output #0: loss = 1.45572 (* 1 = 1.45572 loss)
I0528 22:26:46.952747 16530 sgd_solver.cpp:105] Iteration 100, lr = 0.009995
I0528 22:28:41.054841 16530 solver.cpp:218] Iteration 200 (0.876417 iter/s, 114.101s/100 iters), loss = 1.6183
I0528 22:28:41.055085 16530 solver.cpp:237]     Train net output #0: loss = 1.6183 (* 1 = 1.6183 loss)
I0528 22:28:41.055111 16530 sgd_solver.cpp:105] Iteration 200, lr = 0.00999
I0528 22:30:35.121747 16530 solver.cpp:218] Iteration 300 (0.876689 iter/s, 114.066s/100 iters), loss = 1.24566
I0528 22:30:35.121894 16530 solver.cpp:237]     Train net output #0: loss = 1.24566 (* 1 = 1.24566 loss)
I0528 22:30:35.121932 16530 sgd_solver.cpp:105] Iteration 300, lr = 0.009985
I0528 22:32:29.214933 16530 solver.cpp:218] Iteration 400 (0.876486 iter/s, 114.092s/100 iters), loss = 1.33406
I0528 22:32:29.215173 16530 solver.cpp:237]     Train net output #0: loss = 1.33406 (* 1 = 1.33406 loss)
I0528 22:32:29.215193 16530 sgd_solver.cpp:105] Iteration 400, lr = 0.00998
I0528 22:34:23.286799 16530 solver.cpp:218] Iteration 500 (0.876651 iter/s, 114.071s/100 iters), loss = 1.36489
I0528 22:34:23.287034 16530 solver.cpp:237]     Train net output #0: loss = 1.36489 (* 1 = 1.36489 loss)
I0528 22:34:23.287055 16530 sgd_solver.cpp:105] Iteration 500, lr = 0.009975
I0528 22:36:17.401126 16530 solver.cpp:218] Iteration 600 (0.876324 iter/s, 114.113s/100 iters), loss = 1.69845
I0528 22:36:17.401302 16530 solver.cpp:237]     Train net output #0: loss = 1.69845 (* 1 = 1.69845 loss)
I0528 22:36:17.401340 16530 sgd_solver.cpp:105] Iteration 600, lr = 0.00997
I0528 22:38:11.520499 16530 solver.cpp:218] Iteration 700 (0.876285 iter/s, 114.118s/100 iters), loss = 1.40496
I0528 22:38:11.520696 16530 solver.cpp:237]     Train net output #0: loss = 1.40496 (* 1 = 1.40496 loss)
I0528 22:38:11.520722 16530 sgd_solver.cpp:105] Iteration 700, lr = 0.009965
I0528 22:39:39.581025 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:40:05.713281 16530 solver.cpp:218] Iteration 800 (0.875722 iter/s, 114.191s/100 iters), loss = 1.47541
I0528 22:40:05.713353 16530 solver.cpp:237]     Train net output #0: loss = 1.47541 (* 1 = 1.47541 loss)
I0528 22:40:05.713366 16530 sgd_solver.cpp:105] Iteration 800, lr = 0.00996
I0528 22:41:59.904281 16530 solver.cpp:218] Iteration 900 (0.875735 iter/s, 114.19s/100 iters), loss = 1.40976
I0528 22:41:59.904469 16530 solver.cpp:237]     Train net output #0: loss = 1.40976 (* 1 = 1.40976 loss)
I0528 22:41:59.904495 16530 sgd_solver.cpp:105] Iteration 900, lr = 0.009955
I0528 22:43:52.963886 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_1000.caffemodel
I0528 22:43:53.388592 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_1000.solverstate
I0528 22:43:53.494695 16530 solver.cpp:330] Iteration 1000, Testing net (#0)
I0528 22:44:17.547055 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:45:23.359735 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:46:29.119556 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:46:46.588253 16530 solver.cpp:397]     Test net output #0: accuracy = 0.419431
I0528 22:46:46.588330 16530 solver.cpp:397]     Test net output #1: loss = 1.48077 (* 1 = 1.48077 loss)
I0528 22:46:47.722553 16530 solver.cpp:218] Iteration 1000 (0.347445 iter/s, 287.815s/100 iters), loss = 1.33664
I0528 22:46:47.722632 16530 solver.cpp:237]     Train net output #0: loss = 1.33664 (* 1 = 1.33664 loss)
I0528 22:46:47.722647 16530 sgd_solver.cpp:105] Iteration 1000, lr = 0.00995
I0528 22:48:41.940934 16530 solver.cpp:218] Iteration 1100 (0.875525 iter/s, 114.217s/100 iters), loss = 1.53313
I0528 22:48:41.941155 16530 solver.cpp:237]     Train net output #0: loss = 1.53313 (* 1 = 1.53313 loss)
I0528 22:48:41.941198 16530 sgd_solver.cpp:105] Iteration 1100, lr = 0.009945
I0528 22:50:36.165760 16530 solver.cpp:218] Iteration 1200 (0.875477 iter/s, 114.223s/100 iters), loss = 1.34085
I0528 22:50:36.165913 16530 solver.cpp:237]     Train net output #0: loss = 1.34085 (* 1 = 1.34085 loss)
I0528 22:50:36.165928 16530 sgd_solver.cpp:105] Iteration 1200, lr = 0.00994
I0528 22:52:30.426733 16530 solver.cpp:218] Iteration 1300 (0.875199 iter/s, 114.26s/100 iters), loss = 1.19701
I0528 22:52:30.426950 16530 solver.cpp:237]     Train net output #0: loss = 1.19701 (* 1 = 1.19701 loss)
I0528 22:52:30.426993 16530 sgd_solver.cpp:105] Iteration 1300, lr = 0.009935
I0528 22:54:24.678174 16530 solver.cpp:218] Iteration 1400 (0.875273 iter/s, 114.25s/100 iters), loss = 1.40028
I0528 22:54:24.678356 16530 solver.cpp:237]     Train net output #0: loss = 1.40028 (* 1 = 1.40028 loss)
I0528 22:54:24.678398 16530 sgd_solver.cpp:105] Iteration 1400, lr = 0.00993
I0528 22:56:18.916818 16530 solver.cpp:218] Iteration 1500 (0.87537 iter/s, 114.237s/100 iters), loss = 1.36539
I0528 22:56:18.916999 16530 solver.cpp:237]     Train net output #0: loss = 1.36539 (* 1 = 1.36539 loss)
I0528 22:56:18.917035 16530 sgd_solver.cpp:105] Iteration 1500, lr = 0.009925
I0528 22:57:25.348644 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:58:13.173455 16530 solver.cpp:218] Iteration 1600 (0.875233 iter/s, 114.255s/100 iters), loss = 1.53501
I0528 22:58:13.173604 16530 solver.cpp:237]     Train net output #0: loss = 1.53501 (* 1 = 1.53501 loss)
I0528 22:58:13.173617 16530 sgd_solver.cpp:105] Iteration 1600, lr = 0.00992
I0528 23:00:07.453416 16530 solver.cpp:218] Iteration 1700 (0.875054 iter/s, 114.279s/100 iters), loss = 1.2676
I0528 23:00:07.453570 16530 solver.cpp:237]     Train net output #0: loss = 1.2676 (* 1 = 1.2676 loss)
I0528 23:00:07.453593 16530 sgd_solver.cpp:105] Iteration 1700, lr = 0.009915
I0528 23:02:01.739189 16530 solver.cpp:218] Iteration 1800 (0.875009 iter/s, 114.285s/100 iters), loss = 1.43332
I0528 23:02:01.739377 16530 solver.cpp:237]     Train net output #0: loss = 1.43332 (* 1 = 1.43332 loss)
I0528 23:02:01.739404 16530 sgd_solver.cpp:105] Iteration 1800, lr = 0.00991
I0528 23:03:56.053622 16530 solver.cpp:218] Iteration 1900 (0.87479 iter/s, 114.313s/100 iters), loss = 1.4485
I0528 23:03:56.053835 16530 solver.cpp:237]     Train net output #0: loss = 1.4485 (* 1 = 1.4485 loss)
I0528 23:03:56.053859 16530 sgd_solver.cpp:105] Iteration 1900, lr = 0.009905
I0528 23:05:49.187372 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_2000.caffemodel
I0528 23:05:49.556398 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_2000.solverstate
I0528 23:05:49.657327 16530 solver.cpp:330] Iteration 2000, Testing net (#0)
I0528 23:06:38.210461 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:07:44.107444 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:08:43.057485 16530 solver.cpp:397]     Test net output #0: accuracy = 0.356698
I0528 23:08:43.057673 16530 solver.cpp:397]     Test net output #1: loss = 1.68591 (* 1 = 1.68591 loss)
I0528 23:08:44.192765 16530 solver.cpp:218] Iteration 2000 (0.347058 iter/s, 288.136s/100 iters), loss = 1.30365
I0528 23:08:44.192843 16530 solver.cpp:237]     Train net output #0: loss = 1.30365 (* 1 = 1.30365 loss)
I0528 23:08:44.192857 16530 sgd_solver.cpp:105] Iteration 2000, lr = 0.0099
I0528 23:10:38.471755 16530 solver.cpp:218] Iteration 2100 (0.87506 iter/s, 114.278s/100 iters), loss = 1.46266
I0528 23:10:38.471921 16530 solver.cpp:237]     Train net output #0: loss = 1.46266 (* 1 = 1.46266 loss)
I0528 23:10:38.471971 16530 sgd_solver.cpp:105] Iteration 2100, lr = 0.009895
I0528 23:12:32.743687 16530 solver.cpp:218] Iteration 2200 (0.875115 iter/s, 114.271s/100 iters), loss = 1.42167
I0528 23:12:32.743885 16530 solver.cpp:237]     Train net output #0: loss = 1.42167 (* 1 = 1.42167 loss)
I0528 23:12:32.743933 16530 sgd_solver.cpp:105] Iteration 2200, lr = 0.00989
I0528 23:14:26.998735 16530 solver.cpp:218] Iteration 2300 (0.875245 iter/s, 114.254s/100 iters), loss = 1.19986
I0528 23:14:26.998916 16530 solver.cpp:237]     Train net output #0: loss = 1.19986 (* 1 = 1.19986 loss)
I0528 23:14:26.998965 16530 sgd_solver.cpp:105] Iteration 2300, lr = 0.009885
I0528 23:15:11.717089 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:16:21.274947 16530 solver.cpp:218] Iteration 2400 (0.875082 iter/s, 114.275s/100 iters), loss = 1.29416
I0528 23:16:21.275173 16530 solver.cpp:237]     Train net output #0: loss = 1.29416 (* 1 = 1.29416 loss)
I0528 23:16:21.275188 16530 sgd_solver.cpp:105] Iteration 2400, lr = 0.00988
I0528 23:18:15.551435 16530 solver.cpp:218] Iteration 2500 (0.87508 iter/s, 114.275s/100 iters), loss = 1.27026
I0528 23:18:15.551676 16530 solver.cpp:237]     Train net output #0: loss = 1.27026 (* 1 = 1.27026 loss)
I0528 23:18:15.551688 16530 sgd_solver.cpp:105] Iteration 2500, lr = 0.009875
I0528 23:20:09.829848 16530 solver.cpp:218] Iteration 2600 (0.875066 iter/s, 114.277s/100 iters), loss = 1.17903
I0528 23:20:09.830023 16530 solver.cpp:237]     Train net output #0: loss = 1.17903 (* 1 = 1.17903 loss)
I0528 23:20:09.830036 16530 sgd_solver.cpp:105] Iteration 2600, lr = 0.00987
I0528 23:22:04.200232 16530 solver.cpp:218] Iteration 2700 (0.874362 iter/s, 114.369s/100 iters), loss = 1.3741
I0528 23:22:04.200409 16530 solver.cpp:237]     Train net output #0: loss = 1.3741 (* 1 = 1.3741 loss)
I0528 23:22:04.200438 16530 sgd_solver.cpp:105] Iteration 2700, lr = 0.009865
I0528 23:23:58.585916 16530 solver.cpp:218] Iteration 2800 (0.874245 iter/s, 114.384s/100 iters), loss = 1.09424
I0528 23:23:58.586112 16530 solver.cpp:237]     Train net output #0: loss = 1.09424 (* 1 = 1.09424 loss)
I0528 23:23:58.586153 16530 sgd_solver.cpp:105] Iteration 2800, lr = 0.00986
I0528 23:25:52.981613 16530 solver.cpp:218] Iteration 2900 (0.874168 iter/s, 114.394s/100 iters), loss = 1.29093
I0528 23:25:52.981847 16530 solver.cpp:237]     Train net output #0: loss = 1.29093 (* 1 = 1.29093 loss)
I0528 23:25:52.981863 16530 sgd_solver.cpp:105] Iteration 2900, lr = 0.009855
I0528 23:27:46.228127 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_3000.caffemodel
I0528 23:27:46.506825 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_3000.solverstate
I0528 23:27:46.618428 16530 solver.cpp:330] Iteration 3000, Testing net (#0)
I0528 23:27:53.588645 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:28:59.680047 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:30:05.653035 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:30:40.192728 16530 solver.cpp:397]     Test net output #0: accuracy = 0.462344
I0528 23:30:40.192876 16530 solver.cpp:397]     Test net output #1: loss = 1.41096 (* 1 = 1.41096 loss)
I0528 23:30:41.326849 16530 solver.cpp:218] Iteration 3000 (0.34681 iter/s, 288.342s/100 iters), loss = 1.26561
I0528 23:30:41.326926 16530 solver.cpp:237]     Train net output #0: loss = 1.26561 (* 1 = 1.26561 loss)
I0528 23:30:41.326941 16530 sgd_solver.cpp:105] Iteration 3000, lr = 0.00985
I0528 23:32:35.680065 16530 solver.cpp:218] Iteration 3100 (0.874492 iter/s, 114.352s/100 iters), loss = 1.15551
I0528 23:32:35.680261 16530 solver.cpp:237]     Train net output #0: loss = 1.15551 (* 1 = 1.15551 loss)
I0528 23:32:35.680275 16530 sgd_solver.cpp:105] Iteration 3100, lr = 0.009845
I0528 23:32:59.839531 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:34:30.021229 16530 solver.cpp:218] Iteration 3200 (0.874585 iter/s, 114.34s/100 iters), loss = 1.25216
I0528 23:34:30.021435 16530 solver.cpp:237]     Train net output #0: loss = 1.25216 (* 1 = 1.25216 loss)
I0528 23:34:30.021483 16530 sgd_solver.cpp:105] Iteration 3200, lr = 0.00984
I0528 23:36:24.395220 16530 solver.cpp:218] Iteration 3300 (0.874334 iter/s, 114.373s/100 iters), loss = 1.24401
I0528 23:36:24.395469 16530 solver.cpp:237]     Train net output #0: loss = 1.24401 (* 1 = 1.24401 loss)
I0528 23:36:24.395494 16530 sgd_solver.cpp:105] Iteration 3300, lr = 0.009835
I0528 23:38:18.779000 16530 solver.cpp:218] Iteration 3400 (0.87426 iter/s, 114.382s/100 iters), loss = 1.48794
I0528 23:38:18.779278 16530 solver.cpp:237]     Train net output #0: loss = 1.48794 (* 1 = 1.48794 loss)
I0528 23:38:18.779306 16530 sgd_solver.cpp:105] Iteration 3400, lr = 0.00983
I0528 23:40:13.119009 16530 solver.cpp:218] Iteration 3500 (0.874594 iter/s, 114.339s/100 iters), loss = 1.20083
I0528 23:40:13.119215 16530 solver.cpp:237]     Train net output #0: loss = 1.20083 (* 1 = 1.20083 loss)
I0528 23:40:13.119228 16530 sgd_solver.cpp:105] Iteration 3500, lr = 0.009825
I0528 23:42:07.444109 16530 solver.cpp:218] Iteration 3600 (0.874708 iter/s, 114.324s/100 iters), loss = 1.38763
I0528 23:42:07.444258 16530 solver.cpp:237]     Train net output #0: loss = 1.38763 (* 1 = 1.38763 loss)
I0528 23:42:07.444273 16530 sgd_solver.cpp:105] Iteration 3600, lr = 0.00982
I0528 23:44:01.761507 16530 solver.cpp:218] Iteration 3700 (0.874766 iter/s, 114.316s/100 iters), loss = 1.2953
I0528 23:44:01.761684 16530 solver.cpp:237]     Train net output #0: loss = 1.2953 (* 1 = 1.2953 loss)
I0528 23:44:01.761713 16530 sgd_solver.cpp:105] Iteration 3700, lr = 0.009815
I0528 23:45:56.085459 16530 solver.cpp:218] Iteration 3800 (0.874716 iter/s, 114.323s/100 iters), loss = 1.21855
I0528 23:45:56.085701 16530 solver.cpp:237]     Train net output #0: loss = 1.21855 (* 1 = 1.21855 loss)
I0528 23:45:56.085716 16530 sgd_solver.cpp:105] Iteration 3800, lr = 0.00981
I0528 23:47:50.417796 16530 solver.cpp:218] Iteration 3900 (0.874652 iter/s, 114.331s/100 iters), loss = 1.01624
I0528 23:47:50.418018 16530 solver.cpp:237]     Train net output #0: loss = 1.01624 (* 1 = 1.01624 loss)
I0528 23:47:50.418045 16530 sgd_solver.cpp:105] Iteration 3900, lr = 0.009805
I0528 23:47:52.844892 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:49:43.607430 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_4000.caffemodel
I0528 23:49:43.921921 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_4000.solverstate
I0528 23:49:44.024365 16530 solver.cpp:330] Iteration 4000, Testing net (#0)
I0528 23:50:15.455775 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:51:21.519378 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:52:27.481447 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:52:37.559914 16530 solver.cpp:397]     Test net output #0: accuracy = 0.476168
I0528 23:52:37.559993 16530 solver.cpp:397]     Test net output #1: loss = 1.31383 (* 1 = 1.31383 loss)
I0528 23:52:38.693569 16530 solver.cpp:218] Iteration 4000 (0.346893 iter/s, 288.273s/100 iters), loss = 1.23997
I0528 23:52:38.693647 16530 solver.cpp:237]     Train net output #0: loss = 1.23997 (* 1 = 1.23997 loss)
I0528 23:52:38.693662 16530 sgd_solver.cpp:105] Iteration 4000, lr = 0.0098
I0528 23:54:33.034147 16530 solver.cpp:218] Iteration 4100 (0.874588 iter/s, 114.339s/100 iters), loss = 1.11424
I0528 23:54:33.034353 16530 solver.cpp:237]     Train net output #0: loss = 1.11424 (* 1 = 1.11424 loss)
I0528 23:54:33.034368 16530 sgd_solver.cpp:105] Iteration 4100, lr = 0.009795
I0528 23:56:27.374045 16530 solver.cpp:218] Iteration 4200 (0.874595 iter/s, 114.339s/100 iters), loss = 1.25947
I0528 23:56:27.374205 16530 solver.cpp:237]     Train net output #0: loss = 1.25947 (* 1 = 1.25947 loss)
I0528 23:56:27.374243 16530 sgd_solver.cpp:105] Iteration 4200, lr = 0.00979
I0528 23:58:21.689054 16530 solver.cpp:218] Iteration 4300 (0.874785 iter/s, 114.314s/100 iters), loss = 1.21744
I0528 23:58:21.689234 16530 solver.cpp:237]     Train net output #0: loss = 1.21744 (* 1 = 1.21744 loss)
I0528 23:58:21.689272 16530 sgd_solver.cpp:105] Iteration 4300, lr = 0.009785
I0529 00:00:16.003635 16530 solver.cpp:218] Iteration 4400 (0.874788 iter/s, 114.313s/100 iters), loss = 1.42129
I0529 00:00:16.003924 16530 solver.cpp:237]     Train net output #0: loss = 1.42129 (* 1 = 1.42129 loss)
I0529 00:00:16.003950 16530 sgd_solver.cpp:105] Iteration 4400, lr = 0.00978
I0529 00:02:10.339010 16530 solver.cpp:218] Iteration 4500 (0.87463 iter/s, 114.334s/100 iters), loss = 1.12791
I0529 00:02:10.339284 16530 solver.cpp:237]     Train net output #0: loss = 1.12791 (* 1 = 1.12791 loss)
I0529 00:02:10.339298 16530 sgd_solver.cpp:105] Iteration 4500, lr = 0.009775
I0529 00:04:04.683822 16530 solver.cpp:218] Iteration 4600 (0.874557 iter/s, 114.344s/100 iters), loss = 1.05565
I0529 00:04:04.684036 16530 solver.cpp:237]     Train net output #0: loss = 1.05565 (* 1 = 1.05565 loss)
I0529 00:04:04.684051 16530 sgd_solver.cpp:105] Iteration 4600, lr = 0.00977
I0529 00:05:39.746094 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:05:59.034147 16530 solver.cpp:218] Iteration 4700 (0.874515 iter/s, 114.349s/100 iters), loss = 1.39405
I0529 00:05:59.034220 16530 solver.cpp:237]     Train net output #0: loss = 1.39405 (* 1 = 1.39405 loss)
I0529 00:05:59.034234 16530 sgd_solver.cpp:105] Iteration 4700, lr = 0.009765
I0529 00:07:53.394615 16530 solver.cpp:218] Iteration 4800 (0.874436 iter/s, 114.359s/100 iters), loss = 1.22343
I0529 00:07:53.394743 16530 solver.cpp:237]     Train net output #0: loss = 1.22343 (* 1 = 1.22343 loss)
I0529 00:07:53.394757 16530 sgd_solver.cpp:105] Iteration 4800, lr = 0.00976
I0529 00:09:47.758005 16530 solver.cpp:218] Iteration 4900 (0.874414 iter/s, 114.362s/100 iters), loss = 1.24754
I0529 00:09:47.758298 16530 solver.cpp:237]     Train net output #0: loss = 1.24754 (* 1 = 1.24754 loss)
I0529 00:09:47.758313 16530 sgd_solver.cpp:105] Iteration 4900, lr = 0.009755
I0529 00:11:41.036797 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_5000.caffemodel
I0529 00:11:41.331027 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_5000.solverstate
I0529 00:11:41.426165 16530 solver.cpp:330] Iteration 5000, Testing net (#0)
I0529 00:12:37.353806 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:13:43.463140 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:14:35.058743 16530 solver.cpp:397]     Test net output #0: accuracy = 0.461215
I0529 00:14:35.058902 16530 solver.cpp:397]     Test net output #1: loss = 1.31764 (* 1 = 1.31764 loss)
I0529 00:14:36.194897 16530 solver.cpp:218] Iteration 5000 (0.3467 iter/s, 288.434s/100 iters), loss = 1.11663
I0529 00:14:36.194965 16530 solver.cpp:237]     Train net output #0: loss = 1.11663 (* 1 = 1.11663 loss)
I0529 00:14:36.194979 16530 sgd_solver.cpp:105] Iteration 5000, lr = 0.00975
I0529 00:16:30.632891 16530 solver.cpp:218] Iteration 5100 (0.873844 iter/s, 114.437s/100 iters), loss = 1.11217
I0529 00:16:30.633033 16530 solver.cpp:237]     Train net output #0: loss = 1.11217 (* 1 = 1.11217 loss)
I0529 00:16:30.633049 16530 sgd_solver.cpp:105] Iteration 5100, lr = 0.009745
I0529 00:18:25.057618 16530 solver.cpp:218] Iteration 5200 (0.873946 iter/s, 114.424s/100 iters), loss = 1.2247
I0529 00:18:25.057812 16530 solver.cpp:237]     Train net output #0: loss = 1.2247 (* 1 = 1.2247 loss)
I0529 00:18:25.057838 16530 sgd_solver.cpp:105] Iteration 5200, lr = 0.00974
I0529 00:20:19.472137 16530 solver.cpp:218] Iteration 5300 (0.874024 iter/s, 114.413s/100 iters), loss = 1.25977
I0529 00:20:19.472347 16530 solver.cpp:237]     Train net output #0: loss = 1.25977 (* 1 = 1.25977 loss)
I0529 00:20:19.472399 16530 sgd_solver.cpp:105] Iteration 5300, lr = 0.009735
I0529 00:22:13.909420 16530 solver.cpp:218] Iteration 5400 (0.87385 iter/s, 114.436s/100 iters), loss = 1.2231
I0529 00:22:13.909596 16530 solver.cpp:237]     Train net output #0: loss = 1.2231 (* 1 = 1.2231 loss)
I0529 00:22:13.909611 16530 sgd_solver.cpp:105] Iteration 5400, lr = 0.00973
I0529 00:23:27.337057 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:24:08.381042 16530 solver.cpp:218] Iteration 5500 (0.873588 iter/s, 114.47s/100 iters), loss = 1.30027
I0529 00:24:08.381294 16530 solver.cpp:237]     Train net output #0: loss = 1.30027 (* 1 = 1.30027 loss)
I0529 00:24:08.381309 16530 sgd_solver.cpp:105] Iteration 5500, lr = 0.009725
I0529 00:26:02.811096 16530 solver.cpp:218] Iteration 5600 (0.873906 iter/s, 114.429s/100 iters), loss = 1.04148
I0529 00:26:02.811250 16530 solver.cpp:237]     Train net output #0: loss = 1.04148 (* 1 = 1.04148 loss)
I0529 00:26:02.811267 16530 sgd_solver.cpp:105] Iteration 5600, lr = 0.00972
I0529 00:27:57.276777 16530 solver.cpp:218] Iteration 5700 (0.873633 iter/s, 114.465s/100 iters), loss = 1.1195
I0529 00:27:57.276950 16530 solver.cpp:237]     Train net output #0: loss = 1.1195 (* 1 = 1.1195 loss)
I0529 00:27:57.276965 16530 sgd_solver.cpp:105] Iteration 5700, lr = 0.009715
I0529 00:29:51.732877 16530 solver.cpp:218] Iteration 5800 (0.873707 iter/s, 114.455s/100 iters), loss = 1.49834
I0529 00:29:51.733086 16530 solver.cpp:237]     Train net output #0: loss = 1.49834 (* 1 = 1.49834 loss)
I0529 00:29:51.733100 16530 sgd_solver.cpp:105] Iteration 5800, lr = 0.00971
I0529 00:31:46.158332 16530 solver.cpp:218] Iteration 5900 (0.873941 iter/s, 114.424s/100 iters), loss = 1.13206
I0529 00:31:46.158534 16530 solver.cpp:237]     Train net output #0: loss = 1.13206 (* 1 = 1.13206 loss)
I0529 00:31:46.158570 16530 sgd_solver.cpp:105] Iteration 5900, lr = 0.009705
I0529 00:33:39.450173 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_6000.caffemodel
I0529 00:33:39.771138 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_6000.solverstate
I0529 00:33:39.871825 16530 solver.cpp:330] Iteration 6000, Testing net (#0)
I0529 00:33:54.278637 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:35:00.323616 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:36:06.531610 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:36:33.684279 16530 solver.cpp:397]     Test net output #0: accuracy = 0.472235
I0529 00:36:33.684352 16530 solver.cpp:397]     Test net output #1: loss = 1.27612 (* 1 = 1.27612 loss)
I0529 00:36:34.821769 16530 solver.cpp:218] Iteration 6000 (0.346428 iter/s, 288.661s/100 iters), loss = 1.17023
I0529 00:36:34.821847 16530 solver.cpp:237]     Train net output #0: loss = 1.17023 (* 1 = 1.17023 loss)
I0529 00:36:34.821861 16530 sgd_solver.cpp:105] Iteration 6000, lr = 0.0097
I0529 00:38:29.335521 16530 solver.cpp:218] Iteration 6100 (0.873266 iter/s, 114.513s/100 iters), loss = 1.18265
I0529 00:38:29.335722 16530 solver.cpp:237]     Train net output #0: loss = 1.18265 (* 1 = 1.18265 loss)
I0529 00:38:29.335755 16530 sgd_solver.cpp:105] Iteration 6100, lr = 0.009695
I0529 00:40:23.879142 16530 solver.cpp:218] Iteration 6200 (0.873039 iter/s, 114.542s/100 iters), loss = 1.09055
I0529 00:40:23.879323 16530 solver.cpp:237]     Train net output #0: loss = 1.09055 (* 1 = 1.09055 loss)
I0529 00:40:23.879385 16530 sgd_solver.cpp:105] Iteration 6200, lr = 0.00969
I0529 00:41:16.709239 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:42:18.435534 16530 solver.cpp:218] Iteration 6300 (0.872942 iter/s, 114.555s/100 iters), loss = 1.1642
I0529 00:42:18.435659 16530 solver.cpp:237]     Train net output #0: loss = 1.1642 (* 1 = 1.1642 loss)
I0529 00:42:18.435673 16530 sgd_solver.cpp:105] Iteration 6300, lr = 0.009685
I0529 00:44:12.954344 16530 solver.cpp:218] Iteration 6400 (0.873228 iter/s, 114.518s/100 iters), loss = 1.11361
I0529 00:44:12.954566 16530 solver.cpp:237]     Train net output #0: loss = 1.11361 (* 1 = 1.11361 loss)
I0529 00:44:12.954593 16530 sgd_solver.cpp:105] Iteration 6400, lr = 0.00968
I0529 00:46:07.484441 16530 solver.cpp:218] Iteration 6500 (0.873142 iter/s, 114.529s/100 iters), loss = 1.23843
I0529 00:46:07.484647 16530 solver.cpp:237]     Train net output #0: loss = 1.23843 (* 1 = 1.23843 loss)
I0529 00:46:07.484673 16530 sgd_solver.cpp:105] Iteration 6500, lr = 0.009675
I0529 00:48:01.999151 16530 solver.cpp:218] Iteration 6600 (0.87326 iter/s, 114.513s/100 iters), loss = 1.15083
I0529 00:48:01.999397 16530 solver.cpp:237]     Train net output #0: loss = 1.15083 (* 1 = 1.15083 loss)
I0529 00:48:01.999421 16530 sgd_solver.cpp:105] Iteration 6600, lr = 0.00967
I0529 00:49:56.488488 16530 solver.cpp:218] Iteration 6700 (0.873454 iter/s, 114.488s/100 iters), loss = 1.16867
I0529 00:49:56.488692 16530 solver.cpp:237]     Train net output #0: loss = 1.16867 (* 1 = 1.16867 loss)
I0529 00:49:56.488713 16530 sgd_solver.cpp:105] Iteration 6700, lr = 0.009665
I0529 00:51:50.931035 16530 solver.cpp:218] Iteration 6800 (0.87381 iter/s, 114.441s/100 iters), loss = 1.1871
I0529 00:51:50.931210 16530 solver.cpp:237]     Train net output #0: loss = 1.1871 (* 1 = 1.1871 loss)
I0529 00:51:50.931246 16530 sgd_solver.cpp:105] Iteration 6800, lr = 0.00966
I0529 00:53:45.398831 16530 solver.cpp:218] Iteration 6900 (0.873618 iter/s, 114.467s/100 iters), loss = 1.12221
I0529 00:53:45.399008 16530 solver.cpp:237]     Train net output #0: loss = 1.12221 (* 1 = 1.12221 loss)
I0529 00:53:45.399046 16530 sgd_solver.cpp:105] Iteration 6900, lr = 0.009655
I0529 00:55:38.723078 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_7000.caffemodel
I0529 00:55:39.046149 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_7000.solverstate
I0529 00:55:39.151758 16530 solver.cpp:330] Iteration 7000, Testing net (#0)
I0529 00:56:18.052016 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:57:24.097276 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:58:30.253489 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:58:32.898669 16530 solver.cpp:397]     Test net output #0: accuracy = 0.456036
I0529 00:58:32.898738 16530 solver.cpp:397]     Test net output #1: loss = 1.28924 (* 1 = 1.28924 loss)
I0529 00:58:34.035265 16530 solver.cpp:218] Iteration 7000 (0.34646 iter/s, 288.634s/100 iters), loss = 1.28918
I0529 00:58:34.035338 16530 solver.cpp:237]     Train net output #0: loss = 1.28918 (* 1 = 1.28918 loss)
I0529 00:58:34.035351 16530 sgd_solver.cpp:105] Iteration 7000, lr = 0.00965
I0529 00:59:05.098515 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:00:28.446106 16530 solver.cpp:218] Iteration 7100 (0.874052 iter/s, 114.41s/100 iters), loss = 1.24916
I0529 01:00:28.446321 16530 solver.cpp:237]     Train net output #0: loss = 1.24916 (* 1 = 1.24916 loss)
I0529 01:00:28.446352 16530 sgd_solver.cpp:105] Iteration 7100, lr = 0.009645
I0529 01:02:22.893327 16530 solver.cpp:218] Iteration 7200 (0.873775 iter/s, 114.446s/100 iters), loss = 1.1998
I0529 01:02:22.893507 16530 solver.cpp:237]     Train net output #0: loss = 1.1998 (* 1 = 1.1998 loss)
I0529 01:02:22.893546 16530 sgd_solver.cpp:105] Iteration 7200, lr = 0.00964
I0529 01:04:17.329249 16530 solver.cpp:218] Iteration 7300 (0.873861 iter/s, 114.435s/100 iters), loss = 1.15747
I0529 01:04:17.329434 16530 solver.cpp:237]     Train net output #0: loss = 1.15747 (* 1 = 1.15747 loss)
I0529 01:04:17.329478 16530 sgd_solver.cpp:105] Iteration 7300, lr = 0.009635
I0529 01:06:11.791332 16530 solver.cpp:218] Iteration 7400 (0.873662 iter/s, 114.461s/100 iters), loss = 1.10591
I0529 01:06:11.791537 16530 solver.cpp:237]     Train net output #0: loss = 1.10591 (* 1 = 1.10591 loss)
I0529 01:06:11.791561 16530 sgd_solver.cpp:105] Iteration 7400, lr = 0.00963
I0529 01:08:06.260661 16530 solver.cpp:218] Iteration 7500 (0.873606 iter/s, 114.468s/100 iters), loss = 1.11625
I0529 01:08:06.260854 16530 solver.cpp:237]     Train net output #0: loss = 1.11625 (* 1 = 1.11625 loss)
I0529 01:08:06.260890 16530 sgd_solver.cpp:105] Iteration 7500, lr = 0.009625
I0529 01:10:00.710587 16530 solver.cpp:218] Iteration 7600 (0.873755 iter/s, 114.449s/100 iters), loss = 1.04696
I0529 01:10:00.710791 16530 solver.cpp:237]     Train net output #0: loss = 1.04696 (* 1 = 1.04696 loss)
I0529 01:10:00.710831 16530 sgd_solver.cpp:105] Iteration 7600, lr = 0.00962
I0529 01:11:55.163310 16530 solver.cpp:218] Iteration 7700 (0.873733 iter/s, 114.451s/100 iters), loss = 1.25826
I0529 01:11:55.163589 16530 solver.cpp:237]     Train net output #0: loss = 1.25826 (* 1 = 1.25826 loss)
I0529 01:11:55.163616 16530 sgd_solver.cpp:105] Iteration 7700, lr = 0.009615
I0529 01:13:49.671190 16530 solver.cpp:218] Iteration 7800 (0.873313 iter/s, 114.507s/100 iters), loss = 1.14742
I0529 01:13:49.671402 16530 solver.cpp:237]     Train net output #0: loss = 1.14742 (* 1 = 1.14742 loss)
I0529 01:13:49.671417 16530 sgd_solver.cpp:105] Iteration 7800, lr = 0.00961
I0529 01:13:58.993579 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:15:44.143889 16530 solver.cpp:218] Iteration 7900 (0.873581 iter/s, 114.471s/100 iters), loss = 1.05483
I0529 01:15:44.144078 16530 solver.cpp:237]     Train net output #0: loss = 1.05483 (* 1 = 1.05483 loss)
I0529 01:15:44.144091 16530 sgd_solver.cpp:105] Iteration 7900, lr = 0.009605
I0529 01:17:37.444352 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_8000.caffemodel
I0529 01:17:38.166337 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_8000.solverstate
I0529 01:17:38.287669 16530 solver.cpp:330] Iteration 8000, Testing net (#0)
I0529 01:18:41.695631 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:19:47.869122 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:20:32.093039 16530 solver.cpp:397]     Test net output #0: accuracy = 0.493069
I0529 01:20:32.093209 16530 solver.cpp:397]     Test net output #1: loss = 1.37226 (* 1 = 1.37226 loss)
I0529 01:20:33.230098 16530 solver.cpp:218] Iteration 8000 (0.345921 iter/s, 289.083s/100 iters), loss = 0.966467
I0529 01:20:33.230182 16530 solver.cpp:237]     Train net output #0: loss = 0.966467 (* 1 = 0.966467 loss)
I0529 01:20:33.230196 16530 sgd_solver.cpp:105] Iteration 8000, lr = 0.0096
I0529 01:22:27.672386 16530 solver.cpp:218] Iteration 8100 (0.873812 iter/s, 114.441s/100 iters), loss = 1.0925
I0529 01:22:27.672601 16530 solver.cpp:237]     Train net output #0: loss = 1.0925 (* 1 = 1.0925 loss)
I0529 01:22:27.672627 16530 sgd_solver.cpp:105] Iteration 8100, lr = 0.009595
I0529 01:24:22.143036 16530 solver.cpp:218] Iteration 8200 (0.873596 iter/s, 114.469s/100 iters), loss = 1.06762
I0529 01:24:22.143281 16530 solver.cpp:237]     Train net output #0: loss = 1.06762 (* 1 = 1.06762 loss)
I0529 01:24:22.143316 16530 sgd_solver.cpp:105] Iteration 8200, lr = 0.00959
I0529 01:26:16.589783 16530 solver.cpp:218] Iteration 8300 (0.873779 iter/s, 114.445s/100 iters), loss = 1.30916
I0529 01:26:16.589988 16530 solver.cpp:237]     Train net output #0: loss = 1.30916 (* 1 = 1.30916 loss)
I0529 01:26:16.590026 16530 sgd_solver.cpp:105] Iteration 8300, lr = 0.009585
I0529 01:28:11.012557 16530 solver.cpp:218] Iteration 8400 (0.873962 iter/s, 114.421s/100 iters), loss = 1.14681
I0529 01:28:11.012715 16530 solver.cpp:237]     Train net output #0: loss = 1.14681 (* 1 = 1.14681 loss)
I0529 01:28:11.012728 16530 sgd_solver.cpp:105] Iteration 8400, lr = 0.00958
I0529 01:30:05.416606 16530 solver.cpp:218] Iteration 8500 (0.874104 iter/s, 114.403s/100 iters), loss = 1.13648
I0529 01:30:05.416785 16530 solver.cpp:237]     Train net output #0: loss = 1.13648 (* 1 = 1.13648 loss)
I0529 01:30:05.416800 16530 sgd_solver.cpp:105] Iteration 8500, lr = 0.009575
I0529 01:31:48.548874 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:31:59.842633 16530 solver.cpp:218] Iteration 8600 (0.873937 iter/s, 114.425s/100 iters), loss = 1.09602
I0529 01:31:59.842702 16530 solver.cpp:237]     Train net output #0: loss = 1.09602 (* 1 = 1.09602 loss)
I0529 01:31:59.842715 16530 sgd_solver.cpp:105] Iteration 8600, lr = 0.00957
I0529 01:33:54.216300 16530 solver.cpp:218] Iteration 8700 (0.874336 iter/s, 114.373s/100 iters), loss = 1.3023
I0529 01:33:54.216496 16530 solver.cpp:237]     Train net output #0: loss = 1.3023 (* 1 = 1.3023 loss)
I0529 01:33:54.216528 16530 sgd_solver.cpp:105] Iteration 8700, lr = 0.009565
I0529 01:35:48.563060 16530 solver.cpp:218] Iteration 8800 (0.874542 iter/s, 114.346s/100 iters), loss = 1.05672
I0529 01:35:48.563421 16530 solver.cpp:237]     Train net output #0: loss = 1.05672 (* 1 = 1.05672 loss)
I0529 01:35:48.563436 16530 sgd_solver.cpp:105] Iteration 8800, lr = 0.00956
I0529 01:37:42.927621 16530 solver.cpp:218] Iteration 8900 (0.874406 iter/s, 114.363s/100 iters), loss = 1.41063
I0529 01:37:42.927788 16530 solver.cpp:237]     Train net output #0: loss = 1.41063 (* 1 = 1.41063 loss)
I0529 01:37:42.927803 16530 sgd_solver.cpp:105] Iteration 8900, lr = 0.009555
I0529 01:39:36.146692 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_9000.caffemodel
I0529 01:39:36.462234 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_9000.solverstate
I0529 01:39:36.568886 16530 solver.cpp:330] Iteration 9000, Testing net (#0)
I0529 01:39:58.386886 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:41:04.301296 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:42:10.328585 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:42:30.003777 16530 solver.cpp:397]     Test net output #0: accuracy = 0.514914
I0529 01:42:30.003855 16530 solver.cpp:397]     Test net output #1: loss = 1.20103 (* 1 = 1.20103 loss)
I0529 01:42:31.137349 16530 solver.cpp:218] Iteration 9000 (0.346973 iter/s, 288.207s/100 iters), loss = 1.2028
I0529 01:42:31.137424 16530 solver.cpp:237]     Train net output #0: loss = 1.2028 (* 1 = 1.2028 loss)
I0529 01:42:31.137439 16530 sgd_solver.cpp:105] Iteration 9000, lr = 0.00955
I0529 01:44:25.405213 16530 solver.cpp:218] Iteration 9100 (0.875146 iter/s, 114.267s/100 iters), loss = 1.11709
I0529 01:44:25.405400 16530 solver.cpp:237]     Train net output #0: loss = 1.11709 (* 1 = 1.11709 loss)
I0529 01:44:25.405448 16530 sgd_solver.cpp:105] Iteration 9100, lr = 0.009545
I0529 01:46:19.721921 16530 solver.cpp:218] Iteration 9200 (0.874773 iter/s, 114.315s/100 iters), loss = 0.938736
I0529 01:46:19.722154 16530 solver.cpp:237]     Train net output #0: loss = 0.938736 (* 1 = 0.938736 loss)
I0529 01:46:19.722172 16530 sgd_solver.cpp:105] Iteration 9200, lr = 0.00954
I0529 01:48:14.014974 16530 solver.cpp:218] Iteration 9300 (0.874954 iter/s, 114.292s/100 iters), loss = 1.03102
I0529 01:48:14.015264 16530 solver.cpp:237]     Train net output #0: loss = 1.03102 (* 1 = 1.03102 loss)
I0529 01:48:14.015278 16530 sgd_solver.cpp:105] Iteration 9300, lr = 0.009535
I0529 01:49:35.337883 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:50:08.350869 16530 solver.cpp:218] Iteration 9400 (0.874627 iter/s, 114.335s/100 iters), loss = 1.02799
I0529 01:50:08.351030 16530 solver.cpp:237]     Train net output #0: loss = 1.02799 (* 1 = 1.02799 loss)
I0529 01:50:08.351054 16530 sgd_solver.cpp:105] Iteration 9400, lr = 0.00953
I0529 01:52:02.695293 16530 solver.cpp:218] Iteration 9500 (0.87456 iter/s, 114.343s/100 iters), loss = 1.203
I0529 01:52:02.695494 16530 solver.cpp:237]     Train net output #0: loss = 1.203 (* 1 = 1.203 loss)
I0529 01:52:02.695531 16530 sgd_solver.cpp:105] Iteration 9500, lr = 0.009525
I0529 01:53:57.089094 16530 solver.cpp:218] Iteration 9600 (0.874183 iter/s, 114.392s/100 iters), loss = 1.2118
I0529 01:53:57.089288 16530 solver.cpp:237]     Train net output #0: loss = 1.2118 (* 1 = 1.2118 loss)
I0529 01:53:57.089324 16530 sgd_solver.cpp:105] Iteration 9600, lr = 0.00952
I0529 01:55:51.477816 16530 solver.cpp:218] Iteration 9700 (0.874222 iter/s, 114.387s/100 iters), loss = 1.07003
I0529 01:55:51.478022 16530 solver.cpp:237]     Train net output #0: loss = 1.07003 (* 1 = 1.07003 loss)
I0529 01:55:51.478058 16530 sgd_solver.cpp:105] Iteration 9700, lr = 0.009515
I0529 01:57:45.893246 16530 solver.cpp:218] Iteration 9800 (0.874018 iter/s, 114.414s/100 iters), loss = 1.03653
I0529 01:57:45.893424 16530 solver.cpp:237]     Train net output #0: loss = 1.03653 (* 1 = 1.03653 loss)
I0529 01:57:45.893440 16530 sgd_solver.cpp:105] Iteration 9800, lr = 0.00951
I0529 01:59:40.316386 16530 solver.cpp:218] Iteration 9900 (0.873959 iter/s, 114.422s/100 iters), loss = 1.09684
I0529 01:59:40.316617 16530 solver.cpp:237]     Train net output #0: loss = 1.09684 (* 1 = 1.09684 loss)
I0529 01:59:40.316648 16530 sgd_solver.cpp:105] Iteration 9900, lr = 0.009505
I0529 02:01:33.606547 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_10000.caffemodel
I0529 02:01:33.920825 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_10000.solverstate
I0529 02:01:34.030282 16530 solver.cpp:330] Iteration 10000, Testing net (#0)
I0529 02:02:20.330703 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:03:26.331264 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:04:27.644600 16530 solver.cpp:397]     Test net output #0: accuracy = 0.428894
I0529 02:04:27.644789 16530 solver.cpp:397]     Test net output #1: loss = 1.41061 (* 1 = 1.41061 loss)
I0529 02:04:28.780740 16530 solver.cpp:218] Iteration 10000 (0.346667 iter/s, 288.461s/100 iters), loss = 1.05711
I0529 02:04:28.780819 16530 solver.cpp:237]     Train net output #0: loss = 1.05711 (* 1 = 1.05711 loss)
I0529 02:04:28.780834 16530 sgd_solver.cpp:105] Iteration 10000, lr = 0.0095
I0529 02:06:23.203622 16530 solver.cpp:218] Iteration 10100 (0.87396 iter/s, 114.422s/100 iters), loss = 0.872826
I0529 02:06:23.203843 16530 solver.cpp:237]     Train net output #0: loss = 0.872826 (* 1 = 0.872826 loss)
I0529 02:06:23.203857 16530 sgd_solver.cpp:105] Iteration 10100, lr = 0.009495
I0529 02:07:22.825989 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:08:17.562530 16530 solver.cpp:218] Iteration 10200 (0.87445 iter/s, 114.358s/100 iters), loss = 1.06867
I0529 02:08:17.562674 16530 solver.cpp:237]     Train net output #0: loss = 1.06867 (* 1 = 1.06867 loss)
I0529 02:08:17.562687 16530 sgd_solver.cpp:105] Iteration 10200, lr = 0.00949
I0529 02:10:11.939563 16530 solver.cpp:218] Iteration 10300 (0.874311 iter/s, 114.376s/100 iters), loss = 1.2652
I0529 02:10:11.939752 16530 solver.cpp:237]     Train net output #0: loss = 1.2652 (* 1 = 1.2652 loss)
I0529 02:10:11.939780 16530 sgd_solver.cpp:105] Iteration 10300, lr = 0.009485
I0529 02:12:06.303464 16530 solver.cpp:218] Iteration 10400 (0.874412 iter/s, 114.363s/100 iters), loss = 1.16986
I0529 02:12:06.303654 16530 solver.cpp:237]     Train net output #0: loss = 1.16986 (* 1 = 1.16986 loss)
I0529 02:12:06.303694 16530 sgd_solver.cpp:105] Iteration 10400, lr = 0.00948
I0529 02:14:00.719995 16530 solver.cpp:218] Iteration 10500 (0.874009 iter/s, 114.415s/100 iters), loss = 0.95208
I0529 02:14:00.720404 16530 solver.cpp:237]     Train net output #0: loss = 0.95208 (* 1 = 0.95208 loss)
I0529 02:14:00.720435 16530 sgd_solver.cpp:105] Iteration 10500, lr = 0.009475
I0529 02:15:55.113926 16530 solver.cpp:218] Iteration 10600 (0.874184 iter/s, 114.392s/100 iters), loss = 1.08559
I0529 02:15:55.114105 16530 solver.cpp:237]     Train net output #0: loss = 1.08559 (* 1 = 1.08559 loss)
I0529 02:15:55.114126 16530 sgd_solver.cpp:105] Iteration 10600, lr = 0.00947
I0529 02:17:49.464785 16530 solver.cpp:218] Iteration 10700 (0.874511 iter/s, 114.35s/100 iters), loss = 1.04404
I0529 02:17:49.464927 16530 solver.cpp:237]     Train net output #0: loss = 1.04404 (* 1 = 1.04404 loss)
I0529 02:17:49.464941 16530 sgd_solver.cpp:105] Iteration 10700, lr = 0.009465
I0529 02:19:43.800493 16530 solver.cpp:218] Iteration 10800 (0.874627 iter/s, 114.335s/100 iters), loss = 1.03023
I0529 02:19:43.800693 16530 solver.cpp:237]     Train net output #0: loss = 1.03023 (* 1 = 1.03023 loss)
I0529 02:19:43.800730 16530 sgd_solver.cpp:105] Iteration 10800, lr = 0.00946
I0529 02:21:38.141005 16530 solver.cpp:218] Iteration 10900 (0.87459 iter/s, 114.339s/100 iters), loss = 1.11113
I0529 02:21:38.141237 16530 solver.cpp:237]     Train net output #0: loss = 1.11113 (* 1 = 1.11113 loss)
I0529 02:21:38.141269 16530 sgd_solver.cpp:105] Iteration 10900, lr = 0.009455
I0529 02:22:16.036670 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:23:31.320567 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_11000.caffemodel
I0529 02:23:31.685372 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_11000.solverstate
I0529 02:23:31.794313 16530 solver.cpp:330] Iteration 11000, Testing net (#0)
I0529 02:23:36.597787 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:24:42.518872 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:25:48.418166 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:26:25.206614 16530 solver.cpp:397]     Test net output #0: accuracy = 0.498676
I0529 02:26:25.206776 16530 solver.cpp:397]     Test net output #1: loss = 1.22247 (* 1 = 1.22247 loss)
I0529 02:26:26.344033 16530 solver.cpp:218] Iteration 11000 (0.346981 iter/s, 288.2s/100 iters), loss = 0.938189
I0529 02:26:26.344111 16530 solver.cpp:237]     Train net output #0: loss = 0.938189 (* 1 = 0.938189 loss)
I0529 02:26:26.344133 16530 sgd_solver.cpp:105] Iteration 11000, lr = 0.00945
I0529 02:28:20.624778 16530 solver.cpp:218] Iteration 11100 (0.875046 iter/s, 114.28s/100 iters), loss = 1.2627
I0529 02:28:20.624945 16530 solver.cpp:237]     Train net output #0: loss = 1.2627 (* 1 = 1.2627 loss)
I0529 02:28:20.624969 16530 sgd_solver.cpp:105] Iteration 11100, lr = 0.009445
I0529 02:30:14.915637 16530 solver.cpp:218] Iteration 11200 (0.874969 iter/s, 114.29s/100 iters), loss = 1.15069
I0529 02:30:14.915825 16530 solver.cpp:237]     Train net output #0: loss = 1.15069 (* 1 = 1.15069 loss)
I0529 02:30:14.915838 16530 sgd_solver.cpp:105] Iteration 11200, lr = 0.00944
I0529 02:32:09.195490 16530 solver.cpp:218] Iteration 11300 (0.875054 iter/s, 114.279s/100 iters), loss = 1.0361
I0529 02:32:09.195718 16530 solver.cpp:237]     Train net output #0: loss = 1.0361 (* 1 = 1.0361 loss)
I0529 02:32:09.195754 16530 sgd_solver.cpp:105] Iteration 11300, lr = 0.009435
I0529 02:34:03.497480 16530 solver.cpp:218] Iteration 11400 (0.874884 iter/s, 114.301s/100 iters), loss = 1.07421
I0529 02:34:03.497684 16530 solver.cpp:237]     Train net output #0: loss = 1.07421 (* 1 = 1.07421 loss)
I0529 02:34:03.497697 16530 sgd_solver.cpp:105] Iteration 11400, lr = 0.00943
I0529 02:35:57.854248 16530 solver.cpp:218] Iteration 11500 (0.874465 iter/s, 114.356s/100 iters), loss = 1.033
I0529 02:35:57.854457 16530 solver.cpp:237]     Train net output #0: loss = 1.033 (* 1 = 1.033 loss)
I0529 02:35:57.854482 16530 sgd_solver.cpp:105] Iteration 11500, lr = 0.009425
I0529 02:37:52.190062 16530 solver.cpp:218] Iteration 11600 (0.874626 iter/s, 114.335s/100 iters), loss = 1.00861
I0529 02:37:52.190284 16530 solver.cpp:237]     Train net output #0: loss = 1.00861 (* 1 = 1.00861 loss)
I0529 02:37:52.190296 16530 sgd_solver.cpp:105] Iteration 11600, lr = 0.00942
I0529 02:39:46.493921 16530 solver.cpp:218] Iteration 11700 (0.87487 iter/s, 114.303s/100 iters), loss = 0.920882
I0529 02:39:46.494158 16530 solver.cpp:237]     Train net output #0: loss = 0.920882 (* 1 = 0.920882 loss)
I0529 02:39:46.494187 16530 sgd_solver.cpp:105] Iteration 11700, lr = 0.009415
I0529 02:40:03.785133 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:41:40.827179 16530 solver.cpp:218] Iteration 11800 (0.874645 iter/s, 114.332s/100 iters), loss = 1.24952
I0529 02:41:40.827415 16530 solver.cpp:237]     Train net output #0: loss = 1.24952 (* 1 = 1.24952 loss)
I0529 02:41:40.827440 16530 sgd_solver.cpp:105] Iteration 11800, lr = 0.00941
I0529 02:43:35.139516 16530 solver.cpp:218] Iteration 11900 (0.874805 iter/s, 114.311s/100 iters), loss = 1.04863
I0529 02:43:35.139688 16530 solver.cpp:237]     Train net output #0: loss = 1.04863 (* 1 = 1.04863 loss)
I0529 02:43:35.139734 16530 sgd_solver.cpp:105] Iteration 11900, lr = 0.009405
I0529 02:45:28.348500 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_12000.caffemodel
I0529 02:45:29.038380 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_12000.solverstate
I0529 02:45:29.153667 16530 solver.cpp:330] Iteration 12000, Testing net (#0)
I0529 02:45:58.388674 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:47:04.316390 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:48:10.224447 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:48:22.571683 16530 solver.cpp:397]     Test net output #0: accuracy = 0.486449
I0529 02:48:22.571760 16530 solver.cpp:397]     Test net output #1: loss = 1.29704 (* 1 = 1.29704 loss)
I0529 02:48:23.706933 16530 solver.cpp:218] Iteration 12000 (0.346543 iter/s, 288.565s/100 iters), loss = 1.05417
I0529 02:48:23.707010 16530 solver.cpp:237]     Train net output #0: loss = 1.05417 (* 1 = 1.05417 loss)
I0529 02:48:23.707023 16530 sgd_solver.cpp:105] Iteration 12000, lr = 0.0094
I0529 02:50:18.074295 16530 solver.cpp:218] Iteration 12100 (0.874384 iter/s, 114.366s/100 iters), loss = 1.11938
I0529 02:50:18.074493 16530 solver.cpp:237]     Train net output #0: loss = 1.11938 (* 1 = 1.11938 loss)
I0529 02:50:18.074523 16530 sgd_solver.cpp:105] Iteration 12100, lr = 0.009395
I0529 02:52:12.453737 16530 solver.cpp:218] Iteration 12200 (0.874292 iter/s, 114.378s/100 iters), loss = 1.11344
I0529 02:52:12.453938 16530 solver.cpp:237]     Train net output #0: loss = 1.11344 (* 1 = 1.11344 loss)
I0529 02:52:12.453965 16530 sgd_solver.cpp:105] Iteration 12200, lr = 0.00939
I0529 02:54:06.849274 16530 solver.cpp:218] Iteration 12300 (0.874169 iter/s, 114.394s/100 iters), loss = 0.860461
I0529 02:54:06.849457 16530 solver.cpp:237]     Train net output #0: loss = 0.860461 (* 1 = 0.860461 loss)
I0529 02:54:06.849483 16530 sgd_solver.cpp:105] Iteration 12300, lr = 0.009385
I0529 02:56:01.217974 16530 solver.cpp:218] Iteration 12400 (0.874374 iter/s, 114.368s/100 iters), loss = 0.849813
I0529 02:56:01.218462 16530 solver.cpp:237]     Train net output #0: loss = 0.849813 (* 1 = 0.849813 loss)
I0529 02:56:01.218477 16530 sgd_solver.cpp:105] Iteration 12400, lr = 0.00938
I0529 02:57:51.221918 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:57:55.645874 16530 solver.cpp:218] Iteration 12500 (0.873924 iter/s, 114.426s/100 iters), loss = 1.13676
I0529 02:57:55.645946 16530 solver.cpp:237]     Train net output #0: loss = 1.13676 (* 1 = 1.13676 loss)
I0529 02:57:55.645957 16530 sgd_solver.cpp:105] Iteration 12500, lr = 0.009375
I0529 02:59:50.068312 16530 solver.cpp:218] Iteration 12600 (0.873963 iter/s, 114.421s/100 iters), loss = 0.886698
I0529 02:59:50.068512 16530 solver.cpp:237]     Train net output #0: loss = 0.886698 (* 1 = 0.886698 loss)
I0529 02:59:50.068533 16530 sgd_solver.cpp:105] Iteration 12600, lr = 0.00937
I0529 03:01:44.461978 16530 solver.cpp:218] Iteration 12700 (0.874184 iter/s, 114.392s/100 iters), loss = 0.964674
I0529 03:01:44.462206 16530 solver.cpp:237]     Train net output #0: loss = 0.964674 (* 1 = 0.964674 loss)
I0529 03:01:44.462222 16530 sgd_solver.cpp:105] Iteration 12700, lr = 0.009365
I0529 03:03:38.856161 16530 solver.cpp:218] Iteration 12800 (0.87418 iter/s, 114.393s/100 iters), loss = 1.11931
I0529 03:03:38.856340 16530 solver.cpp:237]     Train net output #0: loss = 1.11931 (* 1 = 1.11931 loss)
I0529 03:03:38.856372 16530 sgd_solver.cpp:105] Iteration 12800, lr = 0.00936
I0529 03:05:33.236464 16530 solver.cpp:218] Iteration 12900 (0.874286 iter/s, 114.379s/100 iters), loss = 0.937117
I0529 03:05:33.236650 16530 solver.cpp:237]     Train net output #0: loss = 0.937117 (* 1 = 0.937117 loss)
I0529 03:05:33.236686 16530 sgd_solver.cpp:105] Iteration 12900, lr = 0.009355
I0529 03:07:26.514849 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_13000.caffemodel
I0529 03:07:27.156071 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_13000.solverstate
I0529 03:07:27.266978 16530 solver.cpp:330] Iteration 13000, Testing net (#0)
I0529 03:08:20.995867 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:09:27.005233 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:10:20.866817 16530 solver.cpp:397]     Test net output #0: accuracy = 0.51581
I0529 03:10:20.867013 16530 solver.cpp:397]     Test net output #1: loss = 1.20064 (* 1 = 1.20064 loss)
I0529 03:10:22.003542 16530 solver.cpp:218] Iteration 13000 (0.346303 iter/s, 288.764s/100 iters), loss = 0.896996
I0529 03:10:22.003623 16530 solver.cpp:237]     Train net output #0: loss = 0.896996 (* 1 = 0.896996 loss)
I0529 03:10:22.003638 16530 sgd_solver.cpp:105] Iteration 13000, lr = 0.00935
I0529 03:12:16.386855 16530 solver.cpp:218] Iteration 13100 (0.874262 iter/s, 114.382s/100 iters), loss = 1.09429
I0529 03:12:16.387063 16530 solver.cpp:237]     Train net output #0: loss = 1.09429 (* 1 = 1.09429 loss)
I0529 03:12:16.387086 16530 sgd_solver.cpp:105] Iteration 13100, lr = 0.009345
I0529 03:14:10.769738 16530 solver.cpp:218] Iteration 13200 (0.874267 iter/s, 114.382s/100 iters), loss = 1.05064
I0529 03:14:10.769914 16530 solver.cpp:237]     Train net output #0: loss = 1.05064 (* 1 = 1.05064 loss)
I0529 03:14:10.769928 16530 sgd_solver.cpp:105] Iteration 13200, lr = 0.00934
I0529 03:15:38.993453 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:16:05.119230 16530 solver.cpp:218] Iteration 13300 (0.874522 iter/s, 114.348s/100 iters), loss = 0.966798
I0529 03:16:05.119318 16530 solver.cpp:237]     Train net output #0: loss = 0.966798 (* 1 = 0.966798 loss)
I0529 03:16:05.119330 16530 sgd_solver.cpp:105] Iteration 13300, lr = 0.009335
I0529 03:17:59.474489 16530 solver.cpp:218] Iteration 13400 (0.874477 iter/s, 114.354s/100 iters), loss = 1.00184
I0529 03:17:59.474686 16530 solver.cpp:237]     Train net output #0: loss = 1.00184 (* 1 = 1.00184 loss)
I0529 03:17:59.474712 16530 sgd_solver.cpp:105] Iteration 13400, lr = 0.00933
I0529 03:19:53.809635 16530 solver.cpp:218] Iteration 13500 (0.874632 iter/s, 114.334s/100 iters), loss = 0.962868
I0529 03:19:53.809805 16530 solver.cpp:237]     Train net output #0: loss = 0.962868 (* 1 = 0.962868 loss)
I0529 03:19:53.809844 16530 sgd_solver.cpp:105] Iteration 13500, lr = 0.009325
I0529 03:21:48.114787 16530 solver.cpp:218] Iteration 13600 (0.874861 iter/s, 114.304s/100 iters), loss = 0.987798
I0529 03:21:48.114989 16530 solver.cpp:237]     Train net output #0: loss = 0.987798 (* 1 = 0.987798 loss)
I0529 03:21:48.115031 16530 sgd_solver.cpp:105] Iteration 13600, lr = 0.00932
I0529 03:23:42.433534 16530 solver.cpp:218] Iteration 13700 (0.874757 iter/s, 114.317s/100 iters), loss = 0.960546
I0529 03:23:42.433758 16530 solver.cpp:237]     Train net output #0: loss = 0.960546 (* 1 = 0.960546 loss)
I0529 03:23:42.433773 16530 sgd_solver.cpp:105] Iteration 13700, lr = 0.009315
I0529 03:25:36.755813 16530 solver.cpp:218] Iteration 13800 (0.87473 iter/s, 114.321s/100 iters), loss = 0.916197
I0529 03:25:36.755965 16530 solver.cpp:237]     Train net output #0: loss = 0.916197 (* 1 = 0.916197 loss)
I0529 03:25:36.755977 16530 sgd_solver.cpp:105] Iteration 13800, lr = 0.00931
I0529 03:27:31.065083 16530 solver.cpp:218] Iteration 13900 (0.874829 iter/s, 114.308s/100 iters), loss = 0.916391
I0529 03:27:31.065280 16530 solver.cpp:237]     Train net output #0: loss = 0.916391 (* 1 = 0.916391 loss)
I0529 03:27:31.065299 16530 sgd_solver.cpp:105] Iteration 13900, lr = 0.009305
I0529 03:29:24.220525 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_14000.caffemodel
I0529 03:29:24.763615 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_14000.solverstate
I0529 03:29:24.880836 16530 solver.cpp:330] Iteration 14000, Testing net (#0)
I0529 03:29:36.984014 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:30:42.993131 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:31:48.950168 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:32:18.322517 16530 solver.cpp:397]     Test net output #0: accuracy = 0.429011
I0529 03:32:18.322594 16530 solver.cpp:397]     Test net output #1: loss = 1.40615 (* 1 = 1.40615 loss)
I0529 03:32:19.457137 16530 solver.cpp:218] Iteration 14000 (0.346754 iter/s, 288.389s/100 iters), loss = 0.999229
I0529 03:32:19.457396 16530 solver.cpp:237]     Train net output #0: loss = 0.999229 (* 1 = 0.999229 loss)
I0529 03:32:19.457422 16530 sgd_solver.cpp:105] Iteration 14000, lr = 0.0093
I0529 03:33:27.041350 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:34:13.782557 16530 solver.cpp:218] Iteration 14100 (0.874706 iter/s, 114.324s/100 iters), loss = 1.04834
I0529 03:34:13.782784 16530 solver.cpp:237]     Train net output #0: loss = 1.04834 (* 1 = 1.04834 loss)
I0529 03:34:13.782797 16530 sgd_solver.cpp:105] Iteration 14100, lr = 0.009295
I0529 03:36:08.096179 16530 solver.cpp:218] Iteration 14200 (0.874796 iter/s, 114.312s/100 iters), loss = 0.898733
I0529 03:36:08.096460 16530 solver.cpp:237]     Train net output #0: loss = 0.898733 (* 1 = 0.898733 loss)
I0529 03:36:08.096491 16530 sgd_solver.cpp:105] Iteration 14200, lr = 0.00929
I0529 03:38:02.456593 16530 solver.cpp:218] Iteration 14300 (0.874437 iter/s, 114.359s/100 iters), loss = 1.07095
I0529 03:38:02.456795 16530 solver.cpp:237]     Train net output #0: loss = 1.07095 (* 1 = 1.07095 loss)
I0529 03:38:02.456810 16530 sgd_solver.cpp:105] Iteration 14300, lr = 0.009285
I0529 03:39:56.781514 16530 solver.cpp:218] Iteration 14400 (0.874708 iter/s, 114.324s/100 iters), loss = 1.00418
I0529 03:39:56.781708 16530 solver.cpp:237]     Train net output #0: loss = 1.00418 (* 1 = 1.00418 loss)
I0529 03:39:56.781736 16530 sgd_solver.cpp:105] Iteration 14400, lr = 0.00928
I0529 03:41:51.154356 16530 solver.cpp:218] Iteration 14500 (0.874341 iter/s, 114.372s/100 iters), loss = 0.898987
I0529 03:41:51.154542 16530 solver.cpp:237]     Train net output #0: loss = 0.898987 (* 1 = 0.898987 loss)
I0529 03:41:51.154554 16530 sgd_solver.cpp:105] Iteration 14500, lr = 0.009275
I0529 03:43:45.531744 16530 solver.cpp:218] Iteration 14600 (0.874307 iter/s, 114.376s/100 iters), loss = 1.08037
I0529 03:43:45.531941 16530 solver.cpp:237]     Train net output #0: loss = 1.08037 (* 1 = 1.08037 loss)
I0529 03:43:45.531960 16530 sgd_solver.cpp:105] Iteration 14600, lr = 0.00927
I0529 03:45:39.945050 16530 solver.cpp:218] Iteration 14700 (0.874033 iter/s, 114.412s/100 iters), loss = 0.95305
I0529 03:45:39.945269 16530 solver.cpp:237]     Train net output #0: loss = 0.95305 (* 1 = 0.95305 loss)
I0529 03:45:39.945282 16530 sgd_solver.cpp:105] Iteration 14700, lr = 0.009265
I0529 03:47:34.386917 16530 solver.cpp:218] Iteration 14800 (0.873815 iter/s, 114.441s/100 iters), loss = 1.18189
I0529 03:47:34.387099 16530 solver.cpp:237]     Train net output #0: loss = 1.18189 (* 1 = 1.18189 loss)
I0529 03:47:34.387286 16530 sgd_solver.cpp:105] Iteration 14800, lr = 0.00926
I0529 03:48:20.313879 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:49:28.818958 16530 solver.cpp:218] Iteration 14900 (0.87389 iter/s, 114.431s/100 iters), loss = 0.928822
I0529 03:49:28.819191 16530 solver.cpp:237]     Train net output #0: loss = 0.928822 (* 1 = 0.928822 loss)
I0529 03:49:28.819216 16530 sgd_solver.cpp:105] Iteration 14900, lr = 0.009255
I0529 03:51:22.142391 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_15000.caffemodel
I0529 03:51:22.682359 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_15000.solverstate
I0529 03:51:22.790730 16530 solver.cpp:330] Iteration 15000, Testing net (#0)
I0529 03:51:59.381896 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:53:05.525437 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:54:11.550552 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:54:16.490404 16530 solver.cpp:397]     Test net output #0: accuracy = 0.512967
I0529 03:54:16.490478 16530 solver.cpp:397]     Test net output #1: loss = 1.20389 (* 1 = 1.20389 loss)
I0529 03:54:17.628000 16530 solver.cpp:218] Iteration 15000 (0.346253 iter/s, 288.806s/100 iters), loss = 0.96626
I0529 03:54:17.628077 16530 solver.cpp:237]     Train net output #0: loss = 0.96626 (* 1 = 0.96626 loss)
I0529 03:54:17.628092 16530 sgd_solver.cpp:105] Iteration 15000, lr = 0.00925
I0529 03:56:12.106107 16530 solver.cpp:218] Iteration 15100 (0.873538 iter/s, 114.477s/100 iters), loss = 1.03455
I0529 03:56:12.106376 16530 solver.cpp:237]     Train net output #0: loss = 1.03455 (* 1 = 1.03455 loss)
I0529 03:56:12.106401 16530 sgd_solver.cpp:105] Iteration 15100, lr = 0.009245
I0529 03:58:06.574473 16530 solver.cpp:218] Iteration 15200 (0.873613 iter/s, 114.467s/100 iters), loss = 1.08972
I0529 03:58:06.574688 16530 solver.cpp:237]     Train net output #0: loss = 1.08972 (* 1 = 1.08972 loss)
I0529 03:58:06.574700 16530 sgd_solver.cpp:105] Iteration 15200, lr = 0.00924
I0529 04:00:01.027330 16530 solver.cpp:218] Iteration 15300 (0.873731 iter/s, 114.452s/100 iters), loss = 0.927147
I0529 04:00:01.027495 16530 solver.cpp:237]     Train net output #0: loss = 0.927147 (* 1 = 0.927147 loss)
I0529 04:00:01.027518 16530 sgd_solver.cpp:105] Iteration 15300, lr = 0.009235
I0529 04:01:55.486971 16530 solver.cpp:218] Iteration 15400 (0.873679 iter/s, 114.458s/100 iters), loss = 1.16113
I0529 04:01:55.487177 16530 solver.cpp:237]     Train net output #0: loss = 1.16113 (* 1 = 1.16113 loss)
I0529 04:01:55.487203 16530 sgd_solver.cpp:105] Iteration 15400, lr = 0.00923
I0529 04:03:49.964854 16530 solver.cpp:218] Iteration 15500 (0.873541 iter/s, 114.477s/100 iters), loss = 0.865372
I0529 04:03:49.965070 16530 solver.cpp:237]     Train net output #0: loss = 0.865372 (* 1 = 0.865372 loss)
I0529 04:03:49.965134 16530 sgd_solver.cpp:105] Iteration 15500, lr = 0.009225
I0529 04:05:44.466357 16530 solver.cpp:218] Iteration 15600 (0.873361 iter/s, 114.5s/100 iters), loss = 0.952012
I0529 04:05:44.466531 16530 solver.cpp:237]     Train net output #0: loss = 0.952012 (* 1 = 0.952012 loss)
I0529 04:05:44.466547 16530 sgd_solver.cpp:105] Iteration 15600, lr = 0.00922
I0529 04:06:08.677948 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:07:38.971011 16530 solver.cpp:218] Iteration 15700 (0.873336 iter/s, 114.503s/100 iters), loss = 0.724126
I0529 04:07:38.971524 16530 solver.cpp:237]     Train net output #0: loss = 0.724126 (* 1 = 0.724126 loss)
I0529 04:07:38.971556 16530 sgd_solver.cpp:105] Iteration 15700, lr = 0.009215
I0529 04:09:33.442812 16530 solver.cpp:218] Iteration 15800 (0.873589 iter/s, 114.47s/100 iters), loss = 0.961095
I0529 04:09:33.443001 16530 solver.cpp:237]     Train net output #0: loss = 0.961095 (* 1 = 0.961095 loss)
I0529 04:09:33.443017 16530 sgd_solver.cpp:105] Iteration 15800, lr = 0.00921
I0529 04:11:27.929893 16530 solver.cpp:218] Iteration 15900 (0.87347 iter/s, 114.486s/100 iters), loss = 1.1824
I0529 04:11:27.930157 16530 solver.cpp:237]     Train net output #0: loss = 1.1824 (* 1 = 1.1824 loss)
I0529 04:11:27.930176 16530 sgd_solver.cpp:105] Iteration 15900, lr = 0.009205
I0529 04:13:21.266865 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_16000.caffemodel
I0529 04:13:21.621911 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_16000.solverstate
I0529 04:13:21.732700 16530 solver.cpp:330] Iteration 16000, Testing net (#0)
I0529 04:14:22.908695 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:15:28.915033 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:16:15.343930 16530 solver.cpp:397]     Test net output #0: accuracy = 0.50183
I0529 04:16:15.344151 16530 solver.cpp:397]     Test net output #1: loss = 1.22681 (* 1 = 1.22681 loss)
I0529 04:16:16.481148 16530 solver.cpp:218] Iteration 16000 (0.346562 iter/s, 288.548s/100 iters), loss = 0.882169
I0529 04:16:16.481218 16530 solver.cpp:237]     Train net output #0: loss = 0.882169 (* 1 = 0.882169 loss)
I0529 04:16:16.481231 16530 sgd_solver.cpp:105] Iteration 16000, lr = 0.0092
I0529 04:18:10.968475 16530 solver.cpp:218] Iteration 16100 (0.873468 iter/s, 114.486s/100 iters), loss = 1.13183
I0529 04:18:10.968690 16530 solver.cpp:237]     Train net output #0: loss = 1.13183 (* 1 = 1.13183 loss)
I0529 04:18:10.968717 16530 sgd_solver.cpp:105] Iteration 16100, lr = 0.009195
I0529 04:20:05.473528 16530 solver.cpp:218] Iteration 16200 (0.873334 iter/s, 114.504s/100 iters), loss = 0.906424
I0529 04:20:05.473711 16530 solver.cpp:237]     Train net output #0: loss = 0.906424 (* 1 = 0.906424 loss)
I0529 04:20:05.473726 16530 sgd_solver.cpp:105] Iteration 16200, lr = 0.00919
I0529 04:21:59.991453 16530 solver.cpp:218] Iteration 16300 (0.873235 iter/s, 114.517s/100 iters), loss = 0.955594
I0529 04:21:59.991670 16530 solver.cpp:237]     Train net output #0: loss = 0.955594 (* 1 = 0.955594 loss)
I0529 04:21:59.991683 16530 sgd_solver.cpp:105] Iteration 16300, lr = 0.009185
I0529 04:23:54.505931 16530 solver.cpp:218] Iteration 16400 (0.873262 iter/s, 114.513s/100 iters), loss = 0.873147
I0529 04:23:54.506132 16530 solver.cpp:237]     Train net output #0: loss = 0.873147 (* 1 = 0.873147 loss)
I0529 04:23:54.506192 16530 sgd_solver.cpp:105] Iteration 16400, lr = 0.00918
I0529 04:23:56.964570 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:25:49.003203 16530 solver.cpp:218] Iteration 16500 (0.873393 iter/s, 114.496s/100 iters), loss = 0.853302
I0529 04:25:49.003386 16530 solver.cpp:237]     Train net output #0: loss = 0.853302 (* 1 = 0.853302 loss)
I0529 04:25:49.003423 16530 sgd_solver.cpp:105] Iteration 16500, lr = 0.009175
I0529 04:27:43.488178 16530 solver.cpp:218] Iteration 16600 (0.873486 iter/s, 114.484s/100 iters), loss = 1.0406
I0529 04:27:43.488364 16530 solver.cpp:237]     Train net output #0: loss = 1.0406 (* 1 = 1.0406 loss)
I0529 04:27:43.488387 16530 sgd_solver.cpp:105] Iteration 16600, lr = 0.00917
I0529 04:29:38.021562 16530 solver.cpp:218] Iteration 16700 (0.873117 iter/s, 114.532s/100 iters), loss = 1.0815
I0529 04:29:38.021827 16530 solver.cpp:237]     Train net output #0: loss = 1.0815 (* 1 = 1.0815 loss)
I0529 04:29:38.021852 16530 sgd_solver.cpp:105] Iteration 16700, lr = 0.009165
I0529 04:31:32.549679 16530 solver.cpp:218] Iteration 16800 (0.873158 iter/s, 114.527s/100 iters), loss = 1.26226
I0529 04:31:32.549906 16530 solver.cpp:237]     Train net output #0: loss = 1.26226 (* 1 = 1.26226 loss)
I0529 04:31:32.549919 16530 sgd_solver.cpp:105] Iteration 16800, lr = 0.00916
I0529 04:33:27.015162 16530 solver.cpp:218] Iteration 16900 (0.873636 iter/s, 114.464s/100 iters), loss = 0.983036
I0529 04:33:27.015352 16530 solver.cpp:237]     Train net output #0: loss = 0.983036 (* 1 = 0.983036 loss)
I0529 04:33:27.015377 16530 sgd_solver.cpp:105] Iteration 16900, lr = 0.009155
I0529 04:35:20.354303 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_17000.caffemodel
I0529 04:35:20.683899 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_17000.solverstate
I0529 04:35:20.793285 16530 solver.cpp:330] Iteration 17000, Testing net (#0)
I0529 04:35:40.340842 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:36:46.487491 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:37:52.478449 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:38:14.447047 16530 solver.cpp:397]     Test net output #0: accuracy = 0.48162
I0529 04:38:14.447132 16530 solver.cpp:397]     Test net output #1: loss = 1.27689 (* 1 = 1.27689 loss)
I0529 04:38:15.583534 16530 solver.cpp:218] Iteration 17000 (0.346542 iter/s, 288.566s/100 iters), loss = 0.934308
I0529 04:38:15.583612 16530 solver.cpp:237]     Train net output #0: loss = 0.934308 (* 1 = 0.934308 loss)
I0529 04:38:15.583626 16530 sgd_solver.cpp:105] Iteration 17000, lr = 0.00915
I0529 04:40:10.032740 16530 solver.cpp:218] Iteration 17100 (0.873759 iter/s, 114.448s/100 iters), loss = 0.883022
I0529 04:40:10.032930 16530 solver.cpp:237]     Train net output #0: loss = 0.883022 (* 1 = 0.883022 loss)
I0529 04:40:10.032960 16530 sgd_solver.cpp:105] Iteration 17100, lr = 0.009145
I0529 04:41:46.300374 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:42:04.467559 16530 solver.cpp:218] Iteration 17200 (0.873869 iter/s, 114.434s/100 iters), loss = 0.952717
I0529 04:42:04.467639 16530 solver.cpp:237]     Train net output #0: loss = 0.952717 (* 1 = 0.952717 loss)
I0529 04:42:04.467667 16530 sgd_solver.cpp:105] Iteration 17200, lr = 0.00914
I0529 04:43:58.873100 16530 solver.cpp:218] Iteration 17300 (0.874092 iter/s, 114.404s/100 iters), loss = 0.987341
I0529 04:43:58.873297 16530 solver.cpp:237]     Train net output #0: loss = 0.987341 (* 1 = 0.987341 loss)
I0529 04:43:58.873334 16530 sgd_solver.cpp:105] Iteration 17300, lr = 0.009135
I0529 04:45:53.273933 16530 solver.cpp:218] Iteration 17400 (0.874129 iter/s, 114.4s/100 iters), loss = 1.19428
I0529 04:45:53.274127 16530 solver.cpp:237]     Train net output #0: loss = 1.19428 (* 1 = 1.19428 loss)
I0529 04:45:53.274142 16530 sgd_solver.cpp:105] Iteration 17400, lr = 0.00913
I0529 04:47:47.640357 16530 solver.cpp:218] Iteration 17500 (0.874391 iter/s, 114.365s/100 iters), loss = 1.07474
I0529 04:47:47.640632 16530 solver.cpp:237]     Train net output #0: loss = 1.07474 (* 1 = 1.07474 loss)
I0529 04:47:47.640645 16530 sgd_solver.cpp:105] Iteration 17500, lr = 0.009125
I0529 04:49:41.991672 16530 solver.cpp:218] Iteration 17600 (0.874511 iter/s, 114.35s/100 iters), loss = 0.874937
I0529 04:49:41.991878 16530 solver.cpp:237]     Train net output #0: loss = 0.874937 (* 1 = 0.874937 loss)
I0529 04:49:41.991902 16530 sgd_solver.cpp:105] Iteration 17600, lr = 0.00912
I0529 04:51:36.355862 16530 solver.cpp:218] Iteration 17700 (0.874409 iter/s, 114.363s/100 iters), loss = 1.1324
I0529 04:51:36.356086 16530 solver.cpp:237]     Train net output #0: loss = 1.1324 (* 1 = 1.1324 loss)
I0529 04:51:36.356130 16530 sgd_solver.cpp:105] Iteration 17700, lr = 0.009115
I0529 04:53:30.745968 16530 solver.cpp:218] Iteration 17800 (0.87421 iter/s, 114.389s/100 iters), loss = 0.886773
I0529 04:53:30.746436 16530 solver.cpp:237]     Train net output #0: loss = 0.886773 (* 1 = 0.886773 loss)
I0529 04:53:30.746469 16530 sgd_solver.cpp:105] Iteration 17800, lr = 0.00911
I0529 04:55:25.101160 16530 solver.cpp:218] Iteration 17900 (0.874479 iter/s, 114.354s/100 iters), loss = 1.18424
I0529 04:55:25.101362 16530 solver.cpp:237]     Train net output #0: loss = 1.18424 (* 1 = 1.18424 loss)
I0529 04:55:25.101382 16530 sgd_solver.cpp:105] Iteration 17900, lr = 0.009105
I0529 04:56:39.578780 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:57:18.311141 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_18000.caffemodel
I0529 04:57:18.879904 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_18000.solverstate
I0529 04:57:18.997671 16530 solver.cpp:330] Iteration 18000, Testing net (#0)
I0529 04:58:02.985384 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:59:09.058323 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:00:12.589272 16530 solver.cpp:397]     Test net output #0: accuracy = 0.46986
I0529 05:00:12.589414 16530 solver.cpp:397]     Test net output #1: loss = 1.49554 (* 1 = 1.49554 loss)
I0529 05:00:13.726446 16530 solver.cpp:218] Iteration 18000 (0.346473 iter/s, 288.623s/100 iters), loss = 1.0228
I0529 05:00:13.726536 16530 solver.cpp:237]     Train net output #0: loss = 1.0228 (* 1 = 1.0228 loss)
I0529 05:00:13.726552 16530 sgd_solver.cpp:105] Iteration 18000, lr = 0.0091
I0529 05:02:08.118613 16530 solver.cpp:218] Iteration 18100 (0.874213 iter/s, 114.389s/100 iters), loss = 0.92997
I0529 05:02:08.118871 16530 solver.cpp:237]     Train net output #0: loss = 0.92997 (* 1 = 0.92997 loss)
I0529 05:02:08.118916 16530 sgd_solver.cpp:105] Iteration 18100, lr = 0.009095
I0529 05:04:02.477653 16530 solver.cpp:218] Iteration 18200 (0.874448 iter/s, 114.358s/100 iters), loss = 0.767405
I0529 05:04:02.477860 16530 solver.cpp:237]     Train net output #0: loss = 0.767405 (* 1 = 0.767405 loss)
I0529 05:04:02.477887 16530 sgd_solver.cpp:105] Iteration 18200, lr = 0.00909
I0529 05:05:56.898207 16530 solver.cpp:218] Iteration 18300 (0.873978 iter/s, 114.419s/100 iters), loss = 0.908952
I0529 05:05:56.898425 16530 solver.cpp:237]     Train net output #0: loss = 0.908952 (* 1 = 0.908952 loss)
I0529 05:05:56.898458 16530 sgd_solver.cpp:105] Iteration 18300, lr = 0.009085
I0529 05:07:51.337959 16530 solver.cpp:218] Iteration 18400 (0.873831 iter/s, 114.439s/100 iters), loss = 0.831555
I0529 05:07:51.338176 16530 solver.cpp:237]     Train net output #0: loss = 0.831555 (* 1 = 0.831555 loss)
I0529 05:07:51.338199 16530 sgd_solver.cpp:105] Iteration 18400, lr = 0.00908
I0529 05:09:45.749945 16530 solver.cpp:218] Iteration 18500 (0.874044 iter/s, 114.411s/100 iters), loss = 1.16133
I0529 05:09:45.750129 16530 solver.cpp:237]     Train net output #0: loss = 1.16133 (* 1 = 1.16133 loss)
I0529 05:09:45.750177 16530 sgd_solver.cpp:105] Iteration 18500, lr = 0.009075
I0529 05:11:40.131773 16530 solver.cpp:218] Iteration 18600 (0.874274 iter/s, 114.381s/100 iters), loss = 0.885006
I0529 05:11:40.131994 16530 solver.cpp:237]     Train net output #0: loss = 0.885006 (* 1 = 0.885006 loss)
I0529 05:11:40.132009 16530 sgd_solver.cpp:105] Iteration 18600, lr = 0.00907
I0529 05:13:34.522578 16530 solver.cpp:218] Iteration 18700 (0.874206 iter/s, 114.39s/100 iters), loss = 0.958848
I0529 05:13:34.522748 16530 solver.cpp:237]     Train net output #0: loss = 0.958848 (* 1 = 0.958848 loss)
I0529 05:13:34.522769 16530 sgd_solver.cpp:105] Iteration 18700, lr = 0.009065
I0529 05:14:27.306562 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:15:28.942368 16530 solver.cpp:218] Iteration 18800 (0.873984 iter/s, 114.419s/100 iters), loss = 0.916008
I0529 05:15:28.942575 16530 solver.cpp:237]     Train net output #0: loss = 0.916008 (* 1 = 0.916008 loss)
I0529 05:15:28.942625 16530 sgd_solver.cpp:105] Iteration 18800, lr = 0.00906
I0529 05:17:23.366199 16530 solver.cpp:218] Iteration 18900 (0.873954 iter/s, 114.423s/100 iters), loss = 0.791778
I0529 05:17:23.366354 16530 solver.cpp:237]     Train net output #0: loss = 0.791778 (* 1 = 0.791778 loss)
I0529 05:17:23.366385 16530 sgd_solver.cpp:105] Iteration 18900, lr = 0.009055
I0529 05:19:16.680768 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_19000.caffemodel
I0529 05:19:17.099963 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_19000.solverstate
I0529 05:19:17.207656 16530 solver.cpp:330] Iteration 19000, Testing net (#0)
I0529 05:19:19.711530 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:20:25.733042 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:21:31.870674 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:22:10.905616 16530 solver.cpp:397]     Test net output #0: accuracy = 0.476558
I0529 05:22:10.905819 16530 solver.cpp:397]     Test net output #1: loss = 1.39883 (* 1 = 1.39883 loss)
I0529 05:22:12.041903 16530 solver.cpp:218] Iteration 19000 (0.346413 iter/s, 288.673s/100 iters), loss = 0.959547
I0529 05:22:12.041980 16530 solver.cpp:237]     Train net output #0: loss = 0.959547 (* 1 = 0.959547 loss)
I0529 05:22:12.041993 16530 sgd_solver.cpp:105] Iteration 19000, lr = 0.00905
I0529 05:24:06.555958 16530 solver.cpp:218] Iteration 19100 (0.873265 iter/s, 114.513s/100 iters), loss = 0.760893
I0529 05:24:06.556154 16530 solver.cpp:237]     Train net output #0: loss = 0.760893 (* 1 = 0.760893 loss)
I0529 05:24:06.556169 16530 sgd_solver.cpp:105] Iteration 19100, lr = 0.009045
I0529 05:26:01.067291 16530 solver.cpp:218] Iteration 19200 (0.873286 iter/s, 114.51s/100 iters), loss = 0.819513
I0529 05:26:01.067469 16530 solver.cpp:237]     Train net output #0: loss = 0.819513 (* 1 = 0.819513 loss)
I0529 05:26:01.067512 16530 sgd_solver.cpp:105] Iteration 19200, lr = 0.00904
I0529 05:27:55.576799 16530 solver.cpp:218] Iteration 19300 (0.873299 iter/s, 114.508s/100 iters), loss = 0.694146
I0529 05:27:55.576994 16530 solver.cpp:237]     Train net output #0: loss = 0.694146 (* 1 = 0.694146 loss)
I0529 05:27:55.577028 16530 sgd_solver.cpp:105] Iteration 19300, lr = 0.009035
I0529 05:29:50.109401 16530 solver.cpp:218] Iteration 19400 (0.873123 iter/s, 114.531s/100 iters), loss = 1.01109
I0529 05:29:50.109694 16530 solver.cpp:237]     Train net output #0: loss = 1.01109 (* 1 = 1.01109 loss)
I0529 05:29:50.109724 16530 sgd_solver.cpp:105] Iteration 19400, lr = 0.00903
I0529 05:31:44.633707 16530 solver.cpp:218] Iteration 19500 (0.873187 iter/s, 114.523s/100 iters), loss = 0.913875
I0529 05:31:44.633874 16530 solver.cpp:237]     Train net output #0: loss = 0.913875 (* 1 = 0.913875 loss)
I0529 05:31:44.633899 16530 sgd_solver.cpp:105] Iteration 19500, lr = 0.009025
I0529 05:32:15.731585 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:33:39.167265 16530 solver.cpp:218] Iteration 19600 (0.873116 iter/s, 114.532s/100 iters), loss = 1.09783
I0529 05:33:39.167457 16530 solver.cpp:237]     Train net output #0: loss = 1.09783 (* 1 = 1.09783 loss)
I0529 05:33:39.167485 16530 sgd_solver.cpp:105] Iteration 19600, lr = 0.00902
I0529 05:35:33.688285 16530 solver.cpp:218] Iteration 19700 (0.873212 iter/s, 114.52s/100 iters), loss = 1.39031
I0529 05:35:33.688510 16530 solver.cpp:237]     Train net output #0: loss = 1.39031 (* 1 = 1.39031 loss)
I0529 05:35:33.688536 16530 sgd_solver.cpp:105] Iteration 19700, lr = 0.009015
I0529 05:37:28.210718 16530 solver.cpp:218] Iteration 19800 (0.873201 iter/s, 114.521s/100 iters), loss = 0.987924
I0529 05:37:28.210912 16530 solver.cpp:237]     Train net output #0: loss = 0.987924 (* 1 = 0.987924 loss)
I0529 05:37:28.210938 16530 sgd_solver.cpp:105] Iteration 19800, lr = 0.00901
I0529 05:39:22.684463 16530 solver.cpp:218] Iteration 19900 (0.873573 iter/s, 114.472s/100 iters), loss = 0.897147
I0529 05:39:22.684625 16530 solver.cpp:237]     Train net output #0: loss = 0.897147 (* 1 = 0.897147 loss)
I0529 05:39:22.684648 16530 sgd_solver.cpp:105] Iteration 19900, lr = 0.009005
I0529 05:41:16.008904 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_20000.caffemodel
I0529 05:41:16.701550 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_20000.solverstate
I0529 05:41:16.812198 16530 solver.cpp:330] Iteration 20000, Testing net (#0)
I0529 05:41:43.825215 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:42:49.854915 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:43:56.003671 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:44:10.556104 16530 solver.cpp:397]     Test net output #0: accuracy = 0.517328
I0529 05:44:10.556190 16530 solver.cpp:397]     Test net output #1: loss = 1.22761 (* 1 = 1.22761 loss)
I0529 05:44:11.692154 16530 solver.cpp:218] Iteration 20000 (0.346015 iter/s, 289.005s/100 iters), loss = 1.08118
I0529 05:44:11.692234 16530 solver.cpp:237]     Train net output #0: loss = 1.08118 (* 1 = 1.08118 loss)
I0529 05:44:11.692248 16530 sgd_solver.cpp:105] Iteration 20000, lr = 0.009
I0529 05:46:06.192925 16530 solver.cpp:218] Iteration 20100 (0.873366 iter/s, 114.5s/100 iters), loss = 0.711437
I0529 05:46:06.193128 16530 solver.cpp:237]     Train net output #0: loss = 0.711437 (* 1 = 0.711437 loss)
I0529 05:46:06.193143 16530 sgd_solver.cpp:105] Iteration 20100, lr = 0.008995
I0529 05:48:00.673785 16530 solver.cpp:218] Iteration 20200 (0.873518 iter/s, 114.48s/100 iters), loss = 0.91831
I0529 05:48:00.673987 16530 solver.cpp:237]     Train net output #0: loss = 0.91831 (* 1 = 0.91831 loss)
I0529 05:48:00.674038 16530 sgd_solver.cpp:105] Iteration 20200, lr = 0.00899
I0529 05:49:55.154790 16530 solver.cpp:218] Iteration 20300 (0.873517 iter/s, 114.48s/100 iters), loss = 1.19752
I0529 05:49:55.154934 16530 solver.cpp:237]     Train net output #0: loss = 1.19752 (* 1 = 1.19752 loss)
I0529 05:49:55.154947 16530 sgd_solver.cpp:105] Iteration 20300, lr = 0.008985
I0529 05:50:05.602886 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:51:49.624492 16530 solver.cpp:218] Iteration 20400 (0.873603 iter/s, 114.468s/100 iters), loss = 0.694257
I0529 05:51:49.624689 16530 solver.cpp:237]     Train net output #0: loss = 0.694257 (* 1 = 0.694257 loss)
I0529 05:51:49.624706 16530 sgd_solver.cpp:105] Iteration 20400, lr = 0.00898
I0529 05:53:44.107280 16530 solver.cpp:218] Iteration 20500 (0.873503 iter/s, 114.482s/100 iters), loss = 0.89706
I0529 05:53:44.107601 16530 solver.cpp:237]     Train net output #0: loss = 0.89706 (* 1 = 0.89706 loss)
I0529 05:53:44.107616 16530 sgd_solver.cpp:105] Iteration 20500, lr = 0.008975
I0529 05:55:38.565816 16530 solver.cpp:218] Iteration 20600 (0.87369 iter/s, 114.457s/100 iters), loss = 0.873259
I0529 05:55:38.565985 16530 solver.cpp:237]     Train net output #0: loss = 0.873259 (* 1 = 0.873259 loss)
I0529 05:55:38.566009 16530 sgd_solver.cpp:105] Iteration 20600, lr = 0.00897
I0529 05:57:33.067726 16530 solver.cpp:218] Iteration 20700 (0.873357 iter/s, 114.501s/100 iters), loss = 0.923461
I0529 05:57:33.067932 16530 solver.cpp:237]     Train net output #0: loss = 0.923461 (* 1 = 0.923461 loss)
I0529 05:57:33.067957 16530 sgd_solver.cpp:105] Iteration 20700, lr = 0.008965
I0529 05:59:27.549521 16530 solver.cpp:218] Iteration 20800 (0.873511 iter/s, 114.481s/100 iters), loss = 0.837472
I0529 05:59:27.549723 16530 solver.cpp:237]     Train net output #0: loss = 0.837472 (* 1 = 0.837472 loss)
I0529 05:59:27.549751 16530 sgd_solver.cpp:105] Iteration 20800, lr = 0.00896
I0529 06:01:21.993093 16530 solver.cpp:218] Iteration 20900 (0.873803 iter/s, 114.442s/100 iters), loss = 0.966143
I0529 06:01:21.993301 16530 solver.cpp:237]     Train net output #0: loss = 0.966143 (* 1 = 0.966143 loss)
I0529 06:01:21.993342 16530 sgd_solver.cpp:105] Iteration 20900, lr = 0.008955
I0529 06:03:15.309772 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_21000.caffemodel
I0529 06:03:16.022879 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_21000.solverstate
I0529 06:03:16.133265 16530 solver.cpp:330] Iteration 21000, Testing net (#0)
I0529 06:04:07.605667 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:05:13.601747 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:06:09.818071 16530 solver.cpp:397]     Test net output #0: accuracy = 0.504595
I0529 06:06:09.818274 16530 solver.cpp:397]     Test net output #1: loss = 1.25339 (* 1 = 1.25339 loss)
I0529 06:06:10.954381 16530 solver.cpp:218] Iteration 21000 (0.346071 iter/s, 288.958s/100 iters), loss = 0.89957
I0529 06:06:10.954462 16530 solver.cpp:237]     Train net output #0: loss = 0.89957 (* 1 = 0.89957 loss)
I0529 06:06:10.954476 16530 sgd_solver.cpp:105] Iteration 21000, lr = 0.00895
I0529 06:07:54.092254 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:08:05.378295 16530 solver.cpp:218] Iteration 21100 (0.873952 iter/s, 114.423s/100 iters), loss = 0.768581
I0529 06:08:05.378371 16530 solver.cpp:237]     Train net output #0: loss = 0.768581 (* 1 = 0.768581 loss)
I0529 06:08:05.378383 16530 sgd_solver.cpp:105] Iteration 21100, lr = 0.008945
I0529 06:09:59.805032 16530 solver.cpp:218] Iteration 21200 (0.873931 iter/s, 114.426s/100 iters), loss = 0.870849
I0529 06:09:59.805192 16530 solver.cpp:237]     Train net output #0: loss = 0.870849 (* 1 = 0.870849 loss)
I0529 06:09:59.805204 16530 sgd_solver.cpp:105] Iteration 21200, lr = 0.00894
I0529 06:11:54.266227 16530 solver.cpp:218] Iteration 21300 (0.873668 iter/s, 114.46s/100 iters), loss = 0.91353
I0529 06:11:54.266383 16530 solver.cpp:237]     Train net output #0: loss = 0.91353 (* 1 = 0.91353 loss)
I0529 06:11:54.266398 16530 sgd_solver.cpp:105] Iteration 21300, lr = 0.008935
I0529 06:13:48.718806 16530 solver.cpp:218] Iteration 21400 (0.873734 iter/s, 114.451s/100 iters), loss = 1.1101
I0529 06:13:48.719012 16530 solver.cpp:237]     Train net output #0: loss = 1.1101 (* 1 = 1.1101 loss)
I0529 06:13:48.719034 16530 sgd_solver.cpp:105] Iteration 21400, lr = 0.00893
I0529 06:15:43.156416 16530 solver.cpp:218] Iteration 21500 (0.873848 iter/s, 114.436s/100 iters), loss = 0.975578
I0529 06:15:43.156628 16530 solver.cpp:237]     Train net output #0: loss = 0.975578 (* 1 = 0.975578 loss)
I0529 06:15:43.156644 16530 sgd_solver.cpp:105] Iteration 21500, lr = 0.008925
I0529 06:17:37.589041 16530 solver.cpp:218] Iteration 21600 (0.873887 iter/s, 114.431s/100 iters), loss = 0.754999
I0529 06:17:37.589354 16530 solver.cpp:237]     Train net output #0: loss = 0.754999 (* 1 = 0.754999 loss)
I0529 06:17:37.589395 16530 sgd_solver.cpp:105] Iteration 21600, lr = 0.00892
I0529 06:19:32.011276 16530 solver.cpp:218] Iteration 21700 (0.873966 iter/s, 114.421s/100 iters), loss = 0.788366
I0529 06:19:32.011464 16530 solver.cpp:237]     Train net output #0: loss = 0.788366 (* 1 = 0.788366 loss)
I0529 06:19:32.011502 16530 sgd_solver.cpp:105] Iteration 21700, lr = 0.008915
I0529 06:21:26.426496 16530 solver.cpp:218] Iteration 21800 (0.874019 iter/s, 114.414s/100 iters), loss = 0.820893
I0529 06:21:26.426683 16530 solver.cpp:237]     Train net output #0: loss = 0.820893 (* 1 = 0.820893 loss)
I0529 06:21:26.426699 16530 sgd_solver.cpp:105] Iteration 21800, lr = 0.00891
I0529 06:22:47.850508 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:23:20.864349 16530 solver.cpp:218] Iteration 21900 (0.873846 iter/s, 114.437s/100 iters), loss = 0.665591
I0529 06:23:20.864531 16530 solver.cpp:237]     Train net output #0: loss = 0.665591 (* 1 = 0.665591 loss)
I0529 06:23:20.864544 16530 sgd_solver.cpp:105] Iteration 21900, lr = 0.008905
I0529 06:25:14.202683 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_22000.caffemodel
I0529 06:25:14.854570 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_22000.solverstate
I0529 06:25:14.963861 16530 solver.cpp:330] Iteration 22000, Testing net (#0)
I0529 06:25:24.899425 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:26:30.978504 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:27:37.023660 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:28:08.756845 16530 solver.cpp:397]     Test net output #0: accuracy = 0.410592
I0529 06:28:08.757068 16530 solver.cpp:397]     Test net output #1: loss = 1.45814 (* 1 = 1.45814 loss)
I0529 06:28:09.891324 16530 solver.cpp:218] Iteration 22000 (0.345992 iter/s, 289.024s/100 iters), loss = 0.950391
I0529 06:28:09.891388 16530 solver.cpp:237]     Train net output #0: loss = 0.950391 (* 1 = 0.950391 loss)
I0529 06:28:09.891402 16530 sgd_solver.cpp:105] Iteration 22000, lr = 0.0089
I0529 06:30:04.409512 16530 solver.cpp:218] Iteration 22100 (0.873232 iter/s, 114.517s/100 iters), loss = 0.934303
I0529 06:30:04.409615 16530 solver.cpp:237]     Train net output #0: loss = 0.934303 (* 1 = 0.934303 loss)
I0529 06:30:04.409627 16530 sgd_solver.cpp:105] Iteration 22100, lr = 0.008895
I0529 06:31:58.951747 16530 solver.cpp:218] Iteration 22200 (0.873049 iter/s, 114.541s/100 iters), loss = 0.832906
I0529 06:31:58.951953 16530 solver.cpp:237]     Train net output #0: loss = 0.832906 (* 1 = 0.832906 loss)
I0529 06:31:58.951982 16530 sgd_solver.cpp:105] Iteration 22200, lr = 0.00889
I0529 06:33:53.499994 16530 solver.cpp:218] Iteration 22300 (0.873004 iter/s, 114.547s/100 iters), loss = 0.677099
I0529 06:33:53.500243 16530 solver.cpp:237]     Train net output #0: loss = 0.677099 (* 1 = 0.677099 loss)
I0529 06:33:53.500258 16530 sgd_solver.cpp:105] Iteration 22300, lr = 0.008885
I0529 06:35:48.060904 16530 solver.cpp:218] Iteration 22400 (0.872908 iter/s, 114.56s/100 iters), loss = 1.26735
I0529 06:35:48.061108 16530 solver.cpp:237]     Train net output #0: loss = 1.26735 (* 1 = 1.26735 loss)
I0529 06:35:48.061131 16530 sgd_solver.cpp:105] Iteration 22400, lr = 0.00888
I0529 06:37:42.634723 16530 solver.cpp:218] Iteration 22500 (0.872809 iter/s, 114.573s/100 iters), loss = 0.791268
I0529 06:37:42.634935 16530 solver.cpp:237]     Train net output #0: loss = 0.791268 (* 1 = 0.791268 loss)
I0529 06:37:42.634966 16530 sgd_solver.cpp:105] Iteration 22500, lr = 0.008875
I0529 06:39:37.213345 16530 solver.cpp:218] Iteration 22600 (0.872773 iter/s, 114.577s/100 iters), loss = 0.889018
I0529 06:39:37.213584 16530 solver.cpp:237]     Train net output #0: loss = 0.889018 (* 1 = 0.889018 loss)
I0529 06:39:37.213599 16530 sgd_solver.cpp:105] Iteration 22600, lr = 0.00887
I0529 06:40:38.091936 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:41:31.820775 16530 solver.cpp:218] Iteration 22700 (0.872554 iter/s, 114.606s/100 iters), loss = 0.814364
I0529 06:41:31.820981 16530 solver.cpp:237]     Train net output #0: loss = 0.814364 (* 1 = 0.814364 loss)
I0529 06:41:31.821034 16530 sgd_solver.cpp:105] Iteration 22700, lr = 0.008865
I0529 06:43:26.407781 16530 solver.cpp:218] Iteration 22800 (0.872709 iter/s, 114.586s/100 iters), loss = 1.09661
I0529 06:43:26.407937 16530 solver.cpp:237]     Train net output #0: loss = 1.09661 (* 1 = 1.09661 loss)
I0529 06:43:26.407960 16530 sgd_solver.cpp:105] Iteration 22800, lr = 0.00886
I0529 06:45:20.981501 16530 solver.cpp:218] Iteration 22900 (0.87281 iter/s, 114.573s/100 iters), loss = 0.811385
I0529 06:45:20.981669 16530 solver.cpp:237]     Train net output #0: loss = 0.811385 (* 1 = 0.811385 loss)
I0529 06:45:20.981683 16530 sgd_solver.cpp:105] Iteration 22900, lr = 0.008855
I0529 06:47:14.408243 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_23000.caffemodel
I0529 06:47:14.885946 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_23000.solverstate
I0529 06:47:14.996093 16530 solver.cpp:330] Iteration 23000, Testing net (#0)
I0529 06:47:49.434151 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:48:55.512709 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:50:01.705605 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:50:08.817991 16530 solver.cpp:397]     Test net output #0: accuracy = 0.447625
I0529 06:50:08.818066 16530 solver.cpp:397]     Test net output #1: loss = 1.52937 (* 1 = 1.52937 loss)
I0529 06:50:09.952853 16530 solver.cpp:218] Iteration 23000 (0.346058 iter/s, 288.969s/100 iters), loss = 0.726687
I0529 06:50:09.952930 16530 solver.cpp:237]     Train net output #0: loss = 0.726687 (* 1 = 0.726687 loss)
I0529 06:50:09.952944 16530 sgd_solver.cpp:105] Iteration 23000, lr = 0.00885
I0529 06:52:04.484510 16530 solver.cpp:218] Iteration 23100 (0.87313 iter/s, 114.531s/100 iters), loss = 0.897172
I0529 06:52:04.484663 16530 solver.cpp:237]     Train net output #0: loss = 0.897172 (* 1 = 0.897172 loss)
I0529 06:52:04.484686 16530 sgd_solver.cpp:105] Iteration 23100, lr = 0.008845
I0529 06:53:59.007215 16530 solver.cpp:218] Iteration 23200 (0.873199 iter/s, 114.521s/100 iters), loss = 0.866255
I0529 06:53:59.007452 16530 solver.cpp:237]     Train net output #0: loss = 0.866255 (* 1 = 0.866255 loss)
I0529 06:53:59.007465 16530 sgd_solver.cpp:105] Iteration 23200, lr = 0.00884
I0529 06:55:53.509652 16530 solver.cpp:218] Iteration 23300 (0.873353 iter/s, 114.501s/100 iters), loss = 0.741293
I0529 06:55:53.509830 16530 solver.cpp:237]     Train net output #0: loss = 0.741293 (* 1 = 0.741293 loss)
I0529 06:55:53.509871 16530 sgd_solver.cpp:105] Iteration 23300, lr = 0.008835
I0529 06:57:47.993417 16530 solver.cpp:218] Iteration 23400 (0.873495 iter/s, 114.483s/100 iters), loss = 0.732786
I0529 06:57:47.993587 16530 solver.cpp:237]     Train net output #0: loss = 0.732786 (* 1 = 0.732786 loss)
I0529 06:57:47.993631 16530 sgd_solver.cpp:105] Iteration 23400, lr = 0.00883
I0529 06:58:27.083446 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:59:42.467720 16530 solver.cpp:218] Iteration 23500 (0.873567 iter/s, 114.473s/100 iters), loss = 0.735249
I0529 06:59:42.467903 16530 solver.cpp:237]     Train net output #0: loss = 0.735249 (* 1 = 0.735249 loss)
I0529 06:59:42.467921 16530 sgd_solver.cpp:105] Iteration 23500, lr = 0.008825
I0529 07:01:36.945369 16530 solver.cpp:218] Iteration 23600 (0.873542 iter/s, 114.476s/100 iters), loss = 0.941996
I0529 07:01:36.945559 16530 solver.cpp:237]     Train net output #0: loss = 0.941996 (* 1 = 0.941996 loss)
I0529 07:01:36.945570 16530 sgd_solver.cpp:105] Iteration 23600, lr = 0.00882
I0529 07:03:31.439672 16530 solver.cpp:218] Iteration 23700 (0.873415 iter/s, 114.493s/100 iters), loss = 0.726434
I0529 07:03:31.439862 16530 solver.cpp:237]     Train net output #0: loss = 0.726434 (* 1 = 0.726434 loss)
I0529 07:03:31.439877 16530 sgd_solver.cpp:105] Iteration 23700, lr = 0.008815
I0529 07:05:25.936331 16530 solver.cpp:218] Iteration 23800 (0.873397 iter/s, 114.496s/100 iters), loss = 0.908928
I0529 07:05:25.936517 16530 solver.cpp:237]     Train net output #0: loss = 0.908928 (* 1 = 0.908928 loss)
I0529 07:05:25.936553 16530 sgd_solver.cpp:105] Iteration 23800, lr = 0.00881
I0529 07:07:20.421013 16530 solver.cpp:218] Iteration 23900 (0.873488 iter/s, 114.484s/100 iters), loss = 0.886763
I0529 07:07:20.421315 16530 solver.cpp:237]     Train net output #0: loss = 0.886763 (* 1 = 0.886763 loss)
I0529 07:07:20.421352 16530 sgd_solver.cpp:105] Iteration 23900, lr = 0.008805
I0529 07:09:13.745885 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_24000.caffemodel
I0529 07:09:14.100739 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_24000.solverstate
I0529 07:09:14.210326 16530 solver.cpp:330] Iteration 24000, Testing net (#0)
I0529 07:10:13.124459 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:11:19.167927 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:12:07.964113 16530 solver.cpp:397]     Test net output #0: accuracy = 0.464135
I0529 07:12:07.964299 16530 solver.cpp:397]     Test net output #1: loss = 1.38022 (* 1 = 1.38022 loss)
I0529 07:12:09.099344 16530 solver.cpp:218] Iteration 24000 (0.346409 iter/s, 288.676s/100 iters), loss = 0.640636
I0529 07:12:09.099409 16530 solver.cpp:237]     Train net output #0: loss = 0.640636 (* 1 = 0.640636 loss)
I0529 07:12:09.099421 16530 sgd_solver.cpp:105] Iteration 24000, lr = 0.0088
I0529 07:14:03.549095 16530 solver.cpp:218] Iteration 24100 (0.873754 iter/s, 114.449s/100 iters), loss = 0.980844
I0529 07:14:03.549252 16530 solver.cpp:237]     Train net output #0: loss = 0.980844 (* 1 = 0.980844 loss)
I0529 07:14:03.549266 16530 sgd_solver.cpp:105] Iteration 24100, lr = 0.008795
I0529 07:15:58.029932 16530 solver.cpp:218] Iteration 24200 (0.873517 iter/s, 114.48s/100 iters), loss = 0.869522
I0529 07:15:58.030170 16530 solver.cpp:237]     Train net output #0: loss = 0.869522 (* 1 = 0.869522 loss)
I0529 07:15:58.030184 16530 sgd_solver.cpp:105] Iteration 24200, lr = 0.00879
I0529 07:16:15.365550 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:17:52.478389 16530 solver.cpp:218] Iteration 24300 (0.873765 iter/s, 114.447s/100 iters), loss = 1.01859
I0529 07:17:52.478593 16530 solver.cpp:237]     Train net output #0: loss = 1.01859 (* 1 = 1.01859 loss)
I0529 07:17:52.478606 16530 sgd_solver.cpp:105] Iteration 24300, lr = 0.008785
I0529 07:19:46.929416 16530 solver.cpp:218] Iteration 24400 (0.873745 iter/s, 114.45s/100 iters), loss = 0.889598
I0529 07:19:46.929591 16530 solver.cpp:237]     Train net output #0: loss = 0.889598 (* 1 = 0.889598 loss)
I0529 07:19:46.929621 16530 sgd_solver.cpp:105] Iteration 24400, lr = 0.00878
I0529 07:21:41.363555 16530 solver.cpp:218] Iteration 24500 (0.873874 iter/s, 114.433s/100 iters), loss = 0.73735
I0529 07:21:41.363762 16530 solver.cpp:237]     Train net output #0: loss = 0.73735 (* 1 = 0.73735 loss)
I0529 07:21:41.363775 16530 sgd_solver.cpp:105] Iteration 24500, lr = 0.008775
I0529 07:23:35.787678 16530 solver.cpp:218] Iteration 24600 (0.873951 iter/s, 114.423s/100 iters), loss = 0.784116
I0529 07:23:35.787874 16530 solver.cpp:237]     Train net output #0: loss = 0.784116 (* 1 = 0.784116 loss)
I0529 07:23:35.787899 16530 sgd_solver.cpp:105] Iteration 24600, lr = 0.00877
I0529 07:25:30.184146 16530 solver.cpp:218] Iteration 24700 (0.874162 iter/s, 114.395s/100 iters), loss = 0.974617
I0529 07:25:30.184320 16530 solver.cpp:237]     Train net output #0: loss = 0.974617 (* 1 = 0.974617 loss)
I0529 07:25:30.184336 16530 sgd_solver.cpp:105] Iteration 24700, lr = 0.008765
I0529 07:27:24.584425 16530 solver.cpp:218] Iteration 24800 (0.874132 iter/s, 114.399s/100 iters), loss = 0.769218
I0529 07:27:24.584643 16530 solver.cpp:237]     Train net output #0: loss = 0.769218 (* 1 = 0.769218 loss)
I0529 07:27:24.584662 16530 sgd_solver.cpp:105] Iteration 24800, lr = 0.00876
I0529 07:29:18.988503 16530 solver.cpp:218] Iteration 24900 (0.874103 iter/s, 114.403s/100 iters), loss = 0.774099
I0529 07:29:18.988684 16530 solver.cpp:237]     Train net output #0: loss = 0.774099 (* 1 = 0.774099 loss)
I0529 07:29:18.988723 16530 sgd_solver.cpp:105] Iteration 24900, lr = 0.008755
I0529 07:31:08.999783 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:31:12.269259 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_25000.caffemodel
I0529 07:31:12.920759 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_25000.solverstate
I0529 07:31:13.029861 16530 solver.cpp:330] Iteration 25000, Testing net (#0)
I0529 07:31:30.426326 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:32:36.445982 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:33:42.497661 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:34:06.787494 16530 solver.cpp:397]     Test net output #0: accuracy = 0.423988
I0529 07:34:06.787562 16530 solver.cpp:397]     Test net output #1: loss = 1.6255 (* 1 = 1.6255 loss)
I0529 07:34:07.923650 16530 solver.cpp:218] Iteration 25000 (0.346101 iter/s, 288.933s/100 iters), loss = 0.763525
I0529 07:34:07.923717 16530 solver.cpp:237]     Train net output #0: loss = 0.763525 (* 1 = 0.763525 loss)
I0529 07:34:07.923730 16530 sgd_solver.cpp:105] Iteration 25000, lr = 0.00875
I0529 07:36:02.393759 16530 solver.cpp:218] Iteration 25100 (0.873599 iter/s, 114.469s/100 iters), loss = 0.663757
I0529 07:36:02.393954 16530 solver.cpp:237]     Train net output #0: loss = 0.663757 (* 1 = 0.663757 loss)
I0529 07:36:02.393985 16530 sgd_solver.cpp:105] Iteration 25100, lr = 0.008745
I0529 07:37:56.837057 16530 solver.cpp:218] Iteration 25200 (0.873804 iter/s, 114.442s/100 iters), loss = 0.745327
I0529 07:37:56.837299 16530 solver.cpp:237]     Train net output #0: loss = 0.745327 (* 1 = 0.745327 loss)
I0529 07:37:56.837313 16530 sgd_solver.cpp:105] Iteration 25200, lr = 0.00874
I0529 07:39:51.253609 16530 solver.cpp:218] Iteration 25300 (0.874008 iter/s, 114.415s/100 iters), loss = 1.01001
I0529 07:39:51.253806 16530 solver.cpp:237]     Train net output #0: loss = 1.01001 (* 1 = 1.01001 loss)
I0529 07:39:51.253841 16530 sgd_solver.cpp:105] Iteration 25300, lr = 0.008735
I0529 07:41:45.733239 16530 solver.cpp:218] Iteration 25400 (0.873526 iter/s, 114.479s/100 iters), loss = 0.765386
I0529 07:41:45.733453 16530 solver.cpp:237]     Train net output #0: loss = 0.765386 (* 1 = 0.765386 loss)
I0529 07:41:45.733491 16530 sgd_solver.cpp:105] Iteration 25400, lr = 0.00873
I0529 07:43:40.200305 16530 solver.cpp:218] Iteration 25500 (0.873622 iter/s, 114.466s/100 iters), loss = 1.07801
I0529 07:43:40.200489 16530 solver.cpp:237]     Train net output #0: loss = 1.07801 (* 1 = 1.07801 loss)
I0529 07:43:40.200502 16530 sgd_solver.cpp:105] Iteration 25500, lr = 0.008725
I0529 07:45:34.687054 16530 solver.cpp:218] Iteration 25600 (0.873472 iter/s, 114.486s/100 iters), loss = 0.799873
I0529 07:45:34.687237 16530 solver.cpp:237]     Train net output #0: loss = 0.799873 (* 1 = 0.799873 loss)
I0529 07:45:34.687273 16530 sgd_solver.cpp:105] Iteration 25600, lr = 0.00872
I0529 07:47:29.185259 16530 solver.cpp:218] Iteration 25700 (0.873385 iter/s, 114.497s/100 iters), loss = 0.934817
I0529 07:47:29.185415 16530 solver.cpp:237]     Train net output #0: loss = 0.934817 (* 1 = 0.934817 loss)
I0529 07:47:29.185458 16530 sgd_solver.cpp:105] Iteration 25700, lr = 0.008715
I0529 07:48:58.598433 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:49:23.649412 16530 solver.cpp:218] Iteration 25800 (0.873644 iter/s, 114.463s/100 iters), loss = 0.970383
I0529 07:49:23.649499 16530 solver.cpp:237]     Train net output #0: loss = 0.970383 (* 1 = 0.970383 loss)
I0529 07:49:23.649515 16530 sgd_solver.cpp:105] Iteration 25800, lr = 0.00871
I0529 07:51:18.130867 16530 solver.cpp:218] Iteration 25900 (0.873512 iter/s, 114.48s/100 iters), loss = 0.80456
I0529 07:51:18.131098 16530 solver.cpp:237]     Train net output #0: loss = 0.80456 (* 1 = 0.80456 loss)
I0529 07:51:18.131130 16530 sgd_solver.cpp:105] Iteration 25900, lr = 0.008705
I0529 07:53:11.465404 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_26000.caffemodel
I0529 07:53:11.821288 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_26000.solverstate
I0529 07:53:11.929783 16530 solver.cpp:330] Iteration 26000, Testing net (#0)
I0529 07:53:53.782060 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:54:59.853945 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:56:05.675477 16530 solver.cpp:397]     Test net output #0: accuracy = 0.505568
I0529 07:56:05.675642 16530 solver.cpp:397]     Test net output #1: loss = 1.52254 (* 1 = 1.52254 loss)
I0529 07:56:06.812335 16530 solver.cpp:218] Iteration 26000 (0.346406 iter/s, 288.679s/100 iters), loss = 0.726807
I0529 07:56:06.812408 16530 solver.cpp:237]     Train net output #0: loss = 0.726807 (* 1 = 0.726807 loss)
I0529 07:56:06.812422 16530 sgd_solver.cpp:105] Iteration 26000, lr = 0.0087
I0529 07:58:01.307833 16530 solver.cpp:218] Iteration 26100 (0.873405 iter/s, 114.494s/100 iters), loss = 0.683097
I0529 07:58:01.307982 16530 solver.cpp:237]     Train net output #0: loss = 0.683097 (* 1 = 0.683097 loss)
I0529 07:58:01.308006 16530 sgd_solver.cpp:105] Iteration 26100, lr = 0.008695
I0529 07:59:55.835829 16530 solver.cpp:218] Iteration 26200 (0.873157 iter/s, 114.527s/100 iters), loss = 0.766895
I0529 07:59:55.836010 16530 solver.cpp:237]     Train net output #0: loss = 0.766895 (* 1 = 0.766895 loss)
I0529 07:59:55.836046 16530 sgd_solver.cpp:105] Iteration 26200, lr = 0.00869
I0529 08:01:50.353549 16530 solver.cpp:218] Iteration 26300 (0.873236 iter/s, 114.517s/100 iters), loss = 0.910086
I0529 08:01:50.353734 16530 solver.cpp:237]     Train net output #0: loss = 0.910086 (* 1 = 0.910086 loss)
I0529 08:01:50.353749 16530 sgd_solver.cpp:105] Iteration 26300, lr = 0.008685
I0529 08:03:44.878594 16530 solver.cpp:218] Iteration 26400 (0.87318 iter/s, 114.524s/100 iters), loss = 0.724023
I0529 08:03:44.878754 16530 solver.cpp:237]     Train net output #0: loss = 0.724023 (* 1 = 0.724023 loss)
I0529 08:03:44.878793 16530 sgd_solver.cpp:105] Iteration 26400, lr = 0.00868
I0529 08:05:39.431942 16530 solver.cpp:218] Iteration 26500 (0.872964 iter/s, 114.552s/100 iters), loss = 0.743424
I0529 08:05:39.432133 16530 solver.cpp:237]     Train net output #0: loss = 0.743424 (* 1 = 0.743424 loss)
I0529 08:05:39.432150 16530 sgd_solver.cpp:105] Iteration 26500, lr = 0.008675
I0529 08:06:47.156155 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:07:33.942200 16530 solver.cpp:218] Iteration 26600 (0.873293 iter/s, 114.509s/100 iters), loss = 0.578855
I0529 08:07:33.942430 16530 solver.cpp:237]     Train net output #0: loss = 0.578855 (* 1 = 0.578855 loss)
I0529 08:07:33.942453 16530 sgd_solver.cpp:105] Iteration 26600, lr = 0.00867
I0529 08:09:28.413561 16530 solver.cpp:218] Iteration 26700 (0.87359 iter/s, 114.47s/100 iters), loss = 0.637426
I0529 08:09:28.413713 16530 solver.cpp:237]     Train net output #0: loss = 0.637426 (* 1 = 0.637426 loss)
I0529 08:09:28.413727 16530 sgd_solver.cpp:105] Iteration 26700, lr = 0.008665
I0529 08:11:22.861516 16530 solver.cpp:218] Iteration 26800 (0.873768 iter/s, 114.447s/100 iters), loss = 0.744346
I0529 08:11:22.861661 16530 solver.cpp:237]     Train net output #0: loss = 0.744346 (* 1 = 0.744346 loss)
I0529 08:11:22.861691 16530 sgd_solver.cpp:105] Iteration 26800, lr = 0.00866
I0529 08:13:17.306921 16530 solver.cpp:218] Iteration 26900 (0.873788 iter/s, 114.444s/100 iters), loss = 0.668742
I0529 08:13:17.307109 16530 solver.cpp:237]     Train net output #0: loss = 0.668742 (* 1 = 0.668742 loss)
I0529 08:13:17.307144 16530 sgd_solver.cpp:105] Iteration 26900, lr = 0.008655
I0529 08:15:10.626220 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_27000.caffemodel
I0529 08:15:10.976982 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_27000.solverstate
I0529 08:15:11.089715 16530 solver.cpp:330] Iteration 27000, Testing net (#0)
I0529 08:15:11.300889 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:16:17.445365 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:17:23.447779 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:18:04.789829 16530 solver.cpp:397]     Test net output #0: accuracy = 0.463512
I0529 08:18:04.790040 16530 solver.cpp:397]     Test net output #1: loss = 1.51302 (* 1 = 1.51302 loss)
I0529 08:18:05.925983 16530 solver.cpp:218] Iteration 27000 (0.346481 iter/s, 288.616s/100 iters), loss = 0.659505
I0529 08:18:05.926045 16530 solver.cpp:237]     Train net output #0: loss = 0.659505 (* 1 = 0.659505 loss)
I0529 08:18:05.926057 16530 sgd_solver.cpp:105] Iteration 27000, lr = 0.00865
I0529 08:20:00.398373 16530 solver.cpp:218] Iteration 27100 (0.873581 iter/s, 114.471s/100 iters), loss = 0.987598
I0529 08:20:00.398558 16530 solver.cpp:237]     Train net output #0: loss = 0.987598 (* 1 = 0.987598 loss)
I0529 08:20:00.398571 16530 sgd_solver.cpp:105] Iteration 27100, lr = 0.008645
I0529 08:21:54.908339 16530 solver.cpp:218] Iteration 27200 (0.873295 iter/s, 114.509s/100 iters), loss = 0.730421
I0529 08:21:54.908495 16530 solver.cpp:237]     Train net output #0: loss = 0.730421 (* 1 = 0.730421 loss)
I0529 08:21:54.908519 16530 sgd_solver.cpp:105] Iteration 27200, lr = 0.00864
I0529 08:23:49.392879 16530 solver.cpp:218] Iteration 27300 (0.873489 iter/s, 114.483s/100 iters), loss = 0.911606
I0529 08:23:49.393054 16530 solver.cpp:237]     Train net output #0: loss = 0.911606 (* 1 = 0.911606 loss)
I0529 08:23:49.393065 16530 sgd_solver.cpp:105] Iteration 27300, lr = 0.008635
I0529 08:24:35.346465 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:43.859966 16530 solver.cpp:218] Iteration 27400 (0.873622 iter/s, 114.466s/100 iters), loss = 0.698797
I0529 08:25:43.860127 16530 solver.cpp:237]     Train net output #0: loss = 0.698797 (* 1 = 0.698797 loss)
I0529 08:25:43.860142 16530 sgd_solver.cpp:105] Iteration 27400, lr = 0.00863
I0529 08:27:38.314262 16530 solver.cpp:218] Iteration 27500 (0.87372 iter/s, 114.453s/100 iters), loss = 0.552492
I0529 08:27:38.314414 16530 solver.cpp:237]     Train net output #0: loss = 0.552492 (* 1 = 0.552492 loss)
I0529 08:27:38.314426 16530 sgd_solver.cpp:105] Iteration 27500, lr = 0.008625
I0529 08:29:32.765538 16530 solver.cpp:218] Iteration 27600 (0.873743 iter/s, 114.45s/100 iters), loss = 0.841119
I0529 08:29:32.765710 16530 solver.cpp:237]     Train net output #0: loss = 0.841119 (* 1 = 0.841119 loss)
I0529 08:29:32.765733 16530 sgd_solver.cpp:105] Iteration 27600, lr = 0.00862
I0529 08:31:27.212652 16530 solver.cpp:218] Iteration 27700 (0.873775 iter/s, 114.446s/100 iters), loss = 0.829529
I0529 08:31:27.212803 16530 solver.cpp:237]     Train net output #0: loss = 0.829529 (* 1 = 0.829529 loss)
I0529 08:31:27.212816 16530 sgd_solver.cpp:105] Iteration 27700, lr = 0.008615
I0529 08:33:21.698767 16530 solver.cpp:218] Iteration 27800 (0.873477 iter/s, 114.485s/100 iters), loss = 0.782853
I0529 08:33:21.698945 16530 solver.cpp:237]     Train net output #0: loss = 0.782853 (* 1 = 0.782853 loss)
I0529 08:33:21.698966 16530 sgd_solver.cpp:105] Iteration 27800, lr = 0.00861
I0529 08:35:16.140540 16530 solver.cpp:218] Iteration 27900 (0.873815 iter/s, 114.441s/100 iters), loss = 0.728786
I0529 08:35:16.140725 16530 solver.cpp:237]     Train net output #0: loss = 0.728786 (* 1 = 0.728786 loss)
I0529 08:35:16.140738 16530 sgd_solver.cpp:105] Iteration 27900, lr = 0.008605
I0529 08:37:09.457984 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_28000.caffemodel
I0529 08:37:10.048678 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_28000.solverstate
I0529 08:37:10.156589 16530 solver.cpp:330] Iteration 28000, Testing net (#0)
I0529 08:37:34.870932 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:38:41.077653 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:39:47.172190 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:40:04.027961 16530 solver.cpp:397]     Test net output #0: accuracy = 0.465927
I0529 08:40:04.028020 16530 solver.cpp:397]     Test net output #1: loss = 1.31797 (* 1 = 1.31797 loss)
I0529 08:40:05.163161 16530 solver.cpp:218] Iteration 28000 (0.345997 iter/s, 289.02s/100 iters), loss = 0.760423
I0529 08:40:05.163223 16530 solver.cpp:237]     Train net output #0: loss = 0.760423 (* 1 = 0.760423 loss)
I0529 08:40:05.163235 16530 sgd_solver.cpp:105] Iteration 28000, lr = 0.0086
I0529 08:41:59.717320 16530 solver.cpp:218] Iteration 28100 (0.872957 iter/s, 114.553s/100 iters), loss = 0.665645
I0529 08:41:59.717469 16530 solver.cpp:237]     Train net output #0: loss = 0.665645 (* 1 = 0.665645 loss)
I0529 08:41:59.717483 16530 sgd_solver.cpp:105] Iteration 28100, lr = 0.008595
I0529 08:42:25.060719 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:43:54.261595 16530 solver.cpp:218] Iteration 28200 (0.873033 iter/s, 114.543s/100 iters), loss = 0.540943
I0529 08:43:54.261732 16530 solver.cpp:237]     Train net output #0: loss = 0.540943 (* 1 = 0.540943 loss)
I0529 08:43:54.261745 16530 sgd_solver.cpp:105] Iteration 28200, lr = 0.00859
I0529 08:45:48.775691 16530 solver.cpp:218] Iteration 28300 (0.873263 iter/s, 114.513s/100 iters), loss = 0.778576
I0529 08:45:48.775880 16530 solver.cpp:237]     Train net output #0: loss = 0.778576 (* 1 = 0.778576 loss)
I0529 08:45:48.775900 16530 sgd_solver.cpp:105] Iteration 28300, lr = 0.008585
I0529 08:47:43.314870 16530 solver.cpp:218] Iteration 28400 (0.873072 iter/s, 114.538s/100 iters), loss = 1.09365
I0529 08:47:43.315069 16530 solver.cpp:237]     Train net output #0: loss = 1.09365 (* 1 = 1.09365 loss)
I0529 08:47:43.315081 16530 sgd_solver.cpp:105] Iteration 28400, lr = 0.00858
I0529 08:49:37.794072 16530 solver.cpp:218] Iteration 28500 (0.87353 iter/s, 114.478s/100 iters), loss = 0.644589
I0529 08:49:37.794236 16530 solver.cpp:237]     Train net output #0: loss = 0.644589 (* 1 = 0.644589 loss)
I0529 08:49:37.794275 16530 sgd_solver.cpp:105] Iteration 28500, lr = 0.008575
I0529 08:51:32.322298 16530 solver.cpp:218] Iteration 28600 (0.873156 iter/s, 114.527s/100 iters), loss = 0.792008
I0529 08:51:32.322438 16530 solver.cpp:237]     Train net output #0: loss = 0.792008 (* 1 = 0.792008 loss)
I0529 08:51:32.322450 16530 sgd_solver.cpp:105] Iteration 28600, lr = 0.00857
I0529 08:53:26.878904 16530 solver.cpp:218] Iteration 28700 (0.872939 iter/s, 114.555s/100 iters), loss = 0.551414
I0529 08:53:26.879097 16530 solver.cpp:237]     Train net output #0: loss = 0.551414 (* 1 = 0.551414 loss)
I0529 08:53:26.879109 16530 sgd_solver.cpp:105] Iteration 28700, lr = 0.008565
I0529 08:55:21.432104 16530 solver.cpp:218] Iteration 28800 (0.872966 iter/s, 114.552s/100 iters), loss = 0.776598
I0529 08:55:21.432301 16530 solver.cpp:237]     Train net output #0: loss = 0.776598 (* 1 = 0.776598 loss)
I0529 08:55:21.432314 16530 sgd_solver.cpp:105] Iteration 28800, lr = 0.00856
I0529 08:57:15.964416 16530 solver.cpp:218] Iteration 28900 (0.873125 iter/s, 114.531s/100 iters), loss = 1.02023
I0529 08:57:15.964566 16530 solver.cpp:237]     Train net output #0: loss = 1.02023 (* 1 = 1.02023 loss)
I0529 08:57:15.964579 16530 sgd_solver.cpp:105] Iteration 28900, lr = 0.008555
I0529 08:57:19.553791 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:59:09.352216 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_29000.caffemodel
I0529 08:59:09.891914 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_29000.solverstate
I0529 08:59:09.999622 16530 solver.cpp:330] Iteration 29000, Testing net (#0)
I0529 08:59:59.222332 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:01:05.381343 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:02:03.753624 16530 solver.cpp:397]     Test net output #0: accuracy = 0.489408
I0529 09:02:03.753870 16530 solver.cpp:397]     Test net output #1: loss = 1.68036 (* 1 = 1.68036 loss)
I0529 09:02:04.891052 16530 solver.cpp:218] Iteration 29000 (0.346112 iter/s, 288.924s/100 iters), loss = 0.796892
I0529 09:02:04.891113 16530 solver.cpp:237]     Train net output #0: loss = 0.796892 (* 1 = 0.796892 loss)
I0529 09:02:04.891131 16530 sgd_solver.cpp:105] Iteration 29000, lr = 0.00855
I0529 09:03:59.365885 16530 solver.cpp:218] Iteration 29100 (0.873562 iter/s, 114.474s/100 iters), loss = 0.6
I0529 09:03:59.366061 16530 solver.cpp:237]     Train net output #0: loss = 0.6 (* 1 = 0.6 loss)
I0529 09:03:59.366075 16530 sgd_solver.cpp:105] Iteration 29100, lr = 0.008545
I0529 09:05:53.818373 16530 solver.cpp:218] Iteration 29200 (0.873734 iter/s, 114.451s/100 iters), loss = 0.708867
I0529 09:05:53.818522 16530 solver.cpp:237]     Train net output #0: loss = 0.708867 (* 1 = 0.708867 loss)
I0529 09:05:53.818547 16530 sgd_solver.cpp:105] Iteration 29200, lr = 0.00854
I0529 09:07:48.268450 16530 solver.cpp:218] Iteration 29300 (0.873752 iter/s, 114.449s/100 iters), loss = 0.766477
I0529 09:07:48.268594 16530 solver.cpp:237]     Train net output #0: loss = 0.766477 (* 1 = 0.766477 loss)
I0529 09:07:48.268606 16530 sgd_solver.cpp:105] Iteration 29300, lr = 0.008535
I0529 09:09:42.729953 16530 solver.cpp:218] Iteration 29400 (0.873664 iter/s, 114.46s/100 iters), loss = 0.840007
I0529 09:09:42.730136 16530 solver.cpp:237]     Train net output #0: loss = 0.840007 (* 1 = 0.840007 loss)
I0529 09:09:42.730151 16530 sgd_solver.cpp:105] Iteration 29400, lr = 0.00853
I0529 09:11:37.224367 16530 solver.cpp:218] Iteration 29500 (0.873414 iter/s, 114.493s/100 iters), loss = 0.726874
I0529 09:11:37.224520 16530 solver.cpp:237]     Train net output #0: loss = 0.726874 (* 1 = 0.726874 loss)
I0529 09:11:37.224545 16530 sgd_solver.cpp:105] Iteration 29500, lr = 0.008525
I0529 09:13:31.742435 16530 solver.cpp:218] Iteration 29600 (0.873233 iter/s, 114.517s/100 iters), loss = 0.768666
I0529 09:13:31.742586 16530 solver.cpp:237]     Train net output #0: loss = 0.768666 (* 1 = 0.768666 loss)
I0529 09:13:31.742599 16530 sgd_solver.cpp:105] Iteration 29600, lr = 0.00852
I0529 09:15:08.112891 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:15:26.271536 16530 solver.cpp:218] Iteration 29700 (0.873149 iter/s, 114.528s/100 iters), loss = 0.671308
I0529 09:15:26.271606 16530 solver.cpp:237]     Train net output #0: loss = 0.671308 (* 1 = 0.671308 loss)
I0529 09:15:26.271617 16530 sgd_solver.cpp:105] Iteration 29700, lr = 0.008515
I0529 09:17:20.762575 16530 solver.cpp:218] Iteration 29800 (0.873439 iter/s, 114.49s/100 iters), loss = 0.789209
I0529 09:17:20.762708 16530 solver.cpp:237]     Train net output #0: loss = 0.789209 (* 1 = 0.789209 loss)
I0529 09:17:20.762722 16530 sgd_solver.cpp:105] Iteration 29800, lr = 0.00851
I0529 09:19:15.274062 16530 solver.cpp:218] Iteration 29900 (0.873283 iter/s, 114.51s/100 iters), loss = 1.03521
I0529 09:19:15.274219 16530 solver.cpp:237]     Train net output #0: loss = 1.03521 (* 1 = 1.03521 loss)
I0529 09:19:15.274232 16530 sgd_solver.cpp:105] Iteration 29900, lr = 0.008505
I0529 09:21:08.666851 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_30000.caffemodel
I0529 09:21:09.213160 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_30000.solverstate
I0529 09:21:09.321223 16530 solver.cpp:330] Iteration 30000, Testing net (#0)
I0529 09:21:16.990336 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:22:23.111961 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:23:29.361232 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:24:03.344889 16530 solver.cpp:397]     Test net output #0: accuracy = 0.485982
I0529 09:24:03.345083 16530 solver.cpp:397]     Test net output #1: loss = 1.57242 (* 1 = 1.57242 loss)
I0529 09:24:04.480813 16530 solver.cpp:218] Iteration 30000 (0.345776 iter/s, 289.204s/100 iters), loss = 0.879031
I0529 09:24:04.480875 16530 solver.cpp:237]     Train net output #0: loss = 0.879031 (* 1 = 0.879031 loss)
I0529 09:24:04.480886 16530 sgd_solver.cpp:105] Iteration 30000, lr = 0.0085
I0529 09:25:59.049835 16530 solver.cpp:218] Iteration 30100 (0.872844 iter/s, 114.568s/100 iters), loss = 0.717131
I0529 09:25:59.050019 16530 solver.cpp:237]     Train net output #0: loss = 0.717131 (* 1 = 0.717131 loss)
I0529 09:25:59.050031 16530 sgd_solver.cpp:105] Iteration 30100, lr = 0.008495
I0529 09:27:53.666779 16530 solver.cpp:218] Iteration 30200 (0.87248 iter/s, 114.616s/100 iters), loss = 0.794901
I0529 09:27:53.666978 16530 solver.cpp:237]     Train net output #0: loss = 0.794901 (* 1 = 0.794901 loss)
I0529 09:27:53.666995 16530 sgd_solver.cpp:105] Iteration 30200, lr = 0.00849
I0529 09:29:48.277977 16530 solver.cpp:218] Iteration 30300 (0.872524 iter/s, 114.61s/100 iters), loss = 0.719205
I0529 09:29:48.278107 16530 solver.cpp:237]     Train net output #0: loss = 0.719205 (* 1 = 0.719205 loss)
I0529 09:29:48.278129 16530 sgd_solver.cpp:105] Iteration 30300, lr = 0.008485
I0529 09:31:42.866802 16530 solver.cpp:218] Iteration 30400 (0.872694 iter/s, 114.588s/100 iters), loss = 0.621256
I0529 09:31:42.866935 16530 solver.cpp:237]     Train net output #0: loss = 0.621256 (* 1 = 0.621256 loss)
I0529 09:31:42.866948 16530 sgd_solver.cpp:105] Iteration 30400, lr = 0.00848
I0529 09:32:57.526209 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:33:37.451429 16530 solver.cpp:218] Iteration 30500 (0.872726 iter/s, 114.584s/100 iters), loss = 0.659637
I0529 09:33:37.451611 16530 solver.cpp:237]     Train net output #0: loss = 0.659637 (* 1 = 0.659637 loss)
I0529 09:33:37.451630 16530 sgd_solver.cpp:105] Iteration 30500, lr = 0.008475
I0529 09:35:32.014055 16530 solver.cpp:218] Iteration 30600 (0.872894 iter/s, 114.561s/100 iters), loss = 0.751262
I0529 09:35:32.014256 16530 solver.cpp:237]     Train net output #0: loss = 0.751262 (* 1 = 0.751262 loss)
I0529 09:35:32.014267 16530 sgd_solver.cpp:105] Iteration 30600, lr = 0.00847
I0529 09:37:26.581790 16530 solver.cpp:218] Iteration 30700 (0.872855 iter/s, 114.567s/100 iters), loss = 0.756088
I0529 09:37:26.581933 16530 solver.cpp:237]     Train net output #0: loss = 0.756088 (* 1 = 0.756088 loss)
I0529 09:37:26.581946 16530 sgd_solver.cpp:105] Iteration 30700, lr = 0.008465
I0529 09:39:21.120954 16530 solver.cpp:218] Iteration 30800 (0.873072 iter/s, 114.538s/100 iters), loss = 0.670424
I0529 09:39:21.121110 16530 solver.cpp:237]     Train net output #0: loss = 0.670424 (* 1 = 0.670424 loss)
I0529 09:39:21.121134 16530 sgd_solver.cpp:105] Iteration 30800, lr = 0.00846
I0529 09:41:15.674085 16530 solver.cpp:218] Iteration 30900 (0.872966 iter/s, 114.552s/100 iters), loss = 0.567268
I0529 09:41:15.674271 16530 solver.cpp:237]     Train net output #0: loss = 0.567268 (* 1 = 0.567268 loss)
I0529 09:41:15.674284 16530 sgd_solver.cpp:105] Iteration 30900, lr = 0.008455
I0529 09:43:09.117347 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_31000.caffemodel
I0529 09:43:09.870224 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_31000.solverstate
I0529 09:43:09.978142 16530 solver.cpp:330] Iteration 31000, Testing net (#0)
I0529 09:43:42.163817 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:44:48.458060 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:45:54.623221 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:46:04.048359 16530 solver.cpp:397]     Test net output #0: accuracy = 0.491978
I0529 09:46:04.048436 16530 solver.cpp:397]     Test net output #1: loss = 1.54982 (* 1 = 1.54982 loss)
I0529 09:46:05.189157 16530 solver.cpp:218] Iteration 31000 (0.345408 iter/s, 289.512s/100 iters), loss = 1.05952
I0529 09:46:05.189216 16530 solver.cpp:237]     Train net output #0: loss = 1.05952 (* 1 = 1.05952 loss)
I0529 09:46:05.189241 16530 sgd_solver.cpp:105] Iteration 31000, lr = 0.00845
I0529 09:47:59.802767 16530 solver.cpp:218] Iteration 31100 (0.872505 iter/s, 114.613s/100 iters), loss = 0.70173
I0529 09:47:59.802973 16530 solver.cpp:237]     Train net output #0: loss = 0.70173 (* 1 = 0.70173 loss)
I0529 09:47:59.802999 16530 sgd_solver.cpp:105] Iteration 31100, lr = 0.008445
I0529 09:49:54.397825 16530 solver.cpp:218] Iteration 31200 (0.872647 iter/s, 114.594s/100 iters), loss = 0.711852
I0529 09:49:54.397982 16530 solver.cpp:237]     Train net output #0: loss = 0.711852 (* 1 = 0.711852 loss)
I0529 09:49:54.397994 16530 sgd_solver.cpp:105] Iteration 31200, lr = 0.00844
I0529 09:50:48.407361 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:51:48.984058 16530 solver.cpp:218] Iteration 31300 (0.872714 iter/s, 114.585s/100 iters), loss = 0.510578
I0529 09:51:48.984246 16530 solver.cpp:237]     Train net output #0: loss = 0.510578 (* 1 = 0.510578 loss)
I0529 09:51:48.984269 16530 sgd_solver.cpp:105] Iteration 31300, lr = 0.008435
I0529 09:53:43.581600 16530 solver.cpp:218] Iteration 31400 (0.872628 iter/s, 114.596s/100 iters), loss = 0.59074
I0529 09:53:43.581785 16530 solver.cpp:237]     Train net output #0: loss = 0.59074 (* 1 = 0.59074 loss)
I0529 09:53:43.581799 16530 sgd_solver.cpp:105] Iteration 31400, lr = 0.00843
I0529 09:55:38.218130 16530 solver.cpp:218] Iteration 31500 (0.872332 iter/s, 114.635s/100 iters), loss = 0.601778
I0529 09:55:38.218283 16530 solver.cpp:237]     Train net output #0: loss = 0.601778 (* 1 = 0.601778 loss)
I0529 09:55:38.218309 16530 sgd_solver.cpp:105] Iteration 31500, lr = 0.008425
I0529 09:57:32.870920 16530 solver.cpp:218] Iteration 31600 (0.872208 iter/s, 114.652s/100 iters), loss = 0.837217
I0529 09:57:32.871140 16530 solver.cpp:237]     Train net output #0: loss = 0.837217 (* 1 = 0.837217 loss)
I0529 09:57:32.871156 16530 sgd_solver.cpp:105] Iteration 31600, lr = 0.00842
I0529 09:59:27.467195 16530 solver.cpp:218] Iteration 31700 (0.872638 iter/s, 114.595s/100 iters), loss = 0.639731
I0529 09:59:27.467402 16530 solver.cpp:237]     Train net output #0: loss = 0.639731 (* 1 = 0.639731 loss)
I0529 09:59:27.467414 16530 sgd_solver.cpp:105] Iteration 31700, lr = 0.008415
I0529 10:01:22.068594 16530 solver.cpp:218] Iteration 31800 (0.872599 iter/s, 114.6s/100 iters), loss = 0.495433
I0529 10:01:22.068800 16530 solver.cpp:237]     Train net output #0: loss = 0.495433 (* 1 = 0.495433 loss)
I0529 10:01:22.068812 16530 sgd_solver.cpp:105] Iteration 31800, lr = 0.00841
I0529 10:03:16.637421 16530 solver.cpp:218] Iteration 31900 (0.872847 iter/s, 114.568s/100 iters), loss = 0.869606
I0529 10:03:16.637575 16530 solver.cpp:237]     Train net output #0: loss = 0.869606 (* 1 = 0.869606 loss)
I0529 10:03:16.637588 16530 sgd_solver.cpp:105] Iteration 31900, lr = 0.008405
I0529 10:05:10.063238 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_32000.caffemodel
I0529 10:05:10.698164 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_32000.solverstate
I0529 10:05:10.806669 16530 solver.cpp:330] Iteration 32000, Testing net (#0)
I0529 10:06:07.524039 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:07:13.727284 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:08:04.730536 16530 solver.cpp:397]     Test net output #0: accuracy = 0.478155
I0529 10:08:04.730726 16530 solver.cpp:397]     Test net output #1: loss = 1.46312 (* 1 = 1.46312 loss)
I0529 10:08:05.866518 16530 solver.cpp:218] Iteration 32000 (0.34575 iter/s, 289.226s/100 iters), loss = 0.772784
I0529 10:08:05.866587 16530 solver.cpp:237]     Train net output #0: loss = 0.772784 (* 1 = 0.772784 loss)
I0529 10:08:05.866600 16530 sgd_solver.cpp:105] Iteration 32000, lr = 0.0084
I0529 10:08:38.089876 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:10:00.430943 16530 solver.cpp:218] Iteration 32100 (0.87288 iter/s, 114.563s/100 iters), loss = 0.652562
I0529 10:10:00.431110 16530 solver.cpp:237]     Train net output #0: loss = 0.652562 (* 1 = 0.652562 loss)
I0529 10:10:00.431131 16530 sgd_solver.cpp:105] Iteration 32100, lr = 0.008395
I0529 10:11:55.029739 16530 solver.cpp:218] Iteration 32200 (0.872619 iter/s, 114.598s/100 iters), loss = 0.754108
I0529 10:11:55.030006 16530 solver.cpp:237]     Train net output #0: loss = 0.754108 (* 1 = 0.754108 loss)
I0529 10:11:55.030019 16530 sgd_solver.cpp:105] Iteration 32200, lr = 0.00839
I0529 10:13:49.605208 16530 solver.cpp:218] Iteration 32300 (0.872797 iter/s, 114.574s/100 iters), loss = 0.539449
I0529 10:13:49.605381 16530 solver.cpp:237]     Train net output #0: loss = 0.539449 (* 1 = 0.539449 loss)
I0529 10:13:49.605415 16530 sgd_solver.cpp:105] Iteration 32300, lr = 0.008385
I0529 10:15:44.188951 16530 solver.cpp:218] Iteration 32400 (0.872733 iter/s, 114.583s/100 iters), loss = 0.517195
I0529 10:15:44.189093 16530 solver.cpp:237]     Train net output #0: loss = 0.517195 (* 1 = 0.517195 loss)
I0529 10:15:44.189106 16530 sgd_solver.cpp:105] Iteration 32400, lr = 0.00838
I0529 10:17:38.771195 16530 solver.cpp:218] Iteration 32500 (0.872745 iter/s, 114.581s/100 iters), loss = 0.735249
I0529 10:17:38.771347 16530 solver.cpp:237]     Train net output #0: loss = 0.735249 (* 1 = 0.735249 loss)
I0529 10:17:38.771387 16530 sgd_solver.cpp:105] Iteration 32500, lr = 0.008375
I0529 10:19:33.375264 16530 solver.cpp:218] Iteration 32600 (0.872578 iter/s, 114.603s/100 iters), loss = 0.735089
I0529 10:19:33.375411 16530 solver.cpp:237]     Train net output #0: loss = 0.735089 (* 1 = 0.735089 loss)
I0529 10:19:33.375432 16530 sgd_solver.cpp:105] Iteration 32600, lr = 0.00837
I0529 10:21:27.955883 16530 solver.cpp:218] Iteration 32700 (0.872757 iter/s, 114.579s/100 iters), loss = 0.673091
I0529 10:21:27.956081 16530 solver.cpp:237]     Train net output #0: loss = 0.673091 (* 1 = 0.673091 loss)
I0529 10:21:27.956095 16530 sgd_solver.cpp:105] Iteration 32700, lr = 0.008365
I0529 10:23:22.566231 16530 solver.cpp:218] Iteration 32800 (0.872531 iter/s, 114.609s/100 iters), loss = 0.704338
I0529 10:23:22.566416 16530 solver.cpp:237]     Train net output #0: loss = 0.704338 (* 1 = 0.704338 loss)
I0529 10:23:22.566452 16530 sgd_solver.cpp:105] Iteration 32800, lr = 0.00836
I0529 10:23:33.051790 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:25:17.165242 16530 solver.cpp:218] Iteration 32900 (0.872617 iter/s, 114.598s/100 iters), loss = 0.694734
I0529 10:25:17.165428 16530 solver.cpp:237]     Train net output #0: loss = 0.694734 (* 1 = 0.694734 loss)
I0529 10:25:17.165441 16530 sgd_solver.cpp:105] Iteration 32900, lr = 0.008355
I0529 10:27:10.596478 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_33000.caffemodel
I0529 10:27:10.920405 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_33000.solverstate
I0529 10:27:11.028949 16530 solver.cpp:330] Iteration 33000, Testing net (#0)
I0529 10:27:26.135385 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:28:32.253633 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:29:38.485188 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:30:04.980481 16530 solver.cpp:397]     Test net output #0: accuracy = 0.398053
I0529 10:30:04.980556 16530 solver.cpp:397]     Test net output #1: loss = 1.85781 (* 1 = 1.85781 loss)
I0529 10:30:06.117224 16530 solver.cpp:218] Iteration 33000 (0.346082 iter/s, 288.949s/100 iters), loss = 0.667996
I0529 10:30:06.117286 16530 solver.cpp:237]     Train net output #0: loss = 0.667996 (* 1 = 0.667996 loss)
I0529 10:30:06.117300 16530 sgd_solver.cpp:105] Iteration 33000, lr = 0.00835
I0529 10:32:00.707599 16530 solver.cpp:218] Iteration 33100 (0.872682 iter/s, 114.589s/100 iters), loss = 0.757436
I0529 10:32:00.707864 16530 solver.cpp:237]     Train net output #0: loss = 0.757436 (* 1 = 0.757436 loss)
I0529 10:32:00.707880 16530 sgd_solver.cpp:105] Iteration 33100, lr = 0.008345
I0529 10:33:55.318102 16530 solver.cpp:218] Iteration 33200 (0.87253 iter/s, 114.609s/100 iters), loss = 0.726766
I0529 10:33:55.318400 16530 solver.cpp:237]     Train net output #0: loss = 0.726766 (* 1 = 0.726766 loss)
I0529 10:33:55.318413 16530 sgd_solver.cpp:105] Iteration 33200, lr = 0.00834
I0529 10:35:49.914563 16530 solver.cpp:218] Iteration 33300 (0.872638 iter/s, 114.595s/100 iters), loss = 0.784625
I0529 10:35:49.914710 16530 solver.cpp:237]     Train net output #0: loss = 0.784625 (* 1 = 0.784625 loss)
I0529 10:35:49.914722 16530 sgd_solver.cpp:105] Iteration 33300, lr = 0.008335
I0529 10:37:44.514063 16530 solver.cpp:218] Iteration 33400 (0.872613 iter/s, 114.598s/100 iters), loss = 0.738935
I0529 10:37:44.514235 16530 solver.cpp:237]     Train net output #0: loss = 0.738935 (* 1 = 0.738935 loss)
I0529 10:37:44.514252 16530 sgd_solver.cpp:105] Iteration 33400, lr = 0.00833
I0529 10:39:39.084369 16530 solver.cpp:218] Iteration 33500 (0.872836 iter/s, 114.569s/100 iters), loss = 0.760051
I0529 10:39:39.084475 16530 solver.cpp:237]     Train net output #0: loss = 0.760051 (* 1 = 0.760051 loss)
I0529 10:39:39.084486 16530 sgd_solver.cpp:105] Iteration 33500, lr = 0.008325
I0529 10:41:23.488615 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:41:33.665076 16530 solver.cpp:218] Iteration 33600 (0.872756 iter/s, 114.58s/100 iters), loss = 0.492684
I0529 10:41:33.665144 16530 solver.cpp:237]     Train net output #0: loss = 0.492684 (* 1 = 0.492684 loss)
I0529 10:41:33.665158 16530 sgd_solver.cpp:105] Iteration 33600, lr = 0.00832
I0529 10:43:28.277130 16530 solver.cpp:218] Iteration 33700 (0.872517 iter/s, 114.611s/100 iters), loss = 0.700173
I0529 10:43:28.277235 16530 solver.cpp:237]     Train net output #0: loss = 0.700173 (* 1 = 0.700173 loss)
I0529 10:43:28.277248 16530 sgd_solver.cpp:105] Iteration 33700, lr = 0.008315
I0529 10:45:22.910308 16530 solver.cpp:218] Iteration 33800 (0.872357 iter/s, 114.632s/100 iters), loss = 0.776783
I0529 10:45:22.910394 16530 solver.cpp:237]     Train net output #0: loss = 0.776783 (* 1 = 0.776783 loss)
I0529 10:45:22.910406 16530 sgd_solver.cpp:105] Iteration 33800, lr = 0.00831
I0529 10:47:17.535408 16530 solver.cpp:218] Iteration 33900 (0.872418 iter/s, 114.624s/100 iters), loss = 0.476305
I0529 10:47:17.535564 16530 solver.cpp:237]     Train net output #0: loss = 0.476305 (* 1 = 0.476305 loss)
I0529 10:47:17.535579 16530 sgd_solver.cpp:105] Iteration 33900, lr = 0.008305
I0529 10:49:10.979884 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_34000.caffemodel
I0529 10:49:11.628747 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_34000.solverstate
I0529 10:49:11.737673 16530 solver.cpp:330] Iteration 34000, Testing net (#0)
I0529 10:49:51.373283 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:50:57.492424 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:52:03.724813 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:52:05.696290 16530 solver.cpp:397]     Test net output #0: accuracy = 0.478038
I0529 10:52:05.696353 16530 solver.cpp:397]     Test net output #1: loss = 1.64309 (* 1 = 1.64309 loss)
I0529 10:52:06.833199 16530 solver.cpp:218] Iteration 34000 (0.345668 iter/s, 289.295s/100 iters), loss = 0.61377
I0529 10:52:06.833262 16530 solver.cpp:237]     Train net output #0: loss = 0.61377 (* 1 = 0.61377 loss)
I0529 10:52:06.833274 16530 sgd_solver.cpp:105] Iteration 34000, lr = 0.0083
I0529 10:54:01.416146 16530 solver.cpp:218] Iteration 34100 (0.872739 iter/s, 114.582s/100 iters), loss = 0.77099
I0529 10:54:01.416319 16530 solver.cpp:237]     Train net output #0: loss = 0.77099 (* 1 = 0.77099 loss)
I0529 10:54:01.416332 16530 sgd_solver.cpp:105] Iteration 34100, lr = 0.008295
I0529 10:55:55.945183 16530 solver.cpp:218] Iteration 34200 (0.873151 iter/s, 114.528s/100 iters), loss = 0.732101
I0529 10:55:55.945358 16530 solver.cpp:237]     Train net output #0: loss = 0.732101 (* 1 = 0.732101 loss)
I0529 10:55:55.945371 16530 sgd_solver.cpp:105] Iteration 34200, lr = 0.00829
I0529 10:57:50.512657 16530 solver.cpp:218] Iteration 34300 (0.872858 iter/s, 114.566s/100 iters), loss = 0.733711
I0529 10:57:50.512817 16530 solver.cpp:237]     Train net output #0: loss = 0.733711 (* 1 = 0.733711 loss)
I0529 10:57:50.512830 16530 sgd_solver.cpp:105] Iteration 34300, lr = 0.008285
I0529 10:59:13.143033 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:59:45.073096 16530 solver.cpp:218] Iteration 34400 (0.872911 iter/s, 114.559s/100 iters), loss = 0.491943
I0529 10:59:45.073204 16530 solver.cpp:237]     Train net output #0: loss = 0.491943 (* 1 = 0.491943 loss)
I0529 10:59:45.073216 16530 sgd_solver.cpp:105] Iteration 34400, lr = 0.00828
I0529 11:01:39.639144 16530 solver.cpp:218] Iteration 34500 (0.872868 iter/s, 114.565s/100 iters), loss = 0.637416
I0529 11:01:39.639333 16530 solver.cpp:237]     Train net output #0: loss = 0.637416 (* 1 = 0.637416 loss)
I0529 11:01:39.639364 16530 sgd_solver.cpp:105] Iteration 34500, lr = 0.008275
I0529 11:03:34.171174 16530 solver.cpp:218] Iteration 34600 (0.873128 iter/s, 114.531s/100 iters), loss = 0.679519
I0529 11:03:34.171342 16530 solver.cpp:237]     Train net output #0: loss = 0.679519 (* 1 = 0.679519 loss)
I0529 11:03:34.171382 16530 sgd_solver.cpp:105] Iteration 34600, lr = 0.00827
I0529 11:05:28.703310 16530 solver.cpp:218] Iteration 34700 (0.873127 iter/s, 114.531s/100 iters), loss = 0.612645
I0529 11:05:28.703457 16530 solver.cpp:237]     Train net output #0: loss = 0.612645 (* 1 = 0.612645 loss)
I0529 11:05:28.703469 16530 sgd_solver.cpp:105] Iteration 34700, lr = 0.008265
I0529 11:07:23.283967 16530 solver.cpp:218] Iteration 34800 (0.872757 iter/s, 114.579s/100 iters), loss = 0.556459
I0529 11:07:23.284139 16530 solver.cpp:237]     Train net output #0: loss = 0.556459 (* 1 = 0.556459 loss)
I0529 11:07:23.284157 16530 sgd_solver.cpp:105] Iteration 34800, lr = 0.00826
I0529 11:09:17.826865 16530 solver.cpp:218] Iteration 34900 (0.873045 iter/s, 114.542s/100 iters), loss = 0.762
I0529 11:09:17.827044 16530 solver.cpp:237]     Train net output #0: loss = 0.762 (* 1 = 0.762 loss)
I0529 11:09:17.827057 16530 sgd_solver.cpp:105] Iteration 34900, lr = 0.008255
I0529 11:11:11.201001 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_35000.caffemodel
I0529 11:11:11.565865 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_35000.solverstate
I0529 11:11:11.665030 16530 solver.cpp:330] Iteration 35000, Testing net (#0)
I0529 11:12:15.816869 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:13:21.884374 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:14:05.543524 16530 solver.cpp:397]     Test net output #0: accuracy = 0.462811
I0529 11:14:05.543695 16530 solver.cpp:397]     Test net output #1: loss = 1.51408 (* 1 = 1.51408 loss)
I0529 11:14:06.678354 16530 solver.cpp:218] Iteration 35000 (0.346202 iter/s, 288.849s/100 iters), loss = 0.86987
I0529 11:14:06.678412 16530 solver.cpp:237]     Train net output #0: loss = 0.86987 (* 1 = 0.86987 loss)
I0529 11:14:06.678424 16530 sgd_solver.cpp:105] Iteration 35000, lr = 0.00825
I0529 11:16:01.200539 16530 solver.cpp:218] Iteration 35100 (0.873202 iter/s, 114.521s/100 iters), loss = 0.76032
I0529 11:16:01.200722 16530 solver.cpp:237]     Train net output #0: loss = 0.76032 (* 1 = 0.76032 loss)
I0529 11:16:01.200734 16530 sgd_solver.cpp:105] Iteration 35100, lr = 0.008245
I0529 11:17:02.069555 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:17:55.765480 16530 solver.cpp:218] Iteration 35200 (0.872877 iter/s, 114.564s/100 iters), loss = 0.719569
I0529 11:17:55.765658 16530 solver.cpp:237]     Train net output #0: loss = 0.719569 (* 1 = 0.719569 loss)
I0529 11:17:55.765671 16530 sgd_solver.cpp:105] Iteration 35200, lr = 0.00824
I0529 11:19:50.331197 16530 solver.cpp:218] Iteration 35300 (0.872871 iter/s, 114.564s/100 iters), loss = 0.586019
I0529 11:19:50.331318 16530 solver.cpp:237]     Train net output #0: loss = 0.586019 (* 1 = 0.586019 loss)
I0529 11:19:50.331338 16530 sgd_solver.cpp:105] Iteration 35300, lr = 0.008235
I0529 11:21:44.938761 16530 solver.cpp:218] Iteration 35400 (0.872552 iter/s, 114.606s/100 iters), loss = 0.491771
I0529 11:21:44.938908 16530 solver.cpp:237]     Train net output #0: loss = 0.491771 (* 1 = 0.491771 loss)
I0529 11:21:44.938920 16530 sgd_solver.cpp:105] Iteration 35400, lr = 0.00823
I0529 11:23:39.526868 16530 solver.cpp:218] Iteration 35500 (0.8727 iter/s, 114.587s/100 iters), loss = 0.621593
I0529 11:23:39.527048 16530 solver.cpp:237]     Train net output #0: loss = 0.621593 (* 1 = 0.621593 loss)
I0529 11:23:39.527061 16530 sgd_solver.cpp:105] Iteration 35500, lr = 0.008225
I0529 11:25:34.123426 16530 solver.cpp:218] Iteration 35600 (0.872636 iter/s, 114.595s/100 iters), loss = 0.765416
I0529 11:25:34.123692 16530 solver.cpp:237]     Train net output #0: loss = 0.765416 (* 1 = 0.765416 loss)
I0529 11:25:34.123721 16530 sgd_solver.cpp:105] Iteration 35600, lr = 0.00822
I0529 11:27:28.686872 16530 solver.cpp:218] Iteration 35700 (0.872889 iter/s, 114.562s/100 iters), loss = 0.655595
I0529 11:27:28.687063 16530 solver.cpp:237]     Train net output #0: loss = 0.655595 (* 1 = 0.655595 loss)
I0529 11:27:28.687077 16530 sgd_solver.cpp:105] Iteration 35700, lr = 0.008215
I0529 11:29:23.226640 16530 solver.cpp:218] Iteration 35800 (0.873069 iter/s, 114.538s/100 iters), loss = 0.599288
I0529 11:29:23.226785 16530 solver.cpp:237]     Train net output #0: loss = 0.599288 (* 1 = 0.599288 loss)
I0529 11:29:23.226799 16530 sgd_solver.cpp:105] Iteration 35800, lr = 0.00821
I0529 11:31:17.776368 16530 solver.cpp:218] Iteration 35900 (0.872993 iter/s, 114.549s/100 iters), loss = 0.675884
I0529 11:31:17.776540 16530 solver.cpp:237]     Train net output #0: loss = 0.675884 (* 1 = 0.675884 loss)
I0529 11:31:17.776553 16530 sgd_solver.cpp:105] Iteration 35900, lr = 0.008205
I0529 11:31:56.886957 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:33:11.148988 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_36000.caffemodel
I0529 11:33:11.496256 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_36000.solverstate
I0529 11:33:11.600630 16530 solver.cpp:330] Iteration 36000, Testing net (#0)
I0529 11:33:34.148591 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:34:40.240707 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:35:46.301049 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:36:05.458540 16530 solver.cpp:397]     Test net output #0: accuracy = 0.478855
I0529 11:36:05.458608 16530 solver.cpp:397]     Test net output #1: loss = 1.89159 (* 1 = 1.89159 loss)
I0529 11:36:06.595554 16530 solver.cpp:218] Iteration 36000 (0.346241 iter/s, 288.816s/100 iters), loss = 0.576938
I0529 11:36:06.595614 16530 solver.cpp:237]     Train net output #0: loss = 0.576938 (* 1 = 0.576938 loss)
I0529 11:36:06.595628 16530 sgd_solver.cpp:105] Iteration 36000, lr = 0.0082
I0529 11:38:01.080781 16530 solver.cpp:218] Iteration 36100 (0.873483 iter/s, 114.484s/100 iters), loss = 0.891958
I0529 11:38:01.081027 16530 solver.cpp:237]     Train net output #0: loss = 0.891958 (* 1 = 0.891958 loss)
I0529 11:38:01.081069 16530 sgd_solver.cpp:105] Iteration 36100, lr = 0.008195
I0529 11:39:55.603152 16530 solver.cpp:218] Iteration 36200 (0.8732 iter/s, 114.521s/100 iters), loss = 0.478903
I0529 11:39:55.603305 16530 solver.cpp:237]     Train net output #0: loss = 0.478903 (* 1 = 0.478903 loss)
I0529 11:39:55.603319 16530 sgd_solver.cpp:105] Iteration 36200, lr = 0.00819
I0529 11:41:50.100973 16530 solver.cpp:218] Iteration 36300 (0.873387 iter/s, 114.497s/100 iters), loss = 0.711478
I0529 11:41:50.101150 16530 solver.cpp:237]     Train net output #0: loss = 0.711478 (* 1 = 0.711478 loss)
I0529 11:41:50.101191 16530 sgd_solver.cpp:105] Iteration 36300, lr = 0.008185
I0529 11:43:44.589859 16530 solver.cpp:218] Iteration 36400 (0.873455 iter/s, 114.488s/100 iters), loss = 0.644644
I0529 11:43:44.590104 16530 solver.cpp:237]     Train net output #0: loss = 0.644644 (* 1 = 0.644644 loss)
I0529 11:43:44.590142 16530 sgd_solver.cpp:105] Iteration 36400, lr = 0.00818
I0529 11:45:39.088305 16530 solver.cpp:218] Iteration 36500 (0.873384 iter/s, 114.497s/100 iters), loss = 0.559393
I0529 11:45:39.088505 16530 solver.cpp:237]     Train net output #0: loss = 0.559393 (* 1 = 0.559393 loss)
I0529 11:45:39.088517 16530 sgd_solver.cpp:105] Iteration 36500, lr = 0.008175
I0529 11:47:33.612370 16530 solver.cpp:218] Iteration 36600 (0.873189 iter/s, 114.523s/100 iters), loss = 0.433223
I0529 11:47:33.612550 16530 solver.cpp:237]     Train net output #0: loss = 0.433223 (* 1 = 0.433223 loss)
I0529 11:47:33.612563 16530 sgd_solver.cpp:105] Iteration 36600, lr = 0.00817
I0529 11:49:28.121776 16530 solver.cpp:218] Iteration 36700 (0.8733 iter/s, 114.508s/100 iters), loss = 0.594818
I0529 11:49:28.122017 16530 solver.cpp:237]     Train net output #0: loss = 0.594818 (* 1 = 0.594818 loss)
I0529 11:49:28.122043 16530 sgd_solver.cpp:105] Iteration 36700, lr = 0.008165
I0529 11:49:46.583328 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:51:22.635226 16530 solver.cpp:218] Iteration 36800 (0.87327 iter/s, 114.512s/100 iters), loss = 0.481188
I0529 11:51:22.635440 16530 solver.cpp:237]     Train net output #0: loss = 0.481188 (* 1 = 0.481188 loss)
I0529 11:51:22.635464 16530 sgd_solver.cpp:105] Iteration 36800, lr = 0.00816
I0529 11:53:17.176379 16530 solver.cpp:218] Iteration 36900 (0.873058 iter/s, 114.54s/100 iters), loss = 0.752204
I0529 11:53:17.176563 16530 solver.cpp:237]     Train net output #0: loss = 0.752204 (* 1 = 0.752204 loss)
I0529 11:53:17.176589 16530 sgd_solver.cpp:105] Iteration 36900, lr = 0.008155
I0529 11:55:10.580020 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_37000.caffemodel
I0529 11:55:11.293797 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_37000.solverstate
I0529 11:55:11.392040 16530 solver.cpp:330] Iteration 37000, Testing net (#0)
I0529 11:55:58.452289 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:57:04.562260 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:58:05.279310 16530 solver.cpp:397]     Test net output #0: accuracy = 0.434657
I0529 11:58:05.279517 16530 solver.cpp:397]     Test net output #1: loss = 2.47123 (* 1 = 2.47123 loss)
I0529 11:58:06.415346 16530 solver.cpp:218] Iteration 37000 (0.345738 iter/s, 289.236s/100 iters), loss = 0.67942
I0529 11:58:06.415407 16530 solver.cpp:237]     Train net output #0: loss = 0.67942 (* 1 = 0.67942 loss)
I0529 11:58:06.415421 16530 sgd_solver.cpp:105] Iteration 37000, lr = 0.00815
I0529 12:00:00.955340 16530 solver.cpp:218] Iteration 37100 (0.873066 iter/s, 114.539s/100 iters), loss = 0.665926
I0529 12:00:00.955500 16530 solver.cpp:237]     Train net output #0: loss = 0.665926 (* 1 = 0.665926 loss)
I0529 12:00:00.955533 16530 sgd_solver.cpp:105] Iteration 37100, lr = 0.008145
I0529 12:01:55.496059 16530 solver.cpp:218] Iteration 37200 (0.873061 iter/s, 114.539s/100 iters), loss = 0.829081
I0529 12:01:55.496227 16530 solver.cpp:237]     Train net output #0: loss = 0.829081 (* 1 = 0.829081 loss)
I0529 12:01:55.496249 16530 sgd_solver.cpp:105] Iteration 37200, lr = 0.00814
I0529 12:03:50.026710 16530 solver.cpp:218] Iteration 37300 (0.873138 iter/s, 114.529s/100 iters), loss = 0.853595
I0529 12:03:50.026919 16530 solver.cpp:237]     Train net output #0: loss = 0.853595 (* 1 = 0.853595 loss)
I0529 12:03:50.026943 16530 sgd_solver.cpp:105] Iteration 37300, lr = 0.008135
I0529 12:05:44.542829 16530 solver.cpp:218] Iteration 37400 (0.873249 iter/s, 114.515s/100 iters), loss = 0.603936
I0529 12:05:44.543020 16530 solver.cpp:237]     Train net output #0: loss = 0.603936 (* 1 = 0.603936 loss)
I0529 12:05:44.543033 16530 sgd_solver.cpp:105] Iteration 37400, lr = 0.00813
I0529 12:07:35.765846 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:07:39.047782 16530 solver.cpp:218] Iteration 37500 (0.873334 iter/s, 114.504s/100 iters), loss = 0.873385
I0529 12:07:39.047860 16530 solver.cpp:237]     Train net output #0: loss = 0.873385 (* 1 = 0.873385 loss)
I0529 12:07:39.047871 16530 sgd_solver.cpp:105] Iteration 37500, lr = 0.008125
I0529 12:09:33.534740 16530 solver.cpp:218] Iteration 37600 (0.87347 iter/s, 114.486s/100 iters), loss = 0.367903
I0529 12:09:33.534942 16530 solver.cpp:237]     Train net output #0: loss = 0.367903 (* 1 = 0.367903 loss)
I0529 12:09:33.534989 16530 sgd_solver.cpp:105] Iteration 37600, lr = 0.00812
I0529 12:11:28.024284 16530 solver.cpp:218] Iteration 37700 (0.873451 iter/s, 114.488s/100 iters), loss = 0.602515
I0529 12:11:28.024483 16530 solver.cpp:237]     Train net output #0: loss = 0.602515 (* 1 = 0.602515 loss)
I0529 12:11:28.024507 16530 sgd_solver.cpp:105] Iteration 37700, lr = 0.008115
I0529 12:13:22.587896 16530 solver.cpp:218] Iteration 37800 (0.872886 iter/s, 114.562s/100 iters), loss = 0.622004
I0529 12:13:22.588093 16530 solver.cpp:237]     Train net output #0: loss = 0.622004 (* 1 = 0.622004 loss)
I0529 12:13:22.588131 16530 sgd_solver.cpp:105] Iteration 37800, lr = 0.00811
I0529 12:15:17.128823 16530 solver.cpp:218] Iteration 37900 (0.873059 iter/s, 114.54s/100 iters), loss = 0.633889
I0529 12:15:17.128996 16530 solver.cpp:237]     Train net output #0: loss = 0.633889 (* 1 = 0.633889 loss)
I0529 12:15:17.129009 16530 sgd_solver.cpp:105] Iteration 37900, lr = 0.008105
I0529 12:17:10.555869 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_38000.caffemodel
I0529 12:17:10.911427 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_38000.solverstate
I0529 12:17:11.015611 16530 solver.cpp:330] Iteration 38000, Testing net (#0)
I0529 12:17:16.366458 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:18:22.606824 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:19:28.690631 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:20:04.905624 16530 solver.cpp:397]     Test net output #0: accuracy = 0.486916
I0529 12:20:04.905807 16530 solver.cpp:397]     Test net output #1: loss = 1.9829 (* 1 = 1.9829 loss)
I0529 12:20:06.044188 16530 solver.cpp:218] Iteration 38000 (0.346125 iter/s, 288.913s/100 iters), loss = 0.820403
I0529 12:20:06.044250 16530 solver.cpp:237]     Train net output #0: loss = 0.820403 (* 1 = 0.820403 loss)
I0529 12:20:06.044262 16530 sgd_solver.cpp:105] Iteration 38000, lr = 0.0081
I0529 12:22:00.600356 16530 solver.cpp:218] Iteration 38100 (0.872943 iter/s, 114.555s/100 iters), loss = 0.473939
I0529 12:22:00.600538 16530 solver.cpp:237]     Train net output #0: loss = 0.473939 (* 1 = 0.473939 loss)
I0529 12:22:00.600550 16530 sgd_solver.cpp:105] Iteration 38100, lr = 0.008095
I0529 12:23:55.146461 16530 solver.cpp:218] Iteration 38200 (0.87302 iter/s, 114.545s/100 iters), loss = 0.416883
I0529 12:23:55.146610 16530 solver.cpp:237]     Train net output #0: loss = 0.416883 (* 1 = 0.416883 loss)
I0529 12:23:55.146625 16530 sgd_solver.cpp:105] Iteration 38200, lr = 0.00809
I0529 12:25:24.684329 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:25:49.723574 16530 solver.cpp:218] Iteration 38300 (0.872783 iter/s, 114.576s/100 iters), loss = 0.657077
I0529 12:25:49.723641 16530 solver.cpp:237]     Train net output #0: loss = 0.657077 (* 1 = 0.657077 loss)
I0529 12:25:49.723652 16530 sgd_solver.cpp:105] Iteration 38300, lr = 0.008085
I0529 12:27:44.255910 16530 solver.cpp:218] Iteration 38400 (0.873124 iter/s, 114.531s/100 iters), loss = 0.608022
I0529 12:27:44.256089 16530 solver.cpp:237]     Train net output #0: loss = 0.608022 (* 1 = 0.608022 loss)
I0529 12:27:44.256101 16530 sgd_solver.cpp:105] Iteration 38400, lr = 0.00808
I0529 12:29:38.805588 16530 solver.cpp:218] Iteration 38500 (0.872992 iter/s, 114.549s/100 iters), loss = 0.377256
I0529 12:29:38.805749 16530 solver.cpp:237]     Train net output #0: loss = 0.377256 (* 1 = 0.377256 loss)
I0529 12:29:38.805784 16530 sgd_solver.cpp:105] Iteration 38500, lr = 0.008075
I0529 12:31:33.369457 16530 solver.cpp:218] Iteration 38600 (0.872884 iter/s, 114.563s/100 iters), loss = 0.559947
I0529 12:31:33.369803 16530 solver.cpp:237]     Train net output #0: loss = 0.559947 (* 1 = 0.559947 loss)
I0529 12:31:33.369817 16530 sgd_solver.cpp:105] Iteration 38600, lr = 0.00807
I0529 12:33:27.873375 16530 solver.cpp:218] Iteration 38700 (0.873342 iter/s, 114.503s/100 iters), loss = 0.501798
I0529 12:33:27.873595 16530 solver.cpp:237]     Train net output #0: loss = 0.501798 (* 1 = 0.501798 loss)
I0529 12:33:27.873608 16530 sgd_solver.cpp:105] Iteration 38700, lr = 0.008065
I0529 12:35:22.395231 16530 solver.cpp:218] Iteration 38800 (0.873204 iter/s, 114.521s/100 iters), loss = 0.603043
I0529 12:35:22.395450 16530 solver.cpp:237]     Train net output #0: loss = 0.603043 (* 1 = 0.603043 loss)
I0529 12:35:22.395462 16530 sgd_solver.cpp:105] Iteration 38800, lr = 0.00806
I0529 12:37:16.909703 16530 solver.cpp:218] Iteration 38900 (0.873261 iter/s, 114.513s/100 iters), loss = 0.539613
I0529 12:37:16.909901 16530 solver.cpp:237]     Train net output #0: loss = 0.539613 (* 1 = 0.539613 loss)
I0529 12:37:16.909925 16530 sgd_solver.cpp:105] Iteration 38900, lr = 0.008055
I0529 12:39:10.293278 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_39000.caffemodel
I0529 12:39:10.897164 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_39000.solverstate
I0529 12:39:11.005868 16530 solver.cpp:330] Iteration 39000, Testing net (#0)
I0529 12:39:40.989267 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:40:47.057978 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:41:53.117228 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:42:04.822405 16530 solver.cpp:397]     Test net output #0: accuracy = 0.424299
I0529 12:42:04.822474 16530 solver.cpp:397]     Test net output #1: loss = 2.09718 (* 1 = 2.09718 loss)
I0529 12:42:05.962440 16530 solver.cpp:218] Iteration 39000 (0.345961 iter/s, 289.05s/100 iters), loss = 0.558101
I0529 12:42:05.962501 16530 solver.cpp:237]     Train net output #0: loss = 0.558101 (* 1 = 0.558101 loss)
I0529 12:42:05.962512 16530 sgd_solver.cpp:105] Iteration 39000, lr = 0.00805
I0529 12:43:13.704777 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:44:00.503068 16530 solver.cpp:218] Iteration 39100 (0.87306 iter/s, 114.54s/100 iters), loss = 0.507145
I0529 12:44:00.503294 16530 solver.cpp:237]     Train net output #0: loss = 0.507145 (* 1 = 0.507145 loss)
I0529 12:44:00.503309 16530 sgd_solver.cpp:105] Iteration 39100, lr = 0.008045
I0529 12:45:55.029291 16530 solver.cpp:218] Iteration 39200 (0.873172 iter/s, 114.525s/100 iters), loss = 0.28921
I0529 12:45:55.029456 16530 solver.cpp:237]     Train net output #0: loss = 0.28921 (* 1 = 0.28921 loss)
I0529 12:45:55.029469 16530 sgd_solver.cpp:105] Iteration 39200, lr = 0.00804
I0529 12:47:49.622694 16530 solver.cpp:218] Iteration 39300 (0.872659 iter/s, 114.592s/100 iters), loss = 0.689746
I0529 12:47:49.622918 16530 solver.cpp:237]     Train net output #0: loss = 0.689746 (* 1 = 0.689746 loss)
I0529 12:47:49.622942 16530 sgd_solver.cpp:105] Iteration 39300, lr = 0.008035
I0529 12:49:44.223202 16530 solver.cpp:218] Iteration 39400 (0.872606 iter/s, 114.599s/100 iters), loss = 0.570453
I0529 12:49:44.223347 16530 solver.cpp:237]     Train net output #0: loss = 0.570453 (* 1 = 0.570453 loss)
I0529 12:49:44.223361 16530 sgd_solver.cpp:105] Iteration 39400, lr = 0.00803
I0529 12:51:38.792677 16530 solver.cpp:218] Iteration 39500 (0.872841 iter/s, 114.568s/100 iters), loss = 0.561813
I0529 12:51:38.792914 16530 solver.cpp:237]     Train net output #0: loss = 0.561813 (* 1 = 0.561813 loss)
I0529 12:51:38.792928 16530 sgd_solver.cpp:105] Iteration 39500, lr = 0.008025
I0529 12:53:33.397567 16530 solver.cpp:218] Iteration 39600 (0.872572 iter/s, 114.604s/100 iters), loss = 0.638402
I0529 12:53:33.397853 16530 solver.cpp:237]     Train net output #0: loss = 0.638402 (* 1 = 0.638402 loss)
I0529 12:53:33.397876 16530 sgd_solver.cpp:105] Iteration 39600, lr = 0.00802
I0529 12:55:28.020699 16530 solver.cpp:218] Iteration 39700 (0.872434 iter/s, 114.622s/100 iters), loss = 0.825827
I0529 12:55:28.020884 16530 solver.cpp:237]     Train net output #0: loss = 0.825827 (* 1 = 0.825827 loss)
I0529 12:55:28.020897 16530 sgd_solver.cpp:105] Iteration 39700, lr = 0.008015
I0529 12:57:22.659613 16530 solver.cpp:218] Iteration 39800 (0.872313 iter/s, 114.638s/100 iters), loss = 0.463735
I0529 12:57:22.659812 16530 solver.cpp:237]     Train net output #0: loss = 0.463734 (* 1 = 0.463734 loss)
I0529 12:57:22.659857 16530 sgd_solver.cpp:105] Iteration 39800, lr = 0.00801
I0529 12:58:09.788836 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:59:17.235857 16530 solver.cpp:218] Iteration 39900 (0.87279 iter/s, 114.575s/100 iters), loss = 0.457684
I0529 12:59:17.236039 16530 solver.cpp:237]     Train net output #0: loss = 0.457684 (* 1 = 0.457684 loss)
I0529 12:59:17.236062 16530 sgd_solver.cpp:105] Iteration 39900, lr = 0.008005
I0529 13:01:10.679356 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_40000.caffemodel
I0529 13:01:10.996951 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_40000.solverstate
I0529 13:01:11.108301 16530 solver.cpp:330] Iteration 40000, Testing net (#0)
I0529 13:02:05.568097 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:03:11.641904 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:04:04.911473 16530 solver.cpp:397]     Test net output #0: accuracy = 0.485826
I0529 13:04:04.911692 16530 solver.cpp:397]     Test net output #1: loss = 2.2526 (* 1 = 2.2526 loss)
I0529 13:04:06.047777 16530 solver.cpp:218] Iteration 40000 (0.346249 iter/s, 288.809s/100 iters), loss = 0.495272
I0529 13:04:06.047838 16530 solver.cpp:237]     Train net output #0: loss = 0.495272 (* 1 = 0.495272 loss)
I0529 13:04:06.047852 16530 sgd_solver.cpp:105] Iteration 40000, lr = 0.008
I0529 13:06:00.633086 16530 solver.cpp:218] Iteration 40100 (0.87272 iter/s, 114.584s/100 iters), loss = 0.318178
I0529 13:06:00.633291 16530 solver.cpp:237]     Train net output #0: loss = 0.318178 (* 1 = 0.318178 loss)
I0529 13:06:00.633316 16530 sgd_solver.cpp:105] Iteration 40100, lr = 0.007995
I0529 13:07:55.184926 16530 solver.cpp:218] Iteration 40200 (0.872976 iter/s, 114.551s/100 iters), loss = 0.707559
I0529 13:07:55.185128 16530 solver.cpp:237]     Train net output #0: loss = 0.707559 (* 1 = 0.707559 loss)
I0529 13:07:55.185143 16530 sgd_solver.cpp:105] Iteration 40200, lr = 0.00799
I0529 13:09:49.740674 16530 solver.cpp:218] Iteration 40300 (0.872946 iter/s, 114.555s/100 iters), loss = 0.53936
I0529 13:09:49.740840 16530 solver.cpp:237]     Train net output #0: loss = 0.53936 (* 1 = 0.53936 loss)
I0529 13:09:49.740854 16530 sgd_solver.cpp:105] Iteration 40300, lr = 0.007985
I0529 13:11:44.314663 16530 solver.cpp:218] Iteration 40400 (0.872807 iter/s, 114.573s/100 iters), loss = 0.615717
I0529 13:11:44.314870 16530 solver.cpp:237]     Train net output #0: loss = 0.615717 (* 1 = 0.615717 loss)
I0529 13:11:44.314884 16530 sgd_solver.cpp:105] Iteration 40400, lr = 0.00798
I0529 13:13:38.840025 16530 solver.cpp:218] Iteration 40500 (0.873178 iter/s, 114.524s/100 iters), loss = 0.592983
I0529 13:13:38.840291 16530 solver.cpp:237]     Train net output #0: loss = 0.592983 (* 1 = 0.592983 loss)
I0529 13:13:38.840303 16530 sgd_solver.cpp:105] Iteration 40500, lr = 0.007975
I0529 13:15:33.373838 16530 solver.cpp:218] Iteration 40600 (0.873114 iter/s, 114.533s/100 iters), loss = 0.405754
I0529 13:15:33.374054 16530 solver.cpp:237]     Train net output #0: loss = 0.405754 (* 1 = 0.405754 loss)
I0529 13:15:33.374068 16530 sgd_solver.cpp:105] Iteration 40600, lr = 0.00797
I0529 13:15:58.734446 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:17:27.912353 16530 solver.cpp:218] Iteration 40700 (0.873078 iter/s, 114.537s/100 iters), loss = 0.522223
I0529 13:17:27.912569 16530 solver.cpp:237]     Train net output #0: loss = 0.522223 (* 1 = 0.522223 loss)
I0529 13:17:27.912588 16530 sgd_solver.cpp:105] Iteration 40700, lr = 0.007965
I0529 13:19:22.491057 16530 solver.cpp:218] Iteration 40800 (0.872771 iter/s, 114.578s/100 iters), loss = 0.661644
I0529 13:19:22.491255 16530 solver.cpp:237]     Train net output #0: loss = 0.661644 (* 1 = 0.661644 loss)
I0529 13:19:22.491279 16530 sgd_solver.cpp:105] Iteration 40800, lr = 0.00796
I0529 13:21:17.052009 16530 solver.cpp:218] Iteration 40900 (0.872906 iter/s, 114.56s/100 iters), loss = 0.695486
I0529 13:21:17.052229 16530 solver.cpp:237]     Train net output #0: loss = 0.695486 (* 1 = 0.695486 loss)
I0529 13:21:17.052254 16530 sgd_solver.cpp:105] Iteration 40900, lr = 0.007955
I0529 13:23:10.510205 16530 solver.cpp:447] Snapshotting to binary proto file pre-resnet-34_iter_41000.caffemodel
I0529 13:23:10.832906 16530 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-34_iter_41000.solverstate
I0529 13:23:10.941215 16530 solver.cpp:330] Iteration 41000, Testing net (#0)
I0529 13:23:23.742213 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:24:29.944897 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:25:35.994932 16537 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:26:04.758266 16530 solver.cpp:397]     Test net output #0: accuracy = 0.415498
I0529 13:26:04.758338 16530 solver.cpp:397]     Test net output #1: loss = 2.63047 (* 1 = 2.63047 loss)
I0529 13:26:05.895982 16530 solver.cpp:218] Iteration 41000 (0.346211 iter/s, 288.841s/100 iters), loss = 0.742599
I0529 13:26:05.896044 16530 solver.cpp:237]     Train net output #0: loss = 0.742599 (* 1 = 0.742599 loss)
I0529 13:26:05.896057 16530 sgd_solver.cpp:105] Iteration 41000, lr = 0.00795
I0529 13:28:00.449537 16530 solver.cpp:218] Iteration 41100 (0.872962 iter/s, 114.553s/100 iters), loss = 0.50261
I0529 13:28:00.449666 16530 solver.cpp:237]     Train net output #0: loss = 0.502609 (* 1 = 0.502609 loss)
I0529 13:28:00.449677 16530 sgd_solver.cpp:105] Iteration 41100, lr = 0.007945
I0529 13:29:55.033306 16530 solver.cpp:218] Iteration 41200 (0.872732 iter/s, 114.583s/100 iters), loss = 0.599063
I0529 13:29:55.033481 16530 solver.cpp:237]     Train net output #0: loss = 0.599062 (* 1 = 0.599062 loss)
I0529 13:29:55.033505 16530 sgd_solver.cpp:105] Iteration 41200, lr = 0.00794
I0529 13:31:49.575623 16530 solver.cpp:218] Iteration 41300 (0.873048 iter/s, 114.541s/100 iters), loss = 0.437826
I0529 13:31:49.575824 16530 solver.cpp:237]     Train net output #0: loss = 0.437826 (* 1 = 0.437826 loss)
I0529 13:31:49.575848 16530 sgd_solver.cpp:105] Iteration 41300, lr = 0.007935
I0529 13:33:44.151717 16530 solver.cpp:218] Iteration 41400 (0.872791 iter/s, 114.575s/100 iters), loss = 0.69441
I0529 13:33:44.151924 16530 solver.cpp:237]     Train net output #0: loss = 0.69441 (* 1 = 0.69441 loss)
I0529 13:33:44.151957 16530 sgd_solver.cpp:105] Iteration 41400, lr = 0.00793
I0529 13:33:47.742419 16535 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:35:38.763362 16530 solver.cpp:218] Iteration 41500 (0.872521 iter/s, 114.61s/100 iters), loss = 0.666661
I0529 13:35:38.763531 16530 solver.cpp:237]     Train net output #0: loss = 0.666661 (* 1 = 0.666661 loss)
I0529 13:35:38.763557 16530 sgd_solver.cpp:105] Iteration 41500, lr = 0.007925
I0529 13:37:33.386155 16530 solver.cpp:218] Iteration 41600 (0.872435 iter/s, 114.622s/100 iters), loss = 0.362867
I0529 13:37:33.386339 16530 solver.cpp:237]     Train net output #0: loss = 0.362867 (* 1 = 0.362867 loss)
I0529 13:37:33.386382 16530 sgd_solver.cpp:105] Iteration 41600, lr = 0.00792
I0529 13:39:28.043015 16530 solver.cpp:218] Iteration 41700 (0.872177 iter/s, 114.656s/100 iters), loss = 0.684581
I0529 13:39:28.043386 16530 solver.cpp:237]     Train net output #0: loss = 0.68458 (* 1 = 0.68458 loss)
I0529 13:39:28.043401 16530 sgd_solver.cpp:105] Iteration 41700, lr = 0.007915
I0529 13:41:22.717311 16530 solver.cpp:218] Iteration 41800 (0.872046 iter/s, 114.673s/100 iters), loss = 0.606291
I0529 13:41:22.717578 16530 solver.cpp:237]     Train net output #0: loss = 0.606291 (* 1 = 0.606291 loss)
I0529 13:41:22.717603 16530 sgd_solver.cpp:105] Iteration 41800, lr = 0.00791
I0529 13:43:17.413913 16530 solver.cpp:218] Iteration 41900 (0.871875 iter/s, 114.695s/100 iters), loss = 0.440936
I0529 13:43:17.414057 16530 solver.cpp:237]     Train net output #0: loss = 0.440936 (* 1 = 0.440936 loss)
I0529 13:43:17.414080 16530 sgd_solver.cpp:105] Iteration 41900, lr = 0.007905
