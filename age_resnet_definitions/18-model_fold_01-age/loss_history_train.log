I0528 21:50:16.057878 142602 caffe.cpp:218] Using GPUs 0
I0528 21:50:16.187261 142602 caffe.cpp:223] GPU 0: Tesla K40m
I0528 21:50:16.642267 142602 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 200000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "pre-resnet-18"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "18_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0528 21:50:16.642627 142602 solver.cpp:87] Creating training net from net file: 18_train_val_test_fold_is_0.prototxt
I0528 21:50:16.644417 142602 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 18_train_val_test_fold_is_0.prototxt
I0528 21:50:16.644433 142602 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 21:50:16.644616 142602 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0528 21:50:16.644672 142602 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0528 21:50:16.645205 142602 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-18"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/age_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv_expand"
  bottom: "layer_512_1_conv2"
  top: "layer_512_1_sum"
}
layer {
  name: "layer_512_2_bn1"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale1"
  type: "Scale"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu1"
  type: "ReLU"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
}
layer {
  name: "layer_512_2_conv1"
  type: "Convolution"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_bn2"
  type: "BatchNorm"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale2"
  type: "Scale"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu2"
  type: "ReLU"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
}
layer {
  name: "layer_512_2_conv2"
  type: "Convolution"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_sum"
  type: "Eltwise"
  bottom: "layer_512_2_conv2"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_2_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0528 21:50:16.645598 142602 layer_factory.hpp:77] Creating layer data
I0528 21:50:16.645978 142602 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/age_train_lmdb
I0528 21:50:16.646016 142602 net.cpp:84] Creating Layer data
I0528 21:50:16.646030 142602 net.cpp:380] data -> data
I0528 21:50:16.646065 142602 net.cpp:380] data -> label
I0528 21:50:16.646087 142602 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 21:50:16.649178 142602 data_layer.cpp:45] output data size: 100,3,224,224
I0528 21:50:16.784145 142602 net.cpp:122] Setting up data
I0528 21:50:16.784207 142602 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:50:16.784215 142602 net.cpp:129] Top shape: 100 (100)
I0528 21:50:16.784219 142602 net.cpp:137] Memory required for data: 60211600
I0528 21:50:16.784231 142602 layer_factory.hpp:77] Creating layer data_bn
I0528 21:50:16.784251 142602 net.cpp:84] Creating Layer data_bn
I0528 21:50:16.784258 142602 net.cpp:406] data_bn <- data
I0528 21:50:16.784276 142602 net.cpp:380] data_bn -> data_bn
I0528 21:50:16.785209 142602 net.cpp:122] Setting up data_bn
I0528 21:50:16.785228 142602 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:50:16.785233 142602 net.cpp:137] Memory required for data: 120422800
I0528 21:50:16.785255 142602 layer_factory.hpp:77] Creating layer data_scale
I0528 21:50:16.785269 142602 net.cpp:84] Creating Layer data_scale
I0528 21:50:16.785274 142602 net.cpp:406] data_scale <- data_bn
I0528 21:50:16.785281 142602 net.cpp:367] data_scale -> data_bn (in-place)
I0528 21:50:16.785333 142602 layer_factory.hpp:77] Creating layer data_scale
I0528 21:50:16.785485 142602 net.cpp:122] Setting up data_scale
I0528 21:50:16.785493 142602 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:50:16.785496 142602 net.cpp:137] Memory required for data: 180634000
I0528 21:50:16.785506 142602 layer_factory.hpp:77] Creating layer conv1
I0528 21:50:16.785523 142602 net.cpp:84] Creating Layer conv1
I0528 21:50:16.785528 142602 net.cpp:406] conv1 <- data_bn
I0528 21:50:16.785536 142602 net.cpp:380] conv1 -> conv1
I0528 21:50:16.976056 142602 net.cpp:122] Setting up conv1
I0528 21:50:16.976104 142602 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:50:16.976109 142602 net.cpp:137] Memory required for data: 501760400
I0528 21:50:16.976120 142602 layer_factory.hpp:77] Creating layer conv1_bn
I0528 21:50:16.976136 142602 net.cpp:84] Creating Layer conv1_bn
I0528 21:50:16.976142 142602 net.cpp:406] conv1_bn <- conv1
I0528 21:50:16.976150 142602 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 21:50:16.976305 142602 net.cpp:122] Setting up conv1_bn
I0528 21:50:16.976312 142602 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:50:16.976316 142602 net.cpp:137] Memory required for data: 822886800
I0528 21:50:16.976328 142602 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:50:16.976337 142602 net.cpp:84] Creating Layer conv1_scale
I0528 21:50:16.976351 142602 net.cpp:406] conv1_scale <- conv1
I0528 21:50:16.976366 142602 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 21:50:16.976408 142602 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:50:16.976512 142602 net.cpp:122] Setting up conv1_scale
I0528 21:50:16.976519 142602 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:50:16.976523 142602 net.cpp:137] Memory required for data: 1144013200
I0528 21:50:16.976528 142602 layer_factory.hpp:77] Creating layer conv1_relu
I0528 21:50:16.976539 142602 net.cpp:84] Creating Layer conv1_relu
I0528 21:50:16.976542 142602 net.cpp:406] conv1_relu <- conv1
I0528 21:50:16.976547 142602 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 21:50:16.977114 142602 net.cpp:122] Setting up conv1_relu
I0528 21:50:16.977130 142602 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:50:16.977134 142602 net.cpp:137] Memory required for data: 1465139600
I0528 21:50:16.977138 142602 layer_factory.hpp:77] Creating layer conv1_pool
I0528 21:50:16.977145 142602 net.cpp:84] Creating Layer conv1_pool
I0528 21:50:16.977149 142602 net.cpp:406] conv1_pool <- conv1
I0528 21:50:16.977155 142602 net.cpp:380] conv1_pool -> conv1_pool
I0528 21:50:16.977208 142602 net.cpp:122] Setting up conv1_pool
I0528 21:50:16.977217 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.977221 142602 net.cpp:137] Memory required for data: 1545421200
I0528 21:50:16.977223 142602 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 21:50:16.977232 142602 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 21:50:16.977236 142602 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 21:50:16.977241 142602 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 21:50:16.977247 142602 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 21:50:16.977277 142602 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 21:50:16.977283 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.977286 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.977289 142602 net.cpp:137] Memory required for data: 1705984400
I0528 21:50:16.977293 142602 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 21:50:16.977304 142602 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 21:50:16.977308 142602 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 21:50:16.977313 142602 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 21:50:16.984407 142602 net.cpp:122] Setting up layer_64_1_conv1
I0528 21:50:16.984424 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.984429 142602 net.cpp:137] Memory required for data: 1786266000
I0528 21:50:16.984434 142602 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 21:50:16.984442 142602 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 21:50:16.984447 142602 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 21:50:16.984452 142602 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 21:50:16.990347 142602 net.cpp:122] Setting up layer_64_1_bn2
I0528 21:50:16.990367 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.990371 142602 net.cpp:137] Memory required for data: 1866547600
I0528 21:50:16.990381 142602 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:50:16.990388 142602 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 21:50:16.990393 142602 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 21:50:16.990399 142602 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 21:50:16.990438 142602 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:50:16.990540 142602 net.cpp:122] Setting up layer_64_1_scale2
I0528 21:50:16.990546 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.990550 142602 net.cpp:137] Memory required for data: 1946829200
I0528 21:50:16.990561 142602 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 21:50:16.990567 142602 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 21:50:16.990576 142602 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 21:50:16.990589 142602 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 21:50:16.990756 142602 net.cpp:122] Setting up layer_64_1_relu2
I0528 21:50:16.990768 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.990772 142602 net.cpp:137] Memory required for data: 2027110800
I0528 21:50:16.990775 142602 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 21:50:16.990787 142602 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 21:50:16.990790 142602 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 21:50:16.990797 142602 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 21:50:16.993199 142602 net.cpp:122] Setting up layer_64_1_conv2
I0528 21:50:16.993217 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993222 142602 net.cpp:137] Memory required for data: 2107392400
I0528 21:50:16.993227 142602 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 21:50:16.993238 142602 net.cpp:84] Creating Layer layer_64_1_sum
I0528 21:50:16.993242 142602 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 21:50:16.993247 142602 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 21:50:16.993252 142602 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 21:50:16.993288 142602 net.cpp:122] Setting up layer_64_1_sum
I0528 21:50:16.993294 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993297 142602 net.cpp:137] Memory required for data: 2187674000
I0528 21:50:16.993300 142602 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:16.993305 142602 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:16.993309 142602 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 21:50:16.993316 142602 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:50:16.993322 142602 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:50:16.993352 142602 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:16.993360 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993365 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993366 142602 net.cpp:137] Memory required for data: 2348237200
I0528 21:50:16.993371 142602 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 21:50:16.993379 142602 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 21:50:16.993382 142602 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:50:16.993388 142602 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 21:50:16.993546 142602 net.cpp:122] Setting up layer_64_2_bn1
I0528 21:50:16.993553 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993556 142602 net.cpp:137] Memory required for data: 2428518800
I0528 21:50:16.993562 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:50:16.993569 142602 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 21:50:16.993572 142602 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 21:50:16.993579 142602 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 21:50:16.993620 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:50:16.993721 142602 net.cpp:122] Setting up layer_64_2_scale1
I0528 21:50:16.993727 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993731 142602 net.cpp:137] Memory required for data: 2508800400
I0528 21:50:16.993736 142602 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 21:50:16.993741 142602 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 21:50:16.993744 142602 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 21:50:16.993751 142602 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 21:50:16.993908 142602 net.cpp:122] Setting up layer_64_2_relu1
I0528 21:50:16.993918 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.993927 142602 net.cpp:137] Memory required for data: 2589082000
I0528 21:50:16.993937 142602 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 21:50:16.993949 142602 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 21:50:16.993953 142602 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 21:50:16.993959 142602 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 21:50:16.996379 142602 net.cpp:122] Setting up layer_64_2_conv1
I0528 21:50:16.996397 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.996400 142602 net.cpp:137] Memory required for data: 2669363600
I0528 21:50:16.996407 142602 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 21:50:16.996415 142602 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 21:50:16.996419 142602 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 21:50:16.996424 142602 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 21:50:16.996587 142602 net.cpp:122] Setting up layer_64_2_bn2
I0528 21:50:16.996594 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.996598 142602 net.cpp:137] Memory required for data: 2749645200
I0528 21:50:16.996604 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:50:16.996611 142602 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 21:50:16.996614 142602 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 21:50:16.996619 142602 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 21:50:16.996661 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:50:16.996758 142602 net.cpp:122] Setting up layer_64_2_scale2
I0528 21:50:16.996767 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.996770 142602 net.cpp:137] Memory required for data: 2829926800
I0528 21:50:16.996776 142602 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 21:50:16.996781 142602 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 21:50:16.996785 142602 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 21:50:16.996790 142602 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 21:50:16.997362 142602 net.cpp:122] Setting up layer_64_2_relu2
I0528 21:50:16.997378 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:16.997382 142602 net.cpp:137] Memory required for data: 2910208400
I0528 21:50:16.997386 142602 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 21:50:16.997398 142602 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 21:50:16.997403 142602 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 21:50:16.997412 142602 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 21:50:17.000355 142602 net.cpp:122] Setting up layer_64_2_conv2
I0528 21:50:17.000373 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.000377 142602 net.cpp:137] Memory required for data: 2990490000
I0528 21:50:17.000383 142602 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 21:50:17.000391 142602 net.cpp:84] Creating Layer layer_64_2_sum
I0528 21:50:17.000396 142602 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 21:50:17.000401 142602 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:50:17.000406 142602 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 21:50:17.000432 142602 net.cpp:122] Setting up layer_64_2_sum
I0528 21:50:17.000439 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.000442 142602 net.cpp:137] Memory required for data: 3070771600
I0528 21:50:17.000445 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 21:50:17.000453 142602 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 21:50:17.000457 142602 net.cpp:406] layer_128_1_bn1 <- layer_64_2_sum
I0528 21:50:17.000461 142602 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 21:50:17.000638 142602 net.cpp:122] Setting up layer_128_1_bn1
I0528 21:50:17.000645 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.000648 142602 net.cpp:137] Memory required for data: 3151053200
I0528 21:50:17.000659 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:50:17.000672 142602 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 21:50:17.000684 142602 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 21:50:17.000689 142602 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 21:50:17.000730 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:50:17.000833 142602 net.cpp:122] Setting up layer_128_1_scale1
I0528 21:50:17.000839 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.000843 142602 net.cpp:137] Memory required for data: 3231334800
I0528 21:50:17.000849 142602 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 21:50:17.000855 142602 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 21:50:17.000859 142602 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 21:50:17.000864 142602 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 21:50:17.001022 142602 net.cpp:122] Setting up layer_128_1_relu1
I0528 21:50:17.001034 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.001037 142602 net.cpp:137] Memory required for data: 3311616400
I0528 21:50:17.001052 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.001060 142602 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.001063 142602 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 21:50:17.001068 142602 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:50:17.001075 142602 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:50:17.001114 142602 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.001121 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.001126 142602 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:50:17.001128 142602 net.cpp:137] Memory required for data: 3472179600
I0528 21:50:17.001132 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 21:50:17.001142 142602 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 21:50:17.001145 142602 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:50:17.001153 142602 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 21:50:17.005470 142602 net.cpp:122] Setting up layer_128_1_conv1
I0528 21:50:17.005487 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.005491 142602 net.cpp:137] Memory required for data: 3512320400
I0528 21:50:17.005497 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 21:50:17.005506 142602 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 21:50:17.005511 142602 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 21:50:17.005517 142602 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.006222 142602 net.cpp:122] Setting up layer_128_1_bn2
I0528 21:50:17.006237 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.006242 142602 net.cpp:137] Memory required for data: 3552461200
I0528 21:50:17.006252 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:50:17.006258 142602 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 21:50:17.006263 142602 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 21:50:17.006268 142602 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.006309 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:50:17.006407 142602 net.cpp:122] Setting up layer_128_1_scale2
I0528 21:50:17.006413 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.006417 142602 net.cpp:137] Memory required for data: 3592602000
I0528 21:50:17.006422 142602 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 21:50:17.006433 142602 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 21:50:17.006436 142602 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 21:50:17.006441 142602 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.006619 142602 net.cpp:122] Setting up layer_128_1_relu2
I0528 21:50:17.006631 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.006635 142602 net.cpp:137] Memory required for data: 3632742800
I0528 21:50:17.006639 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 21:50:17.006649 142602 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 21:50:17.006654 142602 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 21:50:17.006659 142602 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 21:50:17.011922 142602 net.cpp:122] Setting up layer_128_1_conv2
I0528 21:50:17.011940 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.011943 142602 net.cpp:137] Memory required for data: 3672883600
I0528 21:50:17.011948 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 21:50:17.011962 142602 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 21:50:17.011967 142602 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:50:17.011975 142602 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 21:50:17.013674 142602 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 21:50:17.013692 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.013697 142602 net.cpp:137] Memory required for data: 3713024400
I0528 21:50:17.013702 142602 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 21:50:17.013710 142602 net.cpp:84] Creating Layer layer_128_1_sum
I0528 21:50:17.013713 142602 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 21:50:17.013718 142602 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 21:50:17.013723 142602 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 21:50:17.013751 142602 net.cpp:122] Setting up layer_128_1_sum
I0528 21:50:17.013759 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.013762 142602 net.cpp:137] Memory required for data: 3753165200
I0528 21:50:17.013766 142602 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.013772 142602 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.013774 142602 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 21:50:17.013782 142602 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:50:17.013788 142602 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:50:17.013820 142602 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.013828 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.013833 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.013836 142602 net.cpp:137] Memory required for data: 3833446800
I0528 21:50:17.013839 142602 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 21:50:17.013845 142602 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 21:50:17.013849 142602 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:50:17.013855 142602 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 21:50:17.014026 142602 net.cpp:122] Setting up layer_128_2_bn1
I0528 21:50:17.014035 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.014039 142602 net.cpp:137] Memory required for data: 3873587600
I0528 21:50:17.014055 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:50:17.014063 142602 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 21:50:17.014067 142602 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 21:50:17.014073 142602 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 21:50:17.014112 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:50:17.014214 142602 net.cpp:122] Setting up layer_128_2_scale1
I0528 21:50:17.014221 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.014225 142602 net.cpp:137] Memory required for data: 3913728400
I0528 21:50:17.014241 142602 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 21:50:17.014248 142602 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 21:50:17.014251 142602 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 21:50:17.014257 142602 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 21:50:17.015238 142602 net.cpp:122] Setting up layer_128_2_relu1
I0528 21:50:17.015254 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.015257 142602 net.cpp:137] Memory required for data: 3953869200
I0528 21:50:17.015261 142602 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 21:50:17.015272 142602 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 21:50:17.015277 142602 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 21:50:17.015285 142602 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 21:50:17.020674 142602 net.cpp:122] Setting up layer_128_2_conv1
I0528 21:50:17.020691 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.020695 142602 net.cpp:137] Memory required for data: 3994010000
I0528 21:50:17.020701 142602 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 21:50:17.020710 142602 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 21:50:17.020714 142602 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 21:50:17.020720 142602 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.020890 142602 net.cpp:122] Setting up layer_128_2_bn2
I0528 21:50:17.020898 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.020901 142602 net.cpp:137] Memory required for data: 4034150800
I0528 21:50:17.020910 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:50:17.020917 142602 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 21:50:17.020920 142602 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 21:50:17.020925 142602 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.020963 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:50:17.021069 142602 net.cpp:122] Setting up layer_128_2_scale2
I0528 21:50:17.021080 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.021083 142602 net.cpp:137] Memory required for data: 4074291600
I0528 21:50:17.021088 142602 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 21:50:17.021096 142602 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 21:50:17.021100 142602 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 21:50:17.021106 142602 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.021672 142602 net.cpp:122] Setting up layer_128_2_relu2
I0528 21:50:17.021687 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.021690 142602 net.cpp:137] Memory required for data: 4114432400
I0528 21:50:17.021694 142602 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 21:50:17.021704 142602 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 21:50:17.021709 142602 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 21:50:17.021715 142602 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 21:50:17.027513 142602 net.cpp:122] Setting up layer_128_2_conv2
I0528 21:50:17.027530 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.027534 142602 net.cpp:137] Memory required for data: 4154573200
I0528 21:50:17.027539 142602 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 21:50:17.027546 142602 net.cpp:84] Creating Layer layer_128_2_sum
I0528 21:50:17.027550 142602 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 21:50:17.027555 142602 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:50:17.027562 142602 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 21:50:17.027588 142602 net.cpp:122] Setting up layer_128_2_sum
I0528 21:50:17.027597 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.027601 142602 net.cpp:137] Memory required for data: 4194714000
I0528 21:50:17.027609 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 21:50:17.027623 142602 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 21:50:17.027627 142602 net.cpp:406] layer_256_1_bn1 <- layer_128_2_sum
I0528 21:50:17.027636 142602 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 21:50:17.027806 142602 net.cpp:122] Setting up layer_256_1_bn1
I0528 21:50:17.027814 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.027817 142602 net.cpp:137] Memory required for data: 4234854800
I0528 21:50:17.027824 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:50:17.027832 142602 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 21:50:17.027837 142602 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 21:50:17.027842 142602 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 21:50:17.027879 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:50:17.027976 142602 net.cpp:122] Setting up layer_256_1_scale1
I0528 21:50:17.027983 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.027987 142602 net.cpp:137] Memory required for data: 4274995600
I0528 21:50:17.027992 142602 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 21:50:17.027997 142602 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 21:50:17.028002 142602 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 21:50:17.028005 142602 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 21:50:17.028182 142602 net.cpp:122] Setting up layer_256_1_relu1
I0528 21:50:17.028195 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.028199 142602 net.cpp:137] Memory required for data: 4315136400
I0528 21:50:17.028203 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.028211 142602 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.028215 142602 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 21:50:17.028220 142602 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:50:17.028230 142602 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:50:17.028268 142602 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.028275 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.028280 142602 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:50:17.028282 142602 net.cpp:137] Memory required for data: 4395418000
I0528 21:50:17.028286 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 21:50:17.028298 142602 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 21:50:17.028302 142602 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:50:17.028308 142602 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 21:50:17.037895 142602 net.cpp:122] Setting up layer_256_1_conv1
I0528 21:50:17.037912 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.037917 142602 net.cpp:137] Memory required for data: 4415488400
I0528 21:50:17.037922 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 21:50:17.037931 142602 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 21:50:17.037936 142602 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 21:50:17.037941 142602 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.038120 142602 net.cpp:122] Setting up layer_256_1_bn2
I0528 21:50:17.038130 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.038134 142602 net.cpp:137] Memory required for data: 4435558800
I0528 21:50:17.038151 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:50:17.038157 142602 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 21:50:17.038161 142602 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 21:50:17.038168 142602 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.038218 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:50:17.038326 142602 net.cpp:122] Setting up layer_256_1_scale2
I0528 21:50:17.038333 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.038336 142602 net.cpp:137] Memory required for data: 4455629200
I0528 21:50:17.038342 142602 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 21:50:17.038348 142602 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 21:50:17.038352 142602 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 21:50:17.038359 142602 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.038920 142602 net.cpp:122] Setting up layer_256_1_relu2
I0528 21:50:17.038933 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.038936 142602 net.cpp:137] Memory required for data: 4475699600
I0528 21:50:17.038940 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 21:50:17.038951 142602 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 21:50:17.038956 142602 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 21:50:17.038964 142602 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 21:50:17.059670 142602 net.cpp:122] Setting up layer_256_1_conv2
I0528 21:50:17.059689 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.059695 142602 net.cpp:137] Memory required for data: 4495770000
I0528 21:50:17.059700 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 21:50:17.059712 142602 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 21:50:17.059717 142602 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:50:17.059725 142602 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 21:50:17.062482 142602 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 21:50:17.062500 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.062503 142602 net.cpp:137] Memory required for data: 4515840400
I0528 21:50:17.062510 142602 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 21:50:17.062517 142602 net.cpp:84] Creating Layer layer_256_1_sum
I0528 21:50:17.062522 142602 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 21:50:17.062527 142602 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 21:50:17.062532 142602 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 21:50:17.062564 142602 net.cpp:122] Setting up layer_256_1_sum
I0528 21:50:17.062572 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.062574 142602 net.cpp:137] Memory required for data: 4535910800
I0528 21:50:17.062577 142602 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.062583 142602 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.062587 142602 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 21:50:17.062593 142602 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:50:17.062600 142602 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:50:17.062633 142602 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.062641 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.062645 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.062649 142602 net.cpp:137] Memory required for data: 4576051600
I0528 21:50:17.062651 142602 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 21:50:17.062657 142602 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 21:50:17.062660 142602 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:50:17.062667 142602 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 21:50:17.062836 142602 net.cpp:122] Setting up layer_256_2_bn1
I0528 21:50:17.062844 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.062847 142602 net.cpp:137] Memory required for data: 4596122000
I0528 21:50:17.062860 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:50:17.062875 142602 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 21:50:17.062880 142602 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 21:50:17.062885 142602 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 21:50:17.062929 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:50:17.063045 142602 net.cpp:122] Setting up layer_256_2_scale1
I0528 21:50:17.063055 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.063060 142602 net.cpp:137] Memory required for data: 4616192400
I0528 21:50:17.063066 142602 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 21:50:17.063071 142602 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 21:50:17.063074 142602 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 21:50:17.063081 142602 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 21:50:17.063654 142602 net.cpp:122] Setting up layer_256_2_relu1
I0528 21:50:17.063668 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.063670 142602 net.cpp:137] Memory required for data: 4636262800
I0528 21:50:17.063674 142602 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 21:50:17.063685 142602 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 21:50:17.063690 142602 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 21:50:17.063699 142602 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 21:50:17.080912 142602 net.cpp:122] Setting up layer_256_2_conv1
I0528 21:50:17.080932 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.080937 142602 net.cpp:137] Memory required for data: 4656333200
I0528 21:50:17.080943 142602 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 21:50:17.080952 142602 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 21:50:17.080956 142602 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 21:50:17.080962 142602 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.081140 142602 net.cpp:122] Setting up layer_256_2_bn2
I0528 21:50:17.081151 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.081156 142602 net.cpp:137] Memory required for data: 4676403600
I0528 21:50:17.081162 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:50:17.081172 142602 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 21:50:17.081176 142602 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 21:50:17.081182 142602 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.081223 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:50:17.081323 142602 net.cpp:122] Setting up layer_256_2_scale2
I0528 21:50:17.081331 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.081333 142602 net.cpp:137] Memory required for data: 4696474000
I0528 21:50:17.081338 142602 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 21:50:17.081351 142602 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 21:50:17.081354 142602 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 21:50:17.081360 142602 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.081921 142602 net.cpp:122] Setting up layer_256_2_relu2
I0528 21:50:17.081934 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.081938 142602 net.cpp:137] Memory required for data: 4716544400
I0528 21:50:17.081943 142602 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 21:50:17.081954 142602 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 21:50:17.081959 142602 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 21:50:17.081965 142602 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 21:50:17.099561 142602 net.cpp:122] Setting up layer_256_2_conv2
I0528 21:50:17.099580 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.099583 142602 net.cpp:137] Memory required for data: 4736614800
I0528 21:50:17.099589 142602 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 21:50:17.099601 142602 net.cpp:84] Creating Layer layer_256_2_sum
I0528 21:50:17.099611 142602 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 21:50:17.099617 142602 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:50:17.099624 142602 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 21:50:17.099653 142602 net.cpp:122] Setting up layer_256_2_sum
I0528 21:50:17.099661 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.099664 142602 net.cpp:137] Memory required for data: 4756685200
I0528 21:50:17.099668 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 21:50:17.099674 142602 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 21:50:17.099678 142602 net.cpp:406] layer_512_1_bn1 <- layer_256_2_sum
I0528 21:50:17.099685 142602 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 21:50:17.099861 142602 net.cpp:122] Setting up layer_512_1_bn1
I0528 21:50:17.099869 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.099872 142602 net.cpp:137] Memory required for data: 4776755600
I0528 21:50:17.099879 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:50:17.099885 142602 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 21:50:17.099889 142602 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 21:50:17.099895 142602 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 21:50:17.099934 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:50:17.100036 142602 net.cpp:122] Setting up layer_512_1_scale1
I0528 21:50:17.100054 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.100057 142602 net.cpp:137] Memory required for data: 4796826000
I0528 21:50:17.100064 142602 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 21:50:17.100069 142602 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 21:50:17.100072 142602 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 21:50:17.100077 142602 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 21:50:17.100262 142602 net.cpp:122] Setting up layer_512_1_relu1
I0528 21:50:17.100272 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.100276 142602 net.cpp:137] Memory required for data: 4816896400
I0528 21:50:17.100280 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.100286 142602 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.100289 142602 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 21:50:17.100294 142602 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:50:17.100303 142602 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:50:17.100342 142602 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.100348 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.100353 142602 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:50:17.100355 142602 net.cpp:137] Memory required for data: 4857037200
I0528 21:50:17.100358 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 21:50:17.100370 142602 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 21:50:17.100374 142602 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:50:17.100380 142602 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 21:50:17.134327 142602 net.cpp:122] Setting up layer_512_1_conv1
I0528 21:50:17.134347 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.134351 142602 net.cpp:137] Memory required for data: 4867072400
I0528 21:50:17.134357 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 21:50:17.134364 142602 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 21:50:17.134368 142602 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 21:50:17.134376 142602 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.134574 142602 net.cpp:122] Setting up layer_512_1_bn2
I0528 21:50:17.134591 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.134595 142602 net.cpp:137] Memory required for data: 4877107600
I0528 21:50:17.134603 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:50:17.134609 142602 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 21:50:17.134613 142602 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 21:50:17.134618 142602 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.134658 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:50:17.134763 142602 net.cpp:122] Setting up layer_512_1_scale2
I0528 21:50:17.134770 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.134773 142602 net.cpp:137] Memory required for data: 4887142800
I0528 21:50:17.134778 142602 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 21:50:17.134784 142602 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 21:50:17.134788 142602 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 21:50:17.134794 142602 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.135373 142602 net.cpp:122] Setting up layer_512_1_relu2
I0528 21:50:17.135390 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.135393 142602 net.cpp:137] Memory required for data: 4897178000
I0528 21:50:17.135397 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 21:50:17.135409 142602 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 21:50:17.135414 142602 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 21:50:17.135422 142602 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 21:50:17.200327 142602 net.cpp:122] Setting up layer_512_1_conv2
I0528 21:50:17.200345 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.200350 142602 net.cpp:137] Memory required for data: 4907213200
I0528 21:50:17.200356 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 21:50:17.200366 142602 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 21:50:17.200371 142602 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:50:17.200381 142602 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 21:50:17.205739 142602 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 21:50:17.205755 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.205760 142602 net.cpp:137] Memory required for data: 4917248400
I0528 21:50:17.205765 142602 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 21:50:17.205773 142602 net.cpp:84] Creating Layer layer_512_1_sum
I0528 21:50:17.205777 142602 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 21:50:17.205782 142602 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 21:50:17.205788 142602 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 21:50:17.205816 142602 net.cpp:122] Setting up layer_512_1_sum
I0528 21:50:17.205824 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.205828 142602 net.cpp:137] Memory required for data: 4927283600
I0528 21:50:17.205832 142602 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.205837 142602 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.205840 142602 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 21:50:17.205845 142602 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:50:17.205853 142602 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:50:17.205888 142602 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.205894 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.205898 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.205900 142602 net.cpp:137] Memory required for data: 4947354000
I0528 21:50:17.205904 142602 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 21:50:17.205922 142602 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 21:50:17.205926 142602 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:50:17.205932 142602 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 21:50:17.206121 142602 net.cpp:122] Setting up layer_512_2_bn1
I0528 21:50:17.206132 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.206135 142602 net.cpp:137] Memory required for data: 4957389200
I0528 21:50:17.206143 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:50:17.206149 142602 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 21:50:17.206153 142602 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 21:50:17.206164 142602 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 21:50:17.206205 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:50:17.206312 142602 net.cpp:122] Setting up layer_512_2_scale1
I0528 21:50:17.206321 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.206324 142602 net.cpp:137] Memory required for data: 4967424400
I0528 21:50:17.206329 142602 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 21:50:17.206336 142602 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 21:50:17.206338 142602 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 21:50:17.206343 142602 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 21:50:17.206918 142602 net.cpp:122] Setting up layer_512_2_relu1
I0528 21:50:17.206930 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.206934 142602 net.cpp:137] Memory required for data: 4977459600
I0528 21:50:17.206938 142602 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 21:50:17.206950 142602 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 21:50:17.206955 142602 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 21:50:17.206962 142602 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 21:50:17.272395 142602 net.cpp:122] Setting up layer_512_2_conv1
I0528 21:50:17.272420 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.272424 142602 net.cpp:137] Memory required for data: 4987494800
I0528 21:50:17.272430 142602 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 21:50:17.272439 142602 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 21:50:17.272444 142602 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 21:50:17.272450 142602 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.272639 142602 net.cpp:122] Setting up layer_512_2_bn2
I0528 21:50:17.272646 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.272650 142602 net.cpp:137] Memory required for data: 4997530000
I0528 21:50:17.272656 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:50:17.272665 142602 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 21:50:17.272668 142602 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 21:50:17.272673 142602 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.272713 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:50:17.272824 142602 net.cpp:122] Setting up layer_512_2_scale2
I0528 21:50:17.272831 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.272835 142602 net.cpp:137] Memory required for data: 5007565200
I0528 21:50:17.272840 142602 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 21:50:17.272845 142602 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 21:50:17.272850 142602 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 21:50:17.272855 142602 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.273016 142602 net.cpp:122] Setting up layer_512_2_relu2
I0528 21:50:17.273026 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.273030 142602 net.cpp:137] Memory required for data: 5017600400
I0528 21:50:17.273033 142602 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 21:50:17.273056 142602 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 21:50:17.273069 142602 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 21:50:17.273078 142602 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 21:50:17.341543 142602 net.cpp:122] Setting up layer_512_2_conv2
I0528 21:50:17.341572 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.341578 142602 net.cpp:137] Memory required for data: 5027635600
I0528 21:50:17.341588 142602 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 21:50:17.341608 142602 net.cpp:84] Creating Layer layer_512_2_sum
I0528 21:50:17.341616 142602 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 21:50:17.341624 142602 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:50:17.341632 142602 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 21:50:17.341668 142602 net.cpp:122] Setting up layer_512_2_sum
I0528 21:50:17.341678 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.341682 142602 net.cpp:137] Memory required for data: 5037670800
I0528 21:50:17.341686 142602 layer_factory.hpp:77] Creating layer last_bn
I0528 21:50:17.341699 142602 net.cpp:84] Creating Layer last_bn
I0528 21:50:17.341703 142602 net.cpp:406] last_bn <- layer_512_2_sum
I0528 21:50:17.341711 142602 net.cpp:367] last_bn -> layer_512_2_sum (in-place)
I0528 21:50:17.341930 142602 net.cpp:122] Setting up last_bn
I0528 21:50:17.341938 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.341941 142602 net.cpp:137] Memory required for data: 5047706000
I0528 21:50:17.341948 142602 layer_factory.hpp:77] Creating layer last_scale
I0528 21:50:17.341960 142602 net.cpp:84] Creating Layer last_scale
I0528 21:50:17.341964 142602 net.cpp:406] last_scale <- layer_512_2_sum
I0528 21:50:17.341970 142602 net.cpp:367] last_scale -> layer_512_2_sum (in-place)
I0528 21:50:17.342015 142602 layer_factory.hpp:77] Creating layer last_scale
I0528 21:50:17.342136 142602 net.cpp:122] Setting up last_scale
I0528 21:50:17.342149 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.342151 142602 net.cpp:137] Memory required for data: 5057741200
I0528 21:50:17.342157 142602 layer_factory.hpp:77] Creating layer last_relu
I0528 21:50:17.342169 142602 net.cpp:84] Creating Layer last_relu
I0528 21:50:17.342172 142602 net.cpp:406] last_relu <- layer_512_2_sum
I0528 21:50:17.342177 142602 net.cpp:367] last_relu -> layer_512_2_sum (in-place)
I0528 21:50:17.342347 142602 net.cpp:122] Setting up last_relu
I0528 21:50:17.342358 142602 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:50:17.342361 142602 net.cpp:137] Memory required for data: 5067776400
I0528 21:50:17.342365 142602 layer_factory.hpp:77] Creating layer global_pool
I0528 21:50:17.342372 142602 net.cpp:84] Creating Layer global_pool
I0528 21:50:17.342376 142602 net.cpp:406] global_pool <- layer_512_2_sum
I0528 21:50:17.342386 142602 net.cpp:380] global_pool -> global_pool
I0528 21:50:17.343001 142602 net.cpp:122] Setting up global_pool
I0528 21:50:17.343014 142602 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0528 21:50:17.343017 142602 net.cpp:137] Memory required for data: 5067981200
I0528 21:50:17.343021 142602 layer_factory.hpp:77] Creating layer score
I0528 21:50:17.343031 142602 net.cpp:84] Creating Layer score
I0528 21:50:17.343035 142602 net.cpp:406] score <- global_pool
I0528 21:50:17.343051 142602 net.cpp:380] score -> score
I0528 21:50:17.343214 142602 net.cpp:122] Setting up score
I0528 21:50:17.343221 142602 net.cpp:129] Top shape: 100 8 (800)
I0528 21:50:17.343225 142602 net.cpp:137] Memory required for data: 5067984400
I0528 21:50:17.343231 142602 layer_factory.hpp:77] Creating layer loss
I0528 21:50:17.343240 142602 net.cpp:84] Creating Layer loss
I0528 21:50:17.343243 142602 net.cpp:406] loss <- score
I0528 21:50:17.343250 142602 net.cpp:406] loss <- label
I0528 21:50:17.343257 142602 net.cpp:380] loss -> loss
I0528 21:50:17.343272 142602 layer_factory.hpp:77] Creating layer loss
I0528 21:50:17.343945 142602 net.cpp:122] Setting up loss
I0528 21:50:17.343962 142602 net.cpp:129] Top shape: (1)
I0528 21:50:17.343974 142602 net.cpp:132]     with loss weight 1
I0528 21:50:17.344015 142602 net.cpp:137] Memory required for data: 5067984404
I0528 21:50:17.344020 142602 net.cpp:198] loss needs backward computation.
I0528 21:50:17.344024 142602 net.cpp:198] score needs backward computation.
I0528 21:50:17.344028 142602 net.cpp:198] global_pool needs backward computation.
I0528 21:50:17.344032 142602 net.cpp:198] last_relu needs backward computation.
I0528 21:50:17.344034 142602 net.cpp:198] last_scale needs backward computation.
I0528 21:50:17.344038 142602 net.cpp:198] last_bn needs backward computation.
I0528 21:50:17.344048 142602 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 21:50:17.344053 142602 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 21:50:17.344056 142602 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 21:50:17.344059 142602 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 21:50:17.344063 142602 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 21:50:17.344066 142602 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 21:50:17.344070 142602 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 21:50:17.344074 142602 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 21:50:17.344076 142602 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 21:50:17.344080 142602 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 21:50:17.344084 142602 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 21:50:17.344087 142602 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 21:50:17.344094 142602 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 21:50:17.344097 142602 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 21:50:17.344100 142602 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 21:50:17.344105 142602 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 21:50:17.344107 142602 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 21:50:17.344112 142602 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 21:50:17.344116 142602 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 21:50:17.344120 142602 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 21:50:17.344122 142602 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 21:50:17.344126 142602 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 21:50:17.344130 142602 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 21:50:17.344135 142602 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 21:50:17.344138 142602 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 21:50:17.344141 142602 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 21:50:17.344146 142602 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 21:50:17.344151 142602 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 21:50:17.344154 142602 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 21:50:17.344159 142602 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 21:50:17.344163 142602 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 21:50:17.344166 142602 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 21:50:17.344172 142602 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 21:50:17.344175 142602 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 21:50:17.344180 142602 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 21:50:17.344183 142602 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 21:50:17.344187 142602 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 21:50:17.344192 142602 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 21:50:17.344198 142602 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 21:50:17.344210 142602 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 21:50:17.344213 142602 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 21:50:17.344218 142602 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 21:50:17.344221 142602 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 21:50:17.344226 142602 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 21:50:17.344230 142602 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 21:50:17.344235 142602 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 21:50:17.344238 142602 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 21:50:17.344243 142602 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 21:50:17.344246 142602 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 21:50:17.344249 142602 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 21:50:17.344254 142602 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 21:50:17.344259 142602 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 21:50:17.344262 142602 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 21:50:17.344267 142602 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 21:50:17.344272 142602 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 21:50:17.344276 142602 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 21:50:17.344281 142602 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 21:50:17.344285 142602 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 21:50:17.344290 142602 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 21:50:17.344293 142602 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 21:50:17.344296 142602 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 21:50:17.344300 142602 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 21:50:17.344303 142602 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 21:50:17.344307 142602 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 21:50:17.344312 142602 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 21:50:17.344316 142602 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 21:50:17.344321 142602 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 21:50:17.344326 142602 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 21:50:17.344328 142602 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 21:50:17.344332 142602 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 21:50:17.344336 142602 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 21:50:17.344339 142602 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 21:50:17.344343 142602 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 21:50:17.344347 142602 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 21:50:17.344352 142602 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 21:50:17.344357 142602 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 21:50:17.344362 142602 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 21:50:17.344367 142602 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 21:50:17.344369 142602 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 21:50:17.344373 142602 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 21:50:17.344377 142602 net.cpp:198] conv1_pool needs backward computation.
I0528 21:50:17.344382 142602 net.cpp:198] conv1_relu needs backward computation.
I0528 21:50:17.344385 142602 net.cpp:198] conv1_scale needs backward computation.
I0528 21:50:17.344389 142602 net.cpp:198] conv1_bn needs backward computation.
I0528 21:50:17.344395 142602 net.cpp:198] conv1 needs backward computation.
I0528 21:50:17.344403 142602 net.cpp:198] data_scale needs backward computation.
I0528 21:50:17.344406 142602 net.cpp:200] data_bn does not need backward computation.
I0528 21:50:17.344411 142602 net.cpp:200] data does not need backward computation.
I0528 21:50:17.344414 142602 net.cpp:242] This network produces output loss
I0528 21:50:17.344465 142602 net.cpp:255] Network initialization done.
I0528 21:50:17.346705 142602 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 18_train_val_test_fold_is_0.prototxt
I0528 21:50:17.346720 142602 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 21:50:17.346730 142602 solver.cpp:172] Creating test net (#0) specified by net file: 18_train_val_test_fold_is_0.prototxt
I0528 21:50:17.346832 142602 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0528 21:50:17.347395 142602 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-18"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/age_val_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv_expand"
  bottom: "layer_512_1_conv2"
  top: "layer_512_1_sum"
}
layer {
  name: "layer_512_2_bn1"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale1"
  type: "Scale"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu1"
  type: "ReLU"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
}
layer {
  name: "layer_512_2_conv1"
  type: "Convolution"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_bn2"
  type: "BatchNorm"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale2"
  type: "Scale"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu2"
  type: "ReLU"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
}
layer {
  name: "layer_512_2_conv2"
  type: "Convolution"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_sum"
  type: "Eltwise"
  bottom: "layer_512_2_conv2"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_2_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 8
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0528 21:50:17.347759 142602 layer_factory.hpp:77] Creating layer data
I0528 21:50:17.347823 142602 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/age_val_lmdb
I0528 21:50:17.347841 142602 net.cpp:84] Creating Layer data
I0528 21:50:17.347848 142602 net.cpp:380] data -> data
I0528 21:50:17.347857 142602 net.cpp:380] data -> label
I0528 21:50:17.347865 142602 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 21:50:17.350347 142602 data_layer.cpp:45] output data size: 20,3,224,224
I0528 21:50:17.377262 142602 net.cpp:122] Setting up data
I0528 21:50:17.377313 142602 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 21:50:17.377321 142602 net.cpp:129] Top shape: 20 (20)
I0528 21:50:17.377326 142602 net.cpp:137] Memory required for data: 12042320
I0528 21:50:17.377333 142602 layer_factory.hpp:77] Creating layer label_data_1_split
I0528 21:50:17.377349 142602 net.cpp:84] Creating Layer label_data_1_split
I0528 21:50:17.377354 142602 net.cpp:406] label_data_1_split <- label
I0528 21:50:17.377363 142602 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0528 21:50:17.377375 142602 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0528 21:50:17.377552 142602 net.cpp:122] Setting up label_data_1_split
I0528 21:50:17.377562 142602 net.cpp:129] Top shape: 20 (20)
I0528 21:50:17.377566 142602 net.cpp:129] Top shape: 20 (20)
I0528 21:50:17.377569 142602 net.cpp:137] Memory required for data: 12042480
I0528 21:50:17.377573 142602 layer_factory.hpp:77] Creating layer data_bn
I0528 21:50:17.377583 142602 net.cpp:84] Creating Layer data_bn
I0528 21:50:17.377588 142602 net.cpp:406] data_bn <- data
I0528 21:50:17.377593 142602 net.cpp:380] data_bn -> data_bn
I0528 21:50:17.377856 142602 net.cpp:122] Setting up data_bn
I0528 21:50:17.377863 142602 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 21:50:17.377867 142602 net.cpp:137] Memory required for data: 24084720
I0528 21:50:17.377882 142602 layer_factory.hpp:77] Creating layer data_scale
I0528 21:50:17.377889 142602 net.cpp:84] Creating Layer data_scale
I0528 21:50:17.377893 142602 net.cpp:406] data_scale <- data_bn
I0528 21:50:17.377898 142602 net.cpp:367] data_scale -> data_bn (in-place)
I0528 21:50:17.377944 142602 layer_factory.hpp:77] Creating layer data_scale
I0528 21:50:17.378154 142602 net.cpp:122] Setting up data_scale
I0528 21:50:17.378166 142602 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 21:50:17.378170 142602 net.cpp:137] Memory required for data: 36126960
I0528 21:50:17.378178 142602 layer_factory.hpp:77] Creating layer conv1
I0528 21:50:17.378191 142602 net.cpp:84] Creating Layer conv1
I0528 21:50:17.378196 142602 net.cpp:406] conv1 <- data_bn
I0528 21:50:17.378202 142602 net.cpp:380] conv1 -> conv1
I0528 21:50:17.380802 142602 net.cpp:122] Setting up conv1
I0528 21:50:17.380823 142602 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 21:50:17.380828 142602 net.cpp:137] Memory required for data: 100352240
I0528 21:50:17.380836 142602 layer_factory.hpp:77] Creating layer conv1_bn
I0528 21:50:17.380853 142602 net.cpp:84] Creating Layer conv1_bn
I0528 21:50:17.380867 142602 net.cpp:406] conv1_bn <- conv1
I0528 21:50:17.380874 142602 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 21:50:17.381095 142602 net.cpp:122] Setting up conv1_bn
I0528 21:50:17.381106 142602 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 21:50:17.381110 142602 net.cpp:137] Memory required for data: 164577520
I0528 21:50:17.381120 142602 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:50:17.381129 142602 net.cpp:84] Creating Layer conv1_scale
I0528 21:50:17.381132 142602 net.cpp:406] conv1_scale <- conv1
I0528 21:50:17.381137 142602 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 21:50:17.381182 142602 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:50:17.381317 142602 net.cpp:122] Setting up conv1_scale
I0528 21:50:17.381325 142602 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 21:50:17.381327 142602 net.cpp:137] Memory required for data: 228802800
I0528 21:50:17.381333 142602 layer_factory.hpp:77] Creating layer conv1_relu
I0528 21:50:17.381340 142602 net.cpp:84] Creating Layer conv1_relu
I0528 21:50:17.381343 142602 net.cpp:406] conv1_relu <- conv1
I0528 21:50:17.381348 142602 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 21:50:17.381976 142602 net.cpp:122] Setting up conv1_relu
I0528 21:50:17.381990 142602 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 21:50:17.381994 142602 net.cpp:137] Memory required for data: 293028080
I0528 21:50:17.381999 142602 layer_factory.hpp:77] Creating layer conv1_pool
I0528 21:50:17.382007 142602 net.cpp:84] Creating Layer conv1_pool
I0528 21:50:17.382011 142602 net.cpp:406] conv1_pool <- conv1
I0528 21:50:17.382017 142602 net.cpp:380] conv1_pool -> conv1_pool
I0528 21:50:17.382076 142602 net.cpp:122] Setting up conv1_pool
I0528 21:50:17.382089 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.382093 142602 net.cpp:137] Memory required for data: 309084400
I0528 21:50:17.382097 142602 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 21:50:17.382103 142602 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 21:50:17.382107 142602 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 21:50:17.382113 142602 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 21:50:17.382120 142602 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 21:50:17.382160 142602 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 21:50:17.382166 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.382170 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.382174 142602 net.cpp:137] Memory required for data: 341197040
I0528 21:50:17.382176 142602 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 21:50:17.382186 142602 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 21:50:17.382190 142602 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 21:50:17.382196 142602 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 21:50:17.385063 142602 net.cpp:122] Setting up layer_64_1_conv1
I0528 21:50:17.385080 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.385085 142602 net.cpp:137] Memory required for data: 357253360
I0528 21:50:17.385090 142602 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 21:50:17.385098 142602 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 21:50:17.385102 142602 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 21:50:17.385108 142602 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 21:50:17.385305 142602 net.cpp:122] Setting up layer_64_1_bn2
I0528 21:50:17.385313 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.385316 142602 net.cpp:137] Memory required for data: 373309680
I0528 21:50:17.385324 142602 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:50:17.385330 142602 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 21:50:17.385334 142602 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 21:50:17.385344 142602 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 21:50:17.385397 142602 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:50:17.385522 142602 net.cpp:122] Setting up layer_64_1_scale2
I0528 21:50:17.385530 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.385534 142602 net.cpp:137] Memory required for data: 389366000
I0528 21:50:17.385543 142602 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 21:50:17.385550 142602 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 21:50:17.385553 142602 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 21:50:17.385560 142602 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 21:50:17.385722 142602 net.cpp:122] Setting up layer_64_1_relu2
I0528 21:50:17.385732 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.385736 142602 net.cpp:137] Memory required for data: 405422320
I0528 21:50:17.385740 142602 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 21:50:17.385751 142602 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 21:50:17.385754 142602 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 21:50:17.385761 142602 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 21:50:17.388761 142602 net.cpp:122] Setting up layer_64_1_conv2
I0528 21:50:17.388778 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.388782 142602 net.cpp:137] Memory required for data: 421478640
I0528 21:50:17.388788 142602 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 21:50:17.388797 142602 net.cpp:84] Creating Layer layer_64_1_sum
I0528 21:50:17.388800 142602 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 21:50:17.388805 142602 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 21:50:17.388811 142602 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 21:50:17.388844 142602 net.cpp:122] Setting up layer_64_1_sum
I0528 21:50:17.388850 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.388854 142602 net.cpp:137] Memory required for data: 437534960
I0528 21:50:17.388856 142602 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:17.388864 142602 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:17.388869 142602 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 21:50:17.388873 142602 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:50:17.388880 142602 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:50:17.388917 142602 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:50:17.388923 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.388927 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.388931 142602 net.cpp:137] Memory required for data: 469647600
I0528 21:50:17.388933 142602 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 21:50:17.388939 142602 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 21:50:17.388943 142602 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:50:17.388949 142602 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 21:50:17.389171 142602 net.cpp:122] Setting up layer_64_2_bn1
I0528 21:50:17.389183 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.389188 142602 net.cpp:137] Memory required for data: 485703920
I0528 21:50:17.389194 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:50:17.389202 142602 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 21:50:17.389206 142602 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 21:50:17.389211 142602 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 21:50:17.389257 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:50:17.389380 142602 net.cpp:122] Setting up layer_64_2_scale1
I0528 21:50:17.389389 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.389395 142602 net.cpp:137] Memory required for data: 501760240
I0528 21:50:17.389408 142602 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 21:50:17.389415 142602 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 21:50:17.389420 142602 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 21:50:17.389425 142602 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 21:50:17.390000 142602 net.cpp:122] Setting up layer_64_2_relu1
I0528 21:50:17.390013 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.390017 142602 net.cpp:137] Memory required for data: 517816560
I0528 21:50:17.390022 142602 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 21:50:17.390031 142602 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 21:50:17.390036 142602 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 21:50:17.390049 142602 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 21:50:17.392089 142602 net.cpp:122] Setting up layer_64_2_conv1
I0528 21:50:17.392107 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.392110 142602 net.cpp:137] Memory required for data: 533872880
I0528 21:50:17.392115 142602 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 21:50:17.392123 142602 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 21:50:17.392127 142602 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 21:50:17.392133 142602 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 21:50:17.392338 142602 net.cpp:122] Setting up layer_64_2_bn2
I0528 21:50:17.392344 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.392349 142602 net.cpp:137] Memory required for data: 549929200
I0528 21:50:17.392355 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:50:17.392362 142602 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 21:50:17.392366 142602 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 21:50:17.392371 142602 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 21:50:17.392416 142602 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:50:17.392539 142602 net.cpp:122] Setting up layer_64_2_scale2
I0528 21:50:17.392546 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.392549 142602 net.cpp:137] Memory required for data: 565985520
I0528 21:50:17.392555 142602 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 21:50:17.392561 142602 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 21:50:17.392565 142602 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 21:50:17.392570 142602 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 21:50:17.393151 142602 net.cpp:122] Setting up layer_64_2_relu2
I0528 21:50:17.393167 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.393172 142602 net.cpp:137] Memory required for data: 582041840
I0528 21:50:17.393174 142602 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 21:50:17.393184 142602 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 21:50:17.393188 142602 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 21:50:17.393196 142602 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 21:50:17.395634 142602 net.cpp:122] Setting up layer_64_2_conv2
I0528 21:50:17.395651 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.395655 142602 net.cpp:137] Memory required for data: 598098160
I0528 21:50:17.395661 142602 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 21:50:17.395668 142602 net.cpp:84] Creating Layer layer_64_2_sum
I0528 21:50:17.395673 142602 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 21:50:17.395678 142602 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:50:17.395683 142602 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 21:50:17.395712 142602 net.cpp:122] Setting up layer_64_2_sum
I0528 21:50:17.395720 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.395722 142602 net.cpp:137] Memory required for data: 614154480
I0528 21:50:17.395725 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 21:50:17.395737 142602 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 21:50:17.395747 142602 net.cpp:406] layer_128_1_bn1 <- layer_64_2_sum
I0528 21:50:17.395753 142602 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 21:50:17.395964 142602 net.cpp:122] Setting up layer_128_1_bn1
I0528 21:50:17.395972 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.395974 142602 net.cpp:137] Memory required for data: 630210800
I0528 21:50:17.395987 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:50:17.395994 142602 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 21:50:17.395998 142602 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 21:50:17.396004 142602 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 21:50:17.396057 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:50:17.396190 142602 net.cpp:122] Setting up layer_128_1_scale1
I0528 21:50:17.396198 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.396201 142602 net.cpp:137] Memory required for data: 646267120
I0528 21:50:17.396224 142602 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 21:50:17.396230 142602 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 21:50:17.396234 142602 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 21:50:17.396240 142602 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 21:50:17.396407 142602 net.cpp:122] Setting up layer_128_1_relu1
I0528 21:50:17.396419 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.396421 142602 net.cpp:137] Memory required for data: 662323440
I0528 21:50:17.396425 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.396430 142602 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.396435 142602 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 21:50:17.396440 142602 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:50:17.396447 142602 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:50:17.396492 142602 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:50:17.396498 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.396502 142602 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 21:50:17.396505 142602 net.cpp:137] Memory required for data: 694436080
I0528 21:50:17.396508 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 21:50:17.396517 142602 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 21:50:17.396522 142602 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:50:17.396528 142602 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 21:50:17.399962 142602 net.cpp:122] Setting up layer_128_1_conv1
I0528 21:50:17.399979 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.399984 142602 net.cpp:137] Memory required for data: 702464240
I0528 21:50:17.399989 142602 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 21:50:17.399997 142602 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 21:50:17.400002 142602 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 21:50:17.400008 142602 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.400216 142602 net.cpp:122] Setting up layer_128_1_bn2
I0528 21:50:17.400228 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.400230 142602 net.cpp:137] Memory required for data: 710492400
I0528 21:50:17.400238 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:50:17.400249 142602 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 21:50:17.400252 142602 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 21:50:17.400259 142602 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.400302 142602 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:50:17.400426 142602 net.cpp:122] Setting up layer_128_1_scale2
I0528 21:50:17.400441 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.400444 142602 net.cpp:137] Memory required for data: 718520560
I0528 21:50:17.400450 142602 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 21:50:17.400456 142602 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 21:50:17.400460 142602 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 21:50:17.400465 142602 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 21:50:17.401046 142602 net.cpp:122] Setting up layer_128_1_relu2
I0528 21:50:17.401062 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.401067 142602 net.cpp:137] Memory required for data: 726548720
I0528 21:50:17.401069 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 21:50:17.401079 142602 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 21:50:17.401084 142602 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 21:50:17.401091 142602 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 21:50:17.406623 142602 net.cpp:122] Setting up layer_128_1_conv2
I0528 21:50:17.406641 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.406646 142602 net.cpp:137] Memory required for data: 734576880
I0528 21:50:17.406651 142602 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 21:50:17.406661 142602 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 21:50:17.406666 142602 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:50:17.406672 142602 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 21:50:17.409606 142602 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 21:50:17.409623 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.409627 142602 net.cpp:137] Memory required for data: 742605040
I0528 21:50:17.409633 142602 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 21:50:17.409642 142602 net.cpp:84] Creating Layer layer_128_1_sum
I0528 21:50:17.409647 142602 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 21:50:17.409652 142602 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 21:50:17.409657 142602 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 21:50:17.409688 142602 net.cpp:122] Setting up layer_128_1_sum
I0528 21:50:17.409696 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.409700 142602 net.cpp:137] Memory required for data: 750633200
I0528 21:50:17.409703 142602 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.409708 142602 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.409713 142602 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 21:50:17.409718 142602 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:50:17.409723 142602 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:50:17.409765 142602 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:50:17.409771 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.409775 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.409778 142602 net.cpp:137] Memory required for data: 766689520
I0528 21:50:17.409781 142602 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 21:50:17.409790 142602 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 21:50:17.409792 142602 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:50:17.409798 142602 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 21:50:17.410003 142602 net.cpp:122] Setting up layer_128_2_bn1
I0528 21:50:17.410010 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.410013 142602 net.cpp:137] Memory required for data: 774717680
I0528 21:50:17.410020 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:50:17.410033 142602 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 21:50:17.410054 142602 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 21:50:17.410063 142602 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 21:50:17.410111 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:50:17.410231 142602 net.cpp:122] Setting up layer_128_2_scale1
I0528 21:50:17.410240 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.410244 142602 net.cpp:137] Memory required for data: 782745840
I0528 21:50:17.410249 142602 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 21:50:17.410256 142602 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 21:50:17.410259 142602 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 21:50:17.410264 142602 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 21:50:17.410897 142602 net.cpp:122] Setting up layer_128_2_relu1
I0528 21:50:17.410912 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.410917 142602 net.cpp:137] Memory required for data: 790774000
I0528 21:50:17.410920 142602 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 21:50:17.410931 142602 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 21:50:17.410935 142602 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 21:50:17.410943 142602 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 21:50:17.416834 142602 net.cpp:122] Setting up layer_128_2_conv1
I0528 21:50:17.416851 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.416856 142602 net.cpp:137] Memory required for data: 798802160
I0528 21:50:17.416862 142602 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 21:50:17.416870 142602 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 21:50:17.416874 142602 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 21:50:17.416880 142602 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.417095 142602 net.cpp:122] Setting up layer_128_2_bn2
I0528 21:50:17.417107 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.417110 142602 net.cpp:137] Memory required for data: 806830320
I0528 21:50:17.417117 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:50:17.417126 142602 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 21:50:17.417130 142602 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 21:50:17.417135 142602 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.417181 142602 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:50:17.417306 142602 net.cpp:122] Setting up layer_128_2_scale2
I0528 21:50:17.417315 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.417317 142602 net.cpp:137] Memory required for data: 814858480
I0528 21:50:17.417322 142602 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 21:50:17.417328 142602 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 21:50:17.417331 142602 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 21:50:17.417338 142602 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 21:50:17.417507 142602 net.cpp:122] Setting up layer_128_2_relu2
I0528 21:50:17.417517 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.417520 142602 net.cpp:137] Memory required for data: 822886640
I0528 21:50:17.417523 142602 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 21:50:17.417534 142602 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 21:50:17.417541 142602 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 21:50:17.417546 142602 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 21:50:17.423876 142602 net.cpp:122] Setting up layer_128_2_conv2
I0528 21:50:17.423892 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.423897 142602 net.cpp:137] Memory required for data: 830914800
I0528 21:50:17.423902 142602 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 21:50:17.423915 142602 net.cpp:84] Creating Layer layer_128_2_sum
I0528 21:50:17.423923 142602 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 21:50:17.423934 142602 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:50:17.423940 142602 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 21:50:17.423974 142602 net.cpp:122] Setting up layer_128_2_sum
I0528 21:50:17.423982 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.423985 142602 net.cpp:137] Memory required for data: 838942960
I0528 21:50:17.423988 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 21:50:17.423995 142602 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 21:50:17.424000 142602 net.cpp:406] layer_256_1_bn1 <- layer_128_2_sum
I0528 21:50:17.424005 142602 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 21:50:17.424223 142602 net.cpp:122] Setting up layer_256_1_bn1
I0528 21:50:17.424234 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.424237 142602 net.cpp:137] Memory required for data: 846971120
I0528 21:50:17.424245 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:50:17.424252 142602 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 21:50:17.424255 142602 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 21:50:17.424260 142602 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 21:50:17.424310 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:50:17.424432 142602 net.cpp:122] Setting up layer_256_1_scale1
I0528 21:50:17.424439 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.424443 142602 net.cpp:137] Memory required for data: 854999280
I0528 21:50:17.424448 142602 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 21:50:17.424453 142602 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 21:50:17.424456 142602 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 21:50:17.424463 142602 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 21:50:17.424643 142602 net.cpp:122] Setting up layer_256_1_relu1
I0528 21:50:17.424654 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.424656 142602 net.cpp:137] Memory required for data: 863027440
I0528 21:50:17.424660 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.424665 142602 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.424669 142602 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 21:50:17.424676 142602 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:50:17.424686 142602 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:50:17.424736 142602 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:50:17.424743 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.424747 142602 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 21:50:17.424751 142602 net.cpp:137] Memory required for data: 879083760
I0528 21:50:17.424753 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 21:50:17.424767 142602 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 21:50:17.424772 142602 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:50:17.424779 142602 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 21:50:17.435631 142602 net.cpp:122] Setting up layer_256_1_conv1
I0528 21:50:17.435650 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.435655 142602 net.cpp:137] Memory required for data: 883097840
I0528 21:50:17.435662 142602 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 21:50:17.435668 142602 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 21:50:17.435672 142602 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 21:50:17.435680 142602 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.435907 142602 net.cpp:122] Setting up layer_256_1_bn2
I0528 21:50:17.435915 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.435923 142602 net.cpp:137] Memory required for data: 887111920
I0528 21:50:17.435947 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:50:17.435956 142602 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 21:50:17.435961 142602 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 21:50:17.435966 142602 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.436017 142602 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:50:17.436146 142602 net.cpp:122] Setting up layer_256_1_scale2
I0528 21:50:17.436158 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.436162 142602 net.cpp:137] Memory required for data: 891126000
I0528 21:50:17.436168 142602 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 21:50:17.436173 142602 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 21:50:17.436177 142602 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 21:50:17.436182 142602 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 21:50:17.436811 142602 net.cpp:122] Setting up layer_256_1_relu2
I0528 21:50:17.436825 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.436828 142602 net.cpp:137] Memory required for data: 895140080
I0528 21:50:17.436832 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 21:50:17.436846 142602 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 21:50:17.436849 142602 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 21:50:17.436856 142602 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 21:50:17.454531 142602 net.cpp:122] Setting up layer_256_1_conv2
I0528 21:50:17.454551 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.454555 142602 net.cpp:137] Memory required for data: 899154160
I0528 21:50:17.454561 142602 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 21:50:17.454572 142602 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 21:50:17.454577 142602 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:50:17.454584 142602 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 21:50:17.457932 142602 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 21:50:17.457955 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.457960 142602 net.cpp:137] Memory required for data: 903168240
I0528 21:50:17.457967 142602 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 21:50:17.457973 142602 net.cpp:84] Creating Layer layer_256_1_sum
I0528 21:50:17.457978 142602 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 21:50:17.457981 142602 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 21:50:17.457989 142602 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 21:50:17.458022 142602 net.cpp:122] Setting up layer_256_1_sum
I0528 21:50:17.458029 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.458032 142602 net.cpp:137] Memory required for data: 907182320
I0528 21:50:17.458035 142602 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.458050 142602 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.458057 142602 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 21:50:17.458062 142602 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:50:17.458070 142602 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:50:17.458114 142602 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:50:17.458122 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.458125 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.458128 142602 net.cpp:137] Memory required for data: 915210480
I0528 21:50:17.458132 142602 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 21:50:17.458138 142602 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 21:50:17.458148 142602 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:50:17.458160 142602 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 21:50:17.458375 142602 net.cpp:122] Setting up layer_256_2_bn1
I0528 21:50:17.458382 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.458386 142602 net.cpp:137] Memory required for data: 919224560
I0528 21:50:17.458394 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:50:17.458400 142602 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 21:50:17.458403 142602 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 21:50:17.458408 142602 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 21:50:17.458457 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:50:17.458577 142602 net.cpp:122] Setting up layer_256_2_scale1
I0528 21:50:17.458585 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.458588 142602 net.cpp:137] Memory required for data: 923238640
I0528 21:50:17.458593 142602 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 21:50:17.458600 142602 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 21:50:17.458606 142602 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 21:50:17.458609 142602 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 21:50:17.459206 142602 net.cpp:122] Setting up layer_256_2_relu1
I0528 21:50:17.459223 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.459226 142602 net.cpp:137] Memory required for data: 927252720
I0528 21:50:17.459230 142602 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 21:50:17.459241 142602 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 21:50:17.459246 142602 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 21:50:17.459254 142602 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 21:50:17.477540 142602 net.cpp:122] Setting up layer_256_2_conv1
I0528 21:50:17.477556 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.477561 142602 net.cpp:137] Memory required for data: 931266800
I0528 21:50:17.477566 142602 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 21:50:17.477576 142602 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 21:50:17.477581 142602 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 21:50:17.477586 142602 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.477795 142602 net.cpp:122] Setting up layer_256_2_bn2
I0528 21:50:17.477803 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.477807 142602 net.cpp:137] Memory required for data: 935280880
I0528 21:50:17.477813 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:50:17.477826 142602 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 21:50:17.477831 142602 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 21:50:17.477836 142602 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.477885 142602 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:50:17.478009 142602 net.cpp:122] Setting up layer_256_2_scale2
I0528 21:50:17.478018 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.478020 142602 net.cpp:137] Memory required for data: 939294960
I0528 21:50:17.478026 142602 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 21:50:17.478032 142602 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 21:50:17.478035 142602 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 21:50:17.478049 142602 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 21:50:17.478231 142602 net.cpp:122] Setting up layer_256_2_relu2
I0528 21:50:17.478242 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.478245 142602 net.cpp:137] Memory required for data: 943309040
I0528 21:50:17.478250 142602 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 21:50:17.478260 142602 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 21:50:17.478267 142602 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 21:50:17.478286 142602 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 21:50:17.495925 142602 net.cpp:122] Setting up layer_256_2_conv2
I0528 21:50:17.495942 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.495946 142602 net.cpp:137] Memory required for data: 947323120
I0528 21:50:17.495952 142602 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 21:50:17.495959 142602 net.cpp:84] Creating Layer layer_256_2_sum
I0528 21:50:17.495964 142602 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 21:50:17.495967 142602 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:50:17.495975 142602 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 21:50:17.496009 142602 net.cpp:122] Setting up layer_256_2_sum
I0528 21:50:17.496017 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.496019 142602 net.cpp:137] Memory required for data: 951337200
I0528 21:50:17.496023 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 21:50:17.496029 142602 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 21:50:17.496032 142602 net.cpp:406] layer_512_1_bn1 <- layer_256_2_sum
I0528 21:50:17.496045 142602 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 21:50:17.496266 142602 net.cpp:122] Setting up layer_512_1_bn1
I0528 21:50:17.496275 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.496279 142602 net.cpp:137] Memory required for data: 955351280
I0528 21:50:17.496285 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:50:17.496294 142602 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 21:50:17.496299 142602 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 21:50:17.496304 142602 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 21:50:17.496351 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:50:17.496472 142602 net.cpp:122] Setting up layer_512_1_scale1
I0528 21:50:17.496480 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.496484 142602 net.cpp:137] Memory required for data: 959365360
I0528 21:50:17.496490 142602 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 21:50:17.496495 142602 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 21:50:17.496498 142602 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 21:50:17.496505 142602 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 21:50:17.497092 142602 net.cpp:122] Setting up layer_512_1_relu1
I0528 21:50:17.497108 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.497112 142602 net.cpp:137] Memory required for data: 963379440
I0528 21:50:17.497117 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.497123 142602 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.497128 142602 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 21:50:17.497134 142602 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:50:17.497143 142602 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:50:17.497192 142602 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:50:17.497201 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.497205 142602 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 21:50:17.497208 142602 net.cpp:137] Memory required for data: 971407600
I0528 21:50:17.497211 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 21:50:17.497220 142602 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 21:50:17.497225 142602 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:50:17.497232 142602 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 21:50:17.530385 142602 net.cpp:122] Setting up layer_512_1_conv1
I0528 21:50:17.530405 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.530413 142602 net.cpp:137] Memory required for data: 973414640
I0528 21:50:17.530426 142602 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 21:50:17.530432 142602 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 21:50:17.530436 142602 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 21:50:17.530444 142602 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.530676 142602 net.cpp:122] Setting up layer_512_1_bn2
I0528 21:50:17.530684 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.530688 142602 net.cpp:137] Memory required for data: 975421680
I0528 21:50:17.530694 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:50:17.530702 142602 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 21:50:17.530706 142602 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 21:50:17.530712 142602 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.530760 142602 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:50:17.530889 142602 net.cpp:122] Setting up layer_512_1_scale2
I0528 21:50:17.530896 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.530900 142602 net.cpp:137] Memory required for data: 977428720
I0528 21:50:17.530905 142602 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 21:50:17.530911 142602 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 21:50:17.530915 142602 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 21:50:17.530921 142602 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 21:50:17.531512 142602 net.cpp:122] Setting up layer_512_1_relu2
I0528 21:50:17.531527 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.531532 142602 net.cpp:137] Memory required for data: 979435760
I0528 21:50:17.531535 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 21:50:17.531548 142602 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 21:50:17.531553 142602 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 21:50:17.531560 142602 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 21:50:17.597427 142602 net.cpp:122] Setting up layer_512_1_conv2
I0528 21:50:17.597448 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.597453 142602 net.cpp:137] Memory required for data: 981442800
I0528 21:50:17.597460 142602 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 21:50:17.597471 142602 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 21:50:17.597476 142602 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:50:17.597486 142602 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 21:50:17.602572 142602 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 21:50:17.602589 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.602593 142602 net.cpp:137] Memory required for data: 983449840
I0528 21:50:17.602598 142602 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 21:50:17.602607 142602 net.cpp:84] Creating Layer layer_512_1_sum
I0528 21:50:17.602612 142602 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 21:50:17.602617 142602 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 21:50:17.602622 142602 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 21:50:17.602658 142602 net.cpp:122] Setting up layer_512_1_sum
I0528 21:50:17.602664 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.602668 142602 net.cpp:137] Memory required for data: 985456880
I0528 21:50:17.602671 142602 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.602676 142602 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.602680 142602 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 21:50:17.602687 142602 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:50:17.602694 142602 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:50:17.602754 142602 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:50:17.602763 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.602767 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.602771 142602 net.cpp:137] Memory required for data: 989470960
I0528 21:50:17.602774 142602 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 21:50:17.602780 142602 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 21:50:17.602783 142602 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:50:17.602792 142602 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 21:50:17.603018 142602 net.cpp:122] Setting up layer_512_2_bn1
I0528 21:50:17.603024 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.603027 142602 net.cpp:137] Memory required for data: 991478000
I0528 21:50:17.603035 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:50:17.603049 142602 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 21:50:17.603056 142602 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 21:50:17.603065 142602 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 21:50:17.603113 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:50:17.603247 142602 net.cpp:122] Setting up layer_512_2_scale1
I0528 21:50:17.603255 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.603258 142602 net.cpp:137] Memory required for data: 993485040
I0528 21:50:17.603263 142602 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 21:50:17.603269 142602 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 21:50:17.603273 142602 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 21:50:17.603278 142602 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 21:50:17.603863 142602 net.cpp:122] Setting up layer_512_2_relu1
I0528 21:50:17.603878 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.603880 142602 net.cpp:137] Memory required for data: 995492080
I0528 21:50:17.603884 142602 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 21:50:17.603895 142602 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 21:50:17.603900 142602 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 21:50:17.603906 142602 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 21:50:17.669466 142602 net.cpp:122] Setting up layer_512_2_conv1
I0528 21:50:17.669486 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.669492 142602 net.cpp:137] Memory required for data: 997499120
I0528 21:50:17.669497 142602 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 21:50:17.669505 142602 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 21:50:17.669510 142602 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 21:50:17.669517 142602 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.669741 142602 net.cpp:122] Setting up layer_512_2_bn2
I0528 21:50:17.669750 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.669754 142602 net.cpp:137] Memory required for data: 999506160
I0528 21:50:17.669762 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:50:17.669770 142602 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 21:50:17.669775 142602 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 21:50:17.669780 142602 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.669826 142602 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:50:17.669960 142602 net.cpp:122] Setting up layer_512_2_scale2
I0528 21:50:17.669968 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.669971 142602 net.cpp:137] Memory required for data: 1001513200
I0528 21:50:17.669977 142602 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 21:50:17.669983 142602 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 21:50:17.669987 142602 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 21:50:17.669993 142602 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 21:50:17.670191 142602 net.cpp:122] Setting up layer_512_2_relu2
I0528 21:50:17.670204 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.670207 142602 net.cpp:137] Memory required for data: 1003520240
I0528 21:50:17.670212 142602 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 21:50:17.670228 142602 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 21:50:17.670231 142602 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 21:50:17.670238 142602 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 21:50:17.735986 142602 net.cpp:122] Setting up layer_512_2_conv2
I0528 21:50:17.736019 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.736024 142602 net.cpp:137] Memory required for data: 1005527280
I0528 21:50:17.736049 142602 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 21:50:17.736069 142602 net.cpp:84] Creating Layer layer_512_2_sum
I0528 21:50:17.736075 142602 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 21:50:17.736080 142602 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:50:17.736086 142602 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 21:50:17.736129 142602 net.cpp:122] Setting up layer_512_2_sum
I0528 21:50:17.736135 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.736138 142602 net.cpp:137] Memory required for data: 1007534320
I0528 21:50:17.736142 142602 layer_factory.hpp:77] Creating layer last_bn
I0528 21:50:17.736150 142602 net.cpp:84] Creating Layer last_bn
I0528 21:50:17.736155 142602 net.cpp:406] last_bn <- layer_512_2_sum
I0528 21:50:17.736160 142602 net.cpp:367] last_bn -> layer_512_2_sum (in-place)
I0528 21:50:17.736376 142602 net.cpp:122] Setting up last_bn
I0528 21:50:17.736383 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.736387 142602 net.cpp:137] Memory required for data: 1009541360
I0528 21:50:17.736393 142602 layer_factory.hpp:77] Creating layer last_scale
I0528 21:50:17.736400 142602 net.cpp:84] Creating Layer last_scale
I0528 21:50:17.736404 142602 net.cpp:406] last_scale <- layer_512_2_sum
I0528 21:50:17.736413 142602 net.cpp:367] last_scale -> layer_512_2_sum (in-place)
I0528 21:50:17.736459 142602 layer_factory.hpp:77] Creating layer last_scale
I0528 21:50:17.736590 142602 net.cpp:122] Setting up last_scale
I0528 21:50:17.736598 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.736601 142602 net.cpp:137] Memory required for data: 1011548400
I0528 21:50:17.736606 142602 layer_factory.hpp:77] Creating layer last_relu
I0528 21:50:17.736614 142602 net.cpp:84] Creating Layer last_relu
I0528 21:50:17.736618 142602 net.cpp:406] last_relu <- layer_512_2_sum
I0528 21:50:17.736623 142602 net.cpp:367] last_relu -> layer_512_2_sum (in-place)
I0528 21:50:17.737218 142602 net.cpp:122] Setting up last_relu
I0528 21:50:17.737234 142602 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 21:50:17.737238 142602 net.cpp:137] Memory required for data: 1013555440
I0528 21:50:17.737241 142602 layer_factory.hpp:77] Creating layer global_pool
I0528 21:50:17.737251 142602 net.cpp:84] Creating Layer global_pool
I0528 21:50:17.737256 142602 net.cpp:406] global_pool <- layer_512_2_sum
I0528 21:50:17.737262 142602 net.cpp:380] global_pool -> global_pool
I0528 21:50:17.737458 142602 net.cpp:122] Setting up global_pool
I0528 21:50:17.737470 142602 net.cpp:129] Top shape: 20 512 1 1 (10240)
I0528 21:50:17.737474 142602 net.cpp:137] Memory required for data: 1013596400
I0528 21:50:17.737478 142602 layer_factory.hpp:77] Creating layer score
I0528 21:50:17.737485 142602 net.cpp:84] Creating Layer score
I0528 21:50:17.737489 142602 net.cpp:406] score <- global_pool
I0528 21:50:17.737495 142602 net.cpp:380] score -> score
I0528 21:50:17.737648 142602 net.cpp:122] Setting up score
I0528 21:50:17.737655 142602 net.cpp:129] Top shape: 20 8 (160)
I0528 21:50:17.737658 142602 net.cpp:137] Memory required for data: 1013597040
I0528 21:50:17.737664 142602 layer_factory.hpp:77] Creating layer score_score_0_split
I0528 21:50:17.737679 142602 net.cpp:84] Creating Layer score_score_0_split
I0528 21:50:17.737691 142602 net.cpp:406] score_score_0_split <- score
I0528 21:50:17.737697 142602 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0528 21:50:17.737704 142602 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0528 21:50:17.737753 142602 net.cpp:122] Setting up score_score_0_split
I0528 21:50:17.737761 142602 net.cpp:129] Top shape: 20 8 (160)
I0528 21:50:17.737764 142602 net.cpp:129] Top shape: 20 8 (160)
I0528 21:50:17.737767 142602 net.cpp:137] Memory required for data: 1013598320
I0528 21:50:17.737771 142602 layer_factory.hpp:77] Creating layer loss
I0528 21:50:17.737776 142602 net.cpp:84] Creating Layer loss
I0528 21:50:17.737781 142602 net.cpp:406] loss <- score_score_0_split_0
I0528 21:50:17.737784 142602 net.cpp:406] loss <- label_data_1_split_0
I0528 21:50:17.737792 142602 net.cpp:380] loss -> loss
I0528 21:50:17.737799 142602 layer_factory.hpp:77] Creating layer loss
I0528 21:50:17.738497 142602 net.cpp:122] Setting up loss
I0528 21:50:17.738513 142602 net.cpp:129] Top shape: (1)
I0528 21:50:17.738517 142602 net.cpp:132]     with loss weight 1
I0528 21:50:17.738529 142602 net.cpp:137] Memory required for data: 1013598324
I0528 21:50:17.738533 142602 layer_factory.hpp:77] Creating layer accuracy
I0528 21:50:17.738543 142602 net.cpp:84] Creating Layer accuracy
I0528 21:50:17.738548 142602 net.cpp:406] accuracy <- score_score_0_split_1
I0528 21:50:17.738554 142602 net.cpp:406] accuracy <- label_data_1_split_1
I0528 21:50:17.738561 142602 net.cpp:380] accuracy -> accuracy
I0528 21:50:17.738574 142602 net.cpp:122] Setting up accuracy
I0528 21:50:17.738579 142602 net.cpp:129] Top shape: (1)
I0528 21:50:17.738584 142602 net.cpp:137] Memory required for data: 1013598328
I0528 21:50:17.738586 142602 net.cpp:200] accuracy does not need backward computation.
I0528 21:50:17.738590 142602 net.cpp:198] loss needs backward computation.
I0528 21:50:17.738595 142602 net.cpp:198] score_score_0_split needs backward computation.
I0528 21:50:17.738597 142602 net.cpp:198] score needs backward computation.
I0528 21:50:17.738600 142602 net.cpp:198] global_pool needs backward computation.
I0528 21:50:17.738603 142602 net.cpp:198] last_relu needs backward computation.
I0528 21:50:17.738606 142602 net.cpp:198] last_scale needs backward computation.
I0528 21:50:17.738610 142602 net.cpp:198] last_bn needs backward computation.
I0528 21:50:17.738612 142602 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 21:50:17.738616 142602 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 21:50:17.738620 142602 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 21:50:17.738622 142602 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 21:50:17.738626 142602 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 21:50:17.738628 142602 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 21:50:17.738632 142602 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 21:50:17.738636 142602 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 21:50:17.738638 142602 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 21:50:17.738641 142602 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 21:50:17.738646 142602 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 21:50:17.738649 142602 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 21:50:17.738653 142602 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 21:50:17.738656 142602 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 21:50:17.738661 142602 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 21:50:17.738663 142602 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 21:50:17.738667 142602 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 21:50:17.738670 142602 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 21:50:17.738679 142602 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 21:50:17.738689 142602 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 21:50:17.738693 142602 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 21:50:17.738698 142602 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 21:50:17.738701 142602 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 21:50:17.738704 142602 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 21:50:17.738708 142602 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 21:50:17.738711 142602 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 21:50:17.738715 142602 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 21:50:17.738718 142602 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 21:50:17.738721 142602 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 21:50:17.738725 142602 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 21:50:17.738729 142602 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 21:50:17.738732 142602 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 21:50:17.738736 142602 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 21:50:17.738740 142602 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 21:50:17.738744 142602 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 21:50:17.738747 142602 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 21:50:17.738750 142602 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 21:50:17.738754 142602 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 21:50:17.738757 142602 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 21:50:17.738761 142602 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 21:50:17.738765 142602 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 21:50:17.738767 142602 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 21:50:17.738771 142602 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 21:50:17.738775 142602 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 21:50:17.738778 142602 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 21:50:17.738781 142602 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 21:50:17.738785 142602 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 21:50:17.738788 142602 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 21:50:17.738792 142602 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 21:50:17.738795 142602 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 21:50:17.738798 142602 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 21:50:17.738802 142602 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 21:50:17.738808 142602 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 21:50:17.738812 142602 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 21:50:17.738816 142602 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 21:50:17.738819 142602 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 21:50:17.738822 142602 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 21:50:17.738826 142602 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 21:50:17.738829 142602 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 21:50:17.738833 142602 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 21:50:17.738837 142602 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 21:50:17.738840 142602 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 21:50:17.738843 142602 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 21:50:17.738847 142602 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 21:50:17.738857 142602 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 21:50:17.738860 142602 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 21:50:17.738864 142602 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 21:50:17.738867 142602 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 21:50:17.738870 142602 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 21:50:17.738874 142602 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 21:50:17.738878 142602 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 21:50:17.738881 142602 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 21:50:17.738885 142602 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 21:50:17.738888 142602 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 21:50:17.738893 142602 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 21:50:17.738896 142602 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 21:50:17.738899 142602 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 21:50:17.738903 142602 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 21:50:17.738906 142602 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 21:50:17.738910 142602 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 21:50:17.738914 142602 net.cpp:198] conv1_pool needs backward computation.
I0528 21:50:17.738917 142602 net.cpp:198] conv1_relu needs backward computation.
I0528 21:50:17.738921 142602 net.cpp:198] conv1_scale needs backward computation.
I0528 21:50:17.738924 142602 net.cpp:198] conv1_bn needs backward computation.
I0528 21:50:17.738927 142602 net.cpp:198] conv1 needs backward computation.
I0528 21:50:17.738931 142602 net.cpp:198] data_scale needs backward computation.
I0528 21:50:17.738935 142602 net.cpp:200] data_bn does not need backward computation.
I0528 21:50:17.738940 142602 net.cpp:200] label_data_1_split does not need backward computation.
I0528 21:50:17.738943 142602 net.cpp:200] data does not need backward computation.
I0528 21:50:17.738946 142602 net.cpp:242] This network produces output accuracy
I0528 21:50:17.738950 142602 net.cpp:242] This network produces output loss
I0528 21:50:17.739001 142602 net.cpp:255] Network initialization done.
I0528 21:50:17.739372 142602 solver.cpp:56] Solver scaffolding done.
I0528 21:50:17.743731 142602 caffe.cpp:248] Starting Optimization
I0528 21:50:17.743744 142602 solver.cpp:272] Solving Pre-ResNet-18
I0528 21:50:17.743747 142602 solver.cpp:273] Learning Rate Policy: poly
I0528 21:50:17.751370 142602 solver.cpp:330] Iteration 0, Testing net (#0)
I0528 21:50:53.806224 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:51:30.009080 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:51:31.963867 142602 solver.cpp:397]     Test net output #0: accuracy = 0.12265
I0528 21:51:31.963945 142602 solver.cpp:397]     Test net output #1: loss = 87.3361 (* 1 = 87.3361 loss)
I0528 21:51:33.253299 142602 solver.cpp:218] Iteration 0 (6.38332 iter/s, 75.5079s/100 iters), loss = 2.07944
I0528 21:51:33.253334 142602 solver.cpp:237]     Train net output #0: loss = 2.07944 (* 1 = 2.07944 loss)
I0528 21:51:33.253358 142602 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0528 21:53:41.458729 142602 solver.cpp:218] Iteration 100 (0.780015 iter/s, 128.203s/100 iters), loss = 1.60711
I0528 21:53:41.458940 142602 solver.cpp:237]     Train net output #0: loss = 1.60711 (* 1 = 1.60711 loss)
I0528 21:53:41.458952 142602 sgd_solver.cpp:105] Iteration 100, lr = 0.009995
I0528 21:55:49.610388 142602 solver.cpp:218] Iteration 200 (0.780345 iter/s, 128.148s/100 iters), loss = 1.39015
I0528 21:55:49.610605 142602 solver.cpp:237]     Train net output #0: loss = 1.39015 (* 1 = 1.39015 loss)
I0528 21:55:49.610648 142602 sgd_solver.cpp:105] Iteration 200, lr = 0.00999
I0528 21:57:57.736364 142602 solver.cpp:218] Iteration 300 (0.780502 iter/s, 128.123s/100 iters), loss = 1.65598
I0528 21:57:57.736629 142602 solver.cpp:237]     Train net output #0: loss = 1.65598 (* 1 = 1.65598 loss)
I0528 21:57:57.736666 142602 sgd_solver.cpp:105] Iteration 300, lr = 0.009985
I0528 21:59:48.197228 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:00:05.894369 142602 solver.cpp:218] Iteration 400 (0.780307 iter/s, 128.155s/100 iters), loss = 1.45524
I0528 22:00:05.894436 142602 solver.cpp:237]     Train net output #0: loss = 1.45524 (* 1 = 1.45524 loss)
I0528 22:00:05.894451 142602 sgd_solver.cpp:105] Iteration 400, lr = 0.00998
I0528 22:02:14.050506 142602 solver.cpp:218] Iteration 500 (0.780317 iter/s, 128.153s/100 iters), loss = 1.42211
I0528 22:02:14.050793 142602 solver.cpp:237]     Train net output #0: loss = 1.42211 (* 1 = 1.42211 loss)
I0528 22:02:14.050812 142602 sgd_solver.cpp:105] Iteration 500, lr = 0.009975
I0528 22:04:22.259814 142602 solver.cpp:218] Iteration 600 (0.779995 iter/s, 128.206s/100 iters), loss = 1.40671
I0528 22:04:22.260006 142602 solver.cpp:237]     Train net output #0: loss = 1.40671 (* 1 = 1.40671 loss)
I0528 22:04:22.260036 142602 sgd_solver.cpp:105] Iteration 600, lr = 0.00997
I0528 22:06:30.513922 142602 solver.cpp:218] Iteration 700 (0.779722 iter/s, 128.251s/100 iters), loss = 1.36108
I0528 22:06:30.514293 142602 solver.cpp:237]     Train net output #0: loss = 1.36108 (* 1 = 1.36108 loss)
I0528 22:06:30.514313 142602 sgd_solver.cpp:105] Iteration 700, lr = 0.009965
I0528 22:08:09.384483 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:08:38.771005 142602 solver.cpp:218] Iteration 800 (0.779705 iter/s, 128.254s/100 iters), loss = 1.40295
I0528 22:08:38.771087 142602 solver.cpp:237]     Train net output #0: loss = 1.40295 (* 1 = 1.40295 loss)
I0528 22:08:38.771102 142602 sgd_solver.cpp:105] Iteration 800, lr = 0.00996
I0528 22:10:47.008977 142602 solver.cpp:218] Iteration 900 (0.779819 iter/s, 128.235s/100 iters), loss = 1.45093
I0528 22:10:47.009160 142602 solver.cpp:237]     Train net output #0: loss = 1.45093 (* 1 = 1.45093 loss)
I0528 22:10:47.009196 142602 sgd_solver.cpp:105] Iteration 900, lr = 0.009955
I0528 22:12:53.958473 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_1000.caffemodel
I0528 22:12:54.423518 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_1000.solverstate
I0528 22:12:54.481025 142602 solver.cpp:330] Iteration 1000, Testing net (#0)
I0528 22:13:28.864480 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:14:05.126080 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:14:08.796955 142602 solver.cpp:397]     Test net output #0: accuracy = 0.41675
I0528 22:14:08.797049 142602 solver.cpp:397]     Test net output #1: loss = 1.42168 (* 1 = 1.42168 loss)
I0528 22:14:10.072648 142602 solver.cpp:218] Iteration 1000 (0.492468 iter/s, 203.059s/100 iters), loss = 1.34397
I0528 22:14:10.072715 142602 solver.cpp:237]     Train net output #0: loss = 1.34397 (* 1 = 1.34397 loss)
I0528 22:14:10.072731 142602 sgd_solver.cpp:105] Iteration 1000, lr = 0.00995
I0528 22:16:18.331986 142602 solver.cpp:218] Iteration 1100 (0.779689 iter/s, 128.256s/100 iters), loss = 1.38446
I0528 22:16:18.332211 142602 solver.cpp:237]     Train net output #0: loss = 1.38446 (* 1 = 1.38446 loss)
I0528 22:16:18.332249 142602 sgd_solver.cpp:105] Iteration 1100, lr = 0.009945
I0528 22:17:44.527807 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:18:26.589956 142602 solver.cpp:218] Iteration 1200 (0.779699 iter/s, 128.255s/100 iters), loss = 1.3409
I0528 22:18:26.590207 142602 solver.cpp:237]     Train net output #0: loss = 1.3409 (* 1 = 1.3409 loss)
I0528 22:18:26.590255 142602 sgd_solver.cpp:105] Iteration 1200, lr = 0.00994
I0528 22:20:34.858582 142602 solver.cpp:218] Iteration 1300 (0.779634 iter/s, 128.265s/100 iters), loss = 1.23855
I0528 22:20:34.858788 142602 solver.cpp:237]     Train net output #0: loss = 1.23855 (* 1 = 1.23855 loss)
I0528 22:20:34.858811 142602 sgd_solver.cpp:105] Iteration 1300, lr = 0.009935
I0528 22:22:43.078974 142602 solver.cpp:218] Iteration 1400 (0.779927 iter/s, 128.217s/100 iters), loss = 1.22781
I0528 22:22:43.079207 142602 solver.cpp:237]     Train net output #0: loss = 1.22781 (* 1 = 1.22781 loss)
I0528 22:22:43.079224 142602 sgd_solver.cpp:105] Iteration 1400, lr = 0.00993
I0528 22:24:51.353468 142602 solver.cpp:218] Iteration 1500 (0.779599 iter/s, 128.271s/100 iters), loss = 1.22438
I0528 22:24:51.353700 142602 solver.cpp:237]     Train net output #0: loss = 1.22438 (* 1 = 1.22438 loss)
I0528 22:24:51.353739 142602 sgd_solver.cpp:105] Iteration 1500, lr = 0.009925
I0528 22:26:05.999176 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:26:59.643380 142602 solver.cpp:218] Iteration 1600 (0.779505 iter/s, 128.287s/100 iters), loss = 1.25129
I0528 22:26:59.643599 142602 solver.cpp:237]     Train net output #0: loss = 1.25129 (* 1 = 1.25129 loss)
I0528 22:26:59.643628 142602 sgd_solver.cpp:105] Iteration 1600, lr = 0.00992
I0528 22:29:07.878886 142602 solver.cpp:218] Iteration 1700 (0.779835 iter/s, 128.232s/100 iters), loss = 1.28804
I0528 22:29:07.879078 142602 solver.cpp:237]     Train net output #0: loss = 1.28804 (* 1 = 1.28804 loss)
I0528 22:29:07.879110 142602 sgd_solver.cpp:105] Iteration 1700, lr = 0.009915
I0528 22:31:16.147451 142602 solver.cpp:218] Iteration 1800 (0.779634 iter/s, 128.265s/100 iters), loss = 1.30683
I0528 22:31:16.147651 142602 solver.cpp:237]     Train net output #0: loss = 1.30683 (* 1 = 1.30683 loss)
I0528 22:31:16.147666 142602 sgd_solver.cpp:105] Iteration 1800, lr = 0.00991
I0528 22:33:24.427547 142602 solver.cpp:218] Iteration 1900 (0.779564 iter/s, 128.277s/100 iters), loss = 1.22323
I0528 22:33:24.427790 142602 solver.cpp:237]     Train net output #0: loss = 1.22323 (* 1 = 1.22323 loss)
I0528 22:33:24.427806 142602 sgd_solver.cpp:105] Iteration 1900, lr = 0.009905
I0528 22:34:27.490552 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:35:31.458217 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_2000.caffemodel
I0528 22:35:31.675194 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_2000.solverstate
I0528 22:35:31.731768 142602 solver.cpp:330] Iteration 2000, Testing net (#0)
I0528 22:36:04.356215 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:36:40.692255 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:36:46.081951 142602 solver.cpp:397]     Test net output #0: accuracy = 0.45745
I0528 22:36:46.082059 142602 solver.cpp:397]     Test net output #1: loss = 1.42395 (* 1 = 1.42395 loss)
I0528 22:36:47.362210 142602 solver.cpp:218] Iteration 2000 (0.492782 iter/s, 202.93s/100 iters), loss = 1.32162
I0528 22:36:47.362299 142602 solver.cpp:237]     Train net output #0: loss = 1.32162 (* 1 = 1.32162 loss)
I0528 22:36:47.362314 142602 sgd_solver.cpp:105] Iteration 2000, lr = 0.0099
I0528 22:38:55.720054 142602 solver.cpp:218] Iteration 2100 (0.779091 iter/s, 128.355s/100 iters), loss = 1.3363
I0528 22:38:55.720245 142602 solver.cpp:237]     Train net output #0: loss = 1.3363 (* 1 = 1.3363 loss)
I0528 22:38:55.720278 142602 sgd_solver.cpp:105] Iteration 2100, lr = 0.009895
I0528 22:41:04.020730 142602 solver.cpp:218] Iteration 2200 (0.779439 iter/s, 128.297s/100 iters), loss = 1.40504
I0528 22:41:04.020901 142602 solver.cpp:237]     Train net output #0: loss = 1.40504 (* 1 = 1.40504 loss)
I0528 22:41:04.020918 142602 sgd_solver.cpp:105] Iteration 2200, lr = 0.00989
I0528 22:43:12.324977 142602 solver.cpp:218] Iteration 2300 (0.779417 iter/s, 128.301s/100 iters), loss = 1.23004
I0528 22:43:12.325160 142602 solver.cpp:237]     Train net output #0: loss = 1.23004 (* 1 = 1.23004 loss)
I0528 22:43:12.325193 142602 sgd_solver.cpp:105] Iteration 2300, lr = 0.009885
I0528 22:44:02.637362 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:45:20.624914 142602 solver.cpp:218] Iteration 2400 (0.779443 iter/s, 128.297s/100 iters), loss = 1.33036
I0528 22:45:20.625180 142602 solver.cpp:237]     Train net output #0: loss = 1.33036 (* 1 = 1.33036 loss)
I0528 22:45:20.625200 142602 sgd_solver.cpp:105] Iteration 2400, lr = 0.00988
I0528 22:47:28.901989 142602 solver.cpp:218] Iteration 2500 (0.779583 iter/s, 128.274s/100 iters), loss = 1.31922
I0528 22:47:28.902191 142602 solver.cpp:237]     Train net output #0: loss = 1.31922 (* 1 = 1.31922 loss)
I0528 22:47:28.902237 142602 sgd_solver.cpp:105] Iteration 2500, lr = 0.009875
I0528 22:49:37.237123 142602 solver.cpp:218] Iteration 2600 (0.77923 iter/s, 128.332s/100 iters), loss = 1.26171
I0528 22:49:37.237325 142602 solver.cpp:237]     Train net output #0: loss = 1.26171 (* 1 = 1.26171 loss)
I0528 22:49:37.237350 142602 sgd_solver.cpp:105] Iteration 2600, lr = 0.00987
I0528 22:51:45.546178 142602 solver.cpp:218] Iteration 2700 (0.779388 iter/s, 128.306s/100 iters), loss = 1.37043
I0528 22:51:45.546399 142602 solver.cpp:237]     Train net output #0: loss = 1.37043 (* 1 = 1.37043 loss)
I0528 22:51:45.546416 142602 sgd_solver.cpp:105] Iteration 2700, lr = 0.009865
I0528 22:52:24.283061 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:53:53.860652 142602 solver.cpp:218] Iteration 2800 (0.779355 iter/s, 128.311s/100 iters), loss = 1.08915
I0528 22:53:53.860884 142602 solver.cpp:237]     Train net output #0: loss = 1.08915 (* 1 = 1.08915 loss)
I0528 22:53:53.860901 142602 sgd_solver.cpp:105] Iteration 2800, lr = 0.00986
I0528 22:56:02.232394 142602 solver.cpp:218] Iteration 2900 (0.779007 iter/s, 128.368s/100 iters), loss = 1.298
I0528 22:56:02.232619 142602 solver.cpp:237]     Train net output #0: loss = 1.298 (* 1 = 1.298 loss)
I0528 22:56:02.232662 142602 sgd_solver.cpp:105] Iteration 2900, lr = 0.009855
I0528 22:58:09.271770 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_3000.caffemodel
I0528 22:58:09.551337 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_3000.solverstate
I0528 22:58:09.607692 142602 solver.cpp:330] Iteration 3000, Testing net (#0)
I0528 22:58:40.608675 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:59:16.973687 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:59:24.147045 142602 solver.cpp:397]     Test net output #0: accuracy = 0.46595
I0528 22:59:24.147125 142602 solver.cpp:397]     Test net output #1: loss = 1.35626 (* 1 = 1.35626 loss)
I0528 22:59:25.426331 142602 solver.cpp:218] Iteration 3000 (0.492153 iter/s, 203.189s/100 iters), loss = 1.20354
I0528 22:59:25.426410 142602 solver.cpp:237]     Train net output #0: loss = 1.20354 (* 1 = 1.20354 loss)
I0528 22:59:25.426424 142602 sgd_solver.cpp:105] Iteration 3000, lr = 0.00985
I0528 23:01:33.777341 142602 solver.cpp:218] Iteration 3100 (0.779132 iter/s, 128.348s/100 iters), loss = 1.07762
I0528 23:01:33.777501 142602 solver.cpp:237]     Train net output #0: loss = 1.07762 (* 1 = 1.07762 loss)
I0528 23:01:33.777528 142602 sgd_solver.cpp:105] Iteration 3100, lr = 0.009845
I0528 23:02:00.930093 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:03:42.150758 142602 solver.cpp:218] Iteration 3200 (0.778997 iter/s, 128.37s/100 iters), loss = 1.15395
I0528 23:03:42.151005 142602 solver.cpp:237]     Train net output #0: loss = 1.15395 (* 1 = 1.15395 loss)
I0528 23:03:42.151021 142602 sgd_solver.cpp:105] Iteration 3200, lr = 0.00984
I0528 23:05:50.579871 142602 solver.cpp:218] Iteration 3300 (0.77866 iter/s, 128.426s/100 iters), loss = 1.15921
I0528 23:05:50.580078 142602 solver.cpp:237]     Train net output #0: loss = 1.15921 (* 1 = 1.15921 loss)
I0528 23:05:50.580097 142602 sgd_solver.cpp:105] Iteration 3300, lr = 0.009835
I0528 23:07:59.000242 142602 solver.cpp:218] Iteration 3400 (0.778713 iter/s, 128.417s/100 iters), loss = 1.15681
I0528 23:07:59.000439 142602 solver.cpp:237]     Train net output #0: loss = 1.15681 (* 1 = 1.15681 loss)
I0528 23:07:59.000454 142602 sgd_solver.cpp:105] Iteration 3400, lr = 0.00983
I0528 23:10:07.404080 142602 solver.cpp:218] Iteration 3500 (0.778813 iter/s, 128.401s/100 iters), loss = 1.27802
I0528 23:10:07.404294 142602 solver.cpp:237]     Train net output #0: loss = 1.27802 (* 1 = 1.27802 loss)
I0528 23:10:07.404311 142602 sgd_solver.cpp:105] Iteration 3500, lr = 0.009825
I0528 23:10:21.767231 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:12:15.830446 142602 solver.cpp:218] Iteration 3600 (0.778677 iter/s, 128.423s/100 iters), loss = 1.23941
I0528 23:12:15.830665 142602 solver.cpp:237]     Train net output #0: loss = 1.23941 (* 1 = 1.23941 loss)
I0528 23:12:15.830700 142602 sgd_solver.cpp:105] Iteration 3600, lr = 0.00982
I0528 23:14:24.243651 142602 solver.cpp:218] Iteration 3700 (0.778756 iter/s, 128.41s/100 iters), loss = 1.19522
I0528 23:14:24.243866 142602 solver.cpp:237]     Train net output #0: loss = 1.19522 (* 1 = 1.19522 loss)
I0528 23:14:24.243901 142602 sgd_solver.cpp:105] Iteration 3700, lr = 0.009815
I0528 23:16:32.649180 142602 solver.cpp:218] Iteration 3800 (0.778803 iter/s, 128.402s/100 iters), loss = 1.24902
I0528 23:16:32.649348 142602 solver.cpp:237]     Train net output #0: loss = 1.24902 (* 1 = 1.24902 loss)
I0528 23:16:32.649363 142602 sgd_solver.cpp:105] Iteration 3800, lr = 0.00981
I0528 23:18:41.114811 142602 solver.cpp:218] Iteration 3900 (0.778438 iter/s, 128.462s/100 iters), loss = 1.14925
I0528 23:18:41.114977 142602 solver.cpp:237]     Train net output #0: loss = 1.14925 (* 1 = 1.14925 loss)
I0528 23:18:41.115020 142602 sgd_solver.cpp:105] Iteration 3900, lr = 0.009805
I0528 23:18:43.928858 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:20:48.205662 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_4000.caffemodel
I0528 23:20:48.554744 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_4000.solverstate
I0528 23:20:48.606884 142602 solver.cpp:330] Iteration 4000, Testing net (#0)
I0528 23:21:17.818915 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:21:54.122714 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:22:03.009718 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4583
I0528 23:22:03.009815 142602 solver.cpp:397]     Test net output #1: loss = 1.42018 (* 1 = 1.42018 loss)
I0528 23:22:04.288018 142602 solver.cpp:218] Iteration 4000 (0.492203 iter/s, 203.168s/100 iters), loss = 1.09016
I0528 23:22:04.288115 142602 solver.cpp:237]     Train net output #0: loss = 1.09016 (* 1 = 1.09016 loss)
I0528 23:22:04.288131 142602 sgd_solver.cpp:105] Iteration 4000, lr = 0.0098
I0528 23:24:12.681658 142602 solver.cpp:218] Iteration 4100 (0.778875 iter/s, 128.39s/100 iters), loss = 1.23949
I0528 23:24:12.681901 142602 solver.cpp:237]     Train net output #0: loss = 1.23949 (* 1 = 1.23949 loss)
I0528 23:24:12.681919 142602 sgd_solver.cpp:105] Iteration 4100, lr = 0.009795
I0528 23:26:21.054352 142602 solver.cpp:218] Iteration 4200 (0.779002 iter/s, 128.369s/100 iters), loss = 1.12479
I0528 23:26:21.054556 142602 solver.cpp:237]     Train net output #0: loss = 1.12479 (* 1 = 1.12479 loss)
I0528 23:26:21.054582 142602 sgd_solver.cpp:105] Iteration 4200, lr = 0.00979
I0528 23:28:20.666584 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:28:29.448923 142602 solver.cpp:218] Iteration 4300 (0.778869 iter/s, 128.391s/100 iters), loss = 1.17916
I0528 23:28:29.449023 142602 solver.cpp:237]     Train net output #0: loss = 1.17916 (* 1 = 1.17916 loss)
I0528 23:28:29.449043 142602 sgd_solver.cpp:105] Iteration 4300, lr = 0.009785
I0528 23:30:37.848078 142602 solver.cpp:218] Iteration 4400 (0.778841 iter/s, 128.396s/100 iters), loss = 1.15253
I0528 23:30:37.848284 142602 solver.cpp:237]     Train net output #0: loss = 1.15253 (* 1 = 1.15253 loss)
I0528 23:30:37.848325 142602 sgd_solver.cpp:105] Iteration 4400, lr = 0.00978
I0528 23:32:46.191113 142602 solver.cpp:218] Iteration 4500 (0.779182 iter/s, 128.34s/100 iters), loss = 1.1915
I0528 23:32:46.191406 142602 solver.cpp:237]     Train net output #0: loss = 1.1915 (* 1 = 1.1915 loss)
I0528 23:32:46.191442 142602 sgd_solver.cpp:105] Iteration 4500, lr = 0.009775
I0528 23:34:54.520723 142602 solver.cpp:218] Iteration 4600 (0.779263 iter/s, 128.326s/100 iters), loss = 1.10946
I0528 23:34:54.520948 142602 solver.cpp:237]     Train net output #0: loss = 1.10946 (* 1 = 1.10946 loss)
I0528 23:34:54.520984 142602 sgd_solver.cpp:105] Iteration 4600, lr = 0.00977
I0528 23:36:41.325958 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:37:02.934279 142602 solver.cpp:218] Iteration 4700 (0.778753 iter/s, 128.41s/100 iters), loss = 1.13838
I0528 23:37:02.934393 142602 solver.cpp:237]     Train net output #0: loss = 1.13838 (* 1 = 1.13838 loss)
I0528 23:37:02.934422 142602 sgd_solver.cpp:105] Iteration 4700, lr = 0.009765
I0528 23:39:11.348168 142602 solver.cpp:218] Iteration 4800 (0.778751 iter/s, 128.411s/100 iters), loss = 1.18708
I0528 23:39:11.348449 142602 solver.cpp:237]     Train net output #0: loss = 1.18708 (* 1 = 1.18708 loss)
I0528 23:39:11.348464 142602 sgd_solver.cpp:105] Iteration 4800, lr = 0.00976
I0528 23:41:19.711874 142602 solver.cpp:218] Iteration 4900 (0.779057 iter/s, 128.36s/100 iters), loss = 1.14899
I0528 23:41:19.712091 142602 solver.cpp:237]     Train net output #0: loss = 1.14899 (* 1 = 1.14899 loss)
I0528 23:41:19.712122 142602 sgd_solver.cpp:105] Iteration 4900, lr = 0.009755
I0528 23:43:26.832594 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_5000.caffemodel
I0528 23:43:27.073230 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_5000.solverstate
I0528 23:43:27.135376 142602 solver.cpp:330] Iteration 5000, Testing net (#0)
I0528 23:43:54.573412 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:44:30.963618 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:44:41.570123 142602 solver.cpp:397]     Test net output #0: accuracy = 0.48835
I0528 23:44:41.570224 142602 solver.cpp:397]     Test net output #1: loss = 1.2615 (* 1 = 1.2615 loss)
I0528 23:44:42.850157 142602 solver.cpp:218] Iteration 5000 (0.492288 iter/s, 203.133s/100 iters), loss = 1.12514
I0528 23:44:42.850239 142602 solver.cpp:237]     Train net output #0: loss = 1.12514 (* 1 = 1.12514 loss)
I0528 23:44:42.850252 142602 sgd_solver.cpp:105] Iteration 5000, lr = 0.00975
I0528 23:46:18.054785 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:46:51.211043 142602 solver.cpp:218] Iteration 5100 (0.779073 iter/s, 128.358s/100 iters), loss = 1.15433
I0528 23:46:51.211272 142602 solver.cpp:237]     Train net output #0: loss = 1.15433 (* 1 = 1.15433 loss)
I0528 23:46:51.211309 142602 sgd_solver.cpp:105] Iteration 5100, lr = 0.009745
I0528 23:48:59.598024 142602 solver.cpp:218] Iteration 5200 (0.778915 iter/s, 128.384s/100 iters), loss = 1.11965
I0528 23:48:59.598289 142602 solver.cpp:237]     Train net output #0: loss = 1.11965 (* 1 = 1.11965 loss)
I0528 23:48:59.598327 142602 sgd_solver.cpp:105] Iteration 5200, lr = 0.00974
I0528 23:51:07.937830 142602 solver.cpp:218] Iteration 5300 (0.779201 iter/s, 128.337s/100 iters), loss = 1.24218
I0528 23:51:07.938001 142602 solver.cpp:237]     Train net output #0: loss = 1.24218 (* 1 = 1.24218 loss)
I0528 23:51:07.938019 142602 sgd_solver.cpp:105] Iteration 5300, lr = 0.009735
I0528 23:53:16.329272 142602 solver.cpp:218] Iteration 5400 (0.778887 iter/s, 128.388s/100 iters), loss = 1.21297
I0528 23:53:16.329418 142602 solver.cpp:237]     Train net output #0: loss = 1.21297 (* 1 = 1.21297 loss)
I0528 23:53:16.329442 142602 sgd_solver.cpp:105] Iteration 5400, lr = 0.00973
I0528 23:54:38.776463 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:55:24.713670 142602 solver.cpp:218] Iteration 5500 (0.77893 iter/s, 128.381s/100 iters), loss = 1.13228
I0528 23:55:24.713896 142602 solver.cpp:237]     Train net output #0: loss = 1.13228 (* 1 = 1.13228 loss)
I0528 23:55:24.713912 142602 sgd_solver.cpp:105] Iteration 5500, lr = 0.009725
I0528 23:57:33.085891 142602 solver.cpp:218] Iteration 5600 (0.779005 iter/s, 128.369s/100 iters), loss = 1.31034
I0528 23:57:33.086561 142602 solver.cpp:237]     Train net output #0: loss = 1.31034 (* 1 = 1.31034 loss)
I0528 23:57:33.086597 142602 sgd_solver.cpp:105] Iteration 5600, lr = 0.00972
I0528 23:59:41.419330 142602 solver.cpp:218] Iteration 5700 (0.779243 iter/s, 128.33s/100 iters), loss = 1.20771
I0528 23:59:41.419560 142602 solver.cpp:237]     Train net output #0: loss = 1.20771 (* 1 = 1.20771 loss)
I0528 23:59:41.419589 142602 sgd_solver.cpp:105] Iteration 5700, lr = 0.009715
I0529 00:01:49.768785 142602 solver.cpp:218] Iteration 5800 (0.779143 iter/s, 128.346s/100 iters), loss = 1.15114
I0529 00:01:49.769067 142602 solver.cpp:237]     Train net output #0: loss = 1.15114 (* 1 = 1.15114 loss)
I0529 00:01:49.769100 142602 sgd_solver.cpp:105] Iteration 5800, lr = 0.00971
I0529 00:03:00.624826 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:03:58.154222 142602 solver.cpp:218] Iteration 5900 (0.778925 iter/s, 128.382s/100 iters), loss = 1.27934
I0529 00:03:58.154433 142602 solver.cpp:237]     Train net output #0: loss = 1.27934 (* 1 = 1.27934 loss)
I0529 00:03:58.154472 142602 sgd_solver.cpp:105] Iteration 5900, lr = 0.009705
I0529 00:06:05.230271 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_6000.caffemodel
I0529 00:06:05.428784 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_6000.solverstate
I0529 00:06:05.487386 142602 solver.cpp:330] Iteration 6000, Testing net (#0)
I0529 00:06:31.308082 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:07:07.642287 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:07:19.968184 142602 solver.cpp:397]     Test net output #0: accuracy = 0.48515
I0529 00:07:19.968283 142602 solver.cpp:397]     Test net output #1: loss = 1.33022 (* 1 = 1.33022 loss)
I0529 00:07:21.244585 142602 solver.cpp:218] Iteration 6000 (0.492404 iter/s, 203.085s/100 iters), loss = 1.22896
I0529 00:07:21.244704 142602 solver.cpp:237]     Train net output #0: loss = 1.22896 (* 1 = 1.22896 loss)
I0529 00:07:21.244722 142602 sgd_solver.cpp:105] Iteration 6000, lr = 0.0097
I0529 00:09:29.555297 142602 solver.cpp:218] Iteration 6100 (0.779377 iter/s, 128.308s/100 iters), loss = 1.20754
I0529 00:09:29.555474 142602 solver.cpp:237]     Train net output #0: loss = 1.20754 (* 1 = 1.20754 loss)
I0529 00:09:29.555516 142602 sgd_solver.cpp:105] Iteration 6100, lr = 0.009695
I0529 00:11:37.932410 142602 solver.cpp:218] Iteration 6200 (0.778974 iter/s, 128.374s/100 iters), loss = 0.992706
I0529 00:11:37.932652 142602 solver.cpp:237]     Train net output #0: loss = 0.992706 (* 1 = 0.992706 loss)
I0529 00:11:37.932677 142602 sgd_solver.cpp:105] Iteration 6200, lr = 0.00969
I0529 00:12:37.193001 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:13:46.274686 142602 solver.cpp:218] Iteration 6300 (0.779187 iter/s, 128.339s/100 iters), loss = 0.950126
I0529 00:13:46.274920 142602 solver.cpp:237]     Train net output #0: loss = 0.950126 (* 1 = 0.950126 loss)
I0529 00:13:46.274948 142602 sgd_solver.cpp:105] Iteration 6300, lr = 0.009685
I0529 00:15:54.606637 142602 solver.cpp:218] Iteration 6400 (0.779249 iter/s, 128.329s/100 iters), loss = 1.14711
I0529 00:15:54.606860 142602 solver.cpp:237]     Train net output #0: loss = 1.14711 (* 1 = 1.14711 loss)
I0529 00:15:54.606886 142602 sgd_solver.cpp:105] Iteration 6400, lr = 0.00968
I0529 00:18:02.950148 142602 solver.cpp:218] Iteration 6500 (0.779179 iter/s, 128.34s/100 iters), loss = 1.02413
I0529 00:18:02.950419 142602 solver.cpp:237]     Train net output #0: loss = 1.02413 (* 1 = 1.02413 loss)
I0529 00:18:02.950435 142602 sgd_solver.cpp:105] Iteration 6500, lr = 0.009675
I0529 00:20:11.284515 142602 solver.cpp:218] Iteration 6600 (0.779235 iter/s, 128.331s/100 iters), loss = 1.08338
I0529 00:20:11.284754 142602 solver.cpp:237]     Train net output #0: loss = 1.08338 (* 1 = 1.08338 loss)
I0529 00:20:11.284786 142602 sgd_solver.cpp:105] Iteration 6600, lr = 0.00967
I0529 00:20:57.734871 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:22:19.615079 142602 solver.cpp:218] Iteration 6700 (0.779258 iter/s, 128.327s/100 iters), loss = 0.935117
I0529 00:22:19.615305 142602 solver.cpp:237]     Train net output #0: loss = 0.935117 (* 1 = 0.935117 loss)
I0529 00:22:19.615321 142602 sgd_solver.cpp:105] Iteration 6700, lr = 0.009665
I0529 00:24:27.856187 142602 solver.cpp:218] Iteration 6800 (0.779801 iter/s, 128.238s/100 iters), loss = 1.15509
I0529 00:24:27.856428 142602 solver.cpp:237]     Train net output #0: loss = 1.15509 (* 1 = 1.15509 loss)
I0529 00:24:27.856442 142602 sgd_solver.cpp:105] Iteration 6800, lr = 0.00966
I0529 00:26:36.116803 142602 solver.cpp:218] Iteration 6900 (0.779682 iter/s, 128.257s/100 iters), loss = 1.06417
I0529 00:26:36.116994 142602 solver.cpp:237]     Train net output #0: loss = 1.06417 (* 1 = 1.06417 loss)
I0529 00:26:36.117012 142602 sgd_solver.cpp:105] Iteration 6900, lr = 0.009655
I0529 00:28:43.097420 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_7000.caffemodel
I0529 00:28:43.433351 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_7000.solverstate
I0529 00:28:43.490602 142602 solver.cpp:330] Iteration 7000, Testing net (#0)
I0529 00:29:07.473559 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:29:43.752893 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:29:57.847244 142602 solver.cpp:397]     Test net output #0: accuracy = 0.47565
I0529 00:29:57.847318 142602 solver.cpp:397]     Test net output #1: loss = 1.34392 (* 1 = 1.34392 loss)
I0529 00:29:59.127332 142602 solver.cpp:218] Iteration 7000 (0.492598 iter/s, 203.005s/100 iters), loss = 1.10566
I0529 00:29:59.127435 142602 solver.cpp:237]     Train net output #0: loss = 1.10566 (* 1 = 1.10566 loss)
I0529 00:29:59.127459 142602 sgd_solver.cpp:105] Iteration 7000, lr = 0.00965
I0529 00:30:33.942189 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:32:07.383458 142602 solver.cpp:218] Iteration 7100 (0.779709 iter/s, 128.253s/100 iters), loss = 1.03126
I0529 00:32:07.383705 142602 solver.cpp:237]     Train net output #0: loss = 1.03126 (* 1 = 1.03126 loss)
I0529 00:32:07.383744 142602 sgd_solver.cpp:105] Iteration 7100, lr = 0.009645
I0529 00:34:15.663611 142602 solver.cpp:218] Iteration 7200 (0.779564 iter/s, 128.277s/100 iters), loss = 1.07898
I0529 00:34:15.663854 142602 solver.cpp:237]     Train net output #0: loss = 1.07898 (* 1 = 1.07898 loss)
I0529 00:34:15.663895 142602 sgd_solver.cpp:105] Iteration 7200, lr = 0.00964
I0529 00:36:23.970181 142602 solver.cpp:218] Iteration 7300 (0.779404 iter/s, 128.303s/100 iters), loss = 1.27225
I0529 00:36:23.970417 142602 solver.cpp:237]     Train net output #0: loss = 1.27225 (* 1 = 1.27225 loss)
I0529 00:36:23.970437 142602 sgd_solver.cpp:105] Iteration 7300, lr = 0.009635
I0529 00:38:32.303766 142602 solver.cpp:218] Iteration 7400 (0.77924 iter/s, 128.33s/100 iters), loss = 1.02507
I0529 00:38:32.303979 142602 solver.cpp:237]     Train net output #0: loss = 1.02507 (* 1 = 1.02507 loss)
I0529 00:38:32.304015 142602 sgd_solver.cpp:105] Iteration 7400, lr = 0.00963
I0529 00:38:55.626857 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:40:40.585341 142602 solver.cpp:218] Iteration 7500 (0.779555 iter/s, 128.278s/100 iters), loss = 1.02523
I0529 00:40:40.585536 142602 solver.cpp:237]     Train net output #0: loss = 1.02523 (* 1 = 1.02523 loss)
I0529 00:40:40.585573 142602 sgd_solver.cpp:105] Iteration 7500, lr = 0.009625
I0529 00:42:48.922500 142602 solver.cpp:218] Iteration 7600 (0.779218 iter/s, 128.334s/100 iters), loss = 1.04951
I0529 00:42:48.922734 142602 solver.cpp:237]     Train net output #0: loss = 1.04951 (* 1 = 1.04951 loss)
I0529 00:42:48.922778 142602 sgd_solver.cpp:105] Iteration 7600, lr = 0.00962
I0529 00:44:57.217443 142602 solver.cpp:218] Iteration 7700 (0.779474 iter/s, 128.292s/100 iters), loss = 1.08531
I0529 00:44:57.217661 142602 solver.cpp:237]     Train net output #0: loss = 1.08531 (* 1 = 1.08531 loss)
I0529 00:44:57.217684 142602 sgd_solver.cpp:105] Iteration 7700, lr = 0.009615
I0529 00:47:05.522796 142602 solver.cpp:218] Iteration 7800 (0.779411 iter/s, 128.302s/100 iters), loss = 1.05209
I0529 00:47:05.522938 142602 solver.cpp:237]     Train net output #0: loss = 1.05209 (* 1 = 1.05209 loss)
I0529 00:47:05.522970 142602 sgd_solver.cpp:105] Iteration 7800, lr = 0.00961
I0529 00:47:16.026190 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:49:13.820825 142602 solver.cpp:218] Iteration 7900 (0.779455 iter/s, 128.295s/100 iters), loss = 1.13003
I0529 00:49:13.820917 142602 solver.cpp:237]     Train net output #0: loss = 1.13003 (* 1 = 1.13003 loss)
I0529 00:49:13.820931 142602 sgd_solver.cpp:105] Iteration 7900, lr = 0.009605
I0529 00:51:20.874675 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_8000.caffemodel
I0529 00:51:21.139824 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_8000.solverstate
I0529 00:51:21.194768 142602 solver.cpp:330] Iteration 8000, Testing net (#0)
I0529 00:51:43.441100 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:52:19.878522 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:52:35.697101 142602 solver.cpp:397]     Test net output #0: accuracy = 0.5065
I0529 00:52:35.697198 142602 solver.cpp:397]     Test net output #1: loss = 1.22818 (* 1 = 1.22818 loss)
I0529 00:52:36.976663 142602 solver.cpp:218] Iteration 8000 (0.492245 iter/s, 203.151s/100 iters), loss = 0.990896
I0529 00:52:36.976758 142602 solver.cpp:237]     Train net output #0: loss = 0.990896 (* 1 = 0.990896 loss)
I0529 00:52:36.976773 142602 sgd_solver.cpp:105] Iteration 8000, lr = 0.0096
I0529 00:54:45.302847 142602 solver.cpp:218] Iteration 8100 (0.779283 iter/s, 128.323s/100 iters), loss = 1.05088
I0529 00:54:45.303030 142602 solver.cpp:237]     Train net output #0: loss = 1.05088 (* 1 = 1.05088 loss)
I0529 00:54:45.303050 142602 sgd_solver.cpp:105] Iteration 8100, lr = 0.009595
I0529 00:56:52.556411 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:56:53.608690 142602 solver.cpp:218] Iteration 8200 (0.779408 iter/s, 128.303s/100 iters), loss = 0.915969
I0529 00:56:53.608789 142602 solver.cpp:237]     Train net output #0: loss = 0.915969 (* 1 = 0.915969 loss)
I0529 00:56:53.608803 142602 sgd_solver.cpp:105] Iteration 8200, lr = 0.00959
I0529 00:59:01.980413 142602 solver.cpp:218] Iteration 8300 (0.779007 iter/s, 128.368s/100 iters), loss = 0.970089
I0529 00:59:01.980598 142602 solver.cpp:237]     Train net output #0: loss = 0.970089 (* 1 = 0.970089 loss)
I0529 00:59:01.980628 142602 sgd_solver.cpp:105] Iteration 8300, lr = 0.009585
I0529 01:01:10.333359 142602 solver.cpp:218] Iteration 8400 (0.779122 iter/s, 128.35s/100 iters), loss = 1.12667
I0529 01:01:10.333554 142602 solver.cpp:237]     Train net output #0: loss = 1.12667 (* 1 = 1.12667 loss)
I0529 01:01:10.333570 142602 sgd_solver.cpp:105] Iteration 8400, lr = 0.00958
I0529 01:03:18.707281 142602 solver.cpp:218] Iteration 8500 (0.778994 iter/s, 128.371s/100 iters), loss = 0.990158
I0529 01:03:18.707558 142602 solver.cpp:237]     Train net output #0: loss = 0.990158 (* 1 = 0.990158 loss)
I0529 01:03:18.707589 142602 sgd_solver.cpp:105] Iteration 8500, lr = 0.009575
I0529 01:05:14.414613 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:05:27.051174 142602 solver.cpp:218] Iteration 8600 (0.779177 iter/s, 128.341s/100 iters), loss = 1.0997
I0529 01:05:27.051262 142602 solver.cpp:237]     Train net output #0: loss = 1.0997 (* 1 = 1.0997 loss)
I0529 01:05:27.051277 142602 sgd_solver.cpp:105] Iteration 8600, lr = 0.00957
I0529 01:07:35.413197 142602 solver.cpp:218] Iteration 8700 (0.779066 iter/s, 128.359s/100 iters), loss = 1.11189
I0529 01:07:35.413400 142602 solver.cpp:237]     Train net output #0: loss = 1.11189 (* 1 = 1.11189 loss)
I0529 01:07:35.413429 142602 sgd_solver.cpp:105] Iteration 8700, lr = 0.009565
I0529 01:09:43.846398 142602 solver.cpp:218] Iteration 8800 (0.778634 iter/s, 128.43s/100 iters), loss = 0.986774
I0529 01:09:43.846814 142602 solver.cpp:237]     Train net output #0: loss = 0.986774 (* 1 = 0.986774 loss)
I0529 01:09:43.846846 142602 sgd_solver.cpp:105] Iteration 8800, lr = 0.00956
I0529 01:11:52.301076 142602 solver.cpp:218] Iteration 8900 (0.778506 iter/s, 128.451s/100 iters), loss = 1.05624
I0529 01:11:52.301307 142602 solver.cpp:237]     Train net output #0: loss = 1.05624 (* 1 = 1.05624 loss)
I0529 01:11:52.301332 142602 sgd_solver.cpp:105] Iteration 8900, lr = 0.009555
I0529 01:13:35.302718 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:13:59.461757 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_9000.caffemodel
I0529 01:14:00.052495 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_9000.solverstate
I0529 01:14:00.106878 142602 solver.cpp:330] Iteration 9000, Testing net (#0)
I0529 01:14:20.644208 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:14:56.992956 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:15:14.600292 142602 solver.cpp:397]     Test net output #0: accuracy = 0.49125
I0529 01:15:14.600396 142602 solver.cpp:397]     Test net output #1: loss = 1.28172 (* 1 = 1.28172 loss)
I0529 01:15:15.877377 142602 solver.cpp:218] Iteration 9000 (0.491229 iter/s, 203.571s/100 iters), loss = 1.13926
I0529 01:15:15.877470 142602 solver.cpp:237]     Train net output #0: loss = 1.13926 (* 1 = 1.13926 loss)
I0529 01:15:15.877485 142602 sgd_solver.cpp:105] Iteration 9000, lr = 0.00955
I0529 01:17:24.323863 142602 solver.cpp:218] Iteration 9100 (0.778554 iter/s, 128.443s/100 iters), loss = 1.05854
I0529 01:17:24.324409 142602 solver.cpp:237]     Train net output #0: loss = 1.05854 (* 1 = 1.05854 loss)
I0529 01:17:24.324439 142602 sgd_solver.cpp:105] Iteration 9100, lr = 0.009545
I0529 01:19:32.745318 142602 solver.cpp:218] Iteration 9200 (0.778708 iter/s, 128.418s/100 iters), loss = 1.12169
I0529 01:19:32.745513 142602 solver.cpp:237]     Train net output #0: loss = 1.12169 (* 1 = 1.12169 loss)
I0529 01:19:32.745528 142602 sgd_solver.cpp:105] Iteration 9200, lr = 0.00954
I0529 01:21:41.172152 142602 solver.cpp:218] Iteration 9300 (0.778673 iter/s, 128.424s/100 iters), loss = 0.993786
I0529 01:21:41.172392 142602 solver.cpp:237]     Train net output #0: loss = 0.993786 (* 1 = 0.993786 loss)
I0529 01:21:41.172420 142602 sgd_solver.cpp:105] Iteration 9300, lr = 0.009535
I0529 01:23:12.512526 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:23:49.564391 142602 solver.cpp:218] Iteration 9400 (0.778884 iter/s, 128.389s/100 iters), loss = 0.972086
I0529 01:23:49.564630 142602 solver.cpp:237]     Train net output #0: loss = 0.972086 (* 1 = 0.972086 loss)
I0529 01:23:49.564672 142602 sgd_solver.cpp:105] Iteration 9400, lr = 0.00953
I0529 01:25:57.962142 142602 solver.cpp:218] Iteration 9500 (0.77885 iter/s, 128.394s/100 iters), loss = 0.97172
I0529 01:25:57.962306 142602 solver.cpp:237]     Train net output #0: loss = 0.97172 (* 1 = 0.97172 loss)
I0529 01:25:57.962332 142602 sgd_solver.cpp:105] Iteration 9500, lr = 0.009525
I0529 01:28:06.328546 142602 solver.cpp:218] Iteration 9600 (0.779039 iter/s, 128.363s/100 iters), loss = 0.951471
I0529 01:28:06.328774 142602 solver.cpp:237]     Train net output #0: loss = 0.951471 (* 1 = 0.951471 loss)
I0529 01:28:06.328804 142602 sgd_solver.cpp:105] Iteration 9600, lr = 0.00952
I0529 01:30:14.644286 142602 solver.cpp:218] Iteration 9700 (0.779347 iter/s, 128.312s/100 iters), loss = 0.996251
I0529 01:30:14.644457 142602 solver.cpp:237]     Train net output #0: loss = 0.996251 (* 1 = 0.996251 loss)
I0529 01:30:14.644472 142602 sgd_solver.cpp:105] Iteration 9700, lr = 0.009515
I0529 01:31:33.206642 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:32:23.026051 142602 solver.cpp:218] Iteration 9800 (0.778946 iter/s, 128.379s/100 iters), loss = 1.10859
I0529 01:32:23.026290 142602 solver.cpp:237]     Train net output #0: loss = 1.10859 (* 1 = 1.10859 loss)
I0529 01:32:23.026320 142602 sgd_solver.cpp:105] Iteration 9800, lr = 0.00951
I0529 01:34:31.407209 142602 solver.cpp:218] Iteration 9900 (0.778951 iter/s, 128.378s/100 iters), loss = 0.987013
I0529 01:34:31.407474 142602 solver.cpp:237]     Train net output #0: loss = 0.987013 (* 1 = 0.987013 loss)
I0529 01:34:31.407490 142602 sgd_solver.cpp:105] Iteration 9900, lr = 0.009505
I0529 01:36:38.481022 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_10000.caffemodel
I0529 01:36:38.924481 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_10000.solverstate
I0529 01:36:38.984457 142602 solver.cpp:330] Iteration 10000, Testing net (#0)
I0529 01:36:57.769217 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:37:34.128748 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:37:53.453861 142602 solver.cpp:397]     Test net output #0: accuracy = 0.5069
I0529 01:37:53.453948 142602 solver.cpp:397]     Test net output #1: loss = 1.23947 (* 1 = 1.23947 loss)
I0529 01:37:54.734505 142602 solver.cpp:218] Iteration 10000 (0.49183 iter/s, 203.322s/100 iters), loss = 1.11265
I0529 01:37:54.734583 142602 solver.cpp:237]     Train net output #0: loss = 1.11265 (* 1 = 1.11265 loss)
I0529 01:37:54.734601 142602 sgd_solver.cpp:105] Iteration 10000, lr = 0.0095
I0529 01:40:03.099259 142602 solver.cpp:218] Iteration 10100 (0.779049 iter/s, 128.362s/100 iters), loss = 1.11798
I0529 01:40:03.099460 142602 solver.cpp:237]     Train net output #0: loss = 1.11798 (* 1 = 1.11798 loss)
I0529 01:40:03.099475 142602 sgd_solver.cpp:105] Iteration 10100, lr = 0.009495
I0529 01:41:10.071240 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:42:11.471050 142602 solver.cpp:218] Iteration 10200 (0.779007 iter/s, 128.368s/100 iters), loss = 0.827484
I0529 01:42:11.471268 142602 solver.cpp:237]     Train net output #0: loss = 0.827484 (* 1 = 0.827484 loss)
I0529 01:42:11.471298 142602 sgd_solver.cpp:105] Iteration 10200, lr = 0.00949
I0529 01:44:19.820389 142602 solver.cpp:218] Iteration 10300 (0.779144 iter/s, 128.346s/100 iters), loss = 0.901483
I0529 01:44:19.820530 142602 solver.cpp:237]     Train net output #0: loss = 0.901483 (* 1 = 0.901483 loss)
I0529 01:44:19.820560 142602 sgd_solver.cpp:105] Iteration 10300, lr = 0.009485
I0529 01:46:28.202020 142602 solver.cpp:218] Iteration 10400 (0.778947 iter/s, 128.378s/100 iters), loss = 1.09674
I0529 01:46:28.202211 142602 solver.cpp:237]     Train net output #0: loss = 1.09674 (* 1 = 1.09674 loss)
I0529 01:46:28.202227 142602 sgd_solver.cpp:105] Iteration 10400, lr = 0.00948
I0529 01:48:36.580507 142602 solver.cpp:218] Iteration 10500 (0.778966 iter/s, 128.375s/100 iters), loss = 0.939035
I0529 01:48:36.580665 142602 solver.cpp:237]     Train net output #0: loss = 0.939035 (* 1 = 0.939035 loss)
I0529 01:48:36.580689 142602 sgd_solver.cpp:105] Iteration 10500, lr = 0.009475
I0529 01:49:31.979339 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:50:44.975457 142602 solver.cpp:218] Iteration 10600 (0.778866 iter/s, 128.392s/100 iters), loss = 1.15456
I0529 01:50:44.975611 142602 solver.cpp:237]     Train net output #0: loss = 1.15456 (* 1 = 1.15456 loss)
I0529 01:50:44.975625 142602 sgd_solver.cpp:105] Iteration 10600, lr = 0.00947
I0529 01:52:53.345947 142602 solver.cpp:218] Iteration 10700 (0.779015 iter/s, 128.367s/100 iters), loss = 1.02737
I0529 01:52:53.346127 142602 solver.cpp:237]     Train net output #0: loss = 1.02737 (* 1 = 1.02737 loss)
I0529 01:52:53.346153 142602 sgd_solver.cpp:105] Iteration 10700, lr = 0.009465
I0529 01:55:01.724478 142602 solver.cpp:218] Iteration 10800 (0.778965 iter/s, 128.375s/100 iters), loss = 0.822449
I0529 01:55:01.724588 142602 solver.cpp:237]     Train net output #0: loss = 0.822449 (* 1 = 0.822449 loss)
I0529 01:55:01.724601 142602 sgd_solver.cpp:105] Iteration 10800, lr = 0.00946
I0529 01:57:10.139894 142602 solver.cpp:218] Iteration 10900 (0.77874 iter/s, 128.413s/100 iters), loss = 0.944111
I0529 01:57:10.140158 142602 solver.cpp:237]     Train net output #0: loss = 0.944111 (* 1 = 0.944111 loss)
I0529 01:57:10.140182 142602 sgd_solver.cpp:105] Iteration 10900, lr = 0.009455
I0529 01:57:52.756804 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:59:17.238035 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_11000.caffemodel
I0529 01:59:17.632845 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_11000.solverstate
I0529 01:59:17.685901 142602 solver.cpp:330] Iteration 11000, Testing net (#0)
I0529 01:59:34.773375 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:00:11.101833 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:00:32.137202 142602 solver.cpp:397]     Test net output #0: accuracy = 0.35435
I0529 02:00:32.137282 142602 solver.cpp:397]     Test net output #1: loss = 1.63502 (* 1 = 1.63502 loss)
I0529 02:00:33.416311 142602 solver.cpp:218] Iteration 11000 (0.491953 iter/s, 203.271s/100 iters), loss = 1.02601
I0529 02:00:33.416404 142602 solver.cpp:237]     Train net output #0: loss = 1.02601 (* 1 = 1.02601 loss)
I0529 02:00:33.416426 142602 sgd_solver.cpp:105] Iteration 11000, lr = 0.00945
I0529 02:02:41.868032 142602 solver.cpp:218] Iteration 11100 (0.778522 iter/s, 128.449s/100 iters), loss = 1.07118
I0529 02:02:41.868165 142602 solver.cpp:237]     Train net output #0: loss = 1.07118 (* 1 = 1.07118 loss)
I0529 02:02:41.868185 142602 sgd_solver.cpp:105] Iteration 11100, lr = 0.009445
I0529 02:04:50.337591 142602 solver.cpp:218] Iteration 11200 (0.778414 iter/s, 128.466s/100 iters), loss = 1.23576
I0529 02:04:50.337824 142602 solver.cpp:237]     Train net output #0: loss = 1.23576 (* 1 = 1.23576 loss)
I0529 02:04:50.337852 142602 sgd_solver.cpp:105] Iteration 11200, lr = 0.00944
I0529 02:06:58.772043 142602 solver.cpp:218] Iteration 11300 (0.778627 iter/s, 128.431s/100 iters), loss = 0.849015
I0529 02:06:58.772250 142602 solver.cpp:237]     Train net output #0: loss = 0.849015 (* 1 = 0.849015 loss)
I0529 02:06:58.772279 142602 sgd_solver.cpp:105] Iteration 11300, lr = 0.009435
I0529 02:07:29.736207 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:09:07.193967 142602 solver.cpp:218] Iteration 11400 (0.778703 iter/s, 128.419s/100 iters), loss = 1.10797
I0529 02:09:07.194141 142602 solver.cpp:237]     Train net output #0: loss = 1.10797 (* 1 = 1.10797 loss)
I0529 02:09:07.194156 142602 sgd_solver.cpp:105] Iteration 11400, lr = 0.00943
I0529 02:11:15.652601 142602 solver.cpp:218] Iteration 11500 (0.77848 iter/s, 128.455s/100 iters), loss = 0.899418
I0529 02:11:15.652853 142602 solver.cpp:237]     Train net output #0: loss = 0.899418 (* 1 = 0.899418 loss)
I0529 02:11:15.652865 142602 sgd_solver.cpp:105] Iteration 11500, lr = 0.009425
I0529 02:13:24.121736 142602 solver.cpp:218] Iteration 11600 (0.778417 iter/s, 128.466s/100 iters), loss = 1.00938
I0529 02:13:24.121978 142602 solver.cpp:237]     Train net output #0: loss = 1.00938 (* 1 = 1.00938 loss)
I0529 02:13:24.121995 142602 sgd_solver.cpp:105] Iteration 11600, lr = 0.00942
I0529 02:15:32.612201 142602 solver.cpp:218] Iteration 11700 (0.778288 iter/s, 128.487s/100 iters), loss = 0.955552
I0529 02:15:32.612464 142602 solver.cpp:237]     Train net output #0: loss = 0.955552 (* 1 = 0.955552 loss)
I0529 02:15:32.612483 142602 sgd_solver.cpp:105] Iteration 11700, lr = 0.009415
I0529 02:15:52.101413 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:17:41.103857 142602 solver.cpp:218] Iteration 11800 (0.778281 iter/s, 128.488s/100 iters), loss = 0.969917
I0529 02:17:41.104070 142602 solver.cpp:237]     Train net output #0: loss = 0.969917 (* 1 = 0.969917 loss)
I0529 02:17:41.104115 142602 sgd_solver.cpp:105] Iteration 11800, lr = 0.00941
I0529 02:19:49.635871 142602 solver.cpp:218] Iteration 11900 (0.778036 iter/s, 128.529s/100 iters), loss = 1.0579
I0529 02:19:49.636255 142602 solver.cpp:237]     Train net output #0: loss = 1.0579 (* 1 = 1.0579 loss)
I0529 02:19:49.636312 142602 sgd_solver.cpp:105] Iteration 11900, lr = 0.009405
I0529 02:21:56.888574 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_12000.caffemodel
I0529 02:21:57.367533 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_12000.solverstate
I0529 02:21:57.428892 142602 solver.cpp:330] Iteration 12000, Testing net (#0)
I0529 02:22:12.722923 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:22:49.135921 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:23:11.893790 142602 solver.cpp:397]     Test net output #0: accuracy = 0.32935
I0529 02:23:11.893884 142602 solver.cpp:397]     Test net output #1: loss = 1.94486 (* 1 = 1.94486 loss)
I0529 02:23:13.170928 142602 solver.cpp:218] Iteration 12000 (0.491328 iter/s, 203.53s/100 iters), loss = 0.951331
I0529 02:23:13.171010 142602 solver.cpp:237]     Train net output #0: loss = 0.951331 (* 1 = 0.951331 loss)
I0529 02:23:13.171027 142602 sgd_solver.cpp:105] Iteration 12000, lr = 0.0094
I0529 02:25:21.703339 142602 solver.cpp:218] Iteration 12100 (0.778033 iter/s, 128.529s/100 iters), loss = 0.975675
I0529 02:25:21.703557 142602 solver.cpp:237]     Train net output #0: loss = 0.975675 (* 1 = 0.975675 loss)
I0529 02:25:21.703572 142602 sgd_solver.cpp:105] Iteration 12100, lr = 0.009395
I0529 02:25:28.383010 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:27:30.221828 142602 solver.cpp:218] Iteration 12200 (0.778117 iter/s, 128.515s/100 iters), loss = 0.944936
I0529 02:27:30.222031 142602 solver.cpp:237]     Train net output #0: loss = 0.944936 (* 1 = 0.944936 loss)
I0529 02:27:30.222080 142602 sgd_solver.cpp:105] Iteration 12200, lr = 0.00939
I0529 02:29:38.695492 142602 solver.cpp:218] Iteration 12300 (0.778389 iter/s, 128.471s/100 iters), loss = 0.853731
I0529 02:29:38.695674 142602 solver.cpp:237]     Train net output #0: loss = 0.853731 (* 1 = 0.853731 loss)
I0529 02:29:38.695690 142602 sgd_solver.cpp:105] Iteration 12300, lr = 0.009385
I0529 02:31:47.238099 142602 solver.cpp:218] Iteration 12400 (0.777972 iter/s, 128.539s/100 iters), loss = 0.975735
I0529 02:31:47.238358 142602 solver.cpp:237]     Train net output #0: loss = 0.975735 (* 1 = 0.975735 loss)
I0529 02:31:47.238374 142602 sgd_solver.cpp:105] Iteration 12400, lr = 0.00938
I0529 02:33:50.841583 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:33:55.747831 142602 solver.cpp:218] Iteration 12500 (0.778172 iter/s, 128.506s/100 iters), loss = 0.973841
I0529 02:33:55.747931 142602 solver.cpp:237]     Train net output #0: loss = 0.973841 (* 1 = 0.973841 loss)
I0529 02:33:55.747966 142602 sgd_solver.cpp:105] Iteration 12500, lr = 0.009375
I0529 02:36:04.301465 142602 solver.cpp:218] Iteration 12600 (0.777905 iter/s, 128.55s/100 iters), loss = 0.846374
I0529 02:36:04.301687 142602 solver.cpp:237]     Train net output #0: loss = 0.846374 (* 1 = 0.846374 loss)
I0529 02:36:04.301714 142602 sgd_solver.cpp:105] Iteration 12600, lr = 0.00937
I0529 02:38:12.850891 142602 solver.cpp:218] Iteration 12700 (0.777931 iter/s, 128.546s/100 iters), loss = 0.922691
I0529 02:38:12.851328 142602 solver.cpp:237]     Train net output #0: loss = 0.922691 (* 1 = 0.922691 loss)
I0529 02:38:12.851346 142602 sgd_solver.cpp:105] Iteration 12700, lr = 0.009365
I0529 02:40:21.379623 142602 solver.cpp:218] Iteration 12800 (0.778058 iter/s, 128.525s/100 iters), loss = 1.08495
I0529 02:40:21.379817 142602 solver.cpp:237]     Train net output #0: loss = 1.08495 (* 1 = 1.08495 loss)
I0529 02:40:21.379847 142602 sgd_solver.cpp:105] Iteration 12800, lr = 0.00936
I0529 02:42:13.403921 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:42:29.904841 142602 solver.cpp:218] Iteration 12900 (0.778077 iter/s, 128.522s/100 iters), loss = 1.09314
I0529 02:42:29.904927 142602 solver.cpp:237]     Train net output #0: loss = 1.09314 (* 1 = 1.09314 loss)
I0529 02:42:29.904940 142602 sgd_solver.cpp:105] Iteration 12900, lr = 0.009355
I0529 02:44:37.117914 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_13000.caffemodel
I0529 02:44:37.394510 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_13000.solverstate
I0529 02:44:37.453378 142602 solver.cpp:330] Iteration 13000, Testing net (#0)
I0529 02:44:51.083725 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:45:27.496609 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:45:52.053637 142602 solver.cpp:397]     Test net output #0: accuracy = 0.3152
I0529 02:45:52.053736 142602 solver.cpp:397]     Test net output #1: loss = 2.14606 (* 1 = 2.14606 loss)
I0529 02:45:53.336427 142602 solver.cpp:218] Iteration 13000 (0.491578 iter/s, 203.427s/100 iters), loss = 0.872052
I0529 02:45:53.336520 142602 solver.cpp:237]     Train net output #0: loss = 0.872052 (* 1 = 0.872052 loss)
I0529 02:45:53.336539 142602 sgd_solver.cpp:105] Iteration 13000, lr = 0.00935
I0529 02:48:01.886452 142602 solver.cpp:218] Iteration 13100 (0.777927 iter/s, 128.547s/100 iters), loss = 0.853518
I0529 02:48:01.886688 142602 solver.cpp:237]     Train net output #0: loss = 0.853518 (* 1 = 0.853518 loss)
I0529 02:48:01.886704 142602 sgd_solver.cpp:105] Iteration 13100, lr = 0.009345
I0529 02:50:10.394016 142602 solver.cpp:218] Iteration 13200 (0.778184 iter/s, 128.504s/100 iters), loss = 0.891737
I0529 02:50:10.394285 142602 solver.cpp:237]     Train net output #0: loss = 0.891737 (* 1 = 0.891737 loss)
I0529 02:50:10.394304 142602 sgd_solver.cpp:105] Iteration 13200, lr = 0.00934
I0529 02:51:49.629881 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:52:18.900368 142602 solver.cpp:218] Iteration 13300 (0.778192 iter/s, 128.503s/100 iters), loss = 1.10038
I0529 02:52:18.900450 142602 solver.cpp:237]     Train net output #0: loss = 1.10038 (* 1 = 1.10038 loss)
I0529 02:52:18.900465 142602 sgd_solver.cpp:105] Iteration 13300, lr = 0.009335
I0529 02:54:27.375021 142602 solver.cpp:218] Iteration 13400 (0.778382 iter/s, 128.472s/100 iters), loss = 0.948708
I0529 02:54:27.375242 142602 solver.cpp:237]     Train net output #0: loss = 0.948708 (* 1 = 0.948708 loss)
I0529 02:54:27.375283 142602 sgd_solver.cpp:105] Iteration 13400, lr = 0.00933
I0529 02:56:35.788287 142602 solver.cpp:218] Iteration 13500 (0.778755 iter/s, 128.41s/100 iters), loss = 0.761958
I0529 02:56:35.788493 142602 solver.cpp:237]     Train net output #0: loss = 0.761958 (* 1 = 0.761958 loss)
I0529 02:56:35.788511 142602 sgd_solver.cpp:105] Iteration 13500, lr = 0.009325
I0529 02:58:44.266090 142602 solver.cpp:218] Iteration 13600 (0.778364 iter/s, 128.475s/100 iters), loss = 0.948436
I0529 02:58:44.266285 142602 solver.cpp:237]     Train net output #0: loss = 0.948436 (* 1 = 0.948436 loss)
I0529 02:58:44.266300 142602 sgd_solver.cpp:105] Iteration 13600, lr = 0.00932
I0529 03:00:11.805018 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:00:52.704463 142602 solver.cpp:218] Iteration 13700 (0.778603 iter/s, 128.435s/100 iters), loss = 0.935301
I0529 03:00:52.704638 142602 solver.cpp:237]     Train net output #0: loss = 0.935301 (* 1 = 0.935301 loss)
I0529 03:00:52.704674 142602 sgd_solver.cpp:105] Iteration 13700, lr = 0.009315
I0529 03:03:01.157003 142602 solver.cpp:218] Iteration 13800 (0.778517 iter/s, 128.449s/100 iters), loss = 0.935241
I0529 03:03:01.157207 142602 solver.cpp:237]     Train net output #0: loss = 0.935241 (* 1 = 0.935241 loss)
I0529 03:03:01.157232 142602 sgd_solver.cpp:105] Iteration 13800, lr = 0.00931
I0529 03:05:09.549432 142602 solver.cpp:218] Iteration 13900 (0.778881 iter/s, 128.389s/100 iters), loss = 0.812788
I0529 03:05:09.549648 142602 solver.cpp:237]     Train net output #0: loss = 0.812788 (* 1 = 0.812788 loss)
I0529 03:05:09.549664 142602 sgd_solver.cpp:105] Iteration 13900, lr = 0.009305
I0529 03:07:16.703903 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_14000.caffemodel
I0529 03:07:17.195210 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_14000.solverstate
I0529 03:07:17.253137 142602 solver.cpp:330] Iteration 14000, Testing net (#0)
I0529 03:07:29.128693 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:08:05.483451 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:08:31.731220 142602 solver.cpp:397]     Test net output #0: accuracy = 0.371
I0529 03:08:31.731312 142602 solver.cpp:397]     Test net output #1: loss = 1.48998 (* 1 = 1.48998 loss)
I0529 03:08:33.012389 142602 solver.cpp:218] Iteration 14000 (0.491502 iter/s, 203.458s/100 iters), loss = 0.979149
I0529 03:08:33.012476 142602 solver.cpp:237]     Train net output #0: loss = 0.979149 (* 1 = 0.979149 loss)
I0529 03:08:33.012503 142602 sgd_solver.cpp:105] Iteration 14000, lr = 0.0093
I0529 03:09:48.967834 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:10:41.448827 142602 solver.cpp:218] Iteration 14100 (0.778614 iter/s, 128.433s/100 iters), loss = 0.789564
I0529 03:10:41.449089 142602 solver.cpp:237]     Train net output #0: loss = 0.789564 (* 1 = 0.789564 loss)
I0529 03:10:41.449110 142602 sgd_solver.cpp:105] Iteration 14100, lr = 0.009295
I0529 03:12:49.853862 142602 solver.cpp:218] Iteration 14200 (0.778805 iter/s, 128.402s/100 iters), loss = 0.919463
I0529 03:12:49.854082 142602 solver.cpp:237]     Train net output #0: loss = 0.919463 (* 1 = 0.919463 loss)
I0529 03:12:49.854109 142602 sgd_solver.cpp:105] Iteration 14200, lr = 0.00929
I0529 03:14:58.267582 142602 solver.cpp:218] Iteration 14300 (0.778752 iter/s, 128.411s/100 iters), loss = 0.929844
I0529 03:14:58.267820 142602 solver.cpp:237]     Train net output #0: loss = 0.929844 (* 1 = 0.929844 loss)
I0529 03:14:58.267838 142602 sgd_solver.cpp:105] Iteration 14300, lr = 0.009285
I0529 03:17:06.729993 142602 solver.cpp:218] Iteration 14400 (0.778457 iter/s, 128.459s/100 iters), loss = 0.802112
I0529 03:17:06.730330 142602 solver.cpp:237]     Train net output #0: loss = 0.802112 (* 1 = 0.802112 loss)
I0529 03:17:06.730350 142602 sgd_solver.cpp:105] Iteration 14400, lr = 0.00928
I0529 03:18:09.911686 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:19:15.189879 142602 solver.cpp:218] Iteration 14500 (0.778473 iter/s, 128.457s/100 iters), loss = 0.848146
I0529 03:19:15.190060 142602 solver.cpp:237]     Train net output #0: loss = 0.848146 (* 1 = 0.848146 loss)
I0529 03:19:15.190078 142602 sgd_solver.cpp:105] Iteration 14500, lr = 0.009275
I0529 03:21:23.668155 142602 solver.cpp:218] Iteration 14600 (0.778361 iter/s, 128.475s/100 iters), loss = 0.950005
I0529 03:21:23.668349 142602 solver.cpp:237]     Train net output #0: loss = 0.950005 (* 1 = 0.950005 loss)
I0529 03:21:23.668364 142602 sgd_solver.cpp:105] Iteration 14600, lr = 0.00927
I0529 03:23:32.171398 142602 solver.cpp:218] Iteration 14700 (0.778211 iter/s, 128.5s/100 iters), loss = 0.900966
I0529 03:23:32.171690 142602 solver.cpp:237]     Train net output #0: loss = 0.900966 (* 1 = 0.900966 loss)
I0529 03:23:32.171706 142602 sgd_solver.cpp:105] Iteration 14700, lr = 0.009265
I0529 03:25:40.686861 142602 solver.cpp:218] Iteration 14800 (0.778137 iter/s, 128.512s/100 iters), loss = 0.840228
I0529 03:25:40.687060 142602 solver.cpp:237]     Train net output #0: loss = 0.840228 (* 1 = 0.840228 loss)
I0529 03:25:40.687081 142602 sgd_solver.cpp:105] Iteration 14800, lr = 0.00926
I0529 03:26:32.268883 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:27:49.137804 142602 solver.cpp:218] Iteration 14900 (0.778527 iter/s, 128.448s/100 iters), loss = 0.863756
I0529 03:27:49.138084 142602 solver.cpp:237]     Train net output #0: loss = 0.863756 (* 1 = 0.863756 loss)
I0529 03:27:49.138109 142602 sgd_solver.cpp:105] Iteration 14900, lr = 0.009255
I0529 03:29:56.286846 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_15000.caffemodel
I0529 03:29:56.791580 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_15000.solverstate
I0529 03:29:56.848505 142602 solver.cpp:330] Iteration 15000, Testing net (#0)
I0529 03:30:06.959544 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:30:43.332602 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:31:11.282826 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4336
I0529 03:31:11.282925 142602 solver.cpp:397]     Test net output #1: loss = 1.44818 (* 1 = 1.44818 loss)
I0529 03:31:12.565939 142602 solver.cpp:218] Iteration 15000 (0.491587 iter/s, 203.423s/100 iters), loss = 0.845812
I0529 03:31:12.566056 142602 solver.cpp:237]     Train net output #0: loss = 0.845812 (* 1 = 0.845812 loss)
I0529 03:31:12.566074 142602 sgd_solver.cpp:105] Iteration 15000, lr = 0.00925
I0529 03:33:20.984200 142602 solver.cpp:218] Iteration 15100 (0.778725 iter/s, 128.415s/100 iters), loss = 0.839674
I0529 03:33:20.984380 142602 solver.cpp:237]     Train net output #0: loss = 0.839674 (* 1 = 0.839674 loss)
I0529 03:33:20.984396 142602 sgd_solver.cpp:105] Iteration 15100, lr = 0.009245
I0529 03:35:29.454051 142602 solver.cpp:218] Iteration 15200 (0.778413 iter/s, 128.467s/100 iters), loss = 1.09229
I0529 03:35:29.454319 142602 solver.cpp:237]     Train net output #0: loss = 1.09229 (* 1 = 1.09229 loss)
I0529 03:35:29.454334 142602 sgd_solver.cpp:105] Iteration 15200, lr = 0.00924
I0529 03:36:08.232360 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:37:37.885262 142602 solver.cpp:218] Iteration 15300 (0.778647 iter/s, 128.428s/100 iters), loss = 0.920099
I0529 03:37:37.885517 142602 solver.cpp:237]     Train net output #0: loss = 0.920099 (* 1 = 0.920099 loss)
I0529 03:37:37.885538 142602 sgd_solver.cpp:105] Iteration 15300, lr = 0.009235
I0529 03:39:46.337011 142602 solver.cpp:218] Iteration 15400 (0.778523 iter/s, 128.448s/100 iters), loss = 0.832505
I0529 03:39:46.337252 142602 solver.cpp:237]     Train net output #0: loss = 0.832505 (* 1 = 0.832505 loss)
I0529 03:39:46.337283 142602 sgd_solver.cpp:105] Iteration 15400, lr = 0.00923
I0529 03:41:54.752113 142602 solver.cpp:218] Iteration 15500 (0.778744 iter/s, 128.412s/100 iters), loss = 0.981621
I0529 03:41:54.752336 142602 solver.cpp:237]     Train net output #0: loss = 0.981621 (* 1 = 0.981621 loss)
I0529 03:41:54.752351 142602 sgd_solver.cpp:105] Iteration 15500, lr = 0.009225
I0529 03:44:03.183326 142602 solver.cpp:218] Iteration 15600 (0.778647 iter/s, 128.428s/100 iters), loss = 0.961792
I0529 03:44:03.183593 142602 solver.cpp:237]     Train net output #0: loss = 0.961792 (* 1 = 0.961792 loss)
I0529 03:44:03.183625 142602 sgd_solver.cpp:105] Iteration 15600, lr = 0.00922
I0529 03:44:30.391589 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:46:11.540066 142602 solver.cpp:218] Iteration 15700 (0.779099 iter/s, 128.353s/100 iters), loss = 0.748563
I0529 03:46:11.540237 142602 solver.cpp:237]     Train net output #0: loss = 0.748563 (* 1 = 0.748563 loss)
I0529 03:46:11.540274 142602 sgd_solver.cpp:105] Iteration 15700, lr = 0.009215
I0529 03:48:19.919447 142602 solver.cpp:218] Iteration 15800 (0.778961 iter/s, 128.376s/100 iters), loss = 0.767892
I0529 03:48:19.919685 142602 solver.cpp:237]     Train net output #0: loss = 0.767892 (* 1 = 0.767892 loss)
I0529 03:48:19.919713 142602 sgd_solver.cpp:105] Iteration 15800, lr = 0.00921
I0529 03:50:28.310797 142602 solver.cpp:218] Iteration 15900 (0.778889 iter/s, 128.388s/100 iters), loss = 0.850686
I0529 03:50:28.310976 142602 solver.cpp:237]     Train net output #0: loss = 0.850686 (* 1 = 0.850686 loss)
I0529 03:50:28.311009 142602 sgd_solver.cpp:105] Iteration 15900, lr = 0.009205
I0529 03:52:35.425987 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_16000.caffemodel
I0529 03:52:35.579463 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_16000.solverstate
I0529 03:52:35.634730 142602 solver.cpp:330] Iteration 16000, Testing net (#0)
I0529 03:52:44.017345 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:53:20.323269 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:53:50.031260 142602 solver.cpp:397]     Test net output #0: accuracy = 0.3978
I0529 03:53:50.031378 142602 solver.cpp:397]     Test net output #1: loss = 1.97921 (* 1 = 1.97921 loss)
I0529 03:53:51.308537 142602 solver.cpp:218] Iteration 16000 (0.492628 iter/s, 202.993s/100 iters), loss = 0.910991
I0529 03:53:51.308751 142602 solver.cpp:237]     Train net output #0: loss = 0.910991 (* 1 = 0.910991 loss)
I0529 03:53:51.308769 142602 sgd_solver.cpp:105] Iteration 16000, lr = 0.0092
I0529 03:54:06.917399 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:55:59.659195 142602 solver.cpp:218] Iteration 16100 (0.779135 iter/s, 128.347s/100 iters), loss = 0.947144
I0529 03:55:59.659405 142602 solver.cpp:237]     Train net output #0: loss = 0.947144 (* 1 = 0.947144 loss)
I0529 03:55:59.659438 142602 sgd_solver.cpp:105] Iteration 16100, lr = 0.009195
I0529 03:58:08.037808 142602 solver.cpp:218] Iteration 16200 (0.778966 iter/s, 128.375s/100 iters), loss = 0.816086
I0529 03:58:08.038031 142602 solver.cpp:237]     Train net output #0: loss = 0.816086 (* 1 = 0.816086 loss)
I0529 03:58:08.038055 142602 sgd_solver.cpp:105] Iteration 16200, lr = 0.00919
I0529 04:00:16.434156 142602 solver.cpp:218] Iteration 16300 (0.778858 iter/s, 128.393s/100 iters), loss = 0.690732
I0529 04:00:16.434337 142602 solver.cpp:237]     Train net output #0: loss = 0.690732 (* 1 = 0.690732 loss)
I0529 04:00:16.434370 142602 sgd_solver.cpp:105] Iteration 16300, lr = 0.009185
I0529 04:02:24.866541 142602 solver.cpp:218] Iteration 16400 (0.77864 iter/s, 128.429s/100 iters), loss = 0.952961
I0529 04:02:24.866744 142602 solver.cpp:237]     Train net output #0: loss = 0.952961 (* 1 = 0.952961 loss)
I0529 04:02:24.866773 142602 sgd_solver.cpp:105] Iteration 16400, lr = 0.00918
I0529 04:02:27.679083 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:04:33.276427 142602 solver.cpp:218] Iteration 16500 (0.778776 iter/s, 128.407s/100 iters), loss = 0.664332
I0529 04:04:33.276641 142602 solver.cpp:237]     Train net output #0: loss = 0.664332 (* 1 = 0.664332 loss)
I0529 04:04:33.276669 142602 sgd_solver.cpp:105] Iteration 16500, lr = 0.009175
I0529 04:06:41.709313 142602 solver.cpp:218] Iteration 16600 (0.778637 iter/s, 128.43s/100 iters), loss = 0.948912
I0529 04:06:41.709549 142602 solver.cpp:237]     Train net output #0: loss = 0.948912 (* 1 = 0.948912 loss)
I0529 04:06:41.709576 142602 sgd_solver.cpp:105] Iteration 16600, lr = 0.00917
I0529 04:08:50.111795 142602 solver.cpp:218] Iteration 16700 (0.778821 iter/s, 128.399s/100 iters), loss = 0.979465
I0529 04:08:50.112059 142602 solver.cpp:237]     Train net output #0: loss = 0.979465 (* 1 = 0.979465 loss)
I0529 04:08:50.112093 142602 sgd_solver.cpp:105] Iteration 16700, lr = 0.009165
I0529 04:10:49.757125 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:10:58.515228 142602 solver.cpp:218] Iteration 16800 (0.778816 iter/s, 128.4s/100 iters), loss = 0.826627
I0529 04:10:58.515311 142602 solver.cpp:237]     Train net output #0: loss = 0.826627 (* 1 = 0.826627 loss)
I0529 04:10:58.515326 142602 sgd_solver.cpp:105] Iteration 16800, lr = 0.00916
I0529 04:13:06.893144 142602 solver.cpp:218] Iteration 16900 (0.778969 iter/s, 128.375s/100 iters), loss = 0.784934
I0529 04:13:06.893410 142602 solver.cpp:237]     Train net output #0: loss = 0.784934 (* 1 = 0.784934 loss)
I0529 04:13:06.893442 142602 sgd_solver.cpp:105] Iteration 16900, lr = 0.009155
I0529 04:15:14.015830 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_17000.caffemodel
I0529 04:15:14.508155 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_17000.solverstate
I0529 04:15:14.565347 142602 solver.cpp:330] Iteration 17000, Testing net (#0)
I0529 04:15:21.232607 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:15:57.627415 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:16:29.089335 142602 solver.cpp:397]     Test net output #0: accuracy = 0.477
I0529 04:16:29.089591 142602 solver.cpp:397]     Test net output #1: loss = 1.63637 (* 1 = 1.63637 loss)
I0529 04:16:30.368614 142602 solver.cpp:218] Iteration 17000 (0.491472 iter/s, 203.47s/100 iters), loss = 0.850737
I0529 04:16:30.368696 142602 solver.cpp:237]     Train net output #0: loss = 0.850737 (* 1 = 0.850737 loss)
I0529 04:16:30.368717 142602 sgd_solver.cpp:105] Iteration 17000, lr = 0.00915
I0529 04:18:38.784494 142602 solver.cpp:218] Iteration 17100 (0.778739 iter/s, 128.413s/100 iters), loss = 0.837354
I0529 04:18:38.784773 142602 solver.cpp:237]     Train net output #0: loss = 0.837354 (* 1 = 0.837354 loss)
I0529 04:18:38.784796 142602 sgd_solver.cpp:105] Iteration 17100, lr = 0.009145
I0529 04:20:26.824199 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:20:47.156306 142602 solver.cpp:218] Iteration 17200 (0.779007 iter/s, 128.369s/100 iters), loss = 0.722066
I0529 04:20:47.156391 142602 solver.cpp:237]     Train net output #0: loss = 0.722066 (* 1 = 0.722066 loss)
I0529 04:20:47.156405 142602 sgd_solver.cpp:105] Iteration 17200, lr = 0.00914
I0529 04:22:55.573556 142602 solver.cpp:218] Iteration 17300 (0.778731 iter/s, 128.414s/100 iters), loss = 0.843795
I0529 04:22:55.573770 142602 solver.cpp:237]     Train net output #0: loss = 0.843795 (* 1 = 0.843795 loss)
I0529 04:22:55.573787 142602 sgd_solver.cpp:105] Iteration 17300, lr = 0.009135
I0529 04:25:04.007032 142602 solver.cpp:218] Iteration 17400 (0.778633 iter/s, 128.43s/100 iters), loss = 0.749112
I0529 04:25:04.007252 142602 solver.cpp:237]     Train net output #0: loss = 0.749112 (* 1 = 0.749112 loss)
I0529 04:25:04.007268 142602 sgd_solver.cpp:105] Iteration 17400, lr = 0.00913
I0529 04:27:12.471838 142602 solver.cpp:218] Iteration 17500 (0.778443 iter/s, 128.461s/100 iters), loss = 0.972374
I0529 04:27:12.472034 142602 solver.cpp:237]     Train net output #0: loss = 0.972374 (* 1 = 0.972374 loss)
I0529 04:27:12.472213 142602 sgd_solver.cpp:105] Iteration 17500, lr = 0.009125
I0529 04:28:47.799006 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:29:20.939268 142602 solver.cpp:218] Iteration 17600 (0.778427 iter/s, 128.464s/100 iters), loss = 0.850674
I0529 04:29:20.939455 142602 solver.cpp:237]     Train net output #0: loss = 0.850674 (* 1 = 0.850674 loss)
I0529 04:29:20.939469 142602 sgd_solver.cpp:105] Iteration 17600, lr = 0.00912
I0529 04:31:29.378958 142602 solver.cpp:218] Iteration 17700 (0.778595 iter/s, 128.436s/100 iters), loss = 0.853105
I0529 04:31:29.379233 142602 solver.cpp:237]     Train net output #0: loss = 0.853105 (* 1 = 0.853105 loss)
I0529 04:31:29.379248 142602 sgd_solver.cpp:105] Iteration 17700, lr = 0.009115
I0529 04:33:37.800951 142602 solver.cpp:218] Iteration 17800 (0.778703 iter/s, 128.419s/100 iters), loss = 0.825064
I0529 04:33:37.801165 142602 solver.cpp:237]     Train net output #0: loss = 0.825064 (* 1 = 0.825064 loss)
I0529 04:33:37.801205 142602 sgd_solver.cpp:105] Iteration 17800, lr = 0.00911
I0529 04:35:46.170874 142602 solver.cpp:218] Iteration 17900 (0.779019 iter/s, 128.367s/100 iters), loss = 0.757343
I0529 04:35:46.171090 142602 solver.cpp:237]     Train net output #0: loss = 0.757343 (* 1 = 0.757343 loss)
I0529 04:35:46.171110 142602 sgd_solver.cpp:105] Iteration 17900, lr = 0.009105
I0529 04:37:09.855018 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:37:53.262084 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_18000.caffemodel
I0529 04:37:53.550356 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_18000.solverstate
I0529 04:37:53.607285 142602 solver.cpp:330] Iteration 18000, Testing net (#0)
I0529 04:37:58.488622 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:38:34.862363 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:39:08.046772 142602 solver.cpp:397]     Test net output #0: accuracy = 0.35055
I0529 04:39:08.047071 142602 solver.cpp:397]     Test net output #1: loss = 2.30019 (* 1 = 2.30019 loss)
I0529 04:39:09.328048 142602 solver.cpp:218] Iteration 18000 (0.492242 iter/s, 203.152s/100 iters), loss = 0.741989
I0529 04:39:09.328138 142602 solver.cpp:237]     Train net output #0: loss = 0.741989 (* 1 = 0.741989 loss)
I0529 04:39:09.328155 142602 sgd_solver.cpp:105] Iteration 18000, lr = 0.0091
I0529 04:41:17.668893 142602 solver.cpp:218] Iteration 18100 (0.779194 iter/s, 128.338s/100 iters), loss = 0.71676
I0529 04:41:17.669080 142602 solver.cpp:237]     Train net output #0: loss = 0.71676 (* 1 = 0.71676 loss)
I0529 04:41:17.669106 142602 sgd_solver.cpp:105] Iteration 18100, lr = 0.009095
I0529 04:43:26.034070 142602 solver.cpp:218] Iteration 18200 (0.779047 iter/s, 128.362s/100 iters), loss = 0.899039
I0529 04:43:26.034328 142602 solver.cpp:237]     Train net output #0: loss = 0.899039 (* 1 = 0.899039 loss)
I0529 04:43:26.034369 142602 sgd_solver.cpp:105] Iteration 18200, lr = 0.00909
I0529 04:45:34.400950 142602 solver.cpp:218] Iteration 18300 (0.779036 iter/s, 128.364s/100 iters), loss = 0.717773
I0529 04:45:34.401154 142602 solver.cpp:237]     Train net output #0: loss = 0.717773 (* 1 = 0.717773 loss)
I0529 04:45:34.401185 142602 sgd_solver.cpp:105] Iteration 18300, lr = 0.009085
I0529 04:46:46.485373 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:47:42.771025 142602 solver.cpp:218] Iteration 18400 (0.779017 iter/s, 128.367s/100 iters), loss = 0.82211
I0529 04:47:42.771292 142602 solver.cpp:237]     Train net output #0: loss = 0.82211 (* 1 = 0.82211 loss)
I0529 04:47:42.771309 142602 sgd_solver.cpp:105] Iteration 18400, lr = 0.00908
I0529 04:49:51.103618 142602 solver.cpp:218] Iteration 18500 (0.779245 iter/s, 128.329s/100 iters), loss = 0.83733
I0529 04:49:51.103857 142602 solver.cpp:237]     Train net output #0: loss = 0.83733 (* 1 = 0.83733 loss)
I0529 04:49:51.103883 142602 sgd_solver.cpp:105] Iteration 18500, lr = 0.009075
I0529 04:51:59.463315 142602 solver.cpp:218] Iteration 18600 (0.77908 iter/s, 128.357s/100 iters), loss = 0.819601
I0529 04:51:59.463490 142602 solver.cpp:237]     Train net output #0: loss = 0.819601 (* 1 = 0.819601 loss)
I0529 04:51:59.463521 142602 sgd_solver.cpp:105] Iteration 18600, lr = 0.00907
I0529 04:54:07.796306 142602 solver.cpp:218] Iteration 18700 (0.779242 iter/s, 128.33s/100 iters), loss = 0.622678
I0529 04:54:07.796553 142602 solver.cpp:237]     Train net output #0: loss = 0.622678 (* 1 = 0.622678 loss)
I0529 04:54:07.796572 142602 sgd_solver.cpp:105] Iteration 18700, lr = 0.009065
I0529 04:55:07.081629 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:56:16.152601 142602 solver.cpp:218] Iteration 18800 (0.779101 iter/s, 128.353s/100 iters), loss = 0.720387
I0529 04:56:16.152909 142602 solver.cpp:237]     Train net output #0: loss = 0.720387 (* 1 = 0.720387 loss)
I0529 04:56:16.152940 142602 sgd_solver.cpp:105] Iteration 18800, lr = 0.00906
I0529 04:58:24.503545 142602 solver.cpp:218] Iteration 18900 (0.779134 iter/s, 128.348s/100 iters), loss = 0.833906
I0529 04:58:24.503747 142602 solver.cpp:237]     Train net output #0: loss = 0.833906 (* 1 = 0.833906 loss)
I0529 04:58:24.503774 142602 sgd_solver.cpp:105] Iteration 18900, lr = 0.009055
I0529 05:00:31.543465 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_19000.caffemodel
I0529 05:00:31.969492 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_19000.solverstate
I0529 05:00:32.034164 142602 solver.cpp:330] Iteration 19000, Testing net (#0)
I0529 05:00:35.201508 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:01:11.482357 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:01:46.388067 142602 solver.cpp:397]     Test net output #0: accuracy = 0.38765
I0529 05:01:46.388250 142602 solver.cpp:397]     Test net output #1: loss = 2.07522 (* 1 = 2.07522 loss)
I0529 05:01:47.669785 142602 solver.cpp:218] Iteration 19000 (0.49222 iter/s, 203.161s/100 iters), loss = 0.633521
I0529 05:01:47.669869 142602 solver.cpp:237]     Train net output #0: loss = 0.633521 (* 1 = 0.633521 loss)
I0529 05:01:47.669931 142602 sgd_solver.cpp:105] Iteration 19000, lr = 0.00905
I0529 05:03:55.976301 142602 solver.cpp:218] Iteration 19100 (0.779403 iter/s, 128.303s/100 iters), loss = 0.664313
I0529 05:03:55.976604 142602 solver.cpp:237]     Train net output #0: loss = 0.664313 (* 1 = 0.664313 loss)
I0529 05:03:55.976619 142602 sgd_solver.cpp:105] Iteration 19100, lr = 0.009045
I0529 05:04:43.666343 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:06:04.237200 142602 solver.cpp:218] Iteration 19200 (0.779681 iter/s, 128.258s/100 iters), loss = 0.728478
I0529 05:06:04.237422 142602 solver.cpp:237]     Train net output #0: loss = 0.728478 (* 1 = 0.728478 loss)
I0529 05:06:04.237437 142602 sgd_solver.cpp:105] Iteration 19200, lr = 0.00904
I0529 05:08:12.524075 142602 solver.cpp:218] Iteration 19300 (0.779523 iter/s, 128.284s/100 iters), loss = 0.591458
I0529 05:08:12.524267 142602 solver.cpp:237]     Train net output #0: loss = 0.591458 (* 1 = 0.591458 loss)
I0529 05:08:12.524298 142602 sgd_solver.cpp:105] Iteration 19300, lr = 0.009035
I0529 05:10:20.788666 142602 solver.cpp:218] Iteration 19400 (0.779658 iter/s, 128.261s/100 iters), loss = 0.659991
I0529 05:10:20.788844 142602 solver.cpp:237]     Train net output #0: loss = 0.659991 (* 1 = 0.659991 loss)
I0529 05:10:20.788862 142602 sgd_solver.cpp:105] Iteration 19400, lr = 0.00903
I0529 05:12:29.109052 142602 solver.cpp:218] Iteration 19500 (0.77932 iter/s, 128.317s/100 iters), loss = 0.729967
I0529 05:12:29.109212 142602 solver.cpp:237]     Train net output #0: loss = 0.729967 (* 1 = 0.729967 loss)
I0529 05:12:29.109230 142602 sgd_solver.cpp:105] Iteration 19500, lr = 0.009025
I0529 05:13:04.035979 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:14:37.378329 142602 solver.cpp:218] Iteration 19600 (0.77963 iter/s, 128.266s/100 iters), loss = 0.60467
I0529 05:14:37.378504 142602 solver.cpp:237]     Train net output #0: loss = 0.60467 (* 1 = 0.60467 loss)
I0529 05:14:37.378518 142602 sgd_solver.cpp:105] Iteration 19600, lr = 0.00902
I0529 05:16:45.698432 142602 solver.cpp:218] Iteration 19700 (0.779321 iter/s, 128.317s/100 iters), loss = 0.733981
I0529 05:16:45.698624 142602 solver.cpp:237]     Train net output #0: loss = 0.733981 (* 1 = 0.733981 loss)
I0529 05:16:45.698663 142602 sgd_solver.cpp:105] Iteration 19700, lr = 0.009015
I0529 05:18:54.012899 142602 solver.cpp:218] Iteration 19800 (0.779355 iter/s, 128.311s/100 iters), loss = 0.852765
I0529 05:18:54.013073 142602 solver.cpp:237]     Train net output #0: loss = 0.852765 (* 1 = 0.852765 loss)
I0529 05:18:54.013089 142602 sgd_solver.cpp:105] Iteration 19800, lr = 0.00901
I0529 05:21:02.390382 142602 solver.cpp:218] Iteration 19900 (0.778972 iter/s, 128.374s/100 iters), loss = 0.794871
I0529 05:21:02.390594 142602 solver.cpp:237]     Train net output #0: loss = 0.794871 (* 1 = 0.794871 loss)
I0529 05:21:02.390630 142602 sgd_solver.cpp:105] Iteration 19900, lr = 0.009005
I0529 05:21:25.722916 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:23:09.462836 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_20000.caffemodel
I0529 05:23:09.959373 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_20000.solverstate
I0529 05:23:10.018664 142602 solver.cpp:330] Iteration 20000, Testing net (#0)
I0529 05:23:11.479207 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:23:47.854001 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:24:24.188484 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:24:24.374548 142602 solver.cpp:397]     Test net output #0: accuracy = 0.43435
I0529 05:24:24.374667 142602 solver.cpp:397]     Test net output #1: loss = 2.11316 (* 1 = 2.11316 loss)
I0529 05:24:25.654541 142602 solver.cpp:218] Iteration 20000 (0.491983 iter/s, 203.259s/100 iters), loss = 0.719489
I0529 05:24:25.654631 142602 solver.cpp:237]     Train net output #0: loss = 0.719489 (* 1 = 0.719489 loss)
I0529 05:24:25.654693 142602 sgd_solver.cpp:105] Iteration 20000, lr = 0.009
I0529 05:26:33.968067 142602 solver.cpp:218] Iteration 20100 (0.77936 iter/s, 128.31s/100 iters), loss = 0.682548
I0529 05:26:33.968334 142602 solver.cpp:237]     Train net output #0: loss = 0.682548 (* 1 = 0.682548 loss)
I0529 05:26:33.968374 142602 sgd_solver.cpp:105] Iteration 20100, lr = 0.008995
I0529 05:28:42.337847 142602 solver.cpp:218] Iteration 20200 (0.779019 iter/s, 128.367s/100 iters), loss = 0.835633
I0529 05:28:42.338093 142602 solver.cpp:237]     Train net output #0: loss = 0.835633 (* 1 = 0.835633 loss)
I0529 05:28:42.338110 142602 sgd_solver.cpp:105] Iteration 20200, lr = 0.00899
I0529 05:30:50.691818 142602 solver.cpp:218] Iteration 20300 (0.779115 iter/s, 128.351s/100 iters), loss = 0.697499
I0529 05:30:50.692004 142602 solver.cpp:237]     Train net output #0: loss = 0.697499 (* 1 = 0.697499 loss)
I0529 05:30:50.692018 142602 sgd_solver.cpp:105] Iteration 20300, lr = 0.008985
I0529 05:31:02.460139 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:32:59.058213 142602 solver.cpp:218] Iteration 20400 (0.779039 iter/s, 128.363s/100 iters), loss = 0.839763
I0529 05:32:59.058917 142602 solver.cpp:237]     Train net output #0: loss = 0.839763 (* 1 = 0.839763 loss)
I0529 05:32:59.058936 142602 sgd_solver.cpp:105] Iteration 20400, lr = 0.00898
I0529 05:35:07.438129 142602 solver.cpp:218] Iteration 20500 (0.778961 iter/s, 128.376s/100 iters), loss = 0.668744
I0529 05:35:07.438325 142602 solver.cpp:237]     Train net output #0: loss = 0.668744 (* 1 = 0.668744 loss)
I0529 05:35:07.438339 142602 sgd_solver.cpp:105] Iteration 20500, lr = 0.008975
I0529 05:37:15.786480 142602 solver.cpp:218] Iteration 20600 (0.779149 iter/s, 128.345s/100 iters), loss = 0.646333
I0529 05:37:15.786681 142602 solver.cpp:237]     Train net output #0: loss = 0.646333 (* 1 = 0.646333 loss)
I0529 05:37:15.786698 142602 sgd_solver.cpp:105] Iteration 20600, lr = 0.00897
I0529 05:39:23.096340 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:39:24.133569 142602 solver.cpp:218] Iteration 20700 (0.779157 iter/s, 128.344s/100 iters), loss = 0.694266
I0529 05:39:24.133646 142602 solver.cpp:237]     Train net output #0: loss = 0.694266 (* 1 = 0.694266 loss)
I0529 05:39:24.133661 142602 sgd_solver.cpp:105] Iteration 20700, lr = 0.008965
I0529 05:41:32.437309 142602 solver.cpp:218] Iteration 20800 (0.77942 iter/s, 128.301s/100 iters), loss = 0.610283
I0529 05:41:32.437538 142602 solver.cpp:237]     Train net output #0: loss = 0.610283 (* 1 = 0.610283 loss)
I0529 05:41:32.437554 142602 sgd_solver.cpp:105] Iteration 20800, lr = 0.00896
I0529 05:43:40.775213 142602 solver.cpp:218] Iteration 20900 (0.779213 iter/s, 128.335s/100 iters), loss = 0.824914
I0529 05:43:40.775406 142602 solver.cpp:237]     Train net output #0: loss = 0.824914 (* 1 = 0.824914 loss)
I0529 05:43:40.775420 142602 sgd_solver.cpp:105] Iteration 20900, lr = 0.008955
I0529 05:45:47.818958 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_21000.caffemodel
I0529 05:45:48.106545 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_21000.solverstate
I0529 05:45:48.166296 142602 solver.cpp:330] Iteration 21000, Testing net (#0)
I0529 05:46:24.279955 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:47:00.649350 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:47:02.697203 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4261
I0529 05:47:02.697288 142602 solver.cpp:397]     Test net output #1: loss = 1.93455 (* 1 = 1.93455 loss)
I0529 05:47:03.977816 142602 solver.cpp:218] Iteration 21000 (0.492132 iter/s, 203.197s/100 iters), loss = 0.711983
I0529 05:47:03.977916 142602 solver.cpp:237]     Train net output #0: loss = 0.711983 (* 1 = 0.711983 loss)
I0529 05:47:03.977929 142602 sgd_solver.cpp:105] Iteration 21000, lr = 0.00895
I0529 05:48:59.724797 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:49:12.342918 142602 solver.cpp:218] Iteration 21100 (0.779047 iter/s, 128.362s/100 iters), loss = 0.634268
I0529 05:49:12.343005 142602 solver.cpp:237]     Train net output #0: loss = 0.634268 (* 1 = 0.634268 loss)
I0529 05:49:12.343019 142602 sgd_solver.cpp:105] Iteration 21100, lr = 0.008945
I0529 05:51:20.745956 142602 solver.cpp:218] Iteration 21200 (0.778817 iter/s, 128.4s/100 iters), loss = 0.758266
I0529 05:51:20.746163 142602 solver.cpp:237]     Train net output #0: loss = 0.758266 (* 1 = 0.758266 loss)
I0529 05:51:20.746178 142602 sgd_solver.cpp:105] Iteration 21200, lr = 0.00894
I0529 05:53:29.131901 142602 solver.cpp:218] Iteration 21300 (0.778921 iter/s, 128.383s/100 iters), loss = 0.641956
I0529 05:53:29.132529 142602 solver.cpp:237]     Train net output #0: loss = 0.641956 (* 1 = 0.641956 loss)
I0529 05:53:29.132553 142602 sgd_solver.cpp:105] Iteration 21300, lr = 0.008935
I0529 05:55:37.504457 142602 solver.cpp:218] Iteration 21400 (0.779005 iter/s, 128.369s/100 iters), loss = 0.632174
I0529 05:55:37.504672 142602 solver.cpp:237]     Train net output #0: loss = 0.632174 (* 1 = 0.632174 loss)
I0529 05:55:37.504688 142602 sgd_solver.cpp:105] Iteration 21400, lr = 0.00893
I0529 05:57:21.739269 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:57:45.892743 142602 solver.cpp:218] Iteration 21500 (0.778907 iter/s, 128.385s/100 iters), loss = 0.7506
I0529 05:57:45.892856 142602 solver.cpp:237]     Train net output #0: loss = 0.7506 (* 1 = 0.7506 loss)
I0529 05:57:45.892889 142602 sgd_solver.cpp:105] Iteration 21500, lr = 0.008925
I0529 05:59:54.346977 142602 solver.cpp:218] Iteration 21600 (0.778506 iter/s, 128.451s/100 iters), loss = 0.599103
I0529 05:59:54.347246 142602 solver.cpp:237]     Train net output #0: loss = 0.599103 (* 1 = 0.599103 loss)
I0529 05:59:54.347321 142602 sgd_solver.cpp:105] Iteration 21600, lr = 0.00892
I0529 06:02:02.772970 142602 solver.cpp:218] Iteration 21700 (0.778678 iter/s, 128.423s/100 iters), loss = 0.636075
I0529 06:02:02.773180 142602 solver.cpp:237]     Train net output #0: loss = 0.636075 (* 1 = 0.636075 loss)
I0529 06:02:02.773227 142602 sgd_solver.cpp:105] Iteration 21700, lr = 0.008915
I0529 06:04:11.137481 142602 solver.cpp:218] Iteration 21800 (0.779051 iter/s, 128.361s/100 iters), loss = 0.736032
I0529 06:04:11.137676 142602 solver.cpp:237]     Train net output #0: loss = 0.736032 (* 1 = 0.736032 loss)
I0529 06:04:11.137699 142602 sgd_solver.cpp:105] Iteration 21800, lr = 0.00891
I0529 06:05:42.510725 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:06:19.489006 142602 solver.cpp:218] Iteration 21900 (0.779129 iter/s, 128.348s/100 iters), loss = 0.449293
I0529 06:06:19.489217 142602 solver.cpp:237]     Train net output #0: loss = 0.449293 (* 1 = 0.449293 loss)
I0529 06:06:19.489248 142602 sgd_solver.cpp:105] Iteration 21900, lr = 0.008905
I0529 06:08:26.537384 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_22000.caffemodel
I0529 06:08:26.954215 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_22000.solverstate
I0529 06:08:27.014973 142602 solver.cpp:330] Iteration 22000, Testing net (#0)
I0529 06:09:01.349056 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:09:37.626366 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:09:41.376807 142602 solver.cpp:397]     Test net output #0: accuracy = 0.3597
I0529 06:09:41.376893 142602 solver.cpp:397]     Test net output #1: loss = 1.94225 (* 1 = 1.94225 loss)
I0529 06:09:42.657774 142602 solver.cpp:218] Iteration 22000 (0.492213 iter/s, 203.164s/100 iters), loss = 0.60666
I0529 06:09:42.657853 142602 solver.cpp:237]     Train net output #0: loss = 0.60666 (* 1 = 0.60666 loss)
I0529 06:09:42.657872 142602 sgd_solver.cpp:105] Iteration 22000, lr = 0.0089
I0529 06:11:50.981438 142602 solver.cpp:218] Iteration 22100 (0.779298 iter/s, 128.321s/100 iters), loss = 0.605972
I0529 06:11:50.981704 142602 solver.cpp:237]     Train net output #0: loss = 0.605972 (* 1 = 0.605972 loss)
I0529 06:11:50.981757 142602 sgd_solver.cpp:105] Iteration 22100, lr = 0.008895
I0529 06:13:59.293020 142602 solver.cpp:218] Iteration 22200 (0.779372 iter/s, 128.308s/100 iters), loss = 0.661089
I0529 06:13:59.293264 142602 solver.cpp:237]     Train net output #0: loss = 0.661089 (* 1 = 0.661089 loss)
I0529 06:13:59.293292 142602 sgd_solver.cpp:105] Iteration 22200, lr = 0.00889
I0529 06:15:19.099339 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:16:07.631847 142602 solver.cpp:218] Iteration 22300 (0.779207 iter/s, 128.336s/100 iters), loss = 0.748459
I0529 06:16:07.632123 142602 solver.cpp:237]     Train net output #0: loss = 0.748459 (* 1 = 0.748459 loss)
I0529 06:16:07.632158 142602 sgd_solver.cpp:105] Iteration 22300, lr = 0.008885
I0529 06:18:15.936082 142602 solver.cpp:218] Iteration 22400 (0.779417 iter/s, 128.301s/100 iters), loss = 0.682536
I0529 06:18:15.936292 142602 solver.cpp:237]     Train net output #0: loss = 0.682536 (* 1 = 0.682536 loss)
I0529 06:18:15.936323 142602 sgd_solver.cpp:105] Iteration 22400, lr = 0.00888
I0529 06:20:24.266794 142602 solver.cpp:218] Iteration 22500 (0.779256 iter/s, 128.328s/100 iters), loss = 0.705655
I0529 06:20:24.266985 142602 solver.cpp:237]     Train net output #0: loss = 0.705655 (* 1 = 0.705655 loss)
I0529 06:20:24.267033 142602 sgd_solver.cpp:105] Iteration 22500, lr = 0.008875
I0529 06:22:32.566871 142602 solver.cpp:218] Iteration 22600 (0.779441 iter/s, 128.297s/100 iters), loss = 0.714092
I0529 06:22:32.567101 142602 solver.cpp:237]     Train net output #0: loss = 0.714092 (* 1 = 0.714092 loss)
I0529 06:22:32.567118 142602 sgd_solver.cpp:105] Iteration 22600, lr = 0.00887
I0529 06:23:40.805248 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:24:40.897739 142602 solver.cpp:218] Iteration 22700 (0.779255 iter/s, 128.328s/100 iters), loss = 0.610717
I0529 06:24:40.897929 142602 solver.cpp:237]     Train net output #0: loss = 0.610717 (* 1 = 0.610717 loss)
I0529 06:24:40.897959 142602 sgd_solver.cpp:105] Iteration 22700, lr = 0.008865
I0529 06:26:49.212139 142602 solver.cpp:218] Iteration 22800 (0.779355 iter/s, 128.311s/100 iters), loss = 0.707517
I0529 06:26:49.212358 142602 solver.cpp:237]     Train net output #0: loss = 0.707517 (* 1 = 0.707517 loss)
I0529 06:26:49.212383 142602 sgd_solver.cpp:105] Iteration 22800, lr = 0.00886
I0529 06:28:57.507182 142602 solver.cpp:218] Iteration 22900 (0.779473 iter/s, 128.292s/100 iters), loss = 0.760259
I0529 06:28:57.507392 142602 solver.cpp:237]     Train net output #0: loss = 0.760259 (* 1 = 0.760259 loss)
I0529 06:28:57.507432 142602 sgd_solver.cpp:105] Iteration 22900, lr = 0.008855
I0529 06:31:04.548406 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_23000.caffemodel
I0529 06:31:05.009966 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_23000.solverstate
I0529 06:31:05.069655 142602 solver.cpp:330] Iteration 23000, Testing net (#0)
I0529 06:31:37.630182 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:32:14.003491 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:32:19.473886 142602 solver.cpp:397]     Test net output #0: accuracy = 0.34415
I0529 06:32:19.473970 142602 solver.cpp:397]     Test net output #1: loss = 2.05332 (* 1 = 2.05332 loss)
I0529 06:32:20.751022 142602 solver.cpp:218] Iteration 23000 (0.492032 iter/s, 203.239s/100 iters), loss = 0.797258
I0529 06:32:20.751104 142602 solver.cpp:237]     Train net output #0: loss = 0.797258 (* 1 = 0.797258 loss)
I0529 06:32:20.751122 142602 sgd_solver.cpp:105] Iteration 23000, lr = 0.00885
I0529 06:33:16.204778 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:34:29.088351 142602 solver.cpp:218] Iteration 23100 (0.779216 iter/s, 128.334s/100 iters), loss = 0.604678
I0529 06:34:29.088591 142602 solver.cpp:237]     Train net output #0: loss = 0.604678 (* 1 = 0.604678 loss)
I0529 06:34:29.088606 142602 sgd_solver.cpp:105] Iteration 23100, lr = 0.008845
I0529 06:36:37.444367 142602 solver.cpp:218] Iteration 23200 (0.779103 iter/s, 128.353s/100 iters), loss = 0.720811
I0529 06:36:37.444748 142602 solver.cpp:237]     Train net output #0: loss = 0.720811 (* 1 = 0.720811 loss)
I0529 06:36:37.444778 142602 sgd_solver.cpp:105] Iteration 23200, lr = 0.00884
I0529 06:38:45.789880 142602 solver.cpp:218] Iteration 23300 (0.779168 iter/s, 128.342s/100 iters), loss = 0.752456
I0529 06:38:45.790091 142602 solver.cpp:237]     Train net output #0: loss = 0.752456 (* 1 = 0.752456 loss)
I0529 06:38:45.790130 142602 sgd_solver.cpp:105] Iteration 23300, lr = 0.008835
I0529 06:40:54.131417 142602 solver.cpp:218] Iteration 23400 (0.779191 iter/s, 128.338s/100 iters), loss = 0.651007
I0529 06:40:54.131610 142602 solver.cpp:237]     Train net output #0: loss = 0.651007 (* 1 = 0.651007 loss)
I0529 06:40:54.131650 142602 sgd_solver.cpp:105] Iteration 23400, lr = 0.00883
I0529 06:41:37.994973 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:43:02.497992 142602 solver.cpp:218] Iteration 23500 (0.779039 iter/s, 128.363s/100 iters), loss = 0.748548
I0529 06:43:02.498247 142602 solver.cpp:237]     Train net output #0: loss = 0.748548 (* 1 = 0.748548 loss)
I0529 06:43:02.498260 142602 sgd_solver.cpp:105] Iteration 23500, lr = 0.008825
I0529 06:45:10.889219 142602 solver.cpp:218] Iteration 23600 (0.778889 iter/s, 128.388s/100 iters), loss = 0.595951
I0529 06:45:10.889433 142602 solver.cpp:237]     Train net output #0: loss = 0.595951 (* 1 = 0.595951 loss)
I0529 06:45:10.889461 142602 sgd_solver.cpp:105] Iteration 23600, lr = 0.00882
I0529 06:47:19.196162 142602 solver.cpp:218] Iteration 23700 (0.779401 iter/s, 128.304s/100 iters), loss = 0.61401
I0529 06:47:19.196343 142602 solver.cpp:237]     Train net output #0: loss = 0.61401 (* 1 = 0.61401 loss)
I0529 06:47:19.196373 142602 sgd_solver.cpp:105] Iteration 23700, lr = 0.008815
I0529 06:49:27.513695 142602 solver.cpp:218] Iteration 23800 (0.779336 iter/s, 128.314s/100 iters), loss = 0.665218
I0529 06:49:27.513975 142602 solver.cpp:237]     Train net output #0: loss = 0.665218 (* 1 = 0.665218 loss)
I0529 06:49:27.513998 142602 sgd_solver.cpp:105] Iteration 23800, lr = 0.00881
I0529 06:49:59.795476 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:51:35.821866 142602 solver.cpp:218] Iteration 23900 (0.779394 iter/s, 128.305s/100 iters), loss = 0.634692
I0529 06:51:35.822032 142602 solver.cpp:237]     Train net output #0: loss = 0.634692 (* 1 = 0.634692 loss)
I0529 06:51:35.822067 142602 sgd_solver.cpp:105] Iteration 23900, lr = 0.008805
I0529 06:53:42.850143 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_24000.caffemodel
I0529 06:53:43.277598 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_24000.solverstate
I0529 06:53:43.338207 142602 solver.cpp:330] Iteration 24000, Testing net (#0)
I0529 06:54:14.159135 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:54:50.447402 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:54:57.690095 142602 solver.cpp:397]     Test net output #0: accuracy = 0.42685
I0529 06:54:57.690197 142602 solver.cpp:397]     Test net output #1: loss = 1.78242 (* 1 = 1.78242 loss)
I0529 06:54:58.969954 142602 solver.cpp:218] Iteration 24000 (0.492264 iter/s, 203.143s/100 iters), loss = 0.610121
I0529 06:54:58.970057 142602 solver.cpp:237]     Train net output #0: loss = 0.610121 (* 1 = 0.610121 loss)
I0529 06:54:58.970093 142602 sgd_solver.cpp:105] Iteration 24000, lr = 0.0088
I0529 06:57:07.238037 142602 solver.cpp:218] Iteration 24100 (0.779637 iter/s, 128.265s/100 iters), loss = 0.530381
I0529 06:57:07.238360 142602 solver.cpp:237]     Train net output #0: loss = 0.530381 (* 1 = 0.530381 loss)
I0529 06:57:07.238387 142602 sgd_solver.cpp:105] Iteration 24100, lr = 0.008795
I0529 06:59:15.545343 142602 solver.cpp:218] Iteration 24200 (0.7794 iter/s, 128.304s/100 iters), loss = 0.560648
I0529 06:59:15.545622 142602 solver.cpp:237]     Train net output #0: loss = 0.560648 (* 1 = 0.560648 loss)
I0529 06:59:15.545656 142602 sgd_solver.cpp:105] Iteration 24200, lr = 0.00879
I0529 06:59:35.059417 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:01:23.852171 142602 solver.cpp:218] Iteration 24300 (0.779402 iter/s, 128.303s/100 iters), loss = 0.773229
I0529 07:01:23.852402 142602 solver.cpp:237]     Train net output #0: loss = 0.773229 (* 1 = 0.773229 loss)
I0529 07:01:23.852428 142602 sgd_solver.cpp:105] Iteration 24300, lr = 0.008785
I0529 07:03:32.163787 142602 solver.cpp:218] Iteration 24400 (0.779372 iter/s, 128.308s/100 iters), loss = 0.578367
I0529 07:03:32.164072 142602 solver.cpp:237]     Train net output #0: loss = 0.578367 (* 1 = 0.578367 loss)
I0529 07:03:32.164090 142602 sgd_solver.cpp:105] Iteration 24400, lr = 0.00878
I0529 07:05:40.448623 142602 solver.cpp:218] Iteration 24500 (0.779535 iter/s, 128.282s/100 iters), loss = 0.614002
I0529 07:05:40.448808 142602 solver.cpp:237]     Train net output #0: loss = 0.614002 (* 1 = 0.614002 loss)
I0529 07:05:40.448844 142602 sgd_solver.cpp:105] Iteration 24500, lr = 0.008775
I0529 07:07:48.776726 142602 solver.cpp:218] Iteration 24600 (0.779272 iter/s, 128.325s/100 iters), loss = 0.570253
I0529 07:07:48.776955 142602 solver.cpp:237]     Train net output #0: loss = 0.570253 (* 1 = 0.570253 loss)
I0529 07:07:48.776974 142602 sgd_solver.cpp:105] Iteration 24600, lr = 0.00877
I0529 07:07:56.673805 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:09:57.108496 142602 solver.cpp:218] Iteration 24700 (0.779249 iter/s, 128.329s/100 iters), loss = 0.620191
I0529 07:09:57.108695 142602 solver.cpp:237]     Train net output #0: loss = 0.620191 (* 1 = 0.620191 loss)
I0529 07:09:57.108711 142602 sgd_solver.cpp:105] Iteration 24700, lr = 0.008765
I0529 07:12:05.444002 142602 solver.cpp:218] Iteration 24800 (0.779227 iter/s, 128.332s/100 iters), loss = 0.638646
I0529 07:12:05.444239 142602 solver.cpp:237]     Train net output #0: loss = 0.638646 (* 1 = 0.638646 loss)
I0529 07:12:05.444268 142602 sgd_solver.cpp:105] Iteration 24800, lr = 0.00876
I0529 07:14:13.800581 142602 solver.cpp:218] Iteration 24900 (0.779099 iter/s, 128.353s/100 iters), loss = 0.504433
I0529 07:14:13.800814 142602 solver.cpp:237]     Train net output #0: loss = 0.504433 (* 1 = 0.504433 loss)
I0529 07:14:13.800845 142602 sgd_solver.cpp:105] Iteration 24900, lr = 0.008755
I0529 07:16:17.230005 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:16:20.824285 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_25000.caffemodel
I0529 07:16:21.119362 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_25000.solverstate
I0529 07:16:21.181802 142602 solver.cpp:330] Iteration 25000, Testing net (#0)
I0529 07:16:50.322070 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:17:26.650491 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:17:35.629160 142602 solver.cpp:397]     Test net output #0: accuracy = 0.37445
I0529 07:17:35.629230 142602 solver.cpp:397]     Test net output #1: loss = 2.16579 (* 1 = 2.16579 loss)
I0529 07:17:36.905196 142602 solver.cpp:218] Iteration 25000 (0.49237 iter/s, 203.099s/100 iters), loss = 0.498582
I0529 07:17:36.905298 142602 solver.cpp:237]     Train net output #0: loss = 0.498582 (* 1 = 0.498582 loss)
I0529 07:17:36.905315 142602 sgd_solver.cpp:105] Iteration 25000, lr = 0.00875
I0529 07:19:45.259074 142602 solver.cpp:218] Iteration 25100 (0.779116 iter/s, 128.351s/100 iters), loss = 0.536222
I0529 07:19:45.259366 142602 solver.cpp:237]     Train net output #0: loss = 0.536222 (* 1 = 0.536222 loss)
I0529 07:19:45.259384 142602 sgd_solver.cpp:105] Iteration 25100, lr = 0.008745
I0529 07:21:53.619119 142602 solver.cpp:218] Iteration 25200 (0.779079 iter/s, 128.357s/100 iters), loss = 0.702727
I0529 07:21:53.619351 142602 solver.cpp:237]     Train net output #0: loss = 0.702727 (* 1 = 0.702727 loss)
I0529 07:21:53.619374 142602 sgd_solver.cpp:105] Iteration 25200, lr = 0.00874
I0529 07:24:01.979416 142602 solver.cpp:218] Iteration 25300 (0.779077 iter/s, 128.357s/100 iters), loss = 0.683743
I0529 07:24:01.979694 142602 solver.cpp:237]     Train net output #0: loss = 0.683743 (* 1 = 0.683743 loss)
I0529 07:24:01.979710 142602 sgd_solver.cpp:105] Iteration 25300, lr = 0.008735
I0529 07:25:53.845441 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:26:10.299885 142602 solver.cpp:218] Iteration 25400 (0.779319 iter/s, 128.317s/100 iters), loss = 0.557225
I0529 07:26:10.299979 142602 solver.cpp:237]     Train net output #0: loss = 0.557225 (* 1 = 0.557225 loss)
I0529 07:26:10.299993 142602 sgd_solver.cpp:105] Iteration 25400, lr = 0.00873
I0529 07:28:18.607059 142602 solver.cpp:218] Iteration 25500 (0.779398 iter/s, 128.304s/100 iters), loss = 0.426658
I0529 07:28:18.607192 142602 solver.cpp:237]     Train net output #0: loss = 0.426658 (* 1 = 0.426658 loss)
I0529 07:28:18.607206 142602 sgd_solver.cpp:105] Iteration 25500, lr = 0.008725
I0529 07:30:26.866390 142602 solver.cpp:218] Iteration 25600 (0.779689 iter/s, 128.256s/100 iters), loss = 0.507729
I0529 07:30:26.866556 142602 solver.cpp:237]     Train net output #0: loss = 0.507729 (* 1 = 0.507729 loss)
I0529 07:30:26.866577 142602 sgd_solver.cpp:105] Iteration 25600, lr = 0.00872
I0529 07:32:35.152303 142602 solver.cpp:218] Iteration 25700 (0.779528 iter/s, 128.283s/100 iters), loss = 0.591597
I0529 07:32:35.152485 142602 solver.cpp:237]     Train net output #0: loss = 0.591597 (* 1 = 0.591597 loss)
I0529 07:32:35.152530 142602 sgd_solver.cpp:105] Iteration 25700, lr = 0.008715
I0529 07:34:15.368903 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:34:43.390171 142602 solver.cpp:218] Iteration 25800 (0.77982 iter/s, 128.235s/100 iters), loss = 0.501199
I0529 07:34:43.390249 142602 solver.cpp:237]     Train net output #0: loss = 0.501199 (* 1 = 0.501199 loss)
I0529 07:34:43.390261 142602 sgd_solver.cpp:105] Iteration 25800, lr = 0.00871
I0529 07:36:51.702764 142602 solver.cpp:218] Iteration 25900 (0.779365 iter/s, 128.31s/100 iters), loss = 0.532287
I0529 07:36:51.703016 142602 solver.cpp:237]     Train net output #0: loss = 0.532287 (* 1 = 0.532287 loss)
I0529 07:36:51.703032 142602 sgd_solver.cpp:105] Iteration 25900, lr = 0.008705
I0529 07:38:58.648406 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_26000.caffemodel
I0529 07:38:59.065007 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_26000.solverstate
I0529 07:38:59.126891 142602 solver.cpp:330] Iteration 26000, Testing net (#0)
I0529 07:39:26.435528 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:40:02.774453 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:40:13.433156 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4754
I0529 07:40:13.433269 142602 solver.cpp:397]     Test net output #1: loss = 1.67802 (* 1 = 1.67802 loss)
I0529 07:40:14.711859 142602 solver.cpp:218] Iteration 26000 (0.492601 iter/s, 203.004s/100 iters), loss = 0.476652
I0529 07:40:14.711952 142602 solver.cpp:237]     Train net output #0: loss = 0.476652 (* 1 = 0.476652 loss)
I0529 07:40:14.711966 142602 sgd_solver.cpp:105] Iteration 26000, lr = 0.0087
I0529 07:42:22.936772 142602 solver.cpp:218] Iteration 26100 (0.779898 iter/s, 128.222s/100 iters), loss = 0.546002
I0529 07:42:22.936923 142602 solver.cpp:237]     Train net output #0: loss = 0.546002 (* 1 = 0.546002 loss)
I0529 07:42:22.936949 142602 sgd_solver.cpp:105] Iteration 26100, lr = 0.008695
I0529 07:43:50.401383 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:44:31.178385 142602 solver.cpp:218] Iteration 26200 (0.779797 iter/s, 128.238s/100 iters), loss = 0.495551
I0529 07:44:31.178545 142602 solver.cpp:237]     Train net output #0: loss = 0.495551 (* 1 = 0.495551 loss)
I0529 07:44:31.178571 142602 sgd_solver.cpp:105] Iteration 26200, lr = 0.00869
I0529 07:46:39.431958 142602 solver.cpp:218] Iteration 26300 (0.779725 iter/s, 128.25s/100 iters), loss = 0.403812
I0529 07:46:39.432155 142602 solver.cpp:237]     Train net output #0: loss = 0.403812 (* 1 = 0.403812 loss)
I0529 07:46:39.432169 142602 sgd_solver.cpp:105] Iteration 26300, lr = 0.008685
I0529 07:48:47.697293 142602 solver.cpp:218] Iteration 26400 (0.779653 iter/s, 128.262s/100 iters), loss = 0.510839
I0529 07:48:47.697527 142602 solver.cpp:237]     Train net output #0: loss = 0.510839 (* 1 = 0.510839 loss)
I0529 07:48:47.697543 142602 sgd_solver.cpp:105] Iteration 26400, lr = 0.00868
I0529 07:50:55.961942 142602 solver.cpp:218] Iteration 26500 (0.779658 iter/s, 128.261s/100 iters), loss = 0.519437
I0529 07:50:55.962357 142602 solver.cpp:237]     Train net output #0: loss = 0.519437 (* 1 = 0.519437 loss)
I0529 07:50:55.962373 142602 sgd_solver.cpp:105] Iteration 26500, lr = 0.008675
I0529 07:52:11.880112 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:53:04.212960 142602 solver.cpp:218] Iteration 26600 (0.779741 iter/s, 128.248s/100 iters), loss = 0.473146
I0529 07:53:04.213158 142602 solver.cpp:237]     Train net output #0: loss = 0.473146 (* 1 = 0.473146 loss)
I0529 07:53:04.213183 142602 sgd_solver.cpp:105] Iteration 26600, lr = 0.00867
I0529 07:55:12.416692 142602 solver.cpp:218] Iteration 26700 (0.780028 iter/s, 128.201s/100 iters), loss = 0.706791
I0529 07:55:12.416877 142602 solver.cpp:237]     Train net output #0: loss = 0.706791 (* 1 = 0.706791 loss)
I0529 07:55:12.416903 142602 sgd_solver.cpp:105] Iteration 26700, lr = 0.008665
I0529 07:57:20.636010 142602 solver.cpp:218] Iteration 26800 (0.779933 iter/s, 128.216s/100 iters), loss = 0.59674
I0529 07:57:20.636225 142602 solver.cpp:237]     Train net output #0: loss = 0.59674 (* 1 = 0.59674 loss)
I0529 07:57:20.636240 142602 sgd_solver.cpp:105] Iteration 26800, lr = 0.00866
I0529 07:59:28.930124 142602 solver.cpp:218] Iteration 26900 (0.779478 iter/s, 128.291s/100 iters), loss = 0.562625
I0529 07:59:28.930364 142602 solver.cpp:237]     Train net output #0: loss = 0.562625 (* 1 = 0.562625 loss)
I0529 07:59:28.930378 142602 sgd_solver.cpp:105] Iteration 26900, lr = 0.008655
I0529 08:00:33.257776 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:01:35.959378 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_27000.caffemodel
I0529 08:01:36.355751 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_27000.solverstate
I0529 08:01:36.412930 142602 solver.cpp:330] Iteration 27000, Testing net (#0)
I0529 08:02:02.036409 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:02:38.307296 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:02:50.747145 142602 solver.cpp:397]     Test net output #0: accuracy = 0.45105
I0529 08:02:50.747237 142602 solver.cpp:397]     Test net output #1: loss = 2.32847 (* 1 = 2.32847 loss)
I0529 08:02:52.025988 142602 solver.cpp:218] Iteration 27000 (0.49239 iter/s, 203.091s/100 iters), loss = 0.488913
I0529 08:02:52.026077 142602 solver.cpp:237]     Train net output #0: loss = 0.488913 (* 1 = 0.488913 loss)
I0529 08:02:52.026094 142602 sgd_solver.cpp:105] Iteration 27000, lr = 0.00865
I0529 08:05:00.313007 142602 solver.cpp:218] Iteration 27100 (0.779521 iter/s, 128.284s/100 iters), loss = 0.520478
I0529 08:05:00.313184 142602 solver.cpp:237]     Train net output #0: loss = 0.520478 (* 1 = 0.520478 loss)
I0529 08:05:00.313228 142602 sgd_solver.cpp:105] Iteration 27100, lr = 0.008645
I0529 08:07:08.581843 142602 solver.cpp:218] Iteration 27200 (0.779631 iter/s, 128.266s/100 iters), loss = 0.560699
I0529 08:07:08.582093 142602 solver.cpp:237]     Train net output #0: loss = 0.560699 (* 1 = 0.560699 loss)
I0529 08:07:08.582132 142602 sgd_solver.cpp:105] Iteration 27200, lr = 0.00864
I0529 08:09:16.862211 142602 solver.cpp:218] Iteration 27300 (0.779562 iter/s, 128.277s/100 iters), loss = 0.55228
I0529 08:09:16.862406 142602 solver.cpp:237]     Train net output #0: loss = 0.55228 (* 1 = 0.55228 loss)
I0529 08:09:16.862421 142602 sgd_solver.cpp:105] Iteration 27300, lr = 0.008635
I0529 08:10:08.450345 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:11:25.122615 142602 solver.cpp:218] Iteration 27400 (0.779683 iter/s, 128.257s/100 iters), loss = 0.506871
I0529 08:11:25.122808 142602 solver.cpp:237]     Train net output #0: loss = 0.506871 (* 1 = 0.506871 loss)
I0529 08:11:25.122828 142602 sgd_solver.cpp:105] Iteration 27400, lr = 0.00863
I0529 08:13:33.392139 142602 solver.cpp:218] Iteration 27500 (0.779627 iter/s, 128.266s/100 iters), loss = 0.52276
I0529 08:13:33.392349 142602 solver.cpp:237]     Train net output #0: loss = 0.52276 (* 1 = 0.52276 loss)
I0529 08:13:33.392374 142602 sgd_solver.cpp:105] Iteration 27500, lr = 0.008625
I0529 08:15:41.645054 142602 solver.cpp:218] Iteration 27600 (0.779728 iter/s, 128.25s/100 iters), loss = 0.457337
I0529 08:15:41.645284 142602 solver.cpp:237]     Train net output #0: loss = 0.457337 (* 1 = 0.457337 loss)
I0529 08:15:41.645310 142602 sgd_solver.cpp:105] Iteration 27600, lr = 0.00862
I0529 08:17:49.918340 142602 solver.cpp:218] Iteration 27700 (0.779605 iter/s, 128.27s/100 iters), loss = 0.356886
I0529 08:17:49.918562 142602 solver.cpp:237]     Train net output #0: loss = 0.356886 (* 1 = 0.356886 loss)
I0529 08:17:49.918576 142602 sgd_solver.cpp:105] Iteration 27700, lr = 0.008615
I0529 08:18:29.907013 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:19:58.177989 142602 solver.cpp:218] Iteration 27800 (0.779688 iter/s, 128.257s/100 iters), loss = 0.399939
I0529 08:19:58.178174 142602 solver.cpp:237]     Train net output #0: loss = 0.399939 (* 1 = 0.399939 loss)
I0529 08:19:58.178187 142602 sgd_solver.cpp:105] Iteration 27800, lr = 0.00861
I0529 08:22:06.379245 142602 solver.cpp:218] Iteration 27900 (0.780043 iter/s, 128.198s/100 iters), loss = 0.438546
I0529 08:22:06.379452 142602 solver.cpp:237]     Train net output #0: loss = 0.438546 (* 1 = 0.438546 loss)
I0529 08:22:06.379477 142602 sgd_solver.cpp:105] Iteration 27900, lr = 0.008605
I0529 08:24:13.389780 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_28000.caffemodel
I0529 08:24:13.553189 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_28000.solverstate
I0529 08:24:13.612934 142602 solver.cpp:330] Iteration 28000, Testing net (#0)
I0529 08:24:37.529882 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:13.839483 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:27.993654 142602 solver.cpp:397]     Test net output #0: accuracy = 0.46775
I0529 08:25:27.993741 142602 solver.cpp:397]     Test net output #1: loss = 1.9792 (* 1 = 1.9792 loss)
I0529 08:25:29.271610 142602 solver.cpp:218] Iteration 28000 (0.492884 iter/s, 202.888s/100 iters), loss = 0.53883
I0529 08:25:29.271684 142602 solver.cpp:237]     Train net output #0: loss = 0.53883 (* 1 = 0.53883 loss)
I0529 08:25:29.271699 142602 sgd_solver.cpp:105] Iteration 28000, lr = 0.0086
I0529 08:27:37.536087 142602 solver.cpp:218] Iteration 28100 (0.779658 iter/s, 128.261s/100 iters), loss = 0.483728
I0529 08:27:37.536288 142602 solver.cpp:237]     Train net output #0: loss = 0.483728 (* 1 = 0.483728 loss)
I0529 08:27:37.536325 142602 sgd_solver.cpp:105] Iteration 28100, lr = 0.008595
I0529 08:28:05.982435 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:29:45.825337 142602 solver.cpp:218] Iteration 28200 (0.779508 iter/s, 128.286s/100 iters), loss = 0.463699
I0529 08:29:45.825531 142602 solver.cpp:237]     Train net output #0: loss = 0.463699 (* 1 = 0.463699 loss)
I0529 08:29:45.825544 142602 sgd_solver.cpp:105] Iteration 28200, lr = 0.00859
I0529 08:31:54.151998 142602 solver.cpp:218] Iteration 28300 (0.779281 iter/s, 128.323s/100 iters), loss = 0.498267
I0529 08:31:54.152226 142602 solver.cpp:237]     Train net output #0: loss = 0.498267 (* 1 = 0.498267 loss)
I0529 08:31:54.152251 142602 sgd_solver.cpp:105] Iteration 28300, lr = 0.008585
I0529 08:34:02.516589 142602 solver.cpp:218] Iteration 28400 (0.779051 iter/s, 128.361s/100 iters), loss = 0.490288
I0529 08:34:02.516870 142602 solver.cpp:237]     Train net output #0: loss = 0.490288 (* 1 = 0.490288 loss)
I0529 08:34:02.516885 142602 sgd_solver.cpp:105] Iteration 28400, lr = 0.00858
I0529 08:36:10.861637 142602 solver.cpp:218] Iteration 28500 (0.77917 iter/s, 128.342s/100 iters), loss = 0.533253
I0529 08:36:10.861814 142602 solver.cpp:237]     Train net output #0: loss = 0.533253 (* 1 = 0.533253 loss)
I0529 08:36:10.861829 142602 sgd_solver.cpp:105] Iteration 28500, lr = 0.008575
I0529 08:36:26.522179 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:38:19.186612 142602 solver.cpp:218] Iteration 28600 (0.779292 iter/s, 128.322s/100 iters), loss = 0.475387
I0529 08:38:19.186868 142602 solver.cpp:237]     Train net output #0: loss = 0.475387 (* 1 = 0.475387 loss)
I0529 08:38:19.186889 142602 sgd_solver.cpp:105] Iteration 28600, lr = 0.00857
I0529 08:40:27.437548 142602 solver.cpp:218] Iteration 28700 (0.779742 iter/s, 128.248s/100 iters), loss = 0.56518
I0529 08:40:27.437712 142602 solver.cpp:237]     Train net output #0: loss = 0.56518 (* 1 = 0.56518 loss)
I0529 08:40:27.437738 142602 sgd_solver.cpp:105] Iteration 28700, lr = 0.008565
I0529 08:42:35.804812 142602 solver.cpp:218] Iteration 28800 (0.779034 iter/s, 128.364s/100 iters), loss = 0.546526
I0529 08:42:35.805045 142602 solver.cpp:237]     Train net output #0: loss = 0.546526 (* 1 = 0.546526 loss)
I0529 08:42:35.805064 142602 sgd_solver.cpp:105] Iteration 28800, lr = 0.00856
I0529 08:44:44.120436 142602 solver.cpp:218] Iteration 28900 (0.779348 iter/s, 128.312s/100 iters), loss = 0.574093
I0529 08:44:44.120620 142602 solver.cpp:237]     Train net output #0: loss = 0.574093 (* 1 = 0.574093 loss)
I0529 08:44:44.120654 142602 sgd_solver.cpp:105] Iteration 28900, lr = 0.008555
I0529 08:44:48.195675 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:46:51.160807 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_29000.caffemodel
I0529 08:46:51.610610 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_29000.solverstate
I0529 08:46:51.669128 142602 solver.cpp:330] Iteration 29000, Testing net (#0)
I0529 08:47:13.814007 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:47:50.173352 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:48:06.052204 142602 solver.cpp:397]     Test net output #0: accuracy = 0.45555
I0529 08:48:06.052273 142602 solver.cpp:397]     Test net output #1: loss = 2.47752 (* 1 = 2.47752 loss)
I0529 08:48:07.329546 142602 solver.cpp:218] Iteration 29000 (0.492116 iter/s, 203.204s/100 iters), loss = 0.543351
I0529 08:48:07.329610 142602 solver.cpp:237]     Train net output #0: loss = 0.543351 (* 1 = 0.543351 loss)
I0529 08:48:07.329623 142602 sgd_solver.cpp:105] Iteration 29000, lr = 0.00855
I0529 08:50:15.679353 142602 solver.cpp:218] Iteration 29100 (0.77914 iter/s, 128.347s/100 iters), loss = 0.549892
I0529 08:50:15.679524 142602 solver.cpp:237]     Train net output #0: loss = 0.549892 (* 1 = 0.549892 loss)
I0529 08:50:15.679549 142602 sgd_solver.cpp:105] Iteration 29100, lr = 0.008545
I0529 08:52:24.008380 142602 solver.cpp:218] Iteration 29200 (0.779267 iter/s, 128.326s/100 iters), loss = 0.527413
I0529 08:52:24.008585 142602 solver.cpp:237]     Train net output #0: loss = 0.527413 (* 1 = 0.527413 loss)
I0529 08:52:24.008610 142602 sgd_solver.cpp:105] Iteration 29200, lr = 0.00854
I0529 08:54:23.639133 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:54:32.366583 142602 solver.cpp:218] Iteration 29300 (0.77909 iter/s, 128.355s/100 iters), loss = 0.372062
I0529 08:54:32.366662 142602 solver.cpp:237]     Train net output #0: loss = 0.372062 (* 1 = 0.372062 loss)
I0529 08:54:32.366675 142602 sgd_solver.cpp:105] Iteration 29300, lr = 0.008535
I0529 08:56:40.723850 142602 solver.cpp:218] Iteration 29400 (0.779095 iter/s, 128.354s/100 iters), loss = 0.584108
I0529 08:56:40.724071 142602 solver.cpp:237]     Train net output #0: loss = 0.584108 (* 1 = 0.584108 loss)
I0529 08:56:40.724104 142602 sgd_solver.cpp:105] Iteration 29400, lr = 0.00853
I0529 08:58:49.107522 142602 solver.cpp:218] Iteration 29500 (0.778935 iter/s, 128.38s/100 iters), loss = 0.479695
I0529 08:58:49.107756 142602 solver.cpp:237]     Train net output #0: loss = 0.479695 (* 1 = 0.479695 loss)
I0529 08:58:49.107774 142602 sgd_solver.cpp:105] Iteration 29500, lr = 0.008525
I0529 09:00:57.482287 142602 solver.cpp:218] Iteration 29600 (0.778989 iter/s, 128.371s/100 iters), loss = 0.47837
I0529 09:00:57.482595 142602 solver.cpp:237]     Train net output #0: loss = 0.47837 (* 1 = 0.47837 loss)
I0529 09:00:57.482609 142602 sgd_solver.cpp:105] Iteration 29600, lr = 0.00852
I0529 09:02:45.566867 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:03:05.851160 142602 solver.cpp:218] Iteration 29700 (0.779026 iter/s, 128.365s/100 iters), loss = 0.357146
I0529 09:03:05.851250 142602 solver.cpp:237]     Train net output #0: loss = 0.357146 (* 1 = 0.357146 loss)
I0529 09:03:05.851264 142602 sgd_solver.cpp:105] Iteration 29700, lr = 0.008515
I0529 09:05:14.187500 142602 solver.cpp:218] Iteration 29800 (0.779222 iter/s, 128.333s/100 iters), loss = 0.662127
I0529 09:05:14.187736 142602 solver.cpp:237]     Train net output #0: loss = 0.662127 (* 1 = 0.662127 loss)
I0529 09:05:14.187758 142602 sgd_solver.cpp:105] Iteration 29800, lr = 0.00851
I0529 09:07:22.539088 142602 solver.cpp:218] Iteration 29900 (0.77913 iter/s, 128.348s/100 iters), loss = 0.465192
I0529 09:07:22.539299 142602 solver.cpp:237]     Train net output #0: loss = 0.465192 (* 1 = 0.465192 loss)
I0529 09:07:22.539312 142602 sgd_solver.cpp:105] Iteration 29900, lr = 0.008505
I0529 09:09:29.606911 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_30000.caffemodel
I0529 09:09:30.130785 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_30000.solverstate
I0529 09:09:30.191913 142602 solver.cpp:330] Iteration 30000, Testing net (#0)
I0529 09:09:50.636739 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:10:27.059953 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:10:44.580386 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4502
I0529 09:10:44.580471 142602 solver.cpp:397]     Test net output #1: loss = 1.88412 (* 1 = 1.88412 loss)
I0529 09:10:45.857168 142602 solver.cpp:218] Iteration 30000 (0.491852 iter/s, 203.313s/100 iters), loss = 0.535476
I0529 09:10:45.857244 142602 solver.cpp:237]     Train net output #0: loss = 0.535476 (* 1 = 0.535476 loss)
I0529 09:10:45.857256 142602 sgd_solver.cpp:105] Iteration 30000, lr = 0.0085
I0529 09:12:22.325402 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:12:54.230723 142602 solver.cpp:218] Iteration 30100 (0.778996 iter/s, 128.37s/100 iters), loss = 0.626292
I0529 09:12:54.230890 142602 solver.cpp:237]     Train net output #0: loss = 0.626292 (* 1 = 0.626292 loss)
I0529 09:12:54.230916 142602 sgd_solver.cpp:105] Iteration 30100, lr = 0.008495
I0529 09:15:02.622108 142602 solver.cpp:218] Iteration 30200 (0.778888 iter/s, 128.388s/100 iters), loss = 0.376693
I0529 09:15:02.622269 142602 solver.cpp:237]     Train net output #0: loss = 0.376693 (* 1 = 0.376693 loss)
I0529 09:15:02.622284 142602 sgd_solver.cpp:105] Iteration 30200, lr = 0.00849
I0529 09:17:11.040386 142602 solver.cpp:218] Iteration 30300 (0.778725 iter/s, 128.415s/100 iters), loss = 0.38217
I0529 09:17:11.040659 142602 solver.cpp:237]     Train net output #0: loss = 0.38217 (* 1 = 0.38217 loss)
I0529 09:17:11.040678 142602 sgd_solver.cpp:105] Iteration 30300, lr = 0.008485
I0529 09:19:19.482820 142602 solver.cpp:218] Iteration 30400 (0.778579 iter/s, 128.439s/100 iters), loss = 0.3952
I0529 09:19:19.483006 142602 solver.cpp:237]     Train net output #0: loss = 0.3952 (* 1 = 0.3952 loss)
I0529 09:19:19.483023 142602 sgd_solver.cpp:105] Iteration 30400, lr = 0.00848
I0529 09:20:43.206774 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:21:27.896164 142602 solver.cpp:218] Iteration 30500 (0.778755 iter/s, 128.41s/100 iters), loss = 0.50482
I0529 09:21:27.896380 142602 solver.cpp:237]     Train net output #0: loss = 0.50482 (* 1 = 0.50482 loss)
I0529 09:21:27.896396 142602 sgd_solver.cpp:105] Iteration 30500, lr = 0.008475
I0529 09:23:36.367197 142602 solver.cpp:218] Iteration 30600 (0.778406 iter/s, 128.468s/100 iters), loss = 0.371431
I0529 09:23:36.367460 142602 solver.cpp:237]     Train net output #0: loss = 0.371431 (* 1 = 0.371431 loss)
I0529 09:23:36.367476 142602 sgd_solver.cpp:105] Iteration 30600, lr = 0.00847
I0529 09:25:44.794587 142602 solver.cpp:218] Iteration 30700 (0.77867 iter/s, 128.424s/100 iters), loss = 0.464778
I0529 09:25:44.794787 142602 solver.cpp:237]     Train net output #0: loss = 0.464778 (* 1 = 0.464778 loss)
I0529 09:25:44.794801 142602 sgd_solver.cpp:105] Iteration 30700, lr = 0.008465
I0529 09:27:53.324923 142602 solver.cpp:218] Iteration 30800 (0.778047 iter/s, 128.527s/100 iters), loss = 0.522498
I0529 09:27:53.325525 142602 solver.cpp:237]     Train net output #0: loss = 0.522498 (* 1 = 0.522498 loss)
I0529 09:27:53.325543 142602 sgd_solver.cpp:105] Iteration 30800, lr = 0.00846
I0529 09:29:05.536960 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:30:01.855463 142602 solver.cpp:218] Iteration 30900 (0.778047 iter/s, 128.527s/100 iters), loss = 0.391568
I0529 09:30:01.855564 142602 solver.cpp:237]     Train net output #0: loss = 0.391568 (* 1 = 0.391568 loss)
I0529 09:30:01.855587 142602 sgd_solver.cpp:105] Iteration 30900, lr = 0.008455
I0529 09:32:09.125437 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_31000.caffemodel
I0529 09:32:09.621055 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_31000.solverstate
I0529 09:32:09.681721 142602 solver.cpp:330] Iteration 31000, Testing net (#0)
I0529 09:32:28.516309 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:33:04.907665 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:33:24.257233 142602 solver.cpp:397]     Test net output #0: accuracy = 0.48145
I0529 09:33:24.257308 142602 solver.cpp:397]     Test net output #1: loss = 2.11299 (* 1 = 2.11299 loss)
I0529 09:33:25.546875 142602 solver.cpp:218] Iteration 31000 (0.49095 iter/s, 203.687s/100 iters), loss = 0.352738
I0529 09:33:25.546957 142602 solver.cpp:237]     Train net output #0: loss = 0.352738 (* 1 = 0.352738 loss)
I0529 09:33:25.546969 142602 sgd_solver.cpp:105] Iteration 31000, lr = 0.00845
I0529 09:35:34.134665 142602 solver.cpp:218] Iteration 31100 (0.777698 iter/s, 128.585s/100 iters), loss = 0.541281
I0529 09:35:34.134876 142602 solver.cpp:237]     Train net output #0: loss = 0.541281 (* 1 = 0.541281 loss)
I0529 09:35:34.134891 142602 sgd_solver.cpp:105] Iteration 31100, lr = 0.008445
I0529 09:37:42.683564 142602 solver.cpp:218] Iteration 31200 (0.777934 iter/s, 128.546s/100 iters), loss = 0.419944
I0529 09:37:42.683764 142602 solver.cpp:237]     Train net output #0: loss = 0.419944 (* 1 = 0.419944 loss)
I0529 09:37:42.683802 142602 sgd_solver.cpp:105] Iteration 31200, lr = 0.00844
I0529 09:38:43.319702 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:39:51.239998 142602 solver.cpp:218] Iteration 31300 (0.777888 iter/s, 128.553s/100 iters), loss = 0.297096
I0529 09:39:51.240231 142602 solver.cpp:237]     Train net output #0: loss = 0.297096 (* 1 = 0.297096 loss)
I0529 09:39:51.240247 142602 sgd_solver.cpp:105] Iteration 31300, lr = 0.008435
I0529 09:41:59.847600 142602 solver.cpp:218] Iteration 31400 (0.777579 iter/s, 128.604s/100 iters), loss = 0.329511
I0529 09:41:59.847839 142602 solver.cpp:237]     Train net output #0: loss = 0.329511 (* 1 = 0.329511 loss)
I0529 09:41:59.847854 142602 sgd_solver.cpp:105] Iteration 31400, lr = 0.00843
I0529 09:44:08.427224 142602 solver.cpp:218] Iteration 31500 (0.777748 iter/s, 128.576s/100 iters), loss = 0.463353
I0529 09:44:08.427423 142602 solver.cpp:237]     Train net output #0: loss = 0.463353 (* 1 = 0.463353 loss)
I0529 09:44:08.427453 142602 sgd_solver.cpp:105] Iteration 31500, lr = 0.008425
I0529 09:46:16.990778 142602 solver.cpp:218] Iteration 31600 (0.777845 iter/s, 128.56s/100 iters), loss = 0.347629
I0529 09:46:16.990968 142602 solver.cpp:237]     Train net output #0: loss = 0.347629 (* 1 = 0.347629 loss)
I0529 09:46:16.990983 142602 sgd_solver.cpp:105] Iteration 31600, lr = 0.00842
I0529 09:47:04.838246 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:48:25.559222 142602 solver.cpp:218] Iteration 31700 (0.777815 iter/s, 128.565s/100 iters), loss = 0.495737
I0529 09:48:25.559434 142602 solver.cpp:237]     Train net output #0: loss = 0.495737 (* 1 = 0.495737 loss)
I0529 09:48:25.559448 142602 sgd_solver.cpp:105] Iteration 31700, lr = 0.008415
I0529 09:50:34.126874 142602 solver.cpp:218] Iteration 31800 (0.77782 iter/s, 128.564s/100 iters), loss = 0.366554
I0529 09:50:34.127109 142602 solver.cpp:237]     Train net output #0: loss = 0.366554 (* 1 = 0.366554 loss)
I0529 09:50:34.127121 142602 sgd_solver.cpp:105] Iteration 31800, lr = 0.00841
I0529 09:52:42.716843 142602 solver.cpp:218] Iteration 31900 (0.777685 iter/s, 128.587s/100 iters), loss = 0.408058
I0529 09:52:42.717089 142602 solver.cpp:237]     Train net output #0: loss = 0.408058 (* 1 = 0.408058 loss)
I0529 09:52:42.717108 142602 sgd_solver.cpp:105] Iteration 31900, lr = 0.008405
I0529 09:54:50.004834 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_32000.caffemodel
I0529 09:54:50.297014 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_32000.solverstate
I0529 09:54:50.355804 142602 solver.cpp:330] Iteration 32000, Testing net (#0)
I0529 09:55:07.406182 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:55:43.819464 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:56:04.960827 142602 solver.cpp:397]     Test net output #0: accuracy = 0.3252
I0529 09:56:04.960909 142602 solver.cpp:397]     Test net output #1: loss = 3.51774 (* 1 = 3.51774 loss)
I0529 09:56:06.241554 142602 solver.cpp:218] Iteration 32000 (0.491353 iter/s, 203.52s/100 iters), loss = 0.331925
I0529 09:56:06.241626 142602 solver.cpp:237]     Train net output #0: loss = 0.331925 (* 1 = 0.331925 loss)
I0529 09:56:06.241643 142602 sgd_solver.cpp:105] Iteration 32000, lr = 0.0084
I0529 09:56:42.442138 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:58:14.830112 142602 solver.cpp:218] Iteration 32100 (0.777693 iter/s, 128.585s/100 iters), loss = 0.223046
I0529 09:58:14.830301 142602 solver.cpp:237]     Train net output #0: loss = 0.223046 (* 1 = 0.223046 loss)
I0529 09:58:14.830323 142602 sgd_solver.cpp:105] Iteration 32100, lr = 0.008395
I0529 10:00:23.415000 142602 solver.cpp:218] Iteration 32200 (0.777716 iter/s, 128.582s/100 iters), loss = 0.420912
I0529 10:00:23.415181 142602 solver.cpp:237]     Train net output #0: loss = 0.420912 (* 1 = 0.420912 loss)
I0529 10:00:23.415196 142602 sgd_solver.cpp:105] Iteration 32200, lr = 0.00839
I0529 10:02:32.017124 142602 solver.cpp:218] Iteration 32300 (0.777612 iter/s, 128.599s/100 iters), loss = 0.493292
I0529 10:02:32.017307 142602 solver.cpp:237]     Train net output #0: loss = 0.493292 (* 1 = 0.493292 loss)
I0529 10:02:32.017324 142602 sgd_solver.cpp:105] Iteration 32300, lr = 0.008385
I0529 10:04:40.642622 142602 solver.cpp:218] Iteration 32400 (0.777471 iter/s, 128.622s/100 iters), loss = 0.42777
I0529 10:04:40.642874 142602 solver.cpp:237]     Train net output #0: loss = 0.42777 (* 1 = 0.42777 loss)
I0529 10:04:40.642886 142602 sgd_solver.cpp:105] Iteration 32400, lr = 0.00838
I0529 10:05:05.308295 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:06:49.240439 142602 solver.cpp:218] Iteration 32500 (0.777638 iter/s, 128.595s/100 iters), loss = 0.382392
I0529 10:06:49.240646 142602 solver.cpp:237]     Train net output #0: loss = 0.382392 (* 1 = 0.382392 loss)
I0529 10:06:49.240661 142602 sgd_solver.cpp:105] Iteration 32500, lr = 0.008375
I0529 10:08:57.840721 142602 solver.cpp:218] Iteration 32600 (0.777623 iter/s, 128.597s/100 iters), loss = 0.335357
I0529 10:08:57.840973 142602 solver.cpp:237]     Train net output #0: loss = 0.335357 (* 1 = 0.335357 loss)
I0529 10:08:57.840987 142602 sgd_solver.cpp:105] Iteration 32600, lr = 0.00837
I0529 10:11:06.452652 142602 solver.cpp:218] Iteration 32700 (0.777553 iter/s, 128.609s/100 iters), loss = 0.452021
I0529 10:11:06.452932 142602 solver.cpp:237]     Train net output #0: loss = 0.452021 (* 1 = 0.452021 loss)
I0529 10:11:06.452947 142602 sgd_solver.cpp:105] Iteration 32700, lr = 0.008365
I0529 10:13:15.047688 142602 solver.cpp:218] Iteration 32800 (0.777655 iter/s, 128.592s/100 iters), loss = 0.429163
I0529 10:13:15.047896 142602 solver.cpp:237]     Train net output #0: loss = 0.429163 (* 1 = 0.429163 loss)
I0529 10:13:15.047924 142602 sgd_solver.cpp:105] Iteration 32800, lr = 0.00836
I0529 10:13:26.877069 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:15:23.640931 142602 solver.cpp:218] Iteration 32900 (0.777665 iter/s, 128.59s/100 iters), loss = 0.37044
I0529 10:15:23.641242 142602 solver.cpp:237]     Train net output #0: loss = 0.37044 (* 1 = 0.37044 loss)
I0529 10:15:23.641257 142602 sgd_solver.cpp:105] Iteration 32900, lr = 0.008355
I0529 10:17:31.009155 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_33000.caffemodel
I0529 10:17:31.380986 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_33000.solverstate
I0529 10:17:31.437814 142602 solver.cpp:330] Iteration 33000, Testing net (#0)
I0529 10:17:46.715140 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:18:23.210427 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:18:46.075956 142602 solver.cpp:397]     Test net output #0: accuracy = 0.35795
I0529 10:18:46.076050 142602 solver.cpp:397]     Test net output #1: loss = 3.12683 (* 1 = 3.12683 loss)
I0529 10:18:47.356835 142602 solver.cpp:218] Iteration 33000 (0.490892 iter/s, 203.711s/100 iters), loss = 0.437034
I0529 10:18:47.356907 142602 solver.cpp:237]     Train net output #0: loss = 0.437034 (* 1 = 0.437034 loss)
I0529 10:18:47.356921 142602 sgd_solver.cpp:105] Iteration 33000, lr = 0.00835
I0529 10:20:55.944139 142602 solver.cpp:218] Iteration 33100 (0.7777 iter/s, 128.584s/100 iters), loss = 0.391528
I0529 10:20:55.944345 142602 solver.cpp:237]     Train net output #0: loss = 0.391528 (* 1 = 0.391528 loss)
I0529 10:20:55.944360 142602 sgd_solver.cpp:105] Iteration 33100, lr = 0.008345
I0529 10:23:04.581176 142602 solver.cpp:218] Iteration 33200 (0.777401 iter/s, 128.634s/100 iters), loss = 0.493527
I0529 10:23:04.581392 142602 solver.cpp:237]     Train net output #0: loss = 0.493527 (* 1 = 0.493527 loss)
I0529 10:23:04.581415 142602 sgd_solver.cpp:105] Iteration 33200, lr = 0.00834
I0529 10:23:04.816263 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:25:13.200742 142602 solver.cpp:218] Iteration 33300 (0.777506 iter/s, 128.616s/100 iters), loss = 0.336231
I0529 10:25:13.200932 142602 solver.cpp:237]     Train net output #0: loss = 0.336231 (* 1 = 0.336231 loss)
I0529 10:25:13.200944 142602 sgd_solver.cpp:105] Iteration 33300, lr = 0.008335
I0529 10:27:21.834431 142602 solver.cpp:218] Iteration 33400 (0.777421 iter/s, 128.63s/100 iters), loss = 0.412941
I0529 10:27:21.834736 142602 solver.cpp:237]     Train net output #0: loss = 0.412941 (* 1 = 0.412941 loss)
I0529 10:27:21.834750 142602 sgd_solver.cpp:105] Iteration 33400, lr = 0.00833
I0529 10:29:30.440284 142602 solver.cpp:218] Iteration 33500 (0.777589 iter/s, 128.603s/100 iters), loss = 0.328968
I0529 10:29:30.440479 142602 solver.cpp:237]     Train net output #0: loss = 0.328968 (* 1 = 0.328968 loss)
I0529 10:29:30.440506 142602 sgd_solver.cpp:105] Iteration 33500, lr = 0.008325
I0529 10:31:27.643254 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:31:38.996004 142602 solver.cpp:218] Iteration 33600 (0.777892 iter/s, 128.553s/100 iters), loss = 0.428198
I0529 10:31:38.996088 142602 solver.cpp:237]     Train net output #0: loss = 0.428198 (* 1 = 0.428198 loss)
I0529 10:31:38.996119 142602 sgd_solver.cpp:105] Iteration 33600, lr = 0.00832
I0529 10:33:47.611488 142602 solver.cpp:218] Iteration 33700 (0.77753 iter/s, 128.612s/100 iters), loss = 0.303786
I0529 10:33:47.611743 142602 solver.cpp:237]     Train net output #0: loss = 0.303786 (* 1 = 0.303786 loss)
I0529 10:33:47.611768 142602 sgd_solver.cpp:105] Iteration 33700, lr = 0.008315
I0529 10:35:56.181911 142602 solver.cpp:218] Iteration 33800 (0.777803 iter/s, 128.567s/100 iters), loss = 0.437852
I0529 10:35:56.182484 142602 solver.cpp:237]     Train net output #0: loss = 0.437852 (* 1 = 0.437852 loss)
I0529 10:35:56.182508 142602 sgd_solver.cpp:105] Iteration 33800, lr = 0.00831
I0529 10:38:04.776481 142602 solver.cpp:218] Iteration 33900 (0.777659 iter/s, 128.591s/100 iters), loss = 0.335554
I0529 10:38:04.776705 142602 solver.cpp:237]     Train net output #0: loss = 0.335554 (* 1 = 0.335554 loss)
I0529 10:38:04.776720 142602 sgd_solver.cpp:105] Iteration 33900, lr = 0.008305
I0529 10:39:49.148319 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:40:12.061734 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_34000.caffemodel
I0529 10:40:12.234436 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_34000.solverstate
I0529 10:40:12.300014 142602 solver.cpp:330] Iteration 34000, Testing net (#0)
I0529 10:40:25.850281 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:41:02.284219 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:41:26.953857 142602 solver.cpp:397]     Test net output #0: accuracy = 0.43695
I0529 10:41:26.953941 142602 solver.cpp:397]     Test net output #1: loss = 2.50326 (* 1 = 2.50326 loss)
I0529 10:41:28.237126 142602 solver.cpp:218] Iteration 34000 (0.491507 iter/s, 203.456s/100 iters), loss = 0.620458
I0529 10:41:28.237192 142602 solver.cpp:237]     Train net output #0: loss = 0.620458 (* 1 = 0.620458 loss)
I0529 10:41:28.237205 142602 sgd_solver.cpp:105] Iteration 34000, lr = 0.0083
I0529 10:43:36.871106 142602 solver.cpp:218] Iteration 34100 (0.777419 iter/s, 128.631s/100 iters), loss = 0.351627
I0529 10:43:36.871274 142602 solver.cpp:237]     Train net output #0: loss = 0.351627 (* 1 = 0.351627 loss)
I0529 10:43:36.871311 142602 sgd_solver.cpp:105] Iteration 34100, lr = 0.008295
I0529 10:45:45.510527 142602 solver.cpp:218] Iteration 34200 (0.777386 iter/s, 128.636s/100 iters), loss = 0.432758
I0529 10:45:45.510687 142602 solver.cpp:237]     Train net output #0: loss = 0.432758 (* 1 = 0.432758 loss)
I0529 10:45:45.510700 142602 sgd_solver.cpp:105] Iteration 34200, lr = 0.00829
I0529 10:47:54.174897 142602 solver.cpp:218] Iteration 34300 (0.777235 iter/s, 128.661s/100 iters), loss = 0.409817
I0529 10:47:54.175091 142602 solver.cpp:237]     Train net output #0: loss = 0.409817 (* 1 = 0.409817 loss)
I0529 10:47:54.175113 142602 sgd_solver.cpp:105] Iteration 34300, lr = 0.008285
I0529 10:49:27.043591 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:50:02.840544 142602 solver.cpp:218] Iteration 34400 (0.777228 iter/s, 128.662s/100 iters), loss = 0.388858
I0529 10:50:02.840759 142602 solver.cpp:237]     Train net output #0: loss = 0.388858 (* 1 = 0.388858 loss)
I0529 10:50:02.840775 142602 sgd_solver.cpp:105] Iteration 34400, lr = 0.00828
I0529 10:52:11.512534 142602 solver.cpp:218] Iteration 34500 (0.77719 iter/s, 128.669s/100 iters), loss = 0.22883
I0529 10:52:11.512754 142602 solver.cpp:237]     Train net output #0: loss = 0.22883 (* 1 = 0.22883 loss)
I0529 10:52:11.512770 142602 sgd_solver.cpp:105] Iteration 34500, lr = 0.008275
I0529 10:54:20.148545 142602 solver.cpp:218] Iteration 34600 (0.777407 iter/s, 128.633s/100 iters), loss = 0.37213
I0529 10:54:20.148766 142602 solver.cpp:237]     Train net output #0: loss = 0.37213 (* 1 = 0.37213 loss)
I0529 10:54:20.148777 142602 sgd_solver.cpp:105] Iteration 34600, lr = 0.00827
I0529 10:56:28.798367 142602 solver.cpp:218] Iteration 34700 (0.777323 iter/s, 128.647s/100 iters), loss = 0.464293
I0529 10:56:28.798647 142602 solver.cpp:237]     Train net output #0: loss = 0.464293 (* 1 = 0.464293 loss)
I0529 10:56:28.798673 142602 sgd_solver.cpp:105] Iteration 34700, lr = 0.008265
I0529 10:57:48.826891 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:58:37.414520 142602 solver.cpp:218] Iteration 34800 (0.777527 iter/s, 128.613s/100 iters), loss = 0.397714
I0529 10:58:37.414702 142602 solver.cpp:237]     Train net output #0: loss = 0.397714 (* 1 = 0.397714 loss)
I0529 10:58:37.414716 142602 sgd_solver.cpp:105] Iteration 34800, lr = 0.00826
I0529 11:00:46.054744 142602 solver.cpp:218] Iteration 34900 (0.777381 iter/s, 128.637s/100 iters), loss = 0.317377
I0529 11:00:46.054903 142602 solver.cpp:237]     Train net output #0: loss = 0.317377 (* 1 = 0.317377 loss)
I0529 11:00:46.054930 142602 sgd_solver.cpp:105] Iteration 34900, lr = 0.008255
I0529 11:02:53.479523 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_35000.caffemodel
I0529 11:02:53.989374 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_35000.solverstate
I0529 11:02:54.052655 142602 solver.cpp:330] Iteration 35000, Testing net (#0)
I0529 11:03:05.907021 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:03:42.353013 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:04:08.737319 142602 solver.cpp:397]     Test net output #0: accuracy = 0.45935
I0529 11:04:08.737404 142602 solver.cpp:397]     Test net output #1: loss = 2.56351 (* 1 = 2.56351 loss)
I0529 11:04:10.018662 142602 solver.cpp:218] Iteration 35000 (0.490295 iter/s, 203.959s/100 iters), loss = 0.43258
I0529 11:04:10.018740 142602 solver.cpp:237]     Train net output #0: loss = 0.43258 (* 1 = 0.43258 loss)
I0529 11:04:10.018755 142602 sgd_solver.cpp:105] Iteration 35000, lr = 0.00825
I0529 11:06:18.675534 142602 solver.cpp:218] Iteration 35100 (0.77728 iter/s, 128.654s/100 iters), loss = 0.340198
I0529 11:06:18.675684 142602 solver.cpp:237]     Train net output #0: loss = 0.340198 (* 1 = 0.340198 loss)
I0529 11:06:18.675706 142602 sgd_solver.cpp:105] Iteration 35100, lr = 0.008245
I0529 11:07:27.104920 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:08:27.327262 142602 solver.cpp:218] Iteration 35200 (0.777311 iter/s, 128.649s/100 iters), loss = 0.463956
I0529 11:08:27.327538 142602 solver.cpp:237]     Train net output #0: loss = 0.463956 (* 1 = 0.463956 loss)
I0529 11:08:27.327554 142602 sgd_solver.cpp:105] Iteration 35200, lr = 0.00824
I0529 11:10:35.980054 142602 solver.cpp:218] Iteration 35300 (0.777306 iter/s, 128.65s/100 iters), loss = 0.330356
I0529 11:10:35.980235 142602 solver.cpp:237]     Train net output #0: loss = 0.330356 (* 1 = 0.330356 loss)
I0529 11:10:35.980276 142602 sgd_solver.cpp:105] Iteration 35300, lr = 0.008235
I0529 11:12:44.654341 142602 solver.cpp:218] Iteration 35400 (0.777175 iter/s, 128.671s/100 iters), loss = 0.439231
I0529 11:12:44.654527 142602 solver.cpp:237]     Train net output #0: loss = 0.439231 (* 1 = 0.439231 loss)
I0529 11:12:44.654559 142602 sgd_solver.cpp:105] Iteration 35400, lr = 0.00823
I0529 11:14:53.352133 142602 solver.cpp:218] Iteration 35500 (0.777033 iter/s, 128.695s/100 iters), loss = 0.365352
I0529 11:14:53.352370 142602 solver.cpp:237]     Train net output #0: loss = 0.365352 (* 1 = 0.365352 loss)
I0529 11:14:53.352385 142602 sgd_solver.cpp:105] Iteration 35500, lr = 0.008225
I0529 11:15:50.208657 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:17:02.087862 142602 solver.cpp:218] Iteration 35600 (0.776804 iter/s, 128.733s/100 iters), loss = 0.523146
I0529 11:17:02.088021 142602 solver.cpp:237]     Train net output #0: loss = 0.523147 (* 1 = 0.523147 loss)
I0529 11:17:02.088037 142602 sgd_solver.cpp:105] Iteration 35600, lr = 0.00822
I0529 11:19:10.770737 142602 solver.cpp:218] Iteration 35700 (0.777123 iter/s, 128.68s/100 iters), loss = 0.303163
I0529 11:19:10.770972 142602 solver.cpp:237]     Train net output #0: loss = 0.303163 (* 1 = 0.303163 loss)
I0529 11:19:10.771004 142602 sgd_solver.cpp:105] Iteration 35700, lr = 0.008215
I0529 11:21:19.486747 142602 solver.cpp:218] Iteration 35800 (0.776923 iter/s, 128.713s/100 iters), loss = 0.542443
I0529 11:21:19.486965 142602 solver.cpp:237]     Train net output #0: loss = 0.542443 (* 1 = 0.542443 loss)
I0529 11:21:19.486979 142602 sgd_solver.cpp:105] Iteration 35800, lr = 0.00821
I0529 11:23:28.156980 142602 solver.cpp:218] Iteration 35900 (0.7772 iter/s, 128.667s/100 iters), loss = 0.36394
I0529 11:23:28.157150 142602 solver.cpp:237]     Train net output #0: loss = 0.36394 (* 1 = 0.36394 loss)
I0529 11:23:28.157165 142602 sgd_solver.cpp:105] Iteration 35900, lr = 0.008205
I0529 11:24:12.164580 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:25:35.553346 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_36000.caffemodel
I0529 11:25:36.050439 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_36000.solverstate
I0529 11:25:36.110291 142602 solver.cpp:330] Iteration 36000, Testing net (#0)
I0529 11:25:46.165777 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:26:22.673624 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:26:50.793300 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4292
I0529 11:26:50.793385 142602 solver.cpp:397]     Test net output #1: loss = 2.54942 (* 1 = 2.54942 loss)
I0529 11:26:52.075609 142602 solver.cpp:218] Iteration 36000 (0.490403 iter/s, 203.914s/100 iters), loss = 0.423245
I0529 11:26:52.075683 142602 solver.cpp:237]     Train net output #0: loss = 0.423245 (* 1 = 0.423245 loss)
I0529 11:26:52.075697 142602 sgd_solver.cpp:105] Iteration 36000, lr = 0.0082
I0529 11:29:00.781170 142602 solver.cpp:218] Iteration 36100 (0.776985 iter/s, 128.703s/100 iters), loss = 0.320795
I0529 11:29:00.781399 142602 solver.cpp:237]     Train net output #0: loss = 0.320795 (* 1 = 0.320795 loss)
I0529 11:29:00.781411 142602 sgd_solver.cpp:105] Iteration 36100, lr = 0.008195
I0529 11:31:09.467056 142602 solver.cpp:218] Iteration 36200 (0.777106 iter/s, 128.683s/100 iters), loss = 0.253352
I0529 11:31:09.467269 142602 solver.cpp:237]     Train net output #0: loss = 0.253352 (* 1 = 0.253352 loss)
I0529 11:31:09.467295 142602 sgd_solver.cpp:105] Iteration 36200, lr = 0.00819
I0529 11:33:18.107164 142602 solver.cpp:218] Iteration 36300 (0.777382 iter/s, 128.637s/100 iters), loss = 0.500747
I0529 11:33:18.107383 142602 solver.cpp:237]     Train net output #0: loss = 0.500747 (* 1 = 0.500747 loss)
I0529 11:33:18.107398 142602 sgd_solver.cpp:105] Iteration 36300, lr = 0.008185
I0529 11:33:50.488608 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:35:26.740061 142602 solver.cpp:218] Iteration 36400 (0.777426 iter/s, 128.63s/100 iters), loss = 0.518731
I0529 11:35:26.740345 142602 solver.cpp:237]     Train net output #0: loss = 0.518731 (* 1 = 0.518731 loss)
I0529 11:35:26.740360 142602 sgd_solver.cpp:105] Iteration 36400, lr = 0.00818
I0529 11:37:35.395053 142602 solver.cpp:218] Iteration 36500 (0.777293 iter/s, 128.652s/100 iters), loss = 0.381724
I0529 11:37:35.395330 142602 solver.cpp:237]     Train net output #0: loss = 0.381724 (* 1 = 0.381724 loss)
I0529 11:37:35.395345 142602 sgd_solver.cpp:105] Iteration 36500, lr = 0.008175
I0529 11:39:44.044018 142602 solver.cpp:218] Iteration 36600 (0.777328 iter/s, 128.646s/100 iters), loss = 0.258645
I0529 11:39:44.044173 142602 solver.cpp:237]     Train net output #0: loss = 0.258645 (* 1 = 0.258645 loss)
I0529 11:39:44.044185 142602 sgd_solver.cpp:105] Iteration 36600, lr = 0.00817
I0529 11:41:52.718699 142602 solver.cpp:218] Iteration 36700 (0.77717 iter/s, 128.672s/100 iters), loss = 0.270208
I0529 11:41:52.718930 142602 solver.cpp:237]     Train net output #0: loss = 0.270208 (* 1 = 0.270208 loss)
I0529 11:41:52.718941 142602 sgd_solver.cpp:105] Iteration 36700, lr = 0.008165
I0529 11:42:13.542469 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:44:01.375258 142602 solver.cpp:218] Iteration 36800 (0.777281 iter/s, 128.654s/100 iters), loss = 0.449886
I0529 11:44:01.375475 142602 solver.cpp:237]     Train net output #0: loss = 0.449887 (* 1 = 0.449887 loss)
I0529 11:44:01.375493 142602 sgd_solver.cpp:105] Iteration 36800, lr = 0.00816
I0529 11:46:10.062494 142602 solver.cpp:218] Iteration 36900 (0.777097 iter/s, 128.684s/100 iters), loss = 0.374037
I0529 11:46:10.062675 142602 solver.cpp:237]     Train net output #0: loss = 0.374038 (* 1 = 0.374038 loss)
I0529 11:46:10.062712 142602 sgd_solver.cpp:105] Iteration 36900, lr = 0.008155
I0529 11:48:17.433389 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_37000.caffemodel
I0529 11:48:17.935210 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_37000.solverstate
I0529 11:48:17.996424 142602 solver.cpp:330] Iteration 37000, Testing net (#0)
I0529 11:48:26.320878 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:49:02.815963 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:49:32.725446 142602 solver.cpp:397]     Test net output #0: accuracy = 0.40725
I0529 11:49:32.725524 142602 solver.cpp:397]     Test net output #1: loss = 2.48553 (* 1 = 2.48553 loss)
I0529 11:49:34.007304 142602 solver.cpp:218] Iteration 37000 (0.490341 iter/s, 203.94s/100 iters), loss = 0.314914
I0529 11:49:34.007515 142602 solver.cpp:237]     Train net output #0: loss = 0.314915 (* 1 = 0.314915 loss)
I0529 11:49:34.007529 142602 sgd_solver.cpp:105] Iteration 37000, lr = 0.00815
I0529 11:51:42.690145 142602 solver.cpp:218] Iteration 37100 (0.777124 iter/s, 128.68s/100 iters), loss = 0.273642
I0529 11:51:42.690354 142602 solver.cpp:237]     Train net output #0: loss = 0.273642 (* 1 = 0.273642 loss)
I0529 11:51:42.690392 142602 sgd_solver.cpp:105] Iteration 37100, lr = 0.008145
I0529 11:51:50.668705 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:53:51.400863 142602 solver.cpp:218] Iteration 37200 (0.776955 iter/s, 128.708s/100 iters), loss = 0.19974
I0529 11:53:51.401196 142602 solver.cpp:237]     Train net output #0: loss = 0.19974 (* 1 = 0.19974 loss)
I0529 11:53:51.401211 142602 sgd_solver.cpp:105] Iteration 37200, lr = 0.00814
I0529 11:56:00.088171 142602 solver.cpp:218] Iteration 37300 (0.777097 iter/s, 128.684s/100 iters), loss = 0.310348
I0529 11:56:00.088459 142602 solver.cpp:237]     Train net output #0: loss = 0.310348 (* 1 = 0.310348 loss)
I0529 11:56:00.088472 142602 sgd_solver.cpp:105] Iteration 37300, lr = 0.008135
I0529 11:58:08.804404 142602 solver.cpp:218] Iteration 37400 (0.776923 iter/s, 128.713s/100 iters), loss = 0.297437
I0529 11:58:08.804545 142602 solver.cpp:237]     Train net output #0: loss = 0.297437 (* 1 = 0.297437 loss)
I0529 11:58:08.804558 142602 sgd_solver.cpp:105] Iteration 37400, lr = 0.00813
I0529 12:00:13.813531 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:00:17.455346 142602 solver.cpp:218] Iteration 37500 (0.777317 iter/s, 128.648s/100 iters), loss = 0.356389
I0529 12:00:17.455427 142602 solver.cpp:237]     Train net output #0: loss = 0.356389 (* 1 = 0.356389 loss)
I0529 12:00:17.455441 142602 sgd_solver.cpp:105] Iteration 37500, lr = 0.008125
I0529 12:02:26.176192 142602 solver.cpp:218] Iteration 37600 (0.776895 iter/s, 128.718s/100 iters), loss = 0.436307
I0529 12:02:26.176398 142602 solver.cpp:237]     Train net output #0: loss = 0.436308 (* 1 = 0.436308 loss)
I0529 12:02:26.176419 142602 sgd_solver.cpp:105] Iteration 37600, lr = 0.00812
I0529 12:04:34.878229 142602 solver.cpp:218] Iteration 37700 (0.777009 iter/s, 128.699s/100 iters), loss = 0.406435
I0529 12:04:34.878435 142602 solver.cpp:237]     Train net output #0: loss = 0.406435 (* 1 = 0.406435 loss)
I0529 12:04:34.878458 142602 sgd_solver.cpp:105] Iteration 37700, lr = 0.008115
I0529 12:06:43.557768 142602 solver.cpp:218] Iteration 37800 (0.777144 iter/s, 128.676s/100 iters), loss = 0.39745
I0529 12:06:43.558101 142602 solver.cpp:237]     Train net output #0: loss = 0.39745 (* 1 = 0.39745 loss)
I0529 12:06:43.558132 142602 sgd_solver.cpp:105] Iteration 37800, lr = 0.00811
I0529 12:08:37.026302 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:08:52.259706 142602 solver.cpp:218] Iteration 37900 (0.77701 iter/s, 128.699s/100 iters), loss = 0.294068
I0529 12:08:52.259805 142602 solver.cpp:237]     Train net output #0: loss = 0.294068 (* 1 = 0.294068 loss)
I0529 12:08:52.259821 142602 sgd_solver.cpp:105] Iteration 37900, lr = 0.008105
I0529 12:10:59.694849 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_38000.caffemodel
I0529 12:11:00.216001 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_38000.solverstate
I0529 12:11:00.274777 142602 solver.cpp:330] Iteration 38000, Testing net (#0)
I0529 12:11:06.888707 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:11:43.335800 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:12:14.950369 142602 solver.cpp:397]     Test net output #0: accuracy = 0.3712
I0529 12:12:14.950562 142602 solver.cpp:397]     Test net output #1: loss = 3.99265 (* 1 = 3.99265 loss)
I0529 12:12:16.238422 142602 solver.cpp:218] Iteration 38000 (0.490259 iter/s, 203.974s/100 iters), loss = 0.298281
I0529 12:12:16.238514 142602 solver.cpp:237]     Train net output #0: loss = 0.298281 (* 1 = 0.298281 loss)
I0529 12:12:16.238531 142602 sgd_solver.cpp:105] Iteration 38000, lr = 0.0081
I0529 12:14:24.898015 142602 solver.cpp:218] Iteration 38100 (0.777264 iter/s, 128.656s/100 iters), loss = 0.41824
I0529 12:14:24.898169 142602 solver.cpp:237]     Train net output #0: loss = 0.418241 (* 1 = 0.418241 loss)
I0529 12:14:24.898192 142602 sgd_solver.cpp:105] Iteration 38100, lr = 0.008095
I0529 12:16:33.532714 142602 solver.cpp:218] Iteration 38200 (0.777414 iter/s, 128.632s/100 iters), loss = 0.314544
I0529 12:16:33.532865 142602 solver.cpp:237]     Train net output #0: loss = 0.314544 (* 1 = 0.314544 loss)
I0529 12:16:33.532878 142602 sgd_solver.cpp:105] Iteration 38200, lr = 0.00809
I0529 12:18:14.121568 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:18:42.164109 142602 solver.cpp:218] Iteration 38300 (0.777434 iter/s, 128.628s/100 iters), loss = 0.289247
I0529 12:18:42.164191 142602 solver.cpp:237]     Train net output #0: loss = 0.289247 (* 1 = 0.289247 loss)
I0529 12:18:42.164206 142602 sgd_solver.cpp:105] Iteration 38300, lr = 0.008085
I0529 12:20:50.813449 142602 solver.cpp:218] Iteration 38400 (0.777325 iter/s, 128.646s/100 iters), loss = 0.339703
I0529 12:20:50.813632 142602 solver.cpp:237]     Train net output #0: loss = 0.339703 (* 1 = 0.339703 loss)
I0529 12:20:50.813644 142602 sgd_solver.cpp:105] Iteration 38400, lr = 0.00808
I0529 12:22:59.477732 142602 solver.cpp:218] Iteration 38500 (0.777236 iter/s, 128.661s/100 iters), loss = 0.201578
I0529 12:22:59.477908 142602 solver.cpp:237]     Train net output #0: loss = 0.201578 (* 1 = 0.201578 loss)
I0529 12:22:59.477944 142602 sgd_solver.cpp:105] Iteration 38500, lr = 0.008075
I0529 12:25:08.145349 142602 solver.cpp:218] Iteration 38600 (0.777215 iter/s, 128.665s/100 iters), loss = 0.332412
I0529 12:25:08.145606 142602 solver.cpp:237]     Train net output #0: loss = 0.332412 (* 1 = 0.332412 loss)
I0529 12:25:08.145629 142602 sgd_solver.cpp:105] Iteration 38600, lr = 0.00807
I0529 12:26:37.126718 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:27:16.788298 142602 solver.cpp:218] Iteration 38700 (0.777365 iter/s, 128.64s/100 iters), loss = 0.340309
I0529 12:27:16.788592 142602 solver.cpp:237]     Train net output #0: loss = 0.34031 (* 1 = 0.34031 loss)
I0529 12:27:16.788607 142602 sgd_solver.cpp:105] Iteration 38700, lr = 0.008065
I0529 12:29:25.414425 142602 solver.cpp:218] Iteration 38800 (0.777467 iter/s, 128.623s/100 iters), loss = 0.215448
I0529 12:29:25.414697 142602 solver.cpp:237]     Train net output #0: loss = 0.215448 (* 1 = 0.215448 loss)
I0529 12:29:25.414732 142602 sgd_solver.cpp:105] Iteration 38800, lr = 0.00806
I0529 12:31:34.029348 142602 solver.cpp:218] Iteration 38900 (0.777534 iter/s, 128.612s/100 iters), loss = 0.344688
I0529 12:31:34.029609 142602 solver.cpp:237]     Train net output #0: loss = 0.344688 (* 1 = 0.344688 loss)
I0529 12:31:34.029624 142602 sgd_solver.cpp:105] Iteration 38900, lr = 0.008055
I0529 12:33:41.344238 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_39000.caffemodel
I0529 12:33:41.751960 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_39000.solverstate
I0529 12:33:41.810113 142602 solver.cpp:330] Iteration 39000, Testing net (#0)
I0529 12:33:46.639004 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:34:23.066259 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:34:56.334949 142602 solver.cpp:397]     Test net output #0: accuracy = 0.46605
I0529 12:34:56.335119 142602 solver.cpp:397]     Test net output #1: loss = 2.70745 (* 1 = 2.70745 loss)
I0529 12:34:57.615154 142602 solver.cpp:218] Iteration 39000 (0.491205 iter/s, 203.581s/100 iters), loss = 0.340572
I0529 12:34:57.615226 142602 solver.cpp:237]     Train net output #0: loss = 0.340572 (* 1 = 0.340572 loss)
I0529 12:34:57.615239 142602 sgd_solver.cpp:105] Iteration 39000, lr = 0.00805
I0529 12:36:13.744412 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:37:06.207387 142602 solver.cpp:218] Iteration 39100 (0.77767 iter/s, 128.589s/100 iters), loss = 0.245752
I0529 12:37:06.207578 142602 solver.cpp:237]     Train net output #0: loss = 0.245752 (* 1 = 0.245752 loss)
I0529 12:37:06.207605 142602 sgd_solver.cpp:105] Iteration 39100, lr = 0.008045
I0529 12:39:14.779115 142602 solver.cpp:218] Iteration 39200 (0.777795 iter/s, 128.569s/100 iters), loss = 0.413204
I0529 12:39:14.779343 142602 solver.cpp:237]     Train net output #0: loss = 0.413204 (* 1 = 0.413204 loss)
I0529 12:39:14.779368 142602 sgd_solver.cpp:105] Iteration 39200, lr = 0.00804
I0529 12:41:23.342983 142602 solver.cpp:218] Iteration 39300 (0.777843 iter/s, 128.561s/100 iters), loss = 0.347789
I0529 12:41:23.343219 142602 solver.cpp:237]     Train net output #0: loss = 0.347789 (* 1 = 0.347789 loss)
I0529 12:41:23.343233 142602 sgd_solver.cpp:105] Iteration 39300, lr = 0.008035
I0529 12:43:31.896814 142602 solver.cpp:218] Iteration 39400 (0.777904 iter/s, 128.551s/100 iters), loss = 0.268624
I0529 12:43:31.897068 142602 solver.cpp:237]     Train net output #0: loss = 0.268624 (* 1 = 0.268624 loss)
I0529 12:43:31.897094 142602 sgd_solver.cpp:105] Iteration 39400, lr = 0.00803
I0529 12:44:36.426203 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:45:40.426081 142602 solver.cpp:218] Iteration 39500 (0.778053 iter/s, 128.526s/100 iters), loss = 0.245716
I0529 12:45:40.426295 142602 solver.cpp:237]     Train net output #0: loss = 0.245716 (* 1 = 0.245716 loss)
I0529 12:45:40.426311 142602 sgd_solver.cpp:105] Iteration 39500, lr = 0.008025
I0529 12:47:48.977133 142602 solver.cpp:218] Iteration 39600 (0.777921 iter/s, 128.548s/100 iters), loss = 0.469126
I0529 12:47:48.977356 142602 solver.cpp:237]     Train net output #0: loss = 0.469126 (* 1 = 0.469126 loss)
I0529 12:47:48.977382 142602 sgd_solver.cpp:105] Iteration 39600, lr = 0.00802
I0529 12:49:57.493206 142602 solver.cpp:218] Iteration 39700 (0.778132 iter/s, 128.513s/100 iters), loss = 0.405609
I0529 12:49:57.493504 142602 solver.cpp:237]     Train net output #0: loss = 0.405609 (* 1 = 0.405609 loss)
I0529 12:49:57.493516 142602 sgd_solver.cpp:105] Iteration 39700, lr = 0.008015
I0529 12:52:06.029927 142602 solver.cpp:218] Iteration 39800 (0.778008 iter/s, 128.533s/100 iters), loss = 0.300093
I0529 12:52:06.030184 142602 solver.cpp:237]     Train net output #0: loss = 0.300093 (* 1 = 0.300093 loss)
I0529 12:52:06.030197 142602 sgd_solver.cpp:105] Iteration 39800, lr = 0.00801
I0529 12:52:58.965314 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:54:14.543517 142602 solver.cpp:218] Iteration 39900 (0.778147 iter/s, 128.51s/100 iters), loss = 0.261008
I0529 12:54:14.543762 142602 solver.cpp:237]     Train net output #0: loss = 0.261008 (* 1 = 0.261008 loss)
I0529 12:54:14.543778 142602 sgd_solver.cpp:105] Iteration 39900, lr = 0.008005
I0529 12:56:21.760916 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_40000.caffemodel
I0529 12:56:22.239006 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_40000.solverstate
I0529 12:56:22.296964 142602 solver.cpp:330] Iteration 40000, Testing net (#0)
I0529 12:56:25.407781 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:57:01.824925 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:57:36.800786 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4758
I0529 12:57:36.800961 142602 solver.cpp:397]     Test net output #1: loss = 2.70936 (* 1 = 2.70936 loss)
I0529 12:57:38.080824 142602 solver.cpp:218] Iteration 40000 (0.491322 iter/s, 203.532s/100 iters), loss = 0.327443
I0529 12:57:38.080895 142602 solver.cpp:237]     Train net output #0: loss = 0.327443 (* 1 = 0.327443 loss)
I0529 12:57:38.080909 142602 sgd_solver.cpp:105] Iteration 40000, lr = 0.008
I0529 12:59:46.571851 142602 solver.cpp:218] Iteration 40100 (0.778283 iter/s, 128.488s/100 iters), loss = 0.255396
I0529 12:59:46.572146 142602 solver.cpp:237]     Train net output #0: loss = 0.255396 (* 1 = 0.255396 loss)
I0529 12:59:46.572161 142602 sgd_solver.cpp:105] Iteration 40100, lr = 0.007995
I0529 13:01:55.063537 142602 solver.cpp:218] Iteration 40200 (0.77828 iter/s, 128.488s/100 iters), loss = 0.302022
I0529 13:01:55.063714 142602 solver.cpp:237]     Train net output #0: loss = 0.302022 (* 1 = 0.302022 loss)
I0529 13:01:55.063752 142602 sgd_solver.cpp:105] Iteration 40200, lr = 0.00799
I0529 13:02:35.142724 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:04:03.585084 142602 solver.cpp:218] Iteration 40300 (0.778099 iter/s, 128.518s/100 iters), loss = 0.471127
I0529 13:04:03.585250 142602 solver.cpp:237]     Train net output #0: loss = 0.471127 (* 1 = 0.471127 loss)
I0529 13:04:03.585264 142602 sgd_solver.cpp:105] Iteration 40300, lr = 0.007985
I0529 13:06:12.080253 142602 solver.cpp:218] Iteration 40400 (0.778259 iter/s, 128.492s/100 iters), loss = 0.336869
I0529 13:06:12.080512 142602 solver.cpp:237]     Train net output #0: loss = 0.336869 (* 1 = 0.336869 loss)
I0529 13:06:12.080526 142602 sgd_solver.cpp:105] Iteration 40400, lr = 0.00798
I0529 13:08:20.554584 142602 solver.cpp:218] Iteration 40500 (0.778385 iter/s, 128.471s/100 iters), loss = 0.332364
I0529 13:08:20.554811 142602 solver.cpp:237]     Train net output #0: loss = 0.332364 (* 1 = 0.332364 loss)
I0529 13:08:20.554847 142602 sgd_solver.cpp:105] Iteration 40500, lr = 0.007975
I0529 13:10:29.005398 142602 solver.cpp:218] Iteration 40600 (0.778528 iter/s, 128.448s/100 iters), loss = 0.200534
I0529 13:10:29.005637 142602 solver.cpp:237]     Train net output #0: loss = 0.200534 (* 1 = 0.200534 loss)
I0529 13:10:29.005651 142602 sgd_solver.cpp:105] Iteration 40600, lr = 0.00797
I0529 13:10:57.536016 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:12:37.518035 142602 solver.cpp:218] Iteration 40700 (0.778153 iter/s, 128.509s/100 iters), loss = 0.32301
I0529 13:12:37.518283 142602 solver.cpp:237]     Train net output #0: loss = 0.32301 (* 1 = 0.32301 loss)
I0529 13:12:37.518309 142602 sgd_solver.cpp:105] Iteration 40700, lr = 0.007965
I0529 13:14:45.999150 142602 solver.cpp:218] Iteration 40800 (0.778344 iter/s, 128.478s/100 iters), loss = 0.402393
I0529 13:14:45.999397 142602 solver.cpp:237]     Train net output #0: loss = 0.402393 (* 1 = 0.402393 loss)
I0529 13:14:45.999420 142602 sgd_solver.cpp:105] Iteration 40800, lr = 0.00796
I0529 13:16:54.505050 142602 solver.cpp:218] Iteration 40900 (0.778194 iter/s, 128.503s/100 iters), loss = 0.346669
I0529 13:16:54.505255 142602 solver.cpp:237]     Train net output #0: loss = 0.346669 (* 1 = 0.346669 loss)
I0529 13:16:54.505275 142602 sgd_solver.cpp:105] Iteration 40900, lr = 0.007955
I0529 13:19:01.716609 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_41000.caffemodel
I0529 13:19:02.341147 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_41000.solverstate
I0529 13:19:02.406081 142602 solver.cpp:330] Iteration 41000, Testing net (#0)
I0529 13:19:03.790228 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:19:40.146790 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:20:16.573951 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:20:16.904501 142602 solver.cpp:397]     Test net output #0: accuracy = 0.4024
I0529 13:20:16.904582 142602 solver.cpp:397]     Test net output #1: loss = 2.98491 (* 1 = 2.98491 loss)
I0529 13:20:18.184242 142602 solver.cpp:218] Iteration 41000 (0.49098 iter/s, 203.674s/100 iters), loss = 0.190244
I0529 13:20:18.184306 142602 solver.cpp:237]     Train net output #0: loss = 0.190244 (* 1 = 0.190244 loss)
I0529 13:20:18.184319 142602 sgd_solver.cpp:105] Iteration 41000, lr = 0.00795
I0529 13:20:35.126966 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:22:26.713114 142602 solver.cpp:218] Iteration 41100 (0.778054 iter/s, 128.526s/100 iters), loss = 0.229862
I0529 13:22:26.713325 142602 solver.cpp:237]     Train net output #0: loss = 0.229862 (* 1 = 0.229862 loss)
I0529 13:22:26.713361 142602 sgd_solver.cpp:105] Iteration 41100, lr = 0.007945
I0529 13:24:35.244415 142602 solver.cpp:218] Iteration 41200 (0.77804 iter/s, 128.528s/100 iters), loss = 0.433955
I0529 13:24:35.244647 142602 solver.cpp:237]     Train net output #0: loss = 0.433955 (* 1 = 0.433955 loss)
I0529 13:24:35.244663 142602 sgd_solver.cpp:105] Iteration 41200, lr = 0.00794
I0529 13:26:43.795647 142602 solver.cpp:218] Iteration 41300 (0.77792 iter/s, 128.548s/100 iters), loss = 0.348079
I0529 13:26:43.795908 142602 solver.cpp:237]     Train net output #0: loss = 0.348079 (* 1 = 0.348079 loss)
I0529 13:26:43.795925 142602 sgd_solver.cpp:105] Iteration 41300, lr = 0.007935
I0529 13:28:52.301842 142602 solver.cpp:218] Iteration 41400 (0.778192 iter/s, 128.503s/100 iters), loss = 0.494777
I0529 13:28:52.302059 142602 solver.cpp:237]     Train net output #0: loss = 0.494777 (* 1 = 0.494777 loss)
I0529 13:28:52.302076 142602 sgd_solver.cpp:105] Iteration 41400, lr = 0.00793
I0529 13:28:56.412269 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:31:00.844493 142602 solver.cpp:218] Iteration 41500 (0.777971 iter/s, 128.539s/100 iters), loss = 0.336992
I0529 13:31:00.844712 142602 solver.cpp:237]     Train net output #0: loss = 0.336992 (* 1 = 0.336992 loss)
I0529 13:31:00.844724 142602 sgd_solver.cpp:105] Iteration 41500, lr = 0.007925
I0529 13:33:09.366317 142602 solver.cpp:218] Iteration 41600 (0.778098 iter/s, 128.519s/100 iters), loss = 0.342827
I0529 13:33:09.366628 142602 solver.cpp:237]     Train net output #0: loss = 0.342827 (* 1 = 0.342827 loss)
I0529 13:33:09.366652 142602 sgd_solver.cpp:105] Iteration 41600, lr = 0.00792
I0529 13:35:17.894958 142602 solver.cpp:218] Iteration 41700 (0.778057 iter/s, 128.525s/100 iters), loss = 0.297357
I0529 13:35:17.895234 142602 solver.cpp:237]     Train net output #0: loss = 0.297357 (* 1 = 0.297357 loss)
I0529 13:35:17.895248 142602 sgd_solver.cpp:105] Iteration 41700, lr = 0.007915
I0529 13:37:18.954969 142606 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:37:26.457746 142602 solver.cpp:218] Iteration 41800 (0.77785 iter/s, 128.56s/100 iters), loss = 0.230746
I0529 13:37:26.457831 142602 solver.cpp:237]     Train net output #0: loss = 0.230746 (* 1 = 0.230746 loss)
I0529 13:37:26.457846 142602 sgd_solver.cpp:105] Iteration 41800, lr = 0.00791
I0529 13:39:35.059550 142602 solver.cpp:218] Iteration 41900 (0.777613 iter/s, 128.599s/100 iters), loss = 0.215895
I0529 13:39:35.059744 142602 solver.cpp:237]     Train net output #0: loss = 0.215895 (* 1 = 0.215895 loss)
I0529 13:39:35.059762 142602 sgd_solver.cpp:105] Iteration 41900, lr = 0.007905
I0529 13:41:42.417723 142602 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_42000.caffemodel
I0529 13:41:42.904364 142602 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_42000.solverstate
I0529 13:41:42.965790 142602 solver.cpp:330] Iteration 42000, Testing net (#0)
I0529 13:42:19.058789 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:42:55.476807 142607 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:42:57.592054 142602 solver.cpp:397]     Test net output #0: accuracy = 0.46065
I0529 13:42:57.592152 142602 solver.cpp:397]     Test net output #1: loss = 2.43984 (* 1 = 2.43984 loss)
I0529 13:42:58.873464 142602 solver.cpp:218] Iteration 42000 (0.490655 iter/s, 203.809s/100 iters), loss = 0.296009
I0529 13:42:58.873576 142602 solver.cpp:237]     Train net output #0: loss = 0.296009 (* 1 = 0.296009 loss)
I0529 13:42:58.873606 142602 sgd_solver.cpp:105] Iteration 42000, lr = 0.0079
