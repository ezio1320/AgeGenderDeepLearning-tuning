I0524 17:57:34.782551   808 caffe.cpp:218] Using GPUs 0
I0524 17:57:34.835691   808 caffe.cpp:223] GPU 0: GeForce GTX 1060 6GB
I0524 17:57:35.162832   808 solver.cpp:44] Initializing solver from parameters: 
base_lr: 0.05
display: 100
max_iter: 50000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0005
snapshot: 1000
snapshot_prefix: "resnet-imagenet"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "18_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0524 17:57:35.163007   808 solver.cpp:87] Creating training net from net file: 18_train_val_test_fold_is_0.prototxt
I0524 17:57:35.163627   808 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0524 17:57:35.163661   808 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer acc/top-1
I0524 17:57:35.164003   808 net.cpp:51] Initializing net from parameters: 
name: "ResNet-18"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto"
  }
  data_param {
    source: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn_conv1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale_conv1"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "res2a_branch1"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch1"
  type: "BatchNorm"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale2a_branch1"
  type: "Scale"
  bottom: "res2a_branch1"
  top: "res2a_branch1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a"
  type: "Convolution"
  bottom: "pool1"
  top: "res2a_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch2a"
  type: "BatchNorm"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale2a_branch2a"
  type: "Scale"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a_branch2a_relu"
  type: "ReLU"
  bottom: "res2a_branch2a"
  top: "res2a_branch2a"
}
layer {
  name: "res2a_branch2b"
  type: "Convolution"
  bottom: "res2a_branch2a"
  top: "res2a_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2a_branch2b"
  type: "BatchNorm"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale2a_branch2b"
  type: "Scale"
  bottom: "res2a_branch2b"
  top: "res2a_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2a"
  type: "Eltwise"
  bottom: "res2a_branch1"
  bottom: "res2a_branch2b"
  top: "res2a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2a_relu"
  type: "ReLU"
  bottom: "res2a"
  top: "res2a"
}
layer {
  name: "res2b_branch2a"
  type: "Convolution"
  bottom: "res2a"
  top: "res2b_branch2a"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2b_branch2a"
  type: "BatchNorm"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale2b_branch2a"
  type: "Scale"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b_branch2a_relu"
  type: "ReLU"
  bottom: "res2b_branch2a"
  top: "res2b_branch2a"
}
layer {
  name: "res2b_branch2b"
  type: "Convolution"
  bottom: "res2b_branch2a"
  top: "res2b_branch2b"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2b_branch2b"
  type: "BatchNorm"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale2b_branch2b"
  type: "Scale"
  bottom: "res2b_branch2b"
  top: "res2b_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res2b"
  type: "Eltwise"
  bottom: "res2a"
  bottom: "res2b_branch2b"
  top: "res2b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res2b_relu"
  type: "ReLU"
  bottom: "res2b"
  top: "res2b"
}
layer {
  name: "res3a_branch1"
  type: "Convolution"
  bottom: "res2b"
  top: "res3a_branch1"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch1"
  type: "BatchNorm"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale3a_branch1"
  type: "Scale"
  bottom: "res3a_branch1"
  top: "res3a_branch1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a"
  type: "Convolution"
  bottom: "res2b"
  top: "res3a_branch2a"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch2a"
  type: "BatchNorm"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale3a_branch2a"
  type: "Scale"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a_branch2a_relu"
  type: "ReLU"
  bottom: "res3a_branch2a"
  top: "res3a_branch2a"
}
layer {
  name: "res3a_branch2b"
  type: "Convolution"
  bottom: "res3a_branch2a"
  top: "res3a_branch2b"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3a_branch2b"
  type: "BatchNorm"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale3a_branch2b"
  type: "Scale"
  bottom: "res3a_branch2b"
  top: "res3a_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3a"
  type: "Eltwise"
  bottom: "res3a_branch1"
  bottom: "res3a_branch2b"
  top: "res3a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3a_relu"
  type: "ReLU"
  bottom: "res3a"
  top: "res3a"
}
layer {
  name: "res3b_branch2a"
  type: "Convolution"
  bottom: "res3a"
  top: "res3b_branch2a"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3b_branch2a"
  type: "BatchNorm"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale3b_branch2a"
  type: "Scale"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b_branch2a_relu"
  type: "ReLU"
  bottom: "res3b_branch2a"
  top: "res3b_branch2a"
}
layer {
  name: "res3b_branch2b"
  type: "Convolution"
  bottom: "res3b_branch2a"
  top: "res3b_branch2b"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3b_branch2b"
  type: "BatchNorm"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale3b_branch2b"
  type: "Scale"
  bottom: "res3b_branch2b"
  top: "res3b_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res3b"
  type: "Eltwise"
  bottom: "res3a"
  bottom: "res3b_branch2b"
  top: "res3b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res3b_relu"
  type: "ReLU"
  bottom: "res3b"
  top: "res3b"
}
layer {
  name: "res4a_branch1"
  type: "Convolution"
  bottom: "res3b"
  top: "res4a_branch1"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch1"
  type: "BatchNorm"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale4a_branch1"
  type: "Scale"
  bottom: "res4a_branch1"
  top: "res4a_branch1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a"
  type: "Convolution"
  bottom: "res3b"
  top: "res4a_branch2a"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch2a"
  type: "BatchNorm"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale4a_branch2a"
  type: "Scale"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a_branch2a_relu"
  type: "ReLU"
  bottom: "res4a_branch2a"
  top: "res4a_branch2a"
}
layer {
  name: "res4a_branch2b"
  type: "Convolution"
  bottom: "res4a_branch2a"
  top: "res4a_branch2b"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4a_branch2b"
  type: "BatchNorm"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale4a_branch2b"
  type: "Scale"
  bottom: "res4a_branch2b"
  top: "res4a_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4a"
  type: "Eltwise"
  bottom: "res4a_branch1"
  bottom: "res4a_branch2b"
  top: "res4a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4a_relu"
  type: "ReLU"
  bottom: "res4a"
  top: "res4a"
}
layer {
  name: "res4b_branch2a"
  type: "Convolution"
  bottom: "res4a"
  top: "res4b_branch2a"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4b_branch2a"
  type: "BatchNorm"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale4b_branch2a"
  type: "Scale"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b_branch2a_relu"
  type: "ReLU"
  bottom: "res4b_branch2a"
  top: "res4b_branch2a"
}
layer {
  name: "res4b_branch2b"
  type: "Convolution"
  bottom: "res4b_branch2a"
  top: "res4b_branch2b"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4b_branch2b"
  type: "BatchNorm"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale4b_branch2b"
  type: "Scale"
  bottom: "res4b_branch2b"
  top: "res4b_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res4b"
  type: "Eltwise"
  bottom: "res4a"
  bottom: "res4b_branch2b"
  top: "res4b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res4b_relu"
  type: "ReLU"
  bottom: "res4b"
  top: "res4b"
}
layer {
  name: "res5a_branch1"
  type: "Convolution"
  bottom: "res4b"
  top: "res5a_branch1"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5a_branch1"
  type: "BatchNorm"
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale5a_branch1"
  type: "Scale"
  bottom: "res5a_branch1"
  top: "res5a_branch1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a_branch2a"
  type: "Convolution"
  bottom: "res4b"
  top: "res5a_branch2a"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5a_branch2a"
  type: "BatchNorm"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale5a_branch2a"
  type: "Scale"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a_branch2a_relu"
  type: "ReLU"
  bottom: "res5a_branch2a"
  top: "res5a_branch2a"
}
layer {
  name: "res5a_branch2b"
  type: "Convolution"
  bottom: "res5a_branch2a"
  top: "res5a_branch2b"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5a_branch2b"
  type: "BatchNorm"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale5a_branch2b"
  type: "Scale"
  bottom: "res5a_branch2b"
  top: "res5a_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5a"
  type: "Eltwise"
  bottom: "res5a_branch1"
  bottom: "res5a_branch2b"
  top: "res5a"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5a_relu"
  type: "ReLU"
  bottom: "res5a"
  top: "res5a"
}
layer {
  name: "res5b_branch2a"
  type: "Convolution"
  bottom: "res5a"
  top: "res5b_branch2a"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5b_branch2a"
  type: "BatchNorm"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale5b_branch2a"
  type: "Scale"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5b_branch2a_relu"
  type: "ReLU"
  bottom: "res5b_branch2a"
  top: "res5b_branch2a"
}
layer {
  name: "res5b_branch2b"
  type: "Convolution"
  bottom: "res5b_branch2a"
  top: "res5b_branch2b"
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5b_branch2b"
  type: "BatchNorm"
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  batch_norm_param {
    moving_average_fraction: 0.9
  }
}
layer {
  name: "scale5b_branch2b"
  type: "Scale"
  bottom: "res5b_branch2b"
  top: "res5b_branch2b"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "res5b"
  type: "Eltwise"
  bottom: "res5a"
  bottom: "res5b_branch2b"
  top: "res5b"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "res5b_relu"
  type: "ReLU"
  bottom: "res5b"
  top: "res5b"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "res5b"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 8
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc8"
  bottom: "label"
  top: "loss"
}
I0524 17:57:35.164286   808 layer_factory.hpp:77] Creating layer data
I0524 17:57:35.164384   808 db_lmdb.cpp:35] Opened lmdb /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_train_lmdb
I0524 17:57:35.164414   808 net.cpp:84] Creating Layer data
I0524 17:57:35.164423   808 net.cpp:380] data -> data
I0524 17:57:35.164444   808 net.cpp:380] data -> label
I0524 17:57:35.164456   808 data_transformer.cpp:25] Loading mean file from: /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto
I0524 17:57:35.167209   808 data_layer.cpp:45] output data size: 50,3,224,224
I0524 17:57:35.228636   808 net.cpp:122] Setting up data
I0524 17:57:35.228665   808 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0524 17:57:35.228672   808 net.cpp:129] Top shape: 50 (50)
I0524 17:57:35.228674   808 net.cpp:137] Memory required for data: 30105800
I0524 17:57:35.228695   808 layer_factory.hpp:77] Creating layer conv1
I0524 17:57:35.228718   808 net.cpp:84] Creating Layer conv1
I0524 17:57:35.228725   808 net.cpp:406] conv1 <- data
I0524 17:57:35.228739   808 net.cpp:380] conv1 -> conv1
I0524 17:57:35.473549   808 net.cpp:122] Setting up conv1
I0524 17:57:35.473582   808 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0524 17:57:35.473587   808 net.cpp:137] Memory required for data: 190669000
I0524 17:57:35.473608   808 layer_factory.hpp:77] Creating layer bn_conv1
I0524 17:57:35.473633   808 net.cpp:84] Creating Layer bn_conv1
I0524 17:57:35.473637   808 net.cpp:406] bn_conv1 <- conv1
I0524 17:57:35.473644   808 net.cpp:367] bn_conv1 -> conv1 (in-place)
I0524 17:57:35.473817   808 net.cpp:122] Setting up bn_conv1
I0524 17:57:35.473826   808 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0524 17:57:35.473830   808 net.cpp:137] Memory required for data: 351232200
I0524 17:57:35.473840   808 layer_factory.hpp:77] Creating layer scale_conv1
I0524 17:57:35.473847   808 net.cpp:84] Creating Layer scale_conv1
I0524 17:57:35.473850   808 net.cpp:406] scale_conv1 <- conv1
I0524 17:57:35.473855   808 net.cpp:367] scale_conv1 -> conv1 (in-place)
I0524 17:57:35.473906   808 layer_factory.hpp:77] Creating layer scale_conv1
I0524 17:57:35.474022   808 net.cpp:122] Setting up scale_conv1
I0524 17:57:35.474031   808 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0524 17:57:35.474035   808 net.cpp:137] Memory required for data: 511795400
I0524 17:57:35.474042   808 layer_factory.hpp:77] Creating layer conv1_relu
I0524 17:57:35.474050   808 net.cpp:84] Creating Layer conv1_relu
I0524 17:57:35.474052   808 net.cpp:406] conv1_relu <- conv1
I0524 17:57:35.474057   808 net.cpp:367] conv1_relu -> conv1 (in-place)
I0524 17:57:35.474215   808 net.cpp:122] Setting up conv1_relu
I0524 17:57:35.474225   808 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0524 17:57:35.474227   808 net.cpp:137] Memory required for data: 672358600
I0524 17:57:35.474231   808 layer_factory.hpp:77] Creating layer pool1
I0524 17:57:35.474236   808 net.cpp:84] Creating Layer pool1
I0524 17:57:35.474239   808 net.cpp:406] pool1 <- conv1
I0524 17:57:35.474244   808 net.cpp:380] pool1 -> pool1
I0524 17:57:35.474298   808 net.cpp:122] Setting up pool1
I0524 17:57:35.474306   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.474309   808 net.cpp:137] Memory required for data: 712499400
I0524 17:57:35.474313   808 layer_factory.hpp:77] Creating layer pool1_pool1_0_split
I0524 17:57:35.474318   808 net.cpp:84] Creating Layer pool1_pool1_0_split
I0524 17:57:35.474320   808 net.cpp:406] pool1_pool1_0_split <- pool1
I0524 17:57:35.474325   808 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_0
I0524 17:57:35.474333   808 net.cpp:380] pool1_pool1_0_split -> pool1_pool1_0_split_1
I0524 17:57:35.474359   808 net.cpp:122] Setting up pool1_pool1_0_split
I0524 17:57:35.474366   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.474386   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.474390   808 net.cpp:137] Memory required for data: 792781000
I0524 17:57:35.474393   808 layer_factory.hpp:77] Creating layer res2a_branch1
I0524 17:57:35.474403   808 net.cpp:84] Creating Layer res2a_branch1
I0524 17:57:35.474406   808 net.cpp:406] res2a_branch1 <- pool1_pool1_0_split_0
I0524 17:57:35.474412   808 net.cpp:380] res2a_branch1 -> res2a_branch1
I0524 17:57:35.476001   808 net.cpp:122] Setting up res2a_branch1
I0524 17:57:35.476013   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.476029   808 net.cpp:137] Memory required for data: 832921800
I0524 17:57:35.476035   808 layer_factory.hpp:77] Creating layer bn2a_branch1
I0524 17:57:35.476044   808 net.cpp:84] Creating Layer bn2a_branch1
I0524 17:57:35.476049   808 net.cpp:406] bn2a_branch1 <- res2a_branch1
I0524 17:57:35.476054   808 net.cpp:367] bn2a_branch1 -> res2a_branch1 (in-place)
I0524 17:57:35.476203   808 net.cpp:122] Setting up bn2a_branch1
I0524 17:57:35.476212   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.476227   808 net.cpp:137] Memory required for data: 873062600
I0524 17:57:35.476236   808 layer_factory.hpp:77] Creating layer scale2a_branch1
I0524 17:57:35.476243   808 net.cpp:84] Creating Layer scale2a_branch1
I0524 17:57:35.476248   808 net.cpp:406] scale2a_branch1 <- res2a_branch1
I0524 17:57:35.476253   808 net.cpp:367] scale2a_branch1 -> res2a_branch1 (in-place)
I0524 17:57:35.476285   808 layer_factory.hpp:77] Creating layer scale2a_branch1
I0524 17:57:35.476372   808 net.cpp:122] Setting up scale2a_branch1
I0524 17:57:35.476382   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.476385   808 net.cpp:137] Memory required for data: 913203400
I0524 17:57:35.476392   808 layer_factory.hpp:77] Creating layer res2a_branch2a
I0524 17:57:35.476399   808 net.cpp:84] Creating Layer res2a_branch2a
I0524 17:57:35.476403   808 net.cpp:406] res2a_branch2a <- pool1_pool1_0_split_1
I0524 17:57:35.476409   808 net.cpp:380] res2a_branch2a -> res2a_branch2a
I0524 17:57:35.478343   808 net.cpp:122] Setting up res2a_branch2a
I0524 17:57:35.478358   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.478363   808 net.cpp:137] Memory required for data: 953344200
I0524 17:57:35.478368   808 layer_factory.hpp:77] Creating layer bn2a_branch2a
I0524 17:57:35.478376   808 net.cpp:84] Creating Layer bn2a_branch2a
I0524 17:57:35.478380   808 net.cpp:406] bn2a_branch2a <- res2a_branch2a
I0524 17:57:35.478386   808 net.cpp:367] bn2a_branch2a -> res2a_branch2a (in-place)
I0524 17:57:35.478535   808 net.cpp:122] Setting up bn2a_branch2a
I0524 17:57:35.478544   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.478549   808 net.cpp:137] Memory required for data: 993485000
I0524 17:57:35.478556   808 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0524 17:57:35.478564   808 net.cpp:84] Creating Layer scale2a_branch2a
I0524 17:57:35.478567   808 net.cpp:406] scale2a_branch2a <- res2a_branch2a
I0524 17:57:35.478572   808 net.cpp:367] scale2a_branch2a -> res2a_branch2a (in-place)
I0524 17:57:35.478605   808 layer_factory.hpp:77] Creating layer scale2a_branch2a
I0524 17:57:35.478695   808 net.cpp:122] Setting up scale2a_branch2a
I0524 17:57:35.478704   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.478708   808 net.cpp:137] Memory required for data: 1033625800
I0524 17:57:35.478716   808 layer_factory.hpp:77] Creating layer res2a_branch2a_relu
I0524 17:57:35.478724   808 net.cpp:84] Creating Layer res2a_branch2a_relu
I0524 17:57:35.478727   808 net.cpp:406] res2a_branch2a_relu <- res2a_branch2a
I0524 17:57:35.478732   808 net.cpp:367] res2a_branch2a_relu -> res2a_branch2a (in-place)
I0524 17:57:35.478863   808 net.cpp:122] Setting up res2a_branch2a_relu
I0524 17:57:35.478873   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.478876   808 net.cpp:137] Memory required for data: 1073766600
I0524 17:57:35.478880   808 layer_factory.hpp:77] Creating layer res2a_branch2b
I0524 17:57:35.478899   808 net.cpp:84] Creating Layer res2a_branch2b
I0524 17:57:35.478904   808 net.cpp:406] res2a_branch2b <- res2a_branch2a
I0524 17:57:35.478910   808 net.cpp:380] res2a_branch2b -> res2a_branch2b
I0524 17:57:35.480165   808 net.cpp:122] Setting up res2a_branch2b
I0524 17:57:35.480176   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.480181   808 net.cpp:137] Memory required for data: 1113907400
I0524 17:57:35.480186   808 layer_factory.hpp:77] Creating layer bn2a_branch2b
I0524 17:57:35.480193   808 net.cpp:84] Creating Layer bn2a_branch2b
I0524 17:57:35.480197   808 net.cpp:406] bn2a_branch2b <- res2a_branch2b
I0524 17:57:35.480202   808 net.cpp:367] bn2a_branch2b -> res2a_branch2b (in-place)
I0524 17:57:35.480348   808 net.cpp:122] Setting up bn2a_branch2b
I0524 17:57:35.480356   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.480360   808 net.cpp:137] Memory required for data: 1154048200
I0524 17:57:35.480368   808 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0524 17:57:35.480376   808 net.cpp:84] Creating Layer scale2a_branch2b
I0524 17:57:35.480381   808 net.cpp:406] scale2a_branch2b <- res2a_branch2b
I0524 17:57:35.480386   808 net.cpp:367] scale2a_branch2b -> res2a_branch2b (in-place)
I0524 17:57:35.480419   808 layer_factory.hpp:77] Creating layer scale2a_branch2b
I0524 17:57:35.480507   808 net.cpp:122] Setting up scale2a_branch2b
I0524 17:57:35.480516   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.480520   808 net.cpp:137] Memory required for data: 1194189000
I0524 17:57:35.480526   808 layer_factory.hpp:77] Creating layer res2a
I0524 17:57:35.480533   808 net.cpp:84] Creating Layer res2a
I0524 17:57:35.480538   808 net.cpp:406] res2a <- res2a_branch1
I0524 17:57:35.480542   808 net.cpp:406] res2a <- res2a_branch2b
I0524 17:57:35.480546   808 net.cpp:380] res2a -> res2a
I0524 17:57:35.480571   808 net.cpp:122] Setting up res2a
I0524 17:57:35.480579   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.480583   808 net.cpp:137] Memory required for data: 1234329800
I0524 17:57:35.480587   808 layer_factory.hpp:77] Creating layer res2a_relu
I0524 17:57:35.480592   808 net.cpp:84] Creating Layer res2a_relu
I0524 17:57:35.480595   808 net.cpp:406] res2a_relu <- res2a
I0524 17:57:35.480600   808 net.cpp:367] res2a_relu -> res2a (in-place)
I0524 17:57:35.481086   808 net.cpp:122] Setting up res2a_relu
I0524 17:57:35.481097   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.481101   808 net.cpp:137] Memory required for data: 1274470600
I0524 17:57:35.481106   808 layer_factory.hpp:77] Creating layer res2a_res2a_relu_0_split
I0524 17:57:35.481112   808 net.cpp:84] Creating Layer res2a_res2a_relu_0_split
I0524 17:57:35.481115   808 net.cpp:406] res2a_res2a_relu_0_split <- res2a
I0524 17:57:35.481120   808 net.cpp:380] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_0
I0524 17:57:35.481128   808 net.cpp:380] res2a_res2a_relu_0_split -> res2a_res2a_relu_0_split_1
I0524 17:57:35.481160   808 net.cpp:122] Setting up res2a_res2a_relu_0_split
I0524 17:57:35.481168   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.481173   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.481176   808 net.cpp:137] Memory required for data: 1354752200
I0524 17:57:35.481179   808 layer_factory.hpp:77] Creating layer res2b_branch2a
I0524 17:57:35.481186   808 net.cpp:84] Creating Layer res2b_branch2a
I0524 17:57:35.481191   808 net.cpp:406] res2b_branch2a <- res2a_res2a_relu_0_split_0
I0524 17:57:35.481196   808 net.cpp:380] res2b_branch2a -> res2b_branch2a
I0524 17:57:35.482130   808 net.cpp:122] Setting up res2b_branch2a
I0524 17:57:35.482141   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.482144   808 net.cpp:137] Memory required for data: 1394893000
I0524 17:57:35.482149   808 layer_factory.hpp:77] Creating layer bn2b_branch2a
I0524 17:57:35.482156   808 net.cpp:84] Creating Layer bn2b_branch2a
I0524 17:57:35.482161   808 net.cpp:406] bn2b_branch2a <- res2b_branch2a
I0524 17:57:35.482178   808 net.cpp:367] bn2b_branch2a -> res2b_branch2a (in-place)
I0524 17:57:35.482334   808 net.cpp:122] Setting up bn2b_branch2a
I0524 17:57:35.482343   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.482347   808 net.cpp:137] Memory required for data: 1435033800
I0524 17:57:35.482354   808 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0524 17:57:35.482362   808 net.cpp:84] Creating Layer scale2b_branch2a
I0524 17:57:35.482367   808 net.cpp:406] scale2b_branch2a <- res2b_branch2a
I0524 17:57:35.482372   808 net.cpp:367] scale2b_branch2a -> res2b_branch2a (in-place)
I0524 17:57:35.482406   808 layer_factory.hpp:77] Creating layer scale2b_branch2a
I0524 17:57:35.482503   808 net.cpp:122] Setting up scale2b_branch2a
I0524 17:57:35.482512   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.482517   808 net.cpp:137] Memory required for data: 1475174600
I0524 17:57:35.482522   808 layer_factory.hpp:77] Creating layer res2b_branch2a_relu
I0524 17:57:35.482529   808 net.cpp:84] Creating Layer res2b_branch2a_relu
I0524 17:57:35.482534   808 net.cpp:406] res2b_branch2a_relu <- res2b_branch2a
I0524 17:57:35.482539   808 net.cpp:367] res2b_branch2a_relu -> res2b_branch2a (in-place)
I0524 17:57:35.483027   808 net.cpp:122] Setting up res2b_branch2a_relu
I0524 17:57:35.483039   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.483042   808 net.cpp:137] Memory required for data: 1515315400
I0524 17:57:35.483047   808 layer_factory.hpp:77] Creating layer res2b_branch2b
I0524 17:57:35.483054   808 net.cpp:84] Creating Layer res2b_branch2b
I0524 17:57:35.483060   808 net.cpp:406] res2b_branch2b <- res2b_branch2a
I0524 17:57:35.483067   808 net.cpp:380] res2b_branch2b -> res2b_branch2b
I0524 17:57:35.484367   808 net.cpp:122] Setting up res2b_branch2b
I0524 17:57:35.484380   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.484385   808 net.cpp:137] Memory required for data: 1555456200
I0524 17:57:35.484390   808 layer_factory.hpp:77] Creating layer bn2b_branch2b
I0524 17:57:35.484397   808 net.cpp:84] Creating Layer bn2b_branch2b
I0524 17:57:35.484402   808 net.cpp:406] bn2b_branch2b <- res2b_branch2b
I0524 17:57:35.484407   808 net.cpp:367] bn2b_branch2b -> res2b_branch2b (in-place)
I0524 17:57:35.484562   808 net.cpp:122] Setting up bn2b_branch2b
I0524 17:57:35.484570   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.484575   808 net.cpp:137] Memory required for data: 1595597000
I0524 17:57:35.484586   808 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0524 17:57:35.484596   808 net.cpp:84] Creating Layer scale2b_branch2b
I0524 17:57:35.484599   808 net.cpp:406] scale2b_branch2b <- res2b_branch2b
I0524 17:57:35.484604   808 net.cpp:367] scale2b_branch2b -> res2b_branch2b (in-place)
I0524 17:57:35.484642   808 layer_factory.hpp:77] Creating layer scale2b_branch2b
I0524 17:57:35.484740   808 net.cpp:122] Setting up scale2b_branch2b
I0524 17:57:35.484750   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.484753   808 net.cpp:137] Memory required for data: 1635737800
I0524 17:57:35.484760   808 layer_factory.hpp:77] Creating layer res2b
I0524 17:57:35.484767   808 net.cpp:84] Creating Layer res2b
I0524 17:57:35.484771   808 net.cpp:406] res2b <- res2a_res2a_relu_0_split_1
I0524 17:57:35.484776   808 net.cpp:406] res2b <- res2b_branch2b
I0524 17:57:35.484782   808 net.cpp:380] res2b -> res2b
I0524 17:57:35.484805   808 net.cpp:122] Setting up res2b
I0524 17:57:35.484813   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.484817   808 net.cpp:137] Memory required for data: 1675878600
I0524 17:57:35.484820   808 layer_factory.hpp:77] Creating layer res2b_relu
I0524 17:57:35.484825   808 net.cpp:84] Creating Layer res2b_relu
I0524 17:57:35.484829   808 net.cpp:406] res2b_relu <- res2b
I0524 17:57:35.484834   808 net.cpp:367] res2b_relu -> res2b (in-place)
I0524 17:57:35.484973   808 net.cpp:122] Setting up res2b_relu
I0524 17:57:35.484984   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.484997   808 net.cpp:137] Memory required for data: 1716019400
I0524 17:57:35.485002   808 layer_factory.hpp:77] Creating layer res2b_res2b_relu_0_split
I0524 17:57:35.485007   808 net.cpp:84] Creating Layer res2b_res2b_relu_0_split
I0524 17:57:35.485010   808 net.cpp:406] res2b_res2b_relu_0_split <- res2b
I0524 17:57:35.485015   808 net.cpp:380] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_0
I0524 17:57:35.485026   808 net.cpp:380] res2b_res2b_relu_0_split -> res2b_res2b_relu_0_split_1
I0524 17:57:35.485064   808 net.cpp:122] Setting up res2b_res2b_relu_0_split
I0524 17:57:35.485072   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.485079   808 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0524 17:57:35.485082   808 net.cpp:137] Memory required for data: 1796301000
I0524 17:57:35.485085   808 layer_factory.hpp:77] Creating layer res3a_branch1
I0524 17:57:35.485095   808 net.cpp:84] Creating Layer res3a_branch1
I0524 17:57:35.485100   808 net.cpp:406] res3a_branch1 <- res2b_res2b_relu_0_split_0
I0524 17:57:35.485105   808 net.cpp:380] res3a_branch1 -> res3a_branch1
I0524 17:57:35.486521   808 net.cpp:122] Setting up res3a_branch1
I0524 17:57:35.486536   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.486539   808 net.cpp:137] Memory required for data: 1816371400
I0524 17:57:35.486544   808 layer_factory.hpp:77] Creating layer bn3a_branch1
I0524 17:57:35.486552   808 net.cpp:84] Creating Layer bn3a_branch1
I0524 17:57:35.486557   808 net.cpp:406] bn3a_branch1 <- res3a_branch1
I0524 17:57:35.486563   808 net.cpp:367] bn3a_branch1 -> res3a_branch1 (in-place)
I0524 17:57:35.487404   808 net.cpp:122] Setting up bn3a_branch1
I0524 17:57:35.487418   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.487421   808 net.cpp:137] Memory required for data: 1836441800
I0524 17:57:35.487431   808 layer_factory.hpp:77] Creating layer scale3a_branch1
I0524 17:57:35.487444   808 net.cpp:84] Creating Layer scale3a_branch1
I0524 17:57:35.487449   808 net.cpp:406] scale3a_branch1 <- res3a_branch1
I0524 17:57:35.487455   808 net.cpp:367] scale3a_branch1 -> res3a_branch1 (in-place)
I0524 17:57:35.487494   808 layer_factory.hpp:77] Creating layer scale3a_branch1
I0524 17:57:35.487587   808 net.cpp:122] Setting up scale3a_branch1
I0524 17:57:35.487596   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.487599   808 net.cpp:137] Memory required for data: 1856512200
I0524 17:57:35.487606   808 layer_factory.hpp:77] Creating layer res3a_branch2a
I0524 17:57:35.487615   808 net.cpp:84] Creating Layer res3a_branch2a
I0524 17:57:35.487620   808 net.cpp:406] res3a_branch2a <- res2b_res2b_relu_0_split_1
I0524 17:57:35.487627   808 net.cpp:380] res3a_branch2a -> res3a_branch2a
I0524 17:57:35.489367   808 net.cpp:122] Setting up res3a_branch2a
I0524 17:57:35.489379   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.489382   808 net.cpp:137] Memory required for data: 1876582600
I0524 17:57:35.489388   808 layer_factory.hpp:77] Creating layer bn3a_branch2a
I0524 17:57:35.489397   808 net.cpp:84] Creating Layer bn3a_branch2a
I0524 17:57:35.489403   808 net.cpp:406] bn3a_branch2a <- res3a_branch2a
I0524 17:57:35.489408   808 net.cpp:367] bn3a_branch2a -> res3a_branch2a (in-place)
I0524 17:57:35.489569   808 net.cpp:122] Setting up bn3a_branch2a
I0524 17:57:35.489580   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.489585   808 net.cpp:137] Memory required for data: 1896653000
I0524 17:57:35.489593   808 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0524 17:57:35.489599   808 net.cpp:84] Creating Layer scale3a_branch2a
I0524 17:57:35.489603   808 net.cpp:406] scale3a_branch2a <- res3a_branch2a
I0524 17:57:35.489609   808 net.cpp:367] scale3a_branch2a -> res3a_branch2a (in-place)
I0524 17:57:35.489645   808 layer_factory.hpp:77] Creating layer scale3a_branch2a
I0524 17:57:35.489735   808 net.cpp:122] Setting up scale3a_branch2a
I0524 17:57:35.489744   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.489758   808 net.cpp:137] Memory required for data: 1916723400
I0524 17:57:35.489765   808 layer_factory.hpp:77] Creating layer res3a_branch2a_relu
I0524 17:57:35.489773   808 net.cpp:84] Creating Layer res3a_branch2a_relu
I0524 17:57:35.489778   808 net.cpp:406] res3a_branch2a_relu <- res3a_branch2a
I0524 17:57:35.489783   808 net.cpp:367] res3a_branch2a_relu -> res3a_branch2a (in-place)
I0524 17:57:35.489926   808 net.cpp:122] Setting up res3a_branch2a_relu
I0524 17:57:35.489936   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.489940   808 net.cpp:137] Memory required for data: 1936793800
I0524 17:57:35.489943   808 layer_factory.hpp:77] Creating layer res3a_branch2b
I0524 17:57:35.489953   808 net.cpp:84] Creating Layer res3a_branch2b
I0524 17:57:35.489958   808 net.cpp:406] res3a_branch2b <- res3a_branch2a
I0524 17:57:35.489964   808 net.cpp:380] res3a_branch2b -> res3a_branch2b
I0524 17:57:35.492738   808 net.cpp:122] Setting up res3a_branch2b
I0524 17:57:35.492751   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.492755   808 net.cpp:137] Memory required for data: 1956864200
I0524 17:57:35.492761   808 layer_factory.hpp:77] Creating layer bn3a_branch2b
I0524 17:57:35.492768   808 net.cpp:84] Creating Layer bn3a_branch2b
I0524 17:57:35.492772   808 net.cpp:406] bn3a_branch2b <- res3a_branch2b
I0524 17:57:35.492779   808 net.cpp:367] bn3a_branch2b -> res3a_branch2b (in-place)
I0524 17:57:35.492938   808 net.cpp:122] Setting up bn3a_branch2b
I0524 17:57:35.492946   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.492950   808 net.cpp:137] Memory required for data: 1976934600
I0524 17:57:35.492957   808 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0524 17:57:35.492964   808 net.cpp:84] Creating Layer scale3a_branch2b
I0524 17:57:35.492969   808 net.cpp:406] scale3a_branch2b <- res3a_branch2b
I0524 17:57:35.492974   808 net.cpp:367] scale3a_branch2b -> res3a_branch2b (in-place)
I0524 17:57:35.493008   808 layer_factory.hpp:77] Creating layer scale3a_branch2b
I0524 17:57:35.493099   808 net.cpp:122] Setting up scale3a_branch2b
I0524 17:57:35.493108   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.493113   808 net.cpp:137] Memory required for data: 1997005000
I0524 17:57:35.493119   808 layer_factory.hpp:77] Creating layer res3a
I0524 17:57:35.493126   808 net.cpp:84] Creating Layer res3a
I0524 17:57:35.493131   808 net.cpp:406] res3a <- res3a_branch1
I0524 17:57:35.493135   808 net.cpp:406] res3a <- res3a_branch2b
I0524 17:57:35.493140   808 net.cpp:380] res3a -> res3a
I0524 17:57:35.493165   808 net.cpp:122] Setting up res3a
I0524 17:57:35.493173   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.493177   808 net.cpp:137] Memory required for data: 2017075400
I0524 17:57:35.493180   808 layer_factory.hpp:77] Creating layer res3a_relu
I0524 17:57:35.493185   808 net.cpp:84] Creating Layer res3a_relu
I0524 17:57:35.493190   808 net.cpp:406] res3a_relu <- res3a
I0524 17:57:35.493196   808 net.cpp:367] res3a_relu -> res3a (in-place)
I0524 17:57:35.493340   808 net.cpp:122] Setting up res3a_relu
I0524 17:57:35.493351   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.493355   808 net.cpp:137] Memory required for data: 2037145800
I0524 17:57:35.493360   808 layer_factory.hpp:77] Creating layer res3a_res3a_relu_0_split
I0524 17:57:35.493365   808 net.cpp:84] Creating Layer res3a_res3a_relu_0_split
I0524 17:57:35.493368   808 net.cpp:406] res3a_res3a_relu_0_split <- res3a
I0524 17:57:35.493374   808 net.cpp:380] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_0
I0524 17:57:35.493381   808 net.cpp:380] res3a_res3a_relu_0_split -> res3a_res3a_relu_0_split_1
I0524 17:57:35.493418   808 net.cpp:122] Setting up res3a_res3a_relu_0_split
I0524 17:57:35.493427   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.493432   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.493434   808 net.cpp:137] Memory required for data: 2077286600
I0524 17:57:35.493438   808 layer_factory.hpp:77] Creating layer res3b_branch2a
I0524 17:57:35.493455   808 net.cpp:84] Creating Layer res3b_branch2a
I0524 17:57:35.493461   808 net.cpp:406] res3b_branch2a <- res3a_res3a_relu_0_split_0
I0524 17:57:35.493468   808 net.cpp:380] res3b_branch2a -> res3b_branch2a
I0524 17:57:35.496893   808 net.cpp:122] Setting up res3b_branch2a
I0524 17:57:35.496911   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.496915   808 net.cpp:137] Memory required for data: 2097357000
I0524 17:57:35.496922   808 layer_factory.hpp:77] Creating layer bn3b_branch2a
I0524 17:57:35.496928   808 net.cpp:84] Creating Layer bn3b_branch2a
I0524 17:57:35.496933   808 net.cpp:406] bn3b_branch2a <- res3b_branch2a
I0524 17:57:35.496939   808 net.cpp:367] bn3b_branch2a -> res3b_branch2a (in-place)
I0524 17:57:35.497103   808 net.cpp:122] Setting up bn3b_branch2a
I0524 17:57:35.497112   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.497117   808 net.cpp:137] Memory required for data: 2117427400
I0524 17:57:35.497124   808 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0524 17:57:35.497133   808 net.cpp:84] Creating Layer scale3b_branch2a
I0524 17:57:35.497141   808 net.cpp:406] scale3b_branch2a <- res3b_branch2a
I0524 17:57:35.497150   808 net.cpp:367] scale3b_branch2a -> res3b_branch2a (in-place)
I0524 17:57:35.497206   808 layer_factory.hpp:77] Creating layer scale3b_branch2a
I0524 17:57:35.497304   808 net.cpp:122] Setting up scale3b_branch2a
I0524 17:57:35.497314   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.497319   808 net.cpp:137] Memory required for data: 2137497800
I0524 17:57:35.497331   808 layer_factory.hpp:77] Creating layer res3b_branch2a_relu
I0524 17:57:35.497342   808 net.cpp:84] Creating Layer res3b_branch2a_relu
I0524 17:57:35.497350   808 net.cpp:406] res3b_branch2a_relu <- res3b_branch2a
I0524 17:57:35.497360   808 net.cpp:367] res3b_branch2a_relu -> res3b_branch2a (in-place)
I0524 17:57:35.497512   808 net.cpp:122] Setting up res3b_branch2a_relu
I0524 17:57:35.497524   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.497527   808 net.cpp:137] Memory required for data: 2157568200
I0524 17:57:35.497530   808 layer_factory.hpp:77] Creating layer res3b_branch2b
I0524 17:57:35.497540   808 net.cpp:84] Creating Layer res3b_branch2b
I0524 17:57:35.497545   808 net.cpp:406] res3b_branch2b <- res3b_branch2a
I0524 17:57:35.497551   808 net.cpp:380] res3b_branch2b -> res3b_branch2b
I0524 17:57:35.500288   808 net.cpp:122] Setting up res3b_branch2b
I0524 17:57:35.500300   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.500305   808 net.cpp:137] Memory required for data: 2177638600
I0524 17:57:35.500310   808 layer_factory.hpp:77] Creating layer bn3b_branch2b
I0524 17:57:35.500319   808 net.cpp:84] Creating Layer bn3b_branch2b
I0524 17:57:35.500324   808 net.cpp:406] bn3b_branch2b <- res3b_branch2b
I0524 17:57:35.500329   808 net.cpp:367] bn3b_branch2b -> res3b_branch2b (in-place)
I0524 17:57:35.500490   808 net.cpp:122] Setting up bn3b_branch2b
I0524 17:57:35.500499   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.500504   808 net.cpp:137] Memory required for data: 2197709000
I0524 17:57:35.500510   808 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0524 17:57:35.500517   808 net.cpp:84] Creating Layer scale3b_branch2b
I0524 17:57:35.500521   808 net.cpp:406] scale3b_branch2b <- res3b_branch2b
I0524 17:57:35.500526   808 net.cpp:367] scale3b_branch2b -> res3b_branch2b (in-place)
I0524 17:57:35.500563   808 layer_factory.hpp:77] Creating layer scale3b_branch2b
I0524 17:57:35.500660   808 net.cpp:122] Setting up scale3b_branch2b
I0524 17:57:35.500669   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.500674   808 net.cpp:137] Memory required for data: 2217779400
I0524 17:57:35.500689   808 layer_factory.hpp:77] Creating layer res3b
I0524 17:57:35.500697   808 net.cpp:84] Creating Layer res3b
I0524 17:57:35.500701   808 net.cpp:406] res3b <- res3a_res3a_relu_0_split_1
I0524 17:57:35.500716   808 net.cpp:406] res3b <- res3b_branch2b
I0524 17:57:35.500722   808 net.cpp:380] res3b -> res3b
I0524 17:57:35.500751   808 net.cpp:122] Setting up res3b
I0524 17:57:35.500758   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.500762   808 net.cpp:137] Memory required for data: 2237849800
I0524 17:57:35.500766   808 layer_factory.hpp:77] Creating layer res3b_relu
I0524 17:57:35.500771   808 net.cpp:84] Creating Layer res3b_relu
I0524 17:57:35.500775   808 net.cpp:406] res3b_relu <- res3b
I0524 17:57:35.500780   808 net.cpp:367] res3b_relu -> res3b (in-place)
I0524 17:57:35.500926   808 net.cpp:122] Setting up res3b_relu
I0524 17:57:35.500937   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.500941   808 net.cpp:137] Memory required for data: 2257920200
I0524 17:57:35.500944   808 layer_factory.hpp:77] Creating layer res3b_res3b_relu_0_split
I0524 17:57:35.500949   808 net.cpp:84] Creating Layer res3b_res3b_relu_0_split
I0524 17:57:35.500953   808 net.cpp:406] res3b_res3b_relu_0_split <- res3b
I0524 17:57:35.500959   808 net.cpp:380] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_0
I0524 17:57:35.500967   808 net.cpp:380] res3b_res3b_relu_0_split -> res3b_res3b_relu_0_split_1
I0524 17:57:35.501003   808 net.cpp:122] Setting up res3b_res3b_relu_0_split
I0524 17:57:35.501011   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.501016   808 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0524 17:57:35.501019   808 net.cpp:137] Memory required for data: 2298061000
I0524 17:57:35.501025   808 layer_factory.hpp:77] Creating layer res4a_branch1
I0524 17:57:35.501040   808 net.cpp:84] Creating Layer res4a_branch1
I0524 17:57:35.501049   808 net.cpp:406] res4a_branch1 <- res3b_res3b_relu_0_split_0
I0524 17:57:35.501061   808 net.cpp:380] res4a_branch1 -> res4a_branch1
I0524 17:57:35.502614   808 net.cpp:122] Setting up res4a_branch1
I0524 17:57:35.502627   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.502631   808 net.cpp:137] Memory required for data: 2308096200
I0524 17:57:35.502636   808 layer_factory.hpp:77] Creating layer bn4a_branch1
I0524 17:57:35.502645   808 net.cpp:84] Creating Layer bn4a_branch1
I0524 17:57:35.502650   808 net.cpp:406] bn4a_branch1 <- res4a_branch1
I0524 17:57:35.502655   808 net.cpp:367] bn4a_branch1 -> res4a_branch1 (in-place)
I0524 17:57:35.502820   808 net.cpp:122] Setting up bn4a_branch1
I0524 17:57:35.502828   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.502832   808 net.cpp:137] Memory required for data: 2318131400
I0524 17:57:35.502840   808 layer_factory.hpp:77] Creating layer scale4a_branch1
I0524 17:57:35.502846   808 net.cpp:84] Creating Layer scale4a_branch1
I0524 17:57:35.502851   808 net.cpp:406] scale4a_branch1 <- res4a_branch1
I0524 17:57:35.502856   808 net.cpp:367] scale4a_branch1 -> res4a_branch1 (in-place)
I0524 17:57:35.502893   808 layer_factory.hpp:77] Creating layer scale4a_branch1
I0524 17:57:35.502988   808 net.cpp:122] Setting up scale4a_branch1
I0524 17:57:35.502997   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.503001   808 net.cpp:137] Memory required for data: 2328166600
I0524 17:57:35.503007   808 layer_factory.hpp:77] Creating layer res4a_branch2a
I0524 17:57:35.503016   808 net.cpp:84] Creating Layer res4a_branch2a
I0524 17:57:35.503021   808 net.cpp:406] res4a_branch2a <- res3b_res3b_relu_0_split_1
I0524 17:57:35.503027   808 net.cpp:380] res4a_branch2a -> res4a_branch2a
I0524 17:57:35.507608   808 net.cpp:122] Setting up res4a_branch2a
I0524 17:57:35.507627   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.507630   808 net.cpp:137] Memory required for data: 2338201800
I0524 17:57:35.507637   808 layer_factory.hpp:77] Creating layer bn4a_branch2a
I0524 17:57:35.507647   808 net.cpp:84] Creating Layer bn4a_branch2a
I0524 17:57:35.507652   808 net.cpp:406] bn4a_branch2a <- res4a_branch2a
I0524 17:57:35.507658   808 net.cpp:367] bn4a_branch2a -> res4a_branch2a (in-place)
I0524 17:57:35.507822   808 net.cpp:122] Setting up bn4a_branch2a
I0524 17:57:35.507843   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.507848   808 net.cpp:137] Memory required for data: 2348237000
I0524 17:57:35.507855   808 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0524 17:57:35.507861   808 net.cpp:84] Creating Layer scale4a_branch2a
I0524 17:57:35.507866   808 net.cpp:406] scale4a_branch2a <- res4a_branch2a
I0524 17:57:35.507870   808 net.cpp:367] scale4a_branch2a -> res4a_branch2a (in-place)
I0524 17:57:35.507910   808 layer_factory.hpp:77] Creating layer scale4a_branch2a
I0524 17:57:35.508003   808 net.cpp:122] Setting up scale4a_branch2a
I0524 17:57:35.508013   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.508016   808 net.cpp:137] Memory required for data: 2358272200
I0524 17:57:35.508023   808 layer_factory.hpp:77] Creating layer res4a_branch2a_relu
I0524 17:57:35.508030   808 net.cpp:84] Creating Layer res4a_branch2a_relu
I0524 17:57:35.508035   808 net.cpp:406] res4a_branch2a_relu <- res4a_branch2a
I0524 17:57:35.508041   808 net.cpp:367] res4a_branch2a_relu -> res4a_branch2a (in-place)
I0524 17:57:35.508541   808 net.cpp:122] Setting up res4a_branch2a_relu
I0524 17:57:35.508553   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.508558   808 net.cpp:137] Memory required for data: 2368307400
I0524 17:57:35.508560   808 layer_factory.hpp:77] Creating layer res4a_branch2b
I0524 17:57:35.508570   808 net.cpp:84] Creating Layer res4a_branch2b
I0524 17:57:35.508575   808 net.cpp:406] res4a_branch2b <- res4a_branch2a
I0524 17:57:35.508582   808 net.cpp:380] res4a_branch2b -> res4a_branch2b
I0524 17:57:35.516119   808 net.cpp:122] Setting up res4a_branch2b
I0524 17:57:35.516134   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.516139   808 net.cpp:137] Memory required for data: 2378342600
I0524 17:57:35.516144   808 layer_factory.hpp:77] Creating layer bn4a_branch2b
I0524 17:57:35.516152   808 net.cpp:84] Creating Layer bn4a_branch2b
I0524 17:57:35.516158   808 net.cpp:406] bn4a_branch2b <- res4a_branch2b
I0524 17:57:35.516163   808 net.cpp:367] bn4a_branch2b -> res4a_branch2b (in-place)
I0524 17:57:35.516330   808 net.cpp:122] Setting up bn4a_branch2b
I0524 17:57:35.516340   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.516343   808 net.cpp:137] Memory required for data: 2388377800
I0524 17:57:35.516351   808 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0524 17:57:35.516357   808 net.cpp:84] Creating Layer scale4a_branch2b
I0524 17:57:35.516361   808 net.cpp:406] scale4a_branch2b <- res4a_branch2b
I0524 17:57:35.516366   808 net.cpp:367] scale4a_branch2b -> res4a_branch2b (in-place)
I0524 17:57:35.516404   808 layer_factory.hpp:77] Creating layer scale4a_branch2b
I0524 17:57:35.516499   808 net.cpp:122] Setting up scale4a_branch2b
I0524 17:57:35.516507   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.516510   808 net.cpp:137] Memory required for data: 2398413000
I0524 17:57:35.516516   808 layer_factory.hpp:77] Creating layer res4a
I0524 17:57:35.516525   808 net.cpp:84] Creating Layer res4a
I0524 17:57:35.516530   808 net.cpp:406] res4a <- res4a_branch1
I0524 17:57:35.516535   808 net.cpp:406] res4a <- res4a_branch2b
I0524 17:57:35.516541   808 net.cpp:380] res4a -> res4a
I0524 17:57:35.516566   808 net.cpp:122] Setting up res4a
I0524 17:57:35.516573   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.516577   808 net.cpp:137] Memory required for data: 2408448200
I0524 17:57:35.516582   808 layer_factory.hpp:77] Creating layer res4a_relu
I0524 17:57:35.516597   808 net.cpp:84] Creating Layer res4a_relu
I0524 17:57:35.516602   808 net.cpp:406] res4a_relu <- res4a
I0524 17:57:35.516607   808 net.cpp:367] res4a_relu -> res4a (in-place)
I0524 17:57:35.517105   808 net.cpp:122] Setting up res4a_relu
I0524 17:57:35.517117   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.517122   808 net.cpp:137] Memory required for data: 2418483400
I0524 17:57:35.517125   808 layer_factory.hpp:77] Creating layer res4a_res4a_relu_0_split
I0524 17:57:35.517143   808 net.cpp:84] Creating Layer res4a_res4a_relu_0_split
I0524 17:57:35.517148   808 net.cpp:406] res4a_res4a_relu_0_split <- res4a
I0524 17:57:35.517153   808 net.cpp:380] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_0
I0524 17:57:35.517166   808 net.cpp:380] res4a_res4a_relu_0_split -> res4a_res4a_relu_0_split_1
I0524 17:57:35.517204   808 net.cpp:122] Setting up res4a_res4a_relu_0_split
I0524 17:57:35.517215   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.517220   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.517223   808 net.cpp:137] Memory required for data: 2438553800
I0524 17:57:35.517226   808 layer_factory.hpp:77] Creating layer res4b_branch2a
I0524 17:57:35.517235   808 net.cpp:84] Creating Layer res4b_branch2a
I0524 17:57:35.517241   808 net.cpp:406] res4b_branch2a <- res4a_res4a_relu_0_split_0
I0524 17:57:35.517246   808 net.cpp:380] res4b_branch2a -> res4b_branch2a
I0524 17:57:35.525106   808 net.cpp:122] Setting up res4b_branch2a
I0524 17:57:35.525121   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.525125   808 net.cpp:137] Memory required for data: 2448589000
I0524 17:57:35.525132   808 layer_factory.hpp:77] Creating layer bn4b_branch2a
I0524 17:57:35.525140   808 net.cpp:84] Creating Layer bn4b_branch2a
I0524 17:57:35.525144   808 net.cpp:406] bn4b_branch2a <- res4b_branch2a
I0524 17:57:35.525151   808 net.cpp:367] bn4b_branch2a -> res4b_branch2a (in-place)
I0524 17:57:35.525319   808 net.cpp:122] Setting up bn4b_branch2a
I0524 17:57:35.525329   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.525333   808 net.cpp:137] Memory required for data: 2458624200
I0524 17:57:35.525341   808 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0524 17:57:35.525348   808 net.cpp:84] Creating Layer scale4b_branch2a
I0524 17:57:35.525352   808 net.cpp:406] scale4b_branch2a <- res4b_branch2a
I0524 17:57:35.525357   808 net.cpp:367] scale4b_branch2a -> res4b_branch2a (in-place)
I0524 17:57:35.525394   808 layer_factory.hpp:77] Creating layer scale4b_branch2a
I0524 17:57:35.525496   808 net.cpp:122] Setting up scale4b_branch2a
I0524 17:57:35.525506   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.525509   808 net.cpp:137] Memory required for data: 2468659400
I0524 17:57:35.525516   808 layer_factory.hpp:77] Creating layer res4b_branch2a_relu
I0524 17:57:35.525523   808 net.cpp:84] Creating Layer res4b_branch2a_relu
I0524 17:57:35.525528   808 net.cpp:406] res4b_branch2a_relu <- res4b_branch2a
I0524 17:57:35.525533   808 net.cpp:367] res4b_branch2a_relu -> res4b_branch2a (in-place)
I0524 17:57:35.525686   808 net.cpp:122] Setting up res4b_branch2a_relu
I0524 17:57:35.525696   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.525699   808 net.cpp:137] Memory required for data: 2478694600
I0524 17:57:35.525702   808 layer_factory.hpp:77] Creating layer res4b_branch2b
I0524 17:57:35.525712   808 net.cpp:84] Creating Layer res4b_branch2b
I0524 17:57:35.525717   808 net.cpp:406] res4b_branch2b <- res4b_branch2a
I0524 17:57:35.525723   808 net.cpp:380] res4b_branch2b -> res4b_branch2b
I0524 17:57:35.533591   808 net.cpp:122] Setting up res4b_branch2b
I0524 17:57:35.533607   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.533612   808 net.cpp:137] Memory required for data: 2488729800
I0524 17:57:35.533617   808 layer_factory.hpp:77] Creating layer bn4b_branch2b
I0524 17:57:35.533623   808 net.cpp:84] Creating Layer bn4b_branch2b
I0524 17:57:35.533627   808 net.cpp:406] bn4b_branch2b <- res4b_branch2b
I0524 17:57:35.533634   808 net.cpp:367] bn4b_branch2b -> res4b_branch2b (in-place)
I0524 17:57:35.533800   808 net.cpp:122] Setting up bn4b_branch2b
I0524 17:57:35.533810   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.533815   808 net.cpp:137] Memory required for data: 2498765000
I0524 17:57:35.533823   808 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0524 17:57:35.533829   808 net.cpp:84] Creating Layer scale4b_branch2b
I0524 17:57:35.533845   808 net.cpp:406] scale4b_branch2b <- res4b_branch2b
I0524 17:57:35.533851   808 net.cpp:367] scale4b_branch2b -> res4b_branch2b (in-place)
I0524 17:57:35.533888   808 layer_factory.hpp:77] Creating layer scale4b_branch2b
I0524 17:57:35.533985   808 net.cpp:122] Setting up scale4b_branch2b
I0524 17:57:35.533994   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.533998   808 net.cpp:137] Memory required for data: 2508800200
I0524 17:57:35.534003   808 layer_factory.hpp:77] Creating layer res4b
I0524 17:57:35.534013   808 net.cpp:84] Creating Layer res4b
I0524 17:57:35.534018   808 net.cpp:406] res4b <- res4a_res4a_relu_0_split_1
I0524 17:57:35.534021   808 net.cpp:406] res4b <- res4b_branch2b
I0524 17:57:35.534027   808 net.cpp:380] res4b -> res4b
I0524 17:57:35.534054   808 net.cpp:122] Setting up res4b
I0524 17:57:35.534061   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.534065   808 net.cpp:137] Memory required for data: 2518835400
I0524 17:57:35.534070   808 layer_factory.hpp:77] Creating layer res4b_relu
I0524 17:57:35.534073   808 net.cpp:84] Creating Layer res4b_relu
I0524 17:57:35.534078   808 net.cpp:406] res4b_relu <- res4b
I0524 17:57:35.534085   808 net.cpp:367] res4b_relu -> res4b (in-place)
I0524 17:57:35.534579   808 net.cpp:122] Setting up res4b_relu
I0524 17:57:35.534595   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.534598   808 net.cpp:137] Memory required for data: 2528870600
I0524 17:57:35.534602   808 layer_factory.hpp:77] Creating layer res4b_res4b_relu_0_split
I0524 17:57:35.534607   808 net.cpp:84] Creating Layer res4b_res4b_relu_0_split
I0524 17:57:35.534612   808 net.cpp:406] res4b_res4b_relu_0_split <- res4b
I0524 17:57:35.534617   808 net.cpp:380] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_0
I0524 17:57:35.534626   808 net.cpp:380] res4b_res4b_relu_0_split -> res4b_res4b_relu_0_split_1
I0524 17:57:35.534664   808 net.cpp:122] Setting up res4b_res4b_relu_0_split
I0524 17:57:35.534672   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.534677   808 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0524 17:57:35.534680   808 net.cpp:137] Memory required for data: 2548941000
I0524 17:57:35.534684   808 layer_factory.hpp:77] Creating layer res5a_branch1
I0524 17:57:35.534693   808 net.cpp:84] Creating Layer res5a_branch1
I0524 17:57:35.534698   808 net.cpp:406] res5a_branch1 <- res4b_res4b_relu_0_split_0
I0524 17:57:35.534704   808 net.cpp:380] res5a_branch1 -> res5a_branch1
I0524 17:57:35.537027   808 net.cpp:122] Setting up res5a_branch1
I0524 17:57:35.537039   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.537045   808 net.cpp:137] Memory required for data: 2553958600
I0524 17:57:35.537050   808 layer_factory.hpp:77] Creating layer bn5a_branch1
I0524 17:57:35.537057   808 net.cpp:84] Creating Layer bn5a_branch1
I0524 17:57:35.537062   808 net.cpp:406] bn5a_branch1 <- res5a_branch1
I0524 17:57:35.537068   808 net.cpp:367] bn5a_branch1 -> res5a_branch1 (in-place)
I0524 17:57:35.537242   808 net.cpp:122] Setting up bn5a_branch1
I0524 17:57:35.537251   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.537256   808 net.cpp:137] Memory required for data: 2558976200
I0524 17:57:35.537263   808 layer_factory.hpp:77] Creating layer scale5a_branch1
I0524 17:57:35.537269   808 net.cpp:84] Creating Layer scale5a_branch1
I0524 17:57:35.537274   808 net.cpp:406] scale5a_branch1 <- res5a_branch1
I0524 17:57:35.537281   808 net.cpp:367] scale5a_branch1 -> res5a_branch1 (in-place)
I0524 17:57:35.537314   808 layer_factory.hpp:77] Creating layer scale5a_branch1
I0524 17:57:35.537416   808 net.cpp:122] Setting up scale5a_branch1
I0524 17:57:35.537425   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.537430   808 net.cpp:137] Memory required for data: 2563993800
I0524 17:57:35.537436   808 layer_factory.hpp:77] Creating layer res5a_branch2a
I0524 17:57:35.537444   808 net.cpp:84] Creating Layer res5a_branch2a
I0524 17:57:35.537449   808 net.cpp:406] res5a_branch2a <- res4b_res4b_relu_0_split_1
I0524 17:57:35.537466   808 net.cpp:380] res5a_branch2a -> res5a_branch2a
I0524 17:57:35.551386   808 net.cpp:122] Setting up res5a_branch2a
I0524 17:57:35.551404   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.551409   808 net.cpp:137] Memory required for data: 2569011400
I0524 17:57:35.551414   808 layer_factory.hpp:77] Creating layer bn5a_branch2a
I0524 17:57:35.551425   808 net.cpp:84] Creating Layer bn5a_branch2a
I0524 17:57:35.551431   808 net.cpp:406] bn5a_branch2a <- res5a_branch2a
I0524 17:57:35.551437   808 net.cpp:367] bn5a_branch2a -> res5a_branch2a (in-place)
I0524 17:57:35.551617   808 net.cpp:122] Setting up bn5a_branch2a
I0524 17:57:35.551627   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.551632   808 net.cpp:137] Memory required for data: 2574029000
I0524 17:57:35.551651   808 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0524 17:57:35.551658   808 net.cpp:84] Creating Layer scale5a_branch2a
I0524 17:57:35.551661   808 net.cpp:406] scale5a_branch2a <- res5a_branch2a
I0524 17:57:35.551666   808 net.cpp:367] scale5a_branch2a -> res5a_branch2a (in-place)
I0524 17:57:35.551702   808 layer_factory.hpp:77] Creating layer scale5a_branch2a
I0524 17:57:35.551826   808 net.cpp:122] Setting up scale5a_branch2a
I0524 17:57:35.551836   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.551839   808 net.cpp:137] Memory required for data: 2579046600
I0524 17:57:35.551856   808 layer_factory.hpp:77] Creating layer res5a_branch2a_relu
I0524 17:57:35.551864   808 net.cpp:84] Creating Layer res5a_branch2a_relu
I0524 17:57:35.551868   808 net.cpp:406] res5a_branch2a_relu <- res5a_branch2a
I0524 17:57:35.551873   808 net.cpp:367] res5a_branch2a_relu -> res5a_branch2a (in-place)
I0524 17:57:35.552039   808 net.cpp:122] Setting up res5a_branch2a_relu
I0524 17:57:35.552048   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.552052   808 net.cpp:137] Memory required for data: 2584064200
I0524 17:57:35.552067   808 layer_factory.hpp:77] Creating layer res5a_branch2b
I0524 17:57:35.552078   808 net.cpp:84] Creating Layer res5a_branch2b
I0524 17:57:35.552083   808 net.cpp:406] res5a_branch2b <- res5a_branch2a
I0524 17:57:35.552089   808 net.cpp:380] res5a_branch2b -> res5a_branch2b
I0524 17:57:35.578970   808 net.cpp:122] Setting up res5a_branch2b
I0524 17:57:35.578996   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579000   808 net.cpp:137] Memory required for data: 2589081800
I0524 17:57:35.579010   808 layer_factory.hpp:77] Creating layer bn5a_branch2b
I0524 17:57:35.579020   808 net.cpp:84] Creating Layer bn5a_branch2b
I0524 17:57:35.579025   808 net.cpp:406] bn5a_branch2b <- res5a_branch2b
I0524 17:57:35.579046   808 net.cpp:367] bn5a_branch2b -> res5a_branch2b (in-place)
I0524 17:57:35.579236   808 net.cpp:122] Setting up bn5a_branch2b
I0524 17:57:35.579246   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579248   808 net.cpp:137] Memory required for data: 2594099400
I0524 17:57:35.579255   808 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0524 17:57:35.579262   808 net.cpp:84] Creating Layer scale5a_branch2b
I0524 17:57:35.579265   808 net.cpp:406] scale5a_branch2b <- res5a_branch2b
I0524 17:57:35.579272   808 net.cpp:367] scale5a_branch2b -> res5a_branch2b (in-place)
I0524 17:57:35.579321   808 layer_factory.hpp:77] Creating layer scale5a_branch2b
I0524 17:57:35.579437   808 net.cpp:122] Setting up scale5a_branch2b
I0524 17:57:35.579447   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579450   808 net.cpp:137] Memory required for data: 2599117000
I0524 17:57:35.579457   808 layer_factory.hpp:77] Creating layer res5a
I0524 17:57:35.579463   808 net.cpp:84] Creating Layer res5a
I0524 17:57:35.579466   808 net.cpp:406] res5a <- res5a_branch1
I0524 17:57:35.579470   808 net.cpp:406] res5a <- res5a_branch2b
I0524 17:57:35.579485   808 net.cpp:380] res5a -> res5a
I0524 17:57:35.579512   808 net.cpp:122] Setting up res5a
I0524 17:57:35.579520   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579537   808 net.cpp:137] Memory required for data: 2604134600
I0524 17:57:35.579541   808 layer_factory.hpp:77] Creating layer res5a_relu
I0524 17:57:35.579560   808 net.cpp:84] Creating Layer res5a_relu
I0524 17:57:35.579565   808 net.cpp:406] res5a_relu <- res5a
I0524 17:57:35.579569   808 net.cpp:367] res5a_relu -> res5a (in-place)
I0524 17:57:35.579711   808 net.cpp:122] Setting up res5a_relu
I0524 17:57:35.579721   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579725   808 net.cpp:137] Memory required for data: 2609152200
I0524 17:57:35.579727   808 layer_factory.hpp:77] Creating layer res5a_res5a_relu_0_split
I0524 17:57:35.579733   808 net.cpp:84] Creating Layer res5a_res5a_relu_0_split
I0524 17:57:35.579736   808 net.cpp:406] res5a_res5a_relu_0_split <- res5a
I0524 17:57:35.579742   808 net.cpp:380] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_0
I0524 17:57:35.579761   808 net.cpp:380] res5a_res5a_relu_0_split -> res5a_res5a_relu_0_split_1
I0524 17:57:35.579797   808 net.cpp:122] Setting up res5a_res5a_relu_0_split
I0524 17:57:35.579805   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579810   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.579813   808 net.cpp:137] Memory required for data: 2619187400
I0524 17:57:35.579816   808 layer_factory.hpp:77] Creating layer res5b_branch2a
I0524 17:57:35.579828   808 net.cpp:84] Creating Layer res5b_branch2a
I0524 17:57:35.579833   808 net.cpp:406] res5b_branch2a <- res5a_res5a_relu_0_split_0
I0524 17:57:35.579838   808 net.cpp:380] res5b_branch2a -> res5b_branch2a
I0524 17:57:35.606557   808 net.cpp:122] Setting up res5b_branch2a
I0524 17:57:35.606598   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.606602   808 net.cpp:137] Memory required for data: 2624205000
I0524 17:57:35.606611   808 layer_factory.hpp:77] Creating layer bn5b_branch2a
I0524 17:57:35.606622   808 net.cpp:84] Creating Layer bn5b_branch2a
I0524 17:57:35.606627   808 net.cpp:406] bn5b_branch2a <- res5b_branch2a
I0524 17:57:35.606636   808 net.cpp:367] bn5b_branch2a -> res5b_branch2a (in-place)
I0524 17:57:35.606832   808 net.cpp:122] Setting up bn5b_branch2a
I0524 17:57:35.606840   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.606843   808 net.cpp:137] Memory required for data: 2629222600
I0524 17:57:35.606850   808 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0524 17:57:35.606858   808 net.cpp:84] Creating Layer scale5b_branch2a
I0524 17:57:35.606860   808 net.cpp:406] scale5b_branch2a <- res5b_branch2a
I0524 17:57:35.606866   808 net.cpp:367] scale5b_branch2a -> res5b_branch2a (in-place)
I0524 17:57:35.606916   808 layer_factory.hpp:77] Creating layer scale5b_branch2a
I0524 17:57:35.607035   808 net.cpp:122] Setting up scale5b_branch2a
I0524 17:57:35.607045   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.607048   808 net.cpp:137] Memory required for data: 2634240200
I0524 17:57:35.607054   808 layer_factory.hpp:77] Creating layer res5b_branch2a_relu
I0524 17:57:35.607060   808 net.cpp:84] Creating Layer res5b_branch2a_relu
I0524 17:57:35.607064   808 net.cpp:406] res5b_branch2a_relu <- res5b_branch2a
I0524 17:57:35.607067   808 net.cpp:367] res5b_branch2a_relu -> res5b_branch2a (in-place)
I0524 17:57:35.607234   808 net.cpp:122] Setting up res5b_branch2a_relu
I0524 17:57:35.607244   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.607247   808 net.cpp:137] Memory required for data: 2639257800
I0524 17:57:35.607250   808 layer_factory.hpp:77] Creating layer res5b_branch2b
I0524 17:57:35.607261   808 net.cpp:84] Creating Layer res5b_branch2b
I0524 17:57:35.607265   808 net.cpp:406] res5b_branch2b <- res5b_branch2a
I0524 17:57:35.607270   808 net.cpp:380] res5b_branch2b -> res5b_branch2b
I0524 17:57:35.633996   808 net.cpp:122] Setting up res5b_branch2b
I0524 17:57:35.634033   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.634038   808 net.cpp:137] Memory required for data: 2644275400
I0524 17:57:35.634047   808 layer_factory.hpp:77] Creating layer bn5b_branch2b
I0524 17:57:35.634083   808 net.cpp:84] Creating Layer bn5b_branch2b
I0524 17:57:35.634089   808 net.cpp:406] bn5b_branch2b <- res5b_branch2b
I0524 17:57:35.634097   808 net.cpp:367] bn5b_branch2b -> res5b_branch2b (in-place)
I0524 17:57:35.634299   808 net.cpp:122] Setting up bn5b_branch2b
I0524 17:57:35.634307   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.634322   808 net.cpp:137] Memory required for data: 2649293000
I0524 17:57:35.634330   808 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0524 17:57:35.634337   808 net.cpp:84] Creating Layer scale5b_branch2b
I0524 17:57:35.634341   808 net.cpp:406] scale5b_branch2b <- res5b_branch2b
I0524 17:57:35.634346   808 net.cpp:367] scale5b_branch2b -> res5b_branch2b (in-place)
I0524 17:57:35.634399   808 layer_factory.hpp:77] Creating layer scale5b_branch2b
I0524 17:57:35.634531   808 net.cpp:122] Setting up scale5b_branch2b
I0524 17:57:35.634539   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.634542   808 net.cpp:137] Memory required for data: 2654310600
I0524 17:57:35.634548   808 layer_factory.hpp:77] Creating layer res5b
I0524 17:57:35.634555   808 net.cpp:84] Creating Layer res5b
I0524 17:57:35.634572   808 net.cpp:406] res5b <- res5a_res5a_relu_0_split_1
I0524 17:57:35.634575   808 net.cpp:406] res5b <- res5b_branch2b
I0524 17:57:35.634582   808 net.cpp:380] res5b -> res5b
I0524 17:57:35.634608   808 net.cpp:122] Setting up res5b
I0524 17:57:35.634616   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.634619   808 net.cpp:137] Memory required for data: 2659328200
I0524 17:57:35.634623   808 layer_factory.hpp:77] Creating layer res5b_relu
I0524 17:57:35.634630   808 net.cpp:84] Creating Layer res5b_relu
I0524 17:57:35.634634   808 net.cpp:406] res5b_relu <- res5b
I0524 17:57:35.634639   808 net.cpp:367] res5b_relu -> res5b (in-place)
I0524 17:57:35.635162   808 net.cpp:122] Setting up res5b_relu
I0524 17:57:35.635174   808 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0524 17:57:35.635188   808 net.cpp:137] Memory required for data: 2664345800
I0524 17:57:35.635192   808 layer_factory.hpp:77] Creating layer pool5
I0524 17:57:35.635198   808 net.cpp:84] Creating Layer pool5
I0524 17:57:35.635203   808 net.cpp:406] pool5 <- res5b
I0524 17:57:35.635210   808 net.cpp:380] pool5 -> pool5
I0524 17:57:35.635396   808 net.cpp:122] Setting up pool5
I0524 17:57:35.635406   808 net.cpp:129] Top shape: 50 512 1 1 (25600)
I0524 17:57:35.635419   808 net.cpp:137] Memory required for data: 2664448200
I0524 17:57:35.635423   808 layer_factory.hpp:77] Creating layer fc8
I0524 17:57:35.635432   808 net.cpp:84] Creating Layer fc8
I0524 17:57:35.635435   808 net.cpp:406] fc8 <- pool5
I0524 17:57:35.635442   808 net.cpp:380] fc8 -> fc8
I0524 17:57:35.635601   808 net.cpp:122] Setting up fc8
I0524 17:57:35.635608   808 net.cpp:129] Top shape: 50 8 (400)
I0524 17:57:35.635612   808 net.cpp:137] Memory required for data: 2664449800
I0524 17:57:35.635618   808 layer_factory.hpp:77] Creating layer loss
I0524 17:57:35.635624   808 net.cpp:84] Creating Layer loss
I0524 17:57:35.635629   808 net.cpp:406] loss <- fc8
I0524 17:57:35.635633   808 net.cpp:406] loss <- label
I0524 17:57:35.635640   808 net.cpp:380] loss -> loss
I0524 17:57:35.635651   808 layer_factory.hpp:77] Creating layer loss
I0524 17:57:35.635875   808 net.cpp:122] Setting up loss
I0524 17:57:35.635885   808 net.cpp:129] Top shape: (1)
I0524 17:57:35.635890   808 net.cpp:132]     with loss weight 1
I0524 17:57:35.635908   808 net.cpp:137] Memory required for data: 2664449804
I0524 17:57:35.635912   808 net.cpp:198] loss needs backward computation.
I0524 17:57:35.635920   808 net.cpp:198] fc8 needs backward computation.
I0524 17:57:35.635922   808 net.cpp:198] pool5 needs backward computation.
I0524 17:57:35.635926   808 net.cpp:198] res5b_relu needs backward computation.
I0524 17:57:35.635928   808 net.cpp:198] res5b needs backward computation.
I0524 17:57:35.635931   808 net.cpp:198] scale5b_branch2b needs backward computation.
I0524 17:57:35.635944   808 net.cpp:198] bn5b_branch2b needs backward computation.
I0524 17:57:35.635947   808 net.cpp:198] res5b_branch2b needs backward computation.
I0524 17:57:35.635951   808 net.cpp:198] res5b_branch2a_relu needs backward computation.
I0524 17:57:35.635954   808 net.cpp:198] scale5b_branch2a needs backward computation.
I0524 17:57:35.635957   808 net.cpp:198] bn5b_branch2a needs backward computation.
I0524 17:57:35.635960   808 net.cpp:198] res5b_branch2a needs backward computation.
I0524 17:57:35.635963   808 net.cpp:198] res5a_res5a_relu_0_split needs backward computation.
I0524 17:57:35.635967   808 net.cpp:198] res5a_relu needs backward computation.
I0524 17:57:35.635970   808 net.cpp:198] res5a needs backward computation.
I0524 17:57:35.635973   808 net.cpp:198] scale5a_branch2b needs backward computation.
I0524 17:57:35.635977   808 net.cpp:198] bn5a_branch2b needs backward computation.
I0524 17:57:35.635979   808 net.cpp:198] res5a_branch2b needs backward computation.
I0524 17:57:35.635982   808 net.cpp:198] res5a_branch2a_relu needs backward computation.
I0524 17:57:35.635985   808 net.cpp:198] scale5a_branch2a needs backward computation.
I0524 17:57:35.635988   808 net.cpp:198] bn5a_branch2a needs backward computation.
I0524 17:57:35.635992   808 net.cpp:198] res5a_branch2a needs backward computation.
I0524 17:57:35.635994   808 net.cpp:198] scale5a_branch1 needs backward computation.
I0524 17:57:35.635998   808 net.cpp:198] bn5a_branch1 needs backward computation.
I0524 17:57:35.636001   808 net.cpp:198] res5a_branch1 needs backward computation.
I0524 17:57:35.636004   808 net.cpp:198] res4b_res4b_relu_0_split needs backward computation.
I0524 17:57:35.636008   808 net.cpp:198] res4b_relu needs backward computation.
I0524 17:57:35.636010   808 net.cpp:198] res4b needs backward computation.
I0524 17:57:35.636014   808 net.cpp:198] scale4b_branch2b needs backward computation.
I0524 17:57:35.636018   808 net.cpp:198] bn4b_branch2b needs backward computation.
I0524 17:57:35.636020   808 net.cpp:198] res4b_branch2b needs backward computation.
I0524 17:57:35.636023   808 net.cpp:198] res4b_branch2a_relu needs backward computation.
I0524 17:57:35.636026   808 net.cpp:198] scale4b_branch2a needs backward computation.
I0524 17:57:35.636029   808 net.cpp:198] bn4b_branch2a needs backward computation.
I0524 17:57:35.636032   808 net.cpp:198] res4b_branch2a needs backward computation.
I0524 17:57:35.636036   808 net.cpp:198] res4a_res4a_relu_0_split needs backward computation.
I0524 17:57:35.636041   808 net.cpp:198] res4a_relu needs backward computation.
I0524 17:57:35.636044   808 net.cpp:198] res4a needs backward computation.
I0524 17:57:35.636047   808 net.cpp:198] scale4a_branch2b needs backward computation.
I0524 17:57:35.636050   808 net.cpp:198] bn4a_branch2b needs backward computation.
I0524 17:57:35.636054   808 net.cpp:198] res4a_branch2b needs backward computation.
I0524 17:57:35.636056   808 net.cpp:198] res4a_branch2a_relu needs backward computation.
I0524 17:57:35.636059   808 net.cpp:198] scale4a_branch2a needs backward computation.
I0524 17:57:35.636062   808 net.cpp:198] bn4a_branch2a needs backward computation.
I0524 17:57:35.636065   808 net.cpp:198] res4a_branch2a needs backward computation.
I0524 17:57:35.636068   808 net.cpp:198] scale4a_branch1 needs backward computation.
I0524 17:57:35.636071   808 net.cpp:198] bn4a_branch1 needs backward computation.
I0524 17:57:35.636075   808 net.cpp:198] res4a_branch1 needs backward computation.
I0524 17:57:35.636077   808 net.cpp:198] res3b_res3b_relu_0_split needs backward computation.
I0524 17:57:35.636080   808 net.cpp:198] res3b_relu needs backward computation.
I0524 17:57:35.636083   808 net.cpp:198] res3b needs backward computation.
I0524 17:57:35.636087   808 net.cpp:198] scale3b_branch2b needs backward computation.
I0524 17:57:35.636090   808 net.cpp:198] bn3b_branch2b needs backward computation.
I0524 17:57:35.636093   808 net.cpp:198] res3b_branch2b needs backward computation.
I0524 17:57:35.636096   808 net.cpp:198] res3b_branch2a_relu needs backward computation.
I0524 17:57:35.636106   808 net.cpp:198] scale3b_branch2a needs backward computation.
I0524 17:57:35.636108   808 net.cpp:198] bn3b_branch2a needs backward computation.
I0524 17:57:35.636112   808 net.cpp:198] res3b_branch2a needs backward computation.
I0524 17:57:35.636116   808 net.cpp:198] res3a_res3a_relu_0_split needs backward computation.
I0524 17:57:35.636121   808 net.cpp:198] res3a_relu needs backward computation.
I0524 17:57:35.636123   808 net.cpp:198] res3a needs backward computation.
I0524 17:57:35.636127   808 net.cpp:198] scale3a_branch2b needs backward computation.
I0524 17:57:35.636131   808 net.cpp:198] bn3a_branch2b needs backward computation.
I0524 17:57:35.636133   808 net.cpp:198] res3a_branch2b needs backward computation.
I0524 17:57:35.636137   808 net.cpp:198] res3a_branch2a_relu needs backward computation.
I0524 17:57:35.636139   808 net.cpp:198] scale3a_branch2a needs backward computation.
I0524 17:57:35.636142   808 net.cpp:198] bn3a_branch2a needs backward computation.
I0524 17:57:35.636145   808 net.cpp:198] res3a_branch2a needs backward computation.
I0524 17:57:35.636149   808 net.cpp:198] scale3a_branch1 needs backward computation.
I0524 17:57:35.636152   808 net.cpp:198] bn3a_branch1 needs backward computation.
I0524 17:57:35.636154   808 net.cpp:198] res3a_branch1 needs backward computation.
I0524 17:57:35.636158   808 net.cpp:198] res2b_res2b_relu_0_split needs backward computation.
I0524 17:57:35.636162   808 net.cpp:198] res2b_relu needs backward computation.
I0524 17:57:35.636164   808 net.cpp:198] res2b needs backward computation.
I0524 17:57:35.636168   808 net.cpp:198] scale2b_branch2b needs backward computation.
I0524 17:57:35.636170   808 net.cpp:198] bn2b_branch2b needs backward computation.
I0524 17:57:35.636173   808 net.cpp:198] res2b_branch2b needs backward computation.
I0524 17:57:35.636178   808 net.cpp:198] res2b_branch2a_relu needs backward computation.
I0524 17:57:35.636180   808 net.cpp:198] scale2b_branch2a needs backward computation.
I0524 17:57:35.636183   808 net.cpp:198] bn2b_branch2a needs backward computation.
I0524 17:57:35.636186   808 net.cpp:198] res2b_branch2a needs backward computation.
I0524 17:57:35.636189   808 net.cpp:198] res2a_res2a_relu_0_split needs backward computation.
I0524 17:57:35.636193   808 net.cpp:198] res2a_relu needs backward computation.
I0524 17:57:35.636195   808 net.cpp:198] res2a needs backward computation.
I0524 17:57:35.636200   808 net.cpp:198] scale2a_branch2b needs backward computation.
I0524 17:57:35.636204   808 net.cpp:198] bn2a_branch2b needs backward computation.
I0524 17:57:35.636207   808 net.cpp:198] res2a_branch2b needs backward computation.
I0524 17:57:35.636210   808 net.cpp:198] res2a_branch2a_relu needs backward computation.
I0524 17:57:35.636214   808 net.cpp:198] scale2a_branch2a needs backward computation.
I0524 17:57:35.636216   808 net.cpp:198] bn2a_branch2a needs backward computation.
I0524 17:57:35.636219   808 net.cpp:198] res2a_branch2a needs backward computation.
I0524 17:57:35.636224   808 net.cpp:198] scale2a_branch1 needs backward computation.
I0524 17:57:35.636226   808 net.cpp:198] bn2a_branch1 needs backward computation.
I0524 17:57:35.636229   808 net.cpp:198] res2a_branch1 needs backward computation.
I0524 17:57:35.636232   808 net.cpp:198] pool1_pool1_0_split needs backward computation.
I0524 17:57:35.636235   808 net.cpp:198] pool1 needs backward computation.
I0524 17:57:35.636240   808 net.cpp:198] conv1_relu needs backward computation.
I0524 17:57:35.636242   808 net.cpp:198] scale_conv1 needs backward computation.
I0524 17:57:35.636245   808 net.cpp:198] bn_conv1 needs backward computation.
I0524 17:57:35.636248   808 net.cpp:198] conv1 needs backward computation.
I0524 17:57:35.636251   808 net.cpp:200] data does not need backward computation.
I0524 17:57:35.636255   808 net.cpp:242] This network produces output loss
I0524 17:57:35.636306   808 net.cpp:255] Network initialization done.
I0524 17:57:35.636476   808 solver.cpp:56] Solver scaffolding done.
I0524 17:57:35.640278   808 caffe.cpp:248] Starting Optimization
I0524 17:57:35.640288   808 solver.cpp:272] Solving ResNet-18
I0524 17:57:35.640291   808 solver.cpp:273] Learning Rate Policy: poly
I0524 17:57:36.127054   808 solver.cpp:218] Iteration 0 (0 iter/s, 0.48669s/100 iters), loss = 2.12697
I0524 17:57:36.127109   808 solver.cpp:237]     Train net output #0: loss = 2.12697 (* 1 = 2.12697 loss)
I0524 17:57:36.127125   808 sgd_solver.cpp:105] Iteration 0, lr = 0.05
I0524 17:58:18.950152   808 solver.cpp:218] Iteration 100 (2.33518 iter/s, 42.8233s/100 iters), loss = 1.86956
I0524 17:58:18.950249   808 solver.cpp:237]     Train net output #0: loss = 1.86956 (* 1 = 1.86956 loss)
I0524 17:58:18.950258   808 sgd_solver.cpp:105] Iteration 100, lr = 0.0499
I0524 17:59:01.957991   808 solver.cpp:218] Iteration 200 (2.32515 iter/s, 43.008s/100 iters), loss = 1.92952
I0524 17:59:01.958166   808 solver.cpp:237]     Train net output #0: loss = 1.92952 (* 1 = 1.92952 loss)
I0524 17:59:01.958180   808 sgd_solver.cpp:105] Iteration 200, lr = 0.0498
I0524 17:59:15.763579   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 17:59:44.944392   808 solver.cpp:218] Iteration 300 (2.32631 iter/s, 42.9865s/100 iters), loss = 1.79543
I0524 17:59:44.944558   808 solver.cpp:237]     Train net output #0: loss = 1.79543 (* 1 = 1.79543 loss)
I0524 17:59:44.944574   808 sgd_solver.cpp:105] Iteration 300, lr = 0.0497
I0524 18:00:27.943346   808 solver.cpp:218] Iteration 400 (2.32563 iter/s, 42.9991s/100 iters), loss = 1.8158
I0524 18:00:27.943500   808 solver.cpp:237]     Train net output #0: loss = 1.8158 (* 1 = 1.8158 loss)
I0524 18:00:27.943512   808 sgd_solver.cpp:105] Iteration 400, lr = 0.0496
I0524 18:00:57.227514   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:01:10.988453   808 solver.cpp:218] Iteration 500 (2.32314 iter/s, 43.0453s/100 iters), loss = 1.89335
I0524 18:01:10.988665   808 solver.cpp:237]     Train net output #0: loss = 1.89335 (* 1 = 1.89335 loss)
I0524 18:01:10.988679   808 sgd_solver.cpp:105] Iteration 500, lr = 0.0495
I0524 18:01:54.644857   808 solver.cpp:218] Iteration 600 (2.29061 iter/s, 43.6565s/100 iters), loss = 1.98937
I0524 18:01:54.645071   808 solver.cpp:237]     Train net output #0: loss = 1.98937 (* 1 = 1.98937 loss)
I0524 18:01:54.645081   808 sgd_solver.cpp:105] Iteration 600, lr = 0.0494
I0524 18:02:38.389245   808 solver.cpp:218] Iteration 700 (2.286 iter/s, 43.7445s/100 iters), loss = 1.91265
I0524 18:02:38.389364   808 solver.cpp:237]     Train net output #0: loss = 1.91265 (* 1 = 1.91265 loss)
I0524 18:02:38.389374   808 sgd_solver.cpp:105] Iteration 700, lr = 0.0493
I0524 18:02:40.596057   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:03:22.237679   808 solver.cpp:218] Iteration 800 (2.28057 iter/s, 43.8487s/100 iters), loss = 1.85036
I0524 18:03:22.237891   808 solver.cpp:237]     Train net output #0: loss = 1.85036 (* 1 = 1.85036 loss)
I0524 18:03:22.237902   808 sgd_solver.cpp:105] Iteration 800, lr = 0.0492
I0524 18:04:06.187676   808 solver.cpp:218] Iteration 900 (2.27531 iter/s, 43.9501s/100 iters), loss = 1.62555
I0524 18:04:06.187835   808 solver.cpp:237]     Train net output #0: loss = 1.62555 (* 1 = 1.62555 loss)
I0524 18:04:06.187849   808 sgd_solver.cpp:105] Iteration 900, lr = 0.0491
I0524 18:04:24.065608   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:04:49.037649   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_1000.caffemodel
I0524 18:04:49.209149   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_1000.solverstate
I0524 18:04:49.736119   808 solver.cpp:218] Iteration 1000 (2.29628 iter/s, 43.5486s/100 iters), loss = 1.40323
I0524 18:04:49.736182   808 solver.cpp:237]     Train net output #0: loss = 1.40323 (* 1 = 1.40323 loss)
I0524 18:04:49.736191   808 sgd_solver.cpp:105] Iteration 1000, lr = 0.049
I0524 18:05:32.868293   808 solver.cpp:218] Iteration 1100 (2.31844 iter/s, 43.1324s/100 iters), loss = 1.4301
I0524 18:05:32.868479   808 solver.cpp:237]     Train net output #0: loss = 1.4301 (* 1 = 1.4301 loss)
I0524 18:05:32.868492   808 sgd_solver.cpp:105] Iteration 1100, lr = 0.0489
I0524 18:06:06.559212   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:06:16.012269   808 solver.cpp:218] Iteration 1200 (2.31781 iter/s, 43.1441s/100 iters), loss = 1.78215
I0524 18:06:16.012331   808 solver.cpp:237]     Train net output #0: loss = 1.78215 (* 1 = 1.78215 loss)
I0524 18:06:16.012341   808 sgd_solver.cpp:105] Iteration 1200, lr = 0.0488
I0524 18:06:59.121861   808 solver.cpp:218] Iteration 1300 (2.31965 iter/s, 43.1099s/100 iters), loss = 1.40143
I0524 18:06:59.122068   808 solver.cpp:237]     Train net output #0: loss = 1.40143 (* 1 = 1.40143 loss)
I0524 18:06:59.122081   808 sgd_solver.cpp:105] Iteration 1300, lr = 0.0487
I0524 18:07:42.252488   808 solver.cpp:218] Iteration 1400 (2.31853 iter/s, 43.1308s/100 iters), loss = 1.26926
I0524 18:07:42.252606   808 solver.cpp:237]     Train net output #0: loss = 1.26926 (* 1 = 1.26926 loss)
I0524 18:07:42.252616   808 sgd_solver.cpp:105] Iteration 1400, lr = 0.0486
I0524 18:07:48.347239   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:08:25.373006   808 solver.cpp:218] Iteration 1500 (2.31907 iter/s, 43.1208s/100 iters), loss = 1.26381
I0524 18:08:25.373127   808 solver.cpp:237]     Train net output #0: loss = 1.26381 (* 1 = 1.26381 loss)
I0524 18:08:25.373148   808 sgd_solver.cpp:105] Iteration 1500, lr = 0.0485
I0524 18:09:08.493916   808 solver.cpp:218] Iteration 1600 (2.31905 iter/s, 43.121s/100 iters), loss = 1.26945
I0524 18:09:08.494037   808 solver.cpp:237]     Train net output #0: loss = 1.26945 (* 1 = 1.26945 loss)
I0524 18:09:08.494058   808 sgd_solver.cpp:105] Iteration 1600, lr = 0.0484
I0524 18:09:30.536023   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:09:51.633993   808 solver.cpp:218] Iteration 1700 (2.31803 iter/s, 43.14s/100 iters), loss = 1.36276
I0524 18:09:51.634105   808 solver.cpp:237]     Train net output #0: loss = 1.36276 (* 1 = 1.36276 loss)
I0524 18:09:51.634117   808 sgd_solver.cpp:105] Iteration 1700, lr = 0.0483
I0524 18:10:34.754959   808 solver.cpp:218] Iteration 1800 (2.31906 iter/s, 43.1209s/100 iters), loss = 1.11201
I0524 18:10:34.755177   808 solver.cpp:237]     Train net output #0: loss = 1.11201 (* 1 = 1.11201 loss)
I0524 18:10:34.755189   808 sgd_solver.cpp:105] Iteration 1800, lr = 0.0482
I0524 18:11:12.320175   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:11:17.886021   808 solver.cpp:218] Iteration 1900 (2.31852 iter/s, 43.1309s/100 iters), loss = 1.14219
I0524 18:11:17.886080   808 solver.cpp:237]     Train net output #0: loss = 1.14219 (* 1 = 1.14219 loss)
I0524 18:11:17.886090   808 sgd_solver.cpp:105] Iteration 1900, lr = 0.0481
I0524 18:12:00.568815   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_2000.caffemodel
I0524 18:12:00.722568   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_2000.solverstate
I0524 18:12:01.224892   808 solver.cpp:218] Iteration 2000 (2.30739 iter/s, 43.3389s/100 iters), loss = 0.945376
I0524 18:12:01.224941   808 solver.cpp:237]     Train net output #0: loss = 0.945376 (* 1 = 0.945376 loss)
I0524 18:12:01.224951   808 sgd_solver.cpp:105] Iteration 2000, lr = 0.048
I0524 18:12:44.341130   808 solver.cpp:218] Iteration 2100 (2.31931 iter/s, 43.1163s/100 iters), loss = 1.13756
I0524 18:12:44.341295   808 solver.cpp:237]     Train net output #0: loss = 1.13756 (* 1 = 1.13756 loss)
I0524 18:12:44.341306   808 sgd_solver.cpp:105] Iteration 2100, lr = 0.0479
I0524 18:12:54.739265   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:13:27.463222   808 solver.cpp:218] Iteration 2200 (2.319 iter/s, 43.1221s/100 iters), loss = 1.19289
I0524 18:13:27.463383   808 solver.cpp:237]     Train net output #0: loss = 1.19289 (* 1 = 1.19289 loss)
I0524 18:13:27.463397   808 sgd_solver.cpp:105] Iteration 2200, lr = 0.0478
I0524 18:14:10.573786   808 solver.cpp:218] Iteration 2300 (2.31962 iter/s, 43.1106s/100 iters), loss = 1.18607
I0524 18:14:10.573922   808 solver.cpp:237]     Train net output #0: loss = 1.18607 (* 1 = 1.18607 loss)
I0524 18:14:10.573933   808 sgd_solver.cpp:105] Iteration 2300, lr = 0.0477
I0524 18:14:36.501368   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:14:53.707993   808 solver.cpp:218] Iteration 2400 (2.31834 iter/s, 43.1343s/100 iters), loss = 0.983246
I0524 18:14:53.708264   808 solver.cpp:237]     Train net output #0: loss = 0.983246 (* 1 = 0.983246 loss)
I0524 18:14:53.708276   808 sgd_solver.cpp:105] Iteration 2400, lr = 0.0476
I0524 18:15:36.838116   808 solver.cpp:218] Iteration 2500 (2.31857 iter/s, 43.13s/100 iters), loss = 1.01681
I0524 18:15:36.838282   808 solver.cpp:237]     Train net output #0: loss = 1.01681 (* 1 = 1.01681 loss)
I0524 18:15:36.838297   808 sgd_solver.cpp:105] Iteration 2500, lr = 0.0475
I0524 18:16:18.704170   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:16:19.961041   808 solver.cpp:218] Iteration 2600 (2.31895 iter/s, 43.123s/100 iters), loss = 0.920798
I0524 18:16:19.961097   808 solver.cpp:237]     Train net output #0: loss = 0.920798 (* 1 = 0.920798 loss)
I0524 18:16:19.961107   808 sgd_solver.cpp:105] Iteration 2600, lr = 0.0474
I0524 18:17:03.082875   808 solver.cpp:218] Iteration 2700 (2.319 iter/s, 43.122s/100 iters), loss = 0.786183
I0524 18:17:03.082999   808 solver.cpp:237]     Train net output #0: loss = 0.786183 (* 1 = 0.786183 loss)
I0524 18:17:03.083011   808 sgd_solver.cpp:105] Iteration 2700, lr = 0.0473
I0524 18:17:46.209152   808 solver.cpp:218] Iteration 2800 (2.31877 iter/s, 43.1264s/100 iters), loss = 1.07746
I0524 18:17:46.209280   808 solver.cpp:237]     Train net output #0: loss = 1.07746 (* 1 = 1.07746 loss)
I0524 18:17:46.209290   808 sgd_solver.cpp:105] Iteration 2800, lr = 0.0472
I0524 18:18:00.494837   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:18:29.339136   808 solver.cpp:218] Iteration 2900 (2.31857 iter/s, 43.1301s/100 iters), loss = 0.88093
I0524 18:18:29.339267   808 solver.cpp:237]     Train net output #0: loss = 0.88093 (* 1 = 0.88093 loss)
I0524 18:18:29.339292   808 sgd_solver.cpp:105] Iteration 2900, lr = 0.0471
I0524 18:19:12.031543   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_3000.caffemodel
I0524 18:19:12.185204   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_3000.solverstate
I0524 18:19:12.687160   808 solver.cpp:218] Iteration 3000 (2.3069 iter/s, 43.3481s/100 iters), loss = 0.875695
I0524 18:19:12.687208   808 solver.cpp:237]     Train net output #0: loss = 0.875695 (* 1 = 0.875695 loss)
I0524 18:19:12.687217   808 sgd_solver.cpp:105] Iteration 3000, lr = 0.047
I0524 18:19:42.489334   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:19:55.814855   808 solver.cpp:218] Iteration 3100 (2.31869 iter/s, 43.1279s/100 iters), loss = 0.89295
I0524 18:19:55.814898   808 solver.cpp:237]     Train net output #0: loss = 0.89295 (* 1 = 0.89295 loss)
I0524 18:19:55.814906   808 sgd_solver.cpp:105] Iteration 3100, lr = 0.0469
I0524 18:20:38.945744   808 solver.cpp:218] Iteration 3200 (2.31851 iter/s, 43.1311s/100 iters), loss = 1.0985
I0524 18:20:38.945952   808 solver.cpp:237]     Train net output #0: loss = 1.0985 (* 1 = 1.0985 loss)
I0524 18:20:38.945963   808 sgd_solver.cpp:105] Iteration 3200, lr = 0.0468
I0524 18:21:22.067996   808 solver.cpp:218] Iteration 3300 (2.31898 iter/s, 43.1223s/100 iters), loss = 0.938949
I0524 18:21:22.068126   808 solver.cpp:237]     Train net output #0: loss = 0.938949 (* 1 = 0.938949 loss)
I0524 18:21:22.068138   808 sgd_solver.cpp:105] Iteration 3300, lr = 0.0467
I0524 18:21:24.704574   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:22:05.185473   808 solver.cpp:218] Iteration 3400 (2.31924 iter/s, 43.1176s/100 iters), loss = 0.912437
I0524 18:22:05.185665   808 solver.cpp:237]     Train net output #0: loss = 0.912437 (* 1 = 0.912437 loss)
I0524 18:22:05.185676   808 sgd_solver.cpp:105] Iteration 3400, lr = 0.0466
I0524 18:22:48.304702   808 solver.cpp:218] Iteration 3500 (2.31915 iter/s, 43.1193s/100 iters), loss = 0.8626
I0524 18:22:48.304872   808 solver.cpp:237]     Train net output #0: loss = 0.8626 (* 1 = 0.8626 loss)
I0524 18:22:48.304883   808 sgd_solver.cpp:105] Iteration 3500, lr = 0.0465
I0524 18:23:06.478118   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:23:31.445518   808 solver.cpp:218] Iteration 3600 (2.31798 iter/s, 43.1409s/100 iters), loss = 0.675389
I0524 18:23:31.445685   808 solver.cpp:237]     Train net output #0: loss = 0.675389 (* 1 = 0.675389 loss)
I0524 18:23:31.445695   808 sgd_solver.cpp:105] Iteration 3600, lr = 0.0464
I0524 18:24:14.560225   808 solver.cpp:218] Iteration 3700 (2.31939 iter/s, 43.1148s/100 iters), loss = 0.875679
I0524 18:24:14.560397   808 solver.cpp:237]     Train net output #0: loss = 0.875679 (* 1 = 0.875679 loss)
I0524 18:24:14.560410   808 sgd_solver.cpp:105] Iteration 3700, lr = 0.0463
I0524 18:24:48.658673   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:24:57.681409   808 solver.cpp:218] Iteration 3800 (2.31904 iter/s, 43.1213s/100 iters), loss = 0.715867
I0524 18:24:57.681454   808 solver.cpp:237]     Train net output #0: loss = 0.715867 (* 1 = 0.715867 loss)
I0524 18:24:57.681463   808 sgd_solver.cpp:105] Iteration 3800, lr = 0.0462
I0524 18:25:40.796038   808 solver.cpp:218] Iteration 3900 (2.31939 iter/s, 43.1149s/100 iters), loss = 0.792594
I0524 18:25:40.796161   808 solver.cpp:237]     Train net output #0: loss = 0.792594 (* 1 = 0.792594 loss)
I0524 18:25:40.796182   808 sgd_solver.cpp:105] Iteration 3900, lr = 0.0461
I0524 18:26:23.483986   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_4000.caffemodel
I0524 18:26:23.639073   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_4000.solverstate
I0524 18:26:24.141690   808 solver.cpp:218] Iteration 4000 (2.30703 iter/s, 43.3458s/100 iters), loss = 0.560642
I0524 18:26:24.141738   808 solver.cpp:237]     Train net output #0: loss = 0.560642 (* 1 = 0.560642 loss)
I0524 18:26:24.141747   808 sgd_solver.cpp:105] Iteration 4000, lr = 0.046
I0524 18:26:30.661384   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:27:07.271585   808 solver.cpp:218] Iteration 4100 (2.31856 iter/s, 43.1301s/100 iters), loss = 0.79508
I0524 18:27:07.271708   808 solver.cpp:237]     Train net output #0: loss = 0.79508 (* 1 = 0.79508 loss)
I0524 18:27:07.271728   808 sgd_solver.cpp:105] Iteration 4100, lr = 0.0459
I0524 18:27:50.396724   808 solver.cpp:218] Iteration 4200 (2.31882 iter/s, 43.1253s/100 iters), loss = 0.799669
I0524 18:27:50.396852   808 solver.cpp:237]     Train net output #0: loss = 0.799669 (* 1 = 0.799669 loss)
I0524 18:27:50.396863   808 sgd_solver.cpp:105] Iteration 4200, lr = 0.0458
I0524 18:28:12.871763   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:28:33.531726   808 solver.cpp:218] Iteration 4300 (2.31829 iter/s, 43.1352s/100 iters), loss = 0.549134
I0524 18:28:33.531848   808 solver.cpp:237]     Train net output #0: loss = 0.549134 (* 1 = 0.549134 loss)
I0524 18:28:33.531873   808 sgd_solver.cpp:105] Iteration 4300, lr = 0.0457
I0524 18:29:16.651367   808 solver.cpp:218] Iteration 4400 (2.31912 iter/s, 43.1198s/100 iters), loss = 0.667476
I0524 18:29:16.651499   808 solver.cpp:237]     Train net output #0: loss = 0.667476 (* 1 = 0.667476 loss)
I0524 18:29:16.651521   808 sgd_solver.cpp:105] Iteration 4400, lr = 0.0456
I0524 18:29:54.653707   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:29:59.789283   808 solver.cpp:218] Iteration 4500 (2.31814 iter/s, 43.1381s/100 iters), loss = 0.744355
I0524 18:29:59.789340   808 solver.cpp:237]     Train net output #0: loss = 0.744355 (* 1 = 0.744355 loss)
I0524 18:29:59.789350   808 sgd_solver.cpp:105] Iteration 4500, lr = 0.0455
I0524 18:30:42.906428   808 solver.cpp:218] Iteration 4600 (2.31925 iter/s, 43.1174s/100 iters), loss = 0.522066
I0524 18:30:42.906579   808 solver.cpp:237]     Train net output #0: loss = 0.522066 (* 1 = 0.522066 loss)
I0524 18:30:42.906590   808 sgd_solver.cpp:105] Iteration 4600, lr = 0.0454
I0524 18:31:26.029911   808 solver.cpp:218] Iteration 4700 (2.31891 iter/s, 43.1236s/100 iters), loss = 0.813485
I0524 18:31:26.030056   808 solver.cpp:237]     Train net output #0: loss = 0.813485 (* 1 = 0.813485 loss)
I0524 18:31:26.030066   808 sgd_solver.cpp:105] Iteration 4700, lr = 0.0453
I0524 18:31:36.857761   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:32:09.157788   808 solver.cpp:218] Iteration 4800 (2.31868 iter/s, 43.1281s/100 iters), loss = 0.917431
I0524 18:32:09.157914   808 solver.cpp:237]     Train net output #0: loss = 0.917431 (* 1 = 0.917431 loss)
I0524 18:32:09.157927   808 sgd_solver.cpp:105] Iteration 4800, lr = 0.0452
I0524 18:32:52.273603   808 solver.cpp:218] Iteration 4900 (2.31932 iter/s, 43.116s/100 iters), loss = 0.760811
I0524 18:32:52.273722   808 solver.cpp:237]     Train net output #0: loss = 0.760811 (* 1 = 0.760811 loss)
I0524 18:32:52.273737   808 sgd_solver.cpp:105] Iteration 4900, lr = 0.0451
I0524 18:33:18.632026   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:33:34.981312   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_5000.caffemodel
I0524 18:33:35.136287   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_5000.solverstate
I0524 18:33:35.638797   808 solver.cpp:218] Iteration 5000 (2.30599 iter/s, 43.3654s/100 iters), loss = 0.575577
I0524 18:33:35.638846   808 solver.cpp:237]     Train net output #0: loss = 0.575577 (* 1 = 0.575577 loss)
I0524 18:33:35.638855   808 sgd_solver.cpp:105] Iteration 5000, lr = 0.045
I0524 18:34:18.760000   808 solver.cpp:218] Iteration 5100 (2.31903 iter/s, 43.1215s/100 iters), loss = 0.708675
I0524 18:34:18.760165   808 solver.cpp:237]     Train net output #0: loss = 0.708675 (* 1 = 0.708675 loss)
I0524 18:34:18.760177   808 sgd_solver.cpp:105] Iteration 5100, lr = 0.0449
I0524 18:35:01.763821   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:35:02.610416   808 solver.cpp:218] Iteration 5200 (2.28047 iter/s, 43.8506s/100 iters), loss = 0.767527
I0524 18:35:02.610465   808 solver.cpp:237]     Train net output #0: loss = 0.767527 (* 1 = 0.767527 loss)
I0524 18:35:02.610472   808 sgd_solver.cpp:105] Iteration 5200, lr = 0.0448
I0524 18:35:45.782146   808 solver.cpp:218] Iteration 5300 (2.31632 iter/s, 43.172s/100 iters), loss = 0.629197
I0524 18:35:45.782310   808 solver.cpp:237]     Train net output #0: loss = 0.629197 (* 1 = 0.629197 loss)
I0524 18:35:45.782320   808 sgd_solver.cpp:105] Iteration 5300, lr = 0.0447
I0524 18:36:28.954812   808 solver.cpp:218] Iteration 5400 (2.31627 iter/s, 43.1728s/100 iters), loss = 0.531538
I0524 18:36:28.954944   808 solver.cpp:237]     Train net output #0: loss = 0.531538 (* 1 = 0.531538 loss)
I0524 18:36:28.954955   808 sgd_solver.cpp:105] Iteration 5400, lr = 0.0446
I0524 18:36:43.682282   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:37:12.125998   808 solver.cpp:218] Iteration 5500 (2.31639 iter/s, 43.1706s/100 iters), loss = 0.686761
I0524 18:37:12.126170   808 solver.cpp:237]     Train net output #0: loss = 0.686761 (* 1 = 0.686761 loss)
I0524 18:37:12.126183   808 sgd_solver.cpp:105] Iteration 5500, lr = 0.0445
I0524 18:37:55.293942   808 solver.cpp:218] Iteration 5600 (2.31653 iter/s, 43.1681s/100 iters), loss = 0.584612
I0524 18:37:55.294057   808 solver.cpp:237]     Train net output #0: loss = 0.584612 (* 1 = 0.584612 loss)
I0524 18:37:55.294067   808 sgd_solver.cpp:105] Iteration 5600, lr = 0.0444
I0524 18:38:25.986865   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:38:38.465337   808 solver.cpp:218] Iteration 5700 (2.31634 iter/s, 43.1716s/100 iters), loss = 0.543017
I0524 18:38:38.465392   808 solver.cpp:237]     Train net output #0: loss = 0.543017 (* 1 = 0.543017 loss)
I0524 18:38:38.465401   808 sgd_solver.cpp:105] Iteration 5700, lr = 0.0443
I0524 18:39:21.638242   808 solver.cpp:218] Iteration 5800 (2.31625 iter/s, 43.1732s/100 iters), loss = 0.601366
I0524 18:39:21.638375   808 solver.cpp:237]     Train net output #0: loss = 0.601366 (* 1 = 0.601366 loss)
I0524 18:39:21.638386   808 sgd_solver.cpp:105] Iteration 5800, lr = 0.0442
I0524 18:40:04.807708   808 solver.cpp:218] Iteration 5900 (2.31644 iter/s, 43.1696s/100 iters), loss = 0.438864
I0524 18:40:04.807826   808 solver.cpp:237]     Train net output #0: loss = 0.438864 (* 1 = 0.438864 loss)
I0524 18:40:04.807837   808 sgd_solver.cpp:105] Iteration 5900, lr = 0.0441
I0524 18:40:07.873718   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:40:47.536078   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_6000.caffemodel
I0524 18:40:47.688382   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_6000.solverstate
I0524 18:40:48.190551   808 solver.cpp:218] Iteration 6000 (2.30505 iter/s, 43.383s/100 iters), loss = 0.405759
I0524 18:40:48.190599   808 solver.cpp:237]     Train net output #0: loss = 0.405759 (* 1 = 0.405759 loss)
I0524 18:40:48.190608   808 sgd_solver.cpp:105] Iteration 6000, lr = 0.044
I0524 18:41:31.360267   808 solver.cpp:218] Iteration 6100 (2.31642 iter/s, 43.17s/100 iters), loss = 0.359334
I0524 18:41:31.360383   808 solver.cpp:237]     Train net output #0: loss = 0.359334 (* 1 = 0.359334 loss)
I0524 18:41:31.360404   808 sgd_solver.cpp:105] Iteration 6100, lr = 0.0439
I0524 18:41:49.956636   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:42:14.531266   808 solver.cpp:218] Iteration 6200 (2.31636 iter/s, 43.1712s/100 iters), loss = 0.409587
I0524 18:42:14.531394   808 solver.cpp:237]     Train net output #0: loss = 0.409587 (* 1 = 0.409587 loss)
I0524 18:42:14.531404   808 sgd_solver.cpp:105] Iteration 6200, lr = 0.0438
I0524 18:42:57.694754   808 solver.cpp:218] Iteration 6300 (2.31676 iter/s, 43.1637s/100 iters), loss = 0.660634
I0524 18:42:57.694876   808 solver.cpp:237]     Train net output #0: loss = 0.660634 (* 1 = 0.660634 loss)
I0524 18:42:57.694888   808 sgd_solver.cpp:105] Iteration 6300, lr = 0.0437
I0524 18:43:32.279953   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:43:40.866578   808 solver.cpp:218] Iteration 6400 (2.31631 iter/s, 43.172s/100 iters), loss = 0.619867
I0524 18:43:40.866627   808 solver.cpp:237]     Train net output #0: loss = 0.619867 (* 1 = 0.619867 loss)
I0524 18:43:40.866650   808 sgd_solver.cpp:105] Iteration 6400, lr = 0.0436
I0524 18:44:24.037820   808 solver.cpp:218] Iteration 6500 (2.31634 iter/s, 43.1715s/100 iters), loss = 0.399891
I0524 18:44:24.038000   808 solver.cpp:237]     Train net output #0: loss = 0.399891 (* 1 = 0.399891 loss)
I0524 18:44:24.038017   808 sgd_solver.cpp:105] Iteration 6500, lr = 0.0435
I0524 18:45:07.207952   808 solver.cpp:218] Iteration 6600 (2.31641 iter/s, 43.1703s/100 iters), loss = 0.512759
I0524 18:45:07.208091   808 solver.cpp:237]     Train net output #0: loss = 0.512759 (* 1 = 0.512759 loss)
I0524 18:45:07.208103   808 sgd_solver.cpp:105] Iteration 6600, lr = 0.0434
I0524 18:45:14.165318   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:45:50.370549   808 solver.cpp:218] Iteration 6700 (2.31681 iter/s, 43.1628s/100 iters), loss = 0.474563
I0524 18:45:50.370666   808 solver.cpp:237]     Train net output #0: loss = 0.474563 (* 1 = 0.474563 loss)
I0524 18:45:50.370676   808 sgd_solver.cpp:105] Iteration 6700, lr = 0.0433
I0524 18:46:33.536837   808 solver.cpp:218] Iteration 6800 (2.31661 iter/s, 43.1665s/100 iters), loss = 0.605833
I0524 18:46:33.536950   808 solver.cpp:237]     Train net output #0: loss = 0.605833 (* 1 = 0.605833 loss)
I0524 18:46:33.536960   808 sgd_solver.cpp:105] Iteration 6800, lr = 0.0432
I0524 18:46:56.458492   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:47:16.706836   808 solver.cpp:218] Iteration 6900 (2.31641 iter/s, 43.1702s/100 iters), loss = 0.521877
I0524 18:47:16.706981   808 solver.cpp:237]     Train net output #0: loss = 0.521877 (* 1 = 0.521877 loss)
I0524 18:47:16.706992   808 sgd_solver.cpp:105] Iteration 6900, lr = 0.0431
I0524 18:47:59.448846   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_7000.caffemodel
I0524 18:47:59.600508   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_7000.solverstate
I0524 18:48:00.102582   808 solver.cpp:218] Iteration 7000 (2.30436 iter/s, 43.3959s/100 iters), loss = 0.484893
I0524 18:48:00.102648   808 solver.cpp:237]     Train net output #0: loss = 0.484893 (* 1 = 0.484893 loss)
I0524 18:48:00.102658   808 sgd_solver.cpp:105] Iteration 7000, lr = 0.043
I0524 18:48:38.567062   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:48:43.267194   808 solver.cpp:218] Iteration 7100 (2.3167 iter/s, 43.1648s/100 iters), loss = 0.516166
I0524 18:48:43.267237   808 solver.cpp:237]     Train net output #0: loss = 0.516166 (* 1 = 0.516166 loss)
I0524 18:48:43.267246   808 sgd_solver.cpp:105] Iteration 7100, lr = 0.0429
I0524 18:49:26.436661   808 solver.cpp:218] Iteration 7200 (2.31644 iter/s, 43.1697s/100 iters), loss = 0.269137
I0524 18:49:26.436821   808 solver.cpp:237]     Train net output #0: loss = 0.269137 (* 1 = 0.269137 loss)
I0524 18:49:26.436833   808 sgd_solver.cpp:105] Iteration 7200, lr = 0.0428
I0524 18:50:09.613225   808 solver.cpp:218] Iteration 7300 (2.31606 iter/s, 43.1767s/100 iters), loss = 0.53013
I0524 18:50:09.613345   808 solver.cpp:237]     Train net output #0: loss = 0.53013 (* 1 = 0.53013 loss)
I0524 18:50:09.613355   808 sgd_solver.cpp:105] Iteration 7300, lr = 0.0427
I0524 18:50:20.877395   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:50:52.782904   808 solver.cpp:218] Iteration 7400 (2.31643 iter/s, 43.1699s/100 iters), loss = 0.626729
I0524 18:50:52.783021   808 solver.cpp:237]     Train net output #0: loss = 0.626729 (* 1 = 0.626729 loss)
I0524 18:50:52.783030   808 sgd_solver.cpp:105] Iteration 7400, lr = 0.0426
I0524 18:51:35.962687   808 solver.cpp:218] Iteration 7500 (2.31589 iter/s, 43.18s/100 iters), loss = 0.499902
I0524 18:51:35.962867   808 solver.cpp:237]     Train net output #0: loss = 0.499902 (* 1 = 0.499902 loss)
I0524 18:51:35.962879   808 sgd_solver.cpp:105] Iteration 7500, lr = 0.0425
I0524 18:52:02.784737   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:52:19.142503   808 solver.cpp:218] Iteration 7600 (2.31589 iter/s, 43.18s/100 iters), loss = 0.326191
I0524 18:52:19.142673   808 solver.cpp:237]     Train net output #0: loss = 0.326191 (* 1 = 0.326191 loss)
I0524 18:52:19.142685   808 sgd_solver.cpp:105] Iteration 7600, lr = 0.0424
I0524 18:53:02.369925   808 solver.cpp:218] Iteration 7700 (2.31334 iter/s, 43.2276s/100 iters), loss = 0.256356
I0524 18:53:02.370064   808 solver.cpp:237]     Train net output #0: loss = 0.256356 (* 1 = 0.256356 loss)
I0524 18:53:02.370074   808 sgd_solver.cpp:105] Iteration 7700, lr = 0.0423
I0524 18:53:46.204834   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:53:46.630627   808 solver.cpp:218] Iteration 7800 (2.25933 iter/s, 44.2609s/100 iters), loss = 0.382139
I0524 18:53:46.630697   808 solver.cpp:237]     Train net output #0: loss = 0.382139 (* 1 = 0.382139 loss)
I0524 18:53:46.630707   808 sgd_solver.cpp:105] Iteration 7800, lr = 0.0422
I0524 18:54:30.807734   808 solver.cpp:218] Iteration 7900 (2.2636 iter/s, 44.1774s/100 iters), loss = 0.438546
I0524 18:54:30.807857   808 solver.cpp:237]     Train net output #0: loss = 0.438546 (* 1 = 0.438546 loss)
I0524 18:54:30.807867   808 sgd_solver.cpp:105] Iteration 7900, lr = 0.0421
I0524 18:55:14.111697   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_8000.caffemodel
I0524 18:55:14.274274   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_8000.solverstate
I0524 18:55:14.806318   808 solver.cpp:218] Iteration 8000 (2.27279 iter/s, 43.9988s/100 iters), loss = 0.393863
I0524 18:55:14.806375   808 solver.cpp:237]     Train net output #0: loss = 0.393863 (* 1 = 0.393863 loss)
I0524 18:55:14.806385   808 sgd_solver.cpp:105] Iteration 8000, lr = 0.042
I0524 18:55:30.170869   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:55:58.150233   808 solver.cpp:218] Iteration 8100 (2.30711 iter/s, 43.3442s/100 iters), loss = 0.678209
I0524 18:55:58.150475   808 solver.cpp:237]     Train net output #0: loss = 0.678209 (* 1 = 0.678209 loss)
I0524 18:55:58.150486   808 sgd_solver.cpp:105] Iteration 8100, lr = 0.0419
I0524 18:56:42.300042   808 solver.cpp:218] Iteration 8200 (2.26501 iter/s, 44.1499s/100 iters), loss = 0.495079
I0524 18:56:42.300132   808 solver.cpp:237]     Train net output #0: loss = 0.495079 (* 1 = 0.495079 loss)
I0524 18:56:42.300143   808 sgd_solver.cpp:105] Iteration 8200, lr = 0.0418
I0524 18:57:14.547730   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:57:26.812600   808 solver.cpp:218] Iteration 8300 (2.24654 iter/s, 44.5128s/100 iters), loss = 0.19011
I0524 18:57:26.812669   808 solver.cpp:237]     Train net output #0: loss = 0.19011 (* 1 = 0.19011 loss)
I0524 18:57:26.812680   808 sgd_solver.cpp:105] Iteration 8300, lr = 0.0417
I0524 18:58:11.307626   808 solver.cpp:218] Iteration 8400 (2.24743 iter/s, 44.4953s/100 iters), loss = 0.347376
I0524 18:58:11.307824   808 solver.cpp:237]     Train net output #0: loss = 0.347376 (* 1 = 0.347376 loss)
I0524 18:58:11.307840   808 sgd_solver.cpp:105] Iteration 8400, lr = 0.0416
I0524 18:58:55.167547   808 solver.cpp:218] Iteration 8500 (2.27998 iter/s, 43.8601s/100 iters), loss = 0.500428
I0524 18:58:55.167678   808 solver.cpp:237]     Train net output #0: loss = 0.500427 (* 1 = 0.500427 loss)
I0524 18:58:55.167688   808 sgd_solver.cpp:105] Iteration 8500, lr = 0.0415
I0524 18:58:58.665083   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 18:59:39.337307   808 solver.cpp:218] Iteration 8600 (2.26398 iter/s, 44.17s/100 iters), loss = 0.499826
I0524 18:59:39.337482   808 solver.cpp:237]     Train net output #0: loss = 0.499826 (* 1 = 0.499826 loss)
I0524 18:59:39.337522   808 sgd_solver.cpp:105] Iteration 8600, lr = 0.0414
I0524 19:00:23.814275   808 solver.cpp:218] Iteration 8700 (2.24835 iter/s, 44.4771s/100 iters), loss = 0.183043
I0524 19:00:23.814404   808 solver.cpp:237]     Train net output #0: loss = 0.183043 (* 1 = 0.183043 loss)
I0524 19:00:23.814414   808 sgd_solver.cpp:105] Iteration 8700, lr = 0.0413
I0524 19:00:43.758183   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:01:07.861377   808 solver.cpp:218] Iteration 8800 (2.27029 iter/s, 44.0473s/100 iters), loss = 0.344395
I0524 19:01:07.861506   808 solver.cpp:237]     Train net output #0: loss = 0.344395 (* 1 = 0.344395 loss)
I0524 19:01:07.861516   808 sgd_solver.cpp:105] Iteration 8800, lr = 0.0412
I0524 19:01:50.965867   808 solver.cpp:218] Iteration 8900 (2.31993 iter/s, 43.1047s/100 iters), loss = 0.473301
I0524 19:01:50.965992   808 solver.cpp:237]     Train net output #0: loss = 0.473301 (* 1 = 0.473301 loss)
I0524 19:01:50.966003   808 sgd_solver.cpp:105] Iteration 8900, lr = 0.0411
I0524 19:02:25.920485   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:02:33.665406   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_9000.caffemodel
I0524 19:02:33.817560   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_9000.solverstate
I0524 19:02:34.320374   808 solver.cpp:218] Iteration 9000 (2.30655 iter/s, 43.3547s/100 iters), loss = 0.246305
I0524 19:02:34.320420   808 solver.cpp:237]     Train net output #0: loss = 0.246305 (* 1 = 0.246305 loss)
I0524 19:02:34.320428   808 sgd_solver.cpp:105] Iteration 9000, lr = 0.041
I0524 19:03:17.604357   808 solver.cpp:218] Iteration 9100 (2.31031 iter/s, 43.2843s/100 iters), loss = 0.353433
I0524 19:03:17.604549   808 solver.cpp:237]     Train net output #0: loss = 0.353433 (* 1 = 0.353433 loss)
I0524 19:03:17.604560   808 sgd_solver.cpp:105] Iteration 9100, lr = 0.0409
I0524 19:04:00.722846   808 solver.cpp:218] Iteration 9200 (2.31918 iter/s, 43.1186s/100 iters), loss = 0.347696
I0524 19:04:00.724200   808 solver.cpp:237]     Train net output #0: loss = 0.347695 (* 1 = 0.347695 loss)
I0524 19:04:00.724213   808 sgd_solver.cpp:105] Iteration 9200, lr = 0.0408
I0524 19:04:08.114145   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:04:43.840273   808 solver.cpp:218] Iteration 9300 (2.3193 iter/s, 43.1164s/100 iters), loss = 0.19389
I0524 19:04:43.840394   808 solver.cpp:237]     Train net output #0: loss = 0.19389 (* 1 = 0.19389 loss)
I0524 19:04:43.840404   808 sgd_solver.cpp:105] Iteration 9300, lr = 0.0407
I0524 19:05:26.964797   808 solver.cpp:218] Iteration 9400 (2.31886 iter/s, 43.1247s/100 iters), loss = 0.436409
I0524 19:05:26.964963   808 solver.cpp:237]     Train net output #0: loss = 0.436409 (* 1 = 0.436409 loss)
I0524 19:05:26.964975   808 sgd_solver.cpp:105] Iteration 9400, lr = 0.0406
I0524 19:05:50.294824   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:06:10.096405   808 solver.cpp:218] Iteration 9500 (2.31848 iter/s, 43.1318s/100 iters), loss = 0.261037
I0524 19:06:10.096722   808 solver.cpp:237]     Train net output #0: loss = 0.261036 (* 1 = 0.261036 loss)
I0524 19:06:10.096734   808 sgd_solver.cpp:105] Iteration 9500, lr = 0.0405
I0524 19:06:53.204438   808 solver.cpp:218] Iteration 9600 (2.31975 iter/s, 43.108s/100 iters), loss = 0.238125
I0524 19:06:53.204560   808 solver.cpp:237]     Train net output #0: loss = 0.238125 (* 1 = 0.238125 loss)
I0524 19:06:53.204582   808 sgd_solver.cpp:105] Iteration 9600, lr = 0.0404
I0524 19:07:32.070397   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:07:36.336658   808 solver.cpp:218] Iteration 9700 (2.31844 iter/s, 43.1324s/100 iters), loss = 0.431476
I0524 19:07:36.336714   808 solver.cpp:237]     Train net output #0: loss = 0.431476 (* 1 = 0.431476 loss)
I0524 19:07:36.336722   808 sgd_solver.cpp:105] Iteration 9700, lr = 0.0403
I0524 19:08:19.452134   808 solver.cpp:218] Iteration 9800 (2.31934 iter/s, 43.1157s/100 iters), loss = 0.461592
I0524 19:08:19.452267   808 solver.cpp:237]     Train net output #0: loss = 0.461591 (* 1 = 0.461591 loss)
I0524 19:08:19.452289   808 sgd_solver.cpp:105] Iteration 9800, lr = 0.0402
I0524 19:09:02.572069   808 solver.cpp:218] Iteration 9900 (2.3191 iter/s, 43.1201s/100 iters), loss = 0.344118
I0524 19:09:02.572229   808 solver.cpp:237]     Train net output #0: loss = 0.344118 (* 1 = 0.344118 loss)
I0524 19:09:02.572240   808 sgd_solver.cpp:105] Iteration 9900, lr = 0.0401
I0524 19:09:14.267665   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:09:45.279814   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_10000.caffemodel
I0524 19:09:45.432448   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_10000.solverstate
I0524 19:09:45.934573   808 solver.cpp:218] Iteration 10000 (2.30613 iter/s, 43.3627s/100 iters), loss = 0.249436
I0524 19:09:45.934631   808 solver.cpp:237]     Train net output #0: loss = 0.249435 (* 1 = 0.249435 loss)
I0524 19:09:45.934639   808 sgd_solver.cpp:105] Iteration 10000, lr = 0.04
I0524 19:10:29.050071   808 solver.cpp:218] Iteration 10100 (2.31934 iter/s, 43.1158s/100 iters), loss = 0.365564
I0524 19:10:29.050211   808 solver.cpp:237]     Train net output #0: loss = 0.365564 (* 1 = 0.365564 loss)
I0524 19:10:29.050221   808 sgd_solver.cpp:105] Iteration 10100, lr = 0.0399
I0524 19:10:56.265120   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:11:12.178359   808 solver.cpp:218] Iteration 10200 (2.31865 iter/s, 43.1285s/100 iters), loss = 0.245804
I0524 19:11:12.178562   808 solver.cpp:237]     Train net output #0: loss = 0.245804 (* 1 = 0.245804 loss)
I0524 19:11:12.178575   808 sgd_solver.cpp:105] Iteration 10200, lr = 0.0398
I0524 19:11:55.291782   808 solver.cpp:218] Iteration 10300 (2.31945 iter/s, 43.1136s/100 iters), loss = 0.343601
I0524 19:11:55.291939   808 solver.cpp:237]     Train net output #0: loss = 0.3436 (* 1 = 0.3436 loss)
I0524 19:11:55.291960   808 sgd_solver.cpp:105] Iteration 10300, lr = 0.0397
I0524 19:12:38.414958   808 solver.cpp:218] Iteration 10400 (2.31893 iter/s, 43.1234s/100 iters), loss = 0.344207
I0524 19:12:38.415077   808 solver.cpp:237]     Train net output #0: loss = 0.344207 (* 1 = 0.344207 loss)
I0524 19:12:38.415102   808 sgd_solver.cpp:105] Iteration 10400, lr = 0.0396
I0524 19:12:38.457763   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:13:21.542742   808 solver.cpp:218] Iteration 10500 (2.31868 iter/s, 43.128s/100 iters), loss = 0.229806
I0524 19:13:21.542858   808 solver.cpp:237]     Train net output #0: loss = 0.229806 (* 1 = 0.229806 loss)
I0524 19:13:21.542881   808 sgd_solver.cpp:105] Iteration 10500, lr = 0.0395
I0524 19:14:04.656028   808 solver.cpp:218] Iteration 10600 (2.31946 iter/s, 43.1135s/100 iters), loss = 0.289016
I0524 19:14:04.656190   808 solver.cpp:237]     Train net output #0: loss = 0.289016 (* 1 = 0.289016 loss)
I0524 19:14:04.656205   808 sgd_solver.cpp:105] Iteration 10600, lr = 0.0394
I0524 19:14:20.234860   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:14:47.790031   808 solver.cpp:218] Iteration 10700 (2.31835 iter/s, 43.1342s/100 iters), loss = 0.224415
I0524 19:14:47.790153   808 solver.cpp:237]     Train net output #0: loss = 0.224414 (* 1 = 0.224414 loss)
I0524 19:14:47.790165   808 sgd_solver.cpp:105] Iteration 10700, lr = 0.0393
I0524 19:15:30.917773   808 solver.cpp:218] Iteration 10800 (2.31868 iter/s, 43.1279s/100 iters), loss = 0.206181
I0524 19:15:30.917937   808 solver.cpp:237]     Train net output #0: loss = 0.20618 (* 1 = 0.20618 loss)
I0524 19:15:30.917949   808 sgd_solver.cpp:105] Iteration 10800, lr = 0.0392
I0524 19:16:02.445665   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:16:14.057878   808 solver.cpp:218] Iteration 10900 (2.31802 iter/s, 43.1403s/100 iters), loss = 0.326311
I0524 19:16:14.057938   808 solver.cpp:237]     Train net output #0: loss = 0.326311 (* 1 = 0.326311 loss)
I0524 19:16:14.057947   808 sgd_solver.cpp:105] Iteration 10900, lr = 0.0391
I0524 19:16:56.749644   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_11000.caffemodel
I0524 19:16:56.902560   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_11000.solverstate
I0524 19:16:57.404573   808 solver.cpp:218] Iteration 11000 (2.30697 iter/s, 43.347s/100 iters), loss = 0.244834
I0524 19:16:57.404619   808 solver.cpp:237]     Train net output #0: loss = 0.244833 (* 1 = 0.244833 loss)
I0524 19:16:57.404628   808 sgd_solver.cpp:105] Iteration 11000, lr = 0.039
I0524 19:17:40.525252   808 solver.cpp:218] Iteration 11100 (2.31906 iter/s, 43.121s/100 iters), loss = 0.376595
I0524 19:17:40.525370   808 solver.cpp:237]     Train net output #0: loss = 0.376595 (* 1 = 0.376595 loss)
I0524 19:17:40.525379   808 sgd_solver.cpp:105] Iteration 11100, lr = 0.0389
I0524 19:17:44.456213   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:18:23.631386   808 solver.cpp:218] Iteration 11200 (2.31984 iter/s, 43.1064s/100 iters), loss = 0.359132
I0524 19:18:23.631510   808 solver.cpp:237]     Train net output #0: loss = 0.359132 (* 1 = 0.359132 loss)
I0524 19:18:23.631531   808 sgd_solver.cpp:105] Iteration 11200, lr = 0.0388
I0524 19:19:06.746928   808 solver.cpp:218] Iteration 11300 (2.31934 iter/s, 43.1157s/100 iters), loss = 0.183382
I0524 19:19:06.747088   808 solver.cpp:237]     Train net output #0: loss = 0.183381 (* 1 = 0.183381 loss)
I0524 19:19:06.747099   808 sgd_solver.cpp:105] Iteration 11300, lr = 0.0387
I0524 19:19:26.626524   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:19:49.875260   808 solver.cpp:218] Iteration 11400 (2.31863 iter/s, 43.1289s/100 iters), loss = 0.268217
I0524 19:19:49.875411   808 solver.cpp:237]     Train net output #0: loss = 0.268217 (* 1 = 0.268217 loss)
I0524 19:19:49.875419   808 sgd_solver.cpp:105] Iteration 11400, lr = 0.0386
I0524 19:20:32.996773   808 solver.cpp:218] Iteration 11500 (2.31897 iter/s, 43.1225s/100 iters), loss = 0.323697
I0524 19:20:32.996896   808 solver.cpp:237]     Train net output #0: loss = 0.323697 (* 1 = 0.323697 loss)
I0524 19:20:32.996906   808 sgd_solver.cpp:105] Iteration 11500, lr = 0.0385
I0524 19:21:08.400375   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:21:16.127878   808 solver.cpp:218] Iteration 11600 (2.31846 iter/s, 43.1321s/100 iters), loss = 0.222808
I0524 19:21:16.127929   808 solver.cpp:237]     Train net output #0: loss = 0.222807 (* 1 = 0.222807 loss)
I0524 19:21:16.127938   808 sgd_solver.cpp:105] Iteration 11600, lr = 0.0384
I0524 19:21:59.232983   808 solver.cpp:218] Iteration 11700 (2.31986 iter/s, 43.1061s/100 iters), loss = 0.470569
I0524 19:21:59.233104   808 solver.cpp:237]     Train net output #0: loss = 0.470569 (* 1 = 0.470569 loss)
I0524 19:21:59.233130   808 sgd_solver.cpp:105] Iteration 11700, lr = 0.0383
I0524 19:22:42.344521   808 solver.cpp:218] Iteration 11800 (2.31952 iter/s, 43.1124s/100 iters), loss = 0.274573
I0524 19:22:42.344669   808 solver.cpp:237]     Train net output #0: loss = 0.274573 (* 1 = 0.274573 loss)
I0524 19:22:42.344683   808 sgd_solver.cpp:105] Iteration 11800, lr = 0.0382
I0524 19:22:50.166177   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:23:25.480953   808 solver.cpp:218] Iteration 11900 (2.31818 iter/s, 43.1372s/100 iters), loss = 0.171361
I0524 19:23:25.481164   808 solver.cpp:237]     Train net output #0: loss = 0.17136 (* 1 = 0.17136 loss)
I0524 19:23:25.481180   808 sgd_solver.cpp:105] Iteration 11900, lr = 0.0381
I0524 19:24:08.206620   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_12000.caffemodel
I0524 19:24:08.359066   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_12000.solverstate
I0524 19:24:08.860754   808 solver.cpp:218] Iteration 12000 (2.30518 iter/s, 43.3805s/100 iters), loss = 0.241572
I0524 19:24:08.860805   808 solver.cpp:237]     Train net output #0: loss = 0.241571 (* 1 = 0.241571 loss)
I0524 19:24:08.860818   808 sgd_solver.cpp:105] Iteration 12000, lr = 0.038
I0524 19:24:32.623018   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:24:51.991066   808 solver.cpp:218] Iteration 12100 (2.31851 iter/s, 43.1311s/100 iters), loss = 0.351555
I0524 19:24:51.991210   808 solver.cpp:237]     Train net output #0: loss = 0.351555 (* 1 = 0.351555 loss)
I0524 19:24:51.991224   808 sgd_solver.cpp:105] Iteration 12100, lr = 0.0379
I0524 19:25:35.110208   808 solver.cpp:218] Iteration 12200 (2.31912 iter/s, 43.1198s/100 iters), loss = 0.143191
I0524 19:25:35.110335   808 solver.cpp:237]     Train net output #0: loss = 0.143191 (* 1 = 0.143191 loss)
I0524 19:25:35.110363   808 sgd_solver.cpp:105] Iteration 12200, lr = 0.0378
I0524 19:26:14.406672   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:26:18.239790   808 solver.cpp:218] Iteration 12300 (2.31856 iter/s, 43.1303s/100 iters), loss = 0.158583
I0524 19:26:18.239836   808 solver.cpp:237]     Train net output #0: loss = 0.158583 (* 1 = 0.158583 loss)
I0524 19:26:18.239845   808 sgd_solver.cpp:105] Iteration 12300, lr = 0.0377
I0524 19:27:01.511464   808 solver.cpp:218] Iteration 12400 (2.31094 iter/s, 43.2724s/100 iters), loss = 0.388854
I0524 19:27:01.511657   808 solver.cpp:237]     Train net output #0: loss = 0.388853 (* 1 = 0.388853 loss)
I0524 19:27:01.511683   808 sgd_solver.cpp:105] Iteration 12400, lr = 0.0376
I0524 19:27:44.684451   808 solver.cpp:218] Iteration 12500 (2.31623 iter/s, 43.1736s/100 iters), loss = 0.209716
I0524 19:27:44.684631   808 solver.cpp:237]     Train net output #0: loss = 0.209716 (* 1 = 0.209716 loss)
I0524 19:27:44.684648   808 sgd_solver.cpp:105] Iteration 12500, lr = 0.0375
I0524 19:27:56.822612   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:28:27.856969   808 solver.cpp:218] Iteration 12600 (2.31626 iter/s, 43.1731s/100 iters), loss = 0.416421
I0524 19:28:27.857118   808 solver.cpp:237]     Train net output #0: loss = 0.416421 (* 1 = 0.416421 loss)
I0524 19:28:27.857128   808 sgd_solver.cpp:105] Iteration 12600, lr = 0.0374
I0524 19:29:11.033335   808 solver.cpp:218] Iteration 12700 (2.31605 iter/s, 43.1769s/100 iters), loss = 0.241681
I0524 19:29:11.033511   808 solver.cpp:237]     Train net output #0: loss = 0.24168 (* 1 = 0.24168 loss)
I0524 19:29:11.033525   808 sgd_solver.cpp:105] Iteration 12700, lr = 0.0373
I0524 19:29:38.716986   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:29:54.207409   808 solver.cpp:218] Iteration 12800 (2.31618 iter/s, 43.1746s/100 iters), loss = 0.173358
I0524 19:29:54.207620   808 solver.cpp:237]     Train net output #0: loss = 0.173357 (* 1 = 0.173357 loss)
I0524 19:29:54.207633   808 sgd_solver.cpp:105] Iteration 12800, lr = 0.0372
I0524 19:30:37.383500   808 solver.cpp:218] Iteration 12900 (2.31607 iter/s, 43.1766s/100 iters), loss = 0.283584
I0524 19:30:37.383671   808 solver.cpp:237]     Train net output #0: loss = 0.283584 (* 1 = 0.283584 loss)
I0524 19:30:37.383682   808 sgd_solver.cpp:105] Iteration 12900, lr = 0.0371
I0524 19:31:20.125128   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_13000.caffemodel
I0524 19:31:20.277882   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_13000.solverstate
I0524 19:31:20.780009   808 solver.cpp:218] Iteration 13000 (2.30431 iter/s, 43.397s/100 iters), loss = 0.249958
I0524 19:31:20.780058   808 solver.cpp:237]     Train net output #0: loss = 0.249957 (* 1 = 0.249957 loss)
I0524 19:31:20.780066   808 sgd_solver.cpp:105] Iteration 13000, lr = 0.037
I0524 19:31:21.255825   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:32:03.959589   808 solver.cpp:218] Iteration 13100 (2.31588 iter/s, 43.1802s/100 iters), loss = 0.183936
I0524 19:32:03.959834   808 solver.cpp:237]     Train net output #0: loss = 0.183935 (* 1 = 0.183935 loss)
I0524 19:32:03.959846   808 sgd_solver.cpp:105] Iteration 13100, lr = 0.0369
I0524 19:32:47.123051   808 solver.cpp:218] Iteration 13200 (2.31675 iter/s, 43.1638s/100 iters), loss = 0.100069
I0524 19:32:47.123175   808 solver.cpp:237]     Train net output #0: loss = 0.100068 (* 1 = 0.100068 loss)
I0524 19:32:47.123195   808 sgd_solver.cpp:105] Iteration 13200, lr = 0.0368
I0524 19:33:03.146996   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:33:30.298538   808 solver.cpp:218] Iteration 13300 (2.3161 iter/s, 43.176s/100 iters), loss = 0.2191
I0524 19:33:30.298660   808 solver.cpp:237]     Train net output #0: loss = 0.2191 (* 1 = 0.2191 loss)
I0524 19:33:30.298671   808 sgd_solver.cpp:105] Iteration 13300, lr = 0.0367
I0524 19:34:13.463879   808 solver.cpp:218] Iteration 13400 (2.31665 iter/s, 43.1658s/100 iters), loss = 0.198239
I0524 19:34:13.464049   808 solver.cpp:237]     Train net output #0: loss = 0.198238 (* 1 = 0.198238 loss)
I0524 19:34:13.464072   808 sgd_solver.cpp:105] Iteration 13400, lr = 0.0366
I0524 19:34:45.451695   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:34:56.634618   808 solver.cpp:218] Iteration 13500 (2.31636 iter/s, 43.1712s/100 iters), loss = 0.231033
I0524 19:34:56.634665   808 solver.cpp:237]     Train net output #0: loss = 0.231033 (* 1 = 0.231033 loss)
I0524 19:34:56.634672   808 sgd_solver.cpp:105] Iteration 13500, lr = 0.0365
I0524 19:35:39.805493   808 solver.cpp:218] Iteration 13600 (2.31635 iter/s, 43.1714s/100 iters), loss = 0.365748
I0524 19:35:39.805724   808 solver.cpp:237]     Train net output #0: loss = 0.365747 (* 1 = 0.365747 loss)
I0524 19:35:39.805740   808 sgd_solver.cpp:105] Iteration 13600, lr = 0.0364
I0524 19:36:22.977169   808 solver.cpp:218] Iteration 13700 (2.31632 iter/s, 43.172s/100 iters), loss = 0.168386
I0524 19:36:22.977309   808 solver.cpp:237]     Train net output #0: loss = 0.168386 (* 1 = 0.168386 loss)
I0524 19:36:22.977320   808 sgd_solver.cpp:105] Iteration 13700, lr = 0.0363
I0524 19:36:27.345218   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:37:06.146962   808 solver.cpp:218] Iteration 13800 (2.31641 iter/s, 43.1702s/100 iters), loss = 0.223705
I0524 19:37:06.147122   808 solver.cpp:237]     Train net output #0: loss = 0.223705 (* 1 = 0.223705 loss)
I0524 19:37:06.147133   808 sgd_solver.cpp:105] Iteration 13800, lr = 0.0362
I0524 19:37:49.310473   808 solver.cpp:218] Iteration 13900 (2.31675 iter/s, 43.1639s/100 iters), loss = 0.136225
I0524 19:37:49.310652   808 solver.cpp:237]     Train net output #0: loss = 0.136225 (* 1 = 0.136225 loss)
I0524 19:37:49.310667   808 sgd_solver.cpp:105] Iteration 13900, lr = 0.0361
I0524 19:38:09.637703   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:38:32.042726   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_14000.caffemodel
I0524 19:38:32.196435   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_14000.solverstate
I0524 19:38:32.698237   808 solver.cpp:218] Iteration 14000 (2.30478 iter/s, 43.3881s/100 iters), loss = 0.17021
I0524 19:38:32.698288   808 solver.cpp:237]     Train net output #0: loss = 0.170209 (* 1 = 0.170209 loss)
I0524 19:38:32.698297   808 sgd_solver.cpp:105] Iteration 14000, lr = 0.036
I0524 19:39:15.867413   808 solver.cpp:218] Iteration 14100 (2.31644 iter/s, 43.1697s/100 iters), loss = 0.246918
I0524 19:39:15.867535   808 solver.cpp:237]     Train net output #0: loss = 0.246918 (* 1 = 0.246918 loss)
I0524 19:39:15.867557   808 sgd_solver.cpp:105] Iteration 14100, lr = 0.0359
I0524 19:39:51.751065   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:39:59.047796   808 solver.cpp:218] Iteration 14200 (2.31585 iter/s, 43.1808s/100 iters), loss = 0.244855
I0524 19:39:59.047847   808 solver.cpp:237]     Train net output #0: loss = 0.244854 (* 1 = 0.244854 loss)
I0524 19:39:59.047857   808 sgd_solver.cpp:105] Iteration 14200, lr = 0.0358
I0524 19:40:42.226661   808 solver.cpp:218] Iteration 14300 (2.31592 iter/s, 43.1793s/100 iters), loss = 0.247222
I0524 19:40:42.226804   808 solver.cpp:237]     Train net output #0: loss = 0.247222 (* 1 = 0.247222 loss)
I0524 19:40:42.226819   808 sgd_solver.cpp:105] Iteration 14300, lr = 0.0357
I0524 19:41:25.399771   808 solver.cpp:218] Iteration 14400 (2.31624 iter/s, 43.1735s/100 iters), loss = 0.321745
I0524 19:41:25.399890   808 solver.cpp:237]     Train net output #0: loss = 0.321745 (* 1 = 0.321745 loss)
I0524 19:41:25.399899   808 sgd_solver.cpp:105] Iteration 14400, lr = 0.0356
I0524 19:41:34.105701   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:42:08.597046   808 solver.cpp:218] Iteration 14500 (2.31494 iter/s, 43.1977s/100 iters), loss = 0.328373
I0524 19:42:08.597164   808 solver.cpp:237]     Train net output #0: loss = 0.328373 (* 1 = 0.328373 loss)
I0524 19:42:08.597174   808 sgd_solver.cpp:105] Iteration 14500, lr = 0.0355
I0524 19:42:52.034255   808 solver.cpp:218] Iteration 14600 (2.30215 iter/s, 43.4376s/100 iters), loss = 0.358044
I0524 19:42:52.034407   808 solver.cpp:237]     Train net output #0: loss = 0.358043 (* 1 = 0.358043 loss)
I0524 19:42:52.034418   808 sgd_solver.cpp:105] Iteration 14600, lr = 0.0354
I0524 19:43:16.252676   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:43:35.175223   808 solver.cpp:218] Iteration 14700 (2.31796 iter/s, 43.1413s/100 iters), loss = 0.174042
I0524 19:43:35.175343   808 solver.cpp:237]     Train net output #0: loss = 0.174042 (* 1 = 0.174042 loss)
I0524 19:43:35.175364   808 sgd_solver.cpp:105] Iteration 14700, lr = 0.0353
I0524 19:44:18.281530   808 solver.cpp:218] Iteration 14800 (2.31983 iter/s, 43.1067s/100 iters), loss = 0.143969
I0524 19:44:18.281647   808 solver.cpp:237]     Train net output #0: loss = 0.143968 (* 1 = 0.143968 loss)
I0524 19:44:18.281657   808 sgd_solver.cpp:105] Iteration 14800, lr = 0.0352
I0524 19:44:58.061815   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:45:01.467360   808 solver.cpp:218] Iteration 14900 (2.31555 iter/s, 43.1862s/100 iters), loss = 0.223909
I0524 19:45:01.467409   808 solver.cpp:237]     Train net output #0: loss = 0.223908 (* 1 = 0.223908 loss)
I0524 19:45:01.467418   808 sgd_solver.cpp:105] Iteration 14900, lr = 0.0351
I0524 19:45:44.220947   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_15000.caffemodel
I0524 19:45:44.374892   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_15000.solverstate
I0524 19:45:44.877279   808 solver.cpp:218] Iteration 15000 (2.3036 iter/s, 43.4104s/100 iters), loss = 0.284208
I0524 19:45:44.877328   808 solver.cpp:237]     Train net output #0: loss = 0.284207 (* 1 = 0.284207 loss)
I0524 19:45:44.877337   808 sgd_solver.cpp:105] Iteration 15000, lr = 0.035
I0524 19:46:28.045696   808 solver.cpp:218] Iteration 15100 (2.31649 iter/s, 43.1688s/100 iters), loss = 0.221051
I0524 19:46:28.045852   808 solver.cpp:237]     Train net output #0: loss = 0.221051 (* 1 = 0.221051 loss)
I0524 19:46:28.045866   808 sgd_solver.cpp:105] Iteration 15100, lr = 0.0349
I0524 19:46:40.611945   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:47:11.219663   808 solver.cpp:218] Iteration 15200 (2.31619 iter/s, 43.1743s/100 iters), loss = 0.21417
I0524 19:47:11.219832   808 solver.cpp:237]     Train net output #0: loss = 0.21417 (* 1 = 0.21417 loss)
I0524 19:47:11.219843   808 sgd_solver.cpp:105] Iteration 15200, lr = 0.0348
I0524 19:47:54.391717   808 solver.cpp:218] Iteration 15300 (2.3163 iter/s, 43.1724s/100 iters), loss = 0.0798513
I0524 19:47:54.391885   808 solver.cpp:237]     Train net output #0: loss = 0.0798509 (* 1 = 0.0798509 loss)
I0524 19:47:54.391907   808 sgd_solver.cpp:105] Iteration 15300, lr = 0.0347
I0524 19:48:22.505780   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:48:37.560880   808 solver.cpp:218] Iteration 15400 (2.31645 iter/s, 43.1695s/100 iters), loss = 0.264074
I0524 19:48:37.560989   808 solver.cpp:237]     Train net output #0: loss = 0.264073 (* 1 = 0.264073 loss)
I0524 19:48:37.561010   808 sgd_solver.cpp:105] Iteration 15400, lr = 0.0346
I0524 19:49:20.737320   808 solver.cpp:218] Iteration 15500 (2.31606 iter/s, 43.1768s/100 iters), loss = 0.227421
I0524 19:49:20.737448   808 solver.cpp:237]     Train net output #0: loss = 0.227421 (* 1 = 0.227421 loss)
I0524 19:49:20.737459   808 sgd_solver.cpp:105] Iteration 15500, lr = 0.0345
I0524 19:50:03.905387   808 solver.cpp:218] Iteration 15600 (2.31651 iter/s, 43.1684s/100 iters), loss = 0.285807
I0524 19:50:03.905660   808 solver.cpp:237]     Train net output #0: loss = 0.285807 (* 1 = 0.285807 loss)
I0524 19:50:03.905673   808 sgd_solver.cpp:105] Iteration 15600, lr = 0.0344
I0524 19:50:04.820228   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:50:47.086721   808 solver.cpp:218] Iteration 15700 (2.3158 iter/s, 43.1815s/100 iters), loss = 0.266827
I0524 19:50:47.086889   808 solver.cpp:237]     Train net output #0: loss = 0.266826 (* 1 = 0.266826 loss)
I0524 19:50:47.086899   808 sgd_solver.cpp:105] Iteration 15700, lr = 0.0343
I0524 19:51:30.265725   808 solver.cpp:218] Iteration 15800 (2.31592 iter/s, 43.1793s/100 iters), loss = 0.290809
I0524 19:51:30.265895   808 solver.cpp:237]     Train net output #0: loss = 0.290809 (* 1 = 0.290809 loss)
I0524 19:51:30.265911   808 sgd_solver.cpp:105] Iteration 15800, lr = 0.0342
I0524 19:51:46.712177   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:52:13.429767   808 solver.cpp:218] Iteration 15900 (2.31673 iter/s, 43.1643s/100 iters), loss = 0.36725
I0524 19:52:13.429934   808 solver.cpp:237]     Train net output #0: loss = 0.367249 (* 1 = 0.367249 loss)
I0524 19:52:13.429945   808 sgd_solver.cpp:105] Iteration 15900, lr = 0.0341
I0524 19:52:56.172981   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_16000.caffemodel
I0524 19:52:56.325179   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_16000.solverstate
I0524 19:52:56.826481   808 solver.cpp:218] Iteration 16000 (2.30431 iter/s, 43.397s/100 iters), loss = 0.206758
I0524 19:52:56.826531   808 solver.cpp:237]     Train net output #0: loss = 0.206758 (* 1 = 0.206758 loss)
I0524 19:52:56.826539   808 sgd_solver.cpp:105] Iteration 16000, lr = 0.034
I0524 19:53:29.247752   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:53:39.995040   808 solver.cpp:218] Iteration 16100 (2.31648 iter/s, 43.169s/100 iters), loss = 0.460463
I0524 19:53:39.995102   808 solver.cpp:237]     Train net output #0: loss = 0.460463 (* 1 = 0.460463 loss)
I0524 19:53:39.995111   808 sgd_solver.cpp:105] Iteration 16100, lr = 0.0339
I0524 19:54:23.159435   808 solver.cpp:218] Iteration 16200 (2.3167 iter/s, 43.1648s/100 iters), loss = 0.175931
I0524 19:54:23.159559   808 solver.cpp:237]     Train net output #0: loss = 0.175931 (* 1 = 0.175931 loss)
I0524 19:54:23.159567   808 sgd_solver.cpp:105] Iteration 16200, lr = 0.0338
I0524 19:55:06.323500   808 solver.cpp:218] Iteration 16300 (2.31672 iter/s, 43.1644s/100 iters), loss = 0.225195
I0524 19:55:06.323623   808 solver.cpp:237]     Train net output #0: loss = 0.225195 (* 1 = 0.225195 loss)
I0524 19:55:06.323633   808 sgd_solver.cpp:105] Iteration 16300, lr = 0.0337
I0524 19:55:11.125597   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:55:49.497067   808 solver.cpp:218] Iteration 16400 (2.31625 iter/s, 43.1732s/100 iters), loss = 0.248022
I0524 19:55:49.497236   808 solver.cpp:237]     Train net output #0: loss = 0.248022 (* 1 = 0.248022 loss)
I0524 19:55:49.497246   808 sgd_solver.cpp:105] Iteration 16400, lr = 0.0336
I0524 19:56:32.661341   808 solver.cpp:218] Iteration 16500 (2.31675 iter/s, 43.1639s/100 iters), loss = 0.078582
I0524 19:56:32.661517   808 solver.cpp:237]     Train net output #0: loss = 0.0785815 (* 1 = 0.0785815 loss)
I0524 19:56:32.661530   808 sgd_solver.cpp:105] Iteration 16500, lr = 0.0335
I0524 19:56:53.427824   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:57:15.840808   808 solver.cpp:218] Iteration 16600 (2.31594 iter/s, 43.1791s/100 iters), loss = 0.257232
I0524 19:57:15.840958   808 solver.cpp:237]     Train net output #0: loss = 0.257231 (* 1 = 0.257231 loss)
I0524 19:57:15.840981   808 sgd_solver.cpp:105] Iteration 16600, lr = 0.0334
I0524 19:57:59.012852   808 solver.cpp:218] Iteration 16700 (2.31633 iter/s, 43.1717s/100 iters), loss = 0.182101
I0524 19:57:59.013008   808 solver.cpp:237]     Train net output #0: loss = 0.182101 (* 1 = 0.182101 loss)
I0524 19:57:59.013020   808 sgd_solver.cpp:105] Iteration 16700, lr = 0.0333
I0524 19:58:35.323204   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 19:58:42.181927   808 solver.cpp:218] Iteration 16800 (2.31649 iter/s, 43.1688s/100 iters), loss = 0.149432
I0524 19:58:42.181977   808 solver.cpp:237]     Train net output #0: loss = 0.149432 (* 1 = 0.149432 loss)
I0524 19:58:42.181985   808 sgd_solver.cpp:105] Iteration 16800, lr = 0.0332
I0524 19:59:25.357453   808 solver.cpp:218] Iteration 16900 (2.31613 iter/s, 43.1754s/100 iters), loss = 0.190747
I0524 19:59:25.357575   808 solver.cpp:237]     Train net output #0: loss = 0.190747 (* 1 = 0.190747 loss)
I0524 19:59:25.357586   808 sgd_solver.cpp:105] Iteration 16900, lr = 0.0331
I0524 20:00:08.090096   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_17000.caffemodel
I0524 20:00:08.242156   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_17000.solverstate
I0524 20:00:08.744573   808 solver.cpp:218] Iteration 17000 (2.30484 iter/s, 43.387s/100 iters), loss = 0.199271
I0524 20:00:08.744619   808 solver.cpp:237]     Train net output #0: loss = 0.199271 (* 1 = 0.199271 loss)
I0524 20:00:08.744628   808 sgd_solver.cpp:105] Iteration 17000, lr = 0.033
I0524 20:00:17.850289   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:00:51.910537   808 solver.cpp:218] Iteration 17100 (2.31664 iter/s, 43.1659s/100 iters), loss = 0.137969
I0524 20:00:51.910703   808 solver.cpp:237]     Train net output #0: loss = 0.137968 (* 1 = 0.137968 loss)
I0524 20:00:51.910715   808 sgd_solver.cpp:105] Iteration 17100, lr = 0.0329
I0524 20:01:35.083726   808 solver.cpp:218] Iteration 17200 (2.31626 iter/s, 43.173s/100 iters), loss = 0.170481
I0524 20:01:35.083920   808 solver.cpp:237]     Train net output #0: loss = 0.170481 (* 1 = 0.170481 loss)
I0524 20:01:35.083935   808 sgd_solver.cpp:105] Iteration 17200, lr = 0.0328
I0524 20:01:59.735424   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:02:18.251586   808 solver.cpp:218] Iteration 17300 (2.31655 iter/s, 43.1677s/100 iters), loss = 0.222897
I0524 20:02:18.251709   808 solver.cpp:237]     Train net output #0: loss = 0.222897 (* 1 = 0.222897 loss)
I0524 20:02:18.251719   808 sgd_solver.cpp:105] Iteration 17300, lr = 0.0327
I0524 20:03:01.424062   808 solver.cpp:218] Iteration 17400 (2.31629 iter/s, 43.1724s/100 iters), loss = 0.213142
I0524 20:03:01.424229   808 solver.cpp:237]     Train net output #0: loss = 0.213142 (* 1 = 0.213142 loss)
I0524 20:03:01.424242   808 sgd_solver.cpp:105] Iteration 17400, lr = 0.0326
I0524 20:03:42.040704   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:03:44.594532   808 solver.cpp:218] Iteration 17500 (2.3164 iter/s, 43.1704s/100 iters), loss = 0.20455
I0524 20:03:44.594593   808 solver.cpp:237]     Train net output #0: loss = 0.20455 (* 1 = 0.20455 loss)
I0524 20:03:44.594600   808 sgd_solver.cpp:105] Iteration 17500, lr = 0.0325
I0524 20:04:27.769767   808 solver.cpp:218] Iteration 17600 (2.31614 iter/s, 43.1753s/100 iters), loss = 0.196142
I0524 20:04:27.769976   808 solver.cpp:237]     Train net output #0: loss = 0.196141 (* 1 = 0.196141 loss)
I0524 20:04:27.769999   808 sgd_solver.cpp:105] Iteration 17600, lr = 0.0324
I0524 20:05:10.952174   808 solver.cpp:218] Iteration 17700 (2.31576 iter/s, 43.1823s/100 iters), loss = 0.231775
I0524 20:05:10.952299   808 solver.cpp:237]     Train net output #0: loss = 0.231775 (* 1 = 0.231775 loss)
I0524 20:05:10.952309   808 sgd_solver.cpp:105] Iteration 17700, lr = 0.0323
I0524 20:05:23.955890   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:05:54.140503   808 solver.cpp:218] Iteration 17800 (2.31544 iter/s, 43.1883s/100 iters), loss = 0.102758
I0524 20:05:54.140635   808 solver.cpp:237]     Train net output #0: loss = 0.102757 (* 1 = 0.102757 loss)
I0524 20:05:54.140658   808 sgd_solver.cpp:105] Iteration 17800, lr = 0.0322
I0524 20:06:37.320292   808 solver.cpp:218] Iteration 17900 (2.3159 iter/s, 43.1798s/100 iters), loss = 0.373348
I0524 20:06:37.320417   808 solver.cpp:237]     Train net output #0: loss = 0.373347 (* 1 = 0.373347 loss)
I0524 20:06:37.320441   808 sgd_solver.cpp:105] Iteration 17900, lr = 0.0321
I0524 20:07:05.868955   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:07:20.071825   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_18000.caffemodel
I0524 20:07:20.225175   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_18000.solverstate
I0524 20:07:20.727820   808 solver.cpp:218] Iteration 18000 (2.30375 iter/s, 43.4076s/100 iters), loss = 0.278047
I0524 20:07:20.727869   808 solver.cpp:237]     Train net output #0: loss = 0.278046 (* 1 = 0.278046 loss)
I0524 20:07:20.727880   808 sgd_solver.cpp:105] Iteration 18000, lr = 0.032
I0524 20:08:03.901556   808 solver.cpp:218] Iteration 18100 (2.31622 iter/s, 43.1739s/100 iters), loss = 0.234024
I0524 20:08:03.901695   808 solver.cpp:237]     Train net output #0: loss = 0.234023 (* 1 = 0.234023 loss)
I0524 20:08:03.901705   808 sgd_solver.cpp:105] Iteration 18100, lr = 0.0319
I0524 20:08:47.082828   808 solver.cpp:218] Iteration 18200 (2.31582 iter/s, 43.1813s/100 iters), loss = 0.126972
I0524 20:08:47.082959   808 solver.cpp:237]     Train net output #0: loss = 0.126972 (* 1 = 0.126972 loss)
I0524 20:08:47.082970   808 sgd_solver.cpp:105] Iteration 18200, lr = 0.0318
I0524 20:08:48.426893   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:09:30.275861   808 solver.cpp:218] Iteration 18300 (2.31518 iter/s, 43.1931s/100 iters), loss = 0.184938
I0524 20:09:30.276015   808 solver.cpp:237]     Train net output #0: loss = 0.184937 (* 1 = 0.184937 loss)
I0524 20:09:30.276026   808 sgd_solver.cpp:105] Iteration 18300, lr = 0.0317
I0524 20:10:13.454186   808 solver.cpp:218] Iteration 18400 (2.31597 iter/s, 43.1784s/100 iters), loss = 0.188566
I0524 20:10:13.454345   808 solver.cpp:237]     Train net output #0: loss = 0.188566 (* 1 = 0.188566 loss)
I0524 20:10:13.454356   808 sgd_solver.cpp:105] Iteration 18400, lr = 0.0316
I0524 20:10:30.425611   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:10:56.748179   808 solver.cpp:218] Iteration 18500 (2.30979 iter/s, 43.2941s/100 iters), loss = 0.113051
I0524 20:10:56.748389   808 solver.cpp:237]     Train net output #0: loss = 0.113051 (* 1 = 0.113051 loss)
I0524 20:10:56.748400   808 sgd_solver.cpp:105] Iteration 18500, lr = 0.0315
I0524 20:11:39.908571   808 solver.cpp:218] Iteration 18600 (2.31694 iter/s, 43.1604s/100 iters), loss = 0.164457
I0524 20:11:39.908710   808 solver.cpp:237]     Train net output #0: loss = 0.164456 (* 1 = 0.164456 loss)
I0524 20:11:39.908722   808 sgd_solver.cpp:105] Iteration 18600, lr = 0.0314
I0524 20:12:12.762449   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:12:23.076247   808 solver.cpp:218] Iteration 18700 (2.31654 iter/s, 43.1678s/100 iters), loss = 0.320477
I0524 20:12:23.076292   808 solver.cpp:237]     Train net output #0: loss = 0.320476 (* 1 = 0.320476 loss)
I0524 20:12:23.076300   808 sgd_solver.cpp:105] Iteration 18700, lr = 0.0313
I0524 20:13:06.236026   808 solver.cpp:218] Iteration 18800 (2.31696 iter/s, 43.16s/100 iters), loss = 0.128903
I0524 20:13:06.236143   808 solver.cpp:237]     Train net output #0: loss = 0.128902 (* 1 = 0.128902 loss)
I0524 20:13:06.236153   808 sgd_solver.cpp:105] Iteration 18800, lr = 0.0312
I0524 20:13:49.399854   808 solver.cpp:218] Iteration 18900 (2.31675 iter/s, 43.164s/100 iters), loss = 0.137346
I0524 20:13:49.399976   808 solver.cpp:237]     Train net output #0: loss = 0.137346 (* 1 = 0.137346 loss)
I0524 20:13:49.399996   808 sgd_solver.cpp:105] Iteration 18900, lr = 0.0311
I0524 20:13:54.632541   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:14:32.149531   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_19000.caffemodel
I0524 20:14:32.301473   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_19000.solverstate
I0524 20:14:32.802346   808 solver.cpp:218] Iteration 19000 (2.30401 iter/s, 43.4026s/100 iters), loss = 0.192939
I0524 20:14:32.802395   808 solver.cpp:237]     Train net output #0: loss = 0.192939 (* 1 = 0.192939 loss)
I0524 20:14:32.802405   808 sgd_solver.cpp:105] Iteration 19000, lr = 0.031
I0524 20:15:15.971570   808 solver.cpp:218] Iteration 19100 (2.31645 iter/s, 43.1694s/100 iters), loss = 0.218828
I0524 20:15:15.971715   808 solver.cpp:237]     Train net output #0: loss = 0.218828 (* 1 = 0.218828 loss)
I0524 20:15:15.971725   808 sgd_solver.cpp:105] Iteration 19100, lr = 0.0309
I0524 20:15:37.171610   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:15:59.321957   808 solver.cpp:218] Iteration 19200 (2.30678 iter/s, 43.3505s/100 iters), loss = 0.227136
I0524 20:15:59.322121   808 solver.cpp:237]     Train net output #0: loss = 0.227136 (* 1 = 0.227136 loss)
I0524 20:15:59.322134   808 sgd_solver.cpp:105] Iteration 19200, lr = 0.0308
I0524 20:16:43.412073   808 solver.cpp:218] Iteration 19300 (2.26808 iter/s, 44.0902s/100 iters), loss = 0.080061
I0524 20:16:43.412266   808 solver.cpp:237]     Train net output #0: loss = 0.0800608 (* 1 = 0.0800608 loss)
I0524 20:16:43.412278   808 sgd_solver.cpp:105] Iteration 19300, lr = 0.0307
I0524 20:17:20.822661   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:17:27.527148   808 solver.cpp:218] Iteration 19400 (2.2668 iter/s, 44.1151s/100 iters), loss = 0.0581067
I0524 20:17:27.527215   808 solver.cpp:237]     Train net output #0: loss = 0.0581064 (* 1 = 0.0581064 loss)
I0524 20:17:27.527225   808 sgd_solver.cpp:105] Iteration 19400, lr = 0.0306
I0524 20:18:11.605345   808 solver.cpp:218] Iteration 19500 (2.26868 iter/s, 44.0784s/100 iters), loss = 0.119987
I0524 20:18:11.605499   808 solver.cpp:237]     Train net output #0: loss = 0.119987 (* 1 = 0.119987 loss)
I0524 20:18:11.605516   808 sgd_solver.cpp:105] Iteration 19500, lr = 0.0305
I0524 20:18:56.272723   808 solver.cpp:218] Iteration 19600 (2.23876 iter/s, 44.6675s/100 iters), loss = 0.110062
I0524 20:18:56.272812   808 solver.cpp:237]     Train net output #0: loss = 0.110062 (* 1 = 0.110062 loss)
I0524 20:18:56.272822   808 sgd_solver.cpp:105] Iteration 19600, lr = 0.0304
I0524 20:19:05.888636   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:19:39.521008   808 solver.cpp:218] Iteration 19700 (2.31222 iter/s, 43.2485s/100 iters), loss = 0.0769212
I0524 20:19:39.521128   808 solver.cpp:237]     Train net output #0: loss = 0.076921 (* 1 = 0.076921 loss)
I0524 20:19:39.521149   808 sgd_solver.cpp:105] Iteration 19700, lr = 0.0303
I0524 20:20:22.638144   808 solver.cpp:218] Iteration 19800 (2.31925 iter/s, 43.1173s/100 iters), loss = 0.107673
I0524 20:20:22.638273   808 solver.cpp:237]     Train net output #0: loss = 0.107673 (* 1 = 0.107673 loss)
I0524 20:20:22.638296   808 sgd_solver.cpp:105] Iteration 19800, lr = 0.0302
I0524 20:20:47.701267   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:21:05.774292   808 solver.cpp:218] Iteration 19900 (2.31823 iter/s, 43.1363s/100 iters), loss = 0.0736366
I0524 20:21:05.774453   808 solver.cpp:237]     Train net output #0: loss = 0.0736365 (* 1 = 0.0736365 loss)
I0524 20:21:05.774469   808 sgd_solver.cpp:105] Iteration 19900, lr = 0.0301
I0524 20:21:48.467968   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_20000.caffemodel
I0524 20:21:48.621333   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_20000.solverstate
I0524 20:21:49.124876   808 solver.cpp:218] Iteration 20000 (2.30677 iter/s, 43.3507s/100 iters), loss = 0.163765
I0524 20:21:49.124930   808 solver.cpp:237]     Train net output #0: loss = 0.163764 (* 1 = 0.163764 loss)
I0524 20:21:49.124939   808 sgd_solver.cpp:105] Iteration 20000, lr = 0.03
I0524 20:22:30.118613   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:22:32.236472   808 solver.cpp:218] Iteration 20100 (2.31955 iter/s, 43.1119s/100 iters), loss = 0.119351
I0524 20:22:32.236523   808 solver.cpp:237]     Train net output #0: loss = 0.119351 (* 1 = 0.119351 loss)
I0524 20:22:32.236531   808 sgd_solver.cpp:105] Iteration 20100, lr = 0.0299
I0524 20:23:15.355048   808 solver.cpp:218] Iteration 20200 (2.31917 iter/s, 43.1188s/100 iters), loss = 0.194347
I0524 20:23:15.355173   808 solver.cpp:237]     Train net output #0: loss = 0.194347 (* 1 = 0.194347 loss)
I0524 20:23:15.355185   808 sgd_solver.cpp:105] Iteration 20200, lr = 0.0298
I0524 20:23:58.474136   808 solver.cpp:218] Iteration 20300 (2.31915 iter/s, 43.1193s/100 iters), loss = 0.192837
I0524 20:23:58.474300   808 solver.cpp:237]     Train net output #0: loss = 0.192837 (* 1 = 0.192837 loss)
I0524 20:23:58.474311   808 sgd_solver.cpp:105] Iteration 20300, lr = 0.0297
I0524 20:24:11.896934   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:24:42.158231   808 solver.cpp:218] Iteration 20400 (2.28916 iter/s, 43.6842s/100 iters), loss = 0.215179
I0524 20:24:42.158361   808 solver.cpp:237]     Train net output #0: loss = 0.215179 (* 1 = 0.215179 loss)
I0524 20:24:42.158371   808 sgd_solver.cpp:105] Iteration 20400, lr = 0.0296
I0524 20:25:25.283529   808 solver.cpp:218] Iteration 20500 (2.31881 iter/s, 43.1255s/100 iters), loss = 0.0614414
I0524 20:25:25.283656   808 solver.cpp:237]     Train net output #0: loss = 0.0614413 (* 1 = 0.0614413 loss)
I0524 20:25:25.283666   808 sgd_solver.cpp:105] Iteration 20500, lr = 0.0295
I0524 20:25:54.643121   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:26:08.412058   808 solver.cpp:218] Iteration 20600 (2.31864 iter/s, 43.1287s/100 iters), loss = 0.279982
I0524 20:26:08.412227   808 solver.cpp:237]     Train net output #0: loss = 0.279982 (* 1 = 0.279982 loss)
I0524 20:26:08.412237   808 sgd_solver.cpp:105] Iteration 20600, lr = 0.0294
I0524 20:26:51.523648   808 solver.cpp:218] Iteration 20700 (2.31955 iter/s, 43.1118s/100 iters), loss = 0.0529064
I0524 20:26:51.523769   808 solver.cpp:237]     Train net output #0: loss = 0.0529063 (* 1 = 0.0529063 loss)
I0524 20:26:51.523790   808 sgd_solver.cpp:105] Iteration 20700, lr = 0.0293
I0524 20:27:34.644603   808 solver.cpp:218] Iteration 20800 (2.31905 iter/s, 43.1212s/100 iters), loss = 0.0974486
I0524 20:27:34.644723   808 solver.cpp:237]     Train net output #0: loss = 0.0974484 (* 1 = 0.0974484 loss)
I0524 20:27:34.644733   808 sgd_solver.cpp:105] Iteration 20800, lr = 0.0292
I0524 20:27:36.416662   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:28:17.759728   808 solver.cpp:218] Iteration 20900 (2.31936 iter/s, 43.1153s/100 iters), loss = 0.245747
I0524 20:28:17.759850   808 solver.cpp:237]     Train net output #0: loss = 0.245747 (* 1 = 0.245747 loss)
I0524 20:28:17.759860   808 sgd_solver.cpp:105] Iteration 20900, lr = 0.0291
I0524 20:29:00.453980   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_21000.caffemodel
I0524 20:29:00.605911   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_21000.solverstate
I0524 20:29:01.107561   808 solver.cpp:218] Iteration 21000 (2.30691 iter/s, 43.348s/100 iters), loss = 0.110862
I0524 20:29:01.107605   808 solver.cpp:237]     Train net output #0: loss = 0.110862 (* 1 = 0.110862 loss)
I0524 20:29:01.107614   808 sgd_solver.cpp:105] Iteration 21000, lr = 0.029
I0524 20:29:18.412272   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:29:44.236305   808 solver.cpp:218] Iteration 21100 (2.31861 iter/s, 43.1293s/100 iters), loss = 0.091785
I0524 20:29:44.236443   808 solver.cpp:237]     Train net output #0: loss = 0.0917849 (* 1 = 0.0917849 loss)
I0524 20:29:44.236454   808 sgd_solver.cpp:105] Iteration 21100, lr = 0.0289
I0524 20:30:27.350291   808 solver.cpp:218] Iteration 21200 (2.3194 iter/s, 43.1147s/100 iters), loss = 0.113746
I0524 20:30:27.351214   808 solver.cpp:237]     Train net output #0: loss = 0.113746 (* 1 = 0.113746 loss)
I0524 20:30:27.351224   808 sgd_solver.cpp:105] Iteration 21200, lr = 0.0288
I0524 20:31:00.600853   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:31:10.485599   808 solver.cpp:218] Iteration 21300 (2.31829 iter/s, 43.1352s/100 iters), loss = 0.0700301
I0524 20:31:10.485641   808 solver.cpp:237]     Train net output #0: loss = 0.0700299 (* 1 = 0.0700299 loss)
I0524 20:31:10.485651   808 sgd_solver.cpp:105] Iteration 21300, lr = 0.0287
I0524 20:31:53.597254   808 solver.cpp:218] Iteration 21400 (2.31952 iter/s, 43.1124s/100 iters), loss = 0.109987
I0524 20:31:53.597370   808 solver.cpp:237]     Train net output #0: loss = 0.109987 (* 1 = 0.109987 loss)
I0524 20:31:53.597383   808 sgd_solver.cpp:105] Iteration 21400, lr = 0.0286
I0524 20:32:36.710963   808 solver.cpp:218] Iteration 21500 (2.31941 iter/s, 43.1143s/100 iters), loss = 0.0968808
I0524 20:32:36.711079   808 solver.cpp:237]     Train net output #0: loss = 0.0968806 (* 1 = 0.0968806 loss)
I0524 20:32:36.711103   808 sgd_solver.cpp:105] Iteration 21500, lr = 0.0285
I0524 20:32:42.376780   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:33:19.841625   808 solver.cpp:218] Iteration 21600 (2.31851 iter/s, 43.1312s/100 iters), loss = 0.10838
I0524 20:33:19.841747   808 solver.cpp:237]     Train net output #0: loss = 0.10838 (* 1 = 0.10838 loss)
I0524 20:33:19.841758   808 sgd_solver.cpp:105] Iteration 21600, lr = 0.0284
I0524 20:34:02.956696   808 solver.cpp:218] Iteration 21700 (2.31935 iter/s, 43.1156s/100 iters), loss = 0.103881
I0524 20:34:02.956849   808 solver.cpp:237]     Train net output #0: loss = 0.103881 (* 1 = 0.103881 loss)
I0524 20:34:02.956876   808 sgd_solver.cpp:105] Iteration 21700, lr = 0.0283
I0524 20:34:24.598464   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:34:46.275511   808 solver.cpp:218] Iteration 21800 (2.30844 iter/s, 43.3193s/100 iters), loss = 0.124419
I0524 20:34:46.275648   808 solver.cpp:237]     Train net output #0: loss = 0.124419 (* 1 = 0.124419 loss)
I0524 20:34:46.275660   808 sgd_solver.cpp:105] Iteration 21800, lr = 0.0282
I0524 20:35:30.010283   808 solver.cpp:218] Iteration 21900 (2.28648 iter/s, 43.7353s/100 iters), loss = 0.0983984
I0524 20:35:30.010550   808 solver.cpp:237]     Train net output #0: loss = 0.0983982 (* 1 = 0.0983982 loss)
I0524 20:35:30.010560   808 sgd_solver.cpp:105] Iteration 21900, lr = 0.0281
I0524 20:36:07.437279   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:36:13.006536   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_22000.caffemodel
I0524 20:36:13.157932   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_22000.solverstate
I0524 20:36:13.658965   808 solver.cpp:218] Iteration 22000 (2.291 iter/s, 43.649s/100 iters), loss = 0.0893484
I0524 20:36:13.659014   808 solver.cpp:237]     Train net output #0: loss = 0.0893482 (* 1 = 0.0893482 loss)
I0524 20:36:13.659023   808 sgd_solver.cpp:105] Iteration 22000, lr = 0.028
I0524 20:36:56.821497   808 solver.cpp:218] Iteration 22100 (2.31679 iter/s, 43.1631s/100 iters), loss = 0.192178
I0524 20:36:56.821657   808 solver.cpp:237]     Train net output #0: loss = 0.192178 (* 1 = 0.192178 loss)
I0524 20:36:56.821668   808 sgd_solver.cpp:105] Iteration 22100, lr = 0.0279
I0524 20:37:39.996333   808 solver.cpp:218] Iteration 22200 (2.31614 iter/s, 43.1752s/100 iters), loss = 0.14356
I0524 20:37:39.996454   808 solver.cpp:237]     Train net output #0: loss = 0.14356 (* 1 = 0.14356 loss)
I0524 20:37:39.996464   808 sgd_solver.cpp:105] Iteration 22200, lr = 0.0278
I0524 20:37:49.962841   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:38:23.152583   808 solver.cpp:218] Iteration 22300 (2.31714 iter/s, 43.1567s/100 iters), loss = 0.0932605
I0524 20:38:23.152701   808 solver.cpp:237]     Train net output #0: loss = 0.0932603 (* 1 = 0.0932603 loss)
I0524 20:38:23.152710   808 sgd_solver.cpp:105] Iteration 22300, lr = 0.0277
I0524 20:39:06.318158   808 solver.cpp:218] Iteration 22400 (2.31664 iter/s, 43.166s/100 iters), loss = 0.151292
I0524 20:39:06.318300   808 solver.cpp:237]     Train net output #0: loss = 0.151292 (* 1 = 0.151292 loss)
I0524 20:39:06.318312   808 sgd_solver.cpp:105] Iteration 22400, lr = 0.0276
I0524 20:39:31.839689   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:39:49.489308   808 solver.cpp:218] Iteration 22500 (2.31634 iter/s, 43.1716s/100 iters), loss = 0.263457
I0524 20:39:49.489548   808 solver.cpp:237]     Train net output #0: loss = 0.263456 (* 1 = 0.263456 loss)
I0524 20:39:49.489559   808 sgd_solver.cpp:105] Iteration 22500, lr = 0.0275
I0524 20:40:32.658540   808 solver.cpp:218] Iteration 22600 (2.31645 iter/s, 43.1695s/100 iters), loss = 0.110954
I0524 20:40:32.658668   808 solver.cpp:237]     Train net output #0: loss = 0.110954 (* 1 = 0.110954 loss)
I0524 20:40:32.658679   808 sgd_solver.cpp:105] Iteration 22600, lr = 0.0274
I0524 20:41:14.140717   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:41:15.829385   808 solver.cpp:218] Iteration 22700 (2.31636 iter/s, 43.1712s/100 iters), loss = 0.0715714
I0524 20:41:15.829434   808 solver.cpp:237]     Train net output #0: loss = 0.0715712 (* 1 = 0.0715712 loss)
I0524 20:41:15.829443   808 sgd_solver.cpp:105] Iteration 22700, lr = 0.0273
I0524 20:41:58.988533   808 solver.cpp:218] Iteration 22800 (2.31698 iter/s, 43.1596s/100 iters), loss = 0.192538
I0524 20:41:58.988689   808 solver.cpp:237]     Train net output #0: loss = 0.192538 (* 1 = 0.192538 loss)
I0524 20:41:58.988700   808 sgd_solver.cpp:105] Iteration 22800, lr = 0.0272
I0524 20:42:42.159610   808 solver.cpp:218] Iteration 22900 (2.31635 iter/s, 43.1714s/100 iters), loss = 0.204973
I0524 20:42:42.159765   808 solver.cpp:237]     Train net output #0: loss = 0.204973 (* 1 = 0.204973 loss)
I0524 20:42:42.159776   808 sgd_solver.cpp:105] Iteration 22900, lr = 0.0271
I0524 20:42:56.022884   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:43:24.918594   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_23000.caffemodel
I0524 20:43:25.070704   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_23000.solverstate
I0524 20:43:25.573022   808 solver.cpp:218] Iteration 23000 (2.30342 iter/s, 43.4138s/100 iters), loss = 0.0482196
I0524 20:43:25.573068   808 solver.cpp:237]     Train net output #0: loss = 0.0482194 (* 1 = 0.0482194 loss)
I0524 20:43:25.573076   808 sgd_solver.cpp:105] Iteration 23000, lr = 0.027
I0524 20:44:08.738476   808 solver.cpp:218] Iteration 23100 (2.31664 iter/s, 43.1659s/100 iters), loss = 0.112375
I0524 20:44:08.738602   808 solver.cpp:237]     Train net output #0: loss = 0.112375 (* 1 = 0.112375 loss)
I0524 20:44:08.738612   808 sgd_solver.cpp:105] Iteration 23100, lr = 0.0269
I0524 20:44:38.559521   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:44:52.166162   808 solver.cpp:218] Iteration 23200 (2.30266 iter/s, 43.4281s/100 iters), loss = 0.12917
I0524 20:44:52.166285   808 solver.cpp:237]     Train net output #0: loss = 0.12917 (* 1 = 0.12917 loss)
I0524 20:44:52.166304   808 sgd_solver.cpp:105] Iteration 23200, lr = 0.0268
I0524 20:45:35.289158   808 solver.cpp:218] Iteration 23300 (2.31893 iter/s, 43.1234s/100 iters), loss = 0.126611
I0524 20:45:35.289284   808 solver.cpp:237]     Train net output #0: loss = 0.126611 (* 1 = 0.126611 loss)
I0524 20:45:35.289305   808 sgd_solver.cpp:105] Iteration 23300, lr = 0.0267
I0524 20:46:18.403949   808 solver.cpp:218] Iteration 23400 (2.31937 iter/s, 43.1151s/100 iters), loss = 0.0777059
I0524 20:46:18.404088   808 solver.cpp:237]     Train net output #0: loss = 0.0777058 (* 1 = 0.0777058 loss)
I0524 20:46:18.404098   808 sgd_solver.cpp:105] Iteration 23400, lr = 0.0266
I0524 20:46:20.609853   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:47:01.520903   808 solver.cpp:218] Iteration 23500 (2.31925 iter/s, 43.1173s/100 iters), loss = 0.0489664
I0524 20:47:01.521044   808 solver.cpp:237]     Train net output #0: loss = 0.0489663 (* 1 = 0.0489663 loss)
I0524 20:47:01.521061   808 sgd_solver.cpp:105] Iteration 23500, lr = 0.0265
I0524 20:47:44.649034   808 solver.cpp:218] Iteration 23600 (2.31865 iter/s, 43.1285s/100 iters), loss = 0.331541
I0524 20:47:44.649157   808 solver.cpp:237]     Train net output #0: loss = 0.331541 (* 1 = 0.331541 loss)
I0524 20:47:44.649181   808 sgd_solver.cpp:105] Iteration 23600, lr = 0.0264
I0524 20:48:02.387732   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:48:27.776998   808 solver.cpp:218] Iteration 23700 (2.31866 iter/s, 43.1283s/100 iters), loss = 0.101689
I0524 20:48:27.777222   808 solver.cpp:237]     Train net output #0: loss = 0.101689 (* 1 = 0.101689 loss)
I0524 20:48:27.777232   808 sgd_solver.cpp:105] Iteration 23700, lr = 0.0263
I0524 20:49:10.889942   808 solver.cpp:218] Iteration 23800 (2.31948 iter/s, 43.1132s/100 iters), loss = 0.0782543
I0524 20:49:10.890056   808 solver.cpp:237]     Train net output #0: loss = 0.0782541 (* 1 = 0.0782541 loss)
I0524 20:49:10.890066   808 sgd_solver.cpp:105] Iteration 23800, lr = 0.0262
I0524 20:49:44.564940   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:49:54.016170   808 solver.cpp:218] Iteration 23900 (2.31876 iter/s, 43.1266s/100 iters), loss = 0.310227
I0524 20:49:54.016222   808 solver.cpp:237]     Train net output #0: loss = 0.310227 (* 1 = 0.310227 loss)
I0524 20:49:54.016230   808 sgd_solver.cpp:105] Iteration 23900, lr = 0.0261
I0524 20:50:36.697518   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_24000.caffemodel
I0524 20:50:36.850446   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_24000.solverstate
I0524 20:50:37.351196   808 solver.cpp:218] Iteration 24000 (2.30758 iter/s, 43.3354s/100 iters), loss = 0.225666
I0524 20:50:37.351241   808 solver.cpp:237]     Train net output #0: loss = 0.225666 (* 1 = 0.225666 loss)
I0524 20:50:37.351250   808 sgd_solver.cpp:105] Iteration 24000, lr = 0.026
I0524 20:51:20.468799   808 solver.cpp:218] Iteration 24100 (2.31922 iter/s, 43.118s/100 iters), loss = 0.0960151
I0524 20:51:20.469010   808 solver.cpp:237]     Train net output #0: loss = 0.096015 (* 1 = 0.096015 loss)
I0524 20:51:20.469022   808 sgd_solver.cpp:105] Iteration 24100, lr = 0.0259
I0524 20:51:26.561264   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:52:04.035012   808 solver.cpp:218] Iteration 24200 (2.29534 iter/s, 43.5665s/100 iters), loss = 0.0695656
I0524 20:52:04.035204   808 solver.cpp:237]     Train net output #0: loss = 0.0695655 (* 1 = 0.0695655 loss)
I0524 20:52:04.035217   808 sgd_solver.cpp:105] Iteration 24200, lr = 0.0258
I0524 20:52:47.443512   808 solver.cpp:218] Iteration 24300 (2.30368 iter/s, 43.4088s/100 iters), loss = 0.0589236
I0524 20:52:47.443642   808 solver.cpp:237]     Train net output #0: loss = 0.0589235 (* 1 = 0.0589235 loss)
I0524 20:52:47.443652   808 sgd_solver.cpp:105] Iteration 24300, lr = 0.0257
I0524 20:53:09.472796   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:53:30.552448   808 solver.cpp:218] Iteration 24400 (2.31969 iter/s, 43.1092s/100 iters), loss = 0.254948
I0524 20:53:30.552592   808 solver.cpp:237]     Train net output #0: loss = 0.254948 (* 1 = 0.254948 loss)
I0524 20:53:30.552601   808 sgd_solver.cpp:105] Iteration 24400, lr = 0.0256
I0524 20:54:13.657958   808 solver.cpp:218] Iteration 24500 (2.31987 iter/s, 43.1058s/100 iters), loss = 0.108598
I0524 20:54:13.658077   808 solver.cpp:237]     Train net output #0: loss = 0.108598 (* 1 = 0.108598 loss)
I0524 20:54:13.658087   808 sgd_solver.cpp:105] Iteration 24500, lr = 0.0255
I0524 20:54:51.204485   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:54:56.761253   808 solver.cpp:218] Iteration 24600 (2.31999 iter/s, 43.1036s/100 iters), loss = 0.148553
I0524 20:54:56.761301   808 solver.cpp:237]     Train net output #0: loss = 0.148553 (* 1 = 0.148553 loss)
I0524 20:54:56.761309   808 sgd_solver.cpp:105] Iteration 24600, lr = 0.0254
I0524 20:55:39.866304   808 solver.cpp:218] Iteration 24700 (2.31989 iter/s, 43.1054s/100 iters), loss = 0.17251
I0524 20:55:39.866426   808 solver.cpp:237]     Train net output #0: loss = 0.17251 (* 1 = 0.17251 loss)
I0524 20:55:39.866436   808 sgd_solver.cpp:105] Iteration 24700, lr = 0.0253
I0524 20:56:22.965950   808 solver.cpp:218] Iteration 24800 (2.32019 iter/s, 43.1s/100 iters), loss = 0.173911
I0524 20:56:22.966071   808 solver.cpp:237]     Train net output #0: loss = 0.173911 (* 1 = 0.173911 loss)
I0524 20:56:22.966080   808 sgd_solver.cpp:105] Iteration 24800, lr = 0.0252
I0524 20:56:33.354264   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:57:06.069808   808 solver.cpp:218] Iteration 24900 (2.31996 iter/s, 43.1042s/100 iters), loss = 0.165165
I0524 20:57:06.069936   808 solver.cpp:237]     Train net output #0: loss = 0.165165 (* 1 = 0.165165 loss)
I0524 20:57:06.069946   808 sgd_solver.cpp:105] Iteration 24900, lr = 0.0251
I0524 20:57:48.745669   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_25000.caffemodel
I0524 20:57:48.897063   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_25000.solverstate
I0524 20:57:49.397022   808 solver.cpp:218] Iteration 25000 (2.308 iter/s, 43.3275s/100 iters), loss = 0.0586816
I0524 20:57:49.397068   808 solver.cpp:237]     Train net output #0: loss = 0.0586814 (* 1 = 0.0586814 loss)
I0524 20:57:49.397076   808 sgd_solver.cpp:105] Iteration 25000, lr = 0.025
I0524 20:58:15.308816   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:58:32.501323   808 solver.cpp:218] Iteration 25100 (2.31993 iter/s, 43.1047s/100 iters), loss = 0.0685538
I0524 20:58:32.501495   808 solver.cpp:237]     Train net output #0: loss = 0.0685535 (* 1 = 0.0685535 loss)
I0524 20:58:32.501508   808 sgd_solver.cpp:105] Iteration 25100, lr = 0.0249
I0524 20:59:15.604879   808 solver.cpp:218] Iteration 25200 (2.31998 iter/s, 43.1038s/100 iters), loss = 0.142992
I0524 20:59:15.605006   808 solver.cpp:237]     Train net output #0: loss = 0.142992 (* 1 = 0.142992 loss)
I0524 20:59:15.605027   808 sgd_solver.cpp:105] Iteration 25200, lr = 0.0248
I0524 20:59:57.456926   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 20:59:58.712317   808 solver.cpp:218] Iteration 25300 (2.31977 iter/s, 43.1077s/100 iters), loss = 0.145771
I0524 20:59:58.712375   808 solver.cpp:237]     Train net output #0: loss = 0.145771 (* 1 = 0.145771 loss)
I0524 20:59:58.712384   808 sgd_solver.cpp:105] Iteration 25300, lr = 0.0247
I0524 21:00:41.983129   808 solver.cpp:218] Iteration 25400 (2.31101 iter/s, 43.2712s/100 iters), loss = 0.284061
I0524 21:00:41.983266   808 solver.cpp:237]     Train net output #0: loss = 0.284061 (* 1 = 0.284061 loss)
I0524 21:00:41.983276   808 sgd_solver.cpp:105] Iteration 25400, lr = 0.0246
I0524 21:01:25.381716   808 solver.cpp:218] Iteration 25500 (2.30421 iter/s, 43.3989s/100 iters), loss = 0.120427
I0524 21:01:25.381827   808 solver.cpp:237]     Train net output #0: loss = 0.120426 (* 1 = 0.120426 loss)
I0524 21:01:25.381836   808 sgd_solver.cpp:105] Iteration 25500, lr = 0.0245
I0524 21:01:39.677347   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:02:08.555119   808 solver.cpp:218] Iteration 25600 (2.31622 iter/s, 43.1737s/100 iters), loss = 0.112565
I0524 21:02:08.555265   808 solver.cpp:237]     Train net output #0: loss = 0.112565 (* 1 = 0.112565 loss)
I0524 21:02:08.555275   808 sgd_solver.cpp:105] Iteration 25600, lr = 0.0244
I0524 21:02:51.733999   808 solver.cpp:218] Iteration 25700 (2.31593 iter/s, 43.1792s/100 iters), loss = 0.185502
I0524 21:02:51.734117   808 solver.cpp:237]     Train net output #0: loss = 0.185502 (* 1 = 0.185502 loss)
I0524 21:02:51.734136   808 sgd_solver.cpp:105] Iteration 25700, lr = 0.0243
I0524 21:03:22.003571   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:03:34.919484   808 solver.cpp:218] Iteration 25800 (2.31558 iter/s, 43.1857s/100 iters), loss = 0.103404
I0524 21:03:34.919530   808 solver.cpp:237]     Train net output #0: loss = 0.103403 (* 1 = 0.103403 loss)
I0524 21:03:34.919538   808 sgd_solver.cpp:105] Iteration 25800, lr = 0.0242
I0524 21:04:18.083788   808 solver.cpp:218] Iteration 25900 (2.31676 iter/s, 43.1636s/100 iters), loss = 0.0241083
I0524 21:04:18.084007   808 solver.cpp:237]     Train net output #0: loss = 0.0241079 (* 1 = 0.0241079 loss)
I0524 21:04:18.084022   808 sgd_solver.cpp:105] Iteration 25900, lr = 0.0241
I0524 21:05:00.830965   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_26000.caffemodel
I0524 21:05:00.982934   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_26000.solverstate
I0524 21:05:01.484310   808 solver.cpp:218] Iteration 26000 (2.30416 iter/s, 43.3998s/100 iters), loss = 0.0297018
I0524 21:05:01.484361   808 solver.cpp:237]     Train net output #0: loss = 0.0297014 (* 1 = 0.0297014 loss)
I0524 21:05:01.484370   808 sgd_solver.cpp:105] Iteration 26000, lr = 0.024
I0524 21:05:04.126737   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:05:44.658622   808 solver.cpp:218] Iteration 26100 (2.31622 iter/s, 43.1738s/100 iters), loss = 0.0975111
I0524 21:05:44.658762   808 solver.cpp:237]     Train net output #0: loss = 0.0975107 (* 1 = 0.0975107 loss)
I0524 21:05:44.658774   808 sgd_solver.cpp:105] Iteration 26100, lr = 0.0239
I0524 21:06:27.831274   808 solver.cpp:218] Iteration 26200 (2.31631 iter/s, 43.1721s/100 iters), loss = 0.0464732
I0524 21:06:27.831436   808 solver.cpp:237]     Train net output #0: loss = 0.0464729 (* 1 = 0.0464729 loss)
I0524 21:06:27.831463   808 sgd_solver.cpp:105] Iteration 26200, lr = 0.0238
I0524 21:06:46.438115   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:07:11.017511   808 solver.cpp:218] Iteration 26300 (2.31558 iter/s, 43.1857s/100 iters), loss = 0.156241
I0524 21:07:11.017680   808 solver.cpp:237]     Train net output #0: loss = 0.156241 (* 1 = 0.156241 loss)
I0524 21:07:11.017691   808 sgd_solver.cpp:105] Iteration 26300, lr = 0.0237
I0524 21:07:54.202579   808 solver.cpp:218] Iteration 26400 (2.31564 iter/s, 43.1846s/100 iters), loss = 0.149208
I0524 21:07:54.202689   808 solver.cpp:237]     Train net output #0: loss = 0.149208 (* 1 = 0.149208 loss)
I0524 21:07:54.202699   808 sgd_solver.cpp:105] Iteration 26400, lr = 0.0236
I0524 21:08:28.363143   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:08:37.386137   808 solver.cpp:218] Iteration 26500 (2.31572 iter/s, 43.1832s/100 iters), loss = 0.195975
I0524 21:08:37.386193   808 solver.cpp:237]     Train net output #0: loss = 0.195974 (* 1 = 0.195974 loss)
I0524 21:08:37.386200   808 sgd_solver.cpp:105] Iteration 26500, lr = 0.0235
I0524 21:09:20.554822   808 solver.cpp:218] Iteration 26600 (2.31651 iter/s, 43.1684s/100 iters), loss = 0.154234
I0524 21:09:20.554991   808 solver.cpp:237]     Train net output #0: loss = 0.154234 (* 1 = 0.154234 loss)
I0524 21:09:20.555002   808 sgd_solver.cpp:105] Iteration 26600, lr = 0.0234
I0524 21:10:03.734156   808 solver.cpp:218] Iteration 26700 (2.31594 iter/s, 43.179s/100 iters), loss = 0.0453418
I0524 21:10:03.734275   808 solver.cpp:237]     Train net output #0: loss = 0.0453414 (* 1 = 0.0453414 loss)
I0524 21:10:03.734287   808 sgd_solver.cpp:105] Iteration 26700, lr = 0.0233
I0524 21:10:10.263651   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:10:46.900573   808 solver.cpp:218] Iteration 26800 (2.31663 iter/s, 43.1662s/100 iters), loss = 0.12394
I0524 21:10:46.900738   808 solver.cpp:237]     Train net output #0: loss = 0.12394 (* 1 = 0.12394 loss)
I0524 21:10:46.900750   808 sgd_solver.cpp:105] Iteration 26800, lr = 0.0232
I0524 21:11:30.082918   808 solver.cpp:218] Iteration 26900 (2.31578 iter/s, 43.1821s/100 iters), loss = 0.11063
I0524 21:11:30.083046   808 solver.cpp:237]     Train net output #0: loss = 0.110629 (* 1 = 0.110629 loss)
I0524 21:11:30.083062   808 sgd_solver.cpp:105] Iteration 26900, lr = 0.0231
I0524 21:11:52.582216   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:12:12.834460   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_27000.caffemodel
I0524 21:12:12.986907   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_27000.solverstate
I0524 21:12:13.488960   808 solver.cpp:218] Iteration 27000 (2.30384 iter/s, 43.4059s/100 iters), loss = 0.0313494
I0524 21:12:13.489007   808 solver.cpp:237]     Train net output #0: loss = 0.0313491 (* 1 = 0.0313491 loss)
I0524 21:12:13.489017   808 sgd_solver.cpp:105] Iteration 27000, lr = 0.023
I0524 21:12:56.656153   808 solver.cpp:218] Iteration 27100 (2.31658 iter/s, 43.1671s/100 iters), loss = 0.104464
I0524 21:12:56.656324   808 solver.cpp:237]     Train net output #0: loss = 0.104464 (* 1 = 0.104464 loss)
I0524 21:12:56.656335   808 sgd_solver.cpp:105] Iteration 27100, lr = 0.0229
I0524 21:13:34.706352   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:13:39.836838   808 solver.cpp:218] Iteration 27200 (2.31586 iter/s, 43.1805s/100 iters), loss = 0.0335086
I0524 21:13:39.836885   808 solver.cpp:237]     Train net output #0: loss = 0.0335084 (* 1 = 0.0335084 loss)
I0524 21:13:39.836894   808 sgd_solver.cpp:105] Iteration 27200, lr = 0.0228
I0524 21:14:23.009768   808 solver.cpp:218] Iteration 27300 (2.31627 iter/s, 43.1729s/100 iters), loss = 0.0408441
I0524 21:14:23.009937   808 solver.cpp:237]     Train net output #0: loss = 0.0408438 (* 1 = 0.0408438 loss)
I0524 21:14:23.009948   808 sgd_solver.cpp:105] Iteration 27300, lr = 0.0227
I0524 21:15:06.177559   808 solver.cpp:218] Iteration 27400 (2.31655 iter/s, 43.1677s/100 iters), loss = 0.170895
I0524 21:15:06.177721   808 solver.cpp:237]     Train net output #0: loss = 0.170895 (* 1 = 0.170895 loss)
I0524 21:15:06.177732   808 sgd_solver.cpp:105] Iteration 27400, lr = 0.0226
I0524 21:15:17.016361   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:15:49.346380   808 solver.cpp:218] Iteration 27500 (2.31649 iter/s, 43.1687s/100 iters), loss = 0.13579
I0524 21:15:49.346509   808 solver.cpp:237]     Train net output #0: loss = 0.135789 (* 1 = 0.135789 loss)
I0524 21:15:49.346530   808 sgd_solver.cpp:105] Iteration 27500, lr = 0.0225
I0524 21:16:32.511467   808 solver.cpp:218] Iteration 27600 (2.31669 iter/s, 43.165s/100 iters), loss = 0.0424996
I0524 21:16:32.511634   808 solver.cpp:237]     Train net output #0: loss = 0.0424994 (* 1 = 0.0424994 loss)
I0524 21:16:32.511646   808 sgd_solver.cpp:105] Iteration 27600, lr = 0.0224
I0524 21:16:58.898972   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:17:15.692934   808 solver.cpp:218] Iteration 27700 (2.31581 iter/s, 43.1814s/100 iters), loss = 0.0534082
I0524 21:17:15.693060   808 solver.cpp:237]     Train net output #0: loss = 0.053408 (* 1 = 0.053408 loss)
I0524 21:17:15.693081   808 sgd_solver.cpp:105] Iteration 27700, lr = 0.0223
I0524 21:17:58.868150   808 solver.cpp:218] Iteration 27800 (2.31614 iter/s, 43.1752s/100 iters), loss = 0.144836
I0524 21:17:58.868305   808 solver.cpp:237]     Train net output #0: loss = 0.144836 (* 1 = 0.144836 loss)
I0524 21:17:58.868319   808 sgd_solver.cpp:105] Iteration 27800, lr = 0.0222
I0524 21:18:41.207770   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:18:42.032120   808 solver.cpp:218] Iteration 27900 (2.31675 iter/s, 43.1639s/100 iters), loss = 0.170004
I0524 21:18:42.032187   808 solver.cpp:237]     Train net output #0: loss = 0.170004 (* 1 = 0.170004 loss)
I0524 21:18:42.032197   808 sgd_solver.cpp:105] Iteration 27900, lr = 0.0221
I0524 21:19:24.775671   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_28000.caffemodel
I0524 21:19:24.927423   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_28000.solverstate
I0524 21:19:25.428771   808 solver.cpp:218] Iteration 28000 (2.30432 iter/s, 43.3967s/100 iters), loss = 0.0883251
I0524 21:19:25.428834   808 solver.cpp:237]     Train net output #0: loss = 0.088325 (* 1 = 0.088325 loss)
I0524 21:19:25.428844   808 sgd_solver.cpp:105] Iteration 28000, lr = 0.022
I0524 21:20:08.589840   808 solver.cpp:218] Iteration 28100 (2.3169 iter/s, 43.1612s/100 iters), loss = 0.208733
I0524 21:20:08.589957   808 solver.cpp:237]     Train net output #0: loss = 0.208732 (* 1 = 0.208732 loss)
I0524 21:20:08.589967   808 sgd_solver.cpp:105] Iteration 28100, lr = 0.0219
I0524 21:20:23.313199   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:20:51.756129   808 solver.cpp:218] Iteration 28200 (2.31662 iter/s, 43.1663s/100 iters), loss = 0.155105
I0524 21:20:51.756254   808 solver.cpp:237]     Train net output #0: loss = 0.155105 (* 1 = 0.155105 loss)
I0524 21:20:51.756264   808 sgd_solver.cpp:105] Iteration 28200, lr = 0.0218
I0524 21:21:34.934903   808 solver.cpp:218] Iteration 28300 (2.31595 iter/s, 43.1788s/100 iters), loss = 0.05841
I0524 21:21:34.935029   808 solver.cpp:237]     Train net output #0: loss = 0.05841 (* 1 = 0.05841 loss)
I0524 21:21:34.935040   808 sgd_solver.cpp:105] Iteration 28300, lr = 0.0217
I0524 21:22:05.620653   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:22:18.094887   808 solver.cpp:218] Iteration 28400 (2.31696 iter/s, 43.16s/100 iters), loss = 0.0821318
I0524 21:22:18.094943   808 solver.cpp:237]     Train net output #0: loss = 0.0821317 (* 1 = 0.0821317 loss)
I0524 21:22:18.094951   808 sgd_solver.cpp:105] Iteration 28400, lr = 0.0216
I0524 21:23:01.259174   808 solver.cpp:218] Iteration 28500 (2.31672 iter/s, 43.1644s/100 iters), loss = 0.042478
I0524 21:23:01.259301   808 solver.cpp:237]     Train net output #0: loss = 0.0424779 (* 1 = 0.0424779 loss)
I0524 21:23:01.259311   808 sgd_solver.cpp:105] Iteration 28500, lr = 0.0215
I0524 21:23:44.430279   808 solver.cpp:218] Iteration 28600 (2.31636 iter/s, 43.1712s/100 iters), loss = 0.116256
I0524 21:23:44.430394   808 solver.cpp:237]     Train net output #0: loss = 0.116256 (* 1 = 0.116256 loss)
I0524 21:23:44.430404   808 sgd_solver.cpp:105] Iteration 28600, lr = 0.0214
I0524 21:23:47.500203   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:24:27.601303   808 solver.cpp:218] Iteration 28700 (2.31636 iter/s, 43.1711s/100 iters), loss = 0.0659004
I0524 21:24:27.601447   808 solver.cpp:237]     Train net output #0: loss = 0.0659003 (* 1 = 0.0659003 loss)
I0524 21:24:27.601459   808 sgd_solver.cpp:105] Iteration 28700, lr = 0.0213
I0524 21:25:10.773459   808 solver.cpp:218] Iteration 28800 (2.3163 iter/s, 43.1722s/100 iters), loss = 0.0774739
I0524 21:25:10.773597   808 solver.cpp:237]     Train net output #0: loss = 0.0774739 (* 1 = 0.0774739 loss)
I0524 21:25:10.773622   808 sgd_solver.cpp:105] Iteration 28800, lr = 0.0212
I0524 21:25:29.812284   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:25:53.949162   808 solver.cpp:218] Iteration 28900 (2.31611 iter/s, 43.1758s/100 iters), loss = 0.170735
I0524 21:25:53.949339   808 solver.cpp:237]     Train net output #0: loss = 0.170735 (* 1 = 0.170735 loss)
I0524 21:25:53.949352   808 sgd_solver.cpp:105] Iteration 28900, lr = 0.0211
I0524 21:26:36.691560   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_29000.caffemodel
I0524 21:26:36.843684   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_29000.solverstate
I0524 21:26:37.345671   808 solver.cpp:218] Iteration 29000 (2.30433 iter/s, 43.3966s/100 iters), loss = 0.0580344
I0524 21:26:37.345722   808 solver.cpp:237]     Train net output #0: loss = 0.0580342 (* 1 = 0.0580342 loss)
I0524 21:26:37.345731   808 sgd_solver.cpp:105] Iteration 29000, lr = 0.021
I0524 21:27:11.929922   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:27:20.519992   808 solver.cpp:218] Iteration 29100 (2.31618 iter/s, 43.1745s/100 iters), loss = 0.0622221
I0524 21:27:20.520037   808 solver.cpp:237]     Train net output #0: loss = 0.062222 (* 1 = 0.062222 loss)
I0524 21:27:20.520045   808 sgd_solver.cpp:105] Iteration 29100, lr = 0.0209
I0524 21:28:03.692020   808 solver.cpp:218] Iteration 29200 (2.3163 iter/s, 43.1722s/100 iters), loss = 0.175042
I0524 21:28:03.692139   808 solver.cpp:237]     Train net output #0: loss = 0.175042 (* 1 = 0.175042 loss)
I0524 21:28:03.692149   808 sgd_solver.cpp:105] Iteration 29200, lr = 0.0208
I0524 21:28:46.846889   808 solver.cpp:218] Iteration 29300 (2.31723 iter/s, 43.155s/100 iters), loss = 0.0423079
I0524 21:28:46.847020   808 solver.cpp:237]     Train net output #0: loss = 0.0423078 (* 1 = 0.0423078 loss)
I0524 21:28:46.847033   808 sgd_solver.cpp:105] Iteration 29300, lr = 0.0207
I0524 21:28:54.222525   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:29:30.015522   808 solver.cpp:218] Iteration 29400 (2.31649 iter/s, 43.1687s/100 iters), loss = 0.0321907
I0524 21:29:30.015671   808 solver.cpp:237]     Train net output #0: loss = 0.0321906 (* 1 = 0.0321906 loss)
I0524 21:29:30.015681   808 sgd_solver.cpp:105] Iteration 29400, lr = 0.0206
I0524 21:30:13.190889   808 solver.cpp:218] Iteration 29500 (2.31613 iter/s, 43.1755s/100 iters), loss = 0.189231
I0524 21:30:13.191092   808 solver.cpp:237]     Train net output #0: loss = 0.18923 (* 1 = 0.18923 loss)
I0524 21:30:13.191103   808 sgd_solver.cpp:105] Iteration 29500, lr = 0.0205
I0524 21:30:36.119680   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:30:56.748353   808 solver.cpp:218] Iteration 29600 (2.29581 iter/s, 43.5575s/100 iters), loss = 0.0473253
I0524 21:30:56.748581   808 solver.cpp:237]     Train net output #0: loss = 0.0473252 (* 1 = 0.0473252 loss)
I0524 21:30:56.748594   808 sgd_solver.cpp:105] Iteration 29600, lr = 0.0204
I0524 21:31:39.924007   808 solver.cpp:218] Iteration 29700 (2.31612 iter/s, 43.1757s/100 iters), loss = 0.0422625
I0524 21:31:39.924212   808 solver.cpp:237]     Train net output #0: loss = 0.0422623 (* 1 = 0.0422623 loss)
I0524 21:31:39.924223   808 sgd_solver.cpp:105] Iteration 29700, lr = 0.0203
I0524 21:32:18.385781   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:32:23.081104   808 solver.cpp:218] Iteration 29800 (2.31711 iter/s, 43.1572s/100 iters), loss = 0.112908
I0524 21:32:23.081151   808 solver.cpp:237]     Train net output #0: loss = 0.112908 (* 1 = 0.112908 loss)
I0524 21:32:23.081161   808 sgd_solver.cpp:105] Iteration 29800, lr = 0.0202
I0524 21:33:06.247975   808 solver.cpp:218] Iteration 29900 (2.31658 iter/s, 43.1671s/100 iters), loss = 0.0214497
I0524 21:33:06.248142   808 solver.cpp:237]     Train net output #0: loss = 0.0214495 (* 1 = 0.0214495 loss)
I0524 21:33:06.248157   808 sgd_solver.cpp:105] Iteration 29900, lr = 0.0201
I0524 21:33:48.982261   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_30000.caffemodel
I0524 21:33:49.135097   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_30000.solverstate
I0524 21:33:49.638015   808 solver.cpp:218] Iteration 30000 (2.30467 iter/s, 43.3901s/100 iters), loss = 0.106252
I0524 21:33:49.638078   808 solver.cpp:237]     Train net output #0: loss = 0.106252 (* 1 = 0.106252 loss)
I0524 21:33:49.638093   808 sgd_solver.cpp:105] Iteration 30000, lr = 0.02
I0524 21:34:00.913158   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:34:32.821789   808 solver.cpp:218] Iteration 30100 (2.31567 iter/s, 43.184s/100 iters), loss = 0.0895832
I0524 21:34:32.821946   808 solver.cpp:237]     Train net output #0: loss = 0.0895829 (* 1 = 0.0895829 loss)
I0524 21:34:32.821957   808 sgd_solver.cpp:105] Iteration 30100, lr = 0.0199
I0524 21:35:16.002007   808 solver.cpp:218] Iteration 30200 (2.31587 iter/s, 43.1803s/100 iters), loss = 0.0941068
I0524 21:35:16.002141   808 solver.cpp:237]     Train net output #0: loss = 0.0941067 (* 1 = 0.0941067 loss)
I0524 21:35:16.002153   808 sgd_solver.cpp:105] Iteration 30200, lr = 0.0198
I0524 21:35:42.813346   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:35:59.156837   808 solver.cpp:218] Iteration 30300 (2.31723 iter/s, 43.155s/100 iters), loss = 0.0302769
I0524 21:35:59.156967   808 solver.cpp:237]     Train net output #0: loss = 0.0302768 (* 1 = 0.0302768 loss)
I0524 21:35:59.156988   808 sgd_solver.cpp:105] Iteration 30300, lr = 0.0197
I0524 21:36:42.318632   808 solver.cpp:218] Iteration 30400 (2.31686 iter/s, 43.1619s/100 iters), loss = 0.0719164
I0524 21:36:42.318753   808 solver.cpp:237]     Train net output #0: loss = 0.0719163 (* 1 = 0.0719163 loss)
I0524 21:36:42.318763   808 sgd_solver.cpp:105] Iteration 30400, lr = 0.0196
I0524 21:37:25.107777   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:37:25.498720   808 solver.cpp:218] Iteration 30500 (2.31587 iter/s, 43.1802s/100 iters), loss = 0.113111
I0524 21:37:25.498769   808 solver.cpp:237]     Train net output #0: loss = 0.113111 (* 1 = 0.113111 loss)
I0524 21:37:25.498778   808 sgd_solver.cpp:105] Iteration 30500, lr = 0.0195
I0524 21:38:08.675570   808 solver.cpp:218] Iteration 30600 (2.316 iter/s, 43.1779s/100 iters), loss = 0.130924
I0524 21:38:08.675731   808 solver.cpp:237]     Train net output #0: loss = 0.130924 (* 1 = 0.130924 loss)
I0524 21:38:08.675742   808 sgd_solver.cpp:105] Iteration 30600, lr = 0.0194
I0524 21:38:52.288578   808 solver.cpp:218] Iteration 30700 (2.29283 iter/s, 43.6143s/100 iters), loss = 0.0292075
I0524 21:38:52.288699   808 solver.cpp:237]     Train net output #0: loss = 0.0292073 (* 1 = 0.0292073 loss)
I0524 21:38:52.288720   808 sgd_solver.cpp:105] Iteration 30700, lr = 0.0193
I0524 21:39:07.450161   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:39:35.466739   808 solver.cpp:218] Iteration 30800 (2.31592 iter/s, 43.1794s/100 iters), loss = 0.148282
I0524 21:39:35.466930   808 solver.cpp:237]     Train net output #0: loss = 0.148281 (* 1 = 0.148281 loss)
I0524 21:39:35.466941   808 sgd_solver.cpp:105] Iteration 30800, lr = 0.0192
I0524 21:40:18.630657   808 solver.cpp:218] Iteration 30900 (2.31669 iter/s, 43.165s/100 iters), loss = 0.0340227
I0524 21:40:18.630785   808 solver.cpp:237]     Train net output #0: loss = 0.0340226 (* 1 = 0.0340226 loss)
I0524 21:40:18.630795   808 sgd_solver.cpp:105] Iteration 30900, lr = 0.0191
I0524 21:40:49.753537   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:41:01.371593   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_31000.caffemodel
I0524 21:41:01.525444   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_31000.solverstate
I0524 21:41:02.027719   808 solver.cpp:218] Iteration 31000 (2.30424 iter/s, 43.3982s/100 iters), loss = 0.0442995
I0524 21:41:02.027782   808 solver.cpp:237]     Train net output #0: loss = 0.0442994 (* 1 = 0.0442994 loss)
I0524 21:41:02.027791   808 sgd_solver.cpp:105] Iteration 31000, lr = 0.019
I0524 21:41:45.206740   808 solver.cpp:218] Iteration 31100 (2.31588 iter/s, 43.1801s/100 iters), loss = 0.0337411
I0524 21:41:45.206904   808 solver.cpp:237]     Train net output #0: loss = 0.033741 (* 1 = 0.033741 loss)
I0524 21:41:45.206915   808 sgd_solver.cpp:105] Iteration 31100, lr = 0.0189
I0524 21:42:28.366869   808 solver.cpp:218] Iteration 31200 (2.3169 iter/s, 43.1611s/100 iters), loss = 0.0962017
I0524 21:42:28.366984   808 solver.cpp:237]     Train net output #0: loss = 0.0962016 (* 1 = 0.0962016 loss)
I0524 21:42:28.366996   808 sgd_solver.cpp:105] Iteration 31200, lr = 0.0188
I0524 21:42:31.867650   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:43:11.532127   808 solver.cpp:218] Iteration 31300 (2.31663 iter/s, 43.1662s/100 iters), loss = 0.0595008
I0524 21:43:11.532248   808 solver.cpp:237]     Train net output #0: loss = 0.0595006 (* 1 = 0.0595006 loss)
I0524 21:43:11.532258   808 sgd_solver.cpp:105] Iteration 31300, lr = 0.0187
I0524 21:43:54.699470   808 solver.cpp:218] Iteration 31400 (2.31652 iter/s, 43.1682s/100 iters), loss = 0.0190948
I0524 21:43:54.699589   808 solver.cpp:237]     Train net output #0: loss = 0.0190947 (* 1 = 0.0190947 loss)
I0524 21:43:54.699599   808 sgd_solver.cpp:105] Iteration 31400, lr = 0.0186
I0524 21:44:14.163825   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:44:37.865178   808 solver.cpp:218] Iteration 31500 (2.31661 iter/s, 43.1666s/100 iters), loss = 0.0538964
I0524 21:44:37.865306   808 solver.cpp:237]     Train net output #0: loss = 0.0538962 (* 1 = 0.0538962 loss)
I0524 21:44:37.865316   808 sgd_solver.cpp:105] Iteration 31500, lr = 0.0185
I0524 21:45:21.044560   808 solver.cpp:218] Iteration 31600 (2.31588 iter/s, 43.1802s/100 iters), loss = 0.0780884
I0524 21:45:21.044690   808 solver.cpp:237]     Train net output #0: loss = 0.0780883 (* 1 = 0.0780883 loss)
I0524 21:45:21.044701   808 sgd_solver.cpp:105] Iteration 31600, lr = 0.0184
I0524 21:45:56.044445   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:46:04.219388   808 solver.cpp:218] Iteration 31700 (2.31612 iter/s, 43.1756s/100 iters), loss = 0.0865238
I0524 21:46:04.219449   808 solver.cpp:237]     Train net output #0: loss = 0.0865237 (* 1 = 0.0865237 loss)
I0524 21:46:04.219458   808 sgd_solver.cpp:105] Iteration 31700, lr = 0.0183
I0524 21:46:47.380542   808 solver.cpp:218] Iteration 31800 (2.31685 iter/s, 43.162s/100 iters), loss = 0.0573915
I0524 21:46:47.380704   808 solver.cpp:237]     Train net output #0: loss = 0.0573913 (* 1 = 0.0573913 loss)
I0524 21:46:47.380717   808 sgd_solver.cpp:105] Iteration 31800, lr = 0.0182
I0524 21:47:30.552551   808 solver.cpp:218] Iteration 31900 (2.31628 iter/s, 43.1727s/100 iters), loss = 0.0655019
I0524 21:47:30.552669   808 solver.cpp:237]     Train net output #0: loss = 0.0655018 (* 1 = 0.0655018 loss)
I0524 21:47:30.552678   808 sgd_solver.cpp:105] Iteration 31900, lr = 0.0181
I0524 21:47:38.361392   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:48:13.294258   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_32000.caffemodel
I0524 21:48:13.446565   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_32000.solverstate
I0524 21:48:13.948772   808 solver.cpp:218] Iteration 32000 (2.30431 iter/s, 43.3969s/100 iters), loss = 0.0101082
I0524 21:48:13.948833   808 solver.cpp:237]     Train net output #0: loss = 0.0101081 (* 1 = 0.0101081 loss)
I0524 21:48:13.948843   808 sgd_solver.cpp:105] Iteration 32000, lr = 0.018
I0524 21:48:57.116108   808 solver.cpp:218] Iteration 32100 (2.31653 iter/s, 43.1681s/100 iters), loss = 0.060479
I0524 21:48:57.116238   808 solver.cpp:237]     Train net output #0: loss = 0.0604789 (* 1 = 0.0604789 loss)
I0524 21:48:57.116248   808 sgd_solver.cpp:105] Iteration 32100, lr = 0.0179
I0524 21:49:20.486851   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:49:40.301007   808 solver.cpp:218] Iteration 32200 (2.31559 iter/s, 43.1855s/100 iters), loss = 0.109284
I0524 21:49:40.301118   808 solver.cpp:237]     Train net output #0: loss = 0.109284 (* 1 = 0.109284 loss)
I0524 21:49:40.301128   808 sgd_solver.cpp:105] Iteration 32200, lr = 0.0178
I0524 21:50:23.456187   808 solver.cpp:218] Iteration 32300 (2.31718 iter/s, 43.1558s/100 iters), loss = 0.0272706
I0524 21:50:23.456310   808 solver.cpp:237]     Train net output #0: loss = 0.0272705 (* 1 = 0.0272705 loss)
I0524 21:50:23.456320   808 sgd_solver.cpp:105] Iteration 32300, lr = 0.0177
I0524 21:51:02.772979   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:51:06.623549   808 solver.cpp:218] Iteration 32400 (2.31653 iter/s, 43.168s/100 iters), loss = 0.0330322
I0524 21:51:06.623600   808 solver.cpp:237]     Train net output #0: loss = 0.0330321 (* 1 = 0.0330321 loss)
I0524 21:51:06.623608   808 sgd_solver.cpp:105] Iteration 32400, lr = 0.0176
I0524 21:51:49.793728   808 solver.cpp:218] Iteration 32500 (2.31638 iter/s, 43.1708s/100 iters), loss = 0.0201214
I0524 21:51:49.793845   808 solver.cpp:237]     Train net output #0: loss = 0.0201212 (* 1 = 0.0201212 loss)
I0524 21:51:49.793856   808 sgd_solver.cpp:105] Iteration 32500, lr = 0.0175
I0524 21:52:32.959049   808 solver.cpp:218] Iteration 32600 (2.31664 iter/s, 43.1659s/100 iters), loss = 0.102368
I0524 21:52:32.959182   808 solver.cpp:237]     Train net output #0: loss = 0.102368 (* 1 = 0.102368 loss)
I0524 21:52:32.959190   808 sgd_solver.cpp:105] Iteration 32600, lr = 0.0174
I0524 21:52:44.665009   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:53:16.138415   808 solver.cpp:218] Iteration 32700 (2.31589 iter/s, 43.1799s/100 iters), loss = 0.0220536
I0524 21:53:16.138702   808 solver.cpp:237]     Train net output #0: loss = 0.0220534 (* 1 = 0.0220534 loss)
I0524 21:53:16.138712   808 sgd_solver.cpp:105] Iteration 32700, lr = 0.0173
I0524 21:53:59.305591   808 solver.cpp:218] Iteration 32800 (2.31656 iter/s, 43.1675s/100 iters), loss = 0.0111617
I0524 21:53:59.305716   808 solver.cpp:237]     Train net output #0: loss = 0.0111616 (* 1 = 0.0111616 loss)
I0524 21:53:59.305726   808 sgd_solver.cpp:105] Iteration 32800, lr = 0.0172
I0524 21:54:26.551512   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:54:42.472596   808 solver.cpp:218] Iteration 32900 (2.31656 iter/s, 43.1675s/100 iters), loss = 0.130156
I0524 21:54:42.472712   808 solver.cpp:237]     Train net output #0: loss = 0.130156 (* 1 = 0.130156 loss)
I0524 21:54:42.472733   808 sgd_solver.cpp:105] Iteration 32900, lr = 0.0171
I0524 21:55:25.210723   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_33000.caffemodel
I0524 21:55:25.363369   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_33000.solverstate
I0524 21:55:25.864073   808 solver.cpp:218] Iteration 33000 (2.30457 iter/s, 43.392s/100 iters), loss = 0.0844371
I0524 21:55:25.864120   808 solver.cpp:237]     Train net output #0: loss = 0.0844369 (* 1 = 0.0844369 loss)
I0524 21:55:25.864128   808 sgd_solver.cpp:105] Iteration 33000, lr = 0.017
I0524 21:56:09.026736   808 solver.cpp:218] Iteration 33100 (2.31679 iter/s, 43.1632s/100 iters), loss = 0.0363047
I0524 21:56:09.026918   808 solver.cpp:237]     Train net output #0: loss = 0.0363045 (* 1 = 0.0363045 loss)
I0524 21:56:09.026934   808 sgd_solver.cpp:105] Iteration 33100, lr = 0.0169
I0524 21:56:09.072305   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:56:52.197345   808 solver.cpp:218] Iteration 33200 (2.31637 iter/s, 43.171s/100 iters), loss = 0.0433073
I0524 21:56:52.197500   808 solver.cpp:237]     Train net output #0: loss = 0.043307 (* 1 = 0.043307 loss)
I0524 21:56:52.197512   808 sgd_solver.cpp:105] Iteration 33200, lr = 0.0168
I0524 21:57:35.365128   808 solver.cpp:218] Iteration 33300 (2.31652 iter/s, 43.1683s/100 iters), loss = 0.0700333
I0524 21:57:35.365578   808 solver.cpp:237]     Train net output #0: loss = 0.0700331 (* 1 = 0.0700331 loss)
I0524 21:57:35.365599   808 sgd_solver.cpp:105] Iteration 33300, lr = 0.0167
I0524 21:57:50.955000   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:58:18.527122   808 solver.cpp:218] Iteration 33400 (2.31685 iter/s, 43.1621s/100 iters), loss = 0.0466871
I0524 21:58:18.527251   808 solver.cpp:237]     Train net output #0: loss = 0.0466869 (* 1 = 0.0466869 loss)
I0524 21:58:18.527261   808 sgd_solver.cpp:105] Iteration 33400, lr = 0.0166
I0524 21:59:01.707898   808 solver.cpp:218] Iteration 33500 (2.31582 iter/s, 43.1812s/100 iters), loss = 0.0226074
I0524 21:59:01.708806   808 solver.cpp:237]     Train net output #0: loss = 0.0226071 (* 1 = 0.0226071 loss)
I0524 21:59:01.708816   808 sgd_solver.cpp:105] Iteration 33500, lr = 0.0165
I0524 21:59:33.266397   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 21:59:44.876493   808 solver.cpp:218] Iteration 33600 (2.31652 iter/s, 43.1683s/100 iters), loss = 0.0160145
I0524 21:59:44.876538   808 solver.cpp:237]     Train net output #0: loss = 0.0160142 (* 1 = 0.0160142 loss)
I0524 21:59:44.876545   808 sgd_solver.cpp:105] Iteration 33600, lr = 0.0164
I0524 22:00:28.036063   808 solver.cpp:218] Iteration 33700 (2.31696 iter/s, 43.1601s/100 iters), loss = 0.0318637
I0524 22:00:28.036216   808 solver.cpp:237]     Train net output #0: loss = 0.0318635 (* 1 = 0.0318635 loss)
I0524 22:00:28.036226   808 sgd_solver.cpp:105] Iteration 33700, lr = 0.0163
I0524 22:01:11.199858   808 solver.cpp:218] Iteration 33800 (2.31673 iter/s, 43.1642s/100 iters), loss = 0.06399
I0524 22:01:11.200024   808 solver.cpp:237]     Train net output #0: loss = 0.0639898 (* 1 = 0.0639898 loss)
I0524 22:01:11.200042   808 sgd_solver.cpp:105] Iteration 33800, lr = 0.0162
I0524 22:01:15.137411   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:01:54.366463   808 solver.cpp:218] Iteration 33900 (2.31659 iter/s, 43.167s/100 iters), loss = 0.0111607
I0524 22:01:54.366587   808 solver.cpp:237]     Train net output #0: loss = 0.0111605 (* 1 = 0.0111605 loss)
I0524 22:01:54.366611   808 sgd_solver.cpp:105] Iteration 33900, lr = 0.0161
I0524 22:02:37.115310   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_34000.caffemodel
I0524 22:02:37.267056   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_34000.solverstate
I0524 22:02:37.769366   808 solver.cpp:218] Iteration 34000 (2.30397 iter/s, 43.4033s/100 iters), loss = 0.0209657
I0524 22:02:37.769412   808 solver.cpp:237]     Train net output #0: loss = 0.0209655 (* 1 = 0.0209655 loss)
I0524 22:02:37.769420   808 sgd_solver.cpp:105] Iteration 34000, lr = 0.016
I0524 22:02:57.665714   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:03:20.937026   808 solver.cpp:218] Iteration 34100 (2.31652 iter/s, 43.1682s/100 iters), loss = 0.0352779
I0524 22:03:20.937141   808 solver.cpp:237]     Train net output #0: loss = 0.0352778 (* 1 = 0.0352778 loss)
I0524 22:03:20.937151   808 sgd_solver.cpp:105] Iteration 34100, lr = 0.0159
I0524 22:04:04.100118   808 solver.cpp:218] Iteration 34200 (2.31677 iter/s, 43.1635s/100 iters), loss = 0.0479741
I0524 22:04:04.100394   808 solver.cpp:237]     Train net output #0: loss = 0.0479739 (* 1 = 0.0479739 loss)
I0524 22:04:04.100416   808 sgd_solver.cpp:105] Iteration 34200, lr = 0.0158
I0524 22:04:39.545198   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:04:47.267585   808 solver.cpp:218] Iteration 34300 (2.31654 iter/s, 43.1677s/100 iters), loss = 0.019896
I0524 22:04:47.267637   808 solver.cpp:237]     Train net output #0: loss = 0.0198958 (* 1 = 0.0198958 loss)
I0524 22:04:47.267645   808 sgd_solver.cpp:105] Iteration 34300, lr = 0.0157
I0524 22:05:30.441387   808 solver.cpp:218] Iteration 34400 (2.31619 iter/s, 43.1743s/100 iters), loss = 0.0220605
I0524 22:05:30.441624   808 solver.cpp:237]     Train net output #0: loss = 0.0220602 (* 1 = 0.0220602 loss)
I0524 22:05:30.441639   808 sgd_solver.cpp:105] Iteration 34400, lr = 0.0156
I0524 22:06:13.608278   808 solver.cpp:218] Iteration 34500 (2.31657 iter/s, 43.1672s/100 iters), loss = 0.0223877
I0524 22:06:13.608422   808 solver.cpp:237]     Train net output #0: loss = 0.0223875 (* 1 = 0.0223875 loss)
I0524 22:06:13.608434   808 sgd_solver.cpp:105] Iteration 34500, lr = 0.0155
I0524 22:06:21.852475   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:06:56.775027   808 solver.cpp:218] Iteration 34600 (2.31658 iter/s, 43.1672s/100 iters), loss = 0.184348
I0524 22:06:56.775147   808 solver.cpp:237]     Train net output #0: loss = 0.184347 (* 1 = 0.184347 loss)
I0524 22:06:56.775167   808 sgd_solver.cpp:105] Iteration 34600, lr = 0.0154
I0524 22:07:39.939108   808 solver.cpp:218] Iteration 34700 (2.31672 iter/s, 43.1645s/100 iters), loss = 0.0724259
I0524 22:07:39.939244   808 solver.cpp:237]     Train net output #0: loss = 0.0724257 (* 1 = 0.0724257 loss)
I0524 22:07:39.939254   808 sgd_solver.cpp:105] Iteration 34700, lr = 0.0153
I0524 22:08:03.728739   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:08:23.104543   808 solver.cpp:218] Iteration 34800 (2.31665 iter/s, 43.1658s/100 iters), loss = 0.0172906
I0524 22:08:23.104718   808 solver.cpp:237]     Train net output #0: loss = 0.0172904 (* 1 = 0.0172904 loss)
I0524 22:08:23.104729   808 sgd_solver.cpp:105] Iteration 34800, lr = 0.0152
I0524 22:09:06.265090   808 solver.cpp:218] Iteration 34900 (2.31691 iter/s, 43.1609s/100 iters), loss = 0.0146791
I0524 22:09:06.265223   808 solver.cpp:237]     Train net output #0: loss = 0.0146789 (* 1 = 0.0146789 loss)
I0524 22:09:06.265233   808 sgd_solver.cpp:105] Iteration 34900, lr = 0.0151
I0524 22:09:46.026510   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:09:49.014681   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_35000.caffemodel
I0524 22:09:49.167116   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_35000.solverstate
I0524 22:09:49.669123   808 solver.cpp:218] Iteration 35000 (2.30391 iter/s, 43.4044s/100 iters), loss = 0.0237815
I0524 22:09:49.669167   808 solver.cpp:237]     Train net output #0: loss = 0.0237813 (* 1 = 0.0237813 loss)
I0524 22:09:49.669176   808 sgd_solver.cpp:105] Iteration 35000, lr = 0.015
I0524 22:10:32.831023   808 solver.cpp:218] Iteration 35100 (2.31683 iter/s, 43.1624s/100 iters), loss = 0.0546439
I0524 22:10:32.831152   808 solver.cpp:237]     Train net output #0: loss = 0.0546437 (* 1 = 0.0546437 loss)
I0524 22:10:32.831166   808 sgd_solver.cpp:105] Iteration 35100, lr = 0.0149
I0524 22:11:15.989292   808 solver.cpp:218] Iteration 35200 (2.31703 iter/s, 43.1587s/100 iters), loss = 0.0427461
I0524 22:11:15.989428   808 solver.cpp:237]     Train net output #0: loss = 0.0427459 (* 1 = 0.0427459 loss)
I0524 22:11:15.989440   808 sgd_solver.cpp:105] Iteration 35200, lr = 0.0148
I0524 22:11:28.123234   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:11:59.156543   808 solver.cpp:218] Iteration 35300 (2.31656 iter/s, 43.1675s/100 iters), loss = 0.00865931
I0524 22:11:59.156736   808 solver.cpp:237]     Train net output #0: loss = 0.00865915 (* 1 = 0.00865915 loss)
I0524 22:11:59.156749   808 sgd_solver.cpp:105] Iteration 35300, lr = 0.0147
I0524 22:12:42.319522   808 solver.cpp:218] Iteration 35400 (2.3168 iter/s, 43.1629s/100 iters), loss = 0.0105404
I0524 22:12:42.319672   808 solver.cpp:237]     Train net output #0: loss = 0.0105403 (* 1 = 0.0105403 loss)
I0524 22:12:42.319682   808 sgd_solver.cpp:105] Iteration 35400, lr = 0.0146
I0524 22:13:10.008700   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:13:25.496057   808 solver.cpp:218] Iteration 35500 (2.31607 iter/s, 43.1765s/100 iters), loss = 0.0122247
I0524 22:13:25.496182   808 solver.cpp:237]     Train net output #0: loss = 0.0122246 (* 1 = 0.0122246 loss)
I0524 22:13:25.496204   808 sgd_solver.cpp:105] Iteration 35500, lr = 0.0145
I0524 22:14:08.658700   808 solver.cpp:218] Iteration 35600 (2.31682 iter/s, 43.1627s/100 iters), loss = 0.0240174
I0524 22:14:08.658815   808 solver.cpp:237]     Train net output #0: loss = 0.0240172 (* 1 = 0.0240172 loss)
I0524 22:14:08.658825   808 sgd_solver.cpp:105] Iteration 35600, lr = 0.0144
I0524 22:14:52.591877   808 solver.cpp:218] Iteration 35700 (2.27618 iter/s, 43.9333s/100 iters), loss = 0.034565
I0524 22:14:52.592025   808 solver.cpp:237]     Train net output #0: loss = 0.0345648 (* 1 = 0.0345648 loss)
I0524 22:14:52.592036   808 sgd_solver.cpp:105] Iteration 35700, lr = 0.0143
I0524 22:14:53.067005   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:15:35.612491   808 solver.cpp:218] Iteration 35800 (2.32446 iter/s, 43.0207s/100 iters), loss = 0.0579579
I0524 22:15:35.612606   808 solver.cpp:237]     Train net output #0: loss = 0.0579577 (* 1 = 0.0579577 loss)
I0524 22:15:35.612627   808 sgd_solver.cpp:105] Iteration 35800, lr = 0.0142
I0524 22:16:18.630420   808 solver.cpp:218] Iteration 35900 (2.32461 iter/s, 43.018s/100 iters), loss = 0.0801192
I0524 22:16:18.630532   808 solver.cpp:237]     Train net output #0: loss = 0.0801191 (* 1 = 0.0801191 loss)
I0524 22:16:18.630555   808 sgd_solver.cpp:105] Iteration 35900, lr = 0.0141
I0524 22:16:34.598701   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:17:01.224145   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_36000.caffemodel
I0524 22:17:01.375586   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_36000.solverstate
I0524 22:17:01.875555   808 solver.cpp:218] Iteration 36000 (2.31239 iter/s, 43.2453s/100 iters), loss = 0.0426549
I0524 22:17:01.875600   808 solver.cpp:237]     Train net output #0: loss = 0.0426547 (* 1 = 0.0426547 loss)
I0524 22:17:01.875609   808 sgd_solver.cpp:105] Iteration 36000, lr = 0.014
I0524 22:17:44.893347   808 solver.cpp:218] Iteration 36100 (2.32461 iter/s, 43.018s/100 iters), loss = 0.0067224
I0524 22:17:44.893512   808 solver.cpp:237]     Train net output #0: loss = 0.00672226 (* 1 = 0.00672226 loss)
I0524 22:17:44.893530   808 sgd_solver.cpp:105] Iteration 36100, lr = 0.0139
I0524 22:18:16.768465   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:18:27.911756   808 solver.cpp:218] Iteration 36200 (2.32458 iter/s, 43.0185s/100 iters), loss = 0.039352
I0524 22:18:27.911806   808 solver.cpp:237]     Train net output #0: loss = 0.0393519 (* 1 = 0.0393519 loss)
I0524 22:18:27.911815   808 sgd_solver.cpp:105] Iteration 36200, lr = 0.0138
I0524 22:19:10.925118   808 solver.cpp:218] Iteration 36300 (2.32485 iter/s, 43.0136s/100 iters), loss = 0.183278
I0524 22:19:10.925233   808 solver.cpp:237]     Train net output #0: loss = 0.183278 (* 1 = 0.183278 loss)
I0524 22:19:10.925243   808 sgd_solver.cpp:105] Iteration 36300, lr = 0.0137
I0524 22:19:53.939086   808 solver.cpp:218] Iteration 36400 (2.32482 iter/s, 43.0141s/100 iters), loss = 0.123023
I0524 22:19:53.939215   808 solver.cpp:237]     Train net output #0: loss = 0.123023 (* 1 = 0.123023 loss)
I0524 22:19:53.939226   808 sgd_solver.cpp:105] Iteration 36400, lr = 0.0136
I0524 22:19:58.290719   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:20:36.950423   808 solver.cpp:218] Iteration 36500 (2.32496 iter/s, 43.0115s/100 iters), loss = 0.0100628
I0524 22:20:36.950579   808 solver.cpp:237]     Train net output #0: loss = 0.0100628 (* 1 = 0.0100628 loss)
I0524 22:20:36.950589   808 sgd_solver.cpp:105] Iteration 36500, lr = 0.0135
I0524 22:21:19.974580   808 solver.cpp:218] Iteration 36600 (2.32427 iter/s, 43.0243s/100 iters), loss = 0.0094472
I0524 22:21:19.974735   808 solver.cpp:237]     Train net output #0: loss = 0.00944712 (* 1 = 0.00944712 loss)
I0524 22:21:19.974745   808 sgd_solver.cpp:105] Iteration 36600, lr = 0.0134
I0524 22:21:40.234609   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:22:02.995949   808 solver.cpp:218] Iteration 36700 (2.32442 iter/s, 43.0216s/100 iters), loss = 0.0115227
I0524 22:22:02.996134   808 solver.cpp:237]     Train net output #0: loss = 0.0115226 (* 1 = 0.0115226 loss)
I0524 22:22:02.996165   808 sgd_solver.cpp:105] Iteration 36700, lr = 0.0133
I0524 22:22:46.019970   808 solver.cpp:218] Iteration 36800 (2.32427 iter/s, 43.0242s/100 iters), loss = 0.0101718
I0524 22:22:46.020138   808 solver.cpp:237]     Train net output #0: loss = 0.0101717 (* 1 = 0.0101717 loss)
I0524 22:22:46.020149   808 sgd_solver.cpp:105] Iteration 36800, lr = 0.0132
I0524 22:23:21.782493   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:23:29.046147   808 solver.cpp:218] Iteration 36900 (2.32416 iter/s, 43.0264s/100 iters), loss = 0.00916058
I0524 22:23:29.046192   808 solver.cpp:237]     Train net output #0: loss = 0.00916048 (* 1 = 0.00916048 loss)
I0524 22:23:29.046201   808 sgd_solver.cpp:105] Iteration 36900, lr = 0.0131
I0524 22:24:11.633112   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_37000.caffemodel
I0524 22:24:11.784345   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_37000.solverstate
I0524 22:24:12.283190   808 solver.cpp:218] Iteration 37000 (2.31281 iter/s, 43.2374s/100 iters), loss = 0.00510989
I0524 22:24:12.283248   808 solver.cpp:237]     Train net output #0: loss = 0.00510979 (* 1 = 0.00510979 loss)
I0524 22:24:12.283258   808 sgd_solver.cpp:105] Iteration 37000, lr = 0.013
I0524 22:24:55.295068   808 solver.cpp:218] Iteration 37100 (2.32492 iter/s, 43.0122s/100 iters), loss = 0.0229578
I0524 22:24:55.295243   808 solver.cpp:237]     Train net output #0: loss = 0.0229577 (* 1 = 0.0229577 loss)
I0524 22:24:55.295254   808 sgd_solver.cpp:105] Iteration 37100, lr = 0.0129
I0524 22:25:03.943404   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:25:38.312037   808 solver.cpp:218] Iteration 37200 (2.32465 iter/s, 43.0172s/100 iters), loss = 0.0127481
I0524 22:25:38.312186   808 solver.cpp:237]     Train net output #0: loss = 0.012748 (* 1 = 0.012748 loss)
I0524 22:25:38.312196   808 sgd_solver.cpp:105] Iteration 37200, lr = 0.0128
I0524 22:26:21.323714   808 solver.cpp:218] Iteration 37300 (2.32494 iter/s, 43.0119s/100 iters), loss = 0.00519063
I0524 22:26:21.323873   808 solver.cpp:237]     Train net output #0: loss = 0.00519054 (* 1 = 0.00519054 loss)
I0524 22:26:21.323885   808 sgd_solver.cpp:105] Iteration 37300, lr = 0.0127
I0524 22:26:45.457460   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:27:04.343698   808 solver.cpp:218] Iteration 37400 (2.32449 iter/s, 43.0202s/100 iters), loss = 0.00498742
I0524 22:27:04.343860   808 solver.cpp:237]     Train net output #0: loss = 0.00498734 (* 1 = 0.00498734 loss)
I0524 22:27:04.343871   808 sgd_solver.cpp:105] Iteration 37400, lr = 0.0126
I0524 22:27:47.359534   808 solver.cpp:218] Iteration 37500 (2.32471 iter/s, 43.0161s/100 iters), loss = 0.00321567
I0524 22:27:47.359668   808 solver.cpp:237]     Train net output #0: loss = 0.00321559 (* 1 = 0.00321559 loss)
I0524 22:27:47.359678   808 sgd_solver.cpp:105] Iteration 37500, lr = 0.0125
I0524 22:28:27.404307   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:28:30.378485   808 solver.cpp:218] Iteration 37600 (2.32454 iter/s, 43.0192s/100 iters), loss = 0.00298894
I0524 22:28:30.378535   808 solver.cpp:237]     Train net output #0: loss = 0.00298887 (* 1 = 0.00298887 loss)
I0524 22:28:30.378545   808 sgd_solver.cpp:105] Iteration 37600, lr = 0.0124
I0524 22:29:13.400329   808 solver.cpp:218] Iteration 37700 (2.32438 iter/s, 43.0222s/100 iters), loss = 0.00408709
I0524 22:29:13.400455   808 solver.cpp:237]     Train net output #0: loss = 0.00408702 (* 1 = 0.00408702 loss)
I0524 22:29:13.400466   808 sgd_solver.cpp:105] Iteration 37700, lr = 0.0123
I0524 22:29:56.414994   808 solver.cpp:218] Iteration 37800 (2.32477 iter/s, 43.0149s/100 iters), loss = 0.00181335
I0524 22:29:56.415158   808 solver.cpp:237]     Train net output #0: loss = 0.00181328 (* 1 = 0.00181328 loss)
I0524 22:29:56.415169   808 sgd_solver.cpp:105] Iteration 37800, lr = 0.0122
I0524 22:30:08.935745   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:30:39.429847   808 solver.cpp:218] Iteration 37900 (2.32477 iter/s, 43.0151s/100 iters), loss = 0.00220849
I0524 22:30:39.429975   808 solver.cpp:237]     Train net output #0: loss = 0.00220842 (* 1 = 0.00220842 loss)
I0524 22:30:39.429986   808 sgd_solver.cpp:105] Iteration 37900, lr = 0.0121
I0524 22:31:22.025902   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_38000.caffemodel
I0524 22:31:22.178141   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_38000.solverstate
I0524 22:31:22.677326   808 solver.cpp:218] Iteration 38000 (2.31226 iter/s, 43.2478s/100 iters), loss = 0.0120962
I0524 22:31:22.677386   808 solver.cpp:237]     Train net output #0: loss = 0.0120961 (* 1 = 0.0120961 loss)
I0524 22:31:22.677395   808 sgd_solver.cpp:105] Iteration 38000, lr = 0.012
I0524 22:31:51.106542   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:32:05.693034   808 solver.cpp:218] Iteration 38100 (2.32471 iter/s, 43.0161s/100 iters), loss = 0.00710634
I0524 22:32:05.693150   808 solver.cpp:237]     Train net output #0: loss = 0.00710627 (* 1 = 0.00710627 loss)
I0524 22:32:05.693161   808 sgd_solver.cpp:105] Iteration 38100, lr = 0.0119
I0524 22:32:48.700489   808 solver.cpp:218] Iteration 38200 (2.32516 iter/s, 43.0078s/100 iters), loss = 0.00150225
I0524 22:32:48.700598   808 solver.cpp:237]     Train net output #0: loss = 0.00150219 (* 1 = 0.00150219 loss)
I0524 22:32:48.700608   808 sgd_solver.cpp:105] Iteration 38200, lr = 0.0118
I0524 22:33:31.718097   808 solver.cpp:218] Iteration 38300 (2.32461 iter/s, 43.0179s/100 iters), loss = 0.00135996
I0524 22:33:31.718206   808 solver.cpp:237]     Train net output #0: loss = 0.00135989 (* 1 = 0.00135989 loss)
I0524 22:33:31.718215   808 sgd_solver.cpp:105] Iteration 38300, lr = 0.0117
I0524 22:33:32.623520   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:34:14.729909   808 solver.cpp:218] Iteration 38400 (2.32493 iter/s, 43.0121s/100 iters), loss = 0.00200227
I0524 22:34:14.730026   808 solver.cpp:237]     Train net output #0: loss = 0.0020022 (* 1 = 0.0020022 loss)
I0524 22:34:14.730036   808 sgd_solver.cpp:105] Iteration 38400, lr = 0.0116
I0524 22:34:57.735604   808 solver.cpp:218] Iteration 38500 (2.32526 iter/s, 43.006s/100 iters), loss = 0.00188654
I0524 22:34:57.735719   808 solver.cpp:237]     Train net output #0: loss = 0.00188648 (* 1 = 0.00188648 loss)
I0524 22:34:57.735728   808 sgd_solver.cpp:105] Iteration 38500, lr = 0.0115
I0524 22:35:14.138984   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:35:40.757735   808 solver.cpp:218] Iteration 38600 (2.32437 iter/s, 43.0224s/100 iters), loss = 0.00175757
I0524 22:35:40.757897   808 solver.cpp:237]     Train net output #0: loss = 0.00175751 (* 1 = 0.00175751 loss)
I0524 22:35:40.757908   808 sgd_solver.cpp:105] Iteration 38600, lr = 0.0114
I0524 22:36:23.768018   808 solver.cpp:218] Iteration 38700 (2.32501 iter/s, 43.0106s/100 iters), loss = 0.000865814
I0524 22:36:23.768168   808 solver.cpp:237]     Train net output #0: loss = 0.000865752 (* 1 = 0.000865752 loss)
I0524 22:36:23.768178   808 sgd_solver.cpp:105] Iteration 38700, lr = 0.0113
I0524 22:36:56.070159   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:37:06.782069   808 solver.cpp:218] Iteration 38800 (2.32481 iter/s, 43.0143s/100 iters), loss = 0.00120005
I0524 22:37:06.782114   808 solver.cpp:237]     Train net output #0: loss = 0.00119998 (* 1 = 0.00119998 loss)
I0524 22:37:06.782121   808 sgd_solver.cpp:105] Iteration 38800, lr = 0.0112
I0524 22:37:49.802158   808 solver.cpp:218] Iteration 38900 (2.32447 iter/s, 43.0205s/100 iters), loss = 0.00347361
I0524 22:37:49.802317   808 solver.cpp:237]     Train net output #0: loss = 0.00347354 (* 1 = 0.00347354 loss)
I0524 22:37:49.802330   808 sgd_solver.cpp:105] Iteration 38900, lr = 0.0111
I0524 22:38:32.391511   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_39000.caffemodel
I0524 22:38:32.543531   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_39000.solverstate
I0524 22:38:33.043128   808 solver.cpp:218] Iteration 39000 (2.31261 iter/s, 43.2412s/100 iters), loss = 0.000784509
I0524 22:38:33.043172   808 solver.cpp:237]     Train net output #0: loss = 0.000784437 (* 1 = 0.000784437 loss)
I0524 22:38:33.043181   808 sgd_solver.cpp:105] Iteration 39000, lr = 0.011
I0524 22:38:37.826220   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:39:16.051472   808 solver.cpp:218] Iteration 39100 (2.32511 iter/s, 43.0087s/100 iters), loss = 0.000804499
I0524 22:39:16.051606   808 solver.cpp:237]     Train net output #0: loss = 0.000804427 (* 1 = 0.000804427 loss)
I0524 22:39:16.051617   808 sgd_solver.cpp:105] Iteration 39100, lr = 0.0109
I0524 22:39:59.070405   808 solver.cpp:218] Iteration 39200 (2.32454 iter/s, 43.0192s/100 iters), loss = 0.00147362
I0524 22:39:59.070567   808 solver.cpp:237]     Train net output #0: loss = 0.00147354 (* 1 = 0.00147354 loss)
I0524 22:39:59.070578   808 sgd_solver.cpp:105] Iteration 39200, lr = 0.0108
I0524 22:40:19.759827   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:40:42.088361   808 solver.cpp:218] Iteration 39300 (2.3246 iter/s, 43.0182s/100 iters), loss = 0.00142432
I0524 22:40:42.088485   808 solver.cpp:237]     Train net output #0: loss = 0.00142424 (* 1 = 0.00142424 loss)
I0524 22:40:42.088505   808 sgd_solver.cpp:105] Iteration 39300, lr = 0.0107
I0524 22:41:25.110111   808 solver.cpp:218] Iteration 39400 (2.32439 iter/s, 43.0221s/100 iters), loss = 0.00138296
I0524 22:41:25.110263   808 solver.cpp:237]     Train net output #0: loss = 0.00138289 (* 1 = 0.00138289 loss)
I0524 22:41:25.110275   808 sgd_solver.cpp:105] Iteration 39400, lr = 0.0106
I0524 22:42:01.293983   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:42:08.128185   808 solver.cpp:218] Iteration 39500 (2.32459 iter/s, 43.0184s/100 iters), loss = 0.00156071
I0524 22:42:08.128235   808 solver.cpp:237]     Train net output #0: loss = 0.00156064 (* 1 = 0.00156064 loss)
I0524 22:42:08.128244   808 sgd_solver.cpp:105] Iteration 39500, lr = 0.0105
I0524 22:42:51.141954   808 solver.cpp:218] Iteration 39600 (2.32482 iter/s, 43.0142s/100 iters), loss = 0.00107171
I0524 22:42:51.142073   808 solver.cpp:237]     Train net output #0: loss = 0.00107164 (* 1 = 0.00107164 loss)
I0524 22:42:51.142083   808 sgd_solver.cpp:105] Iteration 39600, lr = 0.0104
I0524 22:43:34.164367   808 solver.cpp:218] Iteration 39700 (2.32435 iter/s, 43.0227s/100 iters), loss = 0.00121652
I0524 22:43:34.164490   808 solver.cpp:237]     Train net output #0: loss = 0.00121645 (* 1 = 0.00121645 loss)
I0524 22:43:34.164500   808 sgd_solver.cpp:105] Iteration 39700, lr = 0.0103
I0524 22:43:43.241747   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:44:17.183756   808 solver.cpp:218] Iteration 39800 (2.32452 iter/s, 43.0197s/100 iters), loss = 0.00259149
I0524 22:44:17.183917   808 solver.cpp:237]     Train net output #0: loss = 0.00259142 (* 1 = 0.00259142 loss)
I0524 22:44:17.183928   808 sgd_solver.cpp:105] Iteration 39800, lr = 0.0102
I0524 22:45:00.203464   808 solver.cpp:218] Iteration 39900 (2.3245 iter/s, 43.02s/100 iters), loss = 0.00135655
I0524 22:45:00.203677   808 solver.cpp:237]     Train net output #0: loss = 0.00135649 (* 1 = 0.00135649 loss)
I0524 22:45:00.203703   808 sgd_solver.cpp:105] Iteration 39900, lr = 0.0101
I0524 22:45:24.775689   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:45:42.794267   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_40000.caffemodel
I0524 22:45:42.946074   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_40000.solverstate
I0524 22:45:43.445410   808 solver.cpp:218] Iteration 40000 (2.31256 iter/s, 43.2422s/100 iters), loss = 0.00166577
I0524 22:45:43.445461   808 solver.cpp:237]     Train net output #0: loss = 0.00166571 (* 1 = 0.00166571 loss)
I0524 22:45:43.445480   808 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I0524 22:46:26.460484   808 solver.cpp:218] Iteration 40100 (2.32476 iter/s, 43.0153s/100 iters), loss = 0.00372375
I0524 22:46:26.460606   808 solver.cpp:237]     Train net output #0: loss = 0.00372368 (* 1 = 0.00372368 loss)
I0524 22:46:26.460616   808 sgd_solver.cpp:105] Iteration 40100, lr = 0.0099
I0524 22:47:06.946324   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:47:09.489289   808 solver.cpp:218] Iteration 40200 (2.32402 iter/s, 43.0289s/100 iters), loss = 0.000992783
I0524 22:47:09.489338   808 solver.cpp:237]     Train net output #0: loss = 0.000992718 (* 1 = 0.000992718 loss)
I0524 22:47:09.489346   808 sgd_solver.cpp:105] Iteration 40200, lr = 0.0098
I0524 22:47:52.493242   808 solver.cpp:218] Iteration 40300 (2.32536 iter/s, 43.0041s/100 iters), loss = 0.00428954
I0524 22:47:52.493362   808 solver.cpp:237]     Train net output #0: loss = 0.00428947 (* 1 = 0.00428947 loss)
I0524 22:47:52.493373   808 sgd_solver.cpp:105] Iteration 40300, lr = 0.0097
I0524 22:48:35.509793   808 solver.cpp:218] Iteration 40400 (2.32468 iter/s, 43.0166s/100 iters), loss = 0.00117661
I0524 22:48:35.509932   808 solver.cpp:237]     Train net output #0: loss = 0.00117655 (* 1 = 0.00117655 loss)
I0524 22:48:35.509941   808 sgd_solver.cpp:105] Iteration 40400, lr = 0.0096
I0524 22:48:48.459069   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:49:18.530884   808 solver.cpp:218] Iteration 40500 (2.32444 iter/s, 43.0212s/100 iters), loss = 0.00176423
I0524 22:49:18.531052   808 solver.cpp:237]     Train net output #0: loss = 0.00176417 (* 1 = 0.00176417 loss)
I0524 22:49:18.531064   808 sgd_solver.cpp:105] Iteration 40500, lr = 0.0095
I0524 22:50:01.553998   808 solver.cpp:218] Iteration 40600 (2.32433 iter/s, 43.0232s/100 iters), loss = 0.00163526
I0524 22:50:01.554131   808 solver.cpp:237]     Train net output #0: loss = 0.0016352 (* 1 = 0.0016352 loss)
I0524 22:50:01.554142   808 sgd_solver.cpp:105] Iteration 40600, lr = 0.0094
I0524 22:50:30.417690   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:50:44.576735   808 solver.cpp:218] Iteration 40700 (2.32435 iter/s, 43.0229s/100 iters), loss = 0.000899955
I0524 22:50:44.576876   808 solver.cpp:237]     Train net output #0: loss = 0.00089989 (* 1 = 0.00089989 loss)
I0524 22:50:44.576886   808 sgd_solver.cpp:105] Iteration 40700, lr = 0.0093
I0524 22:51:27.602496   808 solver.cpp:218] Iteration 40800 (2.32418 iter/s, 43.0259s/100 iters), loss = 0.00186487
I0524 22:51:27.602720   808 solver.cpp:237]     Train net output #0: loss = 0.0018648 (* 1 = 0.0018648 loss)
I0524 22:51:27.602732   808 sgd_solver.cpp:105] Iteration 40800, lr = 0.0092
I0524 22:52:10.618357   808 solver.cpp:218] Iteration 40900 (2.32472 iter/s, 43.0159s/100 iters), loss = 0.00141655
I0524 22:52:10.618479   808 solver.cpp:237]     Train net output #0: loss = 0.00141648 (* 1 = 0.00141648 loss)
I0524 22:52:10.618489   808 sgd_solver.cpp:105] Iteration 40900, lr = 0.0091
I0524 22:52:11.955780   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:52:53.206377   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_41000.caffemodel
I0524 22:52:53.357336   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_41000.solverstate
I0524 22:52:53.857062   808 solver.cpp:218] Iteration 41000 (2.31273 iter/s, 43.2389s/100 iters), loss = 0.00171154
I0524 22:52:53.857108   808 solver.cpp:237]     Train net output #0: loss = 0.00171147 (* 1 = 0.00171147 loss)
I0524 22:52:53.857117   808 sgd_solver.cpp:105] Iteration 41000, lr = 0.009
I0524 22:53:36.876461   808 solver.cpp:218] Iteration 41100 (2.32452 iter/s, 43.0196s/100 iters), loss = 0.0031174
I0524 22:53:36.876581   808 solver.cpp:237]     Train net output #0: loss = 0.00311733 (* 1 = 0.00311733 loss)
I0524 22:53:36.876595   808 sgd_solver.cpp:105] Iteration 41100, lr = 0.0089
I0524 22:53:54.122977   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:54:19.892760   808 solver.cpp:218] Iteration 41200 (2.32469 iter/s, 43.0165s/100 iters), loss = 0.00225625
I0524 22:54:19.892894   808 solver.cpp:237]     Train net output #0: loss = 0.00225618 (* 1 = 0.00225618 loss)
I0524 22:54:19.892920   808 sgd_solver.cpp:105] Iteration 41200, lr = 0.0088
I0524 22:55:02.911720   808 solver.cpp:218] Iteration 41300 (2.32455 iter/s, 43.0191s/100 iters), loss = 0.00609405
I0524 22:55:02.911931   808 solver.cpp:237]     Train net output #0: loss = 0.00609399 (* 1 = 0.00609399 loss)
I0524 22:55:02.911942   808 sgd_solver.cpp:105] Iteration 41300, lr = 0.0087
I0524 22:55:35.651928   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:55:45.930579   808 solver.cpp:218] Iteration 41400 (2.32456 iter/s, 43.019s/100 iters), loss = 0.00178388
I0524 22:55:45.930646   808 solver.cpp:237]     Train net output #0: loss = 0.00178382 (* 1 = 0.00178382 loss)
I0524 22:55:45.930655   808 sgd_solver.cpp:105] Iteration 41400, lr = 0.0086
I0524 22:56:28.944310   808 solver.cpp:218] Iteration 41500 (2.32482 iter/s, 43.014s/100 iters), loss = 0.00160532
I0524 22:56:28.944422   808 solver.cpp:237]     Train net output #0: loss = 0.00160526 (* 1 = 0.00160526 loss)
I0524 22:56:28.944432   808 sgd_solver.cpp:105] Iteration 41500, lr = 0.0085
I0524 22:57:11.962901   808 solver.cpp:218] Iteration 41600 (2.32456 iter/s, 43.0188s/100 iters), loss = 0.00170284
I0524 22:57:11.963079   808 solver.cpp:237]     Train net output #0: loss = 0.00170278 (* 1 = 0.00170278 loss)
I0524 22:57:11.963090   808 sgd_solver.cpp:105] Iteration 41600, lr = 0.0084
I0524 22:57:17.178541   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:57:54.979531   808 solver.cpp:218] Iteration 41700 (2.32467 iter/s, 43.0168s/100 iters), loss = 0.00158511
I0524 22:57:54.979653   808 solver.cpp:237]     Train net output #0: loss = 0.00158504 (* 1 = 0.00158504 loss)
I0524 22:57:54.979663   808 sgd_solver.cpp:105] Iteration 41700, lr = 0.0083
I0524 22:58:37.998050   808 solver.cpp:218] Iteration 41800 (2.32457 iter/s, 43.0187s/100 iters), loss = 0.0157457
I0524 22:58:37.998227   808 solver.cpp:237]     Train net output #0: loss = 0.0157457 (* 1 = 0.0157457 loss)
I0524 22:58:37.998245   808 sgd_solver.cpp:105] Iteration 41800, lr = 0.0082
I0524 22:58:59.118078   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 22:59:21.024467   808 solver.cpp:218] Iteration 41900 (2.32414 iter/s, 43.0266s/100 iters), loss = 0.00123279
I0524 22:59:21.024595   808 solver.cpp:237]     Train net output #0: loss = 0.00123273 (* 1 = 0.00123273 loss)
I0524 22:59:21.024616   808 sgd_solver.cpp:105] Iteration 41900, lr = 0.0081
I0524 23:00:03.613309   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_42000.caffemodel
I0524 23:00:03.764482   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_42000.solverstate
I0524 23:00:04.263676   808 solver.cpp:218] Iteration 42000 (2.3127 iter/s, 43.2394s/100 iters), loss = 0.00107915
I0524 23:00:04.263717   808 solver.cpp:237]     Train net output #0: loss = 0.00107909 (* 1 = 0.00107909 loss)
I0524 23:00:04.263726   808 sgd_solver.cpp:105] Iteration 42000, lr = 0.008
I0524 23:00:40.876857   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:00:47.278677   808 solver.cpp:218] Iteration 42100 (2.32475 iter/s, 43.0153s/100 iters), loss = 0.00152071
I0524 23:00:47.278720   808 solver.cpp:237]     Train net output #0: loss = 0.00152065 (* 1 = 0.00152065 loss)
I0524 23:00:47.278730   808 sgd_solver.cpp:105] Iteration 42100, lr = 0.0079
I0524 23:01:30.297219   808 solver.cpp:218] Iteration 42200 (2.32456 iter/s, 43.0189s/100 iters), loss = 0.00167618
I0524 23:01:30.297341   808 solver.cpp:237]     Train net output #0: loss = 0.00167612 (* 1 = 0.00167612 loss)
I0524 23:01:30.297355   808 sgd_solver.cpp:105] Iteration 42200, lr = 0.0078
I0524 23:02:13.316068   808 solver.cpp:218] Iteration 42300 (2.32455 iter/s, 43.0191s/100 iters), loss = 0.00192047
I0524 23:02:13.316272   808 solver.cpp:237]     Train net output #0: loss = 0.00192041 (* 1 = 0.00192041 loss)
I0524 23:02:13.316284   808 sgd_solver.cpp:105] Iteration 42300, lr = 0.0077
I0524 23:02:22.822975   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:02:56.333106   808 solver.cpp:218] Iteration 42400 (2.32465 iter/s, 43.0172s/100 iters), loss = 0.00277379
I0524 23:02:56.333227   808 solver.cpp:237]     Train net output #0: loss = 0.00277373 (* 1 = 0.00277373 loss)
I0524 23:02:56.333238   808 sgd_solver.cpp:105] Iteration 42400, lr = 0.0076
I0524 23:03:39.354413   808 solver.cpp:218] Iteration 42500 (2.32442 iter/s, 43.0216s/100 iters), loss = 0.00136725
I0524 23:03:39.354533   808 solver.cpp:237]     Train net output #0: loss = 0.00136719 (* 1 = 0.00136719 loss)
I0524 23:03:39.354544   808 sgd_solver.cpp:105] Iteration 42500, lr = 0.0075
I0524 23:04:04.351179   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:04:22.362254   808 solver.cpp:218] Iteration 42600 (2.32514 iter/s, 43.0081s/100 iters), loss = 0.0012465
I0524 23:04:22.362479   808 solver.cpp:237]     Train net output #0: loss = 0.00124644 (* 1 = 0.00124644 loss)
I0524 23:04:22.362490   808 sgd_solver.cpp:105] Iteration 42600, lr = 0.0074
I0524 23:05:05.380228   808 solver.cpp:218] Iteration 42700 (2.3246 iter/s, 43.0181s/100 iters), loss = 0.00121206
I0524 23:05:05.380378   808 solver.cpp:237]     Train net output #0: loss = 0.001212 (* 1 = 0.001212 loss)
I0524 23:05:05.380388   808 sgd_solver.cpp:105] Iteration 42700, lr = 0.0073
I0524 23:05:46.277796   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:05:48.387910   808 solver.cpp:218] Iteration 42800 (2.32515 iter/s, 43.0079s/100 iters), loss = 0.00180251
I0524 23:05:48.387956   808 solver.cpp:237]     Train net output #0: loss = 0.00180245 (* 1 = 0.00180245 loss)
I0524 23:05:48.387965   808 sgd_solver.cpp:105] Iteration 42800, lr = 0.0072
I0524 23:06:31.400579   808 solver.cpp:218] Iteration 42900 (2.32488 iter/s, 43.013s/100 iters), loss = 0.0016401
I0524 23:06:31.400691   808 solver.cpp:237]     Train net output #0: loss = 0.00164004 (* 1 = 0.00164004 loss)
I0524 23:06:31.400701   808 sgd_solver.cpp:105] Iteration 42900, lr = 0.0071
I0524 23:07:13.992529   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_43000.caffemodel
I0524 23:07:14.143638   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_43000.solverstate
I0524 23:07:14.642683   808 solver.cpp:218] Iteration 43000 (2.31255 iter/s, 43.2424s/100 iters), loss = 0.00146285
I0524 23:07:14.642734   808 solver.cpp:237]     Train net output #0: loss = 0.00146279 (* 1 = 0.00146279 loss)
I0524 23:07:14.642742   808 sgd_solver.cpp:105] Iteration 43000, lr = 0.007
I0524 23:07:28.027567   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:07:57.658648   808 solver.cpp:218] Iteration 43100 (2.3247 iter/s, 43.0163s/100 iters), loss = 0.00147018
I0524 23:07:57.658778   808 solver.cpp:237]     Train net output #0: loss = 0.00147012 (* 1 = 0.00147012 loss)
I0524 23:07:57.658802   808 sgd_solver.cpp:105] Iteration 43100, lr = 0.0069
I0524 23:08:40.670881   808 solver.cpp:218] Iteration 43200 (2.32491 iter/s, 43.0125s/100 iters), loss = 0.00130537
I0524 23:08:40.671052   808 solver.cpp:237]     Train net output #0: loss = 0.00130531 (* 1 = 0.00130531 loss)
I0524 23:08:40.671064   808 sgd_solver.cpp:105] Iteration 43200, lr = 0.0068
I0524 23:09:09.955094   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:09:23.684298   808 solver.cpp:218] Iteration 43300 (2.32484 iter/s, 43.0136s/100 iters), loss = 0.00167819
I0524 23:09:23.684522   808 solver.cpp:237]     Train net output #0: loss = 0.00167814 (* 1 = 0.00167814 loss)
I0524 23:09:23.684535   808 sgd_solver.cpp:105] Iteration 43300, lr = 0.0067
I0524 23:10:06.707183   808 solver.cpp:218] Iteration 43400 (2.32434 iter/s, 43.0231s/100 iters), loss = 0.00140164
I0524 23:10:06.707311   808 solver.cpp:237]     Train net output #0: loss = 0.00140158 (* 1 = 0.00140158 loss)
I0524 23:10:06.707322   808 sgd_solver.cpp:105] Iteration 43400, lr = 0.0066
I0524 23:10:49.720544   808 solver.cpp:218] Iteration 43500 (2.32485 iter/s, 43.0136s/100 iters), loss = 0.00130435
I0524 23:10:49.720713   808 solver.cpp:237]     Train net output #0: loss = 0.0013043 (* 1 = 0.0013043 loss)
I0524 23:10:49.720726   808 sgd_solver.cpp:105] Iteration 43500, lr = 0.0065
I0524 23:10:51.489382   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:11:32.744966   808 solver.cpp:218] Iteration 43600 (2.32425 iter/s, 43.0246s/100 iters), loss = 0.00239292
I0524 23:11:32.745095   808 solver.cpp:237]     Train net output #0: loss = 0.00239286 (* 1 = 0.00239286 loss)
I0524 23:11:32.745105   808 sgd_solver.cpp:105] Iteration 43600, lr = 0.0064
I0524 23:12:15.754024   808 solver.cpp:218] Iteration 43700 (2.32508 iter/s, 43.0093s/100 iters), loss = 0.00136983
I0524 23:12:15.754243   808 solver.cpp:237]     Train net output #0: loss = 0.00136978 (* 1 = 0.00136978 loss)
I0524 23:12:15.754256   808 sgd_solver.cpp:105] Iteration 43700, lr = 0.0063
I0524 23:12:33.427067   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:12:58.769088   808 solver.cpp:218] Iteration 43800 (2.32476 iter/s, 43.0152s/100 iters), loss = 0.00128823
I0524 23:12:58.769212   808 solver.cpp:237]     Train net output #0: loss = 0.00128817 (* 1 = 0.00128817 loss)
I0524 23:12:58.769232   808 sgd_solver.cpp:105] Iteration 43800, lr = 0.0062
I0524 23:13:41.790537   808 solver.cpp:218] Iteration 43900 (2.32441 iter/s, 43.0217s/100 iters), loss = 0.00248917
I0524 23:13:41.790681   808 solver.cpp:237]     Train net output #0: loss = 0.00248911 (* 1 = 0.00248911 loss)
I0524 23:13:41.790693   808 sgd_solver.cpp:105] Iteration 43900, lr = 0.0061
I0524 23:14:14.964413   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:14:24.384920   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_44000.caffemodel
I0524 23:14:24.536018   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_44000.solverstate
I0524 23:14:25.036165   808 solver.cpp:218] Iteration 44000 (2.31236 iter/s, 43.2459s/100 iters), loss = 0.00181362
I0524 23:14:25.036211   808 solver.cpp:237]     Train net output #0: loss = 0.00181356 (* 1 = 0.00181356 loss)
I0524 23:14:25.036221   808 sgd_solver.cpp:105] Iteration 44000, lr = 0.006
I0524 23:15:08.059018   808 solver.cpp:218] Iteration 44100 (2.32433 iter/s, 43.0232s/100 iters), loss = 0.00174087
I0524 23:15:08.059159   808 solver.cpp:237]     Train net output #0: loss = 0.00174082 (* 1 = 0.00174082 loss)
I0524 23:15:08.059170   808 sgd_solver.cpp:105] Iteration 44100, lr = 0.0059
I0524 23:15:51.083968   808 solver.cpp:218] Iteration 44200 (2.32422 iter/s, 43.0252s/100 iters), loss = 0.00175381
I0524 23:15:51.084091   808 solver.cpp:237]     Train net output #0: loss = 0.00175376 (* 1 = 0.00175376 loss)
I0524 23:15:51.084112   808 sgd_solver.cpp:105] Iteration 44200, lr = 0.0058
I0524 23:15:57.142391   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:16:34.096077   808 solver.cpp:218] Iteration 44300 (2.32491 iter/s, 43.0124s/100 iters), loss = 0.00192366
I0524 23:16:34.096238   808 solver.cpp:237]     Train net output #0: loss = 0.00192361 (* 1 = 0.00192361 loss)
I0524 23:16:34.096249   808 sgd_solver.cpp:105] Iteration 44300, lr = 0.0057
I0524 23:17:17.120115   808 solver.cpp:218] Iteration 44400 (2.32427 iter/s, 43.0243s/100 iters), loss = 0.00211398
I0524 23:17:17.120232   808 solver.cpp:237]     Train net output #0: loss = 0.00211393 (* 1 = 0.00211393 loss)
I0524 23:17:17.120242   808 sgd_solver.cpp:105] Iteration 44400, lr = 0.0056
I0524 23:17:38.671711   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:18:00.135033   808 solver.cpp:218] Iteration 44500 (2.32476 iter/s, 43.0152s/100 iters), loss = 0.0029172
I0524 23:18:00.135159   808 solver.cpp:237]     Train net output #0: loss = 0.00291714 (* 1 = 0.00291714 loss)
I0524 23:18:00.135169   808 sgd_solver.cpp:105] Iteration 44500, lr = 0.0055
I0524 23:18:43.149289   808 solver.cpp:218] Iteration 44600 (2.3248 iter/s, 43.0145s/100 iters), loss = 0.00196371
I0524 23:18:43.149402   808 solver.cpp:237]     Train net output #0: loss = 0.00196365 (* 1 = 0.00196365 loss)
I0524 23:18:43.149413   808 sgd_solver.cpp:105] Iteration 44600, lr = 0.0054
I0524 23:19:20.194520   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:19:26.165910   808 solver.cpp:218] Iteration 44700 (2.32467 iter/s, 43.0169s/100 iters), loss = 0.00223622
I0524 23:19:26.165952   808 solver.cpp:237]     Train net output #0: loss = 0.00223617 (* 1 = 0.00223617 loss)
I0524 23:19:26.165961   808 sgd_solver.cpp:105] Iteration 44700, lr = 0.0053
I0524 23:20:09.181315   808 solver.cpp:218] Iteration 44800 (2.32473 iter/s, 43.0157s/100 iters), loss = 0.00121277
I0524 23:20:09.181469   808 solver.cpp:237]     Train net output #0: loss = 0.00121272 (* 1 = 0.00121272 loss)
I0524 23:20:09.181480   808 sgd_solver.cpp:105] Iteration 44800, lr = 0.0052
I0524 23:20:52.194800   808 solver.cpp:218] Iteration 44900 (2.32485 iter/s, 43.0135s/100 iters), loss = 0.00204576
I0524 23:20:52.194918   808 solver.cpp:237]     Train net output #0: loss = 0.0020457 (* 1 = 0.0020457 loss)
I0524 23:20:52.194928   808 sgd_solver.cpp:105] Iteration 44900, lr = 0.0051
I0524 23:21:02.133781   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:21:34.781488   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_45000.caffemodel
I0524 23:21:34.932144   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_45000.solverstate
I0524 23:21:35.432020   808 solver.cpp:218] Iteration 45000 (2.31282 iter/s, 43.2373s/100 iters), loss = 0.00244222
I0524 23:21:35.432065   808 solver.cpp:237]     Train net output #0: loss = 0.00244216 (* 1 = 0.00244216 loss)
I0524 23:21:35.432073   808 sgd_solver.cpp:105] Iteration 45000, lr = 0.005
I0524 23:22:18.441820   808 solver.cpp:218] Iteration 45100 (2.32504 iter/s, 43.01s/100 iters), loss = 0.00150687
I0524 23:22:18.441937   808 solver.cpp:237]     Train net output #0: loss = 0.00150681 (* 1 = 0.00150681 loss)
I0524 23:22:18.441948   808 sgd_solver.cpp:105] Iteration 45100, lr = 0.0049
I0524 23:22:43.868468   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:23:01.452592   808 solver.cpp:218] Iteration 45200 (2.32499 iter/s, 43.0109s/100 iters), loss = 0.00112018
I0524 23:23:01.452795   808 solver.cpp:237]     Train net output #0: loss = 0.00112012 (* 1 = 0.00112012 loss)
I0524 23:23:01.452810   808 sgd_solver.cpp:105] Iteration 45200, lr = 0.0048
I0524 23:23:44.471432   808 solver.cpp:218] Iteration 45300 (2.32456 iter/s, 43.0189s/100 iters), loss = 0.00110633
I0524 23:23:44.471559   808 solver.cpp:237]     Train net output #0: loss = 0.00110627 (* 1 = 0.00110627 loss)
I0524 23:23:44.471568   808 sgd_solver.cpp:105] Iteration 45300, lr = 0.0047
I0524 23:24:25.808002   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:24:27.487370   808 solver.cpp:218] Iteration 45400 (2.32471 iter/s, 43.0161s/100 iters), loss = 0.00160456
I0524 23:24:27.487414   808 solver.cpp:237]     Train net output #0: loss = 0.0016045 (* 1 = 0.0016045 loss)
I0524 23:24:27.487423   808 sgd_solver.cpp:105] Iteration 45400, lr = 0.0046
I0524 23:25:10.508126   808 solver.cpp:218] Iteration 45500 (2.32445 iter/s, 43.021s/100 iters), loss = 0.00214613
I0524 23:25:10.508242   808 solver.cpp:237]     Train net output #0: loss = 0.00214608 (* 1 = 0.00214608 loss)
I0524 23:25:10.508252   808 sgd_solver.cpp:105] Iteration 45500, lr = 0.0045
I0524 23:25:53.525635   808 solver.cpp:218] Iteration 45600 (2.32463 iter/s, 43.0177s/100 iters), loss = 0.00154013
I0524 23:25:53.525763   808 solver.cpp:237]     Train net output #0: loss = 0.00154008 (* 1 = 0.00154008 loss)
I0524 23:25:53.525785   808 sgd_solver.cpp:105] Iteration 45600, lr = 0.0044
I0524 23:26:07.342108   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:26:36.536905   808 solver.cpp:218] Iteration 45700 (2.32496 iter/s, 43.0114s/100 iters), loss = 0.00158453
I0524 23:26:36.537027   808 solver.cpp:237]     Train net output #0: loss = 0.00158447 (* 1 = 0.00158447 loss)
I0524 23:26:36.537037   808 sgd_solver.cpp:105] Iteration 45700, lr = 0.0043
I0524 23:27:19.551141   808 solver.cpp:218] Iteration 45800 (2.3248 iter/s, 43.0144s/100 iters), loss = 0.00181008
I0524 23:27:19.551259   808 solver.cpp:237]     Train net output #0: loss = 0.00181003 (* 1 = 0.00181003 loss)
I0524 23:27:19.551268   808 sgd_solver.cpp:105] Iteration 45800, lr = 0.0042
I0524 23:27:49.271744   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:28:02.566602   808 solver.cpp:218] Iteration 45900 (2.32474 iter/s, 43.0156s/100 iters), loss = 0.00175195
I0524 23:28:02.566725   808 solver.cpp:237]     Train net output #0: loss = 0.0017519 (* 1 = 0.0017519 loss)
I0524 23:28:02.566735   808 sgd_solver.cpp:105] Iteration 45900, lr = 0.0041
I0524 23:28:45.154772   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_46000.caffemodel
I0524 23:28:45.305555   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_46000.solverstate
I0524 23:28:45.804955   808 solver.cpp:218] Iteration 46000 (2.31275 iter/s, 43.2385s/100 iters), loss = 0.00357276
I0524 23:28:45.804994   808 solver.cpp:237]     Train net output #0: loss = 0.0035727 (* 1 = 0.0035727 loss)
I0524 23:28:45.805003   808 sgd_solver.cpp:105] Iteration 46000, lr = 0.004
I0524 23:29:28.822043   808 solver.cpp:218] Iteration 46100 (2.32464 iter/s, 43.0174s/100 iters), loss = 0.00142359
I0524 23:29:28.822161   808 solver.cpp:237]     Train net output #0: loss = 0.00142354 (* 1 = 0.00142354 loss)
I0524 23:29:28.822171   808 sgd_solver.cpp:105] Iteration 46100, lr = 0.0039
I0524 23:29:31.020967   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:30:11.841814   808 solver.cpp:218] Iteration 46200 (2.3245 iter/s, 43.02s/100 iters), loss = 0.00151172
I0524 23:30:11.841954   808 solver.cpp:237]     Train net output #0: loss = 0.00151166 (* 1 = 0.00151166 loss)
I0524 23:30:11.841964   808 sgd_solver.cpp:105] Iteration 46200, lr = 0.0038
I0524 23:30:54.851491   808 solver.cpp:218] Iteration 46300 (2.32505 iter/s, 43.0099s/100 iters), loss = 0.0018683
I0524 23:30:54.851616   808 solver.cpp:237]     Train net output #0: loss = 0.00186825 (* 1 = 0.00186825 loss)
I0524 23:30:54.851626   808 sgd_solver.cpp:105] Iteration 46300, lr = 0.0037
I0524 23:31:12.965096   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:31:37.875998   808 solver.cpp:218] Iteration 46400 (2.32425 iter/s, 43.0247s/100 iters), loss = 0.00168129
I0524 23:31:37.876129   808 solver.cpp:237]     Train net output #0: loss = 0.00168124 (* 1 = 0.00168124 loss)
I0524 23:31:37.876139   808 sgd_solver.cpp:105] Iteration 46400, lr = 0.0036
I0524 23:32:20.886289   808 solver.cpp:218] Iteration 46500 (2.32501 iter/s, 43.0105s/100 iters), loss = 0.00144037
I0524 23:32:20.886422   808 solver.cpp:237]     Train net output #0: loss = 0.00144031 (* 1 = 0.00144031 loss)
I0524 23:32:20.886435   808 sgd_solver.cpp:105] Iteration 46500, lr = 0.0035
I0524 23:32:54.485172   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:33:03.905874   808 solver.cpp:218] Iteration 46600 (2.32451 iter/s, 43.0198s/100 iters), loss = 0.00191955
I0524 23:33:03.905935   808 solver.cpp:237]     Train net output #0: loss = 0.00191949 (* 1 = 0.00191949 loss)
I0524 23:33:03.905943   808 sgd_solver.cpp:105] Iteration 46600, lr = 0.0034
I0524 23:33:46.922513   808 solver.cpp:218] Iteration 46700 (2.32467 iter/s, 43.0169s/100 iters), loss = 0.00263324
I0524 23:33:46.922642   808 solver.cpp:237]     Train net output #0: loss = 0.00263318 (* 1 = 0.00263318 loss)
I0524 23:33:46.922663   808 sgd_solver.cpp:105] Iteration 46700, lr = 0.0033
I0524 23:34:29.933068   808 solver.cpp:218] Iteration 46800 (2.325 iter/s, 43.0108s/100 iters), loss = 0.00154875
I0524 23:34:29.933220   808 solver.cpp:237]     Train net output #0: loss = 0.0015487 (* 1 = 0.0015487 loss)
I0524 23:34:29.933230   808 sgd_solver.cpp:105] Iteration 46800, lr = 0.0032
I0524 23:34:36.424283   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:35:12.948323   808 solver.cpp:218] Iteration 46900 (2.32475 iter/s, 43.0155s/100 iters), loss = 0.00204303
I0524 23:35:12.948451   808 solver.cpp:237]     Train net output #0: loss = 0.00204297 (* 1 = 0.00204297 loss)
I0524 23:35:12.948472   808 sgd_solver.cpp:105] Iteration 46900, lr = 0.0031
I0524 23:35:55.538633   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_47000.caffemodel
I0524 23:35:55.689924   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_47000.solverstate
I0524 23:35:56.189313   808 solver.cpp:218] Iteration 47000 (2.31261 iter/s, 43.2412s/100 iters), loss = 0.00165938
I0524 23:35:56.189362   808 solver.cpp:237]     Train net output #0: loss = 0.00165932 (* 1 = 0.00165932 loss)
I0524 23:35:56.189370   808 sgd_solver.cpp:105] Iteration 47000, lr = 0.003
I0524 23:36:18.176730   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:36:39.205873   808 solver.cpp:218] Iteration 47100 (2.32467 iter/s, 43.0169s/100 iters), loss = 0.00230589
I0524 23:36:39.206035   808 solver.cpp:237]     Train net output #0: loss = 0.00230584 (* 1 = 0.00230584 loss)
I0524 23:36:39.206050   808 sgd_solver.cpp:105] Iteration 47100, lr = 0.0029
I0524 23:37:22.224066   808 solver.cpp:218] Iteration 47200 (2.32459 iter/s, 43.0184s/100 iters), loss = 0.00146135
I0524 23:37:22.224194   808 solver.cpp:237]     Train net output #0: loss = 0.0014613 (* 1 = 0.0014613 loss)
I0524 23:37:22.224213   808 sgd_solver.cpp:105] Iteration 47200, lr = 0.0028
I0524 23:37:59.697546   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:38:05.239838   808 solver.cpp:218] Iteration 47300 (2.32472 iter/s, 43.016s/100 iters), loss = 0.00198701
I0524 23:38:05.239886   808 solver.cpp:237]     Train net output #0: loss = 0.00198696 (* 1 = 0.00198696 loss)
I0524 23:38:05.239894   808 sgd_solver.cpp:105] Iteration 47300, lr = 0.0027
I0524 23:38:48.242460   808 solver.cpp:218] Iteration 47400 (2.32542 iter/s, 43.0029s/100 iters), loss = 0.00187977
I0524 23:38:48.242578   808 solver.cpp:237]     Train net output #0: loss = 0.00187972 (* 1 = 0.00187972 loss)
I0524 23:38:48.242604   808 sgd_solver.cpp:105] Iteration 47400, lr = 0.0026
I0524 23:39:31.266396   808 solver.cpp:218] Iteration 47500 (2.32427 iter/s, 43.0242s/100 iters), loss = 0.00134339
I0524 23:39:31.266520   808 solver.cpp:237]     Train net output #0: loss = 0.00134334 (* 1 = 0.00134334 loss)
I0524 23:39:31.266546   808 sgd_solver.cpp:105] Iteration 47500, lr = 0.0025
I0524 23:39:41.634973   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:40:14.294304   808 solver.cpp:218] Iteration 47600 (2.32406 iter/s, 43.0281s/100 iters), loss = 0.00202293
I0524 23:40:14.294466   808 solver.cpp:237]     Train net output #0: loss = 0.00202288 (* 1 = 0.00202288 loss)
I0524 23:40:14.294481   808 sgd_solver.cpp:105] Iteration 47600, lr = 0.0024
I0524 23:40:57.309307   808 solver.cpp:218] Iteration 47700 (2.32476 iter/s, 43.0152s/100 iters), loss = 0.00145963
I0524 23:40:57.309453   808 solver.cpp:237]     Train net output #0: loss = 0.00145958 (* 1 = 0.00145958 loss)
I0524 23:40:57.309463   808 sgd_solver.cpp:105] Iteration 47700, lr = 0.0023
I0524 23:41:23.180495   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:41:40.334985   808 solver.cpp:218] Iteration 47800 (2.32418 iter/s, 43.0259s/100 iters), loss = 0.00155898
I0524 23:41:40.335116   808 solver.cpp:237]     Train net output #0: loss = 0.00155893 (* 1 = 0.00155893 loss)
I0524 23:41:40.335142   808 sgd_solver.cpp:105] Iteration 47800, lr = 0.0022
I0524 23:42:23.348541   808 solver.cpp:218] Iteration 47900 (2.32484 iter/s, 43.0138s/100 iters), loss = 0.0014224
I0524 23:42:23.348655   808 solver.cpp:237]     Train net output #0: loss = 0.00142235 (* 1 = 0.00142235 loss)
I0524 23:42:23.348666   808 sgd_solver.cpp:105] Iteration 47900, lr = 0.0021
I0524 23:43:05.123313   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:43:05.943979   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_48000.caffemodel
I0524 23:43:06.095494   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_48000.solverstate
I0524 23:43:06.595577   808 solver.cpp:218] Iteration 48000 (2.31228 iter/s, 43.2473s/100 iters), loss = 0.00162486
I0524 23:43:06.595624   808 solver.cpp:237]     Train net output #0: loss = 0.00162481 (* 1 = 0.00162481 loss)
I0524 23:43:06.595633   808 sgd_solver.cpp:105] Iteration 48000, lr = 0.002
I0524 23:43:49.615221   808 solver.cpp:218] Iteration 48100 (2.3245 iter/s, 43.02s/100 iters), loss = 0.00106255
I0524 23:43:49.615339   808 solver.cpp:237]     Train net output #0: loss = 0.0010625 (* 1 = 0.0010625 loss)
I0524 23:43:49.615363   808 sgd_solver.cpp:105] Iteration 48100, lr = 0.0019
I0524 23:44:32.631427   808 solver.cpp:218] Iteration 48200 (2.32469 iter/s, 43.0165s/100 iters), loss = 0.00160379
I0524 23:44:32.631583   808 solver.cpp:237]     Train net output #0: loss = 0.00160374 (* 1 = 0.00160374 loss)
I0524 23:44:32.631599   808 sgd_solver.cpp:105] Iteration 48200, lr = 0.0018
I0524 23:44:46.878263   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:45:15.654120   808 solver.cpp:218] Iteration 48300 (2.32434 iter/s, 43.0229s/100 iters), loss = 0.00194824
I0524 23:45:15.654289   808 solver.cpp:237]     Train net output #0: loss = 0.00194819 (* 1 = 0.00194819 loss)
I0524 23:45:15.654301   808 sgd_solver.cpp:105] Iteration 48300, lr = 0.0017
I0524 23:45:58.675525   808 solver.cpp:218] Iteration 48400 (2.32441 iter/s, 43.0216s/100 iters), loss = 0.00240193
I0524 23:45:58.675725   808 solver.cpp:237]     Train net output #0: loss = 0.00240188 (* 1 = 0.00240188 loss)
I0524 23:45:58.675736   808 sgd_solver.cpp:105] Iteration 48400, lr = 0.0016
I0524 23:46:28.828560   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:46:41.688092   808 solver.cpp:218] Iteration 48500 (2.32489 iter/s, 43.0128s/100 iters), loss = 0.00139034
I0524 23:46:41.688133   808 solver.cpp:237]     Train net output #0: loss = 0.00139029 (* 1 = 0.00139029 loss)
I0524 23:46:41.688141   808 sgd_solver.cpp:105] Iteration 48500, lr = 0.0015
I0524 23:47:24.700585   808 solver.cpp:218] Iteration 48600 (2.32489 iter/s, 43.0128s/100 iters), loss = 0.00298166
I0524 23:47:24.700747   808 solver.cpp:237]     Train net output #0: loss = 0.00298161 (* 1 = 0.00298161 loss)
I0524 23:47:24.700758   808 sgd_solver.cpp:105] Iteration 48600, lr = 0.0014
I0524 23:48:07.711968   808 solver.cpp:218] Iteration 48700 (2.32495 iter/s, 43.0116s/100 iters), loss = 0.0024383
I0524 23:48:07.712087   808 solver.cpp:237]     Train net output #0: loss = 0.00243825 (* 1 = 0.00243825 loss)
I0524 23:48:07.712108   808 sgd_solver.cpp:105] Iteration 48700, lr = 0.0013
I0524 23:48:10.343183   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:48:50.720048   808 solver.cpp:218] Iteration 48800 (2.32513 iter/s, 43.0083s/100 iters), loss = 0.00148626
I0524 23:48:50.720191   808 solver.cpp:237]     Train net output #0: loss = 0.0014862 (* 1 = 0.0014862 loss)
I0524 23:48:50.720201   808 sgd_solver.cpp:105] Iteration 48800, lr = 0.0012
I0524 23:49:33.737141   808 solver.cpp:218] Iteration 48900 (2.32464 iter/s, 43.0173s/100 iters), loss = 0.00140736
I0524 23:49:33.737264   808 solver.cpp:237]     Train net output #0: loss = 0.00140731 (* 1 = 0.00140731 loss)
I0524 23:49:33.737274   808 sgd_solver.cpp:105] Iteration 48900, lr = 0.0011
I0524 23:49:52.272918   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:50:16.333889   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_49000.caffemodel
I0524 23:50:16.485131   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_49000.solverstate
I0524 23:50:16.984403   808 solver.cpp:218] Iteration 49000 (2.31227 iter/s, 43.2475s/100 iters), loss = 0.00223742
I0524 23:50:16.984447   808 solver.cpp:237]     Train net output #0: loss = 0.00223737 (* 1 = 0.00223737 loss)
I0524 23:50:16.984457   808 sgd_solver.cpp:105] Iteration 49000, lr = 0.000999999
I0524 23:51:00.006083   808 solver.cpp:218] Iteration 49100 (2.32439 iter/s, 43.022s/100 iters), loss = 0.0023995
I0524 23:51:00.006227   808 solver.cpp:237]     Train net output #0: loss = 0.00239945 (* 1 = 0.00239945 loss)
I0524 23:51:00.006237   808 sgd_solver.cpp:105] Iteration 49100, lr = 0.0009
I0524 23:51:34.046526   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:51:43.031007   808 solver.cpp:218] Iteration 49200 (2.32422 iter/s, 43.0252s/100 iters), loss = 0.00221305
I0524 23:51:43.031059   808 solver.cpp:237]     Train net output #0: loss = 0.002213 (* 1 = 0.002213 loss)
I0524 23:51:43.031067   808 sgd_solver.cpp:105] Iteration 49200, lr = 0.000799999
I0524 23:52:26.043520   808 solver.cpp:218] Iteration 49300 (2.32489 iter/s, 43.0128s/100 iters), loss = 0.00208771
I0524 23:52:26.043671   808 solver.cpp:237]     Train net output #0: loss = 0.00208766 (* 1 = 0.00208766 loss)
I0524 23:52:26.043681   808 sgd_solver.cpp:105] Iteration 49300, lr = 0.0007
I0524 23:53:09.063169   808 solver.cpp:218] Iteration 49400 (2.32451 iter/s, 43.0199s/100 iters), loss = 0.00160197
I0524 23:53:09.063294   808 solver.cpp:237]     Train net output #0: loss = 0.00160192 (* 1 = 0.00160192 loss)
I0524 23:53:09.063316   808 sgd_solver.cpp:105] Iteration 49400, lr = 0.000600001
I0524 23:53:15.988652   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:53:52.090279   808 solver.cpp:218] Iteration 49500 (2.3241 iter/s, 43.0273s/100 iters), loss = 0.00185041
I0524 23:53:52.090471   808 solver.cpp:237]     Train net output #0: loss = 0.00185036 (* 1 = 0.00185036 loss)
I0524 23:53:52.090494   808 sgd_solver.cpp:105] Iteration 49500, lr = 0.0005
I0524 23:54:35.103483   808 solver.cpp:218] Iteration 49600 (2.32485 iter/s, 43.0135s/100 iters), loss = 0.00142183
I0524 23:54:35.103626   808 solver.cpp:237]     Train net output #0: loss = 0.00142178 (* 1 = 0.00142178 loss)
I0524 23:54:35.103637   808 sgd_solver.cpp:105] Iteration 49600, lr = 0.000400001
I0524 23:54:57.512775   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:55:18.122217   808 solver.cpp:218] Iteration 49700 (2.32454 iter/s, 43.0193s/100 iters), loss = 0.00195056
I0524 23:55:18.122347   808 solver.cpp:237]     Train net output #0: loss = 0.00195051 (* 1 = 0.00195051 loss)
I0524 23:55:18.122357   808 sgd_solver.cpp:105] Iteration 49700, lr = 0.000299999
I0524 23:56:01.135473   808 solver.cpp:218] Iteration 49800 (2.32484 iter/s, 43.0138s/100 iters), loss = 0.00186547
I0524 23:56:01.135612   808 solver.cpp:237]     Train net output #0: loss = 0.00186542 (* 1 = 0.00186542 loss)
I0524 23:56:01.135623   808 sgd_solver.cpp:105] Iteration 49800, lr = 0.0002
I0524 23:56:39.453248   820 data_layer.cpp:73] Restarting data prefetching from start.
I0524 23:56:44.146605   808 solver.cpp:218] Iteration 49900 (2.32495 iter/s, 43.0116s/100 iters), loss = 0.00194794
I0524 23:56:44.146657   808 solver.cpp:237]     Train net output #0: loss = 0.00194789 (* 1 = 0.00194789 loss)
I0524 23:56:44.146667   808 sgd_solver.cpp:105] Iteration 49900, lr = 9.99987e-05
I0524 23:57:26.747232   808 solver.cpp:447] Snapshotting to binary proto file resnet-imagenet_iter_50000.caffemodel
I0524 23:57:26.899902   808 sgd_solver.cpp:273] Snapshotting solver state to binary proto file resnet-imagenet_iter_50000.solverstate
I0524 23:57:27.089804   808 solver.cpp:310] Iteration 50000, loss = 0.00213705
I0524 23:57:27.089843   808 solver.cpp:315] Optimization Done.
I0524 23:57:27.089859   808 caffe.cpp:259] Optimization Done.
