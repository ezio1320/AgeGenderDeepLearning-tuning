I0526 15:44:48.832350 30701 caffe.cpp:218] Using GPUs 0
I0526 15:44:48.897099 30701 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I0526 15:44:49.197129 30701 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 200000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "pre-resnet-50"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "50_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0526 15:44:49.197314 30701 solver.cpp:87] Creating training net from net file: 50_train_val_test_fold_is_0.prototxt
I0526 15:44:49.198607 30701 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 50_train_val_test_fold_is_0.prototxt
I0526 15:44:49.198627 30701 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0526 15:44:49.198891 30701 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0526 15:44:49.198989 30701 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0526 15:44:49.200182 30701 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-50"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto"
  }
  data_param {
    source: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_train_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn3"
  type: "BatchNorm"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale3"
  type: "Scale"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu3"
  type: "ReLU"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
}
layer {
  name: "layer_256_1_conv3"
  type: "Convolution"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv3"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn3"
  type: "BatchNorm"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale3"
  type: "Scale"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu3"
  type: "ReLU"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
}
layer {
  name: "layer_256_2_conv3"
  type: "Convolution"
 
I0526 15:44:49.201220 30701 layer_factory.hpp:77] Creating layer data
I0526 15:44:49.201346 30701 db_lmdb.cpp:35] Opened lmdb /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_train_lmdb
I0526 15:44:49.201383 30701 net.cpp:84] Creating Layer data
I0526 15:44:49.201395 30701 net.cpp:380] data -> data
I0526 15:44:49.201421 30701 net.cpp:380] data -> label
I0526 15:44:49.201436 30701 data_transformer.cpp:25] Loading mean file from: /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto
I0526 15:44:49.204329 30701 data_layer.cpp:45] output data size: 20,3,224,224
I0526 15:44:49.231775 30701 net.cpp:122] Setting up data
I0526 15:44:49.231803 30701 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0526 15:44:49.231809 30701 net.cpp:129] Top shape: 20 (20)
I0526 15:44:49.231812 30701 net.cpp:137] Memory required for data: 12042320
I0526 15:44:49.231822 30701 layer_factory.hpp:77] Creating layer data_bn
I0526 15:44:49.231842 30701 net.cpp:84] Creating Layer data_bn
I0526 15:44:49.231850 30701 net.cpp:406] data_bn <- data
I0526 15:44:49.231868 30701 net.cpp:380] data_bn -> data_bn
I0526 15:44:49.232836 30701 net.cpp:122] Setting up data_bn
I0526 15:44:49.232847 30701 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0526 15:44:49.232863 30701 net.cpp:137] Memory required for data: 24084560
I0526 15:44:49.232890 30701 layer_factory.hpp:77] Creating layer data_scale
I0526 15:44:49.232903 30701 net.cpp:84] Creating Layer data_scale
I0526 15:44:49.232905 30701 net.cpp:406] data_scale <- data_bn
I0526 15:44:49.232913 30701 net.cpp:367] data_scale -> data_bn (in-place)
I0526 15:44:49.232960 30701 layer_factory.hpp:77] Creating layer data_scale
I0526 15:44:49.233101 30701 net.cpp:122] Setting up data_scale
I0526 15:44:49.233111 30701 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0526 15:44:49.233115 30701 net.cpp:137] Memory required for data: 36126800
I0526 15:44:49.233122 30701 layer_factory.hpp:77] Creating layer conv1
I0526 15:44:49.233136 30701 net.cpp:84] Creating Layer conv1
I0526 15:44:49.233141 30701 net.cpp:406] conv1 <- data_bn
I0526 15:44:49.233146 30701 net.cpp:380] conv1 -> conv1
I0526 15:44:49.453364 30701 net.cpp:122] Setting up conv1
I0526 15:44:49.453394 30701 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0526 15:44:49.453398 30701 net.cpp:137] Memory required for data: 100352080
I0526 15:44:49.453409 30701 layer_factory.hpp:77] Creating layer conv1_bn
I0526 15:44:49.453423 30701 net.cpp:84] Creating Layer conv1_bn
I0526 15:44:49.453438 30701 net.cpp:406] conv1_bn <- conv1
I0526 15:44:49.453447 30701 net.cpp:367] conv1_bn -> conv1 (in-place)
I0526 15:44:49.453619 30701 net.cpp:122] Setting up conv1_bn
I0526 15:44:49.453627 30701 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0526 15:44:49.453630 30701 net.cpp:137] Memory required for data: 164577360
I0526 15:44:49.453641 30701 layer_factory.hpp:77] Creating layer conv1_scale
I0526 15:44:49.453649 30701 net.cpp:84] Creating Layer conv1_scale
I0526 15:44:49.453652 30701 net.cpp:406] conv1_scale <- conv1
I0526 15:44:49.453660 30701 net.cpp:367] conv1_scale -> conv1 (in-place)
I0526 15:44:49.453713 30701 layer_factory.hpp:77] Creating layer conv1_scale
I0526 15:44:49.453829 30701 net.cpp:122] Setting up conv1_scale
I0526 15:44:49.453837 30701 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0526 15:44:49.453840 30701 net.cpp:137] Memory required for data: 228802640
I0526 15:44:49.453846 30701 layer_factory.hpp:77] Creating layer conv1_relu
I0526 15:44:49.453852 30701 net.cpp:84] Creating Layer conv1_relu
I0526 15:44:49.453855 30701 net.cpp:406] conv1_relu <- conv1
I0526 15:44:49.453860 30701 net.cpp:367] conv1_relu -> conv1 (in-place)
I0526 15:44:49.454023 30701 net.cpp:122] Setting up conv1_relu
I0526 15:44:49.454032 30701 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0526 15:44:49.454036 30701 net.cpp:137] Memory required for data: 293027920
I0526 15:44:49.454040 30701 layer_factory.hpp:77] Creating layer conv1_pool
I0526 15:44:49.454046 30701 net.cpp:84] Creating Layer conv1_pool
I0526 15:44:49.454048 30701 net.cpp:406] conv1_pool <- conv1
I0526 15:44:49.454054 30701 net.cpp:380] conv1_pool -> conv1_pool
I0526 15:44:49.454113 30701 net.cpp:122] Setting up conv1_pool
I0526 15:44:49.454123 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.454125 30701 net.cpp:137] Memory required for data: 309084240
I0526 15:44:49.454128 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0526 15:44:49.454139 30701 net.cpp:84] Creating Layer layer_64_1_conv1
I0526 15:44:49.454145 30701 net.cpp:406] layer_64_1_conv1 <- conv1_pool
I0526 15:44:49.454156 30701 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0526 15:44:49.455924 30701 net.cpp:122] Setting up layer_64_1_conv1
I0526 15:44:49.455936 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.455940 30701 net.cpp:137] Memory required for data: 325140560
I0526 15:44:49.455945 30701 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0526 15:44:49.455971 30701 net.cpp:84] Creating Layer layer_64_1_bn2
I0526 15:44:49.455974 30701 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0526 15:44:49.455981 30701 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.456131 30701 net.cpp:122] Setting up layer_64_1_bn2
I0526 15:44:49.456140 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.456143 30701 net.cpp:137] Memory required for data: 341196880
I0526 15:44:49.456151 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0526 15:44:49.456156 30701 net.cpp:84] Creating Layer layer_64_1_scale2
I0526 15:44:49.456159 30701 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0526 15:44:49.456164 30701 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.456224 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0526 15:44:49.456322 30701 net.cpp:122] Setting up layer_64_1_scale2
I0526 15:44:49.456331 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.456336 30701 net.cpp:137] Memory required for data: 357253200
I0526 15:44:49.456354 30701 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0526 15:44:49.456360 30701 net.cpp:84] Creating Layer layer_64_1_relu2
I0526 15:44:49.456364 30701 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0526 15:44:49.456372 30701 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.456985 30701 net.cpp:122] Setting up layer_64_1_relu2
I0526 15:44:49.457000 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.457017 30701 net.cpp:137] Memory required for data: 373309520
I0526 15:44:49.457022 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.457031 30701 net.cpp:84] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.457037 30701 net.cpp:406] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0526 15:44:49.457051 30701 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0526 15:44:49.457062 30701 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0526 15:44:49.457103 30701 net.cpp:122] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.457121 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.457126 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.457130 30701 net.cpp:137] Memory required for data: 405422160
I0526 15:44:49.457134 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0526 15:44:49.457144 30701 net.cpp:84] Creating Layer layer_64_1_conv2
I0526 15:44:49.457149 30701 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0526 15:44:49.457154 30701 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0526 15:44:49.458554 30701 net.cpp:122] Setting up layer_64_1_conv2
I0526 15:44:49.458566 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.458581 30701 net.cpp:137] Memory required for data: 421478480
I0526 15:44:49.458588 30701 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0526 15:44:49.458596 30701 net.cpp:84] Creating Layer layer_64_1_bn3
I0526 15:44:49.458603 30701 net.cpp:406] layer_64_1_bn3 <- layer_64_1_conv2
I0526 15:44:49.458616 30701 net.cpp:367] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.458787 30701 net.cpp:122] Setting up layer_64_1_bn3
I0526 15:44:49.458797 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.458804 30701 net.cpp:137] Memory required for data: 437534800
I0526 15:44:49.458828 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0526 15:44:49.458842 30701 net.cpp:84] Creating Layer layer_64_1_scale3
I0526 15:44:49.458847 30701 net.cpp:406] layer_64_1_scale3 <- layer_64_1_conv2
I0526 15:44:49.458856 30701 net.cpp:367] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.458897 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0526 15:44:49.459022 30701 net.cpp:122] Setting up layer_64_1_scale3
I0526 15:44:49.459031 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.459038 30701 net.cpp:137] Memory required for data: 453591120
I0526 15:44:49.459050 30701 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0526 15:44:49.459062 30701 net.cpp:84] Creating Layer layer_64_1_relu3
I0526 15:44:49.459069 30701 net.cpp:406] layer_64_1_relu3 <- layer_64_1_conv2
I0526 15:44:49.459077 30701 net.cpp:367] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.459695 30701 net.cpp:122] Setting up layer_64_1_relu3
I0526 15:44:49.459707 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.459715 30701 net.cpp:137] Memory required for data: 469647440
I0526 15:44:49.459723 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0526 15:44:49.459749 30701 net.cpp:84] Creating Layer layer_64_1_conv3
I0526 15:44:49.459755 30701 net.cpp:406] layer_64_1_conv3 <- layer_64_1_conv2
I0526 15:44:49.459764 30701 net.cpp:380] layer_64_1_conv3 -> layer_64_1_conv3
I0526 15:44:49.461000 30701 net.cpp:122] Setting up layer_64_1_conv3
I0526 15:44:49.461014 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.461019 30701 net.cpp:137] Memory required for data: 533872720
I0526 15:44:49.461024 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0526 15:44:49.461035 30701 net.cpp:84] Creating Layer layer_64_1_conv_expand
I0526 15:44:49.461040 30701 net.cpp:406] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0526 15:44:49.461047 30701 net.cpp:380] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0526 15:44:49.462285 30701 net.cpp:122] Setting up layer_64_1_conv_expand
I0526 15:44:49.462298 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462306 30701 net.cpp:137] Memory required for data: 598098000
I0526 15:44:49.462317 30701 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0526 15:44:49.462327 30701 net.cpp:84] Creating Layer layer_64_1_sum
I0526 15:44:49.462334 30701 net.cpp:406] layer_64_1_sum <- layer_64_1_conv3
I0526 15:44:49.462342 30701 net.cpp:406] layer_64_1_sum <- layer_64_1_conv_expand
I0526 15:44:49.462354 30701 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0526 15:44:49.462383 30701 net.cpp:122] Setting up layer_64_1_sum
I0526 15:44:49.462393 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462399 30701 net.cpp:137] Memory required for data: 662323280
I0526 15:44:49.462406 30701 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.462419 30701 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.462424 30701 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0526 15:44:49.462436 30701 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0526 15:44:49.462446 30701 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0526 15:44:49.462483 30701 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.462497 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462504 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462510 30701 net.cpp:137] Memory required for data: 790773840
I0526 15:44:49.462517 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0526 15:44:49.462528 30701 net.cpp:84] Creating Layer layer_64_2_bn1
I0526 15:44:49.462534 30701 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0526 15:44:49.462546 30701 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0526 15:44:49.462702 30701 net.cpp:122] Setting up layer_64_2_bn1
I0526 15:44:49.462712 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462718 30701 net.cpp:137] Memory required for data: 854999120
I0526 15:44:49.462733 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0526 15:44:49.462745 30701 net.cpp:84] Creating Layer layer_64_2_scale1
I0526 15:44:49.462751 30701 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0526 15:44:49.462760 30701 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0526 15:44:49.462801 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0526 15:44:49.462898 30701 net.cpp:122] Setting up layer_64_2_scale1
I0526 15:44:49.462908 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.462913 30701 net.cpp:137] Memory required for data: 919224400
I0526 15:44:49.462926 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0526 15:44:49.462934 30701 net.cpp:84] Creating Layer layer_64_2_relu1
I0526 15:44:49.462941 30701 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0526 15:44:49.462952 30701 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0526 15:44:49.463104 30701 net.cpp:122] Setting up layer_64_2_relu1
I0526 15:44:49.463114 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.463130 30701 net.cpp:137] Memory required for data: 983449680
I0526 15:44:49.463138 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0526 15:44:49.463155 30701 net.cpp:84] Creating Layer layer_64_2_conv1
I0526 15:44:49.463160 30701 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0526 15:44:49.463171 30701 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0526 15:44:49.464406 30701 net.cpp:122] Setting up layer_64_2_conv1
I0526 15:44:49.464418 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.464423 30701 net.cpp:137] Memory required for data: 999506000
I0526 15:44:49.464428 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0526 15:44:49.464435 30701 net.cpp:84] Creating Layer layer_64_2_bn2
I0526 15:44:49.464439 30701 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0526 15:44:49.464445 30701 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.464602 30701 net.cpp:122] Setting up layer_64_2_bn2
I0526 15:44:49.464612 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.464615 30701 net.cpp:137] Memory required for data: 1015562320
I0526 15:44:49.464625 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0526 15:44:49.464633 30701 net.cpp:84] Creating Layer layer_64_2_scale2
I0526 15:44:49.464637 30701 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0526 15:44:49.464643 30701 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.464679 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0526 15:44:49.464774 30701 net.cpp:122] Setting up layer_64_2_scale2
I0526 15:44:49.464783 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.464787 30701 net.cpp:137] Memory required for data: 1031618640
I0526 15:44:49.464792 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0526 15:44:49.464798 30701 net.cpp:84] Creating Layer layer_64_2_relu2
I0526 15:44:49.464802 30701 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0526 15:44:49.464807 30701 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.464952 30701 net.cpp:122] Setting up layer_64_2_relu2
I0526 15:44:49.464962 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.464967 30701 net.cpp:137] Memory required for data: 1047674960
I0526 15:44:49.464970 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0526 15:44:49.464979 30701 net.cpp:84] Creating Layer layer_64_2_conv2
I0526 15:44:49.464983 30701 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0526 15:44:49.464989 30701 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0526 15:44:49.466439 30701 net.cpp:122] Setting up layer_64_2_conv2
I0526 15:44:49.466454 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.466457 30701 net.cpp:137] Memory required for data: 1063731280
I0526 15:44:49.466462 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0526 15:44:49.466471 30701 net.cpp:84] Creating Layer layer_64_2_bn3
I0526 15:44:49.466476 30701 net.cpp:406] layer_64_2_bn3 <- layer_64_2_conv2
I0526 15:44:49.466481 30701 net.cpp:367] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.466650 30701 net.cpp:122] Setting up layer_64_2_bn3
I0526 15:44:49.466658 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.466661 30701 net.cpp:137] Memory required for data: 1079787600
I0526 15:44:49.466681 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0526 15:44:49.466691 30701 net.cpp:84] Creating Layer layer_64_2_scale3
I0526 15:44:49.466696 30701 net.cpp:406] layer_64_2_scale3 <- layer_64_2_conv2
I0526 15:44:49.466701 30701 net.cpp:367] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.466744 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0526 15:44:49.466850 30701 net.cpp:122] Setting up layer_64_2_scale3
I0526 15:44:49.466861 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.466867 30701 net.cpp:137] Memory required for data: 1095843920
I0526 15:44:49.466879 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0526 15:44:49.466899 30701 net.cpp:84] Creating Layer layer_64_2_relu3
I0526 15:44:49.466907 30701 net.cpp:406] layer_64_2_relu3 <- layer_64_2_conv2
I0526 15:44:49.466918 30701 net.cpp:367] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.467067 30701 net.cpp:122] Setting up layer_64_2_relu3
I0526 15:44:49.467079 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.467087 30701 net.cpp:137] Memory required for data: 1111900240
I0526 15:44:49.467093 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0526 15:44:49.467113 30701 net.cpp:84] Creating Layer layer_64_2_conv3
I0526 15:44:49.467118 30701 net.cpp:406] layer_64_2_conv3 <- layer_64_2_conv2
I0526 15:44:49.467128 30701 net.cpp:380] layer_64_2_conv3 -> layer_64_2_conv3
I0526 15:44:49.468415 30701 net.cpp:122] Setting up layer_64_2_conv3
I0526 15:44:49.468430 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.468433 30701 net.cpp:137] Memory required for data: 1176125520
I0526 15:44:49.468439 30701 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0526 15:44:49.468451 30701 net.cpp:84] Creating Layer layer_64_2_sum
I0526 15:44:49.468456 30701 net.cpp:406] layer_64_2_sum <- layer_64_2_conv3
I0526 15:44:49.468461 30701 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0526 15:44:49.468467 30701 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0526 15:44:49.468493 30701 net.cpp:122] Setting up layer_64_2_sum
I0526 15:44:49.468502 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.468504 30701 net.cpp:137] Memory required for data: 1240350800
I0526 15:44:49.468508 30701 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.468513 30701 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.468518 30701 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0526 15:44:49.468524 30701 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0526 15:44:49.468531 30701 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0526 15:44:49.468564 30701 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.468570 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.468575 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.468578 30701 net.cpp:137] Memory required for data: 1368801360
I0526 15:44:49.468585 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0526 15:44:49.468597 30701 net.cpp:84] Creating Layer layer_64_3_bn1
I0526 15:44:49.468603 30701 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0526 15:44:49.468612 30701 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0526 15:44:49.468780 30701 net.cpp:122] Setting up layer_64_3_bn1
I0526 15:44:49.468789 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.468796 30701 net.cpp:137] Memory required for data: 1433026640
I0526 15:44:49.468811 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0526 15:44:49.468819 30701 net.cpp:84] Creating Layer layer_64_3_scale1
I0526 15:44:49.468825 30701 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0526 15:44:49.468837 30701 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0526 15:44:49.468885 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0526 15:44:49.468996 30701 net.cpp:122] Setting up layer_64_3_scale1
I0526 15:44:49.469007 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.469009 30701 net.cpp:137] Memory required for data: 1497251920
I0526 15:44:49.469015 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0526 15:44:49.469022 30701 net.cpp:84] Creating Layer layer_64_3_relu1
I0526 15:44:49.469025 30701 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0526 15:44:49.469030 30701 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0526 15:44:49.469179 30701 net.cpp:122] Setting up layer_64_3_relu1
I0526 15:44:49.469189 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.469202 30701 net.cpp:137] Memory required for data: 1561477200
I0526 15:44:49.469205 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0526 15:44:49.469215 30701 net.cpp:84] Creating Layer layer_64_3_conv1
I0526 15:44:49.469219 30701 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0526 15:44:49.469226 30701 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0526 15:44:49.470470 30701 net.cpp:122] Setting up layer_64_3_conv1
I0526 15:44:49.470482 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.470486 30701 net.cpp:137] Memory required for data: 1577533520
I0526 15:44:49.470491 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0526 15:44:49.470499 30701 net.cpp:84] Creating Layer layer_64_3_bn2
I0526 15:44:49.470504 30701 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0526 15:44:49.470510 30701 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.470669 30701 net.cpp:122] Setting up layer_64_3_bn2
I0526 15:44:49.470677 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.470681 30701 net.cpp:137] Memory required for data: 1593589840
I0526 15:44:49.470688 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0526 15:44:49.470696 30701 net.cpp:84] Creating Layer layer_64_3_scale2
I0526 15:44:49.470700 30701 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0526 15:44:49.470705 30701 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.470744 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0526 15:44:49.470842 30701 net.cpp:122] Setting up layer_64_3_scale2
I0526 15:44:49.470851 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.470855 30701 net.cpp:137] Memory required for data: 1609646160
I0526 15:44:49.470861 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0526 15:44:49.470867 30701 net.cpp:84] Creating Layer layer_64_3_relu2
I0526 15:44:49.470871 30701 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0526 15:44:49.470877 30701 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.471025 30701 net.cpp:122] Setting up layer_64_3_relu2
I0526 15:44:49.471035 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.471040 30701 net.cpp:137] Memory required for data: 1625702480
I0526 15:44:49.471043 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0526 15:44:49.471052 30701 net.cpp:84] Creating Layer layer_64_3_conv2
I0526 15:44:49.471056 30701 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0526 15:44:49.471063 30701 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0526 15:44:49.472978 30701 net.cpp:122] Setting up layer_64_3_conv2
I0526 15:44:49.472991 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.472995 30701 net.cpp:137] Memory required for data: 1641758800
I0526 15:44:49.473001 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0526 15:44:49.473009 30701 net.cpp:84] Creating Layer layer_64_3_bn3
I0526 15:44:49.473013 30701 net.cpp:406] layer_64_3_bn3 <- layer_64_3_conv2
I0526 15:44:49.473019 30701 net.cpp:367] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.473179 30701 net.cpp:122] Setting up layer_64_3_bn3
I0526 15:44:49.473188 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.473192 30701 net.cpp:137] Memory required for data: 1657815120
I0526 15:44:49.473199 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0526 15:44:49.473206 30701 net.cpp:84] Creating Layer layer_64_3_scale3
I0526 15:44:49.473211 30701 net.cpp:406] layer_64_3_scale3 <- layer_64_3_conv2
I0526 15:44:49.473215 30701 net.cpp:367] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.473253 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0526 15:44:49.473356 30701 net.cpp:122] Setting up layer_64_3_scale3
I0526 15:44:49.473364 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.473368 30701 net.cpp:137] Memory required for data: 1673871440
I0526 15:44:49.473374 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0526 15:44:49.473389 30701 net.cpp:84] Creating Layer layer_64_3_relu3
I0526 15:44:49.473393 30701 net.cpp:406] layer_64_3_relu3 <- layer_64_3_conv2
I0526 15:44:49.473400 30701 net.cpp:367] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.474022 30701 net.cpp:122] Setting up layer_64_3_relu3
I0526 15:44:49.474033 30701 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0526 15:44:49.474037 30701 net.cpp:137] Memory required for data: 1689927760
I0526 15:44:49.474040 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0526 15:44:49.474050 30701 net.cpp:84] Creating Layer layer_64_3_conv3
I0526 15:44:49.474054 30701 net.cpp:406] layer_64_3_conv3 <- layer_64_3_conv2
I0526 15:44:49.474061 30701 net.cpp:380] layer_64_3_conv3 -> layer_64_3_conv3
I0526 15:44:49.475307 30701 net.cpp:122] Setting up layer_64_3_conv3
I0526 15:44:49.475319 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.475323 30701 net.cpp:137] Memory required for data: 1754153040
I0526 15:44:49.475328 30701 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0526 15:44:49.475335 30701 net.cpp:84] Creating Layer layer_64_3_sum
I0526 15:44:49.475342 30701 net.cpp:406] layer_64_3_sum <- layer_64_3_conv3
I0526 15:44:49.475345 30701 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0526 15:44:49.475352 30701 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0526 15:44:49.475376 30701 net.cpp:122] Setting up layer_64_3_sum
I0526 15:44:49.475383 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.475388 30701 net.cpp:137] Memory required for data: 1818378320
I0526 15:44:49.475390 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0526 15:44:49.475395 30701 net.cpp:84] Creating Layer layer_128_1_bn1
I0526 15:44:49.475400 30701 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0526 15:44:49.475406 30701 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0526 15:44:49.475565 30701 net.cpp:122] Setting up layer_128_1_bn1
I0526 15:44:49.475574 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.475579 30701 net.cpp:137] Memory required for data: 1882603600
I0526 15:44:49.475594 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0526 15:44:49.475601 30701 net.cpp:84] Creating Layer layer_128_1_scale1
I0526 15:44:49.475606 30701 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0526 15:44:49.475611 30701 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0526 15:44:49.475648 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0526 15:44:49.475747 30701 net.cpp:122] Setting up layer_128_1_scale1
I0526 15:44:49.475755 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.475759 30701 net.cpp:137] Memory required for data: 1946828880
I0526 15:44:49.475765 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0526 15:44:49.475771 30701 net.cpp:84] Creating Layer layer_128_1_relu1
I0526 15:44:49.475775 30701 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0526 15:44:49.475781 30701 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0526 15:44:49.475927 30701 net.cpp:122] Setting up layer_128_1_relu1
I0526 15:44:49.475936 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.475940 30701 net.cpp:137] Memory required for data: 2011054160
I0526 15:44:49.475944 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.475955 30701 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.475960 30701 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0526 15:44:49.475966 30701 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0526 15:44:49.475973 30701 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0526 15:44:49.476009 30701 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.476016 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.476030 30701 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0526 15:44:49.476033 30701 net.cpp:137] Memory required for data: 2139504720
I0526 15:44:49.476037 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0526 15:44:49.476047 30701 net.cpp:84] Creating Layer layer_128_1_conv1
I0526 15:44:49.476050 30701 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0526 15:44:49.476058 30701 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0526 15:44:49.477500 30701 net.cpp:122] Setting up layer_128_1_conv1
I0526 15:44:49.477514 30701 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0526 15:44:49.477519 30701 net.cpp:137] Memory required for data: 2171617360
I0526 15:44:49.477524 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0526 15:44:49.477530 30701 net.cpp:84] Creating Layer layer_128_1_bn2
I0526 15:44:49.477535 30701 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0526 15:44:49.477540 30701 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.477697 30701 net.cpp:122] Setting up layer_128_1_bn2
I0526 15:44:49.477705 30701 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0526 15:44:49.477708 30701 net.cpp:137] Memory required for data: 2203730000
I0526 15:44:49.477715 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0526 15:44:49.477722 30701 net.cpp:84] Creating Layer layer_128_1_scale2
I0526 15:44:49.477726 30701 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0526 15:44:49.477732 30701 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.477767 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0526 15:44:49.477861 30701 net.cpp:122] Setting up layer_128_1_scale2
I0526 15:44:49.477871 30701 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0526 15:44:49.477875 30701 net.cpp:137] Memory required for data: 2235842640
I0526 15:44:49.477881 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0526 15:44:49.477887 30701 net.cpp:84] Creating Layer layer_128_1_relu2
I0526 15:44:49.477891 30701 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0526 15:44:49.477895 30701 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.478051 30701 net.cpp:122] Setting up layer_128_1_relu2
I0526 15:44:49.478060 30701 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0526 15:44:49.478065 30701 net.cpp:137] Memory required for data: 2267955280
I0526 15:44:49.478067 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0526 15:44:49.478076 30701 net.cpp:84] Creating Layer layer_128_1_conv2
I0526 15:44:49.478081 30701 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0526 15:44:49.478088 30701 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0526 15:44:49.481600 30701 net.cpp:122] Setting up layer_128_1_conv2
I0526 15:44:49.481616 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.481619 30701 net.cpp:137] Memory required for data: 2275983440
I0526 15:44:49.481626 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0526 15:44:49.481632 30701 net.cpp:84] Creating Layer layer_128_1_bn3
I0526 15:44:49.481637 30701 net.cpp:406] layer_128_1_bn3 <- layer_128_1_conv2
I0526 15:44:49.481644 30701 net.cpp:367] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.482547 30701 net.cpp:122] Setting up layer_128_1_bn3
I0526 15:44:49.482560 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.482563 30701 net.cpp:137] Memory required for data: 2284011600
I0526 15:44:49.482571 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0526 15:44:49.482579 30701 net.cpp:84] Creating Layer layer_128_1_scale3
I0526 15:44:49.482584 30701 net.cpp:406] layer_128_1_scale3 <- layer_128_1_conv2
I0526 15:44:49.482591 30701 net.cpp:367] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.482632 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0526 15:44:49.482727 30701 net.cpp:122] Setting up layer_128_1_scale3
I0526 15:44:49.482736 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.482751 30701 net.cpp:137] Memory required for data: 2292039760
I0526 15:44:49.482758 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0526 15:44:49.482764 30701 net.cpp:84] Creating Layer layer_128_1_relu3
I0526 15:44:49.482766 30701 net.cpp:406] layer_128_1_relu3 <- layer_128_1_conv2
I0526 15:44:49.482771 30701 net.cpp:367] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.482944 30701 net.cpp:122] Setting up layer_128_1_relu3
I0526 15:44:49.482954 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.482956 30701 net.cpp:137] Memory required for data: 2300067920
I0526 15:44:49.482960 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0526 15:44:49.482970 30701 net.cpp:84] Creating Layer layer_128_1_conv3
I0526 15:44:49.482975 30701 net.cpp:406] layer_128_1_conv3 <- layer_128_1_conv2
I0526 15:44:49.482982 30701 net.cpp:380] layer_128_1_conv3 -> layer_128_1_conv3
I0526 15:44:49.484912 30701 net.cpp:122] Setting up layer_128_1_conv3
I0526 15:44:49.484925 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.484928 30701 net.cpp:137] Memory required for data: 2332180560
I0526 15:44:49.484933 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0526 15:44:49.484944 30701 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0526 15:44:49.484948 30701 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0526 15:44:49.484956 30701 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0526 15:44:49.487458 30701 net.cpp:122] Setting up layer_128_1_conv_expand
I0526 15:44:49.487471 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.487475 30701 net.cpp:137] Memory required for data: 2364293200
I0526 15:44:49.487481 30701 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0526 15:44:49.487488 30701 net.cpp:84] Creating Layer layer_128_1_sum
I0526 15:44:49.487493 30701 net.cpp:406] layer_128_1_sum <- layer_128_1_conv3
I0526 15:44:49.487498 30701 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0526 15:44:49.487506 30701 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0526 15:44:49.487532 30701 net.cpp:122] Setting up layer_128_1_sum
I0526 15:44:49.487540 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.487543 30701 net.cpp:137] Memory required for data: 2396405840
I0526 15:44:49.487547 30701 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.487552 30701 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.487555 30701 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0526 15:44:49.487561 30701 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0526 15:44:49.487568 30701 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0526 15:44:49.487601 30701 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.487607 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.487613 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.487617 30701 net.cpp:137] Memory required for data: 2460631120
I0526 15:44:49.487619 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0526 15:44:49.487637 30701 net.cpp:84] Creating Layer layer_128_2_bn1
I0526 15:44:49.487642 30701 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0526 15:44:49.487646 30701 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0526 15:44:49.487805 30701 net.cpp:122] Setting up layer_128_2_bn1
I0526 15:44:49.487813 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.487818 30701 net.cpp:137] Memory required for data: 2492743760
I0526 15:44:49.487825 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0526 15:44:49.487833 30701 net.cpp:84] Creating Layer layer_128_2_scale1
I0526 15:44:49.487836 30701 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0526 15:44:49.487843 30701 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0526 15:44:49.487891 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0526 15:44:49.488003 30701 net.cpp:122] Setting up layer_128_2_scale1
I0526 15:44:49.488013 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.488015 30701 net.cpp:137] Memory required for data: 2524856400
I0526 15:44:49.488021 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0526 15:44:49.488028 30701 net.cpp:84] Creating Layer layer_128_2_relu1
I0526 15:44:49.488031 30701 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0526 15:44:49.488037 30701 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0526 15:44:49.488195 30701 net.cpp:122] Setting up layer_128_2_relu1
I0526 15:44:49.488204 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.488209 30701 net.cpp:137] Memory required for data: 2556969040
I0526 15:44:49.488212 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0526 15:44:49.488224 30701 net.cpp:84] Creating Layer layer_128_2_conv1
I0526 15:44:49.488229 30701 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0526 15:44:49.488235 30701 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0526 15:44:49.489982 30701 net.cpp:122] Setting up layer_128_2_conv1
I0526 15:44:49.489995 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.489998 30701 net.cpp:137] Memory required for data: 2564997200
I0526 15:44:49.490003 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0526 15:44:49.490011 30701 net.cpp:84] Creating Layer layer_128_2_bn2
I0526 15:44:49.490016 30701 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0526 15:44:49.490022 30701 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.490181 30701 net.cpp:122] Setting up layer_128_2_bn2
I0526 15:44:49.490190 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.490193 30701 net.cpp:137] Memory required for data: 2573025360
I0526 15:44:49.490201 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0526 15:44:49.490209 30701 net.cpp:84] Creating Layer layer_128_2_scale2
I0526 15:44:49.490213 30701 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0526 15:44:49.490218 30701 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.490255 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0526 15:44:49.490348 30701 net.cpp:122] Setting up layer_128_2_scale2
I0526 15:44:49.490357 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.490360 30701 net.cpp:137] Memory required for data: 2581053520
I0526 15:44:49.490366 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0526 15:44:49.490373 30701 net.cpp:84] Creating Layer layer_128_2_relu2
I0526 15:44:49.490377 30701 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0526 15:44:49.490383 30701 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.490530 30701 net.cpp:122] Setting up layer_128_2_relu2
I0526 15:44:49.490540 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.490545 30701 net.cpp:137] Memory required for data: 2589081680
I0526 15:44:49.490547 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0526 15:44:49.490556 30701 net.cpp:84] Creating Layer layer_128_2_conv2
I0526 15:44:49.490561 30701 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0526 15:44:49.490568 30701 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0526 15:44:49.494302 30701 net.cpp:122] Setting up layer_128_2_conv2
I0526 15:44:49.494316 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.494321 30701 net.cpp:137] Memory required for data: 2597109840
I0526 15:44:49.494326 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0526 15:44:49.494334 30701 net.cpp:84] Creating Layer layer_128_2_bn3
I0526 15:44:49.494339 30701 net.cpp:406] layer_128_2_bn3 <- layer_128_2_conv2
I0526 15:44:49.494344 30701 net.cpp:367] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.494514 30701 net.cpp:122] Setting up layer_128_2_bn3
I0526 15:44:49.494524 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.494536 30701 net.cpp:137] Memory required for data: 2605138000
I0526 15:44:49.494544 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0526 15:44:49.494551 30701 net.cpp:84] Creating Layer layer_128_2_scale3
I0526 15:44:49.494555 30701 net.cpp:406] layer_128_2_scale3 <- layer_128_2_conv2
I0526 15:44:49.494560 30701 net.cpp:367] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.494601 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0526 15:44:49.494699 30701 net.cpp:122] Setting up layer_128_2_scale3
I0526 15:44:49.494707 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.494710 30701 net.cpp:137] Memory required for data: 2613166160
I0526 15:44:49.494716 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0526 15:44:49.494722 30701 net.cpp:84] Creating Layer layer_128_2_relu3
I0526 15:44:49.494726 30701 net.cpp:406] layer_128_2_relu3 <- layer_128_2_conv2
I0526 15:44:49.494732 30701 net.cpp:367] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.495357 30701 net.cpp:122] Setting up layer_128_2_relu3
I0526 15:44:49.495368 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.495373 30701 net.cpp:137] Memory required for data: 2621194320
I0526 15:44:49.495375 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0526 15:44:49.495386 30701 net.cpp:84] Creating Layer layer_128_2_conv3
I0526 15:44:49.495391 30701 net.cpp:406] layer_128_2_conv3 <- layer_128_2_conv2
I0526 15:44:49.495398 30701 net.cpp:380] layer_128_2_conv3 -> layer_128_2_conv3
I0526 15:44:49.496687 30701 net.cpp:122] Setting up layer_128_2_conv3
I0526 15:44:49.496700 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.496702 30701 net.cpp:137] Memory required for data: 2653306960
I0526 15:44:49.496707 30701 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0526 15:44:49.496714 30701 net.cpp:84] Creating Layer layer_128_2_sum
I0526 15:44:49.496718 30701 net.cpp:406] layer_128_2_sum <- layer_128_2_conv3
I0526 15:44:49.496722 30701 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0526 15:44:49.496731 30701 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0526 15:44:49.496757 30701 net.cpp:122] Setting up layer_128_2_sum
I0526 15:44:49.496765 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.496769 30701 net.cpp:137] Memory required for data: 2685419600
I0526 15:44:49.496773 30701 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.496778 30701 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.496781 30701 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0526 15:44:49.496788 30701 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0526 15:44:49.496795 30701 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0526 15:44:49.496829 30701 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.496835 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.496840 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.496843 30701 net.cpp:137] Memory required for data: 2749644880
I0526 15:44:49.496846 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0526 15:44:49.496853 30701 net.cpp:84] Creating Layer layer_128_3_bn1
I0526 15:44:49.496857 30701 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0526 15:44:49.496865 30701 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0526 15:44:49.497026 30701 net.cpp:122] Setting up layer_128_3_bn1
I0526 15:44:49.497035 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.497040 30701 net.cpp:137] Memory required for data: 2781757520
I0526 15:44:49.497046 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0526 15:44:49.497052 30701 net.cpp:84] Creating Layer layer_128_3_scale1
I0526 15:44:49.497057 30701 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0526 15:44:49.497071 30701 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0526 15:44:49.497112 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0526 15:44:49.497208 30701 net.cpp:122] Setting up layer_128_3_scale1
I0526 15:44:49.497217 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.497221 30701 net.cpp:137] Memory required for data: 2813870160
I0526 15:44:49.497227 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0526 15:44:49.497233 30701 net.cpp:84] Creating Layer layer_128_3_relu1
I0526 15:44:49.497237 30701 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0526 15:44:49.497242 30701 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0526 15:44:49.497871 30701 net.cpp:122] Setting up layer_128_3_relu1
I0526 15:44:49.497882 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.497886 30701 net.cpp:137] Memory required for data: 2845982800
I0526 15:44:49.497890 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0526 15:44:49.497900 30701 net.cpp:84] Creating Layer layer_128_3_conv1
I0526 15:44:49.497905 30701 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0526 15:44:49.497911 30701 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0526 15:44:49.500386 30701 net.cpp:122] Setting up layer_128_3_conv1
I0526 15:44:49.500401 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.500406 30701 net.cpp:137] Memory required for data: 2854010960
I0526 15:44:49.500411 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0526 15:44:49.500417 30701 net.cpp:84] Creating Layer layer_128_3_bn2
I0526 15:44:49.500422 30701 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0526 15:44:49.500428 30701 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.500597 30701 net.cpp:122] Setting up layer_128_3_bn2
I0526 15:44:49.500605 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.500608 30701 net.cpp:137] Memory required for data: 2862039120
I0526 15:44:49.500617 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0526 15:44:49.500622 30701 net.cpp:84] Creating Layer layer_128_3_scale2
I0526 15:44:49.500627 30701 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0526 15:44:49.500633 30701 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.500669 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0526 15:44:49.500766 30701 net.cpp:122] Setting up layer_128_3_scale2
I0526 15:44:49.500775 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.500779 30701 net.cpp:137] Memory required for data: 2870067280
I0526 15:44:49.500785 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0526 15:44:49.500792 30701 net.cpp:84] Creating Layer layer_128_3_relu2
I0526 15:44:49.500795 30701 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0526 15:44:49.500800 30701 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.500952 30701 net.cpp:122] Setting up layer_128_3_relu2
I0526 15:44:49.500962 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.500967 30701 net.cpp:137] Memory required for data: 2878095440
I0526 15:44:49.500969 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0526 15:44:49.500978 30701 net.cpp:84] Creating Layer layer_128_3_conv2
I0526 15:44:49.500983 30701 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0526 15:44:49.500990 30701 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0526 15:44:49.504004 30701 net.cpp:122] Setting up layer_128_3_conv2
I0526 15:44:49.504017 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.504021 30701 net.cpp:137] Memory required for data: 2886123600
I0526 15:44:49.504026 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0526 15:44:49.504035 30701 net.cpp:84] Creating Layer layer_128_3_bn3
I0526 15:44:49.504040 30701 net.cpp:406] layer_128_3_bn3 <- layer_128_3_conv2
I0526 15:44:49.504047 30701 net.cpp:367] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.504223 30701 net.cpp:122] Setting up layer_128_3_bn3
I0526 15:44:49.504232 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.504236 30701 net.cpp:137] Memory required for data: 2894151760
I0526 15:44:49.504243 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0526 15:44:49.504251 30701 net.cpp:84] Creating Layer layer_128_3_scale3
I0526 15:44:49.504254 30701 net.cpp:406] layer_128_3_scale3 <- layer_128_3_conv2
I0526 15:44:49.504259 30701 net.cpp:367] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.504299 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0526 15:44:49.504400 30701 net.cpp:122] Setting up layer_128_3_scale3
I0526 15:44:49.504410 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.504413 30701 net.cpp:137] Memory required for data: 2902179920
I0526 15:44:49.504418 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0526 15:44:49.504427 30701 net.cpp:84] Creating Layer layer_128_3_relu3
I0526 15:44:49.504431 30701 net.cpp:406] layer_128_3_relu3 <- layer_128_3_conv2
I0526 15:44:49.504436 30701 net.cpp:367] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.504590 30701 net.cpp:122] Setting up layer_128_3_relu3
I0526 15:44:49.504601 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.504604 30701 net.cpp:137] Memory required for data: 2910208080
I0526 15:44:49.504607 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0526 15:44:49.504617 30701 net.cpp:84] Creating Layer layer_128_3_conv3
I0526 15:44:49.504621 30701 net.cpp:406] layer_128_3_conv3 <- layer_128_3_conv2
I0526 15:44:49.504628 30701 net.cpp:380] layer_128_3_conv3 -> layer_128_3_conv3
I0526 15:44:49.506384 30701 net.cpp:122] Setting up layer_128_3_conv3
I0526 15:44:49.506397 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506402 30701 net.cpp:137] Memory required for data: 2942320720
I0526 15:44:49.506407 30701 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0526 15:44:49.506412 30701 net.cpp:84] Creating Layer layer_128_3_sum
I0526 15:44:49.506417 30701 net.cpp:406] layer_128_3_sum <- layer_128_3_conv3
I0526 15:44:49.506420 30701 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0526 15:44:49.506428 30701 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0526 15:44:49.506455 30701 net.cpp:122] Setting up layer_128_3_sum
I0526 15:44:49.506463 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506466 30701 net.cpp:137] Memory required for data: 2974433360
I0526 15:44:49.506469 30701 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.506475 30701 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.506479 30701 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0526 15:44:49.506485 30701 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0526 15:44:49.506494 30701 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0526 15:44:49.506527 30701 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.506534 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506539 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506542 30701 net.cpp:137] Memory required for data: 3038658640
I0526 15:44:49.506546 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0526 15:44:49.506553 30701 net.cpp:84] Creating Layer layer_128_4_bn1
I0526 15:44:49.506557 30701 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0526 15:44:49.506563 30701 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0526 15:44:49.506731 30701 net.cpp:122] Setting up layer_128_4_bn1
I0526 15:44:49.506739 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506743 30701 net.cpp:137] Memory required for data: 3070771280
I0526 15:44:49.506750 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0526 15:44:49.506765 30701 net.cpp:84] Creating Layer layer_128_4_scale1
I0526 15:44:49.506769 30701 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0526 15:44:49.506774 30701 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0526 15:44:49.506816 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0526 15:44:49.506916 30701 net.cpp:122] Setting up layer_128_4_scale1
I0526 15:44:49.506924 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.506928 30701 net.cpp:137] Memory required for data: 3102883920
I0526 15:44:49.506934 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0526 15:44:49.506942 30701 net.cpp:84] Creating Layer layer_128_4_relu1
I0526 15:44:49.506945 30701 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0526 15:44:49.506950 30701 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0526 15:44:49.507100 30701 net.cpp:122] Setting up layer_128_4_relu1
I0526 15:44:49.507110 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.507113 30701 net.cpp:137] Memory required for data: 3134996560
I0526 15:44:49.507117 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0526 15:44:49.507127 30701 net.cpp:84] Creating Layer layer_128_4_conv1
I0526 15:44:49.507130 30701 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0526 15:44:49.507138 30701 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0526 15:44:49.508895 30701 net.cpp:122] Setting up layer_128_4_conv1
I0526 15:44:49.508908 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.508913 30701 net.cpp:137] Memory required for data: 3143024720
I0526 15:44:49.508919 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0526 15:44:49.508925 30701 net.cpp:84] Creating Layer layer_128_4_bn2
I0526 15:44:49.508929 30701 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0526 15:44:49.508936 30701 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.509102 30701 net.cpp:122] Setting up layer_128_4_bn2
I0526 15:44:49.509111 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.509114 30701 net.cpp:137] Memory required for data: 3151052880
I0526 15:44:49.509121 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0526 15:44:49.509129 30701 net.cpp:84] Creating Layer layer_128_4_scale2
I0526 15:44:49.509132 30701 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0526 15:44:49.509137 30701 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.509176 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0526 15:44:49.509272 30701 net.cpp:122] Setting up layer_128_4_scale2
I0526 15:44:49.509282 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.509286 30701 net.cpp:137] Memory required for data: 3159081040
I0526 15:44:49.509292 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0526 15:44:49.509299 30701 net.cpp:84] Creating Layer layer_128_4_relu2
I0526 15:44:49.509302 30701 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0526 15:44:49.509307 30701 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.509464 30701 net.cpp:122] Setting up layer_128_4_relu2
I0526 15:44:49.509472 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.509476 30701 net.cpp:137] Memory required for data: 3167109200
I0526 15:44:49.509480 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0526 15:44:49.509490 30701 net.cpp:84] Creating Layer layer_128_4_conv2
I0526 15:44:49.509495 30701 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0526 15:44:49.509502 30701 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0526 15:44:49.512537 30701 net.cpp:122] Setting up layer_128_4_conv2
I0526 15:44:49.512549 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.512553 30701 net.cpp:137] Memory required for data: 3175137360
I0526 15:44:49.512573 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0526 15:44:49.512581 30701 net.cpp:84] Creating Layer layer_128_4_bn3
I0526 15:44:49.512585 30701 net.cpp:406] layer_128_4_bn3 <- layer_128_4_conv2
I0526 15:44:49.512601 30701 net.cpp:367] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.512769 30701 net.cpp:122] Setting up layer_128_4_bn3
I0526 15:44:49.512778 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.512781 30701 net.cpp:137] Memory required for data: 3183165520
I0526 15:44:49.512789 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0526 15:44:49.512796 30701 net.cpp:84] Creating Layer layer_128_4_scale3
I0526 15:44:49.512801 30701 net.cpp:406] layer_128_4_scale3 <- layer_128_4_conv2
I0526 15:44:49.512806 30701 net.cpp:367] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.512845 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0526 15:44:49.512943 30701 net.cpp:122] Setting up layer_128_4_scale3
I0526 15:44:49.512953 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.512956 30701 net.cpp:137] Memory required for data: 3191193680
I0526 15:44:49.512962 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0526 15:44:49.512969 30701 net.cpp:84] Creating Layer layer_128_4_relu3
I0526 15:44:49.512972 30701 net.cpp:406] layer_128_4_relu3 <- layer_128_4_conv2
I0526 15:44:49.512979 30701 net.cpp:367] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.513609 30701 net.cpp:122] Setting up layer_128_4_relu3
I0526 15:44:49.513622 30701 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0526 15:44:49.513625 30701 net.cpp:137] Memory required for data: 3199221840
I0526 15:44:49.513629 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0526 15:44:49.513638 30701 net.cpp:84] Creating Layer layer_128_4_conv3
I0526 15:44:49.513643 30701 net.cpp:406] layer_128_4_conv3 <- layer_128_4_conv2
I0526 15:44:49.513650 30701 net.cpp:380] layer_128_4_conv3 -> layer_128_4_conv3
I0526 15:44:49.514933 30701 net.cpp:122] Setting up layer_128_4_conv3
I0526 15:44:49.514945 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.514948 30701 net.cpp:137] Memory required for data: 3231334480
I0526 15:44:49.514953 30701 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0526 15:44:49.514961 30701 net.cpp:84] Creating Layer layer_128_4_sum
I0526 15:44:49.514964 30701 net.cpp:406] layer_128_4_sum <- layer_128_4_conv3
I0526 15:44:49.514968 30701 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0526 15:44:49.514976 30701 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0526 15:44:49.515002 30701 net.cpp:122] Setting up layer_128_4_sum
I0526 15:44:49.515008 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.515012 30701 net.cpp:137] Memory required for data: 3263447120
I0526 15:44:49.515015 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0526 15:44:49.515022 30701 net.cpp:84] Creating Layer layer_256_1_bn1
I0526 15:44:49.515027 30701 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0526 15:44:49.515033 30701 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0526 15:44:49.515206 30701 net.cpp:122] Setting up layer_256_1_bn1
I0526 15:44:49.515215 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.515219 30701 net.cpp:137] Memory required for data: 3295559760
I0526 15:44:49.515226 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0526 15:44:49.515233 30701 net.cpp:84] Creating Layer layer_256_1_scale1
I0526 15:44:49.515238 30701 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0526 15:44:49.515242 30701 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0526 15:44:49.515283 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0526 15:44:49.515383 30701 net.cpp:122] Setting up layer_256_1_scale1
I0526 15:44:49.515391 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.515394 30701 net.cpp:137] Memory required for data: 3327672400
I0526 15:44:49.515400 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0526 15:44:49.515408 30701 net.cpp:84] Creating Layer layer_256_1_relu1
I0526 15:44:49.515411 30701 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0526 15:44:49.515425 30701 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0526 15:44:49.516064 30701 net.cpp:122] Setting up layer_256_1_relu1
I0526 15:44:49.516077 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.516080 30701 net.cpp:137] Memory required for data: 3359785040
I0526 15:44:49.516084 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.516089 30701 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.516093 30701 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0526 15:44:49.516100 30701 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0526 15:44:49.516108 30701 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0526 15:44:49.516147 30701 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.516155 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.516160 30701 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0526 15:44:49.516162 30701 net.cpp:137] Memory required for data: 3424010320
I0526 15:44:49.516165 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0526 15:44:49.516177 30701 net.cpp:84] Creating Layer layer_256_1_conv1
I0526 15:44:49.516181 30701 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0526 15:44:49.516188 30701 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0526 15:44:49.520293 30701 net.cpp:122] Setting up layer_256_1_conv1
I0526 15:44:49.520313 30701 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0526 15:44:49.520316 30701 net.cpp:137] Memory required for data: 3440066640
I0526 15:44:49.520323 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0526 15:44:49.520330 30701 net.cpp:84] Creating Layer layer_256_1_bn2
I0526 15:44:49.520335 30701 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0526 15:44:49.520342 30701 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.520521 30701 net.cpp:122] Setting up layer_256_1_bn2
I0526 15:44:49.520530 30701 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0526 15:44:49.520534 30701 net.cpp:137] Memory required for data: 3456122960
I0526 15:44:49.520540 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0526 15:44:49.520548 30701 net.cpp:84] Creating Layer layer_256_1_scale2
I0526 15:44:49.520552 30701 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0526 15:44:49.520557 30701 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.520611 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0526 15:44:49.520735 30701 net.cpp:122] Setting up layer_256_1_scale2
I0526 15:44:49.520745 30701 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0526 15:44:49.520747 30701 net.cpp:137] Memory required for data: 3472179280
I0526 15:44:49.520753 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0526 15:44:49.520762 30701 net.cpp:84] Creating Layer layer_256_1_relu2
I0526 15:44:49.520766 30701 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0526 15:44:49.520771 30701 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.520927 30701 net.cpp:122] Setting up layer_256_1_relu2
I0526 15:44:49.520937 30701 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0526 15:44:49.520941 30701 net.cpp:137] Memory required for data: 3488235600
I0526 15:44:49.520943 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0526 15:44:49.520954 30701 net.cpp:84] Creating Layer layer_256_1_conv2
I0526 15:44:49.520957 30701 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0526 15:44:49.520964 30701 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0526 15:44:49.528755 30701 net.cpp:122] Setting up layer_256_1_conv2
I0526 15:44:49.528771 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.528775 30701 net.cpp:137] Memory required for data: 3492249680
I0526 15:44:49.528781 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn3
I0526 15:44:49.528805 30701 net.cpp:84] Creating Layer layer_256_1_bn3
I0526 15:44:49.528808 30701 net.cpp:406] layer_256_1_bn3 <- layer_256_1_conv2
I0526 15:44:49.528815 30701 net.cpp:367] layer_256_1_bn3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.528990 30701 net.cpp:122] Setting up layer_256_1_bn3
I0526 15:44:49.528997 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.529001 30701 net.cpp:137] Memory required for data: 3496263760
I0526 15:44:49.529008 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0526 15:44:49.529016 30701 net.cpp:84] Creating Layer layer_256_1_scale3
I0526 15:44:49.529019 30701 net.cpp:406] layer_256_1_scale3 <- layer_256_1_conv2
I0526 15:44:49.529024 30701 net.cpp:367] layer_256_1_scale3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.529064 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0526 15:44:49.529165 30701 net.cpp:122] Setting up layer_256_1_scale3
I0526 15:44:49.529173 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.529176 30701 net.cpp:137] Memory required for data: 3500277840
I0526 15:44:49.529182 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu3
I0526 15:44:49.529191 30701 net.cpp:84] Creating Layer layer_256_1_relu3
I0526 15:44:49.529194 30701 net.cpp:406] layer_256_1_relu3 <- layer_256_1_conv2
I0526 15:44:49.529201 30701 net.cpp:367] layer_256_1_relu3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.529357 30701 net.cpp:122] Setting up layer_256_1_relu3
I0526 15:44:49.529366 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.529369 30701 net.cpp:137] Memory required for data: 3504291920
I0526 15:44:49.529373 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv3
I0526 15:44:49.529382 30701 net.cpp:84] Creating Layer layer_256_1_conv3
I0526 15:44:49.529386 30701 net.cpp:406] layer_256_1_conv3 <- layer_256_1_conv2
I0526 15:44:49.529393 30701 net.cpp:380] layer_256_1_conv3 -> layer_256_1_conv3
I0526 15:44:49.533160 30701 net.cpp:122] Setting up layer_256_1_conv3
I0526 15:44:49.533174 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.533176 30701 net.cpp:137] Memory required for data: 3520348240
I0526 15:44:49.533182 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0526 15:44:49.533191 30701 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0526 15:44:49.533197 30701 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0526 15:44:49.533205 30701 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0526 15:44:49.540228 30701 net.cpp:122] Setting up layer_256_1_conv_expand
I0526 15:44:49.540242 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540246 30701 net.cpp:137] Memory required for data: 3536404560
I0526 15:44:49.540251 30701 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0526 15:44:49.540259 30701 net.cpp:84] Creating Layer layer_256_1_sum
I0526 15:44:49.540264 30701 net.cpp:406] layer_256_1_sum <- layer_256_1_conv3
I0526 15:44:49.540268 30701 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0526 15:44:49.540274 30701 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0526 15:44:49.540304 30701 net.cpp:122] Setting up layer_256_1_sum
I0526 15:44:49.540313 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540315 30701 net.cpp:137] Memory required for data: 3552460880
I0526 15:44:49.540319 30701 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.540324 30701 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.540329 30701 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0526 15:44:49.540338 30701 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0526 15:44:49.540346 30701 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0526 15:44:49.540393 30701 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.540401 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540416 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540421 30701 net.cpp:137] Memory required for data: 3584573520
I0526 15:44:49.540424 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0526 15:44:49.540431 30701 net.cpp:84] Creating Layer layer_256_2_bn1
I0526 15:44:49.540436 30701 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0526 15:44:49.540441 30701 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0526 15:44:49.540626 30701 net.cpp:122] Setting up layer_256_2_bn1
I0526 15:44:49.540634 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540638 30701 net.cpp:137] Memory required for data: 3600629840
I0526 15:44:49.540645 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0526 15:44:49.540652 30701 net.cpp:84] Creating Layer layer_256_2_scale1
I0526 15:44:49.540657 30701 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0526 15:44:49.540663 30701 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0526 15:44:49.540702 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0526 15:44:49.540808 30701 net.cpp:122] Setting up layer_256_2_scale1
I0526 15:44:49.540817 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.540822 30701 net.cpp:137] Memory required for data: 3616686160
I0526 15:44:49.540827 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0526 15:44:49.540833 30701 net.cpp:84] Creating Layer layer_256_2_relu1
I0526 15:44:49.540838 30701 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0526 15:44:49.540843 30701 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0526 15:44:49.541474 30701 net.cpp:122] Setting up layer_256_2_relu1
I0526 15:44:49.541486 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.541489 30701 net.cpp:137] Memory required for data: 3632742480
I0526 15:44:49.541493 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0526 15:44:49.541502 30701 net.cpp:84] Creating Layer layer_256_2_conv1
I0526 15:44:49.541507 30701 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0526 15:44:49.541514 30701 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0526 15:44:49.545943 30701 net.cpp:122] Setting up layer_256_2_conv1
I0526 15:44:49.545958 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.545964 30701 net.cpp:137] Memory required for data: 3636756560
I0526 15:44:49.545969 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0526 15:44:49.545976 30701 net.cpp:84] Creating Layer layer_256_2_bn2
I0526 15:44:49.545981 30701 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0526 15:44:49.545986 30701 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.546161 30701 net.cpp:122] Setting up layer_256_2_bn2
I0526 15:44:49.546170 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.546175 30701 net.cpp:137] Memory required for data: 3640770640
I0526 15:44:49.546181 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0526 15:44:49.546190 30701 net.cpp:84] Creating Layer layer_256_2_scale2
I0526 15:44:49.546195 30701 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0526 15:44:49.546200 30701 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.546239 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0526 15:44:49.546341 30701 net.cpp:122] Setting up layer_256_2_scale2
I0526 15:44:49.546350 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.546353 30701 net.cpp:137] Memory required for data: 3644784720
I0526 15:44:49.546360 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0526 15:44:49.546367 30701 net.cpp:84] Creating Layer layer_256_2_relu2
I0526 15:44:49.546371 30701 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0526 15:44:49.546380 30701 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.546528 30701 net.cpp:122] Setting up layer_256_2_relu2
I0526 15:44:49.546538 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.546551 30701 net.cpp:137] Memory required for data: 3648798800
I0526 15:44:49.546555 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0526 15:44:49.546586 30701 net.cpp:84] Creating Layer layer_256_2_conv2
I0526 15:44:49.546591 30701 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0526 15:44:49.546597 30701 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0526 15:44:49.554909 30701 net.cpp:122] Setting up layer_256_2_conv2
I0526 15:44:49.554927 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.554930 30701 net.cpp:137] Memory required for data: 3652812880
I0526 15:44:49.554939 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn3
I0526 15:44:49.554946 30701 net.cpp:84] Creating Layer layer_256_2_bn3
I0526 15:44:49.554950 30701 net.cpp:406] layer_256_2_bn3 <- layer_256_2_conv2
I0526 15:44:49.554956 30701 net.cpp:367] layer_256_2_bn3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.555143 30701 net.cpp:122] Setting up layer_256_2_bn3
I0526 15:44:49.555152 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.555155 30701 net.cpp:137] Memory required for data: 3656826960
I0526 15:44:49.555163 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0526 15:44:49.555171 30701 net.cpp:84] Creating Layer layer_256_2_scale3
I0526 15:44:49.555176 30701 net.cpp:406] layer_256_2_scale3 <- layer_256_2_conv2
I0526 15:44:49.555181 30701 net.cpp:367] layer_256_2_scale3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.555224 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0526 15:44:49.555328 30701 net.cpp:122] Setting up layer_256_2_scale3
I0526 15:44:49.555336 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.555339 30701 net.cpp:137] Memory required for data: 3660841040
I0526 15:44:49.555346 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu3
I0526 15:44:49.555351 30701 net.cpp:84] Creating Layer layer_256_2_relu3
I0526 15:44:49.555354 30701 net.cpp:406] layer_256_2_relu3 <- layer_256_2_conv2
I0526 15:44:49.555361 30701 net.cpp:367] layer_256_2_relu3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.555521 30701 net.cpp:122] Setting up layer_256_2_relu3
I0526 15:44:49.555531 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.555534 30701 net.cpp:137] Memory required for data: 3664855120
I0526 15:44:49.555537 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv3
I0526 15:44:49.555548 30701 net.cpp:84] Creating Layer layer_256_2_conv3
I0526 15:44:49.555553 30701 net.cpp:406] layer_256_2_conv3 <- layer_256_2_conv2
I0526 15:44:49.555559 30701 net.cpp:380] layer_256_2_conv3 -> layer_256_2_conv3
I0526 15:44:49.559363 30701 net.cpp:122] Setting up layer_256_2_conv3
I0526 15:44:49.559376 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559379 30701 net.cpp:137] Memory required for data: 3680911440
I0526 15:44:49.559384 30701 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0526 15:44:49.559394 30701 net.cpp:84] Creating Layer layer_256_2_sum
I0526 15:44:49.559399 30701 net.cpp:406] layer_256_2_sum <- layer_256_2_conv3
I0526 15:44:49.559403 30701 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0526 15:44:49.559409 30701 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0526 15:44:49.559439 30701 net.cpp:122] Setting up layer_256_2_sum
I0526 15:44:49.559448 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559450 30701 net.cpp:137] Memory required for data: 3696967760
I0526 15:44:49.559454 30701 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.559459 30701 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.559464 30701 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0526 15:44:49.559470 30701 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0526 15:44:49.559478 30701 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0526 15:44:49.559530 30701 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.559537 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559542 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559545 30701 net.cpp:137] Memory required for data: 3729080400
I0526 15:44:49.559551 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0526 15:44:49.559557 30701 net.cpp:84] Creating Layer layer_256_3_bn1
I0526 15:44:49.559561 30701 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0526 15:44:49.559566 30701 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0526 15:44:49.559751 30701 net.cpp:122] Setting up layer_256_3_bn1
I0526 15:44:49.559758 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559762 30701 net.cpp:137] Memory required for data: 3745136720
I0526 15:44:49.559770 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0526 15:44:49.559777 30701 net.cpp:84] Creating Layer layer_256_3_scale1
I0526 15:44:49.559780 30701 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0526 15:44:49.559787 30701 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0526 15:44:49.559825 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0526 15:44:49.559934 30701 net.cpp:122] Setting up layer_256_3_scale1
I0526 15:44:49.559943 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.559947 30701 net.cpp:137] Memory required for data: 3761193040
I0526 15:44:49.559958 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0526 15:44:49.559963 30701 net.cpp:84] Creating Layer layer_256_3_relu1
I0526 15:44:49.559967 30701 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0526 15:44:49.559972 30701 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0526 15:44:49.560618 30701 net.cpp:122] Setting up layer_256_3_relu1
I0526 15:44:49.560629 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.560633 30701 net.cpp:137] Memory required for data: 3777249360
I0526 15:44:49.560637 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0526 15:44:49.560647 30701 net.cpp:84] Creating Layer layer_256_3_conv1
I0526 15:44:49.560652 30701 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0526 15:44:49.560659 30701 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0526 15:44:49.564641 30701 net.cpp:122] Setting up layer_256_3_conv1
I0526 15:44:49.564656 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.564661 30701 net.cpp:137] Memory required for data: 3781263440
I0526 15:44:49.564666 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0526 15:44:49.564672 30701 net.cpp:84] Creating Layer layer_256_3_bn2
I0526 15:44:49.564677 30701 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0526 15:44:49.564684 30701 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.564863 30701 net.cpp:122] Setting up layer_256_3_bn2
I0526 15:44:49.564872 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.564877 30701 net.cpp:137] Memory required for data: 3785277520
I0526 15:44:49.564884 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0526 15:44:49.564890 30701 net.cpp:84] Creating Layer layer_256_3_scale2
I0526 15:44:49.564895 30701 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0526 15:44:49.564901 30701 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.564940 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0526 15:44:49.565044 30701 net.cpp:122] Setting up layer_256_3_scale2
I0526 15:44:49.565053 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.565057 30701 net.cpp:137] Memory required for data: 3789291600
I0526 15:44:49.565063 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0526 15:44:49.565069 30701 net.cpp:84] Creating Layer layer_256_3_relu2
I0526 15:44:49.565073 30701 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0526 15:44:49.565078 30701 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.565732 30701 net.cpp:122] Setting up layer_256_3_relu2
I0526 15:44:49.565743 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.565747 30701 net.cpp:137] Memory required for data: 3793305680
I0526 15:44:49.565752 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0526 15:44:49.565762 30701 net.cpp:84] Creating Layer layer_256_3_conv2
I0526 15:44:49.565767 30701 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0526 15:44:49.565773 30701 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0526 15:44:49.574007 30701 net.cpp:122] Setting up layer_256_3_conv2
I0526 15:44:49.574020 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.574024 30701 net.cpp:137] Memory required for data: 3797319760
I0526 15:44:49.574029 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn3
I0526 15:44:49.574038 30701 net.cpp:84] Creating Layer layer_256_3_bn3
I0526 15:44:49.574043 30701 net.cpp:406] layer_256_3_bn3 <- layer_256_3_conv2
I0526 15:44:49.574048 30701 net.cpp:367] layer_256_3_bn3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.574229 30701 net.cpp:122] Setting up layer_256_3_bn3
I0526 15:44:49.574239 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.574242 30701 net.cpp:137] Memory required for data: 3801333840
I0526 15:44:49.574249 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0526 15:44:49.574257 30701 net.cpp:84] Creating Layer layer_256_3_scale3
I0526 15:44:49.574261 30701 net.cpp:406] layer_256_3_scale3 <- layer_256_3_conv2
I0526 15:44:49.574266 30701 net.cpp:367] layer_256_3_scale3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.574309 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0526 15:44:49.574414 30701 net.cpp:122] Setting up layer_256_3_scale3
I0526 15:44:49.574422 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.574426 30701 net.cpp:137] Memory required for data: 3805347920
I0526 15:44:49.574432 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu3
I0526 15:44:49.574439 30701 net.cpp:84] Creating Layer layer_256_3_relu3
I0526 15:44:49.574442 30701 net.cpp:406] layer_256_3_relu3 <- layer_256_3_conv2
I0526 15:44:49.574448 30701 net.cpp:367] layer_256_3_relu3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.574606 30701 net.cpp:122] Setting up layer_256_3_relu3
I0526 15:44:49.574617 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.574620 30701 net.cpp:137] Memory required for data: 3809362000
I0526 15:44:49.574625 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv3
I0526 15:44:49.574633 30701 net.cpp:84] Creating Layer layer_256_3_conv3
I0526 15:44:49.574638 30701 net.cpp:406] layer_256_3_conv3 <- layer_256_3_conv2
I0526 15:44:49.574645 30701 net.cpp:380] layer_256_3_conv3 -> layer_256_3_conv3
I0526 15:44:49.578384 30701 net.cpp:122] Setting up layer_256_3_conv3
I0526 15:44:49.578397 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578400 30701 net.cpp:137] Memory required for data: 3825418320
I0526 15:44:49.578405 30701 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0526 15:44:49.578414 30701 net.cpp:84] Creating Layer layer_256_3_sum
I0526 15:44:49.578419 30701 net.cpp:406] layer_256_3_sum <- layer_256_3_conv3
I0526 15:44:49.578423 30701 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0526 15:44:49.578429 30701 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0526 15:44:49.578460 30701 net.cpp:122] Setting up layer_256_3_sum
I0526 15:44:49.578469 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578471 30701 net.cpp:137] Memory required for data: 3841474640
I0526 15:44:49.578474 30701 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.578480 30701 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.578483 30701 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0526 15:44:49.578490 30701 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0526 15:44:49.578505 30701 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0526 15:44:49.578547 30701 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.578554 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578560 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578563 30701 net.cpp:137] Memory required for data: 3873587280
I0526 15:44:49.578567 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0526 15:44:49.578572 30701 net.cpp:84] Creating Layer layer_256_4_bn1
I0526 15:44:49.578575 30701 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0526 15:44:49.578583 30701 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0526 15:44:49.578773 30701 net.cpp:122] Setting up layer_256_4_bn1
I0526 15:44:49.578781 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578784 30701 net.cpp:137] Memory required for data: 3889643600
I0526 15:44:49.578793 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0526 15:44:49.578800 30701 net.cpp:84] Creating Layer layer_256_4_scale1
I0526 15:44:49.578805 30701 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0526 15:44:49.578809 30701 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0526 15:44:49.578848 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0526 15:44:49.578959 30701 net.cpp:122] Setting up layer_256_4_scale1
I0526 15:44:49.578968 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.578971 30701 net.cpp:137] Memory required for data: 3905699920
I0526 15:44:49.578977 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0526 15:44:49.578984 30701 net.cpp:84] Creating Layer layer_256_4_relu1
I0526 15:44:49.578989 30701 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0526 15:44:49.578994 30701 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0526 15:44:49.579146 30701 net.cpp:122] Setting up layer_256_4_relu1
I0526 15:44:49.579156 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.579160 30701 net.cpp:137] Memory required for data: 3921756240
I0526 15:44:49.579164 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0526 15:44:49.579172 30701 net.cpp:84] Creating Layer layer_256_4_conv1
I0526 15:44:49.579177 30701 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0526 15:44:49.579185 30701 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0526 15:44:49.583657 30701 net.cpp:122] Setting up layer_256_4_conv1
I0526 15:44:49.583672 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.583675 30701 net.cpp:137] Memory required for data: 3925770320
I0526 15:44:49.583680 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0526 15:44:49.583688 30701 net.cpp:84] Creating Layer layer_256_4_bn2
I0526 15:44:49.583693 30701 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0526 15:44:49.583699 30701 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.583879 30701 net.cpp:122] Setting up layer_256_4_bn2
I0526 15:44:49.583889 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.583891 30701 net.cpp:137] Memory required for data: 3929784400
I0526 15:44:49.583899 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0526 15:44:49.583907 30701 net.cpp:84] Creating Layer layer_256_4_scale2
I0526 15:44:49.583911 30701 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0526 15:44:49.583916 30701 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.583963 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0526 15:44:49.584072 30701 net.cpp:122] Setting up layer_256_4_scale2
I0526 15:44:49.584081 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.584085 30701 net.cpp:137] Memory required for data: 3933798480
I0526 15:44:49.584091 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0526 15:44:49.584097 30701 net.cpp:84] Creating Layer layer_256_4_relu2
I0526 15:44:49.584101 30701 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0526 15:44:49.584117 30701 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.584276 30701 net.cpp:122] Setting up layer_256_4_relu2
I0526 15:44:49.584287 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.584291 30701 net.cpp:137] Memory required for data: 3937812560
I0526 15:44:49.584295 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0526 15:44:49.584305 30701 net.cpp:84] Creating Layer layer_256_4_conv2
I0526 15:44:49.584308 30701 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0526 15:44:49.584316 30701 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0526 15:44:49.592699 30701 net.cpp:122] Setting up layer_256_4_conv2
I0526 15:44:49.592718 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.592721 30701 net.cpp:137] Memory required for data: 3941826640
I0526 15:44:49.592728 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn3
I0526 15:44:49.592737 30701 net.cpp:84] Creating Layer layer_256_4_bn3
I0526 15:44:49.592742 30701 net.cpp:406] layer_256_4_bn3 <- layer_256_4_conv2
I0526 15:44:49.592749 30701 net.cpp:367] layer_256_4_bn3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.592941 30701 net.cpp:122] Setting up layer_256_4_bn3
I0526 15:44:49.592950 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.592953 30701 net.cpp:137] Memory required for data: 3945840720
I0526 15:44:49.592962 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0526 15:44:49.592969 30701 net.cpp:84] Creating Layer layer_256_4_scale3
I0526 15:44:49.592972 30701 net.cpp:406] layer_256_4_scale3 <- layer_256_4_conv2
I0526 15:44:49.592978 30701 net.cpp:367] layer_256_4_scale3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.593024 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0526 15:44:49.593132 30701 net.cpp:122] Setting up layer_256_4_scale3
I0526 15:44:49.593142 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.593144 30701 net.cpp:137] Memory required for data: 3949854800
I0526 15:44:49.593150 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu3
I0526 15:44:49.593156 30701 net.cpp:84] Creating Layer layer_256_4_relu3
I0526 15:44:49.593159 30701 net.cpp:406] layer_256_4_relu3 <- layer_256_4_conv2
I0526 15:44:49.593165 30701 net.cpp:367] layer_256_4_relu3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.593324 30701 net.cpp:122] Setting up layer_256_4_relu3
I0526 15:44:49.593335 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.593338 30701 net.cpp:137] Memory required for data: 3953868880
I0526 15:44:49.593341 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv3
I0526 15:44:49.593351 30701 net.cpp:84] Creating Layer layer_256_4_conv3
I0526 15:44:49.593354 30701 net.cpp:406] layer_256_4_conv3 <- layer_256_4_conv2
I0526 15:44:49.593361 30701 net.cpp:380] layer_256_4_conv3 -> layer_256_4_conv3
I0526 15:44:49.597157 30701 net.cpp:122] Setting up layer_256_4_conv3
I0526 15:44:49.597170 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597173 30701 net.cpp:137] Memory required for data: 3969925200
I0526 15:44:49.597179 30701 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0526 15:44:49.597187 30701 net.cpp:84] Creating Layer layer_256_4_sum
I0526 15:44:49.597190 30701 net.cpp:406] layer_256_4_sum <- layer_256_4_conv3
I0526 15:44:49.597195 30701 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0526 15:44:49.597200 30701 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0526 15:44:49.597231 30701 net.cpp:122] Setting up layer_256_4_sum
I0526 15:44:49.597239 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597242 30701 net.cpp:137] Memory required for data: 3985981520
I0526 15:44:49.597245 30701 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:49.597250 30701 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:49.597254 30701 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0526 15:44:49.597275 30701 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0526 15:44:49.597282 30701 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0526 15:44:49.597321 30701 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:49.597329 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597333 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597337 30701 net.cpp:137] Memory required for data: 4018094160
I0526 15:44:49.597339 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0526 15:44:49.597344 30701 net.cpp:84] Creating Layer layer_256_5_bn1
I0526 15:44:49.597347 30701 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0526 15:44:49.597354 30701 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0526 15:44:49.597548 30701 net.cpp:122] Setting up layer_256_5_bn1
I0526 15:44:49.597558 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597560 30701 net.cpp:137] Memory required for data: 4034150480
I0526 15:44:49.597568 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0526 15:44:49.597574 30701 net.cpp:84] Creating Layer layer_256_5_scale1
I0526 15:44:49.597579 30701 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0526 15:44:49.597584 30701 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0526 15:44:49.597622 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0526 15:44:49.597735 30701 net.cpp:122] Setting up layer_256_5_scale1
I0526 15:44:49.597743 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.597748 30701 net.cpp:137] Memory required for data: 4050206800
I0526 15:44:49.597754 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0526 15:44:49.597760 30701 net.cpp:84] Creating Layer layer_256_5_relu1
I0526 15:44:49.597765 30701 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0526 15:44:49.597769 30701 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0526 15:44:49.598419 30701 net.cpp:122] Setting up layer_256_5_relu1
I0526 15:44:49.598430 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.598435 30701 net.cpp:137] Memory required for data: 4066263120
I0526 15:44:49.598438 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0526 15:44:49.598448 30701 net.cpp:84] Creating Layer layer_256_5_conv1
I0526 15:44:49.598453 30701 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0526 15:44:49.598460 30701 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0526 15:44:49.602468 30701 net.cpp:122] Setting up layer_256_5_conv1
I0526 15:44:49.602480 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.602484 30701 net.cpp:137] Memory required for data: 4070277200
I0526 15:44:49.602489 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0526 15:44:49.602499 30701 net.cpp:84] Creating Layer layer_256_5_bn2
I0526 15:44:49.602502 30701 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0526 15:44:49.602509 30701 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0526 15:44:49.602694 30701 net.cpp:122] Setting up layer_256_5_bn2
I0526 15:44:49.602702 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.602706 30701 net.cpp:137] Memory required for data: 4074291280
I0526 15:44:49.602715 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0526 15:44:49.602721 30701 net.cpp:84] Creating Layer layer_256_5_scale2
I0526 15:44:49.602725 30701 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0526 15:44:49.602731 30701 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0526 15:44:49.602774 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0526 15:44:49.602881 30701 net.cpp:122] Setting up layer_256_5_scale2
I0526 15:44:49.602890 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.602895 30701 net.cpp:137] Memory required for data: 4078305360
I0526 15:44:49.602900 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0526 15:44:49.602916 30701 net.cpp:84] Creating Layer layer_256_5_relu2
I0526 15:44:49.602919 30701 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0526 15:44:49.602926 30701 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0526 15:44:49.603572 30701 net.cpp:122] Setting up layer_256_5_relu2
I0526 15:44:49.603586 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.603591 30701 net.cpp:137] Memory required for data: 4082319440
I0526 15:44:49.603595 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0526 15:44:49.603603 30701 net.cpp:84] Creating Layer layer_256_5_conv2
I0526 15:44:49.603608 30701 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0526 15:44:49.603615 30701 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0526 15:44:49.612063 30701 net.cpp:122] Setting up layer_256_5_conv2
I0526 15:44:49.612088 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.612092 30701 net.cpp:137] Memory required for data: 4086333520
I0526 15:44:49.612099 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn3
I0526 15:44:49.612110 30701 net.cpp:84] Creating Layer layer_256_5_bn3
I0526 15:44:49.612115 30701 net.cpp:406] layer_256_5_bn3 <- layer_256_5_conv2
I0526 15:44:49.612123 30701 net.cpp:367] layer_256_5_bn3 -> layer_256_5_conv2 (in-place)
I0526 15:44:49.612321 30701 net.cpp:122] Setting up layer_256_5_bn3
I0526 15:44:49.612330 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.612334 30701 net.cpp:137] Memory required for data: 4090347600
I0526 15:44:49.612341 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0526 15:44:49.612349 30701 net.cpp:84] Creating Layer layer_256_5_scale3
I0526 15:44:49.612354 30701 net.cpp:406] layer_256_5_scale3 <- layer_256_5_conv2
I0526 15:44:49.612360 30701 net.cpp:367] layer_256_5_scale3 -> layer_256_5_conv2 (in-place)
I0526 15:44:49.612406 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0526 15:44:49.612519 30701 net.cpp:122] Setting up layer_256_5_scale3
I0526 15:44:49.612529 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.612532 30701 net.cpp:137] Memory required for data: 4094361680
I0526 15:44:49.612537 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu3
I0526 15:44:49.612545 30701 net.cpp:84] Creating Layer layer_256_5_relu3
I0526 15:44:49.612550 30701 net.cpp:406] layer_256_5_relu3 <- layer_256_5_conv2
I0526 15:44:49.612555 30701 net.cpp:367] layer_256_5_relu3 -> layer_256_5_conv2 (in-place)
I0526 15:44:49.612721 30701 net.cpp:122] Setting up layer_256_5_relu3
I0526 15:44:49.612731 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.612735 30701 net.cpp:137] Memory required for data: 4098375760
I0526 15:44:49.612738 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv3
I0526 15:44:49.612749 30701 net.cpp:84] Creating Layer layer_256_5_conv3
I0526 15:44:49.612754 30701 net.cpp:406] layer_256_5_conv3 <- layer_256_5_conv2
I0526 15:44:49.612761 30701 net.cpp:380] layer_256_5_conv3 -> layer_256_5_conv3
I0526 15:44:49.616586 30701 net.cpp:122] Setting up layer_256_5_conv3
I0526 15:44:49.616598 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.616602 30701 net.cpp:137] Memory required for data: 4114432080
I0526 15:44:49.616607 30701 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0526 15:44:49.616614 30701 net.cpp:84] Creating Layer layer_256_5_sum
I0526 15:44:49.616619 30701 net.cpp:406] layer_256_5_sum <- layer_256_5_conv3
I0526 15:44:49.616624 30701 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0526 15:44:49.616631 30701 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0526 15:44:49.616663 30701 net.cpp:122] Setting up layer_256_5_sum
I0526 15:44:49.616672 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.616675 30701 net.cpp:137] Memory required for data: 4130488400
I0526 15:44:49.616678 30701 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:49.616684 30701 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:49.616703 30701 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0526 15:44:49.616709 30701 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0526 15:44:49.616716 30701 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0526 15:44:49.616756 30701 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:49.616765 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.616770 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.616772 30701 net.cpp:137] Memory required for data: 4162601040
I0526 15:44:49.616775 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0526 15:44:49.616782 30701 net.cpp:84] Creating Layer layer_256_6_bn1
I0526 15:44:49.616787 30701 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0526 15:44:49.616793 30701 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0526 15:44:49.616991 30701 net.cpp:122] Setting up layer_256_6_bn1
I0526 15:44:49.616998 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.617002 30701 net.cpp:137] Memory required for data: 4178657360
I0526 15:44:49.617010 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0526 15:44:49.617017 30701 net.cpp:84] Creating Layer layer_256_6_scale1
I0526 15:44:49.617022 30701 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0526 15:44:49.617025 30701 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0526 15:44:49.617067 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0526 15:44:49.617182 30701 net.cpp:122] Setting up layer_256_6_scale1
I0526 15:44:49.617192 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.617194 30701 net.cpp:137] Memory required for data: 4194713680
I0526 15:44:49.617202 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0526 15:44:49.617208 30701 net.cpp:84] Creating Layer layer_256_6_relu1
I0526 15:44:49.617211 30701 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0526 15:44:49.617215 30701 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0526 15:44:49.617377 30701 net.cpp:122] Setting up layer_256_6_relu1
I0526 15:44:49.617388 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.617390 30701 net.cpp:137] Memory required for data: 4210770000
I0526 15:44:49.617394 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0526 15:44:49.617404 30701 net.cpp:84] Creating Layer layer_256_6_conv1
I0526 15:44:49.617408 30701 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0526 15:44:49.617415 30701 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0526 15:44:49.622004 30701 net.cpp:122] Setting up layer_256_6_conv1
I0526 15:44:49.622020 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.622025 30701 net.cpp:137] Memory required for data: 4214784080
I0526 15:44:49.622031 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0526 15:44:49.622040 30701 net.cpp:84] Creating Layer layer_256_6_bn2
I0526 15:44:49.622045 30701 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0526 15:44:49.622051 30701 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0526 15:44:49.622244 30701 net.cpp:122] Setting up layer_256_6_bn2
I0526 15:44:49.622253 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.622257 30701 net.cpp:137] Memory required for data: 4218798160
I0526 15:44:49.622264 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0526 15:44:49.622273 30701 net.cpp:84] Creating Layer layer_256_6_scale2
I0526 15:44:49.622278 30701 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0526 15:44:49.622283 30701 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0526 15:44:49.622334 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0526 15:44:49.622478 30701 net.cpp:122] Setting up layer_256_6_scale2
I0526 15:44:49.622488 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.622491 30701 net.cpp:137] Memory required for data: 4222812240
I0526 15:44:49.622509 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0526 15:44:49.622515 30701 net.cpp:84] Creating Layer layer_256_6_relu2
I0526 15:44:49.622520 30701 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0526 15:44:49.622527 30701 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0526 15:44:49.622685 30701 net.cpp:122] Setting up layer_256_6_relu2
I0526 15:44:49.622696 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.622700 30701 net.cpp:137] Memory required for data: 4226826320
I0526 15:44:49.622704 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0526 15:44:49.622714 30701 net.cpp:84] Creating Layer layer_256_6_conv2
I0526 15:44:49.622719 30701 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0526 15:44:49.622725 30701 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0526 15:44:49.631063 30701 net.cpp:122] Setting up layer_256_6_conv2
I0526 15:44:49.631080 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.631083 30701 net.cpp:137] Memory required for data: 4230840400
I0526 15:44:49.631089 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn3
I0526 15:44:49.631096 30701 net.cpp:84] Creating Layer layer_256_6_bn3
I0526 15:44:49.631101 30701 net.cpp:406] layer_256_6_bn3 <- layer_256_6_conv2
I0526 15:44:49.631108 30701 net.cpp:367] layer_256_6_bn3 -> layer_256_6_conv2 (in-place)
I0526 15:44:49.631302 30701 net.cpp:122] Setting up layer_256_6_bn3
I0526 15:44:49.631311 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.631314 30701 net.cpp:137] Memory required for data: 4234854480
I0526 15:44:49.631321 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0526 15:44:49.631328 30701 net.cpp:84] Creating Layer layer_256_6_scale3
I0526 15:44:49.631333 30701 net.cpp:406] layer_256_6_scale3 <- layer_256_6_conv2
I0526 15:44:49.631341 30701 net.cpp:367] layer_256_6_scale3 -> layer_256_6_conv2 (in-place)
I0526 15:44:49.631386 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0526 15:44:49.631498 30701 net.cpp:122] Setting up layer_256_6_scale3
I0526 15:44:49.631507 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.631510 30701 net.cpp:137] Memory required for data: 4238868560
I0526 15:44:49.631516 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu3
I0526 15:44:49.631522 30701 net.cpp:84] Creating Layer layer_256_6_relu3
I0526 15:44:49.631526 30701 net.cpp:406] layer_256_6_relu3 <- layer_256_6_conv2
I0526 15:44:49.631531 30701 net.cpp:367] layer_256_6_relu3 -> layer_256_6_conv2 (in-place)
I0526 15:44:49.631695 30701 net.cpp:122] Setting up layer_256_6_relu3
I0526 15:44:49.631705 30701 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0526 15:44:49.631711 30701 net.cpp:137] Memory required for data: 4242882640
I0526 15:44:49.631713 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv3
I0526 15:44:49.631722 30701 net.cpp:84] Creating Layer layer_256_6_conv3
I0526 15:44:49.631727 30701 net.cpp:406] layer_256_6_conv3 <- layer_256_6_conv2
I0526 15:44:49.631736 30701 net.cpp:380] layer_256_6_conv3 -> layer_256_6_conv3
I0526 15:44:49.635551 30701 net.cpp:122] Setting up layer_256_6_conv3
I0526 15:44:49.635565 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.635570 30701 net.cpp:137] Memory required for data: 4258938960
I0526 15:44:49.635574 30701 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0526 15:44:49.635581 30701 net.cpp:84] Creating Layer layer_256_6_sum
I0526 15:44:49.635583 30701 net.cpp:406] layer_256_6_sum <- layer_256_6_conv3
I0526 15:44:49.635588 30701 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0526 15:44:49.635593 30701 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0526 15:44:49.635623 30701 net.cpp:122] Setting up layer_256_6_sum
I0526 15:44:49.635632 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.635637 30701 net.cpp:137] Memory required for data: 4274995280
I0526 15:44:49.635639 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0526 15:44:49.635658 30701 net.cpp:84] Creating Layer layer_512_1_bn1
I0526 15:44:49.635663 30701 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0526 15:44:49.635668 30701 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0526 15:44:49.635872 30701 net.cpp:122] Setting up layer_512_1_bn1
I0526 15:44:49.635881 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.635886 30701 net.cpp:137] Memory required for data: 4291051600
I0526 15:44:49.635893 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0526 15:44:49.635900 30701 net.cpp:84] Creating Layer layer_512_1_scale1
I0526 15:44:49.635905 30701 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0526 15:44:49.635911 30701 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0526 15:44:49.635957 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0526 15:44:49.636075 30701 net.cpp:122] Setting up layer_512_1_scale1
I0526 15:44:49.636083 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.636086 30701 net.cpp:137] Memory required for data: 4307107920
I0526 15:44:49.636092 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0526 15:44:49.636098 30701 net.cpp:84] Creating Layer layer_512_1_relu1
I0526 15:44:49.636101 30701 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0526 15:44:49.636107 30701 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0526 15:44:49.636772 30701 net.cpp:122] Setting up layer_512_1_relu1
I0526 15:44:49.636785 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.636788 30701 net.cpp:137] Memory required for data: 4323164240
I0526 15:44:49.636791 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:49.636798 30701 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:49.636802 30701 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0526 15:44:49.636807 30701 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0526 15:44:49.636816 30701 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0526 15:44:49.636862 30701 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:49.636869 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.636873 30701 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0526 15:44:49.636876 30701 net.cpp:137] Memory required for data: 4355276880
I0526 15:44:49.636879 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0526 15:44:49.636889 30701 net.cpp:84] Creating Layer layer_512_1_conv1
I0526 15:44:49.636894 30701 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0526 15:44:49.636900 30701 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0526 15:44:49.643470 30701 net.cpp:122] Setting up layer_512_1_conv1
I0526 15:44:49.643484 30701 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0526 15:44:49.643488 30701 net.cpp:137] Memory required for data: 4363305040
I0526 15:44:49.643493 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0526 15:44:49.643499 30701 net.cpp:84] Creating Layer layer_512_1_bn2
I0526 15:44:49.643504 30701 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0526 15:44:49.643512 30701 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0526 15:44:49.643707 30701 net.cpp:122] Setting up layer_512_1_bn2
I0526 15:44:49.643715 30701 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0526 15:44:49.643719 30701 net.cpp:137] Memory required for data: 4371333200
I0526 15:44:49.643726 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0526 15:44:49.643734 30701 net.cpp:84] Creating Layer layer_512_1_scale2
I0526 15:44:49.643738 30701 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0526 15:44:49.643743 30701 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0526 15:44:49.643784 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0526 15:44:49.643903 30701 net.cpp:122] Setting up layer_512_1_scale2
I0526 15:44:49.643921 30701 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0526 15:44:49.643925 30701 net.cpp:137] Memory required for data: 4379361360
I0526 15:44:49.643931 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0526 15:44:49.643939 30701 net.cpp:84] Creating Layer layer_512_1_relu2
I0526 15:44:49.643944 30701 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0526 15:44:49.643952 30701 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0526 15:44:49.645102 30701 net.cpp:122] Setting up layer_512_1_relu2
I0526 15:44:49.645114 30701 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0526 15:44:49.645118 30701 net.cpp:137] Memory required for data: 4387389520
I0526 15:44:49.645123 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0526 15:44:49.645133 30701 net.cpp:84] Creating Layer layer_512_1_conv2
I0526 15:44:49.645136 30701 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0526 15:44:49.645144 30701 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0526 15:44:49.672605 30701 net.cpp:122] Setting up layer_512_1_conv2
I0526 15:44:49.672634 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.672638 30701 net.cpp:137] Memory required for data: 4389396560
I0526 15:44:49.672647 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn3
I0526 15:44:49.672660 30701 net.cpp:84] Creating Layer layer_512_1_bn3
I0526 15:44:49.672667 30701 net.cpp:406] layer_512_1_bn3 <- layer_512_1_conv2
I0526 15:44:49.672675 30701 net.cpp:367] layer_512_1_bn3 -> layer_512_1_conv2 (in-place)
I0526 15:44:49.672890 30701 net.cpp:122] Setting up layer_512_1_bn3
I0526 15:44:49.672900 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.672904 30701 net.cpp:137] Memory required for data: 4391403600
I0526 15:44:49.672933 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0526 15:44:49.672943 30701 net.cpp:84] Creating Layer layer_512_1_scale3
I0526 15:44:49.672948 30701 net.cpp:406] layer_512_1_scale3 <- layer_512_1_conv2
I0526 15:44:49.672953 30701 net.cpp:367] layer_512_1_scale3 -> layer_512_1_conv2 (in-place)
I0526 15:44:49.673002 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0526 15:44:49.673125 30701 net.cpp:122] Setting up layer_512_1_scale3
I0526 15:44:49.673132 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.673135 30701 net.cpp:137] Memory required for data: 4393410640
I0526 15:44:49.673141 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu3
I0526 15:44:49.673149 30701 net.cpp:84] Creating Layer layer_512_1_relu3
I0526 15:44:49.673153 30701 net.cpp:406] layer_512_1_relu3 <- layer_512_1_conv2
I0526 15:44:49.673158 30701 net.cpp:367] layer_512_1_relu3 -> layer_512_1_conv2 (in-place)
I0526 15:44:49.673319 30701 net.cpp:122] Setting up layer_512_1_relu3
I0526 15:44:49.673328 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.673331 30701 net.cpp:137] Memory required for data: 4395417680
I0526 15:44:49.673336 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv3
I0526 15:44:49.673346 30701 net.cpp:84] Creating Layer layer_512_1_conv3
I0526 15:44:49.673351 30701 net.cpp:406] layer_512_1_conv3 <- layer_512_1_conv2
I0526 15:44:49.673357 30701 net.cpp:380] layer_512_1_conv3 -> layer_512_1_conv3
I0526 15:44:49.685880 30701 net.cpp:122] Setting up layer_512_1_conv3
I0526 15:44:49.685897 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.685901 30701 net.cpp:137] Memory required for data: 4403445840
I0526 15:44:49.685907 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0526 15:44:49.685919 30701 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0526 15:44:49.685922 30701 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0526 15:44:49.685930 30701 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0526 15:44:49.710220 30701 net.cpp:122] Setting up layer_512_1_conv_expand
I0526 15:44:49.710258 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710263 30701 net.cpp:137] Memory required for data: 4411474000
I0526 15:44:49.710295 30701 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0526 15:44:49.710304 30701 net.cpp:84] Creating Layer layer_512_1_sum
I0526 15:44:49.710310 30701 net.cpp:406] layer_512_1_sum <- layer_512_1_conv3
I0526 15:44:49.710319 30701 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0526 15:44:49.710328 30701 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0526 15:44:49.710362 30701 net.cpp:122] Setting up layer_512_1_sum
I0526 15:44:49.710371 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710373 30701 net.cpp:137] Memory required for data: 4419502160
I0526 15:44:49.710377 30701 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:49.710384 30701 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:49.710388 30701 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0526 15:44:49.710394 30701 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0526 15:44:49.710402 30701 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0526 15:44:49.710443 30701 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:49.710451 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710455 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710458 30701 net.cpp:137] Memory required for data: 4435558480
I0526 15:44:49.710461 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0526 15:44:49.710467 30701 net.cpp:84] Creating Layer layer_512_2_bn1
I0526 15:44:49.710472 30701 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0526 15:44:49.710479 30701 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0526 15:44:49.710706 30701 net.cpp:122] Setting up layer_512_2_bn1
I0526 15:44:49.710716 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710718 30701 net.cpp:137] Memory required for data: 4443586640
I0526 15:44:49.710726 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0526 15:44:49.710736 30701 net.cpp:84] Creating Layer layer_512_2_scale1
I0526 15:44:49.710741 30701 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0526 15:44:49.710746 30701 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0526 15:44:49.710794 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0526 15:44:49.710922 30701 net.cpp:122] Setting up layer_512_2_scale1
I0526 15:44:49.710929 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.710934 30701 net.cpp:137] Memory required for data: 4451614800
I0526 15:44:49.710940 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0526 15:44:49.710947 30701 net.cpp:84] Creating Layer layer_512_2_relu1
I0526 15:44:49.710952 30701 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0526 15:44:49.710957 30701 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0526 15:44:49.711114 30701 net.cpp:122] Setting up layer_512_2_relu1
I0526 15:44:49.711123 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.711128 30701 net.cpp:137] Memory required for data: 4459642960
I0526 15:44:49.711132 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0526 15:44:49.711143 30701 net.cpp:84] Creating Layer layer_512_2_conv1
I0526 15:44:49.711148 30701 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0526 15:44:49.711154 30701 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0526 15:44:49.724057 30701 net.cpp:122] Setting up layer_512_2_conv1
I0526 15:44:49.724081 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.724086 30701 net.cpp:137] Memory required for data: 4461650000
I0526 15:44:49.724093 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0526 15:44:49.724103 30701 net.cpp:84] Creating Layer layer_512_2_bn2
I0526 15:44:49.724109 30701 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0526 15:44:49.724117 30701 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0526 15:44:49.724341 30701 net.cpp:122] Setting up layer_512_2_bn2
I0526 15:44:49.724350 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.724354 30701 net.cpp:137] Memory required for data: 4463657040
I0526 15:44:49.724361 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0526 15:44:49.724370 30701 net.cpp:84] Creating Layer layer_512_2_scale2
I0526 15:44:49.724375 30701 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0526 15:44:49.724380 30701 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0526 15:44:49.724426 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0526 15:44:49.724550 30701 net.cpp:122] Setting up layer_512_2_scale2
I0526 15:44:49.724560 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.724562 30701 net.cpp:137] Memory required for data: 4465664080
I0526 15:44:49.724568 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0526 15:44:49.724575 30701 net.cpp:84] Creating Layer layer_512_2_relu2
I0526 15:44:49.724578 30701 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0526 15:44:49.724584 30701 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0526 15:44:49.724743 30701 net.cpp:122] Setting up layer_512_2_relu2
I0526 15:44:49.724752 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.724756 30701 net.cpp:137] Memory required for data: 4467671120
I0526 15:44:49.724759 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0526 15:44:49.724771 30701 net.cpp:84] Creating Layer layer_512_2_conv2
I0526 15:44:49.724776 30701 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0526 15:44:49.724782 30701 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0526 15:44:49.751679 30701 net.cpp:122] Setting up layer_512_2_conv2
I0526 15:44:49.751719 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.751724 30701 net.cpp:137] Memory required for data: 4469678160
I0526 15:44:49.751734 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn3
I0526 15:44:49.751744 30701 net.cpp:84] Creating Layer layer_512_2_bn3
I0526 15:44:49.751749 30701 net.cpp:406] layer_512_2_bn3 <- layer_512_2_conv2
I0526 15:44:49.751758 30701 net.cpp:367] layer_512_2_bn3 -> layer_512_2_conv2 (in-place)
I0526 15:44:49.751988 30701 net.cpp:122] Setting up layer_512_2_bn3
I0526 15:44:49.751997 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.752001 30701 net.cpp:137] Memory required for data: 4471685200
I0526 15:44:49.752008 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0526 15:44:49.752015 30701 net.cpp:84] Creating Layer layer_512_2_scale3
I0526 15:44:49.752018 30701 net.cpp:406] layer_512_2_scale3 <- layer_512_2_conv2
I0526 15:44:49.752024 30701 net.cpp:367] layer_512_2_scale3 -> layer_512_2_conv2 (in-place)
I0526 15:44:49.752082 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0526 15:44:49.752243 30701 net.cpp:122] Setting up layer_512_2_scale3
I0526 15:44:49.752251 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.752254 30701 net.cpp:137] Memory required for data: 4473692240
I0526 15:44:49.752259 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu3
I0526 15:44:49.752265 30701 net.cpp:84] Creating Layer layer_512_2_relu3
I0526 15:44:49.752269 30701 net.cpp:406] layer_512_2_relu3 <- layer_512_2_conv2
I0526 15:44:49.752274 30701 net.cpp:367] layer_512_2_relu3 -> layer_512_2_conv2 (in-place)
I0526 15:44:49.752449 30701 net.cpp:122] Setting up layer_512_2_relu3
I0526 15:44:49.752459 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.752461 30701 net.cpp:137] Memory required for data: 4475699280
I0526 15:44:49.752465 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv3
I0526 15:44:49.752475 30701 net.cpp:84] Creating Layer layer_512_2_conv3
I0526 15:44:49.752480 30701 net.cpp:406] layer_512_2_conv3 <- layer_512_2_conv2
I0526 15:44:49.752486 30701 net.cpp:380] layer_512_2_conv3 -> layer_512_2_conv3
I0526 15:44:49.765557 30701 net.cpp:122] Setting up layer_512_2_conv3
I0526 15:44:49.765584 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.765606 30701 net.cpp:137] Memory required for data: 4483727440
I0526 15:44:49.765615 30701 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0526 15:44:49.765625 30701 net.cpp:84] Creating Layer layer_512_2_sum
I0526 15:44:49.765630 30701 net.cpp:406] layer_512_2_sum <- layer_512_2_conv3
I0526 15:44:49.765637 30701 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0526 15:44:49.765645 30701 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0526 15:44:49.765679 30701 net.cpp:122] Setting up layer_512_2_sum
I0526 15:44:49.765687 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.765692 30701 net.cpp:137] Memory required for data: 4491755600
I0526 15:44:49.765696 30701 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:49.765702 30701 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:49.765707 30701 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0526 15:44:49.765712 30701 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0526 15:44:49.765719 30701 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0526 15:44:49.765760 30701 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:49.765769 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.765774 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.765776 30701 net.cpp:137] Memory required for data: 4507811920
I0526 15:44:49.765779 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0526 15:44:49.765786 30701 net.cpp:84] Creating Layer layer_512_3_bn1
I0526 15:44:49.765791 30701 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0526 15:44:49.765796 30701 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0526 15:44:49.766018 30701 net.cpp:122] Setting up layer_512_3_bn1
I0526 15:44:49.766027 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.766031 30701 net.cpp:137] Memory required for data: 4515840080
I0526 15:44:49.766039 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0526 15:44:49.766047 30701 net.cpp:84] Creating Layer layer_512_3_scale1
I0526 15:44:49.766050 30701 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0526 15:44:49.766055 30701 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0526 15:44:49.766104 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0526 15:44:49.766229 30701 net.cpp:122] Setting up layer_512_3_scale1
I0526 15:44:49.766238 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.766242 30701 net.cpp:137] Memory required for data: 4523868240
I0526 15:44:49.766248 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0526 15:44:49.766254 30701 net.cpp:84] Creating Layer layer_512_3_relu1
I0526 15:44:49.766259 30701 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0526 15:44:49.766265 30701 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0526 15:44:49.766424 30701 net.cpp:122] Setting up layer_512_3_relu1
I0526 15:44:49.766434 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.766438 30701 net.cpp:137] Memory required for data: 4531896400
I0526 15:44:49.766441 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0526 15:44:49.766453 30701 net.cpp:84] Creating Layer layer_512_3_conv1
I0526 15:44:49.766458 30701 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0526 15:44:49.766464 30701 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0526 15:44:49.779301 30701 net.cpp:122] Setting up layer_512_3_conv1
I0526 15:44:49.779320 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.779323 30701 net.cpp:137] Memory required for data: 4533903440
I0526 15:44:49.779330 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0526 15:44:49.779338 30701 net.cpp:84] Creating Layer layer_512_3_bn2
I0526 15:44:49.779342 30701 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0526 15:44:49.779362 30701 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0526 15:44:49.779575 30701 net.cpp:122] Setting up layer_512_3_bn2
I0526 15:44:49.779584 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.779587 30701 net.cpp:137] Memory required for data: 4535910480
I0526 15:44:49.779594 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0526 15:44:49.779603 30701 net.cpp:84] Creating Layer layer_512_3_scale2
I0526 15:44:49.779606 30701 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0526 15:44:49.779611 30701 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0526 15:44:49.779654 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0526 15:44:49.779778 30701 net.cpp:122] Setting up layer_512_3_scale2
I0526 15:44:49.779786 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.779789 30701 net.cpp:137] Memory required for data: 4537917520
I0526 15:44:49.779794 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0526 15:44:49.779800 30701 net.cpp:84] Creating Layer layer_512_3_relu2
I0526 15:44:49.779803 30701 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0526 15:44:49.779809 30701 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0526 15:44:49.780490 30701 net.cpp:122] Setting up layer_512_3_relu2
I0526 15:44:49.780503 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.780506 30701 net.cpp:137] Memory required for data: 4539924560
I0526 15:44:49.780521 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0526 15:44:49.780532 30701 net.cpp:84] Creating Layer layer_512_3_conv2
I0526 15:44:49.780536 30701 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0526 15:44:49.780542 30701 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0526 15:44:49.807680 30701 net.cpp:122] Setting up layer_512_3_conv2
I0526 15:44:49.807718 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.807723 30701 net.cpp:137] Memory required for data: 4541931600
I0526 15:44:49.807731 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn3
I0526 15:44:49.807744 30701 net.cpp:84] Creating Layer layer_512_3_bn3
I0526 15:44:49.807750 30701 net.cpp:406] layer_512_3_bn3 <- layer_512_3_conv2
I0526 15:44:49.807759 30701 net.cpp:367] layer_512_3_bn3 -> layer_512_3_conv2 (in-place)
I0526 15:44:49.807994 30701 net.cpp:122] Setting up layer_512_3_bn3
I0526 15:44:49.808004 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.808018 30701 net.cpp:137] Memory required for data: 4543938640
I0526 15:44:49.808027 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0526 15:44:49.808034 30701 net.cpp:84] Creating Layer layer_512_3_scale3
I0526 15:44:49.808038 30701 net.cpp:406] layer_512_3_scale3 <- layer_512_3_conv2
I0526 15:44:49.808043 30701 net.cpp:367] layer_512_3_scale3 -> layer_512_3_conv2 (in-place)
I0526 15:44:49.808094 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0526 15:44:49.808243 30701 net.cpp:122] Setting up layer_512_3_scale3
I0526 15:44:49.808253 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.808255 30701 net.cpp:137] Memory required for data: 4545945680
I0526 15:44:49.808261 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu3
I0526 15:44:49.808269 30701 net.cpp:84] Creating Layer layer_512_3_relu3
I0526 15:44:49.808271 30701 net.cpp:406] layer_512_3_relu3 <- layer_512_3_conv2
I0526 15:44:49.808277 30701 net.cpp:367] layer_512_3_relu3 -> layer_512_3_conv2 (in-place)
I0526 15:44:49.808446 30701 net.cpp:122] Setting up layer_512_3_relu3
I0526 15:44:49.808468 30701 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0526 15:44:49.808471 30701 net.cpp:137] Memory required for data: 4547952720
I0526 15:44:49.808475 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv3
I0526 15:44:49.808485 30701 net.cpp:84] Creating Layer layer_512_3_conv3
I0526 15:44:49.808488 30701 net.cpp:406] layer_512_3_conv3 <- layer_512_3_conv2
I0526 15:44:49.808495 30701 net.cpp:380] layer_512_3_conv3 -> layer_512_3_conv3
I0526 15:44:49.821079 30701 net.cpp:122] Setting up layer_512_3_conv3
I0526 15:44:49.821116 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.821120 30701 net.cpp:137] Memory required for data: 4555980880
I0526 15:44:49.821127 30701 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0526 15:44:49.821135 30701 net.cpp:84] Creating Layer layer_512_3_sum
I0526 15:44:49.821141 30701 net.cpp:406] layer_512_3_sum <- layer_512_3_conv3
I0526 15:44:49.821146 30701 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0526 15:44:49.821152 30701 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0526 15:44:49.821185 30701 net.cpp:122] Setting up layer_512_3_sum
I0526 15:44:49.821193 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.821197 30701 net.cpp:137] Memory required for data: 4564009040
I0526 15:44:49.821200 30701 layer_factory.hpp:77] Creating layer last_bn
I0526 15:44:49.821208 30701 net.cpp:84] Creating Layer last_bn
I0526 15:44:49.821213 30701 net.cpp:406] last_bn <- layer_512_3_sum
I0526 15:44:49.821218 30701 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0526 15:44:49.821429 30701 net.cpp:122] Setting up last_bn
I0526 15:44:49.821449 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.821451 30701 net.cpp:137] Memory required for data: 4572037200
I0526 15:44:49.821458 30701 layer_factory.hpp:77] Creating layer last_scale
I0526 15:44:49.821465 30701 net.cpp:84] Creating Layer last_scale
I0526 15:44:49.821467 30701 net.cpp:406] last_scale <- layer_512_3_sum
I0526 15:44:49.821476 30701 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0526 15:44:49.821534 30701 layer_factory.hpp:77] Creating layer last_scale
I0526 15:44:49.821672 30701 net.cpp:122] Setting up last_scale
I0526 15:44:49.821681 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.821684 30701 net.cpp:137] Memory required for data: 4580065360
I0526 15:44:49.821691 30701 layer_factory.hpp:77] Creating layer last_relu
I0526 15:44:49.821707 30701 net.cpp:84] Creating Layer last_relu
I0526 15:44:49.821712 30701 net.cpp:406] last_relu <- layer_512_3_sum
I0526 15:44:49.821717 30701 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0526 15:44:49.821884 30701 net.cpp:122] Setting up last_relu
I0526 15:44:49.821894 30701 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0526 15:44:49.821908 30701 net.cpp:137] Memory required for data: 4588093520
I0526 15:44:49.821913 30701 layer_factory.hpp:77] Creating layer global_pool
I0526 15:44:49.821920 30701 net.cpp:84] Creating Layer global_pool
I0526 15:44:49.821924 30701 net.cpp:406] global_pool <- layer_512_3_sum
I0526 15:44:49.821929 30701 net.cpp:380] global_pool -> global_pool
I0526 15:44:49.822705 30701 net.cpp:122] Setting up global_pool
I0526 15:44:49.822715 30701 net.cpp:129] Top shape: 20 2048 1 1 (40960)
I0526 15:44:49.822729 30701 net.cpp:137] Memory required for data: 4588257360
I0526 15:44:49.822733 30701 layer_factory.hpp:77] Creating layer score
I0526 15:44:49.822741 30701 net.cpp:84] Creating Layer score
I0526 15:44:49.822743 30701 net.cpp:406] score <- global_pool
I0526 15:44:49.822751 30701 net.cpp:380] score -> score
I0526 15:44:49.822891 30701 net.cpp:122] Setting up score
I0526 15:44:49.822901 30701 net.cpp:129] Top shape: 20 8 (160)
I0526 15:44:49.822904 30701 net.cpp:137] Memory required for data: 4588258000
I0526 15:44:49.822911 30701 layer_factory.hpp:77] Creating layer loss
I0526 15:44:49.822916 30701 net.cpp:84] Creating Layer loss
I0526 15:44:49.822921 30701 net.cpp:406] loss <- score
I0526 15:44:49.822924 30701 net.cpp:406] loss <- label
I0526 15:44:49.822932 30701 net.cpp:380] loss -> loss
I0526 15:44:49.822942 30701 layer_factory.hpp:77] Creating layer loss
I0526 15:44:49.823765 30701 net.cpp:122] Setting up loss
I0526 15:44:49.823776 30701 net.cpp:129] Top shape: (1)
I0526 15:44:49.823781 30701 net.cpp:132]     with loss weight 1
I0526 15:44:49.823806 30701 net.cpp:137] Memory required for data: 4588258004
I0526 15:44:49.823809 30701 net.cpp:198] loss needs backward computation.
I0526 15:44:49.823817 30701 net.cpp:198] score needs backward computation.
I0526 15:44:49.823828 30701 net.cpp:198] global_pool needs backward computation.
I0526 15:44:49.823832 30701 net.cpp:198] last_relu needs backward computation.
I0526 15:44:49.823835 30701 net.cpp:198] last_scale needs backward computation.
I0526 15:44:49.823838 30701 net.cpp:198] last_bn needs backward computation.
I0526 15:44:49.823842 30701 net.cpp:198] layer_512_3_sum needs backward computation.
I0526 15:44:49.823844 30701 net.cpp:198] layer_512_3_conv3 needs backward computation.
I0526 15:44:49.823848 30701 net.cpp:198] layer_512_3_relu3 needs backward computation.
I0526 15:44:49.823850 30701 net.cpp:198] layer_512_3_scale3 needs backward computation.
I0526 15:44:49.823853 30701 net.cpp:198] layer_512_3_bn3 needs backward computation.
I0526 15:44:49.823856 30701 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0526 15:44:49.823860 30701 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0526 15:44:49.823863 30701 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0526 15:44:49.823866 30701 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0526 15:44:49.823869 30701 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0526 15:44:49.823873 30701 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0526 15:44:49.823875 30701 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0526 15:44:49.823879 30701 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0526 15:44:49.823882 30701 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0526 15:44:49.823885 30701 net.cpp:198] layer_512_2_sum needs backward computation.
I0526 15:44:49.823891 30701 net.cpp:198] layer_512_2_conv3 needs backward computation.
I0526 15:44:49.823894 30701 net.cpp:198] layer_512_2_relu3 needs backward computation.
I0526 15:44:49.823897 30701 net.cpp:198] layer_512_2_scale3 needs backward computation.
I0526 15:44:49.823900 30701 net.cpp:198] layer_512_2_bn3 needs backward computation.
I0526 15:44:49.823904 30701 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0526 15:44:49.823907 30701 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0526 15:44:49.823910 30701 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0526 15:44:49.823914 30701 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0526 15:44:49.823916 30701 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0526 15:44:49.823920 30701 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0526 15:44:49.823922 30701 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0526 15:44:49.823925 30701 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0526 15:44:49.823930 30701 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0526 15:44:49.823933 30701 net.cpp:198] layer_512_1_sum needs backward computation.
I0526 15:44:49.823937 30701 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0526 15:44:49.823940 30701 net.cpp:198] layer_512_1_conv3 needs backward computation.
I0526 15:44:49.823945 30701 net.cpp:198] layer_512_1_relu3 needs backward computation.
I0526 15:44:49.823951 30701 net.cpp:198] layer_512_1_scale3 needs backward computation.
I0526 15:44:49.823956 30701 net.cpp:198] layer_512_1_bn3 needs backward computation.
I0526 15:44:49.823958 30701 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0526 15:44:49.823962 30701 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0526 15:44:49.823966 30701 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0526 15:44:49.823968 30701 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0526 15:44:49.823971 30701 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0526 15:44:49.823976 30701 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0526 15:44:49.823979 30701 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0526 15:44:49.823982 30701 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0526 15:44:49.823985 30701 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0526 15:44:49.823995 30701 net.cpp:198] layer_256_6_sum needs backward computation.
I0526 15:44:49.824000 30701 net.cpp:198] layer_256_6_conv3 needs backward computation.
I0526 15:44:49.824005 30701 net.cpp:198] layer_256_6_relu3 needs backward computation.
I0526 15:44:49.824012 30701 net.cpp:198] layer_256_6_scale3 needs backward computation.
I0526 15:44:49.824014 30701 net.cpp:198] layer_256_6_bn3 needs backward computation.
I0526 15:44:49.824018 30701 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0526 15:44:49.824021 30701 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0526 15:44:49.824024 30701 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0526 15:44:49.824028 30701 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0526 15:44:49.824030 30701 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0526 15:44:49.824034 30701 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0526 15:44:49.824038 30701 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0526 15:44:49.824040 30701 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0526 15:44:49.824044 30701 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0526 15:44:49.824048 30701 net.cpp:198] layer_256_5_sum needs backward computation.
I0526 15:44:49.824051 30701 net.cpp:198] layer_256_5_conv3 needs backward computation.
I0526 15:44:49.824055 30701 net.cpp:198] layer_256_5_relu3 needs backward computation.
I0526 15:44:49.824059 30701 net.cpp:198] layer_256_5_scale3 needs backward computation.
I0526 15:44:49.824061 30701 net.cpp:198] layer_256_5_bn3 needs backward computation.
I0526 15:44:49.824064 30701 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0526 15:44:49.824067 30701 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0526 15:44:49.824071 30701 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0526 15:44:49.824074 30701 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0526 15:44:49.824077 30701 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0526 15:44:49.824080 30701 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0526 15:44:49.824084 30701 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0526 15:44:49.824087 30701 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0526 15:44:49.824090 30701 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0526 15:44:49.824093 30701 net.cpp:198] layer_256_4_sum needs backward computation.
I0526 15:44:49.824097 30701 net.cpp:198] layer_256_4_conv3 needs backward computation.
I0526 15:44:49.824101 30701 net.cpp:198] layer_256_4_relu3 needs backward computation.
I0526 15:44:49.824105 30701 net.cpp:198] layer_256_4_scale3 needs backward computation.
I0526 15:44:49.824107 30701 net.cpp:198] layer_256_4_bn3 needs backward computation.
I0526 15:44:49.824110 30701 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0526 15:44:49.824115 30701 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0526 15:44:49.824117 30701 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0526 15:44:49.824120 30701 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0526 15:44:49.824123 30701 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0526 15:44:49.824126 30701 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0526 15:44:49.824131 30701 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0526 15:44:49.824132 30701 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0526 15:44:49.824136 30701 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0526 15:44:49.824139 30701 net.cpp:198] layer_256_3_sum needs backward computation.
I0526 15:44:49.824143 30701 net.cpp:198] layer_256_3_conv3 needs backward computation.
I0526 15:44:49.824148 30701 net.cpp:198] layer_256_3_relu3 needs backward computation.
I0526 15:44:49.824151 30701 net.cpp:198] layer_256_3_scale3 needs backward computation.
I0526 15:44:49.824162 30701 net.cpp:198] layer_256_3_bn3 needs backward computation.
I0526 15:44:49.824164 30701 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0526 15:44:49.824168 30701 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0526 15:44:49.824172 30701 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0526 15:44:49.824174 30701 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0526 15:44:49.824177 30701 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0526 15:44:49.824182 30701 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0526 15:44:49.824184 30701 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0526 15:44:49.824187 30701 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0526 15:44:49.824190 30701 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0526 15:44:49.824194 30701 net.cpp:198] layer_256_2_sum needs backward computation.
I0526 15:44:49.824198 30701 net.cpp:198] layer_256_2_conv3 needs backward computation.
I0526 15:44:49.824201 30701 net.cpp:198] layer_256_2_relu3 needs backward computation.
I0526 15:44:49.824204 30701 net.cpp:198] layer_256_2_scale3 needs backward computation.
I0526 15:44:49.824208 30701 net.cpp:198] layer_256_2_bn3 needs backward computation.
I0526 15:44:49.824210 30701 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0526 15:44:49.824213 30701 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0526 15:44:49.824216 30701 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0526 15:44:49.824219 30701 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0526 15:44:49.824223 30701 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0526 15:44:49.824225 30701 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0526 15:44:49.824229 30701 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0526 15:44:49.824231 30701 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0526 15:44:49.824235 30701 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0526 15:44:49.824239 30701 net.cpp:198] layer_256_1_sum needs backward computation.
I0526 15:44:49.824242 30701 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0526 15:44:49.824245 30701 net.cpp:198] layer_256_1_conv3 needs backward computation.
I0526 15:44:49.824249 30701 net.cpp:198] layer_256_1_relu3 needs backward computation.
I0526 15:44:49.824254 30701 net.cpp:198] layer_256_1_scale3 needs backward computation.
I0526 15:44:49.824256 30701 net.cpp:198] layer_256_1_bn3 needs backward computation.
I0526 15:44:49.824259 30701 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0526 15:44:49.824264 30701 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0526 15:44:49.824266 30701 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0526 15:44:49.824270 30701 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0526 15:44:49.824272 30701 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0526 15:44:49.824276 30701 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0526 15:44:49.824280 30701 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0526 15:44:49.824283 30701 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0526 15:44:49.824286 30701 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0526 15:44:49.824290 30701 net.cpp:198] layer_128_4_sum needs backward computation.
I0526 15:44:49.824293 30701 net.cpp:198] layer_128_4_conv3 needs backward computation.
I0526 15:44:49.824296 30701 net.cpp:198] layer_128_4_relu3 needs backward computation.
I0526 15:44:49.824300 30701 net.cpp:198] layer_128_4_scale3 needs backward computation.
I0526 15:44:49.824302 30701 net.cpp:198] layer_128_4_bn3 needs backward computation.
I0526 15:44:49.824306 30701 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0526 15:44:49.824308 30701 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0526 15:44:49.824311 30701 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0526 15:44:49.824321 30701 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0526 15:44:49.824323 30701 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0526 15:44:49.824326 30701 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0526 15:44:49.824331 30701 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0526 15:44:49.824333 30701 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0526 15:44:49.824337 30701 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0526 15:44:49.824340 30701 net.cpp:198] layer_128_3_sum needs backward computation.
I0526 15:44:49.824344 30701 net.cpp:198] layer_128_3_conv3 needs backward computation.
I0526 15:44:49.824347 30701 net.cpp:198] layer_128_3_relu3 needs backward computation.
I0526 15:44:49.824350 30701 net.cpp:198] layer_128_3_scale3 needs backward computation.
I0526 15:44:49.824353 30701 net.cpp:198] layer_128_3_bn3 needs backward computation.
I0526 15:44:49.824357 30701 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0526 15:44:49.824359 30701 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0526 15:44:49.824362 30701 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0526 15:44:49.824365 30701 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0526 15:44:49.824368 30701 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0526 15:44:49.824371 30701 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0526 15:44:49.824375 30701 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0526 15:44:49.824378 30701 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0526 15:44:49.824381 30701 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0526 15:44:49.824384 30701 net.cpp:198] layer_128_2_sum needs backward computation.
I0526 15:44:49.824388 30701 net.cpp:198] layer_128_2_conv3 needs backward computation.
I0526 15:44:49.824393 30701 net.cpp:198] layer_128_2_relu3 needs backward computation.
I0526 15:44:49.824396 30701 net.cpp:198] layer_128_2_scale3 needs backward computation.
I0526 15:44:49.824399 30701 net.cpp:198] layer_128_2_bn3 needs backward computation.
I0526 15:44:49.824403 30701 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0526 15:44:49.824406 30701 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0526 15:44:49.824409 30701 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0526 15:44:49.824412 30701 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0526 15:44:49.824415 30701 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0526 15:44:49.824419 30701 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0526 15:44:49.824421 30701 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0526 15:44:49.824425 30701 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0526 15:44:49.824429 30701 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0526 15:44:49.824432 30701 net.cpp:198] layer_128_1_sum needs backward computation.
I0526 15:44:49.824435 30701 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0526 15:44:49.824440 30701 net.cpp:198] layer_128_1_conv3 needs backward computation.
I0526 15:44:49.824442 30701 net.cpp:198] layer_128_1_relu3 needs backward computation.
I0526 15:44:49.824445 30701 net.cpp:198] layer_128_1_scale3 needs backward computation.
I0526 15:44:49.824448 30701 net.cpp:198] layer_128_1_bn3 needs backward computation.
I0526 15:44:49.824451 30701 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0526 15:44:49.824455 30701 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0526 15:44:49.824458 30701 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0526 15:44:49.824461 30701 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0526 15:44:49.824465 30701 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0526 15:44:49.824467 30701 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0526 15:44:49.824476 30701 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0526 15:44:49.824481 30701 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0526 15:44:49.824483 30701 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0526 15:44:49.824486 30701 net.cpp:198] layer_64_3_sum needs backward computation.
I0526 15:44:49.824491 30701 net.cpp:198] layer_64_3_conv3 needs backward computation.
I0526 15:44:49.824494 30701 net.cpp:198] layer_64_3_relu3 needs backward computation.
I0526 15:44:49.824497 30701 net.cpp:198] layer_64_3_scale3 needs backward computation.
I0526 15:44:49.824501 30701 net.cpp:198] layer_64_3_bn3 needs backward computation.
I0526 15:44:49.824504 30701 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0526 15:44:49.824507 30701 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0526 15:44:49.824512 30701 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0526 15:44:49.824515 30701 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0526 15:44:49.824518 30701 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0526 15:44:49.824522 30701 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0526 15:44:49.824525 30701 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0526 15:44:49.824528 30701 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0526 15:44:49.824532 30701 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0526 15:44:49.824535 30701 net.cpp:198] layer_64_2_sum needs backward computation.
I0526 15:44:49.824539 30701 net.cpp:198] layer_64_2_conv3 needs backward computation.
I0526 15:44:49.824542 30701 net.cpp:198] layer_64_2_relu3 needs backward computation.
I0526 15:44:49.824546 30701 net.cpp:198] layer_64_2_scale3 needs backward computation.
I0526 15:44:49.824549 30701 net.cpp:198] layer_64_2_bn3 needs backward computation.
I0526 15:44:49.824553 30701 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0526 15:44:49.824555 30701 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0526 15:44:49.824559 30701 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0526 15:44:49.824563 30701 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0526 15:44:49.824565 30701 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0526 15:44:49.824568 30701 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0526 15:44:49.824571 30701 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0526 15:44:49.824574 30701 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0526 15:44:49.824579 30701 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0526 15:44:49.824581 30701 net.cpp:198] layer_64_1_sum needs backward computation.
I0526 15:44:49.824585 30701 net.cpp:198] layer_64_1_conv_expand needs backward computation.
I0526 15:44:49.824589 30701 net.cpp:198] layer_64_1_conv3 needs backward computation.
I0526 15:44:49.824592 30701 net.cpp:198] layer_64_1_relu3 needs backward computation.
I0526 15:44:49.824595 30701 net.cpp:198] layer_64_1_scale3 needs backward computation.
I0526 15:44:49.824599 30701 net.cpp:198] layer_64_1_bn3 needs backward computation.
I0526 15:44:49.824602 30701 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0526 15:44:49.824605 30701 net.cpp:198] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0526 15:44:49.824609 30701 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0526 15:44:49.824612 30701 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0526 15:44:49.824615 30701 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0526 15:44:49.824618 30701 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0526 15:44:49.824621 30701 net.cpp:198] conv1_pool needs backward computation.
I0526 15:44:49.824625 30701 net.cpp:198] conv1_relu needs backward computation.
I0526 15:44:49.824628 30701 net.cpp:198] conv1_scale needs backward computation.
I0526 15:44:49.824631 30701 net.cpp:198] conv1_bn needs backward computation.
I0526 15:44:49.824643 30701 net.cpp:198] conv1 needs backward computation.
I0526 15:44:49.824647 30701 net.cpp:198] data_scale needs backward computation.
I0526 15:44:49.824651 30701 net.cpp:200] data_bn does not need backward computation.
I0526 15:44:49.824654 30701 net.cpp:200] data does not need backward computation.
I0526 15:44:49.824657 30701 net.cpp:242] This network produces output loss
I0526 15:44:49.824769 30701 net.cpp:255] Network initialization done.
I0526 15:44:49.826468 30701 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 50_train_val_test_fold_is_0.prototxt
I0526 15:44:49.826484 30701 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0526 15:44:49.826491 30701 solver.cpp:172] Creating test net (#0) specified by net file: 50_train_val_test_fold_is_0.prototxt
I0526 15:44:49.826637 30701 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0526 15:44:49.827841 30701 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-50"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto"
  }
  data_param {
    source: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_val_lmdb"
    batch_size: 5
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn3"
  type: "BatchNorm"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale3"
  type: "Scale"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu3"
  type: "ReLU"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
}
layer {
  name: "layer_256_1_conv3"
  type: "Convolution"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv3"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn3"
  type: "BatchNorm"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale3"
  type: "Scale"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu3"
  type: "ReLU"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
}
layer {
  name: "layer_256_2_conv3"
  type: "Convolution"
  bottom: "layer_256_2_conv2
I0526 15:44:49.828477 30701 layer_factory.hpp:77] Creating layer data
I0526 15:44:49.828537 30701 db_lmdb.cpp:35] Opened lmdb /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/age_val_lmdb
I0526 15:44:49.828554 30701 net.cpp:84] Creating Layer data
I0526 15:44:49.828560 30701 net.cpp:380] data -> data
I0526 15:44:49.828568 30701 net.cpp:380] data -> label
I0526 15:44:49.828577 30701 data_transformer.cpp:25] Loading mean file from: /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto
I0526 15:44:49.830754 30701 data_layer.cpp:45] output data size: 5,3,224,224
I0526 15:44:49.839491 30701 net.cpp:122] Setting up data
I0526 15:44:49.839524 30701 net.cpp:129] Top shape: 5 3 224 224 (752640)
I0526 15:44:49.839529 30701 net.cpp:129] Top shape: 5 (5)
I0526 15:44:49.839531 30701 net.cpp:137] Memory required for data: 3010580
I0526 15:44:49.839539 30701 layer_factory.hpp:77] Creating layer label_data_1_split
I0526 15:44:49.839551 30701 net.cpp:84] Creating Layer label_data_1_split
I0526 15:44:49.839556 30701 net.cpp:406] label_data_1_split <- label
I0526 15:44:49.839565 30701 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0526 15:44:49.839577 30701 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0526 15:44:49.839663 30701 net.cpp:122] Setting up label_data_1_split
I0526 15:44:49.839671 30701 net.cpp:129] Top shape: 5 (5)
I0526 15:44:49.839676 30701 net.cpp:129] Top shape: 5 (5)
I0526 15:44:49.839679 30701 net.cpp:137] Memory required for data: 3010620
I0526 15:44:49.839682 30701 layer_factory.hpp:77] Creating layer data_bn
I0526 15:44:49.839691 30701 net.cpp:84] Creating Layer data_bn
I0526 15:44:49.839695 30701 net.cpp:406] data_bn <- data
I0526 15:44:49.839700 30701 net.cpp:380] data_bn -> data_bn
I0526 15:44:49.840006 30701 net.cpp:122] Setting up data_bn
I0526 15:44:49.840016 30701 net.cpp:129] Top shape: 5 3 224 224 (752640)
I0526 15:44:49.840020 30701 net.cpp:137] Memory required for data: 6021180
I0526 15:44:49.840034 30701 layer_factory.hpp:77] Creating layer data_scale
I0526 15:44:49.840041 30701 net.cpp:84] Creating Layer data_scale
I0526 15:44:49.840045 30701 net.cpp:406] data_scale <- data_bn
I0526 15:44:49.840051 30701 net.cpp:367] data_scale -> data_bn (in-place)
I0526 15:44:49.840098 30701 layer_factory.hpp:77] Creating layer data_scale
I0526 15:44:49.840293 30701 net.cpp:122] Setting up data_scale
I0526 15:44:49.840302 30701 net.cpp:129] Top shape: 5 3 224 224 (752640)
I0526 15:44:49.840306 30701 net.cpp:137] Memory required for data: 9031740
I0526 15:44:49.840324 30701 layer_factory.hpp:77] Creating layer conv1
I0526 15:44:49.840337 30701 net.cpp:84] Creating Layer conv1
I0526 15:44:49.840342 30701 net.cpp:406] conv1 <- data_bn
I0526 15:44:49.840348 30701 net.cpp:380] conv1 -> conv1
I0526 15:44:49.841768 30701 net.cpp:122] Setting up conv1
I0526 15:44:49.841783 30701 net.cpp:129] Top shape: 5 64 112 112 (4014080)
I0526 15:44:49.841785 30701 net.cpp:137] Memory required for data: 25088060
I0526 15:44:49.841792 30701 layer_factory.hpp:77] Creating layer conv1_bn
I0526 15:44:49.841799 30701 net.cpp:84] Creating Layer conv1_bn
I0526 15:44:49.841804 30701 net.cpp:406] conv1_bn <- conv1
I0526 15:44:49.841809 30701 net.cpp:367] conv1_bn -> conv1 (in-place)
I0526 15:44:49.842021 30701 net.cpp:122] Setting up conv1_bn
I0526 15:44:49.842031 30701 net.cpp:129] Top shape: 5 64 112 112 (4014080)
I0526 15:44:49.842034 30701 net.cpp:137] Memory required for data: 41144380
I0526 15:44:49.842044 30701 layer_factory.hpp:77] Creating layer conv1_scale
I0526 15:44:49.842051 30701 net.cpp:84] Creating Layer conv1_scale
I0526 15:44:49.842056 30701 net.cpp:406] conv1_scale <- conv1
I0526 15:44:49.842061 30701 net.cpp:367] conv1_scale -> conv1 (in-place)
I0526 15:44:49.842105 30701 layer_factory.hpp:77] Creating layer conv1_scale
I0526 15:44:49.842242 30701 net.cpp:122] Setting up conv1_scale
I0526 15:44:49.842252 30701 net.cpp:129] Top shape: 5 64 112 112 (4014080)
I0526 15:44:49.842257 30701 net.cpp:137] Memory required for data: 57200700
I0526 15:44:49.842262 30701 layer_factory.hpp:77] Creating layer conv1_relu
I0526 15:44:49.842268 30701 net.cpp:84] Creating Layer conv1_relu
I0526 15:44:49.842272 30701 net.cpp:406] conv1_relu <- conv1
I0526 15:44:49.842278 30701 net.cpp:367] conv1_relu -> conv1 (in-place)
I0526 15:44:49.843088 30701 net.cpp:122] Setting up conv1_relu
I0526 15:44:49.843101 30701 net.cpp:129] Top shape: 5 64 112 112 (4014080)
I0526 15:44:49.843104 30701 net.cpp:137] Memory required for data: 73257020
I0526 15:44:49.843107 30701 layer_factory.hpp:77] Creating layer conv1_pool
I0526 15:44:49.843116 30701 net.cpp:84] Creating Layer conv1_pool
I0526 15:44:49.843120 30701 net.cpp:406] conv1_pool <- conv1
I0526 15:44:49.843127 30701 net.cpp:380] conv1_pool -> conv1_pool
I0526 15:44:49.843176 30701 net.cpp:122] Setting up conv1_pool
I0526 15:44:49.843184 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.843189 30701 net.cpp:137] Memory required for data: 77271100
I0526 15:44:49.843191 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0526 15:44:49.843200 30701 net.cpp:84] Creating Layer layer_64_1_conv1
I0526 15:44:49.843204 30701 net.cpp:406] layer_64_1_conv1 <- conv1_pool
I0526 15:44:49.843211 30701 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0526 15:44:49.845000 30701 net.cpp:122] Setting up layer_64_1_conv1
I0526 15:44:49.845016 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845019 30701 net.cpp:137] Memory required for data: 81285180
I0526 15:44:49.845024 30701 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0526 15:44:49.845032 30701 net.cpp:84] Creating Layer layer_64_1_bn2
I0526 15:44:49.845037 30701 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0526 15:44:49.845042 30701 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.845264 30701 net.cpp:122] Setting up layer_64_1_bn2
I0526 15:44:49.845273 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845278 30701 net.cpp:137] Memory required for data: 85299260
I0526 15:44:49.845285 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0526 15:44:49.845293 30701 net.cpp:84] Creating Layer layer_64_1_scale2
I0526 15:44:49.845296 30701 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0526 15:44:49.845301 30701 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.845348 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0526 15:44:49.845484 30701 net.cpp:122] Setting up layer_64_1_scale2
I0526 15:44:49.845492 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845496 30701 net.cpp:137] Memory required for data: 89313340
I0526 15:44:49.845505 30701 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0526 15:44:49.845522 30701 net.cpp:84] Creating Layer layer_64_1_relu2
I0526 15:44:49.845526 30701 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0526 15:44:49.845532 30701 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0526 15:44:49.845693 30701 net.cpp:122] Setting up layer_64_1_relu2
I0526 15:44:49.845703 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845707 30701 net.cpp:137] Memory required for data: 93327420
I0526 15:44:49.845710 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.845716 30701 net.cpp:84] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.845721 30701 net.cpp:406] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0526 15:44:49.845726 30701 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0526 15:44:49.845734 30701 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0526 15:44:49.845778 30701 net.cpp:122] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0526 15:44:49.845787 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845791 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.845794 30701 net.cpp:137] Memory required for data: 101355580
I0526 15:44:49.845798 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0526 15:44:49.845806 30701 net.cpp:84] Creating Layer layer_64_1_conv2
I0526 15:44:49.845811 30701 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0526 15:44:49.845816 30701 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0526 15:44:49.847913 30701 net.cpp:122] Setting up layer_64_1_conv2
I0526 15:44:49.847926 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.847931 30701 net.cpp:137] Memory required for data: 105369660
I0526 15:44:49.847936 30701 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0526 15:44:49.847944 30701 net.cpp:84] Creating Layer layer_64_1_bn3
I0526 15:44:49.847959 30701 net.cpp:406] layer_64_1_bn3 <- layer_64_1_conv2
I0526 15:44:49.847966 30701 net.cpp:367] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.848199 30701 net.cpp:122] Setting up layer_64_1_bn3
I0526 15:44:49.848208 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.848212 30701 net.cpp:137] Memory required for data: 109383740
I0526 15:44:49.848220 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0526 15:44:49.848230 30701 net.cpp:84] Creating Layer layer_64_1_scale3
I0526 15:44:49.848234 30701 net.cpp:406] layer_64_1_scale3 <- layer_64_1_conv2
I0526 15:44:49.848240 30701 net.cpp:367] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.848289 30701 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0526 15:44:49.848423 30701 net.cpp:122] Setting up layer_64_1_scale3
I0526 15:44:49.848431 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.848434 30701 net.cpp:137] Memory required for data: 113397820
I0526 15:44:49.848440 30701 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0526 15:44:49.848456 30701 net.cpp:84] Creating Layer layer_64_1_relu3
I0526 15:44:49.848460 30701 net.cpp:406] layer_64_1_relu3 <- layer_64_1_conv2
I0526 15:44:49.848465 30701 net.cpp:367] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0526 15:44:49.848623 30701 net.cpp:122] Setting up layer_64_1_relu3
I0526 15:44:49.848631 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.848634 30701 net.cpp:137] Memory required for data: 117411900
I0526 15:44:49.848639 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0526 15:44:49.848647 30701 net.cpp:84] Creating Layer layer_64_1_conv3
I0526 15:44:49.848651 30701 net.cpp:406] layer_64_1_conv3 <- layer_64_1_conv2
I0526 15:44:49.848657 30701 net.cpp:380] layer_64_1_conv3 -> layer_64_1_conv3
I0526 15:44:49.850100 30701 net.cpp:122] Setting up layer_64_1_conv3
I0526 15:44:49.850112 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.850116 30701 net.cpp:137] Memory required for data: 133468220
I0526 15:44:49.850122 30701 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0526 15:44:49.850131 30701 net.cpp:84] Creating Layer layer_64_1_conv_expand
I0526 15:44:49.850136 30701 net.cpp:406] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0526 15:44:49.850142 30701 net.cpp:380] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0526 15:44:49.851919 30701 net.cpp:122] Setting up layer_64_1_conv_expand
I0526 15:44:49.851933 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.851936 30701 net.cpp:137] Memory required for data: 149524540
I0526 15:44:49.851943 30701 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0526 15:44:49.851964 30701 net.cpp:84] Creating Layer layer_64_1_sum
I0526 15:44:49.851970 30701 net.cpp:406] layer_64_1_sum <- layer_64_1_conv3
I0526 15:44:49.851975 30701 net.cpp:406] layer_64_1_sum <- layer_64_1_conv_expand
I0526 15:44:49.851980 30701 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0526 15:44:49.852013 30701 net.cpp:122] Setting up layer_64_1_sum
I0526 15:44:49.852021 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852025 30701 net.cpp:137] Memory required for data: 165580860
I0526 15:44:49.852027 30701 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.852033 30701 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.852036 30701 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0526 15:44:49.852041 30701 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0526 15:44:49.852047 30701 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0526 15:44:49.852088 30701 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0526 15:44:49.852097 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852100 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852103 30701 net.cpp:137] Memory required for data: 197693500
I0526 15:44:49.852107 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0526 15:44:49.852113 30701 net.cpp:84] Creating Layer layer_64_2_bn1
I0526 15:44:49.852115 30701 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0526 15:44:49.852120 30701 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0526 15:44:49.852344 30701 net.cpp:122] Setting up layer_64_2_bn1
I0526 15:44:49.852354 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852357 30701 net.cpp:137] Memory required for data: 213749820
I0526 15:44:49.852365 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0526 15:44:49.852372 30701 net.cpp:84] Creating Layer layer_64_2_scale1
I0526 15:44:49.852376 30701 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0526 15:44:49.852381 30701 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0526 15:44:49.852430 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0526 15:44:49.852557 30701 net.cpp:122] Setting up layer_64_2_scale1
I0526 15:44:49.852566 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852581 30701 net.cpp:137] Memory required for data: 229806140
I0526 15:44:49.852587 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0526 15:44:49.852594 30701 net.cpp:84] Creating Layer layer_64_2_relu1
I0526 15:44:49.852598 30701 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0526 15:44:49.852603 30701 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0526 15:44:49.852771 30701 net.cpp:122] Setting up layer_64_2_relu1
I0526 15:44:49.852780 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.852784 30701 net.cpp:137] Memory required for data: 245862460
I0526 15:44:49.852787 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0526 15:44:49.852797 30701 net.cpp:84] Creating Layer layer_64_2_conv1
I0526 15:44:49.852800 30701 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0526 15:44:49.852807 30701 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0526 15:44:49.854766 30701 net.cpp:122] Setting up layer_64_2_conv1
I0526 15:44:49.854779 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.854782 30701 net.cpp:137] Memory required for data: 249876540
I0526 15:44:49.854787 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0526 15:44:49.854794 30701 net.cpp:84] Creating Layer layer_64_2_bn2
I0526 15:44:49.854799 30701 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0526 15:44:49.854804 30701 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.855024 30701 net.cpp:122] Setting up layer_64_2_bn2
I0526 15:44:49.855033 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.855037 30701 net.cpp:137] Memory required for data: 253890620
I0526 15:44:49.855048 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0526 15:44:49.855056 30701 net.cpp:84] Creating Layer layer_64_2_scale2
I0526 15:44:49.855059 30701 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0526 15:44:49.855065 30701 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.855111 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0526 15:44:49.855244 30701 net.cpp:122] Setting up layer_64_2_scale2
I0526 15:44:49.855253 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.855257 30701 net.cpp:137] Memory required for data: 257904700
I0526 15:44:49.855263 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0526 15:44:49.855269 30701 net.cpp:84] Creating Layer layer_64_2_relu2
I0526 15:44:49.855274 30701 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0526 15:44:49.855278 30701 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0526 15:44:49.855479 30701 net.cpp:122] Setting up layer_64_2_relu2
I0526 15:44:49.855489 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.855494 30701 net.cpp:137] Memory required for data: 261918780
I0526 15:44:49.855496 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0526 15:44:49.855505 30701 net.cpp:84] Creating Layer layer_64_2_conv2
I0526 15:44:49.855509 30701 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0526 15:44:49.855515 30701 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0526 15:44:49.857107 30701 net.cpp:122] Setting up layer_64_2_conv2
I0526 15:44:49.857120 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.857125 30701 net.cpp:137] Memory required for data: 265932860
I0526 15:44:49.857130 30701 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0526 15:44:49.857136 30701 net.cpp:84] Creating Layer layer_64_2_bn3
I0526 15:44:49.857141 30701 net.cpp:406] layer_64_2_bn3 <- layer_64_2_conv2
I0526 15:44:49.857146 30701 net.cpp:367] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.857363 30701 net.cpp:122] Setting up layer_64_2_bn3
I0526 15:44:49.857372 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.857376 30701 net.cpp:137] Memory required for data: 269946940
I0526 15:44:49.857383 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0526 15:44:49.857390 30701 net.cpp:84] Creating Layer layer_64_2_scale3
I0526 15:44:49.857394 30701 net.cpp:406] layer_64_2_scale3 <- layer_64_2_conv2
I0526 15:44:49.857410 30701 net.cpp:367] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.857458 30701 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0526 15:44:49.857594 30701 net.cpp:122] Setting up layer_64_2_scale3
I0526 15:44:49.857602 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.857606 30701 net.cpp:137] Memory required for data: 273961020
I0526 15:44:49.857612 30701 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0526 15:44:49.857623 30701 net.cpp:84] Creating Layer layer_64_2_relu3
I0526 15:44:49.857627 30701 net.cpp:406] layer_64_2_relu3 <- layer_64_2_conv2
I0526 15:44:49.857632 30701 net.cpp:367] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0526 15:44:49.857790 30701 net.cpp:122] Setting up layer_64_2_relu3
I0526 15:44:49.857800 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.857803 30701 net.cpp:137] Memory required for data: 277975100
I0526 15:44:49.857807 30701 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0526 15:44:49.857815 30701 net.cpp:84] Creating Layer layer_64_2_conv3
I0526 15:44:49.857820 30701 net.cpp:406] layer_64_2_conv3 <- layer_64_2_conv2
I0526 15:44:49.857825 30701 net.cpp:380] layer_64_2_conv3 -> layer_64_2_conv3
I0526 15:44:49.859227 30701 net.cpp:122] Setting up layer_64_2_conv3
I0526 15:44:49.859241 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859246 30701 net.cpp:137] Memory required for data: 294031420
I0526 15:44:49.859251 30701 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0526 15:44:49.859256 30701 net.cpp:84] Creating Layer layer_64_2_sum
I0526 15:44:49.859261 30701 net.cpp:406] layer_64_2_sum <- layer_64_2_conv3
I0526 15:44:49.859264 30701 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0526 15:44:49.859269 30701 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0526 15:44:49.859304 30701 net.cpp:122] Setting up layer_64_2_sum
I0526 15:44:49.859314 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859318 30701 net.cpp:137] Memory required for data: 310087740
I0526 15:44:49.859320 30701 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.859325 30701 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.859329 30701 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0526 15:44:49.859334 30701 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0526 15:44:49.859340 30701 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0526 15:44:49.859385 30701 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0526 15:44:49.859393 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859397 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859400 30701 net.cpp:137] Memory required for data: 342200380
I0526 15:44:49.859403 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0526 15:44:49.859410 30701 net.cpp:84] Creating Layer layer_64_3_bn1
I0526 15:44:49.859413 30701 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0526 15:44:49.859419 30701 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0526 15:44:49.859645 30701 net.cpp:122] Setting up layer_64_3_bn1
I0526 15:44:49.859654 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859658 30701 net.cpp:137] Memory required for data: 358256700
I0526 15:44:49.859664 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0526 15:44:49.859671 30701 net.cpp:84] Creating Layer layer_64_3_scale1
I0526 15:44:49.859675 30701 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0526 15:44:49.859680 30701 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0526 15:44:49.859728 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0526 15:44:49.859863 30701 net.cpp:122] Setting up layer_64_3_scale1
I0526 15:44:49.859872 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.859875 30701 net.cpp:137] Memory required for data: 374313020
I0526 15:44:49.859889 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0526 15:44:49.859896 30701 net.cpp:84] Creating Layer layer_64_3_relu1
I0526 15:44:49.859899 30701 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0526 15:44:49.859905 30701 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0526 15:44:49.860618 30701 net.cpp:122] Setting up layer_64_3_relu1
I0526 15:44:49.860631 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.860635 30701 net.cpp:137] Memory required for data: 390369340
I0526 15:44:49.860638 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0526 15:44:49.860647 30701 net.cpp:84] Creating Layer layer_64_3_conv1
I0526 15:44:49.860652 30701 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0526 15:44:49.860658 30701 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0526 15:44:49.862076 30701 net.cpp:122] Setting up layer_64_3_conv1
I0526 15:44:49.862089 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.862092 30701 net.cpp:137] Memory required for data: 394383420
I0526 15:44:49.862097 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0526 15:44:49.862105 30701 net.cpp:84] Creating Layer layer_64_3_bn2
I0526 15:44:49.862109 30701 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0526 15:44:49.862116 30701 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.862392 30701 net.cpp:122] Setting up layer_64_3_bn2
I0526 15:44:49.862402 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.862406 30701 net.cpp:137] Memory required for data: 398397500
I0526 15:44:49.862413 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0526 15:44:49.862422 30701 net.cpp:84] Creating Layer layer_64_3_scale2
I0526 15:44:49.862426 30701 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0526 15:44:49.862432 30701 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.862483 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0526 15:44:49.862627 30701 net.cpp:122] Setting up layer_64_3_scale2
I0526 15:44:49.862637 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.862640 30701 net.cpp:137] Memory required for data: 402411580
I0526 15:44:49.862645 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0526 15:44:49.862653 30701 net.cpp:84] Creating Layer layer_64_3_relu2
I0526 15:44:49.862658 30701 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0526 15:44:49.862663 30701 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0526 15:44:49.862834 30701 net.cpp:122] Setting up layer_64_3_relu2
I0526 15:44:49.862843 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.862846 30701 net.cpp:137] Memory required for data: 406425660
I0526 15:44:49.862850 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0526 15:44:49.862859 30701 net.cpp:84] Creating Layer layer_64_3_conv2
I0526 15:44:49.862864 30701 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0526 15:44:49.862871 30701 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0526 15:44:49.864559 30701 net.cpp:122] Setting up layer_64_3_conv2
I0526 15:44:49.864573 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.864575 30701 net.cpp:137] Memory required for data: 410439740
I0526 15:44:49.864580 30701 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0526 15:44:49.864589 30701 net.cpp:84] Creating Layer layer_64_3_bn3
I0526 15:44:49.864594 30701 net.cpp:406] layer_64_3_bn3 <- layer_64_3_conv2
I0526 15:44:49.864599 30701 net.cpp:367] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.864831 30701 net.cpp:122] Setting up layer_64_3_bn3
I0526 15:44:49.864840 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.864845 30701 net.cpp:137] Memory required for data: 414453820
I0526 15:44:49.864851 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0526 15:44:49.864859 30701 net.cpp:84] Creating Layer layer_64_3_scale3
I0526 15:44:49.864864 30701 net.cpp:406] layer_64_3_scale3 <- layer_64_3_conv2
I0526 15:44:49.864879 30701 net.cpp:367] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.864933 30701 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0526 15:44:49.865078 30701 net.cpp:122] Setting up layer_64_3_scale3
I0526 15:44:49.865087 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.865092 30701 net.cpp:137] Memory required for data: 418467900
I0526 15:44:49.865097 30701 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0526 15:44:49.865103 30701 net.cpp:84] Creating Layer layer_64_3_relu3
I0526 15:44:49.865108 30701 net.cpp:406] layer_64_3_relu3 <- layer_64_3_conv2
I0526 15:44:49.865113 30701 net.cpp:367] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0526 15:44:49.865279 30701 net.cpp:122] Setting up layer_64_3_relu3
I0526 15:44:49.865290 30701 net.cpp:129] Top shape: 5 64 56 56 (1003520)
I0526 15:44:49.865294 30701 net.cpp:137] Memory required for data: 422481980
I0526 15:44:49.865298 30701 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0526 15:44:49.865308 30701 net.cpp:84] Creating Layer layer_64_3_conv3
I0526 15:44:49.865311 30701 net.cpp:406] layer_64_3_conv3 <- layer_64_3_conv2
I0526 15:44:49.865317 30701 net.cpp:380] layer_64_3_conv3 -> layer_64_3_conv3
I0526 15:44:49.866741 30701 net.cpp:122] Setting up layer_64_3_conv3
I0526 15:44:49.866753 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.866758 30701 net.cpp:137] Memory required for data: 438538300
I0526 15:44:49.866763 30701 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0526 15:44:49.866771 30701 net.cpp:84] Creating Layer layer_64_3_sum
I0526 15:44:49.866775 30701 net.cpp:406] layer_64_3_sum <- layer_64_3_conv3
I0526 15:44:49.866780 30701 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0526 15:44:49.866786 30701 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0526 15:44:49.866818 30701 net.cpp:122] Setting up layer_64_3_sum
I0526 15:44:49.866827 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.866832 30701 net.cpp:137] Memory required for data: 454594620
I0526 15:44:49.866834 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0526 15:44:49.866842 30701 net.cpp:84] Creating Layer layer_128_1_bn1
I0526 15:44:49.866845 30701 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0526 15:44:49.866850 30701 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0526 15:44:49.867082 30701 net.cpp:122] Setting up layer_128_1_bn1
I0526 15:44:49.867091 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.867095 30701 net.cpp:137] Memory required for data: 470650940
I0526 15:44:49.867110 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0526 15:44:49.867120 30701 net.cpp:84] Creating Layer layer_128_1_scale1
I0526 15:44:49.867123 30701 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0526 15:44:49.867128 30701 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0526 15:44:49.867182 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0526 15:44:49.867318 30701 net.cpp:122] Setting up layer_128_1_scale1
I0526 15:44:49.867327 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.867331 30701 net.cpp:137] Memory required for data: 486707260
I0526 15:44:49.867336 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0526 15:44:49.867343 30701 net.cpp:84] Creating Layer layer_128_1_relu1
I0526 15:44:49.867347 30701 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0526 15:44:49.867353 30701 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0526 15:44:49.867516 30701 net.cpp:122] Setting up layer_128_1_relu1
I0526 15:44:49.867527 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.867530 30701 net.cpp:137] Memory required for data: 502763580
I0526 15:44:49.867533 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.867539 30701 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.867543 30701 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0526 15:44:49.867558 30701 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0526 15:44:49.867566 30701 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0526 15:44:49.867615 30701 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0526 15:44:49.867624 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.867629 30701 net.cpp:129] Top shape: 5 256 56 56 (4014080)
I0526 15:44:49.867631 30701 net.cpp:137] Memory required for data: 534876220
I0526 15:44:49.867635 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0526 15:44:49.867643 30701 net.cpp:84] Creating Layer layer_128_1_conv1
I0526 15:44:49.867648 30701 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0526 15:44:49.867655 30701 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0526 15:44:49.869256 30701 net.cpp:122] Setting up layer_128_1_conv1
I0526 15:44:49.869269 30701 net.cpp:129] Top shape: 5 128 56 56 (2007040)
I0526 15:44:49.869273 30701 net.cpp:137] Memory required for data: 542904380
I0526 15:44:49.869278 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0526 15:44:49.869285 30701 net.cpp:84] Creating Layer layer_128_1_bn2
I0526 15:44:49.869289 30701 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0526 15:44:49.869297 30701 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.869524 30701 net.cpp:122] Setting up layer_128_1_bn2
I0526 15:44:49.869532 30701 net.cpp:129] Top shape: 5 128 56 56 (2007040)
I0526 15:44:49.869536 30701 net.cpp:137] Memory required for data: 550932540
I0526 15:44:49.869544 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0526 15:44:49.869550 30701 net.cpp:84] Creating Layer layer_128_1_scale2
I0526 15:44:49.869554 30701 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0526 15:44:49.869561 30701 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.869607 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0526 15:44:49.869748 30701 net.cpp:122] Setting up layer_128_1_scale2
I0526 15:44:49.869757 30701 net.cpp:129] Top shape: 5 128 56 56 (2007040)
I0526 15:44:49.869760 30701 net.cpp:137] Memory required for data: 558960700
I0526 15:44:49.869766 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0526 15:44:49.869773 30701 net.cpp:84] Creating Layer layer_128_1_relu2
I0526 15:44:49.869777 30701 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0526 15:44:49.869781 30701 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0526 15:44:49.869948 30701 net.cpp:122] Setting up layer_128_1_relu2
I0526 15:44:49.869957 30701 net.cpp:129] Top shape: 5 128 56 56 (2007040)
I0526 15:44:49.869961 30701 net.cpp:137] Memory required for data: 566988860
I0526 15:44:49.869966 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0526 15:44:49.869976 30701 net.cpp:84] Creating Layer layer_128_1_conv2
I0526 15:44:49.869979 30701 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0526 15:44:49.869985 30701 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0526 15:44:49.872742 30701 net.cpp:122] Setting up layer_128_1_conv2
I0526 15:44:49.872757 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.872761 30701 net.cpp:137] Memory required for data: 568995900
I0526 15:44:49.872767 30701 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0526 15:44:49.872774 30701 net.cpp:84] Creating Layer layer_128_1_bn3
I0526 15:44:49.872778 30701 net.cpp:406] layer_128_1_bn3 <- layer_128_1_conv2
I0526 15:44:49.872786 30701 net.cpp:367] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.873006 30701 net.cpp:122] Setting up layer_128_1_bn3
I0526 15:44:49.873015 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.873019 30701 net.cpp:137] Memory required for data: 571002940
I0526 15:44:49.873026 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0526 15:44:49.873034 30701 net.cpp:84] Creating Layer layer_128_1_scale3
I0526 15:44:49.873047 30701 net.cpp:406] layer_128_1_scale3 <- layer_128_1_conv2
I0526 15:44:49.873054 30701 net.cpp:367] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.873102 30701 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0526 15:44:49.873237 30701 net.cpp:122] Setting up layer_128_1_scale3
I0526 15:44:49.873246 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.873250 30701 net.cpp:137] Memory required for data: 573009980
I0526 15:44:49.873255 30701 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0526 15:44:49.873261 30701 net.cpp:84] Creating Layer layer_128_1_relu3
I0526 15:44:49.873265 30701 net.cpp:406] layer_128_1_relu3 <- layer_128_1_conv2
I0526 15:44:49.873272 30701 net.cpp:367] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0526 15:44:49.873437 30701 net.cpp:122] Setting up layer_128_1_relu3
I0526 15:44:49.873448 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.873452 30701 net.cpp:137] Memory required for data: 575017020
I0526 15:44:49.873456 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0526 15:44:49.873466 30701 net.cpp:84] Creating Layer layer_128_1_conv3
I0526 15:44:49.873469 30701 net.cpp:406] layer_128_1_conv3 <- layer_128_1_conv2
I0526 15:44:49.873476 30701 net.cpp:380] layer_128_1_conv3 -> layer_128_1_conv3
I0526 15:44:49.876183 30701 net.cpp:122] Setting up layer_128_1_conv3
I0526 15:44:49.876199 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.876202 30701 net.cpp:137] Memory required for data: 583045180
I0526 15:44:49.876209 30701 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0526 15:44:49.876219 30701 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0526 15:44:49.876224 30701 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0526 15:44:49.876232 30701 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0526 15:44:49.878813 30701 net.cpp:122] Setting up layer_128_1_conv_expand
I0526 15:44:49.878824 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.878829 30701 net.cpp:137] Memory required for data: 591073340
I0526 15:44:49.878834 30701 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0526 15:44:49.878840 30701 net.cpp:84] Creating Layer layer_128_1_sum
I0526 15:44:49.878846 30701 net.cpp:406] layer_128_1_sum <- layer_128_1_conv3
I0526 15:44:49.878851 30701 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0526 15:44:49.878856 30701 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0526 15:44:49.878891 30701 net.cpp:122] Setting up layer_128_1_sum
I0526 15:44:49.878900 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.878903 30701 net.cpp:137] Memory required for data: 599101500
I0526 15:44:49.878906 30701 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.878922 30701 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.878927 30701 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0526 15:44:49.878932 30701 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0526 15:44:49.878940 30701 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0526 15:44:49.878985 30701 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0526 15:44:49.878995 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.878999 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.879003 30701 net.cpp:137] Memory required for data: 615157820
I0526 15:44:49.879006 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0526 15:44:49.879012 30701 net.cpp:84] Creating Layer layer_128_2_bn1
I0526 15:44:49.879017 30701 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0526 15:44:49.879022 30701 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0526 15:44:49.879254 30701 net.cpp:122] Setting up layer_128_2_bn1
I0526 15:44:49.879263 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.879276 30701 net.cpp:137] Memory required for data: 623185980
I0526 15:44:49.879284 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0526 15:44:49.879292 30701 net.cpp:84] Creating Layer layer_128_2_scale1
I0526 15:44:49.879295 30701 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0526 15:44:49.879302 30701 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0526 15:44:49.879354 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0526 15:44:49.879488 30701 net.cpp:122] Setting up layer_128_2_scale1
I0526 15:44:49.879497 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.879500 30701 net.cpp:137] Memory required for data: 631214140
I0526 15:44:49.879506 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0526 15:44:49.879513 30701 net.cpp:84] Creating Layer layer_128_2_relu1
I0526 15:44:49.879516 30701 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0526 15:44:49.879523 30701 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0526 15:44:49.880223 30701 net.cpp:122] Setting up layer_128_2_relu1
I0526 15:44:49.880234 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.880239 30701 net.cpp:137] Memory required for data: 639242300
I0526 15:44:49.880241 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0526 15:44:49.880250 30701 net.cpp:84] Creating Layer layer_128_2_conv1
I0526 15:44:49.880255 30701 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0526 15:44:49.880262 30701 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0526 15:44:49.881636 30701 net.cpp:122] Setting up layer_128_2_conv1
I0526 15:44:49.881647 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.881651 30701 net.cpp:137] Memory required for data: 641249340
I0526 15:44:49.881656 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0526 15:44:49.881664 30701 net.cpp:84] Creating Layer layer_128_2_bn2
I0526 15:44:49.881669 30701 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0526 15:44:49.881675 30701 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.881898 30701 net.cpp:122] Setting up layer_128_2_bn2
I0526 15:44:49.881907 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.881911 30701 net.cpp:137] Memory required for data: 643256380
I0526 15:44:49.881918 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0526 15:44:49.881927 30701 net.cpp:84] Creating Layer layer_128_2_scale2
I0526 15:44:49.881930 30701 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0526 15:44:49.881935 30701 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.881983 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0526 15:44:49.882117 30701 net.cpp:122] Setting up layer_128_2_scale2
I0526 15:44:49.882125 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.882129 30701 net.cpp:137] Memory required for data: 645263420
I0526 15:44:49.882135 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0526 15:44:49.882143 30701 net.cpp:84] Creating Layer layer_128_2_relu2
I0526 15:44:49.882148 30701 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0526 15:44:49.882151 30701 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0526 15:44:49.882861 30701 net.cpp:122] Setting up layer_128_2_relu2
I0526 15:44:49.882872 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.882876 30701 net.cpp:137] Memory required for data: 647270460
I0526 15:44:49.882880 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0526 15:44:49.882889 30701 net.cpp:84] Creating Layer layer_128_2_conv2
I0526 15:44:49.882894 30701 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0526 15:44:49.882901 30701 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0526 15:44:49.886903 30701 net.cpp:122] Setting up layer_128_2_conv2
I0526 15:44:49.886916 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.886919 30701 net.cpp:137] Memory required for data: 649277500
I0526 15:44:49.886925 30701 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0526 15:44:49.886942 30701 net.cpp:84] Creating Layer layer_128_2_bn3
I0526 15:44:49.886947 30701 net.cpp:406] layer_128_2_bn3 <- layer_128_2_conv2
I0526 15:44:49.886956 30701 net.cpp:367] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.887187 30701 net.cpp:122] Setting up layer_128_2_bn3
I0526 15:44:49.887195 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.887199 30701 net.cpp:137] Memory required for data: 651284540
I0526 15:44:49.887207 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0526 15:44:49.887213 30701 net.cpp:84] Creating Layer layer_128_2_scale3
I0526 15:44:49.887217 30701 net.cpp:406] layer_128_2_scale3 <- layer_128_2_conv2
I0526 15:44:49.887224 30701 net.cpp:367] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.887272 30701 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0526 15:44:49.887408 30701 net.cpp:122] Setting up layer_128_2_scale3
I0526 15:44:49.887416 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.887420 30701 net.cpp:137] Memory required for data: 653291580
I0526 15:44:49.887426 30701 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0526 15:44:49.887432 30701 net.cpp:84] Creating Layer layer_128_2_relu3
I0526 15:44:49.887436 30701 net.cpp:406] layer_128_2_relu3 <- layer_128_2_conv2
I0526 15:44:49.887444 30701 net.cpp:367] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0526 15:44:49.887615 30701 net.cpp:122] Setting up layer_128_2_relu3
I0526 15:44:49.887625 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.887629 30701 net.cpp:137] Memory required for data: 655298620
I0526 15:44:49.887632 30701 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0526 15:44:49.887642 30701 net.cpp:84] Creating Layer layer_128_2_conv3
I0526 15:44:49.887647 30701 net.cpp:406] layer_128_2_conv3 <- layer_128_2_conv2
I0526 15:44:49.887653 30701 net.cpp:380] layer_128_2_conv3 -> layer_128_2_conv3
I0526 15:44:49.889601 30701 net.cpp:122] Setting up layer_128_2_conv3
I0526 15:44:49.889616 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.889621 30701 net.cpp:137] Memory required for data: 663326780
I0526 15:44:49.889626 30701 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0526 15:44:49.889632 30701 net.cpp:84] Creating Layer layer_128_2_sum
I0526 15:44:49.889636 30701 net.cpp:406] layer_128_2_sum <- layer_128_2_conv3
I0526 15:44:49.889642 30701 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0526 15:44:49.889648 30701 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0526 15:44:49.889680 30701 net.cpp:122] Setting up layer_128_2_sum
I0526 15:44:49.889688 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.889693 30701 net.cpp:137] Memory required for data: 671354940
I0526 15:44:49.889696 30701 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.889703 30701 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.889708 30701 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0526 15:44:49.889713 30701 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0526 15:44:49.889720 30701 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0526 15:44:49.889765 30701 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0526 15:44:49.889775 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.889780 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.889782 30701 net.cpp:137] Memory required for data: 687411260
I0526 15:44:49.889786 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0526 15:44:49.889791 30701 net.cpp:84] Creating Layer layer_128_3_bn1
I0526 15:44:49.889796 30701 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0526 15:44:49.889803 30701 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0526 15:44:49.890038 30701 net.cpp:122] Setting up layer_128_3_bn1
I0526 15:44:49.890054 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.890058 30701 net.cpp:137] Memory required for data: 695439420
I0526 15:44:49.890066 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0526 15:44:49.890074 30701 net.cpp:84] Creating Layer layer_128_3_scale1
I0526 15:44:49.890079 30701 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0526 15:44:49.890084 30701 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0526 15:44:49.890133 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0526 15:44:49.890266 30701 net.cpp:122] Setting up layer_128_3_scale1
I0526 15:44:49.890275 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.890280 30701 net.cpp:137] Memory required for data: 703467580
I0526 15:44:49.890285 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0526 15:44:49.890290 30701 net.cpp:84] Creating Layer layer_128_3_relu1
I0526 15:44:49.890295 30701 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0526 15:44:49.890301 30701 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0526 15:44:49.890470 30701 net.cpp:122] Setting up layer_128_3_relu1
I0526 15:44:49.890480 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.890482 30701 net.cpp:137] Memory required for data: 711495740
I0526 15:44:49.890486 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0526 15:44:49.890496 30701 net.cpp:84] Creating Layer layer_128_3_conv1
I0526 15:44:49.890501 30701 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0526 15:44:49.890506 30701 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0526 15:44:49.892963 30701 net.cpp:122] Setting up layer_128_3_conv1
I0526 15:44:49.892976 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.892982 30701 net.cpp:137] Memory required for data: 713502780
I0526 15:44:49.892987 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0526 15:44:49.892993 30701 net.cpp:84] Creating Layer layer_128_3_bn2
I0526 15:44:49.892997 30701 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0526 15:44:49.893004 30701 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.893239 30701 net.cpp:122] Setting up layer_128_3_bn2
I0526 15:44:49.893249 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.893252 30701 net.cpp:137] Memory required for data: 715509820
I0526 15:44:49.893260 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0526 15:44:49.893266 30701 net.cpp:84] Creating Layer layer_128_3_scale2
I0526 15:44:49.893270 30701 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0526 15:44:49.893275 30701 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.893324 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0526 15:44:49.893461 30701 net.cpp:122] Setting up layer_128_3_scale2
I0526 15:44:49.893471 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.893476 30701 net.cpp:137] Memory required for data: 717516860
I0526 15:44:49.893481 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0526 15:44:49.893487 30701 net.cpp:84] Creating Layer layer_128_3_relu2
I0526 15:44:49.893491 30701 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0526 15:44:49.893496 30701 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0526 15:44:49.893673 30701 net.cpp:122] Setting up layer_128_3_relu2
I0526 15:44:49.893683 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.893687 30701 net.cpp:137] Memory required for data: 719523900
I0526 15:44:49.893690 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0526 15:44:49.893700 30701 net.cpp:84] Creating Layer layer_128_3_conv2
I0526 15:44:49.893705 30701 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0526 15:44:49.893712 30701 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0526 15:44:49.897511 30701 net.cpp:122] Setting up layer_128_3_conv2
I0526 15:44:49.897524 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.897528 30701 net.cpp:137] Memory required for data: 721530940
I0526 15:44:49.897542 30701 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0526 15:44:49.897553 30701 net.cpp:84] Creating Layer layer_128_3_bn3
I0526 15:44:49.897557 30701 net.cpp:406] layer_128_3_bn3 <- layer_128_3_conv2
I0526 15:44:49.897564 30701 net.cpp:367] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.897804 30701 net.cpp:122] Setting up layer_128_3_bn3
I0526 15:44:49.897812 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.897816 30701 net.cpp:137] Memory required for data: 723537980
I0526 15:44:49.897824 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0526 15:44:49.897831 30701 net.cpp:84] Creating Layer layer_128_3_scale3
I0526 15:44:49.897835 30701 net.cpp:406] layer_128_3_scale3 <- layer_128_3_conv2
I0526 15:44:49.897840 30701 net.cpp:367] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.897893 30701 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0526 15:44:49.898064 30701 net.cpp:122] Setting up layer_128_3_scale3
I0526 15:44:49.898075 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.898078 30701 net.cpp:137] Memory required for data: 725545020
I0526 15:44:49.898084 30701 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0526 15:44:49.898092 30701 net.cpp:84] Creating Layer layer_128_3_relu3
I0526 15:44:49.898097 30701 net.cpp:406] layer_128_3_relu3 <- layer_128_3_conv2
I0526 15:44:49.898102 30701 net.cpp:367] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0526 15:44:49.898278 30701 net.cpp:122] Setting up layer_128_3_relu3
I0526 15:44:49.898288 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.898291 30701 net.cpp:137] Memory required for data: 727552060
I0526 15:44:49.898294 30701 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0526 15:44:49.898304 30701 net.cpp:84] Creating Layer layer_128_3_conv3
I0526 15:44:49.898309 30701 net.cpp:406] layer_128_3_conv3 <- layer_128_3_conv2
I0526 15:44:49.898316 30701 net.cpp:380] layer_128_3_conv3 -> layer_128_3_conv3
I0526 15:44:49.900382 30701 net.cpp:122] Setting up layer_128_3_conv3
I0526 15:44:49.900396 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.900399 30701 net.cpp:137] Memory required for data: 735580220
I0526 15:44:49.900406 30701 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0526 15:44:49.900413 30701 net.cpp:84] Creating Layer layer_128_3_sum
I0526 15:44:49.900416 30701 net.cpp:406] layer_128_3_sum <- layer_128_3_conv3
I0526 15:44:49.900421 30701 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0526 15:44:49.900429 30701 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0526 15:44:49.900465 30701 net.cpp:122] Setting up layer_128_3_sum
I0526 15:44:49.900473 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.900476 30701 net.cpp:137] Memory required for data: 743608380
I0526 15:44:49.900480 30701 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.900485 30701 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.900490 30701 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0526 15:44:49.900496 30701 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0526 15:44:49.900503 30701 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0526 15:44:49.900550 30701 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0526 15:44:49.900558 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.900563 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.900565 30701 net.cpp:137] Memory required for data: 759664700
I0526 15:44:49.900568 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0526 15:44:49.900575 30701 net.cpp:84] Creating Layer layer_128_4_bn1
I0526 15:44:49.900579 30701 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0526 15:44:49.900585 30701 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0526 15:44:49.900838 30701 net.cpp:122] Setting up layer_128_4_bn1
I0526 15:44:49.900848 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.900851 30701 net.cpp:137] Memory required for data: 767692860
I0526 15:44:49.900858 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0526 15:44:49.900864 30701 net.cpp:84] Creating Layer layer_128_4_scale1
I0526 15:44:49.900867 30701 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0526 15:44:49.900872 30701 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0526 15:44:49.900924 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0526 15:44:49.901063 30701 net.cpp:122] Setting up layer_128_4_scale1
I0526 15:44:49.901072 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.901075 30701 net.cpp:137] Memory required for data: 775721020
I0526 15:44:49.901082 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0526 15:44:49.901088 30701 net.cpp:84] Creating Layer layer_128_4_relu1
I0526 15:44:49.901093 30701 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0526 15:44:49.901096 30701 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0526 15:44:49.903090 30701 net.cpp:122] Setting up layer_128_4_relu1
I0526 15:44:49.903103 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.903106 30701 net.cpp:137] Memory required for data: 783749180
I0526 15:44:49.903110 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0526 15:44:49.903120 30701 net.cpp:84] Creating Layer layer_128_4_conv1
I0526 15:44:49.903125 30701 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0526 15:44:49.903131 30701 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0526 15:44:49.904541 30701 net.cpp:122] Setting up layer_128_4_conv1
I0526 15:44:49.904554 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.904558 30701 net.cpp:137] Memory required for data: 785756220
I0526 15:44:49.904563 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0526 15:44:49.904569 30701 net.cpp:84] Creating Layer layer_128_4_bn2
I0526 15:44:49.904573 30701 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0526 15:44:49.904579 30701 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.904810 30701 net.cpp:122] Setting up layer_128_4_bn2
I0526 15:44:49.904819 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.904822 30701 net.cpp:137] Memory required for data: 787763260
I0526 15:44:49.904829 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0526 15:44:49.904836 30701 net.cpp:84] Creating Layer layer_128_4_scale2
I0526 15:44:49.904839 30701 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0526 15:44:49.904844 30701 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.904893 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0526 15:44:49.905033 30701 net.cpp:122] Setting up layer_128_4_scale2
I0526 15:44:49.905042 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.905046 30701 net.cpp:137] Memory required for data: 789770300
I0526 15:44:49.905051 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0526 15:44:49.905061 30701 net.cpp:84] Creating Layer layer_128_4_relu2
I0526 15:44:49.905064 30701 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0526 15:44:49.905069 30701 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0526 15:44:49.909762 30701 net.cpp:122] Setting up layer_128_4_relu2
I0526 15:44:49.909777 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.909780 30701 net.cpp:137] Memory required for data: 791777340
I0526 15:44:49.909785 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0526 15:44:49.909795 30701 net.cpp:84] Creating Layer layer_128_4_conv2
I0526 15:44:49.909799 30701 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0526 15:44:49.909807 30701 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0526 15:44:49.913107 30701 net.cpp:122] Setting up layer_128_4_conv2
I0526 15:44:49.913121 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.913136 30701 net.cpp:137] Memory required for data: 793784380
I0526 15:44:49.913156 30701 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0526 15:44:49.913166 30701 net.cpp:84] Creating Layer layer_128_4_bn3
I0526 15:44:49.913170 30701 net.cpp:406] layer_128_4_bn3 <- layer_128_4_conv2
I0526 15:44:49.913175 30701 net.cpp:367] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.913415 30701 net.cpp:122] Setting up layer_128_4_bn3
I0526 15:44:49.913424 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.913429 30701 net.cpp:137] Memory required for data: 795791420
I0526 15:44:49.913436 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0526 15:44:49.913442 30701 net.cpp:84] Creating Layer layer_128_4_scale3
I0526 15:44:49.913447 30701 net.cpp:406] layer_128_4_scale3 <- layer_128_4_conv2
I0526 15:44:49.913452 30701 net.cpp:367] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.913502 30701 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0526 15:44:49.913643 30701 net.cpp:122] Setting up layer_128_4_scale3
I0526 15:44:49.913652 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.913656 30701 net.cpp:137] Memory required for data: 797798460
I0526 15:44:49.913662 30701 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0526 15:44:49.913668 30701 net.cpp:84] Creating Layer layer_128_4_relu3
I0526 15:44:49.913674 30701 net.cpp:406] layer_128_4_relu3 <- layer_128_4_conv2
I0526 15:44:49.913678 30701 net.cpp:367] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0526 15:44:49.913848 30701 net.cpp:122] Setting up layer_128_4_relu3
I0526 15:44:49.913857 30701 net.cpp:129] Top shape: 5 128 28 28 (501760)
I0526 15:44:49.913861 30701 net.cpp:137] Memory required for data: 799805500
I0526 15:44:49.913864 30701 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0526 15:44:49.913873 30701 net.cpp:84] Creating Layer layer_128_4_conv3
I0526 15:44:49.913878 30701 net.cpp:406] layer_128_4_conv3 <- layer_128_4_conv2
I0526 15:44:49.913885 30701 net.cpp:380] layer_128_4_conv3 -> layer_128_4_conv3
I0526 15:44:49.915843 30701 net.cpp:122] Setting up layer_128_4_conv3
I0526 15:44:49.915854 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.915859 30701 net.cpp:137] Memory required for data: 807833660
I0526 15:44:49.915864 30701 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0526 15:44:49.915871 30701 net.cpp:84] Creating Layer layer_128_4_sum
I0526 15:44:49.915875 30701 net.cpp:406] layer_128_4_sum <- layer_128_4_conv3
I0526 15:44:49.915880 30701 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0526 15:44:49.915887 30701 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0526 15:44:49.915920 30701 net.cpp:122] Setting up layer_128_4_sum
I0526 15:44:49.915930 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.915933 30701 net.cpp:137] Memory required for data: 815861820
I0526 15:44:49.915937 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0526 15:44:49.915942 30701 net.cpp:84] Creating Layer layer_256_1_bn1
I0526 15:44:49.915946 30701 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0526 15:44:49.915958 30701 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0526 15:44:49.916208 30701 net.cpp:122] Setting up layer_256_1_bn1
I0526 15:44:49.916216 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.916220 30701 net.cpp:137] Memory required for data: 823889980
I0526 15:44:49.916227 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0526 15:44:49.916235 30701 net.cpp:84] Creating Layer layer_256_1_scale1
I0526 15:44:49.916239 30701 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0526 15:44:49.916244 30701 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0526 15:44:49.916296 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0526 15:44:49.916432 30701 net.cpp:122] Setting up layer_256_1_scale1
I0526 15:44:49.916441 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.916453 30701 net.cpp:137] Memory required for data: 831918140
I0526 15:44:49.916460 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0526 15:44:49.916465 30701 net.cpp:84] Creating Layer layer_256_1_relu1
I0526 15:44:49.916470 30701 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0526 15:44:49.916476 30701 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0526 15:44:49.916646 30701 net.cpp:122] Setting up layer_256_1_relu1
I0526 15:44:49.916656 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.916659 30701 net.cpp:137] Memory required for data: 839946300
I0526 15:44:49.916663 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.916671 30701 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.916674 30701 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0526 15:44:49.916681 30701 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0526 15:44:49.916687 30701 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0526 15:44:49.916738 30701 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0526 15:44:49.916745 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.916750 30701 net.cpp:129] Top shape: 5 512 28 28 (2007040)
I0526 15:44:49.916754 30701 net.cpp:137] Memory required for data: 856002620
I0526 15:44:49.916756 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0526 15:44:49.916767 30701 net.cpp:84] Creating Layer layer_256_1_conv1
I0526 15:44:49.916771 30701 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0526 15:44:49.916779 30701 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0526 15:44:49.919376 30701 net.cpp:122] Setting up layer_256_1_conv1
I0526 15:44:49.919389 30701 net.cpp:129] Top shape: 5 256 28 28 (1003520)
I0526 15:44:49.919392 30701 net.cpp:137] Memory required for data: 860016700
I0526 15:44:49.919399 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0526 15:44:49.919406 30701 net.cpp:84] Creating Layer layer_256_1_bn2
I0526 15:44:49.919410 30701 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0526 15:44:49.919416 30701 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.919651 30701 net.cpp:122] Setting up layer_256_1_bn2
I0526 15:44:49.919661 30701 net.cpp:129] Top shape: 5 256 28 28 (1003520)
I0526 15:44:49.919664 30701 net.cpp:137] Memory required for data: 864030780
I0526 15:44:49.919672 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0526 15:44:49.919678 30701 net.cpp:84] Creating Layer layer_256_1_scale2
I0526 15:44:49.919682 30701 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0526 15:44:49.919687 30701 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.919739 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0526 15:44:49.919880 30701 net.cpp:122] Setting up layer_256_1_scale2
I0526 15:44:49.919889 30701 net.cpp:129] Top shape: 5 256 28 28 (1003520)
I0526 15:44:49.919893 30701 net.cpp:137] Memory required for data: 868044860
I0526 15:44:49.919898 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0526 15:44:49.919904 30701 net.cpp:84] Creating Layer layer_256_1_relu2
I0526 15:44:49.919909 30701 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0526 15:44:49.919915 30701 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0526 15:44:49.920092 30701 net.cpp:122] Setting up layer_256_1_relu2
I0526 15:44:49.920104 30701 net.cpp:129] Top shape: 5 256 28 28 (1003520)
I0526 15:44:49.920109 30701 net.cpp:137] Memory required for data: 872058940
I0526 15:44:49.920111 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0526 15:44:49.920120 30701 net.cpp:84] Creating Layer layer_256_1_conv2
I0526 15:44:49.920125 30701 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0526 15:44:49.920132 30701 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0526 15:44:49.928069 30701 net.cpp:122] Setting up layer_256_1_conv2
I0526 15:44:49.928084 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.928088 30701 net.cpp:137] Memory required for data: 873062460
I0526 15:44:49.928094 30701 layer_factory.hpp:77] Creating layer layer_256_1_bn3
I0526 15:44:49.928103 30701 net.cpp:84] Creating Layer layer_256_1_bn3
I0526 15:44:49.928108 30701 net.cpp:406] layer_256_1_bn3 <- layer_256_1_conv2
I0526 15:44:49.928113 30701 net.cpp:367] layer_256_1_bn3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.928354 30701 net.cpp:122] Setting up layer_256_1_bn3
I0526 15:44:49.928364 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.928367 30701 net.cpp:137] Memory required for data: 874065980
I0526 15:44:49.928375 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0526 15:44:49.928383 30701 net.cpp:84] Creating Layer layer_256_1_scale3
I0526 15:44:49.928388 30701 net.cpp:406] layer_256_1_scale3 <- layer_256_1_conv2
I0526 15:44:49.928393 30701 net.cpp:367] layer_256_1_scale3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.928447 30701 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0526 15:44:49.928586 30701 net.cpp:122] Setting up layer_256_1_scale3
I0526 15:44:49.928594 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.928598 30701 net.cpp:137] Memory required for data: 875069500
I0526 15:44:49.928603 30701 layer_factory.hpp:77] Creating layer layer_256_1_relu3
I0526 15:44:49.928611 30701 net.cpp:84] Creating Layer layer_256_1_relu3
I0526 15:44:49.928614 30701 net.cpp:406] layer_256_1_relu3 <- layer_256_1_conv2
I0526 15:44:49.928620 30701 net.cpp:367] layer_256_1_relu3 -> layer_256_1_conv2 (in-place)
I0526 15:44:49.928793 30701 net.cpp:122] Setting up layer_256_1_relu3
I0526 15:44:49.928804 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.928808 30701 net.cpp:137] Memory required for data: 876073020
I0526 15:44:49.928812 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv3
I0526 15:44:49.928822 30701 net.cpp:84] Creating Layer layer_256_1_conv3
I0526 15:44:49.928827 30701 net.cpp:406] layer_256_1_conv3 <- layer_256_1_conv2
I0526 15:44:49.928833 30701 net.cpp:380] layer_256_1_conv3 -> layer_256_1_conv3
I0526 15:44:49.933635 30701 net.cpp:122] Setting up layer_256_1_conv3
I0526 15:44:49.933655 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.933660 30701 net.cpp:137] Memory required for data: 880087100
I0526 15:44:49.933666 30701 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0526 15:44:49.933678 30701 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0526 15:44:49.933684 30701 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0526 15:44:49.933694 30701 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0526 15:44:49.940934 30701 net.cpp:122] Setting up layer_256_1_conv_expand
I0526 15:44:49.940948 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.940951 30701 net.cpp:137] Memory required for data: 884101180
I0526 15:44:49.940956 30701 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0526 15:44:49.940964 30701 net.cpp:84] Creating Layer layer_256_1_sum
I0526 15:44:49.940968 30701 net.cpp:406] layer_256_1_sum <- layer_256_1_conv3
I0526 15:44:49.940973 30701 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0526 15:44:49.940980 30701 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0526 15:44:49.941030 30701 net.cpp:122] Setting up layer_256_1_sum
I0526 15:44:49.941038 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941042 30701 net.cpp:137] Memory required for data: 888115260
I0526 15:44:49.941045 30701 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.941051 30701 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.941056 30701 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0526 15:44:49.941062 30701 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0526 15:44:49.941084 30701 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0526 15:44:49.941133 30701 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0526 15:44:49.941143 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941146 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941150 30701 net.cpp:137] Memory required for data: 896143420
I0526 15:44:49.941154 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0526 15:44:49.941164 30701 net.cpp:84] Creating Layer layer_256_2_bn1
I0526 15:44:49.941169 30701 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0526 15:44:49.941175 30701 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0526 15:44:49.941437 30701 net.cpp:122] Setting up layer_256_2_bn1
I0526 15:44:49.941445 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941449 30701 net.cpp:137] Memory required for data: 900157500
I0526 15:44:49.941457 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0526 15:44:49.941464 30701 net.cpp:84] Creating Layer layer_256_2_scale1
I0526 15:44:49.941468 30701 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0526 15:44:49.941473 30701 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0526 15:44:49.941527 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0526 15:44:49.941673 30701 net.cpp:122] Setting up layer_256_2_scale1
I0526 15:44:49.941682 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941686 30701 net.cpp:137] Memory required for data: 904171580
I0526 15:44:49.941692 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0526 15:44:49.941700 30701 net.cpp:84] Creating Layer layer_256_2_relu1
I0526 15:44:49.941705 30701 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0526 15:44:49.941709 30701 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0526 15:44:49.941879 30701 net.cpp:122] Setting up layer_256_2_relu1
I0526 15:44:49.941890 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.941892 30701 net.cpp:137] Memory required for data: 908185660
I0526 15:44:49.941896 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0526 15:44:49.941905 30701 net.cpp:84] Creating Layer layer_256_2_conv1
I0526 15:44:49.941910 30701 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0526 15:44:49.941916 30701 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0526 15:44:49.945857 30701 net.cpp:122] Setting up layer_256_2_conv1
I0526 15:44:49.945869 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.945873 30701 net.cpp:137] Memory required for data: 909189180
I0526 15:44:49.945878 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0526 15:44:49.945885 30701 net.cpp:84] Creating Layer layer_256_2_bn2
I0526 15:44:49.945890 30701 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0526 15:44:49.945896 30701 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.946141 30701 net.cpp:122] Setting up layer_256_2_bn2
I0526 15:44:49.946151 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.946154 30701 net.cpp:137] Memory required for data: 910192700
I0526 15:44:49.946161 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0526 15:44:49.946168 30701 net.cpp:84] Creating Layer layer_256_2_scale2
I0526 15:44:49.946172 30701 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0526 15:44:49.946178 30701 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.946229 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0526 15:44:49.946368 30701 net.cpp:122] Setting up layer_256_2_scale2
I0526 15:44:49.946377 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.946382 30701 net.cpp:137] Memory required for data: 911196220
I0526 15:44:49.946388 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0526 15:44:49.946413 30701 net.cpp:84] Creating Layer layer_256_2_relu2
I0526 15:44:49.946416 30701 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0526 15:44:49.946431 30701 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0526 15:44:49.947151 30701 net.cpp:122] Setting up layer_256_2_relu2
I0526 15:44:49.947162 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.947167 30701 net.cpp:137] Memory required for data: 912199740
I0526 15:44:49.947171 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0526 15:44:49.947181 30701 net.cpp:84] Creating Layer layer_256_2_conv2
I0526 15:44:49.947186 30701 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0526 15:44:49.947193 30701 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0526 15:44:49.955216 30701 net.cpp:122] Setting up layer_256_2_conv2
I0526 15:44:49.955232 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.955236 30701 net.cpp:137] Memory required for data: 913203260
I0526 15:44:49.955242 30701 layer_factory.hpp:77] Creating layer layer_256_2_bn3
I0526 15:44:49.955251 30701 net.cpp:84] Creating Layer layer_256_2_bn3
I0526 15:44:49.955257 30701 net.cpp:406] layer_256_2_bn3 <- layer_256_2_conv2
I0526 15:44:49.955263 30701 net.cpp:367] layer_256_2_bn3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.955513 30701 net.cpp:122] Setting up layer_256_2_bn3
I0526 15:44:49.955523 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.955526 30701 net.cpp:137] Memory required for data: 914206780
I0526 15:44:49.955533 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0526 15:44:49.955540 30701 net.cpp:84] Creating Layer layer_256_2_scale3
I0526 15:44:49.955545 30701 net.cpp:406] layer_256_2_scale3 <- layer_256_2_conv2
I0526 15:44:49.955550 30701 net.cpp:367] layer_256_2_scale3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.955606 30701 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0526 15:44:49.955749 30701 net.cpp:122] Setting up layer_256_2_scale3
I0526 15:44:49.955757 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.955761 30701 net.cpp:137] Memory required for data: 915210300
I0526 15:44:49.955767 30701 layer_factory.hpp:77] Creating layer layer_256_2_relu3
I0526 15:44:49.955775 30701 net.cpp:84] Creating Layer layer_256_2_relu3
I0526 15:44:49.955778 30701 net.cpp:406] layer_256_2_relu3 <- layer_256_2_conv2
I0526 15:44:49.955785 30701 net.cpp:367] layer_256_2_relu3 -> layer_256_2_conv2 (in-place)
I0526 15:44:49.956499 30701 net.cpp:122] Setting up layer_256_2_relu3
I0526 15:44:49.956511 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.956516 30701 net.cpp:137] Memory required for data: 916213820
I0526 15:44:49.956519 30701 layer_factory.hpp:77] Creating layer layer_256_2_conv3
I0526 15:44:49.956531 30701 net.cpp:84] Creating Layer layer_256_2_conv3
I0526 15:44:49.956535 30701 net.cpp:406] layer_256_2_conv3 <- layer_256_2_conv2
I0526 15:44:49.956542 30701 net.cpp:380] layer_256_2_conv3 -> layer_256_2_conv3
I0526 15:44:49.961220 30701 net.cpp:122] Setting up layer_256_2_conv3
I0526 15:44:49.961232 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961236 30701 net.cpp:137] Memory required for data: 920227900
I0526 15:44:49.961241 30701 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0526 15:44:49.961248 30701 net.cpp:84] Creating Layer layer_256_2_sum
I0526 15:44:49.961253 30701 net.cpp:406] layer_256_2_sum <- layer_256_2_conv3
I0526 15:44:49.961258 30701 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0526 15:44:49.961266 30701 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0526 15:44:49.961300 30701 net.cpp:122] Setting up layer_256_2_sum
I0526 15:44:49.961310 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961314 30701 net.cpp:137] Memory required for data: 924241980
I0526 15:44:49.961318 30701 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.961323 30701 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.961328 30701 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0526 15:44:49.961333 30701 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0526 15:44:49.961354 30701 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0526 15:44:49.961405 30701 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0526 15:44:49.961413 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961418 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961421 30701 net.cpp:137] Memory required for data: 932270140
I0526 15:44:49.961424 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0526 15:44:49.961431 30701 net.cpp:84] Creating Layer layer_256_3_bn1
I0526 15:44:49.961436 30701 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0526 15:44:49.961442 30701 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0526 15:44:49.961696 30701 net.cpp:122] Setting up layer_256_3_bn1
I0526 15:44:49.961705 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961709 30701 net.cpp:137] Memory required for data: 936284220
I0526 15:44:49.961716 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0526 15:44:49.961724 30701 net.cpp:84] Creating Layer layer_256_3_scale1
I0526 15:44:49.961727 30701 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0526 15:44:49.961732 30701 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0526 15:44:49.961782 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0526 15:44:49.961930 30701 net.cpp:122] Setting up layer_256_3_scale1
I0526 15:44:49.961938 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.961941 30701 net.cpp:137] Memory required for data: 940298300
I0526 15:44:49.961947 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0526 15:44:49.961956 30701 net.cpp:84] Creating Layer layer_256_3_relu1
I0526 15:44:49.961961 30701 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0526 15:44:49.961964 30701 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0526 15:44:49.962136 30701 net.cpp:122] Setting up layer_256_3_relu1
I0526 15:44:49.962146 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.962151 30701 net.cpp:137] Memory required for data: 944312380
I0526 15:44:49.962153 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0526 15:44:49.962162 30701 net.cpp:84] Creating Layer layer_256_3_conv1
I0526 15:44:49.962167 30701 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0526 15:44:49.962174 30701 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0526 15:44:49.966480 30701 net.cpp:122] Setting up layer_256_3_conv1
I0526 15:44:49.966493 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.966497 30701 net.cpp:137] Memory required for data: 945315900
I0526 15:44:49.966502 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0526 15:44:49.966511 30701 net.cpp:84] Creating Layer layer_256_3_bn2
I0526 15:44:49.966516 30701 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0526 15:44:49.966521 30701 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.966763 30701 net.cpp:122] Setting up layer_256_3_bn2
I0526 15:44:49.966771 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.966775 30701 net.cpp:137] Memory required for data: 946319420
I0526 15:44:49.966784 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0526 15:44:49.966789 30701 net.cpp:84] Creating Layer layer_256_3_scale2
I0526 15:44:49.966794 30701 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0526 15:44:49.966800 30701 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.966850 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0526 15:44:49.966990 30701 net.cpp:122] Setting up layer_256_3_scale2
I0526 15:44:49.967000 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.967005 30701 net.cpp:137] Memory required for data: 947322940
I0526 15:44:49.967010 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0526 15:44:49.967016 30701 net.cpp:84] Creating Layer layer_256_3_relu2
I0526 15:44:49.967031 30701 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0526 15:44:49.967036 30701 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0526 15:44:49.967207 30701 net.cpp:122] Setting up layer_256_3_relu2
I0526 15:44:49.967217 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.967221 30701 net.cpp:137] Memory required for data: 948326460
I0526 15:44:49.967223 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0526 15:44:49.967233 30701 net.cpp:84] Creating Layer layer_256_3_conv2
I0526 15:44:49.967237 30701 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0526 15:44:49.967245 30701 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0526 15:44:49.976097 30701 net.cpp:122] Setting up layer_256_3_conv2
I0526 15:44:49.976120 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.976124 30701 net.cpp:137] Memory required for data: 949329980
I0526 15:44:49.976130 30701 layer_factory.hpp:77] Creating layer layer_256_3_bn3
I0526 15:44:49.976141 30701 net.cpp:84] Creating Layer layer_256_3_bn3
I0526 15:44:49.976146 30701 net.cpp:406] layer_256_3_bn3 <- layer_256_3_conv2
I0526 15:44:49.976155 30701 net.cpp:367] layer_256_3_bn3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.976411 30701 net.cpp:122] Setting up layer_256_3_bn3
I0526 15:44:49.976421 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.976425 30701 net.cpp:137] Memory required for data: 950333500
I0526 15:44:49.976433 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0526 15:44:49.976440 30701 net.cpp:84] Creating Layer layer_256_3_scale3
I0526 15:44:49.976444 30701 net.cpp:406] layer_256_3_scale3 <- layer_256_3_conv2
I0526 15:44:49.976451 30701 net.cpp:367] layer_256_3_scale3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.976508 30701 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0526 15:44:49.976651 30701 net.cpp:122] Setting up layer_256_3_scale3
I0526 15:44:49.976660 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.976663 30701 net.cpp:137] Memory required for data: 951337020
I0526 15:44:49.976670 30701 layer_factory.hpp:77] Creating layer layer_256_3_relu3
I0526 15:44:49.976676 30701 net.cpp:84] Creating Layer layer_256_3_relu3
I0526 15:44:49.976680 30701 net.cpp:406] layer_256_3_relu3 <- layer_256_3_conv2
I0526 15:44:49.976686 30701 net.cpp:367] layer_256_3_relu3 -> layer_256_3_conv2 (in-place)
I0526 15:44:49.976861 30701 net.cpp:122] Setting up layer_256_3_relu3
I0526 15:44:49.976871 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.976874 30701 net.cpp:137] Memory required for data: 952340540
I0526 15:44:49.976878 30701 layer_factory.hpp:77] Creating layer layer_256_3_conv3
I0526 15:44:49.976891 30701 net.cpp:84] Creating Layer layer_256_3_conv3
I0526 15:44:49.976894 30701 net.cpp:406] layer_256_3_conv3 <- layer_256_3_conv2
I0526 15:44:49.976902 30701 net.cpp:380] layer_256_3_conv3 -> layer_256_3_conv3
I0526 15:44:49.981590 30701 net.cpp:122] Setting up layer_256_3_conv3
I0526 15:44:49.981606 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.981609 30701 net.cpp:137] Memory required for data: 956354620
I0526 15:44:49.981616 30701 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0526 15:44:49.981622 30701 net.cpp:84] Creating Layer layer_256_3_sum
I0526 15:44:49.981626 30701 net.cpp:406] layer_256_3_sum <- layer_256_3_conv3
I0526 15:44:49.981631 30701 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0526 15:44:49.981638 30701 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0526 15:44:49.981673 30701 net.cpp:122] Setting up layer_256_3_sum
I0526 15:44:49.981684 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.981688 30701 net.cpp:137] Memory required for data: 960368700
I0526 15:44:49.981691 30701 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.981696 30701 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.981701 30701 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0526 15:44:49.981717 30701 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0526 15:44:49.981727 30701 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0526 15:44:49.981777 30701 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0526 15:44:49.981786 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.981791 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.981793 30701 net.cpp:137] Memory required for data: 968396860
I0526 15:44:49.981797 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0526 15:44:49.981804 30701 net.cpp:84] Creating Layer layer_256_4_bn1
I0526 15:44:49.981808 30701 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0526 15:44:49.981814 30701 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0526 15:44:49.982071 30701 net.cpp:122] Setting up layer_256_4_bn1
I0526 15:44:49.982081 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.982084 30701 net.cpp:137] Memory required for data: 972410940
I0526 15:44:49.982091 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0526 15:44:49.982098 30701 net.cpp:84] Creating Layer layer_256_4_scale1
I0526 15:44:49.982102 30701 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0526 15:44:49.982107 30701 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0526 15:44:49.982158 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0526 15:44:49.982307 30701 net.cpp:122] Setting up layer_256_4_scale1
I0526 15:44:49.982316 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.982321 30701 net.cpp:137] Memory required for data: 976425020
I0526 15:44:49.982326 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0526 15:44:49.982332 30701 net.cpp:84] Creating Layer layer_256_4_relu1
I0526 15:44:49.982337 30701 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0526 15:44:49.982343 30701 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0526 15:44:49.982514 30701 net.cpp:122] Setting up layer_256_4_relu1
I0526 15:44:49.982527 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:49.982532 30701 net.cpp:137] Memory required for data: 980439100
I0526 15:44:49.982534 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0526 15:44:49.982543 30701 net.cpp:84] Creating Layer layer_256_4_conv1
I0526 15:44:49.982548 30701 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0526 15:44:49.982554 30701 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0526 15:44:49.987007 30701 net.cpp:122] Setting up layer_256_4_conv1
I0526 15:44:49.987020 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.987025 30701 net.cpp:137] Memory required for data: 981442620
I0526 15:44:49.987030 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0526 15:44:49.987037 30701 net.cpp:84] Creating Layer layer_256_4_bn2
I0526 15:44:49.987042 30701 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0526 15:44:49.987048 30701 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.987293 30701 net.cpp:122] Setting up layer_256_4_bn2
I0526 15:44:49.987303 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.987306 30701 net.cpp:137] Memory required for data: 982446140
I0526 15:44:49.987313 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0526 15:44:49.987321 30701 net.cpp:84] Creating Layer layer_256_4_scale2
I0526 15:44:49.987326 30701 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0526 15:44:49.987331 30701 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.987383 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0526 15:44:49.987529 30701 net.cpp:122] Setting up layer_256_4_scale2
I0526 15:44:49.987537 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.987541 30701 net.cpp:137] Memory required for data: 983449660
I0526 15:44:49.987546 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0526 15:44:49.987563 30701 net.cpp:84] Creating Layer layer_256_4_relu2
I0526 15:44:49.987568 30701 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0526 15:44:49.987573 30701 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0526 15:44:49.988303 30701 net.cpp:122] Setting up layer_256_4_relu2
I0526 15:44:49.988317 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.988320 30701 net.cpp:137] Memory required for data: 984453180
I0526 15:44:49.988324 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0526 15:44:49.988333 30701 net.cpp:84] Creating Layer layer_256_4_conv2
I0526 15:44:49.988338 30701 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0526 15:44:49.988348 30701 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0526 15:44:49.996292 30701 net.cpp:122] Setting up layer_256_4_conv2
I0526 15:44:49.996306 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.996311 30701 net.cpp:137] Memory required for data: 985456700
I0526 15:44:49.996317 30701 layer_factory.hpp:77] Creating layer layer_256_4_bn3
I0526 15:44:49.996325 30701 net.cpp:84] Creating Layer layer_256_4_bn3
I0526 15:44:49.996330 30701 net.cpp:406] layer_256_4_bn3 <- layer_256_4_conv2
I0526 15:44:49.996335 30701 net.cpp:367] layer_256_4_bn3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.996585 30701 net.cpp:122] Setting up layer_256_4_bn3
I0526 15:44:49.996594 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.996598 30701 net.cpp:137] Memory required for data: 986460220
I0526 15:44:49.996606 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0526 15:44:49.996613 30701 net.cpp:84] Creating Layer layer_256_4_scale3
I0526 15:44:49.996618 30701 net.cpp:406] layer_256_4_scale3 <- layer_256_4_conv2
I0526 15:44:49.996623 30701 net.cpp:367] layer_256_4_scale3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.996680 30701 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0526 15:44:49.996824 30701 net.cpp:122] Setting up layer_256_4_scale3
I0526 15:44:49.996832 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.996836 30701 net.cpp:137] Memory required for data: 987463740
I0526 15:44:49.996842 30701 layer_factory.hpp:77] Creating layer layer_256_4_relu3
I0526 15:44:49.996848 30701 net.cpp:84] Creating Layer layer_256_4_relu3
I0526 15:44:49.996852 30701 net.cpp:406] layer_256_4_relu3 <- layer_256_4_conv2
I0526 15:44:49.996858 30701 net.cpp:367] layer_256_4_relu3 -> layer_256_4_conv2 (in-place)
I0526 15:44:49.997568 30701 net.cpp:122] Setting up layer_256_4_relu3
I0526 15:44:49.997580 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:49.997584 30701 net.cpp:137] Memory required for data: 988467260
I0526 15:44:49.997588 30701 layer_factory.hpp:77] Creating layer layer_256_4_conv3
I0526 15:44:49.997598 30701 net.cpp:84] Creating Layer layer_256_4_conv3
I0526 15:44:49.997604 30701 net.cpp:406] layer_256_4_conv3 <- layer_256_4_conv2
I0526 15:44:49.997611 30701 net.cpp:380] layer_256_4_conv3 -> layer_256_4_conv3
I0526 15:44:50.002408 30701 net.cpp:122] Setting up layer_256_4_conv3
I0526 15:44:50.002429 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.002432 30701 net.cpp:137] Memory required for data: 992481340
I0526 15:44:50.002440 30701 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0526 15:44:50.002454 30701 net.cpp:84] Creating Layer layer_256_4_sum
I0526 15:44:50.002462 30701 net.cpp:406] layer_256_4_sum <- layer_256_4_conv3
I0526 15:44:50.002472 30701 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0526 15:44:50.002485 30701 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0526 15:44:50.002528 30701 net.cpp:122] Setting up layer_256_4_sum
I0526 15:44:50.002539 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.002543 30701 net.cpp:137] Memory required for data: 996495420
I0526 15:44:50.002547 30701 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:50.002553 30701 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:50.002568 30701 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0526 15:44:50.002574 30701 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0526 15:44:50.002584 30701 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0526 15:44:50.002636 30701 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0526 15:44:50.002645 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.002650 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.002653 30701 net.cpp:137] Memory required for data: 1004523580
I0526 15:44:50.002656 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0526 15:44:50.002665 30701 net.cpp:84] Creating Layer layer_256_5_bn1
I0526 15:44:50.002670 30701 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0526 15:44:50.002676 30701 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0526 15:44:50.002946 30701 net.cpp:122] Setting up layer_256_5_bn1
I0526 15:44:50.002956 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.002959 30701 net.cpp:137] Memory required for data: 1008537660
I0526 15:44:50.002967 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0526 15:44:50.002975 30701 net.cpp:84] Creating Layer layer_256_5_scale1
I0526 15:44:50.002979 30701 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0526 15:44:50.002985 30701 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0526 15:44:50.003041 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0526 15:44:50.003192 30701 net.cpp:122] Setting up layer_256_5_scale1
I0526 15:44:50.003201 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.003204 30701 net.cpp:137] Memory required for data: 1012551740
I0526 15:44:50.003211 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0526 15:44:50.003217 30701 net.cpp:84] Creating Layer layer_256_5_relu1
I0526 15:44:50.003221 30701 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0526 15:44:50.003229 30701 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0526 15:44:50.003399 30701 net.cpp:122] Setting up layer_256_5_relu1
I0526 15:44:50.003410 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.003414 30701 net.cpp:137] Memory required for data: 1016565820
I0526 15:44:50.003417 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0526 15:44:50.003427 30701 net.cpp:84] Creating Layer layer_256_5_conv1
I0526 15:44:50.003432 30701 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0526 15:44:50.003437 30701 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0526 15:44:50.007359 30701 net.cpp:122] Setting up layer_256_5_conv1
I0526 15:44:50.007372 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.007375 30701 net.cpp:137] Memory required for data: 1017569340
I0526 15:44:50.007381 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0526 15:44:50.007390 30701 net.cpp:84] Creating Layer layer_256_5_bn2
I0526 15:44:50.007393 30701 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0526 15:44:50.007400 30701 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0526 15:44:50.007652 30701 net.cpp:122] Setting up layer_256_5_bn2
I0526 15:44:50.007660 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.007664 30701 net.cpp:137] Memory required for data: 1018572860
I0526 15:44:50.007671 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0526 15:44:50.007678 30701 net.cpp:84] Creating Layer layer_256_5_scale2
I0526 15:44:50.007683 30701 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0526 15:44:50.007688 30701 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0526 15:44:50.007740 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0526 15:44:50.007887 30701 net.cpp:122] Setting up layer_256_5_scale2
I0526 15:44:50.007896 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.007908 30701 net.cpp:137] Memory required for data: 1019576380
I0526 15:44:50.007915 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0526 15:44:50.007920 30701 net.cpp:84] Creating Layer layer_256_5_relu2
I0526 15:44:50.007926 30701 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0526 15:44:50.007931 30701 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0526 15:44:50.008108 30701 net.cpp:122] Setting up layer_256_5_relu2
I0526 15:44:50.008118 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.008121 30701 net.cpp:137] Memory required for data: 1020579900
I0526 15:44:50.008126 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0526 15:44:50.008136 30701 net.cpp:84] Creating Layer layer_256_5_conv2
I0526 15:44:50.008139 30701 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0526 15:44:50.008147 30701 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0526 15:44:50.016696 30701 net.cpp:122] Setting up layer_256_5_conv2
I0526 15:44:50.016710 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.016715 30701 net.cpp:137] Memory required for data: 1021583420
I0526 15:44:50.016719 30701 layer_factory.hpp:77] Creating layer layer_256_5_bn3
I0526 15:44:50.016728 30701 net.cpp:84] Creating Layer layer_256_5_bn3
I0526 15:44:50.016733 30701 net.cpp:406] layer_256_5_bn3 <- layer_256_5_conv2
I0526 15:44:50.016739 30701 net.cpp:367] layer_256_5_bn3 -> layer_256_5_conv2 (in-place)
I0526 15:44:50.016997 30701 net.cpp:122] Setting up layer_256_5_bn3
I0526 15:44:50.017006 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.017010 30701 net.cpp:137] Memory required for data: 1022586940
I0526 15:44:50.017017 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0526 15:44:50.017024 30701 net.cpp:84] Creating Layer layer_256_5_scale3
I0526 15:44:50.017029 30701 net.cpp:406] layer_256_5_scale3 <- layer_256_5_conv2
I0526 15:44:50.017035 30701 net.cpp:367] layer_256_5_scale3 -> layer_256_5_conv2 (in-place)
I0526 15:44:50.017089 30701 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0526 15:44:50.017236 30701 net.cpp:122] Setting up layer_256_5_scale3
I0526 15:44:50.017246 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.017249 30701 net.cpp:137] Memory required for data: 1023590460
I0526 15:44:50.017254 30701 layer_factory.hpp:77] Creating layer layer_256_5_relu3
I0526 15:44:50.017261 30701 net.cpp:84] Creating Layer layer_256_5_relu3
I0526 15:44:50.017266 30701 net.cpp:406] layer_256_5_relu3 <- layer_256_5_conv2
I0526 15:44:50.017271 30701 net.cpp:367] layer_256_5_relu3 -> layer_256_5_conv2 (in-place)
I0526 15:44:50.017446 30701 net.cpp:122] Setting up layer_256_5_relu3
I0526 15:44:50.017455 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.017458 30701 net.cpp:137] Memory required for data: 1024593980
I0526 15:44:50.017462 30701 layer_factory.hpp:77] Creating layer layer_256_5_conv3
I0526 15:44:50.017472 30701 net.cpp:84] Creating Layer layer_256_5_conv3
I0526 15:44:50.017477 30701 net.cpp:406] layer_256_5_conv3 <- layer_256_5_conv2
I0526 15:44:50.017483 30701 net.cpp:380] layer_256_5_conv3 -> layer_256_5_conv3
I0526 15:44:50.022186 30701 net.cpp:122] Setting up layer_256_5_conv3
I0526 15:44:50.022202 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022207 30701 net.cpp:137] Memory required for data: 1028608060
I0526 15:44:50.022212 30701 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0526 15:44:50.022218 30701 net.cpp:84] Creating Layer layer_256_5_sum
I0526 15:44:50.022223 30701 net.cpp:406] layer_256_5_sum <- layer_256_5_conv3
I0526 15:44:50.022228 30701 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0526 15:44:50.022233 30701 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0526 15:44:50.022270 30701 net.cpp:122] Setting up layer_256_5_sum
I0526 15:44:50.022279 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022284 30701 net.cpp:137] Memory required for data: 1032622140
I0526 15:44:50.022286 30701 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:50.022302 30701 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:50.022306 30701 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0526 15:44:50.022312 30701 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0526 15:44:50.022321 30701 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0526 15:44:50.022373 30701 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0526 15:44:50.022382 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022387 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022392 30701 net.cpp:137] Memory required for data: 1040650300
I0526 15:44:50.022394 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0526 15:44:50.022402 30701 net.cpp:84] Creating Layer layer_256_6_bn1
I0526 15:44:50.022406 30701 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0526 15:44:50.022413 30701 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0526 15:44:50.022680 30701 net.cpp:122] Setting up layer_256_6_bn1
I0526 15:44:50.022688 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022692 30701 net.cpp:137] Memory required for data: 1044664380
I0526 15:44:50.022699 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0526 15:44:50.022706 30701 net.cpp:84] Creating Layer layer_256_6_scale1
I0526 15:44:50.022711 30701 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0526 15:44:50.022716 30701 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0526 15:44:50.022768 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0526 15:44:50.022922 30701 net.cpp:122] Setting up layer_256_6_scale1
I0526 15:44:50.022931 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.022935 30701 net.cpp:137] Memory required for data: 1048678460
I0526 15:44:50.022941 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0526 15:44:50.022948 30701 net.cpp:84] Creating Layer layer_256_6_relu1
I0526 15:44:50.022951 30701 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0526 15:44:50.022958 30701 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0526 15:44:50.023129 30701 net.cpp:122] Setting up layer_256_6_relu1
I0526 15:44:50.023140 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.023144 30701 net.cpp:137] Memory required for data: 1052692540
I0526 15:44:50.023149 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0526 15:44:50.023157 30701 net.cpp:84] Creating Layer layer_256_6_conv1
I0526 15:44:50.023161 30701 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0526 15:44:50.023167 30701 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0526 15:44:50.027091 30701 net.cpp:122] Setting up layer_256_6_conv1
I0526 15:44:50.027104 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.027108 30701 net.cpp:137] Memory required for data: 1053696060
I0526 15:44:50.027114 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0526 15:44:50.027122 30701 net.cpp:84] Creating Layer layer_256_6_bn2
I0526 15:44:50.027127 30701 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0526 15:44:50.027132 30701 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0526 15:44:50.027385 30701 net.cpp:122] Setting up layer_256_6_bn2
I0526 15:44:50.027395 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.027398 30701 net.cpp:137] Memory required for data: 1054699580
I0526 15:44:50.027405 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0526 15:44:50.027412 30701 net.cpp:84] Creating Layer layer_256_6_scale2
I0526 15:44:50.027416 30701 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0526 15:44:50.027421 30701 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0526 15:44:50.027477 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0526 15:44:50.027626 30701 net.cpp:122] Setting up layer_256_6_scale2
I0526 15:44:50.027643 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.027647 30701 net.cpp:137] Memory required for data: 1055703100
I0526 15:44:50.027653 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0526 15:44:50.027659 30701 net.cpp:84] Creating Layer layer_256_6_relu2
I0526 15:44:50.027663 30701 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0526 15:44:50.027669 30701 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0526 15:44:50.028409 30701 net.cpp:122] Setting up layer_256_6_relu2
I0526 15:44:50.028419 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.028424 30701 net.cpp:137] Memory required for data: 1056706620
I0526 15:44:50.028427 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0526 15:44:50.028439 30701 net.cpp:84] Creating Layer layer_256_6_conv2
I0526 15:44:50.028443 30701 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0526 15:44:50.028450 30701 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0526 15:44:50.036540 30701 net.cpp:122] Setting up layer_256_6_conv2
I0526 15:44:50.036561 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.036563 30701 net.cpp:137] Memory required for data: 1057710140
I0526 15:44:50.036571 30701 layer_factory.hpp:77] Creating layer layer_256_6_bn3
I0526 15:44:50.036581 30701 net.cpp:84] Creating Layer layer_256_6_bn3
I0526 15:44:50.036586 30701 net.cpp:406] layer_256_6_bn3 <- layer_256_6_conv2
I0526 15:44:50.036594 30701 net.cpp:367] layer_256_6_bn3 -> layer_256_6_conv2 (in-place)
I0526 15:44:50.036877 30701 net.cpp:122] Setting up layer_256_6_bn3
I0526 15:44:50.036890 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.036896 30701 net.cpp:137] Memory required for data: 1058713660
I0526 15:44:50.036908 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0526 15:44:50.036931 30701 net.cpp:84] Creating Layer layer_256_6_scale3
I0526 15:44:50.036936 30701 net.cpp:406] layer_256_6_scale3 <- layer_256_6_conv2
I0526 15:44:50.036943 30701 net.cpp:367] layer_256_6_scale3 -> layer_256_6_conv2 (in-place)
I0526 15:44:50.037003 30701 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0526 15:44:50.037189 30701 net.cpp:122] Setting up layer_256_6_scale3
I0526 15:44:50.037199 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.037201 30701 net.cpp:137] Memory required for data: 1059717180
I0526 15:44:50.037220 30701 layer_factory.hpp:77] Creating layer layer_256_6_relu3
I0526 15:44:50.037226 30701 net.cpp:84] Creating Layer layer_256_6_relu3
I0526 15:44:50.037230 30701 net.cpp:406] layer_256_6_relu3 <- layer_256_6_conv2
I0526 15:44:50.037236 30701 net.cpp:367] layer_256_6_relu3 -> layer_256_6_conv2 (in-place)
I0526 15:44:50.037966 30701 net.cpp:122] Setting up layer_256_6_relu3
I0526 15:44:50.037976 30701 net.cpp:129] Top shape: 5 256 14 14 (250880)
I0526 15:44:50.037981 30701 net.cpp:137] Memory required for data: 1060720700
I0526 15:44:50.037997 30701 layer_factory.hpp:77] Creating layer layer_256_6_conv3
I0526 15:44:50.038008 30701 net.cpp:84] Creating Layer layer_256_6_conv3
I0526 15:44:50.038013 30701 net.cpp:406] layer_256_6_conv3 <- layer_256_6_conv2
I0526 15:44:50.038022 30701 net.cpp:380] layer_256_6_conv3 -> layer_256_6_conv3
I0526 15:44:50.042680 30701 net.cpp:122] Setting up layer_256_6_conv3
I0526 15:44:50.042692 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.042696 30701 net.cpp:137] Memory required for data: 1064734780
I0526 15:44:50.042714 30701 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0526 15:44:50.042722 30701 net.cpp:84] Creating Layer layer_256_6_sum
I0526 15:44:50.042727 30701 net.cpp:406] layer_256_6_sum <- layer_256_6_conv3
I0526 15:44:50.042732 30701 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0526 15:44:50.042737 30701 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0526 15:44:50.042775 30701 net.cpp:122] Setting up layer_256_6_sum
I0526 15:44:50.042784 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.042788 30701 net.cpp:137] Memory required for data: 1068748860
I0526 15:44:50.042803 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0526 15:44:50.042809 30701 net.cpp:84] Creating Layer layer_512_1_bn1
I0526 15:44:50.042814 30701 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0526 15:44:50.042821 30701 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0526 15:44:50.043098 30701 net.cpp:122] Setting up layer_512_1_bn1
I0526 15:44:50.043108 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.043112 30701 net.cpp:137] Memory required for data: 1072762940
I0526 15:44:50.043119 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0526 15:44:50.043128 30701 net.cpp:84] Creating Layer layer_512_1_scale1
I0526 15:44:50.043131 30701 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0526 15:44:50.043136 30701 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0526 15:44:50.043189 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0526 15:44:50.043344 30701 net.cpp:122] Setting up layer_512_1_scale1
I0526 15:44:50.043354 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.043357 30701 net.cpp:137] Memory required for data: 1076777020
I0526 15:44:50.043364 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0526 15:44:50.043371 30701 net.cpp:84] Creating Layer layer_512_1_relu1
I0526 15:44:50.043376 30701 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0526 15:44:50.043380 30701 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0526 15:44:50.043551 30701 net.cpp:122] Setting up layer_512_1_relu1
I0526 15:44:50.043561 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.043565 30701 net.cpp:137] Memory required for data: 1080791100
I0526 15:44:50.043568 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:50.043576 30701 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:50.043582 30701 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0526 15:44:50.043588 30701 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0526 15:44:50.043596 30701 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0526 15:44:50.043651 30701 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0526 15:44:50.043659 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.043664 30701 net.cpp:129] Top shape: 5 1024 14 14 (1003520)
I0526 15:44:50.043668 30701 net.cpp:137] Memory required for data: 1088819260
I0526 15:44:50.043670 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0526 15:44:50.043680 30701 net.cpp:84] Creating Layer layer_512_1_conv1
I0526 15:44:50.043684 30701 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0526 15:44:50.043691 30701 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0526 15:44:50.050987 30701 net.cpp:122] Setting up layer_512_1_conv1
I0526 15:44:50.051002 30701 net.cpp:129] Top shape: 5 512 14 14 (501760)
I0526 15:44:50.051005 30701 net.cpp:137] Memory required for data: 1090826300
I0526 15:44:50.051012 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0526 15:44:50.051019 30701 net.cpp:84] Creating Layer layer_512_1_bn2
I0526 15:44:50.051024 30701 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0526 15:44:50.051031 30701 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0526 15:44:50.051295 30701 net.cpp:122] Setting up layer_512_1_bn2
I0526 15:44:50.051304 30701 net.cpp:129] Top shape: 5 512 14 14 (501760)
I0526 15:44:50.051308 30701 net.cpp:137] Memory required for data: 1092833340
I0526 15:44:50.051316 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0526 15:44:50.051323 30701 net.cpp:84] Creating Layer layer_512_1_scale2
I0526 15:44:50.051327 30701 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0526 15:44:50.051332 30701 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0526 15:44:50.051383 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0526 15:44:50.051550 30701 net.cpp:122] Setting up layer_512_1_scale2
I0526 15:44:50.051559 30701 net.cpp:129] Top shape: 5 512 14 14 (501760)
I0526 15:44:50.051563 30701 net.cpp:137] Memory required for data: 1094840380
I0526 15:44:50.051569 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0526 15:44:50.051576 30701 net.cpp:84] Creating Layer layer_512_1_relu2
I0526 15:44:50.051580 30701 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0526 15:44:50.051585 30701 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0526 15:44:50.051760 30701 net.cpp:122] Setting up layer_512_1_relu2
I0526 15:44:50.051771 30701 net.cpp:129] Top shape: 5 512 14 14 (501760)
I0526 15:44:50.051775 30701 net.cpp:137] Memory required for data: 1096847420
I0526 15:44:50.051779 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0526 15:44:50.051789 30701 net.cpp:84] Creating Layer layer_512_1_conv2
I0526 15:44:50.051792 30701 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0526 15:44:50.051800 30701 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0526 15:44:50.079375 30701 net.cpp:122] Setting up layer_512_1_conv2
I0526 15:44:50.079404 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.079408 30701 net.cpp:137] Memory required for data: 1097349180
I0526 15:44:50.079428 30701 layer_factory.hpp:77] Creating layer layer_512_1_bn3
I0526 15:44:50.079440 30701 net.cpp:84] Creating Layer layer_512_1_bn3
I0526 15:44:50.079447 30701 net.cpp:406] layer_512_1_bn3 <- layer_512_1_conv2
I0526 15:44:50.079455 30701 net.cpp:367] layer_512_1_bn3 -> layer_512_1_conv2 (in-place)
I0526 15:44:50.079748 30701 net.cpp:122] Setting up layer_512_1_bn3
I0526 15:44:50.079758 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.079761 30701 net.cpp:137] Memory required for data: 1097850940
I0526 15:44:50.079805 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0526 15:44:50.079815 30701 net.cpp:84] Creating Layer layer_512_1_scale3
I0526 15:44:50.079819 30701 net.cpp:406] layer_512_1_scale3 <- layer_512_1_conv2
I0526 15:44:50.079825 30701 net.cpp:367] layer_512_1_scale3 -> layer_512_1_conv2 (in-place)
I0526 15:44:50.079885 30701 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0526 15:44:50.080065 30701 net.cpp:122] Setting up layer_512_1_scale3
I0526 15:44:50.080073 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.080076 30701 net.cpp:137] Memory required for data: 1098352700
I0526 15:44:50.080094 30701 layer_factory.hpp:77] Creating layer layer_512_1_relu3
I0526 15:44:50.080101 30701 net.cpp:84] Creating Layer layer_512_1_relu3
I0526 15:44:50.080106 30701 net.cpp:406] layer_512_1_relu3 <- layer_512_1_conv2
I0526 15:44:50.080112 30701 net.cpp:367] layer_512_1_relu3 -> layer_512_1_conv2 (in-place)
I0526 15:44:50.080292 30701 net.cpp:122] Setting up layer_512_1_relu3
I0526 15:44:50.080303 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.080307 30701 net.cpp:137] Memory required for data: 1098854460
I0526 15:44:50.080312 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv3
I0526 15:44:50.080323 30701 net.cpp:84] Creating Layer layer_512_1_conv3
I0526 15:44:50.080328 30701 net.cpp:406] layer_512_1_conv3 <- layer_512_1_conv2
I0526 15:44:50.080334 30701 net.cpp:380] layer_512_1_conv3 -> layer_512_1_conv3
I0526 15:44:50.093318 30701 net.cpp:122] Setting up layer_512_1_conv3
I0526 15:44:50.093334 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.093338 30701 net.cpp:137] Memory required for data: 1100861500
I0526 15:44:50.093343 30701 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0526 15:44:50.093356 30701 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0526 15:44:50.093361 30701 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0526 15:44:50.093369 30701 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0526 15:44:50.118181 30701 net.cpp:122] Setting up layer_512_1_conv_expand
I0526 15:44:50.118211 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.118234 30701 net.cpp:137] Memory required for data: 1102868540
I0526 15:44:50.118244 30701 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0526 15:44:50.118255 30701 net.cpp:84] Creating Layer layer_512_1_sum
I0526 15:44:50.118261 30701 net.cpp:406] layer_512_1_sum <- layer_512_1_conv3
I0526 15:44:50.118268 30701 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0526 15:44:50.118278 30701 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0526 15:44:50.118330 30701 net.cpp:122] Setting up layer_512_1_sum
I0526 15:44:50.118340 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.118343 30701 net.cpp:137] Memory required for data: 1104875580
I0526 15:44:50.118346 30701 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:50.118353 30701 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:50.118357 30701 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0526 15:44:50.118363 30701 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0526 15:44:50.118372 30701 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0526 15:44:50.118436 30701 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0526 15:44:50.118445 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.118450 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.118453 30701 net.cpp:137] Memory required for data: 1108889660
I0526 15:44:50.118456 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0526 15:44:50.118465 30701 net.cpp:84] Creating Layer layer_512_2_bn1
I0526 15:44:50.118469 30701 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0526 15:44:50.118476 30701 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0526 15:44:50.118788 30701 net.cpp:122] Setting up layer_512_2_bn1
I0526 15:44:50.118798 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.118801 30701 net.cpp:137] Memory required for data: 1110896700
I0526 15:44:50.118820 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0526 15:44:50.118829 30701 net.cpp:84] Creating Layer layer_512_2_scale1
I0526 15:44:50.118834 30701 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0526 15:44:50.118840 30701 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0526 15:44:50.118914 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0526 15:44:50.119104 30701 net.cpp:122] Setting up layer_512_2_scale1
I0526 15:44:50.119114 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.119128 30701 net.cpp:137] Memory required for data: 1112903740
I0526 15:44:50.119137 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0526 15:44:50.119143 30701 net.cpp:84] Creating Layer layer_512_2_relu1
I0526 15:44:50.119148 30701 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0526 15:44:50.119153 30701 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0526 15:44:50.119335 30701 net.cpp:122] Setting up layer_512_2_relu1
I0526 15:44:50.119345 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.119349 30701 net.cpp:137] Memory required for data: 1114910780
I0526 15:44:50.119352 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0526 15:44:50.119364 30701 net.cpp:84] Creating Layer layer_512_2_conv1
I0526 15:44:50.119369 30701 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0526 15:44:50.119376 30701 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0526 15:44:50.132408 30701 net.cpp:122] Setting up layer_512_2_conv1
I0526 15:44:50.132426 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.132428 30701 net.cpp:137] Memory required for data: 1115412540
I0526 15:44:50.132434 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0526 15:44:50.132444 30701 net.cpp:84] Creating Layer layer_512_2_bn2
I0526 15:44:50.132449 30701 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0526 15:44:50.132455 30701 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0526 15:44:50.132745 30701 net.cpp:122] Setting up layer_512_2_bn2
I0526 15:44:50.132755 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.132758 30701 net.cpp:137] Memory required for data: 1115914300
I0526 15:44:50.132766 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0526 15:44:50.132773 30701 net.cpp:84] Creating Layer layer_512_2_scale2
I0526 15:44:50.132777 30701 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0526 15:44:50.132783 30701 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0526 15:44:50.132840 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0526 15:44:50.133003 30701 net.cpp:122] Setting up layer_512_2_scale2
I0526 15:44:50.133013 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.133016 30701 net.cpp:137] Memory required for data: 1116416060
I0526 15:44:50.133023 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0526 15:44:50.133028 30701 net.cpp:84] Creating Layer layer_512_2_relu2
I0526 15:44:50.133033 30701 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0526 15:44:50.133038 30701 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0526 15:44:50.133214 30701 net.cpp:122] Setting up layer_512_2_relu2
I0526 15:44:50.133225 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.133229 30701 net.cpp:137] Memory required for data: 1116917820
I0526 15:44:50.133232 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0526 15:44:50.133242 30701 net.cpp:84] Creating Layer layer_512_2_conv2
I0526 15:44:50.133246 30701 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0526 15:44:50.133254 30701 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0526 15:44:50.161056 30701 net.cpp:122] Setting up layer_512_2_conv2
I0526 15:44:50.161097 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.161101 30701 net.cpp:137] Memory required for data: 1117419580
I0526 15:44:50.161110 30701 layer_factory.hpp:77] Creating layer layer_512_2_bn3
I0526 15:44:50.161121 30701 net.cpp:84] Creating Layer layer_512_2_bn3
I0526 15:44:50.161126 30701 net.cpp:406] layer_512_2_bn3 <- layer_512_2_conv2
I0526 15:44:50.161135 30701 net.cpp:367] layer_512_2_bn3 -> layer_512_2_conv2 (in-place)
I0526 15:44:50.161439 30701 net.cpp:122] Setting up layer_512_2_bn3
I0526 15:44:50.161448 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.161451 30701 net.cpp:137] Memory required for data: 1117921340
I0526 15:44:50.161458 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0526 15:44:50.161468 30701 net.cpp:84] Creating Layer layer_512_2_scale3
I0526 15:44:50.161471 30701 net.cpp:406] layer_512_2_scale3 <- layer_512_2_conv2
I0526 15:44:50.161475 30701 net.cpp:367] layer_512_2_scale3 -> layer_512_2_conv2 (in-place)
I0526 15:44:50.161566 30701 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0526 15:44:50.161768 30701 net.cpp:122] Setting up layer_512_2_scale3
I0526 15:44:50.161778 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.161792 30701 net.cpp:137] Memory required for data: 1118423100
I0526 15:44:50.161801 30701 layer_factory.hpp:77] Creating layer layer_512_2_relu3
I0526 15:44:50.161810 30701 net.cpp:84] Creating Layer layer_512_2_relu3
I0526 15:44:50.161814 30701 net.cpp:406] layer_512_2_relu3 <- layer_512_2_conv2
I0526 15:44:50.161819 30701 net.cpp:367] layer_512_2_relu3 -> layer_512_2_conv2 (in-place)
I0526 15:44:50.162570 30701 net.cpp:122] Setting up layer_512_2_relu3
I0526 15:44:50.162582 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.162586 30701 net.cpp:137] Memory required for data: 1118924860
I0526 15:44:50.162601 30701 layer_factory.hpp:77] Creating layer layer_512_2_conv3
I0526 15:44:50.162614 30701 net.cpp:84] Creating Layer layer_512_2_conv3
I0526 15:44:50.162619 30701 net.cpp:406] layer_512_2_conv3 <- layer_512_2_conv2
I0526 15:44:50.162626 30701 net.cpp:380] layer_512_2_conv3 -> layer_512_2_conv3
I0526 15:44:50.175820 30701 net.cpp:122] Setting up layer_512_2_conv3
I0526 15:44:50.175866 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.175870 30701 net.cpp:137] Memory required for data: 1120931900
I0526 15:44:50.175890 30701 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0526 15:44:50.175902 30701 net.cpp:84] Creating Layer layer_512_2_sum
I0526 15:44:50.175909 30701 net.cpp:406] layer_512_2_sum <- layer_512_2_conv3
I0526 15:44:50.175916 30701 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0526 15:44:50.175922 30701 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0526 15:44:50.175971 30701 net.cpp:122] Setting up layer_512_2_sum
I0526 15:44:50.175979 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.175982 30701 net.cpp:137] Memory required for data: 1122938940
I0526 15:44:50.175985 30701 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:50.175992 30701 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:50.175995 30701 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0526 15:44:50.176002 30701 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0526 15:44:50.176009 30701 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0526 15:44:50.176064 30701 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0526 15:44:50.176072 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.176077 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.176080 30701 net.cpp:137] Memory required for data: 1126953020
I0526 15:44:50.176084 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0526 15:44:50.176090 30701 net.cpp:84] Creating Layer layer_512_3_bn1
I0526 15:44:50.176093 30701 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0526 15:44:50.176100 30701 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0526 15:44:50.176398 30701 net.cpp:122] Setting up layer_512_3_bn1
I0526 15:44:50.176409 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.176411 30701 net.cpp:137] Memory required for data: 1128960060
I0526 15:44:50.176419 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0526 15:44:50.176429 30701 net.cpp:84] Creating Layer layer_512_3_scale1
I0526 15:44:50.176434 30701 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0526 15:44:50.176439 30701 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0526 15:44:50.176498 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0526 15:44:50.176666 30701 net.cpp:122] Setting up layer_512_3_scale1
I0526 15:44:50.176674 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.176678 30701 net.cpp:137] Memory required for data: 1130967100
I0526 15:44:50.176684 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0526 15:44:50.176692 30701 net.cpp:84] Creating Layer layer_512_3_relu1
I0526 15:44:50.176697 30701 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0526 15:44:50.176702 30701 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0526 15:44:50.176880 30701 net.cpp:122] Setting up layer_512_3_relu1
I0526 15:44:50.176890 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.176894 30701 net.cpp:137] Memory required for data: 1132974140
I0526 15:44:50.176898 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0526 15:44:50.176908 30701 net.cpp:84] Creating Layer layer_512_3_conv1
I0526 15:44:50.176913 30701 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0526 15:44:50.176920 30701 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0526 15:44:50.190547 30701 net.cpp:122] Setting up layer_512_3_conv1
I0526 15:44:50.190565 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.190569 30701 net.cpp:137] Memory required for data: 1133475900
I0526 15:44:50.190574 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0526 15:44:50.190583 30701 net.cpp:84] Creating Layer layer_512_3_bn2
I0526 15:44:50.190588 30701 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0526 15:44:50.190605 30701 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0526 15:44:50.190886 30701 net.cpp:122] Setting up layer_512_3_bn2
I0526 15:44:50.190894 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.190898 30701 net.cpp:137] Memory required for data: 1133977660
I0526 15:44:50.190907 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0526 15:44:50.190917 30701 net.cpp:84] Creating Layer layer_512_3_scale2
I0526 15:44:50.190922 30701 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0526 15:44:50.190927 30701 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0526 15:44:50.190980 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0526 15:44:50.191148 30701 net.cpp:122] Setting up layer_512_3_scale2
I0526 15:44:50.191156 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.191160 30701 net.cpp:137] Memory required for data: 1134479420
I0526 15:44:50.191166 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0526 15:44:50.191174 30701 net.cpp:84] Creating Layer layer_512_3_relu2
I0526 15:44:50.191177 30701 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0526 15:44:50.191184 30701 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0526 15:44:50.191365 30701 net.cpp:122] Setting up layer_512_3_relu2
I0526 15:44:50.191375 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.191380 30701 net.cpp:137] Memory required for data: 1134981180
I0526 15:44:50.191382 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0526 15:44:50.191392 30701 net.cpp:84] Creating Layer layer_512_3_conv2
I0526 15:44:50.191397 30701 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0526 15:44:50.191404 30701 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0526 15:44:50.219169 30701 net.cpp:122] Setting up layer_512_3_conv2
I0526 15:44:50.219199 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.219203 30701 net.cpp:137] Memory required for data: 1135482940
I0526 15:44:50.219213 30701 layer_factory.hpp:77] Creating layer layer_512_3_bn3
I0526 15:44:50.219223 30701 net.cpp:84] Creating Layer layer_512_3_bn3
I0526 15:44:50.219230 30701 net.cpp:406] layer_512_3_bn3 <- layer_512_3_conv2
I0526 15:44:50.219240 30701 net.cpp:367] layer_512_3_bn3 -> layer_512_3_conv2 (in-place)
I0526 15:44:50.219544 30701 net.cpp:122] Setting up layer_512_3_bn3
I0526 15:44:50.219553 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.219558 30701 net.cpp:137] Memory required for data: 1135984700
I0526 15:44:50.219576 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0526 15:44:50.219585 30701 net.cpp:84] Creating Layer layer_512_3_scale3
I0526 15:44:50.219590 30701 net.cpp:406] layer_512_3_scale3 <- layer_512_3_conv2
I0526 15:44:50.219595 30701 net.cpp:367] layer_512_3_scale3 -> layer_512_3_conv2 (in-place)
I0526 15:44:50.219660 30701 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0526 15:44:50.219830 30701 net.cpp:122] Setting up layer_512_3_scale3
I0526 15:44:50.219838 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.219842 30701 net.cpp:137] Memory required for data: 1136486460
I0526 15:44:50.219848 30701 layer_factory.hpp:77] Creating layer layer_512_3_relu3
I0526 15:44:50.219857 30701 net.cpp:84] Creating Layer layer_512_3_relu3
I0526 15:44:50.219861 30701 net.cpp:406] layer_512_3_relu3 <- layer_512_3_conv2
I0526 15:44:50.219866 30701 net.cpp:367] layer_512_3_relu3 -> layer_512_3_conv2 (in-place)
I0526 15:44:50.220048 30701 net.cpp:122] Setting up layer_512_3_relu3
I0526 15:44:50.220058 30701 net.cpp:129] Top shape: 5 512 7 7 (125440)
I0526 15:44:50.220062 30701 net.cpp:137] Memory required for data: 1136988220
I0526 15:44:50.220065 30701 layer_factory.hpp:77] Creating layer layer_512_3_conv3
I0526 15:44:50.220077 30701 net.cpp:84] Creating Layer layer_512_3_conv3
I0526 15:44:50.220082 30701 net.cpp:406] layer_512_3_conv3 <- layer_512_3_conv2
I0526 15:44:50.220088 30701 net.cpp:380] layer_512_3_conv3 -> layer_512_3_conv3
I0526 15:44:50.233131 30701 net.cpp:122] Setting up layer_512_3_conv3
I0526 15:44:50.233147 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.233150 30701 net.cpp:137] Memory required for data: 1138995260
I0526 15:44:50.233156 30701 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0526 15:44:50.233165 30701 net.cpp:84] Creating Layer layer_512_3_sum
I0526 15:44:50.233170 30701 net.cpp:406] layer_512_3_sum <- layer_512_3_conv3
I0526 15:44:50.233175 30701 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0526 15:44:50.233182 30701 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0526 15:44:50.233222 30701 net.cpp:122] Setting up layer_512_3_sum
I0526 15:44:50.233232 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.233234 30701 net.cpp:137] Memory required for data: 1141002300
I0526 15:44:50.233238 30701 layer_factory.hpp:77] Creating layer last_bn
I0526 15:44:50.233245 30701 net.cpp:84] Creating Layer last_bn
I0526 15:44:50.233250 30701 net.cpp:406] last_bn <- layer_512_3_sum
I0526 15:44:50.233256 30701 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0526 15:44:50.233543 30701 net.cpp:122] Setting up last_bn
I0526 15:44:50.233552 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.233556 30701 net.cpp:137] Memory required for data: 1143009340
I0526 15:44:50.233563 30701 layer_factory.hpp:77] Creating layer last_scale
I0526 15:44:50.233570 30701 net.cpp:84] Creating Layer last_scale
I0526 15:44:50.233574 30701 net.cpp:406] last_scale <- layer_512_3_sum
I0526 15:44:50.233582 30701 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0526 15:44:50.233638 30701 layer_factory.hpp:77] Creating layer last_scale
I0526 15:44:50.233808 30701 net.cpp:122] Setting up last_scale
I0526 15:44:50.233819 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.233822 30701 net.cpp:137] Memory required for data: 1145016380
I0526 15:44:50.233829 30701 layer_factory.hpp:77] Creating layer last_relu
I0526 15:44:50.233834 30701 net.cpp:84] Creating Layer last_relu
I0526 15:44:50.233839 30701 net.cpp:406] last_relu <- layer_512_3_sum
I0526 15:44:50.233844 30701 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0526 15:44:50.234022 30701 net.cpp:122] Setting up last_relu
I0526 15:44:50.234032 30701 net.cpp:129] Top shape: 5 2048 7 7 (501760)
I0526 15:44:50.234036 30701 net.cpp:137] Memory required for data: 1147023420
I0526 15:44:50.234040 30701 layer_factory.hpp:77] Creating layer global_pool
I0526 15:44:50.234046 30701 net.cpp:84] Creating Layer global_pool
I0526 15:44:50.234050 30701 net.cpp:406] global_pool <- layer_512_3_sum
I0526 15:44:50.234057 30701 net.cpp:380] global_pool -> global_pool
I0526 15:44:50.234861 30701 net.cpp:122] Setting up global_pool
I0526 15:44:50.234874 30701 net.cpp:129] Top shape: 5 2048 1 1 (10240)
I0526 15:44:50.234877 30701 net.cpp:137] Memory required for data: 1147064380
I0526 15:44:50.234881 30701 layer_factory.hpp:77] Creating layer score
I0526 15:44:50.234889 30701 net.cpp:84] Creating Layer score
I0526 15:44:50.234892 30701 net.cpp:406] score <- global_pool
I0526 15:44:50.234899 30701 net.cpp:380] score -> score
I0526 15:44:50.235077 30701 net.cpp:122] Setting up score
I0526 15:44:50.235088 30701 net.cpp:129] Top shape: 5 8 (40)
I0526 15:44:50.235091 30701 net.cpp:137] Memory required for data: 1147064540
I0526 15:44:50.235098 30701 layer_factory.hpp:77] Creating layer score_score_0_split
I0526 15:44:50.235105 30701 net.cpp:84] Creating Layer score_score_0_split
I0526 15:44:50.235108 30701 net.cpp:406] score_score_0_split <- score
I0526 15:44:50.235115 30701 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0526 15:44:50.235121 30701 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0526 15:44:50.235175 30701 net.cpp:122] Setting up score_score_0_split
I0526 15:44:50.235183 30701 net.cpp:129] Top shape: 5 8 (40)
I0526 15:44:50.235188 30701 net.cpp:129] Top shape: 5 8 (40)
I0526 15:44:50.235190 30701 net.cpp:137] Memory required for data: 1147064860
I0526 15:44:50.235193 30701 layer_factory.hpp:77] Creating layer loss
I0526 15:44:50.235213 30701 net.cpp:84] Creating Layer loss
I0526 15:44:50.235218 30701 net.cpp:406] loss <- score_score_0_split_0
I0526 15:44:50.235221 30701 net.cpp:406] loss <- label_data_1_split_0
I0526 15:44:50.235226 30701 net.cpp:380] loss -> loss
I0526 15:44:50.235234 30701 layer_factory.hpp:77] Creating layer loss
I0526 15:44:50.235535 30701 net.cpp:122] Setting up loss
I0526 15:44:50.235544 30701 net.cpp:129] Top shape: (1)
I0526 15:44:50.235548 30701 net.cpp:132]     with loss weight 1
I0526 15:44:50.235560 30701 net.cpp:137] Memory required for data: 1147064864
I0526 15:44:50.235563 30701 layer_factory.hpp:77] Creating layer accuracy
I0526 15:44:50.235570 30701 net.cpp:84] Creating Layer accuracy
I0526 15:44:50.235574 30701 net.cpp:406] accuracy <- score_score_0_split_1
I0526 15:44:50.235579 30701 net.cpp:406] accuracy <- label_data_1_split_1
I0526 15:44:50.235585 30701 net.cpp:380] accuracy -> accuracy
I0526 15:44:50.235595 30701 net.cpp:122] Setting up accuracy
I0526 15:44:50.235600 30701 net.cpp:129] Top shape: (1)
I0526 15:44:50.235604 30701 net.cpp:137] Memory required for data: 1147064868
I0526 15:44:50.235607 30701 net.cpp:200] accuracy does not need backward computation.
I0526 15:44:50.235610 30701 net.cpp:198] loss needs backward computation.
I0526 15:44:50.235615 30701 net.cpp:198] score_score_0_split needs backward computation.
I0526 15:44:50.235618 30701 net.cpp:198] score needs backward computation.
I0526 15:44:50.235621 30701 net.cpp:198] global_pool needs backward computation.
I0526 15:44:50.235625 30701 net.cpp:198] last_relu needs backward computation.
I0526 15:44:50.235627 30701 net.cpp:198] last_scale needs backward computation.
I0526 15:44:50.235630 30701 net.cpp:198] last_bn needs backward computation.
I0526 15:44:50.235632 30701 net.cpp:198] layer_512_3_sum needs backward computation.
I0526 15:44:50.235636 30701 net.cpp:198] layer_512_3_conv3 needs backward computation.
I0526 15:44:50.235640 30701 net.cpp:198] layer_512_3_relu3 needs backward computation.
I0526 15:44:50.235642 30701 net.cpp:198] layer_512_3_scale3 needs backward computation.
I0526 15:44:50.235646 30701 net.cpp:198] layer_512_3_bn3 needs backward computation.
I0526 15:44:50.235648 30701 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0526 15:44:50.235651 30701 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0526 15:44:50.235654 30701 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0526 15:44:50.235657 30701 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0526 15:44:50.235661 30701 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0526 15:44:50.235664 30701 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0526 15:44:50.235667 30701 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0526 15:44:50.235671 30701 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0526 15:44:50.235673 30701 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0526 15:44:50.235677 30701 net.cpp:198] layer_512_2_sum needs backward computation.
I0526 15:44:50.235680 30701 net.cpp:198] layer_512_2_conv3 needs backward computation.
I0526 15:44:50.235684 30701 net.cpp:198] layer_512_2_relu3 needs backward computation.
I0526 15:44:50.235687 30701 net.cpp:198] layer_512_2_scale3 needs backward computation.
I0526 15:44:50.235690 30701 net.cpp:198] layer_512_2_bn3 needs backward computation.
I0526 15:44:50.235693 30701 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0526 15:44:50.235697 30701 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0526 15:44:50.235699 30701 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0526 15:44:50.235702 30701 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0526 15:44:50.235705 30701 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0526 15:44:50.235708 30701 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0526 15:44:50.235713 30701 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0526 15:44:50.235715 30701 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0526 15:44:50.235726 30701 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0526 15:44:50.235730 30701 net.cpp:198] layer_512_1_sum needs backward computation.
I0526 15:44:50.235735 30701 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0526 15:44:50.235739 30701 net.cpp:198] layer_512_1_conv3 needs backward computation.
I0526 15:44:50.235743 30701 net.cpp:198] layer_512_1_relu3 needs backward computation.
I0526 15:44:50.235747 30701 net.cpp:198] layer_512_1_scale3 needs backward computation.
I0526 15:44:50.235750 30701 net.cpp:198] layer_512_1_bn3 needs backward computation.
I0526 15:44:50.235754 30701 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0526 15:44:50.235756 30701 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0526 15:44:50.235759 30701 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0526 15:44:50.235762 30701 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0526 15:44:50.235765 30701 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0526 15:44:50.235769 30701 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0526 15:44:50.235772 30701 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0526 15:44:50.235775 30701 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0526 15:44:50.235779 30701 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0526 15:44:50.235781 30701 net.cpp:198] layer_256_6_sum needs backward computation.
I0526 15:44:50.235785 30701 net.cpp:198] layer_256_6_conv3 needs backward computation.
I0526 15:44:50.235788 30701 net.cpp:198] layer_256_6_relu3 needs backward computation.
I0526 15:44:50.235791 30701 net.cpp:198] layer_256_6_scale3 needs backward computation.
I0526 15:44:50.235795 30701 net.cpp:198] layer_256_6_bn3 needs backward computation.
I0526 15:44:50.235797 30701 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0526 15:44:50.235801 30701 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0526 15:44:50.235805 30701 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0526 15:44:50.235807 30701 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0526 15:44:50.235810 30701 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0526 15:44:50.235813 30701 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0526 15:44:50.235817 30701 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0526 15:44:50.235821 30701 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0526 15:44:50.235823 30701 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0526 15:44:50.235827 30701 net.cpp:198] layer_256_5_sum needs backward computation.
I0526 15:44:50.235832 30701 net.cpp:198] layer_256_5_conv3 needs backward computation.
I0526 15:44:50.235836 30701 net.cpp:198] layer_256_5_relu3 needs backward computation.
I0526 15:44:50.235839 30701 net.cpp:198] layer_256_5_scale3 needs backward computation.
I0526 15:44:50.235842 30701 net.cpp:198] layer_256_5_bn3 needs backward computation.
I0526 15:44:50.235846 30701 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0526 15:44:50.235848 30701 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0526 15:44:50.235852 30701 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0526 15:44:50.235854 30701 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0526 15:44:50.235857 30701 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0526 15:44:50.235862 30701 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0526 15:44:50.235864 30701 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0526 15:44:50.235867 30701 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0526 15:44:50.235870 30701 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0526 15:44:50.235873 30701 net.cpp:198] layer_256_4_sum needs backward computation.
I0526 15:44:50.235877 30701 net.cpp:198] layer_256_4_conv3 needs backward computation.
I0526 15:44:50.235887 30701 net.cpp:198] layer_256_4_relu3 needs backward computation.
I0526 15:44:50.235889 30701 net.cpp:198] layer_256_4_scale3 needs backward computation.
I0526 15:44:50.235893 30701 net.cpp:198] layer_256_4_bn3 needs backward computation.
I0526 15:44:50.235896 30701 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0526 15:44:50.235899 30701 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0526 15:44:50.235903 30701 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0526 15:44:50.235905 30701 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0526 15:44:50.235908 30701 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0526 15:44:50.235913 30701 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0526 15:44:50.235915 30701 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0526 15:44:50.235918 30701 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0526 15:44:50.235921 30701 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0526 15:44:50.235925 30701 net.cpp:198] layer_256_3_sum needs backward computation.
I0526 15:44:50.235929 30701 net.cpp:198] layer_256_3_conv3 needs backward computation.
I0526 15:44:50.235932 30701 net.cpp:198] layer_256_3_relu3 needs backward computation.
I0526 15:44:50.235935 30701 net.cpp:198] layer_256_3_scale3 needs backward computation.
I0526 15:44:50.235939 30701 net.cpp:198] layer_256_3_bn3 needs backward computation.
I0526 15:44:50.235941 30701 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0526 15:44:50.235945 30701 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0526 15:44:50.235954 30701 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0526 15:44:50.235958 30701 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0526 15:44:50.235961 30701 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0526 15:44:50.235965 30701 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0526 15:44:50.235968 30701 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0526 15:44:50.235971 30701 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0526 15:44:50.235975 30701 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0526 15:44:50.235978 30701 net.cpp:198] layer_256_2_sum needs backward computation.
I0526 15:44:50.235983 30701 net.cpp:198] layer_256_2_conv3 needs backward computation.
I0526 15:44:50.235987 30701 net.cpp:198] layer_256_2_relu3 needs backward computation.
I0526 15:44:50.235991 30701 net.cpp:198] layer_256_2_scale3 needs backward computation.
I0526 15:44:50.235993 30701 net.cpp:198] layer_256_2_bn3 needs backward computation.
I0526 15:44:50.235996 30701 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0526 15:44:50.235999 30701 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0526 15:44:50.236002 30701 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0526 15:44:50.236006 30701 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0526 15:44:50.236009 30701 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0526 15:44:50.236012 30701 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0526 15:44:50.236016 30701 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0526 15:44:50.236018 30701 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0526 15:44:50.236022 30701 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0526 15:44:50.236026 30701 net.cpp:198] layer_256_1_sum needs backward computation.
I0526 15:44:50.236029 30701 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0526 15:44:50.236033 30701 net.cpp:198] layer_256_1_conv3 needs backward computation.
I0526 15:44:50.236037 30701 net.cpp:198] layer_256_1_relu3 needs backward computation.
I0526 15:44:50.236039 30701 net.cpp:198] layer_256_1_scale3 needs backward computation.
I0526 15:44:50.236043 30701 net.cpp:198] layer_256_1_bn3 needs backward computation.
I0526 15:44:50.236053 30701 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0526 15:44:50.236057 30701 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0526 15:44:50.236060 30701 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0526 15:44:50.236063 30701 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0526 15:44:50.236066 30701 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0526 15:44:50.236070 30701 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0526 15:44:50.236073 30701 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0526 15:44:50.236076 30701 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0526 15:44:50.236079 30701 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0526 15:44:50.236083 30701 net.cpp:198] layer_128_4_sum needs backward computation.
I0526 15:44:50.236088 30701 net.cpp:198] layer_128_4_conv3 needs backward computation.
I0526 15:44:50.236093 30701 net.cpp:198] layer_128_4_relu3 needs backward computation.
I0526 15:44:50.236095 30701 net.cpp:198] layer_128_4_scale3 needs backward computation.
I0526 15:44:50.236099 30701 net.cpp:198] layer_128_4_bn3 needs backward computation.
I0526 15:44:50.236101 30701 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0526 15:44:50.236105 30701 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0526 15:44:50.236109 30701 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0526 15:44:50.236111 30701 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0526 15:44:50.236114 30701 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0526 15:44:50.236117 30701 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0526 15:44:50.236121 30701 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0526 15:44:50.236124 30701 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0526 15:44:50.236129 30701 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0526 15:44:50.236131 30701 net.cpp:198] layer_128_3_sum needs backward computation.
I0526 15:44:50.236135 30701 net.cpp:198] layer_128_3_conv3 needs backward computation.
I0526 15:44:50.236138 30701 net.cpp:198] layer_128_3_relu3 needs backward computation.
I0526 15:44:50.236141 30701 net.cpp:198] layer_128_3_scale3 needs backward computation.
I0526 15:44:50.236145 30701 net.cpp:198] layer_128_3_bn3 needs backward computation.
I0526 15:44:50.236147 30701 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0526 15:44:50.236150 30701 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0526 15:44:50.236153 30701 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0526 15:44:50.236156 30701 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0526 15:44:50.236160 30701 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0526 15:44:50.236163 30701 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0526 15:44:50.236166 30701 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0526 15:44:50.236169 30701 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0526 15:44:50.236172 30701 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0526 15:44:50.236176 30701 net.cpp:198] layer_128_2_sum needs backward computation.
I0526 15:44:50.236179 30701 net.cpp:198] layer_128_2_conv3 needs backward computation.
I0526 15:44:50.236183 30701 net.cpp:198] layer_128_2_relu3 needs backward computation.
I0526 15:44:50.236186 30701 net.cpp:198] layer_128_2_scale3 needs backward computation.
I0526 15:44:50.236189 30701 net.cpp:198] layer_128_2_bn3 needs backward computation.
I0526 15:44:50.236192 30701 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0526 15:44:50.236196 30701 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0526 15:44:50.236198 30701 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0526 15:44:50.236202 30701 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0526 15:44:50.236204 30701 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0526 15:44:50.236212 30701 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0526 15:44:50.236215 30701 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0526 15:44:50.236218 30701 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0526 15:44:50.236222 30701 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0526 15:44:50.236227 30701 net.cpp:198] layer_128_1_sum needs backward computation.
I0526 15:44:50.236232 30701 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0526 15:44:50.236234 30701 net.cpp:198] layer_128_1_conv3 needs backward computation.
I0526 15:44:50.236238 30701 net.cpp:198] layer_128_1_relu3 needs backward computation.
I0526 15:44:50.236241 30701 net.cpp:198] layer_128_1_scale3 needs backward computation.
I0526 15:44:50.236244 30701 net.cpp:198] layer_128_1_bn3 needs backward computation.
I0526 15:44:50.236248 30701 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0526 15:44:50.236250 30701 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0526 15:44:50.236253 30701 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0526 15:44:50.236256 30701 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0526 15:44:50.236259 30701 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0526 15:44:50.236263 30701 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0526 15:44:50.236266 30701 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0526 15:44:50.236269 30701 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0526 15:44:50.236273 30701 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0526 15:44:50.236275 30701 net.cpp:198] layer_64_3_sum needs backward computation.
I0526 15:44:50.236279 30701 net.cpp:198] layer_64_3_conv3 needs backward computation.
I0526 15:44:50.236284 30701 net.cpp:198] layer_64_3_relu3 needs backward computation.
I0526 15:44:50.236286 30701 net.cpp:198] layer_64_3_scale3 needs backward computation.
I0526 15:44:50.236289 30701 net.cpp:198] layer_64_3_bn3 needs backward computation.
I0526 15:44:50.236292 30701 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0526 15:44:50.236297 30701 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0526 15:44:50.236301 30701 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0526 15:44:50.236304 30701 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0526 15:44:50.236307 30701 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0526 15:44:50.236310 30701 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0526 15:44:50.236313 30701 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0526 15:44:50.236316 30701 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0526 15:44:50.236320 30701 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0526 15:44:50.236323 30701 net.cpp:198] layer_64_2_sum needs backward computation.
I0526 15:44:50.236327 30701 net.cpp:198] layer_64_2_conv3 needs backward computation.
I0526 15:44:50.236330 30701 net.cpp:198] layer_64_2_relu3 needs backward computation.
I0526 15:44:50.236335 30701 net.cpp:198] layer_64_2_scale3 needs backward computation.
I0526 15:44:50.236340 30701 net.cpp:198] layer_64_2_bn3 needs backward computation.
I0526 15:44:50.236342 30701 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0526 15:44:50.236346 30701 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0526 15:44:50.236348 30701 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0526 15:44:50.236351 30701 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0526 15:44:50.236354 30701 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0526 15:44:50.236358 30701 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0526 15:44:50.236361 30701 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0526 15:44:50.236364 30701 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0526 15:44:50.236367 30701 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0526 15:44:50.236377 30701 net.cpp:198] layer_64_1_sum needs backward computation.
I0526 15:44:50.236382 30701 net.cpp:198] layer_64_1_conv_expand needs backward computation.
I0526 15:44:50.236385 30701 net.cpp:198] layer_64_1_conv3 needs backward computation.
I0526 15:44:50.236389 30701 net.cpp:198] layer_64_1_relu3 needs backward computation.
I0526 15:44:50.236392 30701 net.cpp:198] layer_64_1_scale3 needs backward computation.
I0526 15:44:50.236395 30701 net.cpp:198] layer_64_1_bn3 needs backward computation.
I0526 15:44:50.236398 30701 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0526 15:44:50.236402 30701 net.cpp:198] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0526 15:44:50.236407 30701 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0526 15:44:50.236410 30701 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0526 15:44:50.236413 30701 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0526 15:44:50.236416 30701 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0526 15:44:50.236420 30701 net.cpp:198] conv1_pool needs backward computation.
I0526 15:44:50.236423 30701 net.cpp:198] conv1_relu needs backward computation.
I0526 15:44:50.236428 30701 net.cpp:198] conv1_scale needs backward computation.
I0526 15:44:50.236430 30701 net.cpp:198] conv1_bn needs backward computation.
I0526 15:44:50.236435 30701 net.cpp:198] conv1 needs backward computation.
I0526 15:44:50.236438 30701 net.cpp:198] data_scale needs backward computation.
I0526 15:44:50.236443 30701 net.cpp:200] data_bn does not need backward computation.
I0526 15:44:50.236448 30701 net.cpp:200] label_data_1_split does not need backward computation.
I0526 15:44:50.236451 30701 net.cpp:200] data does not need backward computation.
I0526 15:44:50.236454 30701 net.cpp:242] This network produces output accuracy
I0526 15:44:50.236457 30701 net.cpp:242] This network produces output loss
I0526 15:44:50.236574 30701 net.cpp:255] Network initialization done.
I0526 15:44:50.237108 30701 solver.cpp:56] Solver scaffolding done.
I0526 15:44:50.246671 30701 caffe.cpp:248] Starting Optimization
I0526 15:44:50.246690 30701 solver.cpp:272] Solving Pre-ResNet-50
I0526 15:44:50.246692 30701 solver.cpp:273] Learning Rate Policy: poly
I0526 15:44:50.262821 30701 solver.cpp:330] Iteration 0, Testing net (#0)
I0526 15:44:53.354516 30701 solver.cpp:397]     Test net output #0: accuracy = 0.038
I0526 15:44:53.354578 30701 solver.cpp:397]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I0526 15:44:53.710078 30701 solver.cpp:218] Iteration 0 (1.41435e-17 iter/s, 3.4632s/100 iters), loss = 2.07944
I0526 15:44:53.710139 30701 solver.cpp:237]     Train net output #0: loss = 2.07944 (* 1 = 2.07944 loss)
I0526 15:44:53.710175 30701 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0526 15:45:24.428915 30701 solver.cpp:218] Iteration 100 (3.25544 iter/s, 30.7178s/100 iters), loss = 2.25081
I0526 15:45:24.429097 30701 solver.cpp:237]     Train net output #0: loss = 2.25081 (* 1 = 2.25081 loss)
I0526 15:45:24.429116 30701 sgd_solver.cpp:105] Iteration 100, lr = 0.009995
I0526 15:45:55.579936 30701 solver.cpp:218] Iteration 200 (3.21037 iter/s, 31.1491s/100 iters), loss = 2.05924
I0526 15:45:55.580078 30701 solver.cpp:237]     Train net output #0: loss = 2.05924 (* 1 = 2.05924 loss)
I0526 15:45:55.580096 30701 sgd_solver.cpp:105] Iteration 200, lr = 0.00999
I0526 15:46:26.839642 30701 solver.cpp:218] Iteration 300 (3.19912 iter/s, 31.2586s/100 iters), loss = 1.92594
I0526 15:46:26.839830 30701 solver.cpp:237]     Train net output #0: loss = 1.92594 (* 1 = 1.92594 loss)
I0526 15:46:26.839841 30701 sgd_solver.cpp:105] Iteration 300, lr = 0.009985
I0526 15:46:58.023186 30701 solver.cpp:218] Iteration 400 (3.20694 iter/s, 31.1824s/100 iters), loss = 1.93857
I0526 15:46:58.023360 30701 solver.cpp:237]     Train net output #0: loss = 1.93857 (* 1 = 1.93857 loss)
I0526 15:46:58.023375 30701 sgd_solver.cpp:105] Iteration 400, lr = 0.00998
I0526 15:47:29.531705 30701 solver.cpp:218] Iteration 500 (3.17392 iter/s, 31.5068s/100 iters), loss = 2.0217
I0526 15:47:29.531875 30701 solver.cpp:237]     Train net output #0: loss = 2.0217 (* 1 = 2.0217 loss)
I0526 15:47:29.531894 30701 sgd_solver.cpp:105] Iteration 500, lr = 0.009975
I0526 15:47:57.526849 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 15:48:01.829427 30701 solver.cpp:218] Iteration 600 (3.0963 iter/s, 32.2966s/100 iters), loss = 1.64
I0526 15:48:01.829546 30701 solver.cpp:237]     Train net output #0: loss = 1.64 (* 1 = 1.64 loss)
I0526 15:48:01.829563 30701 sgd_solver.cpp:105] Iteration 600, lr = 0.00997
I0526 15:48:33.520360 30701 solver.cpp:218] Iteration 700 (3.15558 iter/s, 31.6898s/100 iters), loss = 1.88596
I0526 15:48:33.520472 30701 solver.cpp:237]     Train net output #0: loss = 1.88596 (* 1 = 1.88596 loss)
I0526 15:48:33.520483 30701 sgd_solver.cpp:105] Iteration 700, lr = 0.009965
I0526 15:49:05.013973 30701 solver.cpp:218] Iteration 800 (3.17542 iter/s, 31.4919s/100 iters), loss = 1.8358
I0526 15:49:05.014082 30701 solver.cpp:237]     Train net output #0: loss = 1.8358 (* 1 = 1.8358 loss)
I0526 15:49:05.014114 30701 sgd_solver.cpp:105] Iteration 800, lr = 0.00996
I0526 15:49:36.285481 30701 solver.cpp:218] Iteration 900 (3.19797 iter/s, 31.2698s/100 iters), loss = 1.97166
I0526 15:49:36.285639 30701 solver.cpp:237]     Train net output #0: loss = 1.97166 (* 1 = 1.97166 loss)
I0526 15:49:36.285657 30701 sgd_solver.cpp:105] Iteration 900, lr = 0.009955
I0526 15:50:07.245645 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_1000.caffemodel
I0526 15:50:07.631472 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_1000.solverstate
I0526 15:50:07.802395 30701 solver.cpp:330] Iteration 1000, Testing net (#0)
I0526 15:50:11.064888 30701 solver.cpp:397]     Test net output #0: accuracy = 0.244
I0526 15:50:11.064954 30701 solver.cpp:397]     Test net output #1: loss = 1.94914 (* 1 = 1.94914 loss)
I0526 15:50:11.377372 30701 solver.cpp:218] Iteration 1000 (2.84975 iter/s, 35.0907s/100 iters), loss = 1.85178
I0526 15:50:11.377439 30701 solver.cpp:237]     Train net output #0: loss = 1.85178 (* 1 = 1.85178 loss)
I0526 15:50:11.377447 30701 sgd_solver.cpp:105] Iteration 1000, lr = 0.00995
I0526 15:50:42.556679 30701 solver.cpp:218] Iteration 1100 (3.20735 iter/s, 31.1784s/100 iters), loss = 1.8954
I0526 15:50:42.556772 30701 solver.cpp:237]     Train net output #0: loss = 1.8954 (* 1 = 1.8954 loss)
I0526 15:50:42.556782 30701 sgd_solver.cpp:105] Iteration 1100, lr = 0.009945
I0526 15:51:06.718734 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 15:51:13.424597 30701 solver.cpp:218] Iteration 1200 (3.23971 iter/s, 30.867s/100 iters), loss = 1.75166
I0526 15:51:13.424777 30701 solver.cpp:237]     Train net output #0: loss = 1.75166 (* 1 = 1.75166 loss)
I0526 15:51:13.424788 30701 sgd_solver.cpp:105] Iteration 1200, lr = 0.00994
I0526 15:51:42.105495 30701 solver.cpp:218] Iteration 1300 (3.48676 iter/s, 28.6799s/100 iters), loss = 1.91576
I0526 15:51:42.105546 30701 solver.cpp:237]     Train net output #0: loss = 1.91576 (* 1 = 1.91576 loss)
I0526 15:51:42.105556 30701 sgd_solver.cpp:105] Iteration 1300, lr = 0.009935
I0526 15:52:10.311928 30701 solver.cpp:218] Iteration 1400 (3.54539 iter/s, 28.2056s/100 iters), loss = 1.73314
I0526 15:52:10.312100 30701 solver.cpp:237]     Train net output #0: loss = 1.73314 (* 1 = 1.73314 loss)
I0526 15:52:10.312111 30701 sgd_solver.cpp:105] Iteration 1400, lr = 0.00993
I0526 15:52:39.559742 30701 solver.cpp:218] Iteration 1500 (3.41917 iter/s, 29.2468s/100 iters), loss = 1.92998
I0526 15:52:39.559808 30701 solver.cpp:237]     Train net output #0: loss = 1.92998 (* 1 = 1.92998 loss)
I0526 15:52:39.559821 30701 sgd_solver.cpp:105] Iteration 1500, lr = 0.009925
I0526 15:53:10.932677 30701 solver.cpp:218] Iteration 1600 (3.18756 iter/s, 31.372s/100 iters), loss = 2.19993
I0526 15:53:10.932833 30701 solver.cpp:237]     Train net output #0: loss = 2.19993 (* 1 = 2.19993 loss)
I0526 15:53:10.932849 30701 sgd_solver.cpp:105] Iteration 1600, lr = 0.00992
I0526 15:53:42.211931 30701 solver.cpp:218] Iteration 1700 (3.19717 iter/s, 31.2776s/100 iters), loss = 1.7376
I0526 15:53:42.212059 30701 solver.cpp:237]     Train net output #0: loss = 1.7376 (* 1 = 1.7376 loss)
I0526 15:53:42.212076 30701 sgd_solver.cpp:105] Iteration 1700, lr = 0.009915
I0526 15:54:03.833463 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 15:54:13.602563 30701 solver.cpp:218] Iteration 1800 (3.18583 iter/s, 31.389s/100 iters), loss = 1.88074
I0526 15:54:13.602694 30701 solver.cpp:237]     Train net output #0: loss = 1.88074 (* 1 = 1.88074 loss)
I0526 15:54:13.602727 30701 sgd_solver.cpp:105] Iteration 1800, lr = 0.00991
I0526 15:54:44.873721 30701 solver.cpp:218] Iteration 1900 (3.19794 iter/s, 31.2702s/100 iters), loss = 1.60604
I0526 15:54:44.873927 30701 solver.cpp:237]     Train net output #0: loss = 1.60604 (* 1 = 1.60604 loss)
I0526 15:54:44.873955 30701 sgd_solver.cpp:105] Iteration 1900, lr = 0.009905
I0526 15:55:15.828898 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_2000.caffemodel
I0526 15:55:16.152863 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_2000.solverstate
I0526 15:55:16.306190 30701 solver.cpp:330] Iteration 2000, Testing net (#0)
I0526 15:55:18.027220 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 15:55:19.550043 30701 solver.cpp:397]     Test net output #0: accuracy = 0.324
I0526 15:55:19.550086 30701 solver.cpp:397]     Test net output #1: loss = 2.06782 (* 1 = 2.06782 loss)
I0526 15:55:19.854074 30701 solver.cpp:218] Iteration 2000 (2.85884 iter/s, 34.9792s/100 iters), loss = 1.8317
I0526 15:55:19.854132 30701 solver.cpp:237]     Train net output #0: loss = 1.8317 (* 1 = 1.8317 loss)
I0526 15:55:19.854157 30701 sgd_solver.cpp:105] Iteration 2000, lr = 0.0099
I0526 15:55:51.004703 30701 solver.cpp:218] Iteration 2100 (3.2103 iter/s, 31.1497s/100 iters), loss = 1.51992
I0526 15:55:51.004840 30701 solver.cpp:237]     Train net output #0: loss = 1.51992 (* 1 = 1.51992 loss)
I0526 15:55:51.004854 30701 sgd_solver.cpp:105] Iteration 2100, lr = 0.009895
I0526 15:56:22.300868 30701 solver.cpp:218] Iteration 2200 (3.19544 iter/s, 31.2946s/100 iters), loss = 1.62153
I0526 15:56:22.300990 30701 solver.cpp:237]     Train net output #0: loss = 1.62153 (* 1 = 1.62153 loss)
I0526 15:56:22.301002 30701 sgd_solver.cpp:105] Iteration 2200, lr = 0.00989
I0526 15:56:53.546615 30701 solver.cpp:218] Iteration 2300 (3.20053 iter/s, 31.2448s/100 iters), loss = 1.7243
I0526 15:56:53.546739 30701 solver.cpp:237]     Train net output #0: loss = 1.7243 (* 1 = 1.7243 loss)
I0526 15:56:53.546756 30701 sgd_solver.cpp:105] Iteration 2300, lr = 0.009885
I0526 15:57:12.439915 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 15:57:25.058812 30701 solver.cpp:218] Iteration 2400 (3.17353 iter/s, 31.5106s/100 iters), loss = 1.7652
I0526 15:57:25.058934 30701 solver.cpp:237]     Train net output #0: loss = 1.7652 (* 1 = 1.7652 loss)
I0526 15:57:25.058950 30701 sgd_solver.cpp:105] Iteration 2400, lr = 0.00988
I0526 15:57:55.703568 30701 solver.cpp:218] Iteration 2500 (3.2633 iter/s, 30.6438s/100 iters), loss = 1.46238
I0526 15:57:55.703744 30701 solver.cpp:237]     Train net output #0: loss = 1.46238 (* 1 = 1.46238 loss)
I0526 15:57:55.703754 30701 sgd_solver.cpp:105] Iteration 2500, lr = 0.009875
I0526 15:58:23.863998 30701 solver.cpp:218] Iteration 2600 (3.5512 iter/s, 28.1595s/100 iters), loss = 1.473
I0526 15:58:23.864044 30701 solver.cpp:237]     Train net output #0: loss = 1.473 (* 1 = 1.473 loss)
I0526 15:58:23.864053 30701 sgd_solver.cpp:105] Iteration 2600, lr = 0.00987
I0526 15:58:52.079695 30701 solver.cpp:218] Iteration 2700 (3.54422 iter/s, 28.2149s/100 iters), loss = 1.43359
I0526 15:58:52.079881 30701 solver.cpp:237]     Train net output #0: loss = 1.43359 (* 1 = 1.43359 loss)
I0526 15:58:52.079892 30701 sgd_solver.cpp:105] Iteration 2700, lr = 0.009865
I0526 15:59:20.618726 30701 solver.cpp:218] Iteration 2800 (3.50409 iter/s, 28.5381s/100 iters), loss = 1.84013
I0526 15:59:20.618796 30701 solver.cpp:237]     Train net output #0: loss = 1.84013 (* 1 = 1.84013 loss)
I0526 15:59:20.618806 30701 sgd_solver.cpp:105] Iteration 2800, lr = 0.00986
I0526 15:59:51.919034 30701 solver.cpp:218] Iteration 2900 (3.19495 iter/s, 31.2994s/100 iters), loss = 1.39234
I0526 15:59:51.919181 30701 solver.cpp:237]     Train net output #0: loss = 1.39234 (* 1 = 1.39234 loss)
I0526 15:59:51.919217 30701 sgd_solver.cpp:105] Iteration 2900, lr = 0.009855
I0526 16:00:07.894870 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:00:22.874469 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_3000.caffemodel
I0526 16:00:23.197197 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_3000.solverstate
I0526 16:00:23.350114 30701 solver.cpp:330] Iteration 3000, Testing net (#0)
I0526 16:00:26.618639 30701 solver.cpp:397]     Test net output #0: accuracy = 0.304
I0526 16:00:26.618685 30701 solver.cpp:397]     Test net output #1: loss = 1.95177 (* 1 = 1.95177 loss)
I0526 16:00:26.926856 30701 solver.cpp:218] Iteration 3000 (2.85659 iter/s, 35.0067s/100 iters), loss = 1.52152
I0526 16:00:26.926919 30701 solver.cpp:237]     Train net output #0: loss = 1.52152 (* 1 = 1.52152 loss)
I0526 16:00:26.926934 30701 sgd_solver.cpp:105] Iteration 3000, lr = 0.00985
I0526 16:00:58.140872 30701 solver.cpp:218] Iteration 3100 (3.20378 iter/s, 31.2131s/100 iters), loss = 1.51161
I0526 16:00:58.141002 30701 solver.cpp:237]     Train net output #0: loss = 1.51161 (* 1 = 1.51161 loss)
I0526 16:00:58.141021 30701 sgd_solver.cpp:105] Iteration 3100, lr = 0.009845
I0526 16:01:29.526455 30701 solver.cpp:218] Iteration 3200 (3.18634 iter/s, 31.384s/100 iters), loss = 1.31405
I0526 16:01:29.526625 30701 solver.cpp:237]     Train net output #0: loss = 1.31405 (* 1 = 1.31405 loss)
I0526 16:01:29.526664 30701 sgd_solver.cpp:105] Iteration 3200, lr = 0.00984
I0526 16:02:00.913764 30701 solver.cpp:218] Iteration 3300 (3.1861 iter/s, 31.3863s/100 iters), loss = 1.28198
I0526 16:02:00.913900 30701 solver.cpp:237]     Train net output #0: loss = 1.28198 (* 1 = 1.28198 loss)
I0526 16:02:00.913918 30701 sgd_solver.cpp:105] Iteration 3300, lr = 0.009835
I0526 16:02:32.233613 30701 solver.cpp:218] Iteration 3400 (3.19296 iter/s, 31.3189s/100 iters), loss = 1.62771
I0526 16:02:32.233742 30701 solver.cpp:237]     Train net output #0: loss = 1.62771 (* 1 = 1.62771 loss)
I0526 16:02:32.233759 30701 sgd_solver.cpp:105] Iteration 3400, lr = 0.00983
I0526 16:03:03.519094 30701 solver.cpp:218] Iteration 3500 (3.19653 iter/s, 31.2839s/100 iters), loss = 1.12876
I0526 16:03:03.519207 30701 solver.cpp:237]     Train net output #0: loss = 1.12876 (* 1 = 1.12876 loss)
I0526 16:03:03.519220 30701 sgd_solver.cpp:105] Iteration 3500, lr = 0.009825
I0526 16:03:16.699154 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:03:34.844156 30701 solver.cpp:218] Iteration 3600 (3.19249 iter/s, 31.3235s/100 iters), loss = 1.47595
I0526 16:03:34.844277 30701 solver.cpp:237]     Train net output #0: loss = 1.47595 (* 1 = 1.47595 loss)
I0526 16:03:34.844295 30701 sgd_solver.cpp:105] Iteration 3600, lr = 0.00982
I0526 16:04:06.219560 30701 solver.cpp:218] Iteration 3700 (3.1873 iter/s, 31.3745s/100 iters), loss = 1.26095
I0526 16:04:06.219683 30701 solver.cpp:237]     Train net output #0: loss = 1.26095 (* 1 = 1.26095 loss)
I0526 16:04:06.219697 30701 sgd_solver.cpp:105] Iteration 3700, lr = 0.009815
I0526 16:04:37.484702 30701 solver.cpp:218] Iteration 3800 (3.19854 iter/s, 31.2642s/100 iters), loss = 1.28631
I0526 16:04:37.484824 30701 solver.cpp:237]     Train net output #0: loss = 1.28631 (* 1 = 1.28631 loss)
I0526 16:04:37.484836 30701 sgd_solver.cpp:105] Iteration 3800, lr = 0.00981
I0526 16:05:08.753358 30701 solver.cpp:218] Iteration 3900 (3.19825 iter/s, 31.2671s/100 iters), loss = 1.59535
I0526 16:05:08.753522 30701 solver.cpp:237]     Train net output #0: loss = 1.59535 (* 1 = 1.59535 loss)
I0526 16:05:08.753561 30701 sgd_solver.cpp:105] Iteration 3900, lr = 0.009805
I0526 16:05:39.768920 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_4000.caffemodel
I0526 16:05:40.091310 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_4000.solverstate
I0526 16:05:40.243309 30701 solver.cpp:330] Iteration 4000, Testing net (#0)
I0526 16:05:43.516280 30701 solver.cpp:397]     Test net output #0: accuracy = 0.31
I0526 16:05:43.516321 30701 solver.cpp:397]     Test net output #1: loss = 1.83538 (* 1 = 1.83538 loss)
I0526 16:05:43.824390 30701 solver.cpp:218] Iteration 4000 (2.85144 iter/s, 35.07s/100 iters), loss = 1.63836
I0526 16:05:43.824450 30701 solver.cpp:237]     Train net output #0: loss = 1.63836 (* 1 = 1.63836 loss)
I0526 16:05:43.824460 30701 sgd_solver.cpp:105] Iteration 4000, lr = 0.0098
I0526 16:06:13.549330 30701 solver.cpp:218] Iteration 4100 (3.36435 iter/s, 29.7234s/100 iters), loss = 1.4586
I0526 16:06:13.549477 30701 solver.cpp:237]     Train net output #0: loss = 1.4586 (* 1 = 1.4586 loss)
I0526 16:06:13.549489 30701 sgd_solver.cpp:105] Iteration 4100, lr = 0.009795
I0526 16:06:23.105715 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:06:41.718958 30701 solver.cpp:218] Iteration 4200 (3.55003 iter/s, 28.1688s/100 iters), loss = 1.27725
I0526 16:06:41.719005 30701 solver.cpp:237]     Train net output #0: loss = 1.27725 (* 1 = 1.27725 loss)
I0526 16:06:41.719014 30701 sgd_solver.cpp:105] Iteration 4200, lr = 0.00979
I0526 16:07:10.193948 30701 solver.cpp:218] Iteration 4300 (3.51195 iter/s, 28.4742s/100 iters), loss = 1.3847
I0526 16:07:10.194156 30701 solver.cpp:237]     Train net output #0: loss = 1.3847 (* 1 = 1.3847 loss)
I0526 16:07:10.194169 30701 sgd_solver.cpp:105] Iteration 4300, lr = 0.009785
I0526 16:07:38.307644 30701 solver.cpp:218] Iteration 4400 (3.5571 iter/s, 28.1128s/100 iters), loss = 1.35953
I0526 16:07:38.307690 30701 solver.cpp:237]     Train net output #0: loss = 1.35953 (* 1 = 1.35953 loss)
I0526 16:07:38.307699 30701 sgd_solver.cpp:105] Iteration 4400, lr = 0.00978
I0526 16:08:06.374703 30701 solver.cpp:218] Iteration 4500 (3.56299 iter/s, 28.0663s/100 iters), loss = 1.24454
I0526 16:08:06.374872 30701 solver.cpp:237]     Train net output #0: loss = 1.24454 (* 1 = 1.24454 loss)
I0526 16:08:06.374888 30701 sgd_solver.cpp:105] Iteration 4500, lr = 0.009775
I0526 16:08:34.488175 30701 solver.cpp:218] Iteration 4600 (3.55712 iter/s, 28.1126s/100 iters), loss = 1.5431
I0526 16:08:34.488220 30701 solver.cpp:237]     Train net output #0: loss = 1.5431 (* 1 = 1.5431 loss)
I0526 16:08:34.488229 30701 sgd_solver.cpp:105] Iteration 4600, lr = 0.00977
I0526 16:09:02.727329 30701 solver.cpp:218] Iteration 4700 (3.54127 iter/s, 28.2384s/100 iters), loss = 1.29001
I0526 16:09:02.727494 30701 solver.cpp:237]     Train net output #0: loss = 1.29001 (* 1 = 1.29001 loss)
I0526 16:09:02.727505 30701 sgd_solver.cpp:105] Iteration 4700, lr = 0.009765
I0526 16:09:09.763620 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:09:30.803647 30701 solver.cpp:218] Iteration 4800 (3.56183 iter/s, 28.0755s/100 iters), loss = 1.23773
I0526 16:09:30.803692 30701 solver.cpp:237]     Train net output #0: loss = 1.23773 (* 1 = 1.23773 loss)
I0526 16:09:30.803701 30701 sgd_solver.cpp:105] Iteration 4800, lr = 0.00976
I0526 16:09:58.947651 30701 solver.cpp:218] Iteration 4900 (3.55325 iter/s, 28.1433s/100 iters), loss = 1.07
I0526 16:09:58.947811 30701 solver.cpp:237]     Train net output #0: loss = 1.07 (* 1 = 1.07 loss)
I0526 16:09:58.947824 30701 sgd_solver.cpp:105] Iteration 4900, lr = 0.009755
I0526 16:10:26.793246 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_5000.caffemodel
I0526 16:10:27.101894 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_5000.solverstate
I0526 16:10:27.249130 30701 solver.cpp:330] Iteration 5000, Testing net (#0)
I0526 16:10:27.551290 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:10:30.206185 30701 solver.cpp:397]     Test net output #0: accuracy = 0.302
I0526 16:10:30.206365 30701 solver.cpp:397]     Test net output #1: loss = 1.89559 (* 1 = 1.89559 loss)
I0526 16:10:30.485757 30701 solver.cpp:218] Iteration 5000 (3.17086 iter/s, 31.5372s/100 iters), loss = 1.49486
I0526 16:10:30.485801 30701 solver.cpp:237]     Train net output #0: loss = 1.49486 (* 1 = 1.49486 loss)
I0526 16:10:30.485810 30701 sgd_solver.cpp:105] Iteration 5000, lr = 0.00975
I0526 16:10:58.575765 30701 solver.cpp:218] Iteration 5100 (3.56008 iter/s, 28.0893s/100 iters), loss = 1.0673
I0526 16:10:58.575816 30701 solver.cpp:237]     Train net output #0: loss = 1.0673 (* 1 = 1.0673 loss)
I0526 16:10:58.575825 30701 sgd_solver.cpp:105] Iteration 5100, lr = 0.009745
I0526 16:11:26.674589 30701 solver.cpp:218] Iteration 5200 (3.55896 iter/s, 28.0981s/100 iters), loss = 1.20478
I0526 16:11:26.674760 30701 solver.cpp:237]     Train net output #0: loss = 1.20478 (* 1 = 1.20478 loss)
I0526 16:11:26.674772 30701 sgd_solver.cpp:105] Iteration 5200, lr = 0.00974
I0526 16:11:54.793135 30701 solver.cpp:218] Iteration 5300 (3.55648 iter/s, 28.1177s/100 iters), loss = 1.42273
I0526 16:11:54.793179 30701 solver.cpp:237]     Train net output #0: loss = 1.42273 (* 1 = 1.42273 loss)
I0526 16:11:54.793187 30701 sgd_solver.cpp:105] Iteration 5300, lr = 0.009735
I0526 16:11:59.302825 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:12:22.900115 30701 solver.cpp:218] Iteration 5400 (3.55793 iter/s, 28.1063s/100 iters), loss = 1.16855
I0526 16:12:22.900164 30701 solver.cpp:237]     Train net output #0: loss = 1.16855 (* 1 = 1.16855 loss)
I0526 16:12:22.900172 30701 sgd_solver.cpp:105] Iteration 5400, lr = 0.00973
I0526 16:12:51.015485 30701 solver.cpp:218] Iteration 5500 (3.55686 iter/s, 28.1146s/100 iters), loss = 1.19902
I0526 16:12:51.015658 30701 solver.cpp:237]     Train net output #0: loss = 1.19902 (* 1 = 1.19902 loss)
I0526 16:12:51.015669 30701 sgd_solver.cpp:105] Iteration 5500, lr = 0.009725
I0526 16:13:19.120326 30701 solver.cpp:218] Iteration 5600 (3.55821 iter/s, 28.104s/100 iters), loss = 1.47365
I0526 16:13:19.120374 30701 solver.cpp:237]     Train net output #0: loss = 1.47365 (* 1 = 1.47365 loss)
I0526 16:13:19.120383 30701 sgd_solver.cpp:105] Iteration 5600, lr = 0.00972
I0526 16:13:47.224393 30701 solver.cpp:218] Iteration 5700 (3.5583 iter/s, 28.1033s/100 iters), loss = 1.10048
I0526 16:13:47.224560 30701 solver.cpp:237]     Train net output #0: loss = 1.10048 (* 1 = 1.10048 loss)
I0526 16:13:47.224572 30701 sgd_solver.cpp:105] Iteration 5700, lr = 0.009715
I0526 16:14:15.321466 30701 solver.cpp:218] Iteration 5800 (3.55914 iter/s, 28.0967s/100 iters), loss = 1.06474
I0526 16:14:15.321523 30701 solver.cpp:237]     Train net output #0: loss = 1.06474 (* 1 = 1.06474 loss)
I0526 16:14:15.321532 30701 sgd_solver.cpp:105] Iteration 5800, lr = 0.00971
I0526 16:14:43.414791 30701 solver.cpp:218] Iteration 5900 (3.55959 iter/s, 28.0931s/100 iters), loss = 0.946703
I0526 16:14:43.415004 30701 solver.cpp:237]     Train net output #0: loss = 0.946703 (* 1 = 0.946703 loss)
I0526 16:14:43.415015 30701 sgd_solver.cpp:105] Iteration 5900, lr = 0.009705
I0526 16:14:45.401062 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:15:11.257550 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_6000.caffemodel
I0526 16:15:11.567510 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_6000.solverstate
I0526 16:15:11.714366 30701 solver.cpp:330] Iteration 6000, Testing net (#0)
I0526 16:15:14.670891 30701 solver.cpp:397]     Test net output #0: accuracy = 0.486
I0526 16:15:14.671005 30701 solver.cpp:397]     Test net output #1: loss = 1.33178 (* 1 = 1.33178 loss)
I0526 16:15:14.949497 30701 solver.cpp:218] Iteration 6000 (3.17115 iter/s, 31.5343s/100 iters), loss = 0.914748
I0526 16:15:14.949550 30701 solver.cpp:237]     Train net output #0: loss = 0.914748 (* 1 = 0.914748 loss)
I0526 16:15:14.949563 30701 sgd_solver.cpp:105] Iteration 6000, lr = 0.0097
I0526 16:15:43.037791 30701 solver.cpp:218] Iteration 6100 (3.56024 iter/s, 28.088s/100 iters), loss = 1.23857
I0526 16:15:43.037843 30701 solver.cpp:237]     Train net output #0: loss = 1.23857 (* 1 = 1.23857 loss)
I0526 16:15:43.037855 30701 sgd_solver.cpp:105] Iteration 6100, lr = 0.009695
I0526 16:16:11.104290 30701 solver.cpp:218] Iteration 6200 (3.563 iter/s, 28.0662s/100 iters), loss = 1.004
I0526 16:16:11.104488 30701 solver.cpp:237]     Train net output #0: loss = 1.004 (* 1 = 1.004 loss)
I0526 16:16:11.104504 30701 sgd_solver.cpp:105] Iteration 6200, lr = 0.00969
I0526 16:16:39.350095 30701 solver.cpp:218] Iteration 6300 (3.54041 iter/s, 28.2453s/100 iters), loss = 1.36939
I0526 16:16:39.350162 30701 solver.cpp:237]     Train net output #0: loss = 1.36939 (* 1 = 1.36939 loss)
I0526 16:16:39.350172 30701 sgd_solver.cpp:105] Iteration 6300, lr = 0.009685
I0526 16:17:07.436779 30701 solver.cpp:218] Iteration 6400 (3.56045 iter/s, 28.0863s/100 iters), loss = 1.04723
I0526 16:17:07.436931 30701 solver.cpp:237]     Train net output #0: loss = 1.04723 (* 1 = 1.04723 loss)
I0526 16:17:07.436942 30701 sgd_solver.cpp:105] Iteration 6400, lr = 0.00968
I0526 16:17:34.966352 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:17:35.513895 30701 solver.cpp:218] Iteration 6500 (3.56168 iter/s, 28.0767s/100 iters), loss = 0.939255
I0526 16:17:35.513942 30701 solver.cpp:237]     Train net output #0: loss = 0.939255 (* 1 = 0.939255 loss)
I0526 16:17:35.513952 30701 sgd_solver.cpp:105] Iteration 6500, lr = 0.009675
I0526 16:18:04.024003 30701 solver.cpp:218] Iteration 6600 (3.50757 iter/s, 28.5097s/100 iters), loss = 1.07105
I0526 16:18:04.024169 30701 solver.cpp:237]     Train net output #0: loss = 1.07105 (* 1 = 1.07105 loss)
I0526 16:18:04.024180 30701 sgd_solver.cpp:105] Iteration 6600, lr = 0.00967
I0526 16:18:32.396343 30701 solver.cpp:218] Iteration 6700 (3.52462 iter/s, 28.3718s/100 iters), loss = 1.55052
I0526 16:18:32.396389 30701 solver.cpp:237]     Train net output #0: loss = 1.55052 (* 1 = 1.55052 loss)
I0526 16:18:32.396397 30701 sgd_solver.cpp:105] Iteration 6700, lr = 0.009665
I0526 16:19:00.757942 30701 solver.cpp:218] Iteration 6800 (3.52594 iter/s, 28.3612s/100 iters), loss = 1.35294
I0526 16:19:00.758106 30701 solver.cpp:237]     Train net output #0: loss = 1.35294 (* 1 = 1.35294 loss)
I0526 16:19:00.758117 30701 sgd_solver.cpp:105] Iteration 6800, lr = 0.00966
I0526 16:19:29.117013 30701 solver.cpp:218] Iteration 6900 (3.52627 iter/s, 28.3585s/100 iters), loss = 1.00543
I0526 16:19:29.117058 30701 solver.cpp:237]     Train net output #0: loss = 1.00543 (* 1 = 1.00543 loss)
I0526 16:19:29.117067 30701 sgd_solver.cpp:105] Iteration 6900, lr = 0.009655
I0526 16:19:57.257467 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_7000.caffemodel
I0526 16:19:57.565536 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_7000.solverstate
I0526 16:19:57.711452 30701 solver.cpp:330] Iteration 7000, Testing net (#0)
I0526 16:19:59.730509 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:20:00.716202 30701 solver.cpp:397]     Test net output #0: accuracy = 0.508
I0526 16:20:00.716251 30701 solver.cpp:397]     Test net output #1: loss = 1.40413 (* 1 = 1.40413 loss)
I0526 16:20:00.994369 30701 solver.cpp:218] Iteration 7000 (3.13707 iter/s, 31.8769s/100 iters), loss = 0.750591
I0526 16:20:00.994426 30701 solver.cpp:237]     Train net output #0: loss = 0.750591 (* 1 = 0.750591 loss)
I0526 16:20:00.994436 30701 sgd_solver.cpp:105] Iteration 7000, lr = 0.00965
I0526 16:20:26.037030 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:20:29.111713 30701 solver.cpp:218] Iteration 7100 (3.55658 iter/s, 28.1169s/100 iters), loss = 0.93392
I0526 16:20:29.111886 30701 solver.cpp:237]     Train net output #0: loss = 0.93392 (* 1 = 0.93392 loss)
I0526 16:20:29.111896 30701 sgd_solver.cpp:105] Iteration 7100, lr = 0.009645
I0526 16:20:57.241475 30701 solver.cpp:218] Iteration 7200 (3.55503 iter/s, 28.1292s/100 iters), loss = 1.16824
I0526 16:20:57.241519 30701 solver.cpp:237]     Train net output #0: loss = 1.16824 (* 1 = 1.16824 loss)
I0526 16:20:57.241528 30701 sgd_solver.cpp:105] Iteration 7200, lr = 0.00964
I0526 16:21:25.371156 30701 solver.cpp:218] Iteration 7300 (3.55502 iter/s, 28.1292s/100 iters), loss = 1.17337
I0526 16:21:25.371466 30701 solver.cpp:237]     Train net output #0: loss = 1.17337 (* 1 = 1.17337 loss)
I0526 16:21:25.371479 30701 sgd_solver.cpp:105] Iteration 7300, lr = 0.009635
I0526 16:21:53.493414 30701 solver.cpp:218] Iteration 7400 (3.55599 iter/s, 28.1215s/100 iters), loss = 0.886274
I0526 16:21:53.493463 30701 solver.cpp:237]     Train net output #0: loss = 0.886274 (* 1 = 0.886274 loss)
I0526 16:21:53.493470 30701 sgd_solver.cpp:105] Iteration 7400, lr = 0.00963
I0526 16:22:21.755980 30701 solver.cpp:218] Iteration 7500 (3.53831 iter/s, 28.2621s/100 iters), loss = 0.686815
I0526 16:22:21.756170 30701 solver.cpp:237]     Train net output #0: loss = 0.686815 (* 1 = 0.686815 loss)
I0526 16:22:21.756192 30701 sgd_solver.cpp:105] Iteration 7500, lr = 0.009625
I0526 16:22:49.882112 30701 solver.cpp:218] Iteration 7600 (3.55549 iter/s, 28.1255s/100 iters), loss = 0.983903
I0526 16:22:49.882174 30701 solver.cpp:237]     Train net output #0: loss = 0.983903 (* 1 = 0.983903 loss)
I0526 16:22:49.882181 30701 sgd_solver.cpp:105] Iteration 7600, lr = 0.00962
I0526 16:23:12.430444 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:23:18.040863 30701 solver.cpp:218] Iteration 7700 (3.55136 iter/s, 28.1582s/100 iters), loss = 0.909709
I0526 16:23:18.040922 30701 solver.cpp:237]     Train net output #0: loss = 0.909709 (* 1 = 0.909709 loss)
I0526 16:23:18.040931 30701 sgd_solver.cpp:105] Iteration 7700, lr = 0.009615
I0526 16:23:46.185241 30701 solver.cpp:218] Iteration 7800 (3.55317 iter/s, 28.1439s/100 iters), loss = 0.585045
I0526 16:23:46.185461 30701 solver.cpp:237]     Train net output #0: loss = 0.585045 (* 1 = 0.585045 loss)
I0526 16:23:46.185473 30701 sgd_solver.cpp:105] Iteration 7800, lr = 0.00961
I0526 16:24:14.333276 30701 solver.cpp:218] Iteration 7900 (3.55273 iter/s, 28.1474s/100 iters), loss = 0.926267
I0526 16:24:14.333333 30701 solver.cpp:237]     Train net output #0: loss = 0.926267 (* 1 = 0.926267 loss)
I0526 16:24:14.333341 30701 sgd_solver.cpp:105] Iteration 7900, lr = 0.009605
I0526 16:24:42.194237 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_8000.caffemodel
I0526 16:24:42.506204 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_8000.solverstate
I0526 16:24:42.654340 30701 solver.cpp:330] Iteration 8000, Testing net (#0)
I0526 16:24:45.614250 30701 solver.cpp:397]     Test net output #0: accuracy = 0.446
I0526 16:24:45.614305 30701 solver.cpp:397]     Test net output #1: loss = 1.48303 (* 1 = 1.48303 loss)
I0526 16:24:45.893218 30701 solver.cpp:218] Iteration 8000 (3.16863 iter/s, 31.5594s/100 iters), loss = 0.859535
I0526 16:24:45.893262 30701 solver.cpp:237]     Train net output #0: loss = 0.859535 (* 1 = 0.859535 loss)
I0526 16:24:45.893270 30701 sgd_solver.cpp:105] Iteration 8000, lr = 0.0096
I0526 16:25:14.029546 30701 solver.cpp:218] Iteration 8100 (3.55419 iter/s, 28.1358s/100 iters), loss = 1.05511
I0526 16:25:14.029690 30701 solver.cpp:237]     Train net output #0: loss = 1.05511 (* 1 = 1.05511 loss)
I0526 16:25:14.029703 30701 sgd_solver.cpp:105] Iteration 8100, lr = 0.009595
I0526 16:25:42.168951 30701 solver.cpp:218] Iteration 8200 (3.55382 iter/s, 28.1387s/100 iters), loss = 0.995897
I0526 16:25:42.169011 30701 solver.cpp:237]     Train net output #0: loss = 0.995897 (* 1 = 0.995897 loss)
I0526 16:25:42.169020 30701 sgd_solver.cpp:105] Iteration 8200, lr = 0.00959
I0526 16:26:02.459244 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:26:10.337894 30701 solver.cpp:218] Iteration 8300 (3.55008 iter/s, 28.1684s/100 iters), loss = 0.949595
I0526 16:26:10.337954 30701 solver.cpp:237]     Train net output #0: loss = 0.949595 (* 1 = 0.949595 loss)
I0526 16:26:10.337965 30701 sgd_solver.cpp:105] Iteration 8300, lr = 0.009585
I0526 16:26:38.467149 30701 solver.cpp:218] Iteration 8400 (3.55509 iter/s, 28.1287s/100 iters), loss = 0.62996
I0526 16:26:38.467326 30701 solver.cpp:237]     Train net output #0: loss = 0.62996 (* 1 = 0.62996 loss)
I0526 16:26:38.467337 30701 sgd_solver.cpp:105] Iteration 8400, lr = 0.00958
I0526 16:27:06.610555 30701 solver.cpp:218] Iteration 8500 (3.55332 iter/s, 28.1427s/100 iters), loss = 0.842869
I0526 16:27:06.610610 30701 solver.cpp:237]     Train net output #0: loss = 0.842869 (* 1 = 0.842869 loss)
I0526 16:27:06.610633 30701 sgd_solver.cpp:105] Iteration 8500, lr = 0.009575
I0526 16:27:34.934700 30701 solver.cpp:218] Iteration 8600 (3.53063 iter/s, 28.3236s/100 iters), loss = 0.871417
I0526 16:27:34.934875 30701 solver.cpp:237]     Train net output #0: loss = 0.871417 (* 1 = 0.871417 loss)
I0526 16:27:34.934887 30701 sgd_solver.cpp:105] Iteration 8600, lr = 0.00957
I0526 16:28:03.758939 30701 solver.cpp:218] Iteration 8700 (3.46939 iter/s, 28.8235s/100 iters), loss = 0.682986
I0526 16:28:03.759006 30701 solver.cpp:237]     Train net output #0: loss = 0.682986 (* 1 = 0.682986 loss)
I0526 16:28:03.759022 30701 sgd_solver.cpp:105] Iteration 8700, lr = 0.009565
I0526 16:28:32.165020 30701 solver.cpp:218] Iteration 8800 (3.52045 iter/s, 28.4055s/100 iters), loss = 1.19339
I0526 16:28:32.165225 30701 solver.cpp:237]     Train net output #0: loss = 1.19339 (* 1 = 1.19339 loss)
I0526 16:28:32.165235 30701 sgd_solver.cpp:105] Iteration 8800, lr = 0.00956
I0526 16:28:50.192536 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:29:00.665114 30701 solver.cpp:218] Iteration 8900 (3.50885 iter/s, 28.4994s/100 iters), loss = 1.10564
I0526 16:29:00.665164 30701 solver.cpp:237]     Train net output #0: loss = 1.10564 (* 1 = 1.10564 loss)
I0526 16:29:00.665174 30701 sgd_solver.cpp:105] Iteration 8900, lr = 0.009555
I0526 16:29:29.178817 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_9000.caffemodel
I0526 16:29:29.488582 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_9000.solverstate
I0526 16:29:29.636718 30701 solver.cpp:330] Iteration 9000, Testing net (#0)
I0526 16:29:32.592249 30701 solver.cpp:397]     Test net output #0: accuracy = 0.486
I0526 16:29:32.592299 30701 solver.cpp:397]     Test net output #1: loss = 1.82164 (* 1 = 1.82164 loss)
I0526 16:29:32.874874 30701 solver.cpp:218] Iteration 9000 (3.10471 iter/s, 32.2091s/100 iters), loss = 1.04323
I0526 16:29:32.874920 30701 solver.cpp:237]     Train net output #0: loss = 1.04323 (* 1 = 1.04323 loss)
I0526 16:29:32.874928 30701 sgd_solver.cpp:105] Iteration 9000, lr = 0.00955
I0526 16:30:01.410966 30701 solver.cpp:218] Iteration 9100 (3.50441 iter/s, 28.5355s/100 iters), loss = 0.991457
I0526 16:30:01.411098 30701 solver.cpp:237]     Train net output #0: loss = 0.991457 (* 1 = 0.991457 loss)
I0526 16:30:01.411118 30701 sgd_solver.cpp:105] Iteration 9100, lr = 0.009545
I0526 16:30:30.111870 30701 solver.cpp:218] Iteration 9200 (3.4843 iter/s, 28.7002s/100 iters), loss = 0.765505
I0526 16:30:30.111925 30701 solver.cpp:237]     Train net output #0: loss = 0.765505 (* 1 = 0.765505 loss)
I0526 16:30:30.111934 30701 sgd_solver.cpp:105] Iteration 9200, lr = 0.00954
I0526 16:30:58.542938 30701 solver.cpp:218] Iteration 9300 (3.51735 iter/s, 28.4305s/100 iters), loss = 1.18055
I0526 16:30:58.543108 30701 solver.cpp:237]     Train net output #0: loss = 1.18055 (* 1 = 1.18055 loss)
I0526 16:30:58.543120 30701 sgd_solver.cpp:105] Iteration 9300, lr = 0.009535
I0526 16:31:27.065238 30701 solver.cpp:218] Iteration 9400 (3.50612 iter/s, 28.5216s/100 iters), loss = 0.953316
I0526 16:31:27.065287 30701 solver.cpp:237]     Train net output #0: loss = 0.953316 (* 1 = 0.953316 loss)
I0526 16:31:27.065296 30701 sgd_solver.cpp:105] Iteration 9400, lr = 0.00953
I0526 16:31:42.796890 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:31:55.985431 30701 solver.cpp:218] Iteration 9500 (3.45786 iter/s, 28.9196s/100 iters), loss = 0.873855
I0526 16:31:55.985476 30701 solver.cpp:237]     Train net output #0: loss = 0.873855 (* 1 = 0.873855 loss)
I0526 16:31:55.985484 30701 sgd_solver.cpp:105] Iteration 9500, lr = 0.009525
I0526 16:32:25.028565 30701 solver.cpp:218] Iteration 9600 (3.44323 iter/s, 29.0425s/100 iters), loss = 0.930359
I0526 16:32:25.028785 30701 solver.cpp:237]     Train net output #0: loss = 0.930359 (* 1 = 0.930359 loss)
I0526 16:32:25.028812 30701 sgd_solver.cpp:105] Iteration 9600, lr = 0.00952
I0526 16:32:53.476795 30701 solver.cpp:218] Iteration 9700 (3.51525 iter/s, 28.4475s/100 iters), loss = 0.737455
I0526 16:32:53.476840 30701 solver.cpp:237]     Train net output #0: loss = 0.737455 (* 1 = 0.737455 loss)
I0526 16:32:53.476848 30701 sgd_solver.cpp:105] Iteration 9700, lr = 0.009515
I0526 16:33:21.611677 30701 solver.cpp:218] Iteration 9800 (3.55438 iter/s, 28.1343s/100 iters), loss = 0.624125
I0526 16:33:21.611851 30701 solver.cpp:237]     Train net output #0: loss = 0.624125 (* 1 = 0.624125 loss)
I0526 16:33:21.611863 30701 sgd_solver.cpp:105] Iteration 9800, lr = 0.00951
I0526 16:33:49.786443 30701 solver.cpp:218] Iteration 9900 (3.54937 iter/s, 28.174s/100 iters), loss = 0.601609
I0526 16:33:49.786496 30701 solver.cpp:237]     Train net output #0: loss = 0.601609 (* 1 = 0.601609 loss)
I0526 16:33:49.786505 30701 sgd_solver.cpp:105] Iteration 9900, lr = 0.009505
I0526 16:34:17.980365 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_10000.caffemodel
I0526 16:34:18.291049 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_10000.solverstate
I0526 16:34:18.438463 30701 solver.cpp:330] Iteration 10000, Testing net (#0)
I0526 16:34:19.154510 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:34:21.462185 30701 solver.cpp:397]     Test net output #0: accuracy = 0.546
I0526 16:34:21.462229 30701 solver.cpp:397]     Test net output #1: loss = 1.2263 (* 1 = 1.2263 loss)
I0526 16:34:21.749231 30701 solver.cpp:218] Iteration 10000 (3.12871 iter/s, 31.9621s/100 iters), loss = 0.827341
I0526 16:34:21.749299 30701 solver.cpp:237]     Train net output #0: loss = 0.827341 (* 1 = 0.827341 loss)
I0526 16:34:21.749307 30701 sgd_solver.cpp:105] Iteration 10000, lr = 0.0095
I0526 16:34:34.880318 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:34:50.808305 30701 solver.cpp:218] Iteration 10100 (3.44134 iter/s, 29.0584s/100 iters), loss = 0.731985
I0526 16:34:50.808478 30701 solver.cpp:237]     Train net output #0: loss = 0.731985 (* 1 = 0.731985 loss)
I0526 16:34:50.808490 30701 sgd_solver.cpp:105] Iteration 10100, lr = 0.009495
I0526 16:35:19.639081 30701 solver.cpp:218] Iteration 10200 (3.46861 iter/s, 28.83s/100 iters), loss = 0.831917
I0526 16:35:19.639130 30701 solver.cpp:237]     Train net output #0: loss = 0.831917 (* 1 = 0.831917 loss)
I0526 16:35:19.639139 30701 sgd_solver.cpp:105] Iteration 10200, lr = 0.00949
I0526 16:35:48.606844 30701 solver.cpp:218] Iteration 10300 (3.45219 iter/s, 28.9671s/100 iters), loss = 0.426586
I0526 16:35:48.606971 30701 solver.cpp:237]     Train net output #0: loss = 0.426586 (* 1 = 0.426586 loss)
I0526 16:35:48.606993 30701 sgd_solver.cpp:105] Iteration 10300, lr = 0.009485
I0526 16:36:17.266233 30701 solver.cpp:218] Iteration 10400 (3.48935 iter/s, 28.6587s/100 iters), loss = 1.23973
I0526 16:36:17.266290 30701 solver.cpp:237]     Train net output #0: loss = 1.23973 (* 1 = 1.23973 loss)
I0526 16:36:17.266300 30701 sgd_solver.cpp:105] Iteration 10400, lr = 0.00948
I0526 16:36:45.861138 30701 solver.cpp:218] Iteration 10500 (3.49721 iter/s, 28.5943s/100 iters), loss = 0.908933
I0526 16:36:45.861353 30701 solver.cpp:237]     Train net output #0: loss = 0.908933 (* 1 = 0.908933 loss)
I0526 16:36:45.861369 30701 sgd_solver.cpp:105] Iteration 10500, lr = 0.009475
I0526 16:37:14.810130 30701 solver.cpp:218] Iteration 10600 (3.45444 iter/s, 28.9482s/100 iters), loss = 1.36114
I0526 16:37:14.810179 30701 solver.cpp:237]     Train net output #0: loss = 1.36114 (* 1 = 1.36114 loss)
I0526 16:37:14.810189 30701 sgd_solver.cpp:105] Iteration 10600, lr = 0.00947
I0526 16:37:25.008760 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:37:43.237382 30701 solver.cpp:218] Iteration 10700 (3.51783 iter/s, 28.4266s/100 iters), loss = 1.22941
I0526 16:37:43.237426 30701 solver.cpp:237]     Train net output #0: loss = 1.22941 (* 1 = 1.22941 loss)
I0526 16:37:43.237433 30701 sgd_solver.cpp:105] Iteration 10700, lr = 0.009465
I0526 16:38:12.293922 30701 solver.cpp:218] Iteration 10800 (3.44164 iter/s, 29.0559s/100 iters), loss = 0.656766
I0526 16:38:12.294050 30701 solver.cpp:237]     Train net output #0: loss = 0.656766 (* 1 = 0.656766 loss)
I0526 16:38:12.294070 30701 sgd_solver.cpp:105] Iteration 10800, lr = 0.00946
I0526 16:38:40.846109 30701 solver.cpp:218] Iteration 10900 (3.50247 iter/s, 28.5513s/100 iters), loss = 0.562292
I0526 16:38:40.846158 30701 solver.cpp:237]     Train net output #0: loss = 0.562292 (* 1 = 0.562292 loss)
I0526 16:38:40.846166 30701 sgd_solver.cpp:105] Iteration 10900, lr = 0.009455
I0526 16:39:09.256804 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_11000.caffemodel
I0526 16:39:09.568203 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_11000.solverstate
I0526 16:39:09.715927 30701 solver.cpp:330] Iteration 11000, Testing net (#0)
I0526 16:39:12.693975 30701 solver.cpp:397]     Test net output #0: accuracy = 0.542
I0526 16:39:12.694012 30701 solver.cpp:397]     Test net output #1: loss = 1.38135 (* 1 = 1.38135 loss)
I0526 16:39:12.975157 30701 solver.cpp:218] Iteration 11000 (3.11252 iter/s, 32.1283s/100 iters), loss = 0.460558
I0526 16:39:12.975214 30701 solver.cpp:237]     Train net output #0: loss = 0.460558 (* 1 = 0.460558 loss)
I0526 16:39:12.975222 30701 sgd_solver.cpp:105] Iteration 11000, lr = 0.00945
I0526 16:39:41.462327 30701 solver.cpp:218] Iteration 11100 (3.51043 iter/s, 28.4865s/100 iters), loss = 0.968867
I0526 16:39:41.462491 30701 solver.cpp:237]     Train net output #0: loss = 0.968867 (* 1 = 0.968867 loss)
I0526 16:39:41.462502 30701 sgd_solver.cpp:105] Iteration 11100, lr = 0.009445
I0526 16:40:09.791332 30701 solver.cpp:218] Iteration 11200 (3.53004 iter/s, 28.3283s/100 iters), loss = 0.870473
I0526 16:40:09.791383 30701 solver.cpp:237]     Train net output #0: loss = 0.870473 (* 1 = 0.870473 loss)
I0526 16:40:09.791391 30701 sgd_solver.cpp:105] Iteration 11200, lr = 0.00944
I0526 16:40:17.518033 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:40:38.698452 30701 solver.cpp:218] Iteration 11300 (3.45943 iter/s, 28.9065s/100 iters), loss = 0.736762
I0526 16:40:38.698530 30701 solver.cpp:237]     Train net output #0: loss = 0.736762 (* 1 = 0.736762 loss)
I0526 16:40:38.698545 30701 sgd_solver.cpp:105] Iteration 11300, lr = 0.009435
I0526 16:41:07.361318 30701 solver.cpp:218] Iteration 11400 (3.48892 iter/s, 28.6622s/100 iters), loss = 0.447721
I0526 16:41:07.361562 30701 solver.cpp:237]     Train net output #0: loss = 0.447721 (* 1 = 0.447721 loss)
I0526 16:41:07.361578 30701 sgd_solver.cpp:105] Iteration 11400, lr = 0.00943
I0526 16:41:36.073917 30701 solver.cpp:218] Iteration 11500 (3.48289 iter/s, 28.7118s/100 iters), loss = 0.876826
I0526 16:41:36.073963 30701 solver.cpp:237]     Train net output #0: loss = 0.876826 (* 1 = 0.876826 loss)
I0526 16:41:36.073972 30701 sgd_solver.cpp:105] Iteration 11500, lr = 0.009425
I0526 16:42:04.358029 30701 solver.cpp:218] Iteration 11600 (3.53563 iter/s, 28.2835s/100 iters), loss = 0.397374
I0526 16:42:04.358209 30701 solver.cpp:237]     Train net output #0: loss = 0.397374 (* 1 = 0.397374 loss)
I0526 16:42:04.358227 30701 sgd_solver.cpp:105] Iteration 11600, lr = 0.00942
I0526 16:42:33.039094 30701 solver.cpp:218] Iteration 11700 (3.48672 iter/s, 28.6803s/100 iters), loss = 1.06199
I0526 16:42:33.039155 30701 solver.cpp:237]     Train net output #0: loss = 1.06199 (* 1 = 1.06199 loss)
I0526 16:42:33.039165 30701 sgd_solver.cpp:105] Iteration 11700, lr = 0.009415
I0526 16:43:01.700242 30701 solver.cpp:218] Iteration 11800 (3.48913 iter/s, 28.6605s/100 iters), loss = 0.484753
I0526 16:43:01.700455 30701 solver.cpp:237]     Train net output #0: loss = 0.484753 (* 1 = 0.484753 loss)
I0526 16:43:01.700467 30701 sgd_solver.cpp:105] Iteration 11800, lr = 0.00941
I0526 16:43:06.879400 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:43:30.170181 30701 solver.cpp:218] Iteration 11900 (3.51258 iter/s, 28.4691s/100 iters), loss = 0.3922
I0526 16:43:30.170228 30701 solver.cpp:237]     Train net output #0: loss = 0.3922 (* 1 = 0.3922 loss)
I0526 16:43:30.170236 30701 sgd_solver.cpp:105] Iteration 11900, lr = 0.009405
I0526 16:43:58.599143 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_12000.caffemodel
I0526 16:43:58.909104 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_12000.solverstate
I0526 16:43:59.056747 30701 solver.cpp:330] Iteration 12000, Testing net (#0)
I0526 16:44:01.493263 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:44:02.108234 30701 solver.cpp:397]     Test net output #0: accuracy = 0.504
I0526 16:44:02.108283 30701 solver.cpp:397]     Test net output #1: loss = 1.98416 (* 1 = 1.98416 loss)
I0526 16:44:02.390630 30701 solver.cpp:218] Iteration 12000 (3.10369 iter/s, 32.2197s/100 iters), loss = 1.17783
I0526 16:44:02.390681 30701 solver.cpp:237]     Train net output #0: loss = 1.17783 (* 1 = 1.17783 loss)
I0526 16:44:02.390688 30701 sgd_solver.cpp:105] Iteration 12000, lr = 0.0094
I0526 16:44:31.028734 30701 solver.cpp:218] Iteration 12100 (3.49193 iter/s, 28.6374s/100 iters), loss = 0.625142
I0526 16:44:31.028918 30701 solver.cpp:237]     Train net output #0: loss = 0.625142 (* 1 = 0.625142 loss)
I0526 16:44:31.028941 30701 sgd_solver.cpp:105] Iteration 12100, lr = 0.009395
I0526 16:44:59.357874 30701 solver.cpp:218] Iteration 12200 (3.53003 iter/s, 28.3284s/100 iters), loss = 1.21445
I0526 16:44:59.357931 30701 solver.cpp:237]     Train net output #0: loss = 1.21445 (* 1 = 1.21445 loss)
I0526 16:44:59.357941 30701 sgd_solver.cpp:105] Iteration 12200, lr = 0.00939
I0526 16:45:27.540604 30701 solver.cpp:218] Iteration 12300 (3.54835 iter/s, 28.1821s/100 iters), loss = 0.676257
I0526 16:45:27.540822 30701 solver.cpp:237]     Train net output #0: loss = 0.676257 (* 1 = 0.676257 loss)
I0526 16:45:27.540833 30701 sgd_solver.cpp:105] Iteration 12300, lr = 0.009385
I0526 16:45:55.955979 30701 solver.cpp:218] Iteration 12400 (3.51932 iter/s, 28.4146s/100 iters), loss = 0.5225
I0526 16:45:55.956033 30701 solver.cpp:237]     Train net output #0: loss = 0.5225 (* 1 = 0.5225 loss)
I0526 16:45:55.956058 30701 sgd_solver.cpp:105] Iteration 12400, lr = 0.00938
I0526 16:45:58.795439 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:46:24.107205 30701 solver.cpp:218] Iteration 12500 (3.55232 iter/s, 28.1506s/100 iters), loss = 1.00508
I0526 16:46:24.107254 30701 solver.cpp:237]     Train net output #0: loss = 1.00508 (* 1 = 1.00508 loss)
I0526 16:46:24.107262 30701 sgd_solver.cpp:105] Iteration 12500, lr = 0.009375
I0526 16:46:52.235824 30701 solver.cpp:218] Iteration 12600 (3.55518 iter/s, 28.128s/100 iters), loss = 0.726277
I0526 16:46:52.235963 30701 solver.cpp:237]     Train net output #0: loss = 0.726277 (* 1 = 0.726277 loss)
I0526 16:46:52.235973 30701 sgd_solver.cpp:105] Iteration 12600, lr = 0.00937
I0526 16:47:20.487939 30701 solver.cpp:218] Iteration 12700 (3.53965 iter/s, 28.2514s/100 iters), loss = 0.977723
I0526 16:47:20.487993 30701 solver.cpp:237]     Train net output #0: loss = 0.977723 (* 1 = 0.977723 loss)
I0526 16:47:20.488003 30701 sgd_solver.cpp:105] Iteration 12700, lr = 0.009365
I0526 16:47:49.151212 30701 solver.cpp:218] Iteration 12800 (3.48887 iter/s, 28.6626s/100 iters), loss = 0.539631
I0526 16:47:49.151363 30701 solver.cpp:237]     Train net output #0: loss = 0.53963 (* 1 = 0.53963 loss)
I0526 16:47:49.151376 30701 sgd_solver.cpp:105] Iteration 12800, lr = 0.00936
I0526 16:48:18.381216 30701 solver.cpp:218] Iteration 12900 (3.42122 iter/s, 29.2294s/100 iters), loss = 0.58567
I0526 16:48:18.381274 30701 solver.cpp:237]     Train net output #0: loss = 0.58567 (* 1 = 0.58567 loss)
I0526 16:48:18.381283 30701 sgd_solver.cpp:105] Iteration 12900, lr = 0.009355
I0526 16:48:46.917707 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_13000.caffemodel
I0526 16:48:47.227752 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_13000.solverstate
I0526 16:48:47.374274 30701 solver.cpp:330] Iteration 13000, Testing net (#0)
I0526 16:48:50.325311 30701 solver.cpp:397]     Test net output #0: accuracy = 0.462
I0526 16:48:50.325348 30701 solver.cpp:397]     Test net output #1: loss = 1.64009 (* 1 = 1.64009 loss)
I0526 16:48:50.603901 30701 solver.cpp:218] Iteration 13000 (3.10346 iter/s, 32.2221s/100 iters), loss = 0.654489
I0526 16:48:50.603979 30701 solver.cpp:237]     Train net output #0: loss = 0.654488 (* 1 = 0.654488 loss)
I0526 16:48:50.603991 30701 sgd_solver.cpp:105] Iteration 13000, lr = 0.00935
I0526 16:48:50.904655 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:49:19.240813 30701 solver.cpp:218] Iteration 13100 (3.49206 iter/s, 28.6364s/100 iters), loss = 0.506316
I0526 16:49:19.567513 30701 solver.cpp:237]     Train net output #0: loss = 0.506316 (* 1 = 0.506316 loss)
I0526 16:49:19.567548 30701 sgd_solver.cpp:105] Iteration 13100, lr = 0.009345
I0526 16:49:47.745281 30701 solver.cpp:218] Iteration 13200 (3.54895 iter/s, 28.1773s/100 iters), loss = 0.613789
I0526 16:49:47.745329 30701 solver.cpp:237]     Train net output #0: loss = 0.613789 (* 1 = 0.613789 loss)
I0526 16:49:47.745338 30701 sgd_solver.cpp:105] Iteration 13200, lr = 0.00934
I0526 16:50:16.189438 30701 solver.cpp:218] Iteration 13300 (3.51572 iter/s, 28.4437s/100 iters), loss = 0.577742
I0526 16:50:16.189697 30701 solver.cpp:237]     Train net output #0: loss = 0.577742 (* 1 = 0.577742 loss)
I0526 16:50:16.189708 30701 sgd_solver.cpp:105] Iteration 13300, lr = 0.009335
I0526 16:50:44.394654 30701 solver.cpp:218] Iteration 13400 (3.54553 iter/s, 28.2045s/100 iters), loss = 0.614492
I0526 16:50:44.394700 30701 solver.cpp:237]     Train net output #0: loss = 0.614491 (* 1 = 0.614491 loss)
I0526 16:50:44.394718 30701 sgd_solver.cpp:105] Iteration 13400, lr = 0.00933
I0526 16:51:12.532780 30701 solver.cpp:218] Iteration 13500 (3.55396 iter/s, 28.1376s/100 iters), loss = 0.901167
I0526 16:51:12.532997 30701 solver.cpp:237]     Train net output #0: loss = 0.901167 (* 1 = 0.901167 loss)
I0526 16:51:12.533010 30701 sgd_solver.cpp:105] Iteration 13500, lr = 0.009325
I0526 16:51:38.452052 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:51:40.693177 30701 solver.cpp:218] Iteration 13600 (3.55117 iter/s, 28.1597s/100 iters), loss = 0.382503
I0526 16:51:40.693243 30701 solver.cpp:237]     Train net output #0: loss = 0.382502 (* 1 = 0.382502 loss)
I0526 16:51:40.693264 30701 sgd_solver.cpp:105] Iteration 13600, lr = 0.00932
I0526 16:52:08.832556 30701 solver.cpp:218] Iteration 13700 (3.55381 iter/s, 28.1388s/100 iters), loss = 0.727139
I0526 16:52:08.832759 30701 solver.cpp:237]     Train net output #0: loss = 0.727138 (* 1 = 0.727138 loss)
I0526 16:52:08.832772 30701 sgd_solver.cpp:105] Iteration 13700, lr = 0.009315
I0526 16:52:36.990773 30701 solver.cpp:218] Iteration 13800 (3.55144 iter/s, 28.1576s/100 iters), loss = 0.606103
I0526 16:52:36.990823 30701 solver.cpp:237]     Train net output #0: loss = 0.606102 (* 1 = 0.606102 loss)
I0526 16:52:36.990830 30701 sgd_solver.cpp:105] Iteration 13800, lr = 0.00931
I0526 16:53:05.137233 30701 solver.cpp:218] Iteration 13900 (3.55291 iter/s, 28.1459s/100 iters), loss = 0.589175
I0526 16:53:05.137363 30701 solver.cpp:237]     Train net output #0: loss = 0.589174 (* 1 = 0.589174 loss)
I0526 16:53:05.137373 30701 sgd_solver.cpp:105] Iteration 13900, lr = 0.009305
I0526 16:53:32.984307 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_14000.caffemodel
I0526 16:53:33.298974 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_14000.solverstate
I0526 16:53:33.447944 30701 solver.cpp:330] Iteration 14000, Testing net (#0)
I0526 16:53:36.397954 30701 solver.cpp:397]     Test net output #0: accuracy = 0.584
I0526 16:53:36.398139 30701 solver.cpp:397]     Test net output #1: loss = 1.35202 (* 1 = 1.35202 loss)
I0526 16:53:36.677392 30701 solver.cpp:218] Iteration 14000 (3.17063 iter/s, 31.5395s/100 iters), loss = 0.369087
I0526 16:53:36.677446 30701 solver.cpp:237]     Train net output #0: loss = 0.369086 (* 1 = 0.369086 loss)
I0526 16:53:36.677455 30701 sgd_solver.cpp:105] Iteration 14000, lr = 0.0093
I0526 16:54:04.849596 30701 solver.cpp:218] Iteration 14100 (3.54967 iter/s, 28.1717s/100 iters), loss = 0.533521
I0526 16:54:04.849644 30701 solver.cpp:237]     Train net output #0: loss = 0.533521 (* 1 = 0.533521 loss)
I0526 16:54:04.849668 30701 sgd_solver.cpp:105] Iteration 14100, lr = 0.009295
I0526 16:54:28.230347 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:54:33.001556 30701 solver.cpp:218] Iteration 14200 (3.55222 iter/s, 28.1514s/100 iters), loss = 0.575549
I0526 16:54:33.001603 30701 solver.cpp:237]     Train net output #0: loss = 0.575549 (* 1 = 0.575549 loss)
I0526 16:54:33.001612 30701 sgd_solver.cpp:105] Iteration 14200, lr = 0.00929
I0526 16:55:01.149549 30701 solver.cpp:218] Iteration 14300 (3.55272 iter/s, 28.1474s/100 iters), loss = 0.850889
I0526 16:55:01.149798 30701 solver.cpp:237]     Train net output #0: loss = 0.850888 (* 1 = 0.850888 loss)
I0526 16:55:01.149811 30701 sgd_solver.cpp:105] Iteration 14300, lr = 0.009285
I0526 16:55:29.303665 30701 solver.cpp:218] Iteration 14400 (3.55197 iter/s, 28.1534s/100 iters), loss = 0.782866
I0526 16:55:29.303724 30701 solver.cpp:237]     Train net output #0: loss = 0.782866 (* 1 = 0.782866 loss)
I0526 16:55:29.303732 30701 sgd_solver.cpp:105] Iteration 14400, lr = 0.00928
I0526 16:55:57.467744 30701 solver.cpp:218] Iteration 14500 (3.55069 iter/s, 28.1635s/100 iters), loss = 0.703469
I0526 16:55:57.467980 30701 solver.cpp:237]     Train net output #0: loss = 0.703468 (* 1 = 0.703468 loss)
I0526 16:55:57.467993 30701 sgd_solver.cpp:105] Iteration 14500, lr = 0.009275
I0526 16:56:25.625449 30701 solver.cpp:218] Iteration 14600 (3.55152 iter/s, 28.157s/100 iters), loss = 0.20888
I0526 16:56:25.625499 30701 solver.cpp:237]     Train net output #0: loss = 0.208879 (* 1 = 0.208879 loss)
I0526 16:56:25.625507 30701 sgd_solver.cpp:105] Iteration 14600, lr = 0.00927
I0526 16:56:53.765036 30701 solver.cpp:218] Iteration 14700 (3.55378 iter/s, 28.139s/100 iters), loss = 0.427143
I0526 16:56:53.765202 30701 solver.cpp:237]     Train net output #0: loss = 0.427142 (* 1 = 0.427142 loss)
I0526 16:56:53.765213 30701 sgd_solver.cpp:105] Iteration 14700, lr = 0.009265
I0526 16:57:14.616528 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:57:21.916849 30701 solver.cpp:218] Iteration 14800 (3.55225 iter/s, 28.1511s/100 iters), loss = 0.342705
I0526 16:57:21.916893 30701 solver.cpp:237]     Train net output #0: loss = 0.342704 (* 1 = 0.342704 loss)
I0526 16:57:21.916903 30701 sgd_solver.cpp:105] Iteration 14800, lr = 0.00926
I0526 16:57:50.057898 30701 solver.cpp:218] Iteration 14900 (3.5536 iter/s, 28.1405s/100 iters), loss = 0.210451
I0526 16:57:50.058091 30701 solver.cpp:237]     Train net output #0: loss = 0.210451 (* 1 = 0.210451 loss)
I0526 16:57:50.058104 30701 sgd_solver.cpp:105] Iteration 14900, lr = 0.009255
I0526 16:58:17.943260 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_15000.caffemodel
I0526 16:58:18.255471 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_15000.solverstate
I0526 16:58:18.403066 30701 solver.cpp:330] Iteration 15000, Testing net (#0)
I0526 16:58:19.497511 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 16:58:21.351021 30701 solver.cpp:397]     Test net output #0: accuracy = 0.626
I0526 16:58:21.351275 30701 solver.cpp:397]     Test net output #1: loss = 1.18178 (* 1 = 1.18178 loss)
I0526 16:58:21.630861 30701 solver.cpp:218] Iteration 15000 (3.16734 iter/s, 31.5722s/100 iters), loss = 0.403759
I0526 16:58:21.630909 30701 solver.cpp:237]     Train net output #0: loss = 0.403758 (* 1 = 0.403758 loss)
I0526 16:58:21.630918 30701 sgd_solver.cpp:105] Iteration 15000, lr = 0.00925
I0526 16:58:49.739753 30701 solver.cpp:218] Iteration 15100 (3.55767 iter/s, 28.1083s/100 iters), loss = 0.639463
I0526 16:58:49.739799 30701 solver.cpp:237]     Train net output #0: loss = 0.639462 (* 1 = 0.639462 loss)
I0526 16:58:49.739809 30701 sgd_solver.cpp:105] Iteration 15100, lr = 0.009245
I0526 16:59:17.847458 30701 solver.cpp:218] Iteration 15200 (3.55782 iter/s, 28.1071s/100 iters), loss = 0.898399
I0526 16:59:17.847604 30701 solver.cpp:237]     Train net output #0: loss = 0.898398 (* 1 = 0.898398 loss)
I0526 16:59:17.847614 30701 sgd_solver.cpp:105] Iteration 15200, lr = 0.00924
I0526 16:59:45.971457 30701 solver.cpp:218] Iteration 15300 (3.55577 iter/s, 28.1233s/100 iters), loss = 0.32868
I0526 16:59:45.971501 30701 solver.cpp:237]     Train net output #0: loss = 0.32868 (* 1 = 0.32868 loss)
I0526 16:59:45.971509 30701 sgd_solver.cpp:105] Iteration 15300, lr = 0.009235
I0526 17:00:04.277299 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:00:14.091472 30701 solver.cpp:218] Iteration 15400 (3.55626 iter/s, 28.1194s/100 iters), loss = 0.723261
I0526 17:00:14.091547 30701 solver.cpp:237]     Train net output #0: loss = 0.72326 (* 1 = 0.72326 loss)
I0526 17:00:14.091555 30701 sgd_solver.cpp:105] Iteration 15400, lr = 0.00923
I0526 17:00:42.367365 30701 solver.cpp:218] Iteration 15500 (3.53666 iter/s, 28.2753s/100 iters), loss = 0.58731
I0526 17:00:42.367522 30701 solver.cpp:237]     Train net output #0: loss = 0.587309 (* 1 = 0.587309 loss)
I0526 17:00:42.367534 30701 sgd_solver.cpp:105] Iteration 15500, lr = 0.009225
I0526 17:01:10.496534 30701 solver.cpp:218] Iteration 15600 (3.55512 iter/s, 28.1285s/100 iters), loss = 0.335794
I0526 17:01:10.496577 30701 solver.cpp:237]     Train net output #0: loss = 0.335793 (* 1 = 0.335793 loss)
I0526 17:01:10.496587 30701 sgd_solver.cpp:105] Iteration 15600, lr = 0.00922
I0526 17:01:38.621876 30701 solver.cpp:218] Iteration 15700 (3.55559 iter/s, 28.1248s/100 iters), loss = 0.420084
I0526 17:01:38.622048 30701 solver.cpp:237]     Train net output #0: loss = 0.420083 (* 1 = 0.420083 loss)
I0526 17:01:38.622061 30701 sgd_solver.cpp:105] Iteration 15700, lr = 0.009215
I0526 17:02:06.757607 30701 solver.cpp:218] Iteration 15800 (3.55429 iter/s, 28.135s/100 iters), loss = 0.461475
I0526 17:02:06.757658 30701 solver.cpp:237]     Train net output #0: loss = 0.461475 (* 1 = 0.461475 loss)
I0526 17:02:06.757665 30701 sgd_solver.cpp:105] Iteration 15800, lr = 0.00921
I0526 17:02:34.883275 30701 solver.cpp:218] Iteration 15900 (3.55555 iter/s, 28.1251s/100 iters), loss = 0.24139
I0526 17:02:34.883429 30701 solver.cpp:237]     Train net output #0: loss = 0.24139 (* 1 = 0.24139 loss)
I0526 17:02:34.883451 30701 sgd_solver.cpp:105] Iteration 15900, lr = 0.009205
I0526 17:02:50.935930 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:03:02.747349 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_16000.caffemodel
I0526 17:03:03.056689 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_16000.solverstate
I0526 17:03:03.203717 30701 solver.cpp:330] Iteration 16000, Testing net (#0)
I0526 17:03:06.166199 30701 solver.cpp:397]     Test net output #0: accuracy = 0.588
I0526 17:03:06.166347 30701 solver.cpp:397]     Test net output #1: loss = 1.36132 (* 1 = 1.36132 loss)
I0526 17:03:06.446040 30701 solver.cpp:218] Iteration 16000 (3.16837 iter/s, 31.562s/100 iters), loss = 0.992733
I0526 17:03:06.446085 30701 solver.cpp:237]     Train net output #0: loss = 0.992732 (* 1 = 0.992732 loss)
I0526 17:03:06.446094 30701 sgd_solver.cpp:105] Iteration 16000, lr = 0.0092
I0526 17:03:34.573925 30701 solver.cpp:218] Iteration 16100 (3.55527 iter/s, 28.1273s/100 iters), loss = 0.364972
I0526 17:03:34.573974 30701 solver.cpp:237]     Train net output #0: loss = 0.364971 (* 1 = 0.364971 loss)
I0526 17:03:34.573983 30701 sgd_solver.cpp:105] Iteration 16100, lr = 0.009195
I0526 17:04:02.730999 30701 solver.cpp:218] Iteration 16200 (3.55158 iter/s, 28.1565s/100 iters), loss = 0.84972
I0526 17:04:02.731192 30701 solver.cpp:237]     Train net output #0: loss = 0.84972 (* 1 = 0.84972 loss)
I0526 17:04:02.731204 30701 sgd_solver.cpp:105] Iteration 16200, lr = 0.00919
I0526 17:04:30.878312 30701 solver.cpp:218] Iteration 16300 (3.55283 iter/s, 28.1466s/100 iters), loss = 0.238248
I0526 17:04:30.878355 30701 solver.cpp:237]     Train net output #0: loss = 0.238247 (* 1 = 0.238247 loss)
I0526 17:04:30.878363 30701 sgd_solver.cpp:105] Iteration 16300, lr = 0.009185
I0526 17:04:59.034493 30701 solver.cpp:218] Iteration 16400 (3.55169 iter/s, 28.1556s/100 iters), loss = 0.324493
I0526 17:04:59.034654 30701 solver.cpp:237]     Train net output #0: loss = 0.324493 (* 1 = 0.324493 loss)
I0526 17:04:59.034665 30701 sgd_solver.cpp:105] Iteration 16400, lr = 0.00918
I0526 17:05:27.184864 30701 solver.cpp:218] Iteration 16500 (3.55244 iter/s, 28.1497s/100 iters), loss = 0.431452
I0526 17:05:27.184911 30701 solver.cpp:237]     Train net output #0: loss = 0.431452 (* 1 = 0.431452 loss)
I0526 17:05:27.184924 30701 sgd_solver.cpp:105] Iteration 16500, lr = 0.009175
I0526 17:05:40.719074 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:05:55.339207 30701 solver.cpp:218] Iteration 16600 (3.55192 iter/s, 28.1537s/100 iters), loss = 0.48554
I0526 17:05:55.339257 30701 solver.cpp:237]     Train net output #0: loss = 0.485539 (* 1 = 0.485539 loss)
I0526 17:05:55.339269 30701 sgd_solver.cpp:105] Iteration 16600, lr = 0.00917
I0526 17:06:23.496304 30701 solver.cpp:218] Iteration 16700 (3.55158 iter/s, 28.1565s/100 iters), loss = 0.540239
I0526 17:06:23.496462 30701 solver.cpp:237]     Train net output #0: loss = 0.540239 (* 1 = 0.540239 loss)
I0526 17:06:23.496479 30701 sgd_solver.cpp:105] Iteration 16700, lr = 0.009165
I0526 17:06:51.650496 30701 solver.cpp:218] Iteration 16800 (3.55196 iter/s, 28.1535s/100 iters), loss = 0.179863
I0526 17:06:51.650552 30701 solver.cpp:237]     Train net output #0: loss = 0.179863 (* 1 = 0.179863 loss)
I0526 17:06:51.650578 30701 sgd_solver.cpp:105] Iteration 16800, lr = 0.00916
I0526 17:07:19.808529 30701 solver.cpp:218] Iteration 16900 (3.55146 iter/s, 28.1574s/100 iters), loss = 0.345658
I0526 17:07:19.808744 30701 solver.cpp:237]     Train net output #0: loss = 0.345657 (* 1 = 0.345657 loss)
I0526 17:07:19.808761 30701 sgd_solver.cpp:105] Iteration 16900, lr = 0.009155
I0526 17:07:47.678201 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_17000.caffemodel
I0526 17:07:47.989121 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_17000.solverstate
I0526 17:07:48.136582 30701 solver.cpp:330] Iteration 17000, Testing net (#0)
I0526 17:07:50.923738 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:07:51.101158 30701 solver.cpp:397]     Test net output #0: accuracy = 0.636
I0526 17:07:51.101207 30701 solver.cpp:397]     Test net output #1: loss = 1.24466 (* 1 = 1.24466 loss)
I0526 17:07:51.381955 30701 solver.cpp:218] Iteration 17000 (3.1673 iter/s, 31.5726s/100 iters), loss = 0.627369
I0526 17:07:51.382004 30701 solver.cpp:237]     Train net output #0: loss = 0.627368 (* 1 = 0.627368 loss)
I0526 17:07:51.382014 30701 sgd_solver.cpp:105] Iteration 17000, lr = 0.00915
I0526 17:08:19.498607 30701 solver.cpp:218] Iteration 17100 (3.55669 iter/s, 28.116s/100 iters), loss = 0.160872
I0526 17:08:19.498654 30701 solver.cpp:237]     Train net output #0: loss = 0.160871 (* 1 = 0.160871 loss)
I0526 17:08:19.498662 30701 sgd_solver.cpp:105] Iteration 17100, lr = 0.009145
I0526 17:08:30.477300 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:08:47.620399 30701 solver.cpp:218] Iteration 17200 (3.55604 iter/s, 28.1212s/100 iters), loss = 0.446783
I0526 17:08:47.620460 30701 solver.cpp:237]     Train net output #0: loss = 0.446782 (* 1 = 0.446782 loss)
I0526 17:08:47.620468 30701 sgd_solver.cpp:105] Iteration 17200, lr = 0.00914
I0526 17:09:15.773334 30701 solver.cpp:218] Iteration 17300 (3.55211 iter/s, 28.1523s/100 iters), loss = 0.208283
I0526 17:09:15.773546 30701 solver.cpp:237]     Train net output #0: loss = 0.208282 (* 1 = 0.208282 loss)
I0526 17:09:15.773558 30701 sgd_solver.cpp:105] Iteration 17300, lr = 0.009135
I0526 17:09:43.930187 30701 solver.cpp:218] Iteration 17400 (3.55163 iter/s, 28.1561s/100 iters), loss = 0.247806
I0526 17:09:43.930233 30701 solver.cpp:237]     Train net output #0: loss = 0.247805 (* 1 = 0.247805 loss)
I0526 17:09:43.930241 30701 sgd_solver.cpp:105] Iteration 17400, lr = 0.00913
I0526 17:10:12.085532 30701 solver.cpp:218] Iteration 17500 (3.5518 iter/s, 28.1547s/100 iters), loss = 0.353676
I0526 17:10:12.085695 30701 solver.cpp:237]     Train net output #0: loss = 0.353675 (* 1 = 0.353675 loss)
I0526 17:10:12.085706 30701 sgd_solver.cpp:105] Iteration 17500, lr = 0.009125
I0526 17:10:40.233361 30701 solver.cpp:218] Iteration 17600 (3.55276 iter/s, 28.1471s/100 iters), loss = 0.421424
I0526 17:10:40.233407 30701 solver.cpp:237]     Train net output #0: loss = 0.421423 (* 1 = 0.421423 loss)
I0526 17:10:40.233414 30701 sgd_solver.cpp:105] Iteration 17600, lr = 0.00912
I0526 17:11:08.359166 30701 solver.cpp:218] Iteration 17700 (3.55553 iter/s, 28.1252s/100 iters), loss = 0.384077
I0526 17:11:08.359318 30701 solver.cpp:237]     Train net output #0: loss = 0.384076 (* 1 = 0.384076 loss)
I0526 17:11:08.359330 30701 sgd_solver.cpp:105] Iteration 17700, lr = 0.009115
I0526 17:11:16.819272 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:11:36.501736 30701 solver.cpp:218] Iteration 17800 (3.55343 iter/s, 28.1419s/100 iters), loss = 0.286333
I0526 17:11:36.501780 30701 solver.cpp:237]     Train net output #0: loss = 0.286332 (* 1 = 0.286332 loss)
I0526 17:11:36.501788 30701 sgd_solver.cpp:105] Iteration 17800, lr = 0.00911
I0526 17:12:04.643347 30701 solver.cpp:218] Iteration 17900 (3.55353 iter/s, 28.141s/100 iters), loss = 0.20941
I0526 17:12:04.643501 30701 solver.cpp:237]     Train net output #0: loss = 0.209409 (* 1 = 0.209409 loss)
I0526 17:12:04.643512 30701 sgd_solver.cpp:105] Iteration 17900, lr = 0.009105
I0526 17:12:32.511783 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_18000.caffemodel
I0526 17:12:32.820574 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_18000.solverstate
I0526 17:12:32.967671 30701 solver.cpp:330] Iteration 18000, Testing net (#0)
I0526 17:12:35.926556 30701 solver.cpp:397]     Test net output #0: accuracy = 0.648
I0526 17:12:35.926676 30701 solver.cpp:397]     Test net output #1: loss = 1.14375 (* 1 = 1.14375 loss)
I0526 17:12:36.206251 30701 solver.cpp:218] Iteration 18000 (3.16835 iter/s, 31.5621s/100 iters), loss = 0.225297
I0526 17:12:36.206295 30701 solver.cpp:237]     Train net output #0: loss = 0.225296 (* 1 = 0.225296 loss)
I0526 17:12:36.206305 30701 sgd_solver.cpp:105] Iteration 18000, lr = 0.0091
I0526 17:13:04.366619 30701 solver.cpp:218] Iteration 18100 (3.55117 iter/s, 28.1598s/100 iters), loss = 0.351194
I0526 17:13:04.366678 30701 solver.cpp:237]     Train net output #0: loss = 0.351193 (* 1 = 0.351193 loss)
I0526 17:13:04.366688 30701 sgd_solver.cpp:105] Iteration 18100, lr = 0.009095
I0526 17:13:32.476701 30701 solver.cpp:218] Iteration 18200 (3.55752 iter/s, 28.1095s/100 iters), loss = 0.593828
I0526 17:13:32.476914 30701 solver.cpp:237]     Train net output #0: loss = 0.593826 (* 1 = 0.593826 loss)
I0526 17:13:32.476927 30701 sgd_solver.cpp:105] Iteration 18200, lr = 0.00909
I0526 17:14:00.609043 30701 solver.cpp:218] Iteration 18300 (3.55472 iter/s, 28.1316s/100 iters), loss = 0.422849
I0526 17:14:00.609100 30701 solver.cpp:237]     Train net output #0: loss = 0.422847 (* 1 = 0.422847 loss)
I0526 17:14:00.609110 30701 sgd_solver.cpp:105] Iteration 18300, lr = 0.009085
I0526 17:14:06.541019 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:14:28.766708 30701 solver.cpp:218] Iteration 18400 (3.55151 iter/s, 28.157s/100 iters), loss = 0.630292
I0526 17:14:28.766764 30701 solver.cpp:237]     Train net output #0: loss = 0.630291 (* 1 = 0.630291 loss)
I0526 17:14:28.766773 30701 sgd_solver.cpp:105] Iteration 18400, lr = 0.00908
I0526 17:14:56.864336 30701 solver.cpp:218] Iteration 18500 (3.5591 iter/s, 28.097s/100 iters), loss = 0.353709
I0526 17:14:56.864511 30701 solver.cpp:237]     Train net output #0: loss = 0.353707 (* 1 = 0.353707 loss)
I0526 17:14:56.864521 30701 sgd_solver.cpp:105] Iteration 18500, lr = 0.009075
I0526 17:15:24.963471 30701 solver.cpp:218] Iteration 18600 (3.55892 iter/s, 28.0984s/100 iters), loss = 0.193358
I0526 17:15:24.963517 30701 solver.cpp:237]     Train net output #0: loss = 0.193356 (* 1 = 0.193356 loss)
I0526 17:15:24.963526 30701 sgd_solver.cpp:105] Iteration 18600, lr = 0.00907
I0526 17:15:53.072691 30701 solver.cpp:218] Iteration 18700 (3.55763 iter/s, 28.1086s/100 iters), loss = 0.266336
I0526 17:15:53.072891 30701 solver.cpp:237]     Train net output #0: loss = 0.266335 (* 1 = 0.266335 loss)
I0526 17:15:53.072903 30701 sgd_solver.cpp:105] Iteration 18700, lr = 0.009065
I0526 17:16:21.205518 30701 solver.cpp:218] Iteration 18800 (3.55466 iter/s, 28.1321s/100 iters), loss = 0.288117
I0526 17:16:21.205562 30701 solver.cpp:237]     Train net output #0: loss = 0.288116 (* 1 = 0.288116 loss)
I0526 17:16:21.205571 30701 sgd_solver.cpp:105] Iteration 18800, lr = 0.00906
I0526 17:16:49.310163 30701 solver.cpp:218] Iteration 18900 (3.55821 iter/s, 28.104s/100 iters), loss = 0.313111
I0526 17:16:49.310319 30701 solver.cpp:237]     Train net output #0: loss = 0.313109 (* 1 = 0.313109 loss)
I0526 17:16:49.310334 30701 sgd_solver.cpp:105] Iteration 18900, lr = 0.009055
I0526 17:16:52.705569 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:17:17.139942 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_19000.caffemodel
I0526 17:17:17.452168 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_19000.solverstate
I0526 17:17:17.599491 30701 solver.cpp:330] Iteration 19000, Testing net (#0)
I0526 17:17:20.555179 30701 solver.cpp:397]     Test net output #0: accuracy = 0.576
I0526 17:17:20.555339 30701 solver.cpp:397]     Test net output #1: loss = 1.65797 (* 1 = 1.65797 loss)
I0526 17:17:20.835780 30701 solver.cpp:218] Iteration 19000 (3.1721 iter/s, 31.5248s/100 iters), loss = 0.253396
I0526 17:17:20.835840 30701 solver.cpp:237]     Train net output #0: loss = 0.253395 (* 1 = 0.253395 loss)
I0526 17:17:20.835850 30701 sgd_solver.cpp:105] Iteration 19000, lr = 0.00905
I0526 17:17:48.955966 30701 solver.cpp:218] Iteration 19100 (3.55624 iter/s, 28.1196s/100 iters), loss = 0.247542
I0526 17:17:48.956013 30701 solver.cpp:237]     Train net output #0: loss = 0.247541 (* 1 = 0.247541 loss)
I0526 17:17:48.956022 30701 sgd_solver.cpp:105] Iteration 19100, lr = 0.009045
I0526 17:18:17.090428 30701 solver.cpp:218] Iteration 19200 (3.55444 iter/s, 28.1338s/100 iters), loss = 0.595709
I0526 17:18:17.090589 30701 solver.cpp:237]     Train net output #0: loss = 0.595708 (* 1 = 0.595708 loss)
I0526 17:18:17.090600 30701 sgd_solver.cpp:105] Iteration 19200, lr = 0.00904
I0526 17:18:45.233631 30701 solver.cpp:218] Iteration 19300 (3.55335 iter/s, 28.1425s/100 iters), loss = 0.445725
I0526 17:18:45.233674 30701 solver.cpp:237]     Train net output #0: loss = 0.445724 (* 1 = 0.445724 loss)
I0526 17:18:45.233682 30701 sgd_solver.cpp:105] Iteration 19300, lr = 0.009035
I0526 17:19:13.364878 30701 solver.cpp:218] Iteration 19400 (3.55484 iter/s, 28.1306s/100 iters), loss = 0.413644
I0526 17:19:13.365152 30701 solver.cpp:237]     Train net output #0: loss = 0.413643 (* 1 = 0.413643 loss)
I0526 17:19:13.365165 30701 sgd_solver.cpp:105] Iteration 19400, lr = 0.00903
I0526 17:19:41.489011 30701 solver.cpp:218] Iteration 19500 (3.55577 iter/s, 28.1233s/100 iters), loss = 0.201879
I0526 17:19:41.489066 30701 solver.cpp:237]     Train net output #0: loss = 0.201878 (* 1 = 0.201878 loss)
I0526 17:19:41.489075 30701 sgd_solver.cpp:105] Iteration 19500, lr = 0.009025
I0526 17:19:42.357718 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:20:09.643821 30701 solver.cpp:218] Iteration 19600 (3.55187 iter/s, 28.1542s/100 iters), loss = 0.320639
I0526 17:20:09.644040 30701 solver.cpp:237]     Train net output #0: loss = 0.320638 (* 1 = 0.320638 loss)
I0526 17:20:09.644064 30701 sgd_solver.cpp:105] Iteration 19600, lr = 0.00902
I0526 17:20:37.789769 30701 solver.cpp:218] Iteration 19700 (3.55301 iter/s, 28.1452s/100 iters), loss = 0.70236
I0526 17:20:37.789815 30701 solver.cpp:237]     Train net output #0: loss = 0.702359 (* 1 = 0.702359 loss)
I0526 17:20:37.789824 30701 sgd_solver.cpp:105] Iteration 19700, lr = 0.009015
I0526 17:21:05.943286 30701 solver.cpp:218] Iteration 19800 (3.55203 iter/s, 28.1529s/100 iters), loss = 0.436046
I0526 17:21:05.943411 30701 solver.cpp:237]     Train net output #0: loss = 0.436045 (* 1 = 0.436045 loss)
I0526 17:21:05.943421 30701 sgd_solver.cpp:105] Iteration 19800, lr = 0.00901
I0526 17:21:34.083946 30701 solver.cpp:218] Iteration 19900 (3.55366 iter/s, 28.14s/100 iters), loss = 0.206447
I0526 17:21:34.083998 30701 solver.cpp:237]     Train net output #0: loss = 0.206446 (* 1 = 0.206446 loss)
I0526 17:21:34.084007 30701 sgd_solver.cpp:105] Iteration 19900, lr = 0.009005
I0526 17:22:01.946847 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_20000.caffemodel
I0526 17:22:02.256614 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_20000.solverstate
I0526 17:22:02.405673 30701 solver.cpp:330] Iteration 20000, Testing net (#0)
I0526 17:22:03.918507 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:22:05.368643 30701 solver.cpp:397]     Test net output #0: accuracy = 0.618
I0526 17:22:05.368680 30701 solver.cpp:397]     Test net output #1: loss = 1.2651 (* 1 = 1.2651 loss)
I0526 17:22:05.647847 30701 solver.cpp:218] Iteration 20000 (3.16825 iter/s, 31.5632s/100 iters), loss = 0.476141
I0526 17:22:05.647894 30701 solver.cpp:237]     Train net output #0: loss = 0.47614 (* 1 = 0.47614 loss)
I0526 17:22:05.647903 30701 sgd_solver.cpp:105] Iteration 20000, lr = 0.009
I0526 17:22:32.378865 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:22:33.776016 30701 solver.cpp:218] Iteration 20100 (3.55529 iter/s, 28.1271s/100 iters), loss = 0.336696
I0526 17:22:33.776063 30701 solver.cpp:237]     Train net output #0: loss = 0.336695 (* 1 = 0.336695 loss)
I0526 17:22:33.776072 30701 sgd_solver.cpp:105] Iteration 20100, lr = 0.008995
I0526 17:23:01.904891 30701 solver.cpp:218] Iteration 20200 (3.5552 iter/s, 28.1278s/100 iters), loss = 0.261557
I0526 17:23:01.904935 30701 solver.cpp:237]     Train net output #0: loss = 0.261556 (* 1 = 0.261556 loss)
I0526 17:23:01.904944 30701 sgd_solver.cpp:105] Iteration 20200, lr = 0.00899
I0526 17:23:30.062913 30701 solver.cpp:218] Iteration 20300 (3.55152 iter/s, 28.157s/100 iters), loss = 0.619636
I0526 17:23:30.063081 30701 solver.cpp:237]     Train net output #0: loss = 0.619635 (* 1 = 0.619635 loss)
I0526 17:23:30.063094 30701 sgd_solver.cpp:105] Iteration 20300, lr = 0.008985
I0526 17:23:58.223311 30701 solver.cpp:218] Iteration 20400 (3.55123 iter/s, 28.1592s/100 iters), loss = 0.424121
I0526 17:23:58.223358 30701 solver.cpp:237]     Train net output #0: loss = 0.42412 (* 1 = 0.42412 loss)
I0526 17:23:58.223367 30701 sgd_solver.cpp:105] Iteration 20400, lr = 0.00898
I0526 17:24:26.388250 30701 solver.cpp:218] Iteration 20500 (3.55064 iter/s, 28.1639s/100 iters), loss = 0.258423
I0526 17:24:26.388413 30701 solver.cpp:237]     Train net output #0: loss = 0.258422 (* 1 = 0.258422 loss)
I0526 17:24:26.388424 30701 sgd_solver.cpp:105] Iteration 20500, lr = 0.008975
I0526 17:24:54.558425 30701 solver.cpp:218] Iteration 20600 (3.54999 iter/s, 28.1691s/100 iters), loss = 0.234388
I0526 17:24:54.558470 30701 solver.cpp:237]     Train net output #0: loss = 0.234387 (* 1 = 0.234387 loss)
I0526 17:24:54.558478 30701 sgd_solver.cpp:105] Iteration 20600, lr = 0.00897
I0526 17:25:18.777665 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:25:22.695996 30701 solver.cpp:218] Iteration 20700 (3.55409 iter/s, 28.1366s/100 iters), loss = 0.282406
I0526 17:25:22.696050 30701 solver.cpp:237]     Train net output #0: loss = 0.282405 (* 1 = 0.282405 loss)
I0526 17:25:22.696059 30701 sgd_solver.cpp:105] Iteration 20700, lr = 0.008965
I0526 17:25:50.787369 30701 solver.cpp:218] Iteration 20800 (3.55994 iter/s, 28.0904s/100 iters), loss = 0.496838
I0526 17:25:50.787518 30701 solver.cpp:237]     Train net output #0: loss = 0.496836 (* 1 = 0.496836 loss)
I0526 17:25:50.787528 30701 sgd_solver.cpp:105] Iteration 20800, lr = 0.00896
I0526 17:26:18.874238 30701 solver.cpp:218] Iteration 20900 (3.56051 iter/s, 28.0858s/100 iters), loss = 1.00322
I0526 17:26:18.874281 30701 solver.cpp:237]     Train net output #0: loss = 1.00322 (* 1 = 1.00322 loss)
I0526 17:26:18.874289 30701 sgd_solver.cpp:105] Iteration 20900, lr = 0.008955
I0526 17:26:46.689846 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_21000.caffemodel
I0526 17:26:46.999147 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_21000.solverstate
I0526 17:26:47.146208 30701 solver.cpp:330] Iteration 21000, Testing net (#0)
I0526 17:26:50.110455 30701 solver.cpp:397]     Test net output #0: accuracy = 0.654
I0526 17:26:50.110491 30701 solver.cpp:397]     Test net output #1: loss = 1.27151 (* 1 = 1.27151 loss)
I0526 17:26:50.389547 30701 solver.cpp:218] Iteration 21000 (3.17317 iter/s, 31.5143s/100 iters), loss = 0.275685
I0526 17:26:50.389592 30701 solver.cpp:237]     Train net output #0: loss = 0.275684 (* 1 = 0.275684 loss)
I0526 17:26:50.389601 30701 sgd_solver.cpp:105] Iteration 21000, lr = 0.00895
I0526 17:27:18.520812 30701 solver.cpp:218] Iteration 21100 (3.55488 iter/s, 28.1303s/100 iters), loss = 0.142238
I0526 17:27:18.521020 30701 solver.cpp:237]     Train net output #0: loss = 0.142237 (* 1 = 0.142237 loss)
I0526 17:27:18.521031 30701 sgd_solver.cpp:105] Iteration 21100, lr = 0.008945
I0526 17:27:46.648202 30701 solver.cpp:218] Iteration 21200 (3.55539 iter/s, 28.1263s/100 iters), loss = 0.0583028
I0526 17:27:46.648257 30701 solver.cpp:237]     Train net output #0: loss = 0.0583017 (* 1 = 0.0583017 loss)
I0526 17:27:46.648267 30701 sgd_solver.cpp:105] Iteration 21200, lr = 0.00894
I0526 17:28:08.323863 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:28:14.784258 30701 solver.cpp:218] Iteration 21300 (3.55427 iter/s, 28.1351s/100 iters), loss = 0.370017
I0526 17:28:14.784307 30701 solver.cpp:237]     Train net output #0: loss = 0.370016 (* 1 = 0.370016 loss)
I0526 17:28:14.784314 30701 sgd_solver.cpp:105] Iteration 21300, lr = 0.008935
I0526 17:28:42.922658 30701 solver.cpp:218] Iteration 21400 (3.55398 iter/s, 28.1375s/100 iters), loss = 0.37533
I0526 17:28:42.922782 30701 solver.cpp:237]     Train net output #0: loss = 0.375329 (* 1 = 0.375329 loss)
I0526 17:28:42.922792 30701 sgd_solver.cpp:105] Iteration 21400, lr = 0.00893
I0526 17:29:11.080772 30701 solver.cpp:218] Iteration 21500 (3.55149 iter/s, 28.1572s/100 iters), loss = 0.544533
I0526 17:29:11.080831 30701 solver.cpp:237]     Train net output #0: loss = 0.544532 (* 1 = 0.544532 loss)
I0526 17:29:11.080839 30701 sgd_solver.cpp:105] Iteration 21500, lr = 0.008925
I0526 17:29:39.772701 30701 solver.cpp:218] Iteration 21600 (3.48541 iter/s, 28.691s/100 iters), loss = 0.155434
I0526 17:29:39.772826 30701 solver.cpp:237]     Train net output #0: loss = 0.155432 (* 1 = 0.155432 loss)
I0526 17:29:39.772850 30701 sgd_solver.cpp:105] Iteration 21600, lr = 0.00892
I0526 17:30:08.350464 30701 solver.cpp:218] Iteration 21700 (3.49934 iter/s, 28.5768s/100 iters), loss = 0.200073
I0526 17:30:08.350513 30701 solver.cpp:237]     Train net output #0: loss = 0.200072 (* 1 = 0.200072 loss)
I0526 17:30:08.350522 30701 sgd_solver.cpp:105] Iteration 21700, lr = 0.008915
I0526 17:30:37.118645 30701 solver.cpp:218] Iteration 21800 (3.47617 iter/s, 28.7673s/100 iters), loss = 0.29267
I0526 17:30:37.118854 30701 solver.cpp:237]     Train net output #0: loss = 0.292669 (* 1 = 0.292669 loss)
I0526 17:30:37.118866 30701 sgd_solver.cpp:105] Iteration 21800, lr = 0.00891
I0526 17:30:56.389952 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:31:05.532691 30701 solver.cpp:218] Iteration 21900 (3.51951 iter/s, 28.4131s/100 iters), loss = 0.284539
I0526 17:31:05.532742 30701 solver.cpp:237]     Train net output #0: loss = 0.284538 (* 1 = 0.284538 loss)
I0526 17:31:05.532752 30701 sgd_solver.cpp:105] Iteration 21900, lr = 0.008905
I0526 17:31:33.693858 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_22000.caffemodel
I0526 17:31:34.003639 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_22000.solverstate
I0526 17:31:34.149902 30701 solver.cpp:330] Iteration 22000, Testing net (#0)
I0526 17:31:37.113767 30701 solver.cpp:397]     Test net output #0: accuracy = 0.628
I0526 17:31:37.113803 30701 solver.cpp:397]     Test net output #1: loss = 1.55106 (* 1 = 1.55106 loss)
I0526 17:31:37.392432 30701 solver.cpp:218] Iteration 22000 (3.13885 iter/s, 31.8588s/100 iters), loss = 0.311383
I0526 17:31:37.392477 30701 solver.cpp:237]     Train net output #0: loss = 0.311382 (* 1 = 0.311382 loss)
I0526 17:31:37.392485 30701 sgd_solver.cpp:105] Iteration 22000, lr = 0.0089
I0526 17:32:05.559916 30701 solver.cpp:218] Iteration 22100 (3.5503 iter/s, 28.1667s/100 iters), loss = 0.190887
I0526 17:32:05.560078 30701 solver.cpp:237]     Train net output #0: loss = 0.190886 (* 1 = 0.190886 loss)
I0526 17:32:05.560089 30701 sgd_solver.cpp:105] Iteration 22100, lr = 0.008895
I0526 17:32:33.720276 30701 solver.cpp:218] Iteration 22200 (3.55121 iter/s, 28.1594s/100 iters), loss = 0.251947
I0526 17:32:33.720320 30701 solver.cpp:237]     Train net output #0: loss = 0.251946 (* 1 = 0.251946 loss)
I0526 17:32:33.720329 30701 sgd_solver.cpp:105] Iteration 22200, lr = 0.00889
I0526 17:33:02.106760 30701 solver.cpp:218] Iteration 22300 (3.5229 iter/s, 28.3857s/100 iters), loss = 0.232037
I0526 17:33:02.106927 30701 solver.cpp:237]     Train net output #0: loss = 0.232036 (* 1 = 0.232036 loss)
I0526 17:33:02.106942 30701 sgd_solver.cpp:105] Iteration 22300, lr = 0.008885
I0526 17:33:30.851986 30701 solver.cpp:218] Iteration 22400 (3.47895 iter/s, 28.7443s/100 iters), loss = 0.271853
I0526 17:33:30.852061 30701 solver.cpp:237]     Train net output #0: loss = 0.271852 (* 1 = 0.271852 loss)
I0526 17:33:30.852072 30701 sgd_solver.cpp:105] Iteration 22400, lr = 0.00888
I0526 17:33:47.588457 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:33:59.110750 30701 solver.cpp:218] Iteration 22500 (3.53883 iter/s, 28.2579s/100 iters), loss = 0.0905505
I0526 17:33:59.110796 30701 solver.cpp:237]     Train net output #0: loss = 0.0905495 (* 1 = 0.0905495 loss)
I0526 17:33:59.110805 30701 sgd_solver.cpp:105] Iteration 22500, lr = 0.008875
I0526 17:34:27.256503 30701 solver.cpp:218] Iteration 22600 (3.55303 iter/s, 28.145s/100 iters), loss = 0.34178
I0526 17:34:27.256669 30701 solver.cpp:237]     Train net output #0: loss = 0.341779 (* 1 = 0.341779 loss)
I0526 17:34:27.256680 30701 sgd_solver.cpp:105] Iteration 22600, lr = 0.00887
I0526 17:34:55.440248 30701 solver.cpp:218] Iteration 22700 (3.54826 iter/s, 28.1828s/100 iters), loss = 0.499144
I0526 17:34:55.440296 30701 solver.cpp:237]     Train net output #0: loss = 0.499143 (* 1 = 0.499143 loss)
I0526 17:34:55.440305 30701 sgd_solver.cpp:105] Iteration 22700, lr = 0.008865
I0526 17:35:24.227898 30701 solver.cpp:218] Iteration 22800 (3.47381 iter/s, 28.7869s/100 iters), loss = 0.235838
I0526 17:35:24.228080 30701 solver.cpp:237]     Train net output #0: loss = 0.235837 (* 1 = 0.235837 loss)
I0526 17:35:24.228096 30701 sgd_solver.cpp:105] Iteration 22800, lr = 0.00886
I0526 17:35:52.992445 30701 solver.cpp:218] Iteration 22900 (3.47661 iter/s, 28.7636s/100 iters), loss = 0.185305
I0526 17:35:52.992492 30701 solver.cpp:237]     Train net output #0: loss = 0.185304 (* 1 = 0.185304 loss)
I0526 17:35:52.992501 30701 sgd_solver.cpp:105] Iteration 22900, lr = 0.008855
I0526 17:36:21.267510 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_23000.caffemodel
I0526 17:36:21.671944 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_23000.solverstate
I0526 17:36:21.820212 30701 solver.cpp:330] Iteration 23000, Testing net (#0)
I0526 17:36:22.066488 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:36:24.883797 30701 solver.cpp:397]     Test net output #0: accuracy = 0.638
I0526 17:36:24.883843 30701 solver.cpp:397]     Test net output #1: loss = 1.4781 (* 1 = 1.4781 loss)
I0526 17:36:25.177399 30701 solver.cpp:218] Iteration 23000 (3.10713 iter/s, 32.1841s/100 iters), loss = 0.4792
I0526 17:36:25.177464 30701 solver.cpp:237]     Train net output #0: loss = 0.479199 (* 1 = 0.479199 loss)
I0526 17:36:25.177476 30701 sgd_solver.cpp:105] Iteration 23000, lr = 0.00885
I0526 17:36:39.579507 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:36:58.437995 30701 solver.cpp:218] Iteration 23100 (3.00664 iter/s, 33.2597s/100 iters), loss = 0.244408
I0526 17:36:58.438199 30701 solver.cpp:237]     Train net output #0: loss = 0.244407 (* 1 = 0.244407 loss)
I0526 17:36:58.438211 30701 sgd_solver.cpp:105] Iteration 23100, lr = 0.008845
I0526 17:37:40.965903 30701 solver.cpp:218] Iteration 23200 (2.35147 iter/s, 42.5266s/100 iters), loss = 0.28923
I0526 17:37:40.966059 30701 solver.cpp:237]     Train net output #0: loss = 0.289229 (* 1 = 0.289229 loss)
I0526 17:37:40.966073 30701 sgd_solver.cpp:105] Iteration 23200, lr = 0.00884
I0526 17:38:24.745388 30701 solver.cpp:218] Iteration 23300 (2.28424 iter/s, 43.7782s/100 iters), loss = 0.175377
I0526 17:38:24.745565 30701 solver.cpp:237]     Train net output #0: loss = 0.175375 (* 1 = 0.175375 loss)
I0526 17:38:24.745578 30701 sgd_solver.cpp:105] Iteration 23300, lr = 0.008835
I0526 17:39:08.661573 30701 solver.cpp:218] Iteration 23400 (2.27723 iter/s, 43.9131s/100 iters), loss = 0.507997
I0526 17:39:08.661707 30701 solver.cpp:237]     Train net output #0: loss = 0.507995 (* 1 = 0.507995 loss)
I0526 17:39:08.661718 30701 sgd_solver.cpp:105] Iteration 23400, lr = 0.00883
I0526 17:39:52.594305 30701 solver.cpp:218] Iteration 23500 (2.27634 iter/s, 43.9302s/100 iters), loss = 0.161089
I0526 17:39:52.594449 30701 solver.cpp:237]     Train net output #0: loss = 0.161088 (* 1 = 0.161088 loss)
I0526 17:39:52.594460 30701 sgd_solver.cpp:105] Iteration 23500, lr = 0.008825
I0526 17:40:36.525698 30701 solver.cpp:218] Iteration 23600 (2.27634 iter/s, 43.9301s/100 iters), loss = 0.231309
I0526 17:40:36.525863 30701 solver.cpp:237]     Train net output #0: loss = 0.231307 (* 1 = 0.231307 loss)
I0526 17:40:36.525883 30701 sgd_solver.cpp:105] Iteration 23600, lr = 0.00882
I0526 17:40:54.550117 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:41:20.390336 30701 solver.cpp:218] Iteration 23700 (2.27981 iter/s, 43.8634s/100 iters), loss = 0.224823
I0526 17:41:20.390472 30701 solver.cpp:237]     Train net output #0: loss = 0.224822 (* 1 = 0.224822 loss)
I0526 17:41:20.390492 30701 sgd_solver.cpp:105] Iteration 23700, lr = 0.008815
I0526 17:41:53.269654 30701 solver.cpp:218] Iteration 23800 (3.04151 iter/s, 32.8784s/100 iters), loss = 0.177438
I0526 17:41:53.269824 30701 solver.cpp:237]     Train net output #0: loss = 0.177437 (* 1 = 0.177437 loss)
I0526 17:41:53.269837 30701 sgd_solver.cpp:105] Iteration 23800, lr = 0.00881
I0526 17:42:22.468896 30701 solver.cpp:218] Iteration 23900 (3.42486 iter/s, 29.1983s/100 iters), loss = 0.388334
I0526 17:42:22.468953 30701 solver.cpp:237]     Train net output #0: loss = 0.388332 (* 1 = 0.388332 loss)
I0526 17:42:22.468962 30701 sgd_solver.cpp:105] Iteration 23900, lr = 0.008805
I0526 17:42:53.790446 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_24000.caffemodel
I0526 17:42:54.119469 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_24000.solverstate
I0526 17:42:54.273887 30701 solver.cpp:330] Iteration 24000, Testing net (#0)
I0526 17:42:57.633460 30701 solver.cpp:397]     Test net output #0: accuracy = 0.658
I0526 17:42:57.633518 30701 solver.cpp:397]     Test net output #1: loss = 1.27406 (* 1 = 1.27406 loss)
I0526 17:42:57.950217 30701 solver.cpp:218] Iteration 24000 (2.81846 iter/s, 35.4804s/100 iters), loss = 0.175186
I0526 17:42:57.950314 30701 solver.cpp:237]     Train net output #0: loss = 0.175184 (* 1 = 0.175184 loss)
I0526 17:42:57.950330 30701 sgd_solver.cpp:105] Iteration 24000, lr = 0.0088
I0526 17:43:29.875080 30701 solver.cpp:218] Iteration 24100 (3.13244 iter/s, 31.924s/100 iters), loss = 0.0767237
I0526 17:43:29.875264 30701 solver.cpp:237]     Train net output #0: loss = 0.0767221 (* 1 = 0.0767221 loss)
I0526 17:43:29.875280 30701 sgd_solver.cpp:105] Iteration 24100, lr = 0.008795
I0526 17:44:01.528301 30701 solver.cpp:218] Iteration 24200 (3.15933 iter/s, 31.6523s/100 iters), loss = 0.31252
I0526 17:44:01.528451 30701 solver.cpp:237]     Train net output #0: loss = 0.312518 (* 1 = 0.312518 loss)
I0526 17:44:01.528462 30701 sgd_solver.cpp:105] Iteration 24200, lr = 0.00879
I0526 17:44:11.963575 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:44:33.085893 30701 solver.cpp:218] Iteration 24300 (3.1689 iter/s, 31.5567s/100 iters), loss = 0.0606067
I0526 17:44:33.086022 30701 solver.cpp:237]     Train net output #0: loss = 0.0606049 (* 1 = 0.0606049 loss)
I0526 17:44:33.086040 30701 sgd_solver.cpp:105] Iteration 24300, lr = 0.008785
I0526 17:45:04.609038 30701 solver.cpp:218] Iteration 24400 (3.17236 iter/s, 31.5223s/100 iters), loss = 0.188923
I0526 17:45:04.609191 30701 solver.cpp:237]     Train net output #0: loss = 0.188921 (* 1 = 0.188921 loss)
I0526 17:45:04.609203 30701 sgd_solver.cpp:105] Iteration 24400, lr = 0.00878
I0526 17:45:36.118752 30701 solver.cpp:218] Iteration 24500 (3.17372 iter/s, 31.5088s/100 iters), loss = 0.592851
I0526 17:45:36.118932 30701 solver.cpp:237]     Train net output #0: loss = 0.592849 (* 1 = 0.592849 loss)
I0526 17:45:36.118948 30701 sgd_solver.cpp:105] Iteration 24500, lr = 0.008775
I0526 17:46:07.676460 30701 solver.cpp:218] Iteration 24600 (3.16889 iter/s, 31.5568s/100 iters), loss = 0.062922
I0526 17:46:07.676636 30701 solver.cpp:237]     Train net output #0: loss = 0.0629204 (* 1 = 0.0629204 loss)
I0526 17:46:07.676651 30701 sgd_solver.cpp:105] Iteration 24600, lr = 0.00877
I0526 17:46:39.325937 30701 solver.cpp:218] Iteration 24700 (3.1597 iter/s, 31.6486s/100 iters), loss = 0.140036
I0526 17:46:39.326113 30701 solver.cpp:237]     Train net output #0: loss = 0.140035 (* 1 = 0.140035 loss)
I0526 17:46:39.326124 30701 sgd_solver.cpp:105] Iteration 24700, lr = 0.008765
I0526 17:47:10.825137 30701 solver.cpp:218] Iteration 24800 (3.17478 iter/s, 31.4983s/100 iters), loss = 0.169957
I0526 17:47:10.825294 30701 solver.cpp:237]     Train net output #0: loss = 0.169956 (* 1 = 0.169956 loss)
I0526 17:47:10.825314 30701 sgd_solver.cpp:105] Iteration 24800, lr = 0.00876
I0526 17:47:18.405771 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:47:42.313235 30701 solver.cpp:218] Iteration 24900 (3.17589 iter/s, 31.4872s/100 iters), loss = 0.0969553
I0526 17:47:42.313396 30701 solver.cpp:237]     Train net output #0: loss = 0.0969537 (* 1 = 0.0969537 loss)
I0526 17:47:42.313413 30701 sgd_solver.cpp:105] Iteration 24900, lr = 0.008755
I0526 17:48:13.529872 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_25000.caffemodel
I0526 17:48:13.853085 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_25000.solverstate
I0526 17:48:14.005273 30701 solver.cpp:330] Iteration 25000, Testing net (#0)
I0526 17:48:16.113550 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:48:17.295992 30701 solver.cpp:397]     Test net output #0: accuracy = 0.612
I0526 17:48:17.296037 30701 solver.cpp:397]     Test net output #1: loss = 1.73395 (* 1 = 1.73395 loss)
I0526 17:48:17.608026 30701 solver.cpp:218] Iteration 25000 (2.83336 iter/s, 35.2938s/100 iters), loss = 0.283599
I0526 17:48:17.608088 30701 solver.cpp:237]     Train net output #0: loss = 0.283597 (* 1 = 0.283597 loss)
I0526 17:48:17.608100 30701 sgd_solver.cpp:105] Iteration 25000, lr = 0.00875
I0526 17:48:49.092183 30701 solver.cpp:218] Iteration 25100 (3.17628 iter/s, 31.4833s/100 iters), loss = 0.228078
I0526 17:48:49.092365 30701 solver.cpp:237]     Train net output #0: loss = 0.228076 (* 1 = 0.228076 loss)
I0526 17:48:49.092377 30701 sgd_solver.cpp:105] Iteration 25100, lr = 0.008745
I0526 17:49:20.576431 30701 solver.cpp:218] Iteration 25200 (3.17628 iter/s, 31.4833s/100 iters), loss = 0.2866
I0526 17:49:20.576596 30701 solver.cpp:237]     Train net output #0: loss = 0.286598 (* 1 = 0.286598 loss)
I0526 17:49:20.576608 30701 sgd_solver.cpp:105] Iteration 25200, lr = 0.00874
I0526 17:49:51.730175 30701 solver.cpp:218] Iteration 25300 (3.20998 iter/s, 31.1529s/100 iters), loss = 0.0702577
I0526 17:49:51.730386 30701 solver.cpp:237]     Train net output #0: loss = 0.0702562 (* 1 = 0.0702562 loss)
I0526 17:49:51.730403 30701 sgd_solver.cpp:105] Iteration 25300, lr = 0.008735
I0526 17:50:19.940517 30701 solver.cpp:218] Iteration 25400 (3.5449 iter/s, 28.2095s/100 iters), loss = 0.0542007
I0526 17:50:19.940568 30701 solver.cpp:237]     Train net output #0: loss = 0.0541993 (* 1 = 0.0541993 loss)
I0526 17:50:19.940577 30701 sgd_solver.cpp:105] Iteration 25400, lr = 0.00873
I0526 17:50:24.193701 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:50:59.324457 30701 solver.cpp:218] Iteration 25500 (2.53917 iter/s, 39.383s/100 iters), loss = 0.128766
I0526 17:50:59.324683 30701 solver.cpp:237]     Train net output #0: loss = 0.128765 (* 1 = 0.128765 loss)
I0526 17:50:59.324697 30701 sgd_solver.cpp:105] Iteration 25500, lr = 0.008725
I0526 17:51:43.330476 30701 solver.cpp:218] Iteration 25600 (2.27248 iter/s, 44.0048s/100 iters), loss = 0.285674
I0526 17:51:43.330631 30701 solver.cpp:237]     Train net output #0: loss = 0.285672 (* 1 = 0.285672 loss)
I0526 17:51:43.330642 30701 sgd_solver.cpp:105] Iteration 25600, lr = 0.00872
I0526 17:52:27.566568 30701 solver.cpp:218] Iteration 25700 (2.26066 iter/s, 44.2349s/100 iters), loss = 0.181628
I0526 17:52:27.566681 30701 solver.cpp:237]     Train net output #0: loss = 0.181627 (* 1 = 0.181627 loss)
I0526 17:52:27.566696 30701 sgd_solver.cpp:105] Iteration 25700, lr = 0.008715
I0526 17:53:11.587265 30701 solver.cpp:218] Iteration 25800 (2.27172 iter/s, 44.0195s/100 iters), loss = 0.291165
I0526 17:53:11.587389 30701 solver.cpp:237]     Train net output #0: loss = 0.291164 (* 1 = 0.291164 loss)
I0526 17:53:11.587400 30701 sgd_solver.cpp:105] Iteration 25800, lr = 0.00871
I0526 17:53:55.430598 30701 solver.cpp:218] Iteration 25900 (2.28102 iter/s, 43.8401s/100 iters), loss = 0.0915145
I0526 17:53:55.430730 30701 solver.cpp:237]     Train net output #0: loss = 0.0915129 (* 1 = 0.0915129 loss)
I0526 17:53:55.430743 30701 sgd_solver.cpp:105] Iteration 25900, lr = 0.008705
I0526 17:54:39.740160 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_26000.caffemodel
I0526 17:54:40.059552 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_26000.solverstate
I0526 17:54:40.209336 30701 solver.cpp:330] Iteration 26000, Testing net (#0)
I0526 17:54:44.771886 30701 solver.cpp:397]     Test net output #0: accuracy = 0.684
I0526 17:54:44.771937 30701 solver.cpp:397]     Test net output #1: loss = 1.11884 (* 1 = 1.11884 loss)
I0526 17:54:45.197125 30701 solver.cpp:218] Iteration 26000 (2.00944 iter/s, 49.7652s/100 iters), loss = 0.151602
I0526 17:54:45.197199 30701 solver.cpp:237]     Train net output #0: loss = 0.1516 (* 1 = 0.1516 loss)
I0526 17:54:45.197209 30701 sgd_solver.cpp:105] Iteration 26000, lr = 0.0087
I0526 17:54:47.894352 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:55:29.621930 30701 solver.cpp:218] Iteration 26100 (2.25105 iter/s, 44.4237s/100 iters), loss = 0.260392
I0526 17:55:29.622428 30701 solver.cpp:237]     Train net output #0: loss = 0.260391 (* 1 = 0.260391 loss)
I0526 17:55:29.622447 30701 sgd_solver.cpp:105] Iteration 26100, lr = 0.008695
I0526 17:56:14.637501 30701 solver.cpp:218] Iteration 26200 (2.22153 iter/s, 45.014s/100 iters), loss = 0.120804
I0526 17:56:14.637675 30701 solver.cpp:237]     Train net output #0: loss = 0.120803 (* 1 = 0.120803 loss)
I0526 17:56:14.637687 30701 sgd_solver.cpp:105] Iteration 26200, lr = 0.00869
I0526 17:56:59.093613 30701 solver.cpp:218] Iteration 26300 (2.24946 iter/s, 44.455s/100 iters), loss = 0.0439257
I0526 17:56:59.093780 30701 solver.cpp:237]     Train net output #0: loss = 0.0439243 (* 1 = 0.0439243 loss)
I0526 17:56:59.093791 30701 sgd_solver.cpp:105] Iteration 26300, lr = 0.008685
I0526 17:57:43.966897 30701 solver.cpp:218] Iteration 26400 (2.22855 iter/s, 44.8722s/100 iters), loss = 0.217025
I0526 17:57:43.967075 30701 solver.cpp:237]     Train net output #0: loss = 0.217023 (* 1 = 0.217023 loss)
I0526 17:57:43.967098 30701 sgd_solver.cpp:105] Iteration 26400, lr = 0.00868
I0526 17:58:27.959529 30701 solver.cpp:218] Iteration 26500 (2.27327 iter/s, 43.9896s/100 iters), loss = 0.082046
I0526 17:58:27.959686 30701 solver.cpp:237]     Train net output #0: loss = 0.0820445 (* 1 = 0.0820445 loss)
I0526 17:58:27.959697 30701 sgd_solver.cpp:105] Iteration 26500, lr = 0.008675
I0526 17:59:10.667482 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 17:59:11.964329 30701 solver.cpp:218] Iteration 26600 (2.27253 iter/s, 44.0037s/100 iters), loss = 0.0399315
I0526 17:59:11.964401 30701 solver.cpp:237]     Train net output #0: loss = 0.0399301 (* 1 = 0.0399301 loss)
I0526 17:59:11.964416 30701 sgd_solver.cpp:105] Iteration 26600, lr = 0.00867
I0526 17:59:56.082751 30701 solver.cpp:218] Iteration 26700 (2.26668 iter/s, 44.1174s/100 iters), loss = 0.208606
I0526 17:59:56.082916 30701 solver.cpp:237]     Train net output #0: loss = 0.208605 (* 1 = 0.208605 loss)
I0526 17:59:56.082937 30701 sgd_solver.cpp:105] Iteration 26700, lr = 0.008665
I0526 18:00:40.339608 30701 solver.cpp:218] Iteration 26800 (2.25959 iter/s, 44.2558s/100 iters), loss = 0.113747
I0526 18:00:40.339761 30701 solver.cpp:237]     Train net output #0: loss = 0.113746 (* 1 = 0.113746 loss)
I0526 18:00:40.339772 30701 sgd_solver.cpp:105] Iteration 26800, lr = 0.00866
I0526 18:01:25.362093 30701 solver.cpp:218] Iteration 26900 (2.22117 iter/s, 45.0214s/100 iters), loss = 0.179559
I0526 18:01:25.362263 30701 solver.cpp:237]     Train net output #0: loss = 0.179557 (* 1 = 0.179557 loss)
I0526 18:01:25.362278 30701 sgd_solver.cpp:105] Iteration 26900, lr = 0.008655
I0526 18:02:09.535895 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_27000.caffemodel
I0526 18:02:09.896693 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_27000.solverstate
I0526 18:02:10.049721 30701 solver.cpp:330] Iteration 27000, Testing net (#0)
I0526 18:02:14.721792 30701 solver.cpp:397]     Test net output #0: accuracy = 0.582
I0526 18:02:14.721838 30701 solver.cpp:397]     Test net output #1: loss = 1.64952 (* 1 = 1.64952 loss)
I0526 18:02:15.144616 30701 solver.cpp:218] Iteration 27000 (2.00879 iter/s, 49.7813s/100 iters), loss = 0.0552686
I0526 18:02:15.144675 30701 solver.cpp:237]     Train net output #0: loss = 0.055267 (* 1 = 0.055267 loss)
I0526 18:02:15.144685 30701 sgd_solver.cpp:105] Iteration 27000, lr = 0.00865
I0526 18:02:59.271457 30701 solver.cpp:218] Iteration 27100 (2.26625 iter/s, 44.1258s/100 iters), loss = 0.159921
I0526 18:02:59.271723 30701 solver.cpp:237]     Train net output #0: loss = 0.159919 (* 1 = 0.159919 loss)
I0526 18:02:59.271744 30701 sgd_solver.cpp:105] Iteration 27100, lr = 0.008645
I0526 18:03:38.259579 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:03:43.469264 30701 solver.cpp:218] Iteration 27200 (2.26262 iter/s, 44.1966s/100 iters), loss = 0.0565856
I0526 18:03:43.469324 30701 solver.cpp:237]     Train net output #0: loss = 0.056584 (* 1 = 0.056584 loss)
I0526 18:03:43.469334 30701 sgd_solver.cpp:105] Iteration 27200, lr = 0.00864
I0526 18:04:23.319751 30701 solver.cpp:218] Iteration 27300 (2.50956 iter/s, 39.8477s/100 iters), loss = 0.0796442
I0526 18:04:23.319967 30701 solver.cpp:237]     Train net output #0: loss = 0.0796425 (* 1 = 0.0796425 loss)
I0526 18:04:23.319984 30701 sgd_solver.cpp:105] Iteration 27300, lr = 0.008635
I0526 18:04:51.556095 30701 solver.cpp:218] Iteration 27400 (3.54164 iter/s, 28.2355s/100 iters), loss = 0.0803686
I0526 18:04:51.556147 30701 solver.cpp:237]     Train net output #0: loss = 0.0803669 (* 1 = 0.0803669 loss)
I0526 18:04:51.556157 30701 sgd_solver.cpp:105] Iteration 27400, lr = 0.00863
I0526 18:05:20.103483 30701 solver.cpp:218] Iteration 27500 (3.50303 iter/s, 28.5467s/100 iters), loss = 0.0672082
I0526 18:05:20.103646 30701 solver.cpp:237]     Train net output #0: loss = 0.0672064 (* 1 = 0.0672064 loss)
I0526 18:05:20.103657 30701 sgd_solver.cpp:105] Iteration 27500, lr = 0.008625
I0526 18:05:48.519999 30701 solver.cpp:218] Iteration 27600 (3.51918 iter/s, 28.4157s/100 iters), loss = 0.299794
I0526 18:05:48.520054 30701 solver.cpp:237]     Train net output #0: loss = 0.299792 (* 1 = 0.299792 loss)
I0526 18:05:48.520063 30701 sgd_solver.cpp:105] Iteration 27600, lr = 0.00862
I0526 18:06:17.038251 30701 solver.cpp:218] Iteration 27700 (3.50661 iter/s, 28.5176s/100 iters), loss = 0.32882
I0526 18:06:17.038417 30701 solver.cpp:237]     Train net output #0: loss = 0.328818 (* 1 = 0.328818 loss)
I0526 18:06:17.038434 30701 sgd_solver.cpp:105] Iteration 27700, lr = 0.008615
I0526 18:06:40.003767 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:06:45.708446 30701 solver.cpp:218] Iteration 27800 (3.48804 iter/s, 28.6694s/100 iters), loss = 0.272495
I0526 18:06:45.708513 30701 solver.cpp:237]     Train net output #0: loss = 0.272493 (* 1 = 0.272493 loss)
I0526 18:06:45.708525 30701 sgd_solver.cpp:105] Iteration 27800, lr = 0.00861
I0526 18:07:14.442483 30701 solver.cpp:218] Iteration 27900 (3.48028 iter/s, 28.7334s/100 iters), loss = 0.298527
I0526 18:07:14.442648 30701 solver.cpp:237]     Train net output #0: loss = 0.298526 (* 1 = 0.298526 loss)
I0526 18:07:14.442661 30701 sgd_solver.cpp:105] Iteration 27900, lr = 0.008605
I0526 18:07:42.872558 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_28000.caffemodel
I0526 18:07:43.192314 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_28000.solverstate
I0526 18:07:43.347434 30701 solver.cpp:330] Iteration 28000, Testing net (#0)
I0526 18:07:43.997928 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:07:46.380600 30701 solver.cpp:397]     Test net output #0: accuracy = 0.67
I0526 18:07:46.380801 30701 solver.cpp:397]     Test net output #1: loss = 1.34877 (* 1 = 1.34877 loss)
I0526 18:07:46.665411 30701 solver.cpp:218] Iteration 28000 (3.10346 iter/s, 32.2221s/100 iters), loss = 0.0226788
I0526 18:07:46.665469 30701 solver.cpp:237]     Train net output #0: loss = 0.022677 (* 1 = 0.022677 loss)
I0526 18:07:46.665478 30701 sgd_solver.cpp:105] Iteration 28000, lr = 0.0086
I0526 18:08:15.440409 30701 solver.cpp:218] Iteration 28100 (3.47533 iter/s, 28.7742s/100 iters), loss = 0.0458244
I0526 18:08:15.440472 30701 solver.cpp:237]     Train net output #0: loss = 0.0458227 (* 1 = 0.0458227 loss)
I0526 18:08:15.440482 30701 sgd_solver.cpp:105] Iteration 28100, lr = 0.008595
I0526 18:08:44.209228 30701 solver.cpp:218] Iteration 28200 (3.47607 iter/s, 28.7681s/100 iters), loss = 0.228858
I0526 18:08:44.209378 30701 solver.cpp:237]     Train net output #0: loss = 0.228856 (* 1 = 0.228856 loss)
I0526 18:08:44.209394 30701 sgd_solver.cpp:105] Iteration 28200, lr = 0.00859
I0526 18:09:13.063503 30701 solver.cpp:218] Iteration 28300 (3.46578 iter/s, 28.8535s/100 iters), loss = 0.165746
I0526 18:09:13.063546 30701 solver.cpp:237]     Train net output #0: loss = 0.165745 (* 1 = 0.165745 loss)
I0526 18:09:13.063555 30701 sgd_solver.cpp:105] Iteration 28300, lr = 0.008585
I0526 18:09:33.487262 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:09:41.826475 30701 solver.cpp:218] Iteration 28400 (3.47677 iter/s, 28.7623s/100 iters), loss = 0.148289
I0526 18:09:41.826539 30701 solver.cpp:237]     Train net output #0: loss = 0.148287 (* 1 = 0.148287 loss)
I0526 18:09:41.826551 30701 sgd_solver.cpp:105] Iteration 28400, lr = 0.00858
I0526 18:10:10.553575 30701 solver.cpp:218] Iteration 28500 (3.48112 iter/s, 28.7264s/100 iters), loss = 0.151839
I0526 18:10:10.553791 30701 solver.cpp:237]     Train net output #0: loss = 0.151837 (* 1 = 0.151837 loss)
I0526 18:10:10.553802 30701 sgd_solver.cpp:105] Iteration 28500, lr = 0.008575
I0526 18:10:39.240551 30701 solver.cpp:218] Iteration 28600 (3.486 iter/s, 28.6862s/100 iters), loss = 0.0339847
I0526 18:10:39.240607 30701 solver.cpp:237]     Train net output #0: loss = 0.0339831 (* 1 = 0.0339831 loss)
I0526 18:10:39.240617 30701 sgd_solver.cpp:105] Iteration 28600, lr = 0.00857
I0526 18:11:09.827559 30701 solver.cpp:218] Iteration 28700 (3.26944 iter/s, 30.5863s/100 iters), loss = 0.269838
I0526 18:11:09.827690 30701 solver.cpp:237]     Train net output #0: loss = 0.269837 (* 1 = 0.269837 loss)
I0526 18:11:09.827700 30701 sgd_solver.cpp:105] Iteration 28700, lr = 0.008565
I0526 18:11:53.911945 30701 solver.cpp:218] Iteration 28800 (2.26854 iter/s, 44.0813s/100 iters), loss = 0.229668
I0526 18:11:53.912168 30701 solver.cpp:237]     Train net output #0: loss = 0.229666 (* 1 = 0.229666 loss)
I0526 18:11:53.912181 30701 sgd_solver.cpp:105] Iteration 28800, lr = 0.00856
I0526 18:12:37.904501 30701 solver.cpp:218] Iteration 28900 (2.27317 iter/s, 43.9914s/100 iters), loss = 0.0329223
I0526 18:12:37.904729 30701 solver.cpp:237]     Train net output #0: loss = 0.0329207 (* 1 = 0.0329207 loss)
I0526 18:12:37.904752 30701 sgd_solver.cpp:105] Iteration 28900, lr = 0.008555
I0526 18:13:05.481456 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:13:17.534224 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_29000.caffemodel
I0526 18:13:17.848793 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_29000.solverstate
I0526 18:13:17.997495 30701 solver.cpp:330] Iteration 29000, Testing net (#0)
I0526 18:13:20.979672 30701 solver.cpp:397]     Test net output #0: accuracy = 0.65
I0526 18:13:20.979719 30701 solver.cpp:397]     Test net output #1: loss = 1.53876 (* 1 = 1.53876 loss)
I0526 18:13:21.258827 30701 solver.cpp:218] Iteration 29000 (2.30664 iter/s, 43.3532s/100 iters), loss = 0.169571
I0526 18:13:21.258874 30701 solver.cpp:237]     Train net output #0: loss = 0.16957 (* 1 = 0.16957 loss)
I0526 18:13:21.258883 30701 sgd_solver.cpp:105] Iteration 29000, lr = 0.00855
I0526 18:13:51.954191 30701 solver.cpp:218] Iteration 29100 (3.2579 iter/s, 30.6946s/100 iters), loss = 0.130927
I0526 18:13:51.954294 30701 solver.cpp:237]     Train net output #0: loss = 0.130925 (* 1 = 0.130925 loss)
I0526 18:13:51.954305 30701 sgd_solver.cpp:105] Iteration 29100, lr = 0.008545
I0526 18:14:37.614163 30701 solver.cpp:218] Iteration 29200 (2.19026 iter/s, 45.6568s/100 iters), loss = 0.203038
I0526 18:14:37.614287 30701 solver.cpp:237]     Train net output #0: loss = 0.203036 (* 1 = 0.203036 loss)
I0526 18:14:37.614303 30701 sgd_solver.cpp:105] Iteration 29200, lr = 0.00854
I0526 18:15:16.414994 30701 solver.cpp:218] Iteration 29300 (2.57739 iter/s, 38.799s/100 iters), loss = 0.0978252
I0526 18:15:16.415227 30701 solver.cpp:237]     Train net output #0: loss = 0.0978236 (* 1 = 0.0978236 loss)
I0526 18:15:16.415244 30701 sgd_solver.cpp:105] Iteration 29300, lr = 0.008535
I0526 18:15:44.550915 30701 solver.cpp:218] Iteration 29400 (3.55428 iter/s, 28.1351s/100 iters), loss = 0.118053
I0526 18:15:44.550962 30701 solver.cpp:237]     Train net output #0: loss = 0.118052 (* 1 = 0.118052 loss)
I0526 18:15:44.550976 30701 sgd_solver.cpp:105] Iteration 29400, lr = 0.00853
I0526 18:16:12.649533 30701 solver.cpp:218] Iteration 29500 (3.55898 iter/s, 28.0979s/100 iters), loss = 0.0349449
I0526 18:16:12.649740 30701 solver.cpp:237]     Train net output #0: loss = 0.0349434 (* 1 = 0.0349434 loss)
I0526 18:16:12.649770 30701 sgd_solver.cpp:105] Iteration 29500, lr = 0.008525
I0526 18:16:27.558275 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:16:40.742291 30701 solver.cpp:218] Iteration 29600 (3.55974 iter/s, 28.0919s/100 iters), loss = 0.143311
I0526 18:16:40.742341 30701 solver.cpp:237]     Train net output #0: loss = 0.14331 (* 1 = 0.14331 loss)
I0526 18:16:40.742349 30701 sgd_solver.cpp:105] Iteration 29600, lr = 0.00852
I0526 18:17:08.871356 30701 solver.cpp:218] Iteration 29700 (3.55513 iter/s, 28.1284s/100 iters), loss = 0.0925771
I0526 18:17:08.871531 30701 solver.cpp:237]     Train net output #0: loss = 0.0925756 (* 1 = 0.0925756 loss)
I0526 18:17:08.871546 30701 sgd_solver.cpp:105] Iteration 29700, lr = 0.008515
I0526 18:17:37.016350 30701 solver.cpp:218] Iteration 29800 (3.55313 iter/s, 28.1442s/100 iters), loss = 0.102906
I0526 18:17:37.016394 30701 solver.cpp:237]     Train net output #0: loss = 0.102904 (* 1 = 0.102904 loss)
I0526 18:17:37.016403 30701 sgd_solver.cpp:105] Iteration 29800, lr = 0.00851
I0526 18:18:05.158229 30701 solver.cpp:218] Iteration 29900 (3.55351 iter/s, 28.1412s/100 iters), loss = 0.0204884
I0526 18:18:05.158445 30701 solver.cpp:237]     Train net output #0: loss = 0.0204869 (* 1 = 0.0204869 loss)
I0526 18:18:05.158457 30701 sgd_solver.cpp:105] Iteration 29900, lr = 0.008505
I0526 18:18:33.034508 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_30000.caffemodel
I0526 18:18:33.342619 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_30000.solverstate
I0526 18:18:33.489226 30701 solver.cpp:330] Iteration 30000, Testing net (#0)
I0526 18:18:35.802567 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:18:36.453213 30701 solver.cpp:397]     Test net output #0: accuracy = 0.698
I0526 18:18:36.453266 30701 solver.cpp:397]     Test net output #1: loss = 1.22138 (* 1 = 1.22138 loss)
I0526 18:18:36.730682 30701 solver.cpp:218] Iteration 30000 (3.16741 iter/s, 31.5716s/100 iters), loss = 0.250185
I0526 18:18:36.730731 30701 solver.cpp:237]     Train net output #0: loss = 0.250183 (* 1 = 0.250183 loss)
I0526 18:18:36.730739 30701 sgd_solver.cpp:105] Iteration 30000, lr = 0.0085
I0526 18:19:04.846238 30701 solver.cpp:218] Iteration 30100 (3.55683 iter/s, 28.1149s/100 iters), loss = 0.112978
I0526 18:19:04.846300 30701 solver.cpp:237]     Train net output #0: loss = 0.112977 (* 1 = 0.112977 loss)
I0526 18:19:04.846309 30701 sgd_solver.cpp:105] Iteration 30100, lr = 0.008495
I0526 18:19:17.251427 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:19:32.986553 30701 solver.cpp:218] Iteration 30200 (3.5537 iter/s, 28.1396s/100 iters), loss = 0.0686886
I0526 18:19:32.986598 30701 solver.cpp:237]     Train net output #0: loss = 0.0686871 (* 1 = 0.0686871 loss)
I0526 18:19:32.986608 30701 sgd_solver.cpp:105] Iteration 30200, lr = 0.00849
I0526 18:20:01.099306 30701 solver.cpp:218] Iteration 30300 (3.55719 iter/s, 28.1121s/100 iters), loss = 0.180423
I0526 18:20:01.099469 30701 solver.cpp:237]     Train net output #0: loss = 0.180421 (* 1 = 0.180421 loss)
I0526 18:20:01.099481 30701 sgd_solver.cpp:105] Iteration 30300, lr = 0.008485
I0526 18:20:29.712929 30701 solver.cpp:218] Iteration 30400 (3.49493 iter/s, 28.6128s/100 iters), loss = 0.157105
I0526 18:20:29.712982 30701 solver.cpp:237]     Train net output #0: loss = 0.157103 (* 1 = 0.157103 loss)
I0526 18:20:29.712990 30701 sgd_solver.cpp:105] Iteration 30400, lr = 0.00848
I0526 18:20:58.086412 30701 solver.cpp:218] Iteration 30500 (3.5245 iter/s, 28.3728s/100 iters), loss = 0.146464
I0526 18:20:58.086671 30701 solver.cpp:237]     Train net output #0: loss = 0.146462 (* 1 = 0.146462 loss)
I0526 18:20:58.086683 30701 sgd_solver.cpp:105] Iteration 30500, lr = 0.008475
I0526 18:21:26.465382 30701 solver.cpp:218] Iteration 30600 (3.52384 iter/s, 28.3781s/100 iters), loss = 0.0216463
I0526 18:21:26.465431 30701 solver.cpp:237]     Train net output #0: loss = 0.0216447 (* 1 = 0.0216447 loss)
I0526 18:21:26.465440 30701 sgd_solver.cpp:105] Iteration 30600, lr = 0.00847
I0526 18:21:55.294580 30701 solver.cpp:218] Iteration 30700 (3.46879 iter/s, 28.8285s/100 iters), loss = 0.0148003
I0526 18:21:55.294767 30701 solver.cpp:237]     Train net output #0: loss = 0.0147987 (* 1 = 0.0147987 loss)
I0526 18:21:55.294778 30701 sgd_solver.cpp:105] Iteration 30700, lr = 0.008465
I0526 18:22:05.250586 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:22:23.674521 30701 solver.cpp:218] Iteration 30800 (3.52372 iter/s, 28.3791s/100 iters), loss = 0.012144
I0526 18:22:23.674592 30701 solver.cpp:237]     Train net output #0: loss = 0.0121424 (* 1 = 0.0121424 loss)
I0526 18:22:23.674602 30701 sgd_solver.cpp:105] Iteration 30800, lr = 0.00846
I0526 18:22:52.050333 30701 solver.cpp:218] Iteration 30900 (3.52421 iter/s, 28.3751s/100 iters), loss = 0.0813159
I0526 18:22:52.050511 30701 solver.cpp:237]     Train net output #0: loss = 0.0813143 (* 1 = 0.0813143 loss)
I0526 18:22:52.050535 30701 sgd_solver.cpp:105] Iteration 30900, lr = 0.008455
I0526 18:23:20.181782 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_31000.caffemodel
I0526 18:23:20.494510 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_31000.solverstate
I0526 18:23:20.642650 30701 solver.cpp:330] Iteration 31000, Testing net (#0)
I0526 18:23:23.626442 30701 solver.cpp:397]     Test net output #0: accuracy = 0.724
I0526 18:23:23.626545 30701 solver.cpp:397]     Test net output #1: loss = 1.1835 (* 1 = 1.1835 loss)
I0526 18:23:23.908432 30701 solver.cpp:218] Iteration 31000 (3.139 iter/s, 31.8572s/100 iters), loss = 0.0154943
I0526 18:23:23.908499 30701 solver.cpp:237]     Train net output #0: loss = 0.0154927 (* 1 = 0.0154927 loss)
I0526 18:23:23.908509 30701 sgd_solver.cpp:105] Iteration 31000, lr = 0.00845
I0526 18:23:52.303885 30701 solver.cpp:218] Iteration 31100 (3.52177 iter/s, 28.3948s/100 iters), loss = 0.0381351
I0526 18:23:52.303961 30701 solver.cpp:237]     Train net output #0: loss = 0.0381335 (* 1 = 0.0381335 loss)
I0526 18:23:52.303972 30701 sgd_solver.cpp:105] Iteration 31100, lr = 0.008445
I0526 18:24:20.717862 30701 solver.cpp:218] Iteration 31200 (3.5195 iter/s, 28.4131s/100 iters), loss = 0.0960129
I0526 18:24:20.718031 30701 solver.cpp:237]     Train net output #0: loss = 0.0960113 (* 1 = 0.0960113 loss)
I0526 18:24:20.718045 30701 sgd_solver.cpp:105] Iteration 31200, lr = 0.00844
I0526 18:24:49.434614 30701 solver.cpp:218] Iteration 31300 (3.48238 iter/s, 28.716s/100 iters), loss = 0.0202956
I0526 18:24:49.434671 30701 solver.cpp:237]     Train net output #0: loss = 0.020294 (* 1 = 0.020294 loss)
I0526 18:24:49.434680 30701 sgd_solver.cpp:105] Iteration 31300, lr = 0.008435
I0526 18:24:57.191052 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:25:18.767774 30701 solver.cpp:218] Iteration 31400 (3.40921 iter/s, 29.3323s/100 iters), loss = 0.236786
I0526 18:25:18.767834 30701 solver.cpp:237]     Train net output #0: loss = 0.236785 (* 1 = 0.236785 loss)
I0526 18:25:18.767844 30701 sgd_solver.cpp:105] Iteration 31400, lr = 0.00843
I0526 18:25:47.264402 30701 solver.cpp:218] Iteration 31500 (3.50927 iter/s, 28.496s/100 iters), loss = 0.120506
I0526 18:25:47.264525 30701 solver.cpp:237]     Train net output #0: loss = 0.120505 (* 1 = 0.120505 loss)
I0526 18:25:47.264551 30701 sgd_solver.cpp:105] Iteration 31500, lr = 0.008425
I0526 18:26:15.830521 30701 solver.cpp:218] Iteration 31600 (3.50074 iter/s, 28.5654s/100 iters), loss = 0.065028
I0526 18:26:15.830576 30701 solver.cpp:237]     Train net output #0: loss = 0.0650264 (* 1 = 0.0650264 loss)
I0526 18:26:15.830590 30701 sgd_solver.cpp:105] Iteration 31600, lr = 0.00842
I0526 18:26:44.178910 30701 solver.cpp:218] Iteration 31700 (3.52762 iter/s, 28.3477s/100 iters), loss = 0.0341105
I0526 18:26:44.179090 30701 solver.cpp:237]     Train net output #0: loss = 0.0341088 (* 1 = 0.0341088 loss)
I0526 18:26:44.179105 30701 sgd_solver.cpp:105] Iteration 31700, lr = 0.008415
I0526 18:27:12.584652 30701 solver.cpp:218] Iteration 31800 (3.52051 iter/s, 28.405s/100 iters), loss = 0.0613921
I0526 18:27:12.584712 30701 solver.cpp:237]     Train net output #0: loss = 0.0613904 (* 1 = 0.0613904 loss)
I0526 18:27:12.584722 30701 sgd_solver.cpp:105] Iteration 31800, lr = 0.00841
I0526 18:27:41.153024 30701 solver.cpp:218] Iteration 31900 (3.50046 iter/s, 28.5677s/100 iters), loss = 0.0395047
I0526 18:27:41.153220 30701 solver.cpp:237]     Train net output #0: loss = 0.0395029 (* 1 = 0.0395029 loss)
I0526 18:27:41.153237 30701 sgd_solver.cpp:105] Iteration 31900, lr = 0.008405
I0526 18:27:46.399174 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:28:10.150436 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_32000.caffemodel
I0526 18:28:10.466035 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_32000.solverstate
I0526 18:28:10.615610 30701 solver.cpp:330] Iteration 32000, Testing net (#0)
I0526 18:28:13.685887 30701 solver.cpp:397]     Test net output #0: accuracy = 0.602
I0526 18:28:13.685983 30701 solver.cpp:397]     Test net output #1: loss = 1.50044 (* 1 = 1.50044 loss)
I0526 18:28:13.986354 30701 solver.cpp:218] Iteration 32000 (3.04577 iter/s, 32.8324s/100 iters), loss = 0.006939
I0526 18:28:13.986414 30701 solver.cpp:237]     Train net output #0: loss = 0.00693727 (* 1 = 0.00693727 loss)
I0526 18:28:13.986424 30701 sgd_solver.cpp:105] Iteration 32000, lr = 0.0084
I0526 18:28:43.269287 30701 solver.cpp:218] Iteration 32100 (3.41504 iter/s, 29.2822s/100 iters), loss = 0.116471
I0526 18:28:43.269349 30701 solver.cpp:237]     Train net output #0: loss = 0.116469 (* 1 = 0.116469 loss)
I0526 18:28:43.269361 30701 sgd_solver.cpp:105] Iteration 32100, lr = 0.008395
I0526 18:29:12.145331 30701 solver.cpp:218] Iteration 32200 (3.46316 iter/s, 28.8754s/100 iters), loss = 0.122812
I0526 18:29:12.145457 30701 solver.cpp:237]     Train net output #0: loss = 0.122811 (* 1 = 0.122811 loss)
I0526 18:29:12.145470 30701 sgd_solver.cpp:105] Iteration 32200, lr = 0.00839
I0526 18:29:40.830201 30701 solver.cpp:218] Iteration 32300 (3.48625 iter/s, 28.6841s/100 iters), loss = 0.00714111
I0526 18:29:40.830252 30701 solver.cpp:237]     Train net output #0: loss = 0.00713956 (* 1 = 0.00713956 loss)
I0526 18:29:40.830260 30701 sgd_solver.cpp:105] Iteration 32300, lr = 0.008385
I0526 18:30:09.450819 30701 solver.cpp:218] Iteration 32400 (3.49407 iter/s, 28.6199s/100 iters), loss = 0.106881
I0526 18:30:09.450949 30701 solver.cpp:237]     Train net output #0: loss = 0.106879 (* 1 = 0.106879 loss)
I0526 18:30:09.450968 30701 sgd_solver.cpp:105] Iteration 32400, lr = 0.00838
I0526 18:30:37.801726 30701 solver.cpp:218] Iteration 32500 (3.5273 iter/s, 28.3503s/100 iters), loss = 0.00615288
I0526 18:30:37.801789 30701 solver.cpp:237]     Train net output #0: loss = 0.00615135 (* 1 = 0.00615135 loss)
I0526 18:30:37.801802 30701 sgd_solver.cpp:105] Iteration 32500, lr = 0.008375
I0526 18:30:40.377998 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:31:06.179221 30701 solver.cpp:218] Iteration 32600 (3.52398 iter/s, 28.377s/100 iters), loss = 0.100348
I0526 18:31:06.179277 30701 solver.cpp:237]     Train net output #0: loss = 0.100347 (* 1 = 0.100347 loss)
I0526 18:31:06.179287 30701 sgd_solver.cpp:105] Iteration 32600, lr = 0.00837
I0526 18:31:34.557562 30701 solver.cpp:218] Iteration 32700 (3.52387 iter/s, 28.3779s/100 iters), loss = 0.349359
I0526 18:31:34.557684 30701 solver.cpp:237]     Train net output #0: loss = 0.349358 (* 1 = 0.349358 loss)
I0526 18:31:34.557706 30701 sgd_solver.cpp:105] Iteration 32700, lr = 0.008365
I0526 18:32:03.368744 30701 solver.cpp:218] Iteration 32800 (3.47094 iter/s, 28.8106s/100 iters), loss = 0.0998274
I0526 18:32:03.368803 30701 solver.cpp:237]     Train net output #0: loss = 0.0998257 (* 1 = 0.0998257 loss)
I0526 18:32:03.368813 30701 sgd_solver.cpp:105] Iteration 32800, lr = 0.00836
I0526 18:32:32.809216 30701 solver.cpp:218] Iteration 32900 (3.39674 iter/s, 29.44s/100 iters), loss = 0.17055
I0526 18:32:32.809332 30701 solver.cpp:237]     Train net output #0: loss = 0.170548 (* 1 = 0.170548 loss)
I0526 18:32:32.809350 30701 sgd_solver.cpp:105] Iteration 32900, lr = 0.008355
I0526 18:33:01.266052 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_33000.caffemodel
I0526 18:33:01.576134 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_33000.solverstate
I0526 18:33:01.724020 30701 solver.cpp:330] Iteration 33000, Testing net (#0)
I0526 18:33:02.775032 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:33:04.705163 30701 solver.cpp:397]     Test net output #0: accuracy = 0.734
I0526 18:33:04.705276 30701 solver.cpp:397]     Test net output #1: loss = 1.1342 (* 1 = 1.1342 loss)
I0526 18:33:04.985802 30701 solver.cpp:218] Iteration 33000 (3.10791 iter/s, 32.176s/100 iters), loss = 0.100765
I0526 18:33:04.985859 30701 solver.cpp:237]     Train net output #0: loss = 0.100764 (* 1 = 0.100764 loss)
I0526 18:33:04.985867 30701 sgd_solver.cpp:105] Iteration 33000, lr = 0.00835
I0526 18:33:33.819576 30701 solver.cpp:218] Iteration 33100 (3.46822 iter/s, 28.8333s/100 iters), loss = 0.0487494
I0526 18:33:33.819636 30701 solver.cpp:237]     Train net output #0: loss = 0.0487478 (* 1 = 0.0487478 loss)
I0526 18:33:33.819645 30701 sgd_solver.cpp:105] Iteration 33100, lr = 0.008345
I0526 18:33:33.838752 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:34:02.581151 30701 solver.cpp:218] Iteration 33200 (3.47693 iter/s, 28.761s/100 iters), loss = 0.272065
I0526 18:34:02.581316 30701 solver.cpp:237]     Train net output #0: loss = 0.272063 (* 1 = 0.272063 loss)
I0526 18:34:02.581327 30701 sgd_solver.cpp:105] Iteration 33200, lr = 0.00834
I0526 18:34:31.414336 30701 solver.cpp:218] Iteration 33300 (3.4683 iter/s, 28.8326s/100 iters), loss = 0.0204148
I0526 18:34:31.414398 30701 solver.cpp:237]     Train net output #0: loss = 0.0204132 (* 1 = 0.0204132 loss)
I0526 18:34:31.414412 30701 sgd_solver.cpp:105] Iteration 33300, lr = 0.008335
I0526 18:35:00.764633 30701 solver.cpp:218] Iteration 33400 (3.40718 iter/s, 29.3498s/100 iters), loss = 0.0136828
I0526 18:35:00.764750 30701 solver.cpp:237]     Train net output #0: loss = 0.0136813 (* 1 = 0.0136813 loss)
I0526 18:35:00.764760 30701 sgd_solver.cpp:105] Iteration 33400, lr = 0.00833
I0526 18:35:29.118496 30701 solver.cpp:218] Iteration 33500 (3.52693 iter/s, 28.3533s/100 iters), loss = 0.123002
I0526 18:35:29.118554 30701 solver.cpp:237]     Train net output #0: loss = 0.123 (* 1 = 0.123 loss)
I0526 18:35:29.118564 30701 sgd_solver.cpp:105] Iteration 33500, lr = 0.008325
I0526 18:35:57.314694 30701 solver.cpp:218] Iteration 33600 (3.54664 iter/s, 28.1957s/100 iters), loss = 0.05944
I0526 18:35:57.314846 30701 solver.cpp:237]     Train net output #0: loss = 0.0594385 (* 1 = 0.0594385 loss)
I0526 18:35:57.314857 30701 sgd_solver.cpp:105] Iteration 33600, lr = 0.00832
I0526 18:36:22.991449 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:36:25.523339 30701 solver.cpp:218] Iteration 33700 (3.54509 iter/s, 28.208s/100 iters), loss = 0.00988385
I0526 18:36:25.523393 30701 solver.cpp:237]     Train net output #0: loss = 0.00988235 (* 1 = 0.00988235 loss)
I0526 18:36:25.523404 30701 sgd_solver.cpp:105] Iteration 33700, lr = 0.008315
I0526 18:36:53.824062 30701 solver.cpp:218] Iteration 33800 (3.53355 iter/s, 28.3002s/100 iters), loss = 0.0155769
I0526 18:36:53.824247 30701 solver.cpp:237]     Train net output #0: loss = 0.0155754 (* 1 = 0.0155754 loss)
I0526 18:36:53.824260 30701 sgd_solver.cpp:105] Iteration 33800, lr = 0.00831
I0526 18:37:21.989167 30701 solver.cpp:218] Iteration 33900 (3.55058 iter/s, 28.1644s/100 iters), loss = 0.428764
I0526 18:37:21.989225 30701 solver.cpp:237]     Train net output #0: loss = 0.428762 (* 1 = 0.428762 loss)
I0526 18:37:21.989238 30701 sgd_solver.cpp:105] Iteration 33900, lr = 0.008305
I0526 18:37:49.896854 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_34000.caffemodel
I0526 18:37:50.252912 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_34000.solverstate
I0526 18:37:50.400293 30701 solver.cpp:330] Iteration 34000, Testing net (#0)
I0526 18:37:53.373567 30701 solver.cpp:397]     Test net output #0: accuracy = 0.698
I0526 18:37:53.373602 30701 solver.cpp:397]     Test net output #1: loss = 1.36628 (* 1 = 1.36628 loss)
I0526 18:37:53.653511 30701 solver.cpp:218] Iteration 34000 (3.15819 iter/s, 31.6637s/100 iters), loss = 0.132242
I0526 18:37:53.653563 30701 solver.cpp:237]     Train net output #0: loss = 0.132241 (* 1 = 0.132241 loss)
I0526 18:37:53.653573 30701 sgd_solver.cpp:105] Iteration 34000, lr = 0.0083
I0526 18:38:21.857260 30701 solver.cpp:218] Iteration 34100 (3.5457 iter/s, 28.2032s/100 iters), loss = 0.0476745
I0526 18:38:21.857421 30701 solver.cpp:237]     Train net output #0: loss = 0.047673 (* 1 = 0.047673 loss)
I0526 18:38:21.857432 30701 sgd_solver.cpp:105] Iteration 34100, lr = 0.008295
I0526 18:38:50.604427 30701 solver.cpp:218] Iteration 34200 (3.47869 iter/s, 28.7465s/100 iters), loss = 0.0650409
I0526 18:38:50.604485 30701 solver.cpp:237]     Train net output #0: loss = 0.0650393 (* 1 = 0.0650393 loss)
I0526 18:38:50.604495 30701 sgd_solver.cpp:105] Iteration 34200, lr = 0.00829
I0526 18:39:13.747443 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:39:18.811038 30701 solver.cpp:218] Iteration 34300 (3.54534 iter/s, 28.206s/100 iters), loss = 0.146505
I0526 18:39:18.811086 30701 solver.cpp:237]     Train net output #0: loss = 0.146503 (* 1 = 0.146503 loss)
I0526 18:39:18.811095 30701 sgd_solver.cpp:105] Iteration 34300, lr = 0.008285
I0526 18:39:47.004380 30701 solver.cpp:218] Iteration 34400 (3.54701 iter/s, 28.1928s/100 iters), loss = 0.0515158
I0526 18:39:47.004501 30701 solver.cpp:237]     Train net output #0: loss = 0.0515142 (* 1 = 0.0515142 loss)
I0526 18:39:47.004511 30701 sgd_solver.cpp:105] Iteration 34400, lr = 0.00828
I0526 18:40:15.168895 30701 solver.cpp:218] Iteration 34500 (3.55065 iter/s, 28.1639s/100 iters), loss = 0.051628
I0526 18:40:15.168954 30701 solver.cpp:237]     Train net output #0: loss = 0.0516265 (* 1 = 0.0516265 loss)
I0526 18:40:15.168965 30701 sgd_solver.cpp:105] Iteration 34500, lr = 0.008275
I0526 18:40:43.357720 30701 solver.cpp:218] Iteration 34600 (3.54758 iter/s, 28.1882s/100 iters), loss = 0.0549582
I0526 18:40:43.357875 30701 solver.cpp:237]     Train net output #0: loss = 0.0549566 (* 1 = 0.0549566 loss)
I0526 18:40:43.357887 30701 sgd_solver.cpp:105] Iteration 34600, lr = 0.00827
I0526 18:41:11.529963 30701 solver.cpp:218] Iteration 34700 (3.54968 iter/s, 28.1716s/100 iters), loss = 0.0395508
I0526 18:41:11.530028 30701 solver.cpp:237]     Train net output #0: loss = 0.0395492 (* 1 = 0.0395492 loss)
I0526 18:41:11.530037 30701 sgd_solver.cpp:105] Iteration 34700, lr = 0.008265
I0526 18:41:39.713351 30701 solver.cpp:218] Iteration 34800 (3.54826 iter/s, 28.1828s/100 iters), loss = 0.0188943
I0526 18:41:39.713470 30701 solver.cpp:237]     Train net output #0: loss = 0.0188927 (* 1 = 0.0188927 loss)
I0526 18:41:39.713482 30701 sgd_solver.cpp:105] Iteration 34800, lr = 0.00826
I0526 18:42:00.311205 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:42:07.901510 30701 solver.cpp:218] Iteration 34900 (3.54767 iter/s, 28.1875s/100 iters), loss = 0.0540675
I0526 18:42:07.901566 30701 solver.cpp:237]     Train net output #0: loss = 0.0540661 (* 1 = 0.0540661 loss)
I0526 18:42:07.901582 30701 sgd_solver.cpp:105] Iteration 34900, lr = 0.008255
I0526 18:42:35.795155 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_35000.caffemodel
I0526 18:42:36.203177 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_35000.solverstate
I0526 18:42:36.354517 30701 solver.cpp:330] Iteration 35000, Testing net (#0)
I0526 18:42:39.087707 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:42:39.325793 30701 solver.cpp:397]     Test net output #0: accuracy = 0.762
I0526 18:42:39.325840 30701 solver.cpp:397]     Test net output #1: loss = 0.83923 (* 1 = 0.83923 loss)
I0526 18:42:39.603036 30701 solver.cpp:218] Iteration 35000 (3.15449 iter/s, 31.7009s/100 iters), loss = 0.00871798
I0526 18:42:39.603086 30701 solver.cpp:237]     Train net output #0: loss = 0.00871657 (* 1 = 0.00871657 loss)
I0526 18:42:39.603096 30701 sgd_solver.cpp:105] Iteration 35000, lr = 0.00825
I0526 18:43:07.788343 30701 solver.cpp:218] Iteration 35100 (3.54802 iter/s, 28.1847s/100 iters), loss = 0.0542195
I0526 18:43:07.788558 30701 solver.cpp:237]     Train net output #0: loss = 0.0542182 (* 1 = 0.0542182 loss)
I0526 18:43:07.788573 30701 sgd_solver.cpp:105] Iteration 35100, lr = 0.008245
I0526 18:43:35.992075 30701 solver.cpp:218] Iteration 35200 (3.54572 iter/s, 28.203s/100 iters), loss = 0.00801967
I0526 18:43:35.992136 30701 solver.cpp:237]     Train net output #0: loss = 0.00801838 (* 1 = 0.00801838 loss)
I0526 18:43:35.992143 30701 sgd_solver.cpp:105] Iteration 35200, lr = 0.00824
I0526 18:44:04.185621 30701 solver.cpp:218] Iteration 35300 (3.54699 iter/s, 28.1929s/100 iters), loss = 0.0127272
I0526 18:44:04.185781 30701 solver.cpp:237]     Train net output #0: loss = 0.0127259 (* 1 = 0.0127259 loss)
I0526 18:44:04.185792 30701 sgd_solver.cpp:105] Iteration 35300, lr = 0.008235
I0526 18:44:32.380065 30701 solver.cpp:218] Iteration 35400 (3.54689 iter/s, 28.1937s/100 iters), loss = 0.195741
I0526 18:44:32.380116 30701 solver.cpp:237]     Train net output #0: loss = 0.195739 (* 1 = 0.195739 loss)
I0526 18:44:32.380129 30701 sgd_solver.cpp:105] Iteration 35400, lr = 0.00823
I0526 18:44:50.459646 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:45:00.597712 30701 solver.cpp:218] Iteration 35500 (3.54396 iter/s, 28.217s/100 iters), loss = 0.0651272
I0526 18:45:00.597776 30701 solver.cpp:237]     Train net output #0: loss = 0.0651258 (* 1 = 0.0651258 loss)
I0526 18:45:00.597786 30701 sgd_solver.cpp:105] Iteration 35500, lr = 0.008225
I0526 18:45:28.797080 30701 solver.cpp:218] Iteration 35600 (3.54626 iter/s, 28.1988s/100 iters), loss = 0.00536905
I0526 18:45:28.797269 30701 solver.cpp:237]     Train net output #0: loss = 0.0053677 (* 1 = 0.0053677 loss)
I0526 18:45:28.797281 30701 sgd_solver.cpp:105] Iteration 35600, lr = 0.00822
I0526 18:45:56.998761 30701 solver.cpp:218] Iteration 35700 (3.54598 iter/s, 28.201s/100 iters), loss = 0.0135862
I0526 18:45:56.998823 30701 solver.cpp:237]     Train net output #0: loss = 0.0135848 (* 1 = 0.0135848 loss)
I0526 18:45:56.998832 30701 sgd_solver.cpp:105] Iteration 35700, lr = 0.008215
I0526 18:46:25.230311 30701 solver.cpp:218] Iteration 35800 (3.54222 iter/s, 28.2309s/100 iters), loss = 0.0554415
I0526 18:46:25.230412 30701 solver.cpp:237]     Train net output #0: loss = 0.0554401 (* 1 = 0.0554401 loss)
I0526 18:46:25.230425 30701 sgd_solver.cpp:105] Iteration 35800, lr = 0.00821
I0526 18:46:53.448853 30701 solver.cpp:218] Iteration 35900 (3.54385 iter/s, 28.2179s/100 iters), loss = 0.0213446
I0526 18:46:53.448914 30701 solver.cpp:237]     Train net output #0: loss = 0.0213432 (* 1 = 0.0213432 loss)
I0526 18:46:53.448923 30701 sgd_solver.cpp:105] Iteration 35900, lr = 0.008205
I0526 18:47:21.392956 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_36000.caffemodel
I0526 18:47:21.808130 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_36000.solverstate
I0526 18:47:21.957396 30701 solver.cpp:330] Iteration 36000, Testing net (#0)
I0526 18:47:24.927039 30701 solver.cpp:397]     Test net output #0: accuracy = 0.688
I0526 18:47:24.927074 30701 solver.cpp:397]     Test net output #1: loss = 1.45158 (* 1 = 1.45158 loss)
I0526 18:47:25.206020 30701 solver.cpp:218] Iteration 36000 (3.14896 iter/s, 31.7565s/100 iters), loss = 0.0694154
I0526 18:47:25.206068 30701 solver.cpp:237]     Train net output #0: loss = 0.0694139 (* 1 = 0.0694139 loss)
I0526 18:47:25.206087 30701 sgd_solver.cpp:105] Iteration 36000, lr = 0.0082
I0526 18:47:41.004549 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:47:53.396914 30701 solver.cpp:218] Iteration 36100 (3.54732 iter/s, 28.1903s/100 iters), loss = 0.199782
I0526 18:47:53.397066 30701 solver.cpp:237]     Train net output #0: loss = 0.199781 (* 1 = 0.199781 loss)
I0526 18:47:53.397081 30701 sgd_solver.cpp:105] Iteration 36100, lr = 0.008195
I0526 18:48:21.569890 30701 solver.cpp:218] Iteration 36200 (3.54959 iter/s, 28.1723s/100 iters), loss = 0.0511562
I0526 18:48:21.569948 30701 solver.cpp:237]     Train net output #0: loss = 0.0511548 (* 1 = 0.0511548 loss)
I0526 18:48:21.569957 30701 sgd_solver.cpp:105] Iteration 36200, lr = 0.00819
I0526 18:48:49.765847 30701 solver.cpp:218] Iteration 36300 (3.54669 iter/s, 28.1953s/100 iters), loss = 0.0279151
I0526 18:48:49.766007 30701 solver.cpp:237]     Train net output #0: loss = 0.0279137 (* 1 = 0.0279137 loss)
I0526 18:48:49.766019 30701 sgd_solver.cpp:105] Iteration 36300, lr = 0.008185
I0526 18:49:17.982781 30701 solver.cpp:218] Iteration 36400 (3.54406 iter/s, 28.2162s/100 iters), loss = 0.0827481
I0526 18:49:17.982831 30701 solver.cpp:237]     Train net output #0: loss = 0.0827466 (* 1 = 0.0827466 loss)
I0526 18:49:17.982841 30701 sgd_solver.cpp:105] Iteration 36400, lr = 0.00818
I0526 18:49:46.175946 30701 solver.cpp:218] Iteration 36500 (3.54704 iter/s, 28.1925s/100 iters), loss = 0.030421
I0526 18:49:46.176126 30701 solver.cpp:237]     Train net output #0: loss = 0.0304195 (* 1 = 0.0304195 loss)
I0526 18:49:46.176146 30701 sgd_solver.cpp:105] Iteration 36500, lr = 0.008175
I0526 18:50:14.400441 30701 solver.cpp:218] Iteration 36600 (3.54312 iter/s, 28.2238s/100 iters), loss = 0.0294604
I0526 18:50:14.400491 30701 solver.cpp:237]     Train net output #0: loss = 0.0294589 (* 1 = 0.0294589 loss)
I0526 18:50:14.400501 30701 sgd_solver.cpp:105] Iteration 36600, lr = 0.00817
I0526 18:50:27.677395 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:50:42.612066 30701 solver.cpp:218] Iteration 36700 (3.54472 iter/s, 28.211s/100 iters), loss = 0.0407923
I0526 18:50:42.612115 30701 solver.cpp:237]     Train net output #0: loss = 0.0407908 (* 1 = 0.0407908 loss)
I0526 18:50:42.612124 30701 sgd_solver.cpp:105] Iteration 36700, lr = 0.008165
I0526 18:51:10.829407 30701 solver.cpp:218] Iteration 36800 (3.544 iter/s, 28.2167s/100 iters), loss = 0.557771
I0526 18:51:10.829561 30701 solver.cpp:237]     Train net output #0: loss = 0.557769 (* 1 = 0.557769 loss)
I0526 18:51:10.829572 30701 sgd_solver.cpp:105] Iteration 36800, lr = 0.00816
I0526 18:51:39.019891 30701 solver.cpp:218] Iteration 36900 (3.54739 iter/s, 28.1898s/100 iters), loss = 0.270361
I0526 18:51:39.019961 30701 solver.cpp:237]     Train net output #0: loss = 0.270359 (* 1 = 0.270359 loss)
I0526 18:51:39.019971 30701 sgd_solver.cpp:105] Iteration 36900, lr = 0.008155
I0526 18:52:06.961174 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_37000.caffemodel
I0526 18:52:07.373873 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_37000.solverstate
I0526 18:52:07.532701 30701 solver.cpp:330] Iteration 37000, Testing net (#0)
I0526 18:52:10.500515 30701 solver.cpp:397]     Test net output #0: accuracy = 0.728
I0526 18:52:10.500551 30701 solver.cpp:397]     Test net output #1: loss = 1.20385 (* 1 = 1.20385 loss)
I0526 18:52:10.778278 30701 solver.cpp:218] Iteration 37000 (3.14885 iter/s, 31.7577s/100 iters), loss = 0.0389178
I0526 18:52:10.778331 30701 solver.cpp:237]     Train net output #0: loss = 0.0389164 (* 1 = 0.0389164 loss)
I0526 18:52:10.778342 30701 sgd_solver.cpp:105] Iteration 37000, lr = 0.00815
I0526 18:52:38.949604 30701 solver.cpp:218] Iteration 37100 (3.54979 iter/s, 28.1707s/100 iters), loss = 0.0167815
I0526 18:52:38.949762 30701 solver.cpp:237]     Train net output #0: loss = 0.0167801 (* 1 = 0.0167801 loss)
I0526 18:52:38.949774 30701 sgd_solver.cpp:105] Iteration 37100, lr = 0.008145
I0526 18:53:07.126358 30701 solver.cpp:218] Iteration 37200 (3.54912 iter/s, 28.176s/100 iters), loss = 0.113508
I0526 18:53:07.126417 30701 solver.cpp:237]     Train net output #0: loss = 0.113506 (* 1 = 0.113506 loss)
I0526 18:53:07.126426 30701 sgd_solver.cpp:105] Iteration 37200, lr = 0.00814
I0526 18:53:17.844955 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:53:35.298058 30701 solver.cpp:218] Iteration 37300 (3.54974 iter/s, 28.1711s/100 iters), loss = 0.0580214
I0526 18:53:35.298106 30701 solver.cpp:237]     Train net output #0: loss = 0.05802 (* 1 = 0.05802 loss)
I0526 18:53:35.298115 30701 sgd_solver.cpp:105] Iteration 37300, lr = 0.008135
I0526 18:54:03.476575 30701 solver.cpp:218] Iteration 37400 (3.54888 iter/s, 28.1779s/100 iters), loss = 0.0255591
I0526 18:54:03.476694 30701 solver.cpp:237]     Train net output #0: loss = 0.0255577 (* 1 = 0.0255577 loss)
I0526 18:54:03.476706 30701 sgd_solver.cpp:105] Iteration 37400, lr = 0.00813
I0526 18:54:31.666709 30701 solver.cpp:218] Iteration 37500 (3.54743 iter/s, 28.1894s/100 iters), loss = 0.0101965
I0526 18:54:31.666772 30701 solver.cpp:237]     Train net output #0: loss = 0.0101952 (* 1 = 0.0101952 loss)
I0526 18:54:31.666782 30701 sgd_solver.cpp:105] Iteration 37500, lr = 0.008125
I0526 18:54:59.830149 30701 solver.cpp:218] Iteration 37600 (3.55078 iter/s, 28.1628s/100 iters), loss = 0.125432
I0526 18:54:59.830317 30701 solver.cpp:237]     Train net output #0: loss = 0.12543 (* 1 = 0.12543 loss)
I0526 18:54:59.830345 30701 sgd_solver.cpp:105] Iteration 37600, lr = 0.00812
I0526 18:55:27.986577 30701 solver.cpp:218] Iteration 37700 (3.55168 iter/s, 28.1557s/100 iters), loss = 0.0309897
I0526 18:55:27.986626 30701 solver.cpp:237]     Train net output #0: loss = 0.0309883 (* 1 = 0.0309883 loss)
I0526 18:55:27.986636 30701 sgd_solver.cpp:105] Iteration 37700, lr = 0.008115
I0526 18:55:56.164043 30701 solver.cpp:218] Iteration 37800 (3.54901 iter/s, 28.1768s/100 iters), loss = 0.00611649
I0526 18:55:56.164175 30701 solver.cpp:237]     Train net output #0: loss = 0.00611502 (* 1 = 0.00611502 loss)
I0526 18:55:56.164191 30701 sgd_solver.cpp:105] Iteration 37800, lr = 0.00811
I0526 18:56:04.362135 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:56:24.387464 30701 solver.cpp:218] Iteration 37900 (3.54325 iter/s, 28.2227s/100 iters), loss = 0.0150938
I0526 18:56:24.387511 30701 solver.cpp:237]     Train net output #0: loss = 0.0150924 (* 1 = 0.0150924 loss)
I0526 18:56:24.387521 30701 sgd_solver.cpp:105] Iteration 37900, lr = 0.008105
I0526 18:56:52.324151 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_38000.caffemodel
I0526 18:56:52.851377 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_38000.solverstate
I0526 18:56:53.003545 30701 solver.cpp:330] Iteration 38000, Testing net (#0)
I0526 18:56:54.427290 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:56:55.961386 30701 solver.cpp:397]     Test net output #0: accuracy = 0.756
I0526 18:56:55.961422 30701 solver.cpp:397]     Test net output #1: loss = 1.02217 (* 1 = 1.02217 loss)
I0526 18:56:56.240597 30701 solver.cpp:218] Iteration 38000 (3.13948 iter/s, 31.8524s/100 iters), loss = 0.0269552
I0526 18:56:56.240653 30701 solver.cpp:237]     Train net output #0: loss = 0.0269538 (* 1 = 0.0269538 loss)
I0526 18:56:56.240664 30701 sgd_solver.cpp:105] Iteration 38000, lr = 0.0081
I0526 18:57:24.407436 30701 solver.cpp:218] Iteration 38100 (3.55035 iter/s, 28.1662s/100 iters), loss = 0.0102994
I0526 18:57:24.407593 30701 solver.cpp:237]     Train net output #0: loss = 0.010298 (* 1 = 0.010298 loss)
I0526 18:57:24.407605 30701 sgd_solver.cpp:105] Iteration 38100, lr = 0.008095
I0526 18:57:52.569808 30701 solver.cpp:218] Iteration 38200 (3.55093 iter/s, 28.1616s/100 iters), loss = 0.0120277
I0526 18:57:52.569865 30701 solver.cpp:237]     Train net output #0: loss = 0.0120262 (* 1 = 0.0120262 loss)
I0526 18:57:52.569875 30701 sgd_solver.cpp:105] Iteration 38200, lr = 0.00809
I0526 18:58:20.747395 30701 solver.cpp:218] Iteration 38300 (3.549 iter/s, 28.1769s/100 iters), loss = 0.0772017
I0526 18:58:20.747593 30701 solver.cpp:237]     Train net output #0: loss = 0.0772002 (* 1 = 0.0772002 loss)
I0526 18:58:20.747604 30701 sgd_solver.cpp:105] Iteration 38300, lr = 0.008085
I0526 18:58:48.893090 30701 solver.cpp:218] Iteration 38400 (3.55304 iter/s, 28.1449s/100 iters), loss = 0.0781914
I0526 18:58:48.893137 30701 solver.cpp:237]     Train net output #0: loss = 0.0781899 (* 1 = 0.0781899 loss)
I0526 18:58:48.893146 30701 sgd_solver.cpp:105] Iteration 38400, lr = 0.00808
I0526 18:58:54.548017 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 18:59:17.071140 30701 solver.cpp:218] Iteration 38500 (3.54894 iter/s, 28.1774s/100 iters), loss = 0.00343068
I0526 18:59:17.071187 30701 solver.cpp:237]     Train net output #0: loss = 0.00342917 (* 1 = 0.00342917 loss)
I0526 18:59:17.071209 30701 sgd_solver.cpp:105] Iteration 38500, lr = 0.008075
I0526 18:59:45.230559 30701 solver.cpp:218] Iteration 38600 (3.55129 iter/s, 28.1588s/100 iters), loss = 0.0116092
I0526 18:59:45.230669 30701 solver.cpp:237]     Train net output #0: loss = 0.0116077 (* 1 = 0.0116077 loss)
I0526 18:59:45.230680 30701 sgd_solver.cpp:105] Iteration 38600, lr = 0.00807
I0526 19:00:13.452635 30701 solver.cpp:218] Iteration 38700 (3.54341 iter/s, 28.2214s/100 iters), loss = 0.0140649
I0526 19:00:13.452690 30701 solver.cpp:237]     Train net output #0: loss = 0.0140634 (* 1 = 0.0140634 loss)
I0526 19:00:13.452705 30701 sgd_solver.cpp:105] Iteration 38700, lr = 0.008065
I0526 19:00:41.666414 30701 solver.cpp:218] Iteration 38800 (3.54445 iter/s, 28.2131s/100 iters), loss = 0.0405046
I0526 19:00:41.666558 30701 solver.cpp:237]     Train net output #0: loss = 0.0405031 (* 1 = 0.0405031 loss)
I0526 19:00:41.666573 30701 sgd_solver.cpp:105] Iteration 38800, lr = 0.00806
I0526 19:01:09.851069 30701 solver.cpp:218] Iteration 38900 (3.54812 iter/s, 28.1839s/100 iters), loss = 0.0287624
I0526 19:01:09.851119 30701 solver.cpp:237]     Train net output #0: loss = 0.028761 (* 1 = 0.028761 loss)
I0526 19:01:09.851140 30701 sgd_solver.cpp:105] Iteration 38900, lr = 0.008055
I0526 19:01:37.758811 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_39000.caffemodel
I0526 19:01:38.220805 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_39000.solverstate
I0526 19:01:38.371175 30701 solver.cpp:330] Iteration 39000, Testing net (#0)
I0526 19:01:41.336308 30701 solver.cpp:397]     Test net output #0: accuracy = 0.682
I0526 19:01:41.336343 30701 solver.cpp:397]     Test net output #1: loss = 1.59636 (* 1 = 1.59636 loss)
I0526 19:01:41.613411 30701 solver.cpp:218] Iteration 39000 (3.14845 iter/s, 31.7616s/100 iters), loss = 0.356155
I0526 19:01:41.613464 30701 solver.cpp:237]     Train net output #0: loss = 0.356154 (* 1 = 0.356154 loss)
I0526 19:01:41.613473 30701 sgd_solver.cpp:105] Iteration 39000, lr = 0.00805
I0526 19:01:44.739104 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:02:09.822787 30701 solver.cpp:218] Iteration 39100 (3.545 iter/s, 28.2087s/100 iters), loss = 0.18833
I0526 19:02:09.822938 30701 solver.cpp:237]     Train net output #0: loss = 0.188329 (* 1 = 0.188329 loss)
I0526 19:02:09.822952 30701 sgd_solver.cpp:105] Iteration 39100, lr = 0.008045
I0526 19:02:37.990531 30701 solver.cpp:218] Iteration 39200 (3.55025 iter/s, 28.167s/100 iters), loss = 0.0244305
I0526 19:02:37.990597 30701 solver.cpp:237]     Train net output #0: loss = 0.0244291 (* 1 = 0.0244291 loss)
I0526 19:02:37.990607 30701 sgd_solver.cpp:105] Iteration 39200, lr = 0.00804
I0526 19:03:06.159430 30701 solver.cpp:218] Iteration 39300 (3.55009 iter/s, 28.1683s/100 iters), loss = 0.0380142
I0526 19:03:06.159574 30701 solver.cpp:237]     Train net output #0: loss = 0.0380127 (* 1 = 0.0380127 loss)
I0526 19:03:06.159586 30701 sgd_solver.cpp:105] Iteration 39300, lr = 0.008035
I0526 19:03:34.307793 30701 solver.cpp:218] Iteration 39400 (3.5527 iter/s, 28.1476s/100 iters), loss = 0.0124063
I0526 19:03:34.307857 30701 solver.cpp:237]     Train net output #0: loss = 0.012405 (* 1 = 0.012405 loss)
I0526 19:03:34.307868 30701 sgd_solver.cpp:105] Iteration 39400, lr = 0.00803
I0526 19:04:02.486341 30701 solver.cpp:218] Iteration 39500 (3.54888 iter/s, 28.1779s/100 iters), loss = 0.0925151
I0526 19:04:02.486519 30701 solver.cpp:237]     Train net output #0: loss = 0.0925136 (* 1 = 0.0925136 loss)
I0526 19:04:02.486532 30701 sgd_solver.cpp:105] Iteration 39500, lr = 0.008025
I0526 19:04:30.677269 30701 solver.cpp:218] Iteration 39600 (3.54734 iter/s, 28.1902s/100 iters), loss = 0.010996
I0526 19:04:30.677331 30701 solver.cpp:237]     Train net output #0: loss = 0.0109945 (* 1 = 0.0109945 loss)
I0526 19:04:30.677341 30701 sgd_solver.cpp:105] Iteration 39600, lr = 0.00802
I0526 19:04:31.541100 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:04:58.858078 30701 solver.cpp:218] Iteration 39700 (3.54857 iter/s, 28.1804s/100 iters), loss = 0.00394943
I0526 19:04:58.858278 30701 solver.cpp:237]     Train net output #0: loss = 0.00394787 (* 1 = 0.00394787 loss)
I0526 19:04:58.858291 30701 sgd_solver.cpp:105] Iteration 39700, lr = 0.008015
I0526 19:05:27.029917 30701 solver.cpp:218] Iteration 39800 (3.54971 iter/s, 28.1713s/100 iters), loss = 0.0720891
I0526 19:05:27.029968 30701 solver.cpp:237]     Train net output #0: loss = 0.0720875 (* 1 = 0.0720875 loss)
I0526 19:05:27.029978 30701 sgd_solver.cpp:105] Iteration 39800, lr = 0.00801
I0526 19:05:55.210016 30701 solver.cpp:218] Iteration 39900 (3.54865 iter/s, 28.1797s/100 iters), loss = 0.00221364
I0526 19:05:55.210165 30701 solver.cpp:237]     Train net output #0: loss = 0.0022121 (* 1 = 0.0022121 loss)
I0526 19:05:55.210176 30701 sgd_solver.cpp:105] Iteration 39900, lr = 0.008005
I0526 19:06:23.111228 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_40000.caffemodel
I0526 19:06:23.523320 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_40000.solverstate
I0526 19:06:23.674263 30701 solver.cpp:330] Iteration 40000, Testing net (#0)
I0526 19:06:26.636581 30701 solver.cpp:397]     Test net output #0: accuracy = 0.718
I0526 19:06:26.636682 30701 solver.cpp:397]     Test net output #1: loss = 1.32074 (* 1 = 1.32074 loss)
I0526 19:06:26.916683 30701 solver.cpp:218] Iteration 40000 (3.15397 iter/s, 31.7061s/100 iters), loss = 0.167397
I0526 19:06:26.916738 30701 solver.cpp:237]     Train net output #0: loss = 0.167395 (* 1 = 0.167395 loss)
I0526 19:06:26.916751 30701 sgd_solver.cpp:105] Iteration 40000, lr = 0.008
I0526 19:06:55.113235 30701 solver.cpp:218] Iteration 40100 (3.54659 iter/s, 28.1961s/100 iters), loss = 0.0159952
I0526 19:06:55.113282 30701 solver.cpp:237]     Train net output #0: loss = 0.0159935 (* 1 = 0.0159935 loss)
I0526 19:06:55.113291 30701 sgd_solver.cpp:105] Iteration 40100, lr = 0.007995
I0526 19:07:21.625953 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:07:23.303666 30701 solver.cpp:218] Iteration 40200 (3.54736 iter/s, 28.19s/100 iters), loss = 0.0103658
I0526 19:07:23.303726 30701 solver.cpp:237]     Train net output #0: loss = 0.0103641 (* 1 = 0.0103641 loss)
I0526 19:07:23.303736 30701 sgd_solver.cpp:105] Iteration 40200, lr = 0.00799
I0526 19:07:51.482617 30701 solver.cpp:218] Iteration 40300 (3.54881 iter/s, 28.1785s/100 iters), loss = 0.0296297
I0526 19:07:51.482674 30701 solver.cpp:237]     Train net output #0: loss = 0.029628 (* 1 = 0.029628 loss)
I0526 19:07:51.482682 30701 sgd_solver.cpp:105] Iteration 40300, lr = 0.007985
I0526 19:08:19.694867 30701 solver.cpp:218] Iteration 40400 (3.54462 iter/s, 28.2118s/100 iters), loss = 0.103765
I0526 19:08:19.694988 30701 solver.cpp:237]     Train net output #0: loss = 0.103763 (* 1 = 0.103763 loss)
I0526 19:08:19.695008 30701 sgd_solver.cpp:105] Iteration 40400, lr = 0.00798
I0526 19:08:47.843860 30701 solver.cpp:218] Iteration 40500 (3.55259 iter/s, 28.1485s/100 iters), loss = 0.0553874
I0526 19:08:47.843916 30701 solver.cpp:237]     Train net output #0: loss = 0.0553858 (* 1 = 0.0553858 loss)
I0526 19:08:47.843930 30701 sgd_solver.cpp:105] Iteration 40500, lr = 0.007975
I0526 19:09:16.067523 30701 solver.cpp:218] Iteration 40600 (3.54318 iter/s, 28.2232s/100 iters), loss = 0.156095
I0526 19:09:16.067700 30701 solver.cpp:237]     Train net output #0: loss = 0.156094 (* 1 = 0.156094 loss)
I0526 19:09:16.067713 30701 sgd_solver.cpp:105] Iteration 40600, lr = 0.00797
I0526 19:09:44.276340 30701 solver.cpp:218] Iteration 40700 (3.54507 iter/s, 28.2082s/100 iters), loss = 0.00498585
I0526 19:09:44.276386 30701 solver.cpp:237]     Train net output #0: loss = 0.00498425 (* 1 = 0.00498425 loss)
I0526 19:09:44.276394 30701 sgd_solver.cpp:105] Iteration 40700, lr = 0.007965
I0526 19:10:08.280583 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:10:12.500659 30701 solver.cpp:218] Iteration 40800 (3.5431 iter/s, 28.2238s/100 iters), loss = 0.122606
I0526 19:10:12.500720 30701 solver.cpp:237]     Train net output #0: loss = 0.122604 (* 1 = 0.122604 loss)
I0526 19:10:12.500728 30701 sgd_solver.cpp:105] Iteration 40800, lr = 0.00796
I0526 19:10:40.700785 30701 solver.cpp:218] Iteration 40900 (3.54615 iter/s, 28.1996s/100 iters), loss = 0.0411469
I0526 19:10:40.700960 30701 solver.cpp:237]     Train net output #0: loss = 0.0411453 (* 1 = 0.0411453 loss)
I0526 19:10:40.700985 30701 sgd_solver.cpp:105] Iteration 40900, lr = 0.007955
I0526 19:11:08.633744 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_41000.caffemodel
I0526 19:11:09.034152 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_41000.solverstate
I0526 19:11:09.184013 30701 solver.cpp:330] Iteration 41000, Testing net (#0)
I0526 19:11:09.336683 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:11:12.153210 30701 solver.cpp:397]     Test net output #0: accuracy = 0.74
I0526 19:11:12.153362 30701 solver.cpp:397]     Test net output #1: loss = 1.20923 (* 1 = 1.20923 loss)
I0526 19:11:12.432586 30701 solver.cpp:218] Iteration 41000 (3.15148 iter/s, 31.7311s/100 iters), loss = 0.00529483
I0526 19:11:12.432648 30701 solver.cpp:237]     Train net output #0: loss = 0.00529326 (* 1 = 0.00529326 loss)
I0526 19:11:12.432659 30701 sgd_solver.cpp:105] Iteration 41000, lr = 0.00795
I0526 19:11:40.600376 30701 solver.cpp:218] Iteration 41100 (3.55022 iter/s, 28.1673s/100 iters), loss = 0.00996489
I0526 19:11:40.600424 30701 solver.cpp:237]     Train net output #0: loss = 0.00996334 (* 1 = 0.00996334 loss)
I0526 19:11:40.600445 30701 sgd_solver.cpp:105] Iteration 41100, lr = 0.007945
I0526 19:12:08.791939 30701 solver.cpp:218] Iteration 41200 (3.54722 iter/s, 28.1911s/100 iters), loss = 0.0324224
I0526 19:12:08.792083 30701 solver.cpp:237]     Train net output #0: loss = 0.0324209 (* 1 = 0.0324209 loss)
I0526 19:12:08.792093 30701 sgd_solver.cpp:105] Iteration 41200, lr = 0.00794
I0526 19:12:37.017145 30701 solver.cpp:218] Iteration 41300 (3.54301 iter/s, 28.2246s/100 iters), loss = 0.120812
I0526 19:12:37.017192 30701 solver.cpp:237]     Train net output #0: loss = 0.12081 (* 1 = 0.12081 loss)
I0526 19:12:37.017201 30701 sgd_solver.cpp:105] Iteration 41300, lr = 0.007935
I0526 19:12:58.502427 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:13:05.255650 30701 solver.cpp:218] Iteration 41400 (3.54133 iter/s, 28.238s/100 iters), loss = 0.0551959
I0526 19:13:05.255715 30701 solver.cpp:237]     Train net output #0: loss = 0.0551944 (* 1 = 0.0551944 loss)
I0526 19:13:05.255728 30701 sgd_solver.cpp:105] Iteration 41400, lr = 0.00793
I0526 19:13:33.447188 30701 solver.cpp:218] Iteration 41500 (3.54723 iter/s, 28.191s/100 iters), loss = 0.00175003
I0526 19:13:33.447343 30701 solver.cpp:237]     Train net output #0: loss = 0.00174862 (* 1 = 0.00174862 loss)
I0526 19:13:33.447358 30701 sgd_solver.cpp:105] Iteration 41500, lr = 0.007925
I0526 19:14:01.654585 30701 solver.cpp:218] Iteration 41600 (3.54525 iter/s, 28.2068s/100 iters), loss = 0.0372311
I0526 19:14:01.654639 30701 solver.cpp:237]     Train net output #0: loss = 0.0372297 (* 1 = 0.0372297 loss)
I0526 19:14:01.654647 30701 sgd_solver.cpp:105] Iteration 41600, lr = 0.00792
I0526 19:14:29.851536 30701 solver.cpp:218] Iteration 41700 (3.54655 iter/s, 28.1964s/100 iters), loss = 0.062711
I0526 19:14:29.851740 30701 solver.cpp:237]     Train net output #0: loss = 0.0627096 (* 1 = 0.0627096 loss)
I0526 19:14:29.851763 30701 sgd_solver.cpp:105] Iteration 41700, lr = 0.007915
I0526 19:14:58.046635 30701 solver.cpp:218] Iteration 41800 (3.5468 iter/s, 28.1944s/100 iters), loss = 0.0245216
I0526 19:14:58.046700 30701 solver.cpp:237]     Train net output #0: loss = 0.0245201 (* 1 = 0.0245201 loss)
I0526 19:14:58.046708 30701 sgd_solver.cpp:105] Iteration 41800, lr = 0.00791
I0526 19:15:26.235772 30701 solver.cpp:218] Iteration 41900 (3.54754 iter/s, 28.1886s/100 iters), loss = 0.0106947
I0526 19:15:26.235970 30701 solver.cpp:237]     Train net output #0: loss = 0.0106933 (* 1 = 0.0106933 loss)
I0526 19:15:26.235982 30701 sgd_solver.cpp:105] Iteration 41900, lr = 0.007905
I0526 19:15:45.133020 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:15:54.136581 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_42000.caffemodel
I0526 19:15:54.484078 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_42000.solverstate
I0526 19:15:54.633441 30701 solver.cpp:330] Iteration 42000, Testing net (#0)
I0526 19:15:57.598580 30701 solver.cpp:397]     Test net output #0: accuracy = 0.702
I0526 19:15:57.598711 30701 solver.cpp:397]     Test net output #1: loss = 1.20882 (* 1 = 1.20882 loss)
I0526 19:15:57.875172 30701 solver.cpp:218] Iteration 42000 (3.16069 iter/s, 31.6387s/100 iters), loss = 0.0729356
I0526 19:15:57.875231 30701 solver.cpp:237]     Train net output #0: loss = 0.0729342 (* 1 = 0.0729342 loss)
I0526 19:15:57.875241 30701 sgd_solver.cpp:105] Iteration 42000, lr = 0.0079
I0526 19:16:26.047940 30701 solver.cpp:218] Iteration 42100 (3.5496 iter/s, 28.1722s/100 iters), loss = 0.0536437
I0526 19:16:26.048002 30701 solver.cpp:237]     Train net output #0: loss = 0.0536423 (* 1 = 0.0536423 loss)
I0526 19:16:26.048012 30701 sgd_solver.cpp:105] Iteration 42100, lr = 0.007895
I0526 19:16:54.206955 30701 solver.cpp:218] Iteration 42200 (3.55133 iter/s, 28.1584s/100 iters), loss = 0.300117
I0526 19:16:54.207100 30701 solver.cpp:237]     Train net output #0: loss = 0.300116 (* 1 = 0.300116 loss)
I0526 19:16:54.207113 30701 sgd_solver.cpp:105] Iteration 42200, lr = 0.00789
I0526 19:17:22.412021 30701 solver.cpp:218] Iteration 42300 (3.54554 iter/s, 28.2044s/100 iters), loss = 0.0985688
I0526 19:17:22.412067 30701 solver.cpp:237]     Train net output #0: loss = 0.0985671 (* 1 = 0.0985671 loss)
I0526 19:17:22.412075 30701 sgd_solver.cpp:105] Iteration 42300, lr = 0.007885
I0526 19:17:50.606854 30701 solver.cpp:218] Iteration 42400 (3.54682 iter/s, 28.1943s/100 iters), loss = 0.15533
I0526 19:17:50.607086 30701 solver.cpp:237]     Train net output #0: loss = 0.155328 (* 1 = 0.155328 loss)
I0526 19:17:50.607102 30701 sgd_solver.cpp:105] Iteration 42400, lr = 0.00788
I0526 19:18:18.806988 30701 solver.cpp:218] Iteration 42500 (3.54617 iter/s, 28.1994s/100 iters), loss = 0.0127144
I0526 19:18:18.807035 30701 solver.cpp:237]     Train net output #0: loss = 0.0127127 (* 1 = 0.0127127 loss)
I0526 19:18:18.807044 30701 sgd_solver.cpp:105] Iteration 42500, lr = 0.007875
I0526 19:18:35.197662 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:18:47.012382 30701 solver.cpp:218] Iteration 42600 (3.54549 iter/s, 28.2048s/100 iters), loss = 0.154361
I0526 19:18:47.012439 30701 solver.cpp:237]     Train net output #0: loss = 0.154359 (* 1 = 0.154359 loss)
I0526 19:18:47.012446 30701 sgd_solver.cpp:105] Iteration 42600, lr = 0.00787
I0526 19:19:15.215214 30701 solver.cpp:218] Iteration 42700 (3.54581 iter/s, 28.2023s/100 iters), loss = 0.0353608
I0526 19:19:15.215368 30701 solver.cpp:237]     Train net output #0: loss = 0.0353592 (* 1 = 0.0353592 loss)
I0526 19:19:15.215379 30701 sgd_solver.cpp:105] Iteration 42700, lr = 0.007865
I0526 19:19:43.412356 30701 solver.cpp:218] Iteration 42800 (3.54654 iter/s, 28.1965s/100 iters), loss = 0.0441561
I0526 19:19:43.412413 30701 solver.cpp:237]     Train net output #0: loss = 0.0441545 (* 1 = 0.0441545 loss)
I0526 19:19:43.412422 30701 sgd_solver.cpp:105] Iteration 42800, lr = 0.00786
I0526 19:20:11.614958 30701 solver.cpp:218] Iteration 42900 (3.54584 iter/s, 28.202s/100 iters), loss = 0.0270787
I0526 19:20:11.615137 30701 solver.cpp:237]     Train net output #0: loss = 0.027077 (* 1 = 0.027077 loss)
I0526 19:20:11.615155 30701 sgd_solver.cpp:105] Iteration 42900, lr = 0.007855
I0526 19:20:39.550334 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_43000.caffemodel
I0526 19:20:39.997628 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_43000.solverstate
I0526 19:20:40.160150 30701 solver.cpp:330] Iteration 43000, Testing net (#0)
I0526 19:20:41.999568 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:20:43.125661 30701 solver.cpp:397]     Test net output #0: accuracy = 0.728
I0526 19:20:43.125710 30701 solver.cpp:397]     Test net output #1: loss = 1.27322 (* 1 = 1.27322 loss)
I0526 19:20:43.403759 30701 solver.cpp:218] Iteration 43000 (3.14584 iter/s, 31.7881s/100 iters), loss = 0.207984
I0526 19:20:43.403820 30701 solver.cpp:237]     Train net output #0: loss = 0.207982 (* 1 = 0.207982 loss)
I0526 19:20:43.403830 30701 sgd_solver.cpp:105] Iteration 43000, lr = 0.00785
I0526 19:21:11.541162 30701 solver.cpp:218] Iteration 43100 (3.55406 iter/s, 28.1368s/100 iters), loss = 0.217216
I0526 19:21:11.541221 30701 solver.cpp:237]     Train net output #0: loss = 0.217214 (* 1 = 0.217214 loss)
I0526 19:21:11.541230 30701 sgd_solver.cpp:105] Iteration 43100, lr = 0.007845
I0526 19:21:25.351263 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:21:39.681289 30701 solver.cpp:218] Iteration 43200 (3.55372 iter/s, 28.1395s/100 iters), loss = 0.031995
I0526 19:21:39.681356 30701 solver.cpp:237]     Train net output #0: loss = 0.0319933 (* 1 = 0.0319933 loss)
I0526 19:21:39.681365 30701 sgd_solver.cpp:105] Iteration 43200, lr = 0.00784
I0526 19:22:07.827813 30701 solver.cpp:218] Iteration 43300 (3.55291 iter/s, 28.1459s/100 iters), loss = 0.0401715
I0526 19:22:07.827986 30701 solver.cpp:237]     Train net output #0: loss = 0.0401698 (* 1 = 0.0401698 loss)
I0526 19:22:07.827996 30701 sgd_solver.cpp:105] Iteration 43300, lr = 0.007835
I0526 19:22:35.975180 30701 solver.cpp:218] Iteration 43400 (3.55282 iter/s, 28.1467s/100 iters), loss = 0.063627
I0526 19:22:35.975241 30701 solver.cpp:237]     Train net output #0: loss = 0.0636252 (* 1 = 0.0636252 loss)
I0526 19:22:35.975250 30701 sgd_solver.cpp:105] Iteration 43400, lr = 0.00783
I0526 19:23:04.117208 30701 solver.cpp:218] Iteration 43500 (3.55348 iter/s, 28.1414s/100 iters), loss = 0.0742869
I0526 19:23:04.117419 30701 solver.cpp:237]     Train net output #0: loss = 0.0742852 (* 1 = 0.0742852 loss)
I0526 19:23:04.117430 30701 sgd_solver.cpp:105] Iteration 43500, lr = 0.007825
I0526 19:23:32.268066 30701 solver.cpp:218] Iteration 43600 (3.55238 iter/s, 28.1502s/100 iters), loss = 0.00635335
I0526 19:23:32.268124 30701 solver.cpp:237]     Train net output #0: loss = 0.00635166 (* 1 = 0.00635166 loss)
I0526 19:23:32.268133 30701 sgd_solver.cpp:105] Iteration 43600, lr = 0.00782
I0526 19:24:00.416143 30701 solver.cpp:218] Iteration 43700 (3.55271 iter/s, 28.1475s/100 iters), loss = 0.0201374
I0526 19:24:00.416297 30701 solver.cpp:237]     Train net output #0: loss = 0.0201357 (* 1 = 0.0201357 loss)
I0526 19:24:00.416309 30701 sgd_solver.cpp:105] Iteration 43700, lr = 0.007815
I0526 19:24:11.967077 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:24:28.555215 30701 solver.cpp:218] Iteration 43800 (3.55386 iter/s, 28.1384s/100 iters), loss = 0.0839386
I0526 19:24:28.555275 30701 solver.cpp:237]     Train net output #0: loss = 0.083937 (* 1 = 0.083937 loss)
I0526 19:24:28.555285 30701 sgd_solver.cpp:105] Iteration 43800, lr = 0.00781
I0526 19:24:56.686734 30701 solver.cpp:218] Iteration 43900 (3.55481 iter/s, 28.1309s/100 iters), loss = 0.0378691
I0526 19:24:56.686985 30701 solver.cpp:237]     Train net output #0: loss = 0.0378674 (* 1 = 0.0378674 loss)
I0526 19:24:56.686996 30701 sgd_solver.cpp:105] Iteration 43900, lr = 0.007805
I0526 19:25:24.567848 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_44000.caffemodel
I0526 19:25:25.021777 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_44000.solverstate
I0526 19:25:25.172745 30701 solver.cpp:330] Iteration 44000, Testing net (#0)
I0526 19:25:28.131259 30701 solver.cpp:397]     Test net output #0: accuracy = 0.762
I0526 19:25:28.131381 30701 solver.cpp:397]     Test net output #1: loss = 1.12242 (* 1 = 1.12242 loss)
I0526 19:25:28.411422 30701 solver.cpp:218] Iteration 44000 (3.1522 iter/s, 31.7239s/100 iters), loss = 0.0398797
I0526 19:25:28.411484 30701 solver.cpp:237]     Train net output #0: loss = 0.039878 (* 1 = 0.039878 loss)
I0526 19:25:28.411492 30701 sgd_solver.cpp:105] Iteration 44000, lr = 0.0078
I0526 19:25:56.595257 30701 solver.cpp:218] Iteration 44100 (3.54821 iter/s, 28.1832s/100 iters), loss = 0.10617
I0526 19:25:56.595319 30701 solver.cpp:237]     Train net output #0: loss = 0.106168 (* 1 = 0.106168 loss)
I0526 19:25:56.595329 30701 sgd_solver.cpp:105] Iteration 44100, lr = 0.007795
I0526 19:26:24.802248 30701 solver.cpp:218] Iteration 44200 (3.5453 iter/s, 28.2064s/100 iters), loss = 0.0154961
I0526 19:26:24.802472 30701 solver.cpp:237]     Train net output #0: loss = 0.0154944 (* 1 = 0.0154944 loss)
I0526 19:26:24.802484 30701 sgd_solver.cpp:105] Iteration 44200, lr = 0.00779
I0526 19:26:53.001543 30701 solver.cpp:218] Iteration 44300 (3.54628 iter/s, 28.1985s/100 iters), loss = 0.0113258
I0526 19:26:53.001600 30701 solver.cpp:237]     Train net output #0: loss = 0.0113241 (* 1 = 0.0113241 loss)
I0526 19:26:53.001610 30701 sgd_solver.cpp:105] Iteration 44300, lr = 0.007785
I0526 19:27:02.051906 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:27:21.207065 30701 solver.cpp:218] Iteration 44400 (3.54548 iter/s, 28.2049s/100 iters), loss = 0.0091503
I0526 19:27:21.207123 30701 solver.cpp:237]     Train net output #0: loss = 0.00914863 (* 1 = 0.00914863 loss)
I0526 19:27:21.207132 30701 sgd_solver.cpp:105] Iteration 44400, lr = 0.00778
I0526 19:27:49.398622 30701 solver.cpp:218] Iteration 44500 (3.54724 iter/s, 28.191s/100 iters), loss = 0.0567435
I0526 19:27:49.398782 30701 solver.cpp:237]     Train net output #0: loss = 0.0567418 (* 1 = 0.0567418 loss)
I0526 19:27:49.398794 30701 sgd_solver.cpp:105] Iteration 44500, lr = 0.007775
I0526 19:28:17.572909 30701 solver.cpp:218] Iteration 44600 (3.54942 iter/s, 28.1736s/100 iters), loss = 0.0375575
I0526 19:28:17.572969 30701 solver.cpp:237]     Train net output #0: loss = 0.0375558 (* 1 = 0.0375558 loss)
I0526 19:28:17.572978 30701 sgd_solver.cpp:105] Iteration 44600, lr = 0.00777
I0526 19:28:45.748553 30701 solver.cpp:218] Iteration 44700 (3.54924 iter/s, 28.1751s/100 iters), loss = 0.0041606
I0526 19:28:45.748708 30701 solver.cpp:237]     Train net output #0: loss = 0.00415891 (* 1 = 0.00415891 loss)
I0526 19:28:45.748719 30701 sgd_solver.cpp:105] Iteration 44700, lr = 0.007765
I0526 19:29:13.934012 30701 solver.cpp:218] Iteration 44800 (3.54801 iter/s, 28.1848s/100 iters), loss = 0.00221584
I0526 19:29:13.934062 30701 solver.cpp:237]     Train net output #0: loss = 0.00221418 (* 1 = 0.00221418 loss)
I0526 19:29:13.934072 30701 sgd_solver.cpp:105] Iteration 44800, lr = 0.00776
I0526 19:29:42.119541 30701 solver.cpp:218] Iteration 44900 (3.54799 iter/s, 28.1849s/100 iters), loss = 0.00753524
I0526 19:29:42.119681 30701 solver.cpp:237]     Train net output #0: loss = 0.00753357 (* 1 = 0.00753357 loss)
I0526 19:29:42.119693 30701 sgd_solver.cpp:105] Iteration 44900, lr = 0.007755
I0526 19:29:48.622599 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:30:10.037325 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_45000.caffemodel
I0526 19:30:10.428303 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_45000.solverstate
I0526 19:30:10.590502 30701 solver.cpp:330] Iteration 45000, Testing net (#0)
I0526 19:30:13.547426 30701 solver.cpp:397]     Test net output #0: accuracy = 0.712
I0526 19:30:13.547583 30701 solver.cpp:397]     Test net output #1: loss = 1.30887 (* 1 = 1.30887 loss)
I0526 19:30:13.826498 30701 solver.cpp:218] Iteration 45000 (3.15396 iter/s, 31.7062s/100 iters), loss = 0.336029
I0526 19:30:13.826556 30701 solver.cpp:237]     Train net output #0: loss = 0.336028 (* 1 = 0.336028 loss)
I0526 19:30:13.826565 30701 sgd_solver.cpp:105] Iteration 45000, lr = 0.00775
I0526 19:30:42.009109 30701 solver.cpp:218] Iteration 45100 (3.54836 iter/s, 28.182s/100 iters), loss = 0.00394698
I0526 19:30:42.009167 30701 solver.cpp:237]     Train net output #0: loss = 0.00394528 (* 1 = 0.00394528 loss)
I0526 19:30:42.009176 30701 sgd_solver.cpp:105] Iteration 45100, lr = 0.007745
I0526 19:31:10.199405 30701 solver.cpp:218] Iteration 45200 (3.54739 iter/s, 28.1897s/100 iters), loss = 0.0819676
I0526 19:31:10.199508 30701 solver.cpp:237]     Train net output #0: loss = 0.0819659 (* 1 = 0.0819659 loss)
I0526 19:31:10.199518 30701 sgd_solver.cpp:105] Iteration 45200, lr = 0.00774
I0526 19:31:38.373740 30701 solver.cpp:218] Iteration 45300 (3.54941 iter/s, 28.1737s/100 iters), loss = 0.0895096
I0526 19:31:38.373798 30701 solver.cpp:237]     Train net output #0: loss = 0.089508 (* 1 = 0.089508 loss)
I0526 19:31:38.373807 30701 sgd_solver.cpp:105] Iteration 45300, lr = 0.007735
I0526 19:32:06.536933 30701 solver.cpp:218] Iteration 45400 (3.55081 iter/s, 28.1626s/100 iters), loss = 0.0721247
I0526 19:32:06.537084 30701 solver.cpp:237]     Train net output #0: loss = 0.0721231 (* 1 = 0.0721231 loss)
I0526 19:32:06.537096 30701 sgd_solver.cpp:105] Iteration 45400, lr = 0.00773
I0526 19:32:34.712752 30701 solver.cpp:218] Iteration 45500 (3.54923 iter/s, 28.1751s/100 iters), loss = 0.0110355
I0526 19:32:34.712813 30701 solver.cpp:237]     Train net output #0: loss = 0.0110337 (* 1 = 0.0110337 loss)
I0526 19:32:34.712822 30701 sgd_solver.cpp:105] Iteration 45500, lr = 0.007725
I0526 19:32:38.682353 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:33:02.902323 30701 solver.cpp:218] Iteration 45600 (3.54749 iter/s, 28.189s/100 iters), loss = 0.00851423
I0526 19:33:02.902380 30701 solver.cpp:237]     Train net output #0: loss = 0.00851253 (* 1 = 0.00851253 loss)
I0526 19:33:02.902390 30701 sgd_solver.cpp:105] Iteration 45600, lr = 0.00772
I0526 19:33:31.070754 30701 solver.cpp:218] Iteration 45700 (3.55015 iter/s, 28.1678s/100 iters), loss = 0.066088
I0526 19:33:31.070951 30701 solver.cpp:237]     Train net output #0: loss = 0.0660864 (* 1 = 0.0660864 loss)
I0526 19:33:31.070966 30701 sgd_solver.cpp:105] Iteration 45700, lr = 0.007715
I0526 19:33:59.259599 30701 solver.cpp:218] Iteration 45800 (3.54759 iter/s, 28.1881s/100 iters), loss = 0.0417598
I0526 19:33:59.259656 30701 solver.cpp:237]     Train net output #0: loss = 0.0417581 (* 1 = 0.0417581 loss)
I0526 19:33:59.259665 30701 sgd_solver.cpp:105] Iteration 45800, lr = 0.00771
I0526 19:34:27.443027 30701 solver.cpp:218] Iteration 45900 (3.54826 iter/s, 28.1828s/100 iters), loss = 0.347092
I0526 19:34:27.443183 30701 solver.cpp:237]     Train net output #0: loss = 0.34709 (* 1 = 0.34709 loss)
I0526 19:34:27.443195 30701 sgd_solver.cpp:105] Iteration 45900, lr = 0.007705
I0526 19:34:55.340255 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_46000.caffemodel
I0526 19:34:55.706261 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_46000.solverstate
I0526 19:34:55.855172 30701 solver.cpp:330] Iteration 46000, Testing net (#0)
I0526 19:34:56.422448 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:34:58.827792 30701 solver.cpp:397]     Test net output #0: accuracy = 0.768
I0526 19:34:58.827973 30701 solver.cpp:397]     Test net output #1: loss = 1.1566 (* 1 = 1.1566 loss)
I0526 19:34:59.108392 30701 solver.cpp:218] Iteration 46000 (3.1581 iter/s, 31.6646s/100 iters), loss = 0.0253065
I0526 19:34:59.108453 30701 solver.cpp:237]     Train net output #0: loss = 0.0253048 (* 1 = 0.0253048 loss)
I0526 19:34:59.108461 30701 sgd_solver.cpp:105] Iteration 46000, lr = 0.0077
I0526 19:35:27.323268 30701 solver.cpp:218] Iteration 46100 (3.54431 iter/s, 28.2143s/100 iters), loss = 0.020638
I0526 19:35:27.323319 30701 solver.cpp:237]     Train net output #0: loss = 0.0206363 (* 1 = 0.0206363 loss)
I0526 19:35:27.323340 30701 sgd_solver.cpp:105] Iteration 46100, lr = 0.007695
I0526 19:35:28.755440 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:35:55.541488 30701 solver.cpp:218] Iteration 46200 (3.54388 iter/s, 28.2176s/100 iters), loss = 0.0684976
I0526 19:35:55.541580 30701 solver.cpp:237]     Train net output #0: loss = 0.068496 (* 1 = 0.068496 loss)
I0526 19:35:55.541591 30701 sgd_solver.cpp:105] Iteration 46200, lr = 0.00769
I0526 19:36:23.718978 30701 solver.cpp:218] Iteration 46300 (3.54901 iter/s, 28.1769s/100 iters), loss = 0.02651
I0526 19:36:23.719043 30701 solver.cpp:237]     Train net output #0: loss = 0.0265083 (* 1 = 0.0265083 loss)
I0526 19:36:23.719051 30701 sgd_solver.cpp:105] Iteration 46300, lr = 0.007685
I0526 19:36:51.890079 30701 solver.cpp:218] Iteration 46400 (3.54981 iter/s, 28.1705s/100 iters), loss = 0.0243127
I0526 19:36:51.890231 30701 solver.cpp:237]     Train net output #0: loss = 0.0243111 (* 1 = 0.0243111 loss)
I0526 19:36:51.890244 30701 sgd_solver.cpp:105] Iteration 46400, lr = 0.00768
I0526 19:37:20.076457 30701 solver.cpp:218] Iteration 46500 (3.5479 iter/s, 28.1857s/100 iters), loss = 0.0588673
I0526 19:37:20.076508 30701 solver.cpp:237]     Train net output #0: loss = 0.0588657 (* 1 = 0.0588657 loss)
I0526 19:37:20.076517 30701 sgd_solver.cpp:105] Iteration 46500, lr = 0.007675
I0526 19:37:48.295364 30701 solver.cpp:218] Iteration 46600 (3.5438 iter/s, 28.2183s/100 iters), loss = 0.0985336
I0526 19:37:48.295516 30701 solver.cpp:237]     Train net output #0: loss = 0.0985319 (* 1 = 0.0985319 loss)
I0526 19:37:48.295531 30701 sgd_solver.cpp:105] Iteration 46600, lr = 0.00767
I0526 19:38:15.387245 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:38:16.502390 30701 solver.cpp:218] Iteration 46700 (3.5453 iter/s, 28.2063s/100 iters), loss = 0.0333488
I0526 19:38:16.502449 30701 solver.cpp:237]     Train net output #0: loss = 0.0333472 (* 1 = 0.0333472 loss)
I0526 19:38:16.502475 30701 sgd_solver.cpp:105] Iteration 46700, lr = 0.007665
I0526 19:38:44.716971 30701 solver.cpp:218] Iteration 46800 (3.54435 iter/s, 28.2139s/100 iters), loss = 0.0083728
I0526 19:38:44.717092 30701 solver.cpp:237]     Train net output #0: loss = 0.00837118 (* 1 = 0.00837118 loss)
I0526 19:38:44.717105 30701 sgd_solver.cpp:105] Iteration 46800, lr = 0.00766
I0526 19:39:12.915833 30701 solver.cpp:218] Iteration 46900 (3.54641 iter/s, 28.1975s/100 iters), loss = 0.00950049
I0526 19:39:12.915881 30701 solver.cpp:237]     Train net output #0: loss = 0.00949885 (* 1 = 0.00949885 loss)
I0526 19:39:12.915890 30701 sgd_solver.cpp:105] Iteration 46900, lr = 0.007655
I0526 19:39:40.851135 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_47000.caffemodel
I0526 19:39:41.258258 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_47000.solverstate
I0526 19:39:41.409974 30701 solver.cpp:330] Iteration 47000, Testing net (#0)
I0526 19:39:44.371073 30701 solver.cpp:397]     Test net output #0: accuracy = 0.75
I0526 19:39:44.371109 30701 solver.cpp:397]     Test net output #1: loss = 1.30687 (* 1 = 1.30687 loss)
I0526 19:39:44.648419 30701 solver.cpp:218] Iteration 47000 (3.15148 iter/s, 31.7312s/100 iters), loss = 0.165059
I0526 19:39:44.648485 30701 solver.cpp:237]     Train net output #0: loss = 0.165058 (* 1 = 0.165058 loss)
I0526 19:39:44.648494 30701 sgd_solver.cpp:105] Iteration 47000, lr = 0.00765
I0526 19:40:12.820986 30701 solver.cpp:218] Iteration 47100 (3.54971 iter/s, 28.1713s/100 iters), loss = 0.12022
I0526 19:40:12.821169 30701 solver.cpp:237]     Train net output #0: loss = 0.120219 (* 1 = 0.120219 loss)
I0526 19:40:12.821180 30701 sgd_solver.cpp:105] Iteration 47100, lr = 0.007645
I0526 19:40:40.994864 30701 solver.cpp:218] Iteration 47200 (3.54956 iter/s, 28.1725s/100 iters), loss = 0.0910341
I0526 19:40:40.994926 30701 solver.cpp:237]     Train net output #0: loss = 0.0910325 (* 1 = 0.0910325 loss)
I0526 19:40:40.994936 30701 sgd_solver.cpp:105] Iteration 47200, lr = 0.00764
I0526 19:41:05.518180 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:41:09.153424 30701 solver.cpp:218] Iteration 47300 (3.55147 iter/s, 28.1574s/100 iters), loss = 0.00828977
I0526 19:41:09.153483 30701 solver.cpp:237]     Train net output #0: loss = 0.00828807 (* 1 = 0.00828807 loss)
I0526 19:41:09.153492 30701 sgd_solver.cpp:105] Iteration 47300, lr = 0.007635
I0526 19:41:37.305488 30701 solver.cpp:218] Iteration 47400 (3.55228 iter/s, 28.1509s/100 iters), loss = 0.0566519
I0526 19:41:37.305642 30701 solver.cpp:237]     Train net output #0: loss = 0.0566502 (* 1 = 0.0566502 loss)
I0526 19:41:37.305655 30701 sgd_solver.cpp:105] Iteration 47400, lr = 0.00763
I0526 19:42:05.467257 30701 solver.cpp:218] Iteration 47500 (3.55107 iter/s, 28.1605s/100 iters), loss = 0.0481575
I0526 19:42:05.467315 30701 solver.cpp:237]     Train net output #0: loss = 0.0481558 (* 1 = 0.0481558 loss)
I0526 19:42:05.467324 30701 sgd_solver.cpp:105] Iteration 47500, lr = 0.007625
I0526 19:42:33.625465 30701 solver.cpp:218] Iteration 47600 (3.5515 iter/s, 28.1571s/100 iters), loss = 0.00344947
I0526 19:42:33.625628 30701 solver.cpp:237]     Train net output #0: loss = 0.00344772 (* 1 = 0.00344772 loss)
I0526 19:42:33.625640 30701 sgd_solver.cpp:105] Iteration 47600, lr = 0.00762
I0526 19:43:01.789643 30701 solver.cpp:218] Iteration 47700 (3.55076 iter/s, 28.163s/100 iters), loss = 0.102093
I0526 19:43:01.789700 30701 solver.cpp:237]     Train net output #0: loss = 0.102092 (* 1 = 0.102092 loss)
I0526 19:43:01.789708 30701 sgd_solver.cpp:105] Iteration 47700, lr = 0.007615
I0526 19:43:29.955793 30701 solver.cpp:218] Iteration 47800 (3.55049 iter/s, 28.1651s/100 iters), loss = 0.0384266
I0526 19:43:29.955940 30701 solver.cpp:237]     Train net output #0: loss = 0.0384248 (* 1 = 0.0384248 loss)
I0526 19:43:29.955961 30701 sgd_solver.cpp:105] Iteration 47800, lr = 0.00761
I0526 19:43:52.225495 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:43:58.126219 30701 solver.cpp:218] Iteration 47900 (3.54996 iter/s, 28.1693s/100 iters), loss = 0.00170332
I0526 19:43:58.126269 30701 solver.cpp:237]     Train net output #0: loss = 0.00170157 (* 1 = 0.00170157 loss)
I0526 19:43:58.126278 30701 sgd_solver.cpp:105] Iteration 47900, lr = 0.007605
I0526 19:44:26.005404 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_48000.caffemodel
I0526 19:44:26.393270 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_48000.solverstate
I0526 19:44:26.545454 30701 solver.cpp:330] Iteration 48000, Testing net (#0)
I0526 19:44:28.795500 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:44:29.502846 30701 solver.cpp:397]     Test net output #0: accuracy = 0.716
I0526 19:44:29.502881 30701 solver.cpp:397]     Test net output #1: loss = 1.3302 (* 1 = 1.3302 loss)
I0526 19:44:29.781451 30701 solver.cpp:218] Iteration 48000 (3.15915 iter/s, 31.6541s/100 iters), loss = 0.00433792
I0526 19:44:29.781509 30701 solver.cpp:237]     Train net output #0: loss = 0.00433618 (* 1 = 0.00433618 loss)
I0526 19:44:29.781519 30701 sgd_solver.cpp:105] Iteration 48000, lr = 0.0076
I0526 19:44:57.924120 30701 solver.cpp:218] Iteration 48100 (3.55345 iter/s, 28.1417s/100 iters), loss = 0.0292279
I0526 19:44:57.924271 30701 solver.cpp:237]     Train net output #0: loss = 0.0292261 (* 1 = 0.0292261 loss)
I0526 19:44:57.924283 30701 sgd_solver.cpp:105] Iteration 48100, lr = 0.007595
I0526 19:45:26.075424 30701 solver.cpp:218] Iteration 48200 (3.55237 iter/s, 28.1502s/100 iters), loss = 0.108037
I0526 19:45:26.075484 30701 solver.cpp:237]     Train net output #0: loss = 0.108035 (* 1 = 0.108035 loss)
I0526 19:45:26.075492 30701 sgd_solver.cpp:105] Iteration 48200, lr = 0.00759
I0526 19:45:54.229868 30701 solver.cpp:218] Iteration 48300 (3.55196 iter/s, 28.1535s/100 iters), loss = 0.0561705
I0526 19:45:54.230052 30701 solver.cpp:237]     Train net output #0: loss = 0.0561687 (* 1 = 0.0561687 loss)
I0526 19:45:54.230064 30701 sgd_solver.cpp:105] Iteration 48300, lr = 0.007585
I0526 19:46:22.385040 30701 solver.cpp:218] Iteration 48400 (3.55188 iter/s, 28.1541s/100 iters), loss = 0.00148319
I0526 19:46:22.385099 30701 solver.cpp:237]     Train net output #0: loss = 0.00148137 (* 1 = 0.00148137 loss)
I0526 19:46:22.385108 30701 sgd_solver.cpp:105] Iteration 48400, lr = 0.00758
I0526 19:46:42.101645 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:46:50.531910 30701 solver.cpp:218] Iteration 48500 (3.55291 iter/s, 28.1459s/100 iters), loss = 0.00971845
I0526 19:46:50.531965 30701 solver.cpp:237]     Train net output #0: loss = 0.00971657 (* 1 = 0.00971657 loss)
I0526 19:46:50.531975 30701 sgd_solver.cpp:105] Iteration 48500, lr = 0.007575
I0526 19:47:18.682495 30701 solver.cpp:218] Iteration 48600 (3.55244 iter/s, 28.1497s/100 iters), loss = 0.221898
I0526 19:47:18.682636 30701 solver.cpp:237]     Train net output #0: loss = 0.221896 (* 1 = 0.221896 loss)
I0526 19:47:18.682652 30701 sgd_solver.cpp:105] Iteration 48600, lr = 0.00757
I0526 19:47:46.821166 30701 solver.cpp:218] Iteration 48700 (3.55395 iter/s, 28.1377s/100 iters), loss = 0.00561652
I0526 19:47:46.821213 30701 solver.cpp:237]     Train net output #0: loss = 0.00561464 (* 1 = 0.00561464 loss)
I0526 19:47:46.821233 30701 sgd_solver.cpp:105] Iteration 48700, lr = 0.007565
I0526 19:48:14.980592 30701 solver.cpp:218] Iteration 48800 (3.55132 iter/s, 28.1585s/100 iters), loss = 0.00365309
I0526 19:48:14.980751 30701 solver.cpp:237]     Train net output #0: loss = 0.00365123 (* 1 = 0.00365123 loss)
I0526 19:48:14.980764 30701 sgd_solver.cpp:105] Iteration 48800, lr = 0.00756
I0526 19:48:43.129739 30701 solver.cpp:218] Iteration 48900 (3.55263 iter/s, 28.1482s/100 iters), loss = 0.0258893
I0526 19:48:43.129797 30701 solver.cpp:237]     Train net output #0: loss = 0.0258875 (* 1 = 0.0258875 loss)
I0526 19:48:43.129807 30701 sgd_solver.cpp:105] Iteration 48900, lr = 0.007555
I0526 19:49:10.996083 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_49000.caffemodel
I0526 19:49:11.374361 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_49000.solverstate
I0526 19:49:11.524755 30701 solver.cpp:330] Iteration 49000, Testing net (#0)
I0526 19:49:14.481560 30701 solver.cpp:397]     Test net output #0: accuracy = 0.742
I0526 19:49:14.481597 30701 solver.cpp:397]     Test net output #1: loss = 1.18274 (* 1 = 1.18274 loss)
I0526 19:49:14.760633 30701 solver.cpp:218] Iteration 49000 (3.16156 iter/s, 31.6299s/100 iters), loss = 0.000392076
I0526 19:49:14.760682 30701 solver.cpp:237]     Train net output #0: loss = 0.000390253 (* 1 = 0.000390253 loss)
I0526 19:49:14.760704 30701 sgd_solver.cpp:105] Iteration 49000, lr = 0.00755
I0526 19:49:31.957231 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:49:42.921381 30701 solver.cpp:218] Iteration 49100 (3.55115 iter/s, 28.1599s/100 iters), loss = 0.108591
I0526 19:49:42.921520 30701 solver.cpp:237]     Train net output #0: loss = 0.108589 (* 1 = 0.108589 loss)
I0526 19:49:42.921533 30701 sgd_solver.cpp:105] Iteration 49100, lr = 0.007545
I0526 19:50:11.107887 30701 solver.cpp:218] Iteration 49200 (3.54791 iter/s, 28.1856s/100 iters), loss = 0.12447
I0526 19:50:11.107954 30701 solver.cpp:237]     Train net output #0: loss = 0.124468 (* 1 = 0.124468 loss)
I0526 19:50:11.107964 30701 sgd_solver.cpp:105] Iteration 49200, lr = 0.00754
I0526 19:50:39.309733 30701 solver.cpp:218] Iteration 49300 (3.54597 iter/s, 28.201s/100 iters), loss = 0.0423792
I0526 19:50:39.309871 30701 solver.cpp:237]     Train net output #0: loss = 0.0423773 (* 1 = 0.0423773 loss)
I0526 19:50:39.309883 30701 sgd_solver.cpp:105] Iteration 49300, lr = 0.007535
I0526 19:51:07.510464 30701 solver.cpp:218] Iteration 49400 (3.54612 iter/s, 28.1998s/100 iters), loss = 0.00862497
I0526 19:51:07.510519 30701 solver.cpp:237]     Train net output #0: loss = 0.00862308 (* 1 = 0.00862308 loss)
I0526 19:51:07.510529 30701 sgd_solver.cpp:105] Iteration 49400, lr = 0.00753
I0526 19:51:35.714179 30701 solver.cpp:218] Iteration 49500 (3.54574 iter/s, 28.2029s/100 iters), loss = 0.0190879
I0526 19:51:35.714339 30701 solver.cpp:237]     Train net output #0: loss = 0.019086 (* 1 = 0.019086 loss)
I0526 19:51:35.714351 30701 sgd_solver.cpp:105] Iteration 49500, lr = 0.007525
I0526 19:52:03.914680 30701 solver.cpp:218] Iteration 49600 (3.54615 iter/s, 28.1996s/100 iters), loss = 0.054088
I0526 19:52:03.914732 30701 solver.cpp:237]     Train net output #0: loss = 0.054086 (* 1 = 0.054086 loss)
I0526 19:52:03.914743 30701 sgd_solver.cpp:105] Iteration 49600, lr = 0.00752
I0526 19:52:18.597255 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:52:32.125993 30701 solver.cpp:218] Iteration 49700 (3.54478 iter/s, 28.2105s/100 iters), loss = 0.0986409
I0526 19:52:32.126051 30701 solver.cpp:237]     Train net output #0: loss = 0.098639 (* 1 = 0.098639 loss)
I0526 19:52:32.126060 30701 sgd_solver.cpp:105] Iteration 49700, lr = 0.007515
I0526 19:53:00.324074 30701 solver.cpp:218] Iteration 49800 (3.54644 iter/s, 28.1973s/100 iters), loss = 0.133204
I0526 19:53:00.324312 30701 solver.cpp:237]     Train net output #0: loss = 0.133202 (* 1 = 0.133202 loss)
I0526 19:53:00.324326 30701 sgd_solver.cpp:105] Iteration 49800, lr = 0.00751
I0526 19:53:28.533527 30701 solver.cpp:218] Iteration 49900 (3.54503 iter/s, 28.2085s/100 iters), loss = 0.0866298
I0526 19:53:28.533589 30701 solver.cpp:237]     Train net output #0: loss = 0.0866279 (* 1 = 0.0866279 loss)
I0526 19:53:28.533598 30701 sgd_solver.cpp:105] Iteration 49900, lr = 0.007505
I0526 19:53:56.488651 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_50000.caffemodel
I0526 19:53:56.920204 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_50000.solverstate
I0526 19:53:57.071326 30701 solver.cpp:330] Iteration 50000, Testing net (#0)
I0526 19:54:00.031404 30701 solver.cpp:397]     Test net output #0: accuracy = 0.768
I0526 19:54:00.031438 30701 solver.cpp:397]     Test net output #1: loss = 1.20415 (* 1 = 1.20415 loss)
I0526 19:54:00.314738 30701 solver.cpp:218] Iteration 50000 (3.1466 iter/s, 31.7803s/100 iters), loss = 0.00339838
I0526 19:54:00.314800 30701 solver.cpp:237]     Train net output #0: loss = 0.0033965 (* 1 = 0.0033965 loss)
I0526 19:54:00.314808 30701 sgd_solver.cpp:105] Iteration 50000, lr = 0.0075
I0526 19:54:28.467417 30701 solver.cpp:218] Iteration 50100 (3.55216 iter/s, 28.1519s/100 iters), loss = 0.0105093
I0526 19:54:28.467548 30701 solver.cpp:237]     Train net output #0: loss = 0.0105074 (* 1 = 0.0105074 loss)
I0526 19:54:28.467558 30701 sgd_solver.cpp:105] Iteration 50100, lr = 0.007495
I0526 19:54:56.661828 30701 solver.cpp:218] Iteration 50200 (3.54691 iter/s, 28.1936s/100 iters), loss = 0.132885
I0526 19:54:56.661890 30701 solver.cpp:237]     Train net output #0: loss = 0.132883 (* 1 = 0.132883 loss)
I0526 19:54:56.661900 30701 sgd_solver.cpp:105] Iteration 50200, lr = 0.00749
I0526 19:55:08.811406 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:55:24.879624 30701 solver.cpp:218] Iteration 50300 (3.54396 iter/s, 28.217s/100 iters), loss = 0.041791
I0526 19:55:24.879688 30701 solver.cpp:237]     Train net output #0: loss = 0.0417891 (* 1 = 0.0417891 loss)
I0526 19:55:24.879699 30701 sgd_solver.cpp:105] Iteration 50300, lr = 0.007485
I0526 19:55:53.078486 30701 solver.cpp:218] Iteration 50400 (3.54634 iter/s, 28.1981s/100 iters), loss = 0.126446
I0526 19:55:53.078625 30701 solver.cpp:237]     Train net output #0: loss = 0.126444 (* 1 = 0.126444 loss)
I0526 19:55:53.078639 30701 sgd_solver.cpp:105] Iteration 50400, lr = 0.00748
I0526 19:56:21.286336 30701 solver.cpp:218] Iteration 50500 (3.54522 iter/s, 28.207s/100 iters), loss = 0.0609578
I0526 19:56:21.286388 30701 solver.cpp:237]     Train net output #0: loss = 0.060956 (* 1 = 0.060956 loss)
I0526 19:56:21.286398 30701 sgd_solver.cpp:105] Iteration 50500, lr = 0.007475
I0526 19:56:49.499655 30701 solver.cpp:218] Iteration 50600 (3.54452 iter/s, 28.2126s/100 iters), loss = 0.00464453
I0526 19:56:49.499799 30701 solver.cpp:237]     Train net output #0: loss = 0.00464268 (* 1 = 0.00464268 loss)
I0526 19:56:49.499812 30701 sgd_solver.cpp:105] Iteration 50600, lr = 0.00747
I0526 19:57:17.699167 30701 solver.cpp:218] Iteration 50700 (3.54627 iter/s, 28.1987s/100 iters), loss = 0.00453122
I0526 19:57:17.699232 30701 solver.cpp:237]     Train net output #0: loss = 0.00452942 (* 1 = 0.00452942 loss)
I0526 19:57:17.699242 30701 sgd_solver.cpp:105] Iteration 50700, lr = 0.007465
I0526 19:57:45.889976 30701 solver.cpp:218] Iteration 50800 (3.54735 iter/s, 28.1901s/100 iters), loss = 0.0946331
I0526 19:57:45.890091 30701 solver.cpp:237]     Train net output #0: loss = 0.0946313 (* 1 = 0.0946313 loss)
I0526 19:57:45.890107 30701 sgd_solver.cpp:105] Iteration 50800, lr = 0.00746
I0526 19:57:55.500941 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:58:14.118489 30701 solver.cpp:218] Iteration 50900 (3.54262 iter/s, 28.2277s/100 iters), loss = 0.0111095
I0526 19:58:14.118546 30701 solver.cpp:237]     Train net output #0: loss = 0.0111077 (* 1 = 0.0111077 loss)
I0526 19:58:14.118556 30701 sgd_solver.cpp:105] Iteration 50900, lr = 0.007455
I0526 19:58:42.054920 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_51000.caffemodel
I0526 19:58:42.514539 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_51000.solverstate
I0526 19:58:42.665510 30701 solver.cpp:330] Iteration 51000, Testing net (#0)
I0526 19:58:43.621912 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 19:58:45.638938 30701 solver.cpp:397]     Test net output #0: accuracy = 0.772
I0526 19:58:45.638985 30701 solver.cpp:397]     Test net output #1: loss = 1.13546 (* 1 = 1.13546 loss)
I0526 19:58:45.917165 30701 solver.cpp:218] Iteration 51000 (3.14487 iter/s, 31.7978s/100 iters), loss = 0.0418528
I0526 19:58:45.917217 30701 solver.cpp:237]     Train net output #0: loss = 0.041851 (* 1 = 0.041851 loss)
I0526 19:58:45.917228 30701 sgd_solver.cpp:105] Iteration 51000, lr = 0.00745
I0526 19:59:14.095413 30701 solver.cpp:218] Iteration 51100 (3.54893 iter/s, 28.1775s/100 iters), loss = 0.00112712
I0526 19:59:14.095633 30701 solver.cpp:237]     Train net output #0: loss = 0.00112535 (* 1 = 0.00112535 loss)
I0526 19:59:14.095643 30701 sgd_solver.cpp:105] Iteration 51100, lr = 0.007445
I0526 19:59:42.257800 30701 solver.cpp:218] Iteration 51200 (3.55095 iter/s, 28.1615s/100 iters), loss = 0.0159232
I0526 19:59:42.257863 30701 solver.cpp:237]     Train net output #0: loss = 0.0159213 (* 1 = 0.0159213 loss)
I0526 19:59:42.257874 30701 sgd_solver.cpp:105] Iteration 51200, lr = 0.00744
I0526 20:00:10.431305 30701 solver.cpp:218] Iteration 51300 (3.54953 iter/s, 28.1728s/100 iters), loss = 0.0447355
I0526 20:00:10.431421 30701 solver.cpp:237]     Train net output #0: loss = 0.0447337 (* 1 = 0.0447337 loss)
I0526 20:00:10.431433 30701 sgd_solver.cpp:105] Iteration 51300, lr = 0.007435
I0526 20:00:38.637496 30701 solver.cpp:218] Iteration 51400 (3.54542 iter/s, 28.2054s/100 iters), loss = 0.00519881
I0526 20:00:38.637554 30701 solver.cpp:237]     Train net output #0: loss = 0.005197 (* 1 = 0.005197 loss)
I0526 20:00:38.637569 30701 sgd_solver.cpp:105] Iteration 51400, lr = 0.00743
I0526 20:00:45.989670 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:01:06.873581 30701 solver.cpp:218] Iteration 51500 (3.54166 iter/s, 28.2354s/100 iters), loss = 0.349135
I0526 20:01:06.873631 30701 solver.cpp:237]     Train net output #0: loss = 0.349133 (* 1 = 0.349133 loss)
I0526 20:01:06.873641 30701 sgd_solver.cpp:105] Iteration 51500, lr = 0.007425
I0526 20:01:35.093544 30701 solver.cpp:218] Iteration 51600 (3.54368 iter/s, 28.2192s/100 iters), loss = 0.0118169
I0526 20:01:35.093690 30701 solver.cpp:237]     Train net output #0: loss = 0.0118151 (* 1 = 0.0118151 loss)
I0526 20:01:35.093703 30701 sgd_solver.cpp:105] Iteration 51600, lr = 0.00742
I0526 20:02:03.325963 30701 solver.cpp:218] Iteration 51700 (3.54213 iter/s, 28.2316s/100 iters), loss = 0.00422055
I0526 20:02:03.326022 30701 solver.cpp:237]     Train net output #0: loss = 0.00421869 (* 1 = 0.00421869 loss)
I0526 20:02:03.326031 30701 sgd_solver.cpp:105] Iteration 51700, lr = 0.007415
I0526 20:02:31.546496 30701 solver.cpp:218] Iteration 51800 (3.54361 iter/s, 28.2198s/100 iters), loss = 0.00871762
I0526 20:02:31.546685 30701 solver.cpp:237]     Train net output #0: loss = 0.00871576 (* 1 = 0.00871576 loss)
I0526 20:02:31.546697 30701 sgd_solver.cpp:105] Iteration 51800, lr = 0.00741
I0526 20:02:59.766773 30701 solver.cpp:218] Iteration 51900 (3.54366 iter/s, 28.2194s/100 iters), loss = 0.00456581
I0526 20:02:59.766839 30701 solver.cpp:237]     Train net output #0: loss = 0.00456391 (* 1 = 0.00456391 loss)
I0526 20:02:59.766851 30701 sgd_solver.cpp:105] Iteration 51900, lr = 0.007405
I0526 20:03:27.711141 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_52000.caffemodel
I0526 20:03:28.133929 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_52000.solverstate
I0526 20:03:28.284462 30701 solver.cpp:330] Iteration 52000, Testing net (#0)
I0526 20:03:31.237704 30701 solver.cpp:397]     Test net output #0: accuracy = 0.636
I0526 20:03:31.237751 30701 solver.cpp:397]     Test net output #1: loss = 2.07655 (* 1 = 2.07655 loss)
I0526 20:03:31.517248 30701 solver.cpp:218] Iteration 52000 (3.14964 iter/s, 31.7497s/100 iters), loss = 0.115745
I0526 20:03:31.517305 30701 solver.cpp:237]     Train net output #0: loss = 0.115743 (* 1 = 0.115743 loss)
I0526 20:03:31.517315 30701 sgd_solver.cpp:105] Iteration 52000, lr = 0.0074
I0526 20:03:36.327215 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:03:59.729033 30701 solver.cpp:218] Iteration 52100 (3.54471 iter/s, 28.2111s/100 iters), loss = 0.0554847
I0526 20:03:59.729149 30701 solver.cpp:237]     Train net output #0: loss = 0.0554828 (* 1 = 0.0554828 loss)
I0526 20:03:59.729173 30701 sgd_solver.cpp:105] Iteration 52100, lr = 0.007395
I0526 20:04:27.931885 30701 solver.cpp:218] Iteration 52200 (3.54584 iter/s, 28.2021s/100 iters), loss = 0.124117
I0526 20:04:27.931958 30701 solver.cpp:237]     Train net output #0: loss = 0.124115 (* 1 = 0.124115 loss)
I0526 20:04:27.931974 30701 sgd_solver.cpp:105] Iteration 52200, lr = 0.00739
I0526 20:04:56.129351 30701 solver.cpp:218] Iteration 52300 (3.54651 iter/s, 28.1968s/100 iters), loss = 0.0419164
I0526 20:04:56.129475 30701 solver.cpp:237]     Train net output #0: loss = 0.0419144 (* 1 = 0.0419144 loss)
I0526 20:04:56.129489 30701 sgd_solver.cpp:105] Iteration 52300, lr = 0.007385
I0526 20:05:24.313231 30701 solver.cpp:218] Iteration 52400 (3.54822 iter/s, 28.1831s/100 iters), loss = 0.016929
I0526 20:05:24.313282 30701 solver.cpp:237]     Train net output #0: loss = 0.0169271 (* 1 = 0.0169271 loss)
I0526 20:05:24.313292 30701 sgd_solver.cpp:105] Iteration 52400, lr = 0.00738
I0526 20:05:52.489558 30701 solver.cpp:218] Iteration 52500 (3.54917 iter/s, 28.1756s/100 iters), loss = 0.0576338
I0526 20:05:52.489706 30701 solver.cpp:237]     Train net output #0: loss = 0.0576319 (* 1 = 0.0576319 loss)
I0526 20:05:52.489717 30701 sgd_solver.cpp:105] Iteration 52500, lr = 0.007375
I0526 20:06:20.661914 30701 solver.cpp:218] Iteration 52600 (3.54968 iter/s, 28.1715s/100 iters), loss = 0.00292835
I0526 20:06:20.661984 30701 solver.cpp:237]     Train net output #0: loss = 0.00292647 (* 1 = 0.00292647 loss)
I0526 20:06:20.661994 30701 sgd_solver.cpp:105] Iteration 52600, lr = 0.00737
I0526 20:06:22.932426 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:06:48.814460 30701 solver.cpp:218] Iteration 52700 (3.55217 iter/s, 28.1518s/100 iters), loss = 0.018549
I0526 20:06:48.814509 30701 solver.cpp:237]     Train net output #0: loss = 0.0185471 (* 1 = 0.0185471 loss)
I0526 20:06:48.814530 30701 sgd_solver.cpp:105] Iteration 52700, lr = 0.007365
I0526 20:07:16.995657 30701 solver.cpp:218] Iteration 52800 (3.54855 iter/s, 28.1805s/100 iters), loss = 0.000918113
I0526 20:07:16.995784 30701 solver.cpp:237]     Train net output #0: loss = 0.000916172 (* 1 = 0.000916172 loss)
I0526 20:07:16.995795 30701 sgd_solver.cpp:105] Iteration 52800, lr = 0.00736
I0526 20:07:45.198213 30701 solver.cpp:218] Iteration 52900 (3.54588 iter/s, 28.2018s/100 iters), loss = 0.062444
I0526 20:07:45.198279 30701 solver.cpp:237]     Train net output #0: loss = 0.0624421 (* 1 = 0.0624421 loss)
I0526 20:07:45.198294 30701 sgd_solver.cpp:105] Iteration 52900, lr = 0.007355
I0526 20:08:13.117933 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_53000.caffemodel
I0526 20:08:13.560190 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_53000.solverstate
I0526 20:08:13.722079 30701 solver.cpp:330] Iteration 53000, Testing net (#0)
I0526 20:08:16.358505 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:08:16.683271 30701 solver.cpp:397]     Test net output #0: accuracy = 0.768
I0526 20:08:16.683315 30701 solver.cpp:397]     Test net output #1: loss = 0.969789 (* 1 = 0.969789 loss)
I0526 20:08:16.960453 30701 solver.cpp:218] Iteration 53000 (3.14847 iter/s, 31.7614s/100 iters), loss = 0.157443
I0526 20:08:16.960501 30701 solver.cpp:237]     Train net output #0: loss = 0.157441 (* 1 = 0.157441 loss)
I0526 20:08:16.960516 30701 sgd_solver.cpp:105] Iteration 53000, lr = 0.00735
I0526 20:08:45.159404 30701 solver.cpp:218] Iteration 53100 (3.54632 iter/s, 28.1983s/100 iters), loss = 0.00816506
I0526 20:08:45.159600 30701 solver.cpp:237]     Train net output #0: loss = 0.00816309 (* 1 = 0.00816309 loss)
I0526 20:08:45.159611 30701 sgd_solver.cpp:105] Iteration 53100, lr = 0.007345
I0526 20:09:13.075510 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:09:13.342597 30701 solver.cpp:218] Iteration 53200 (3.54832 iter/s, 28.1824s/100 iters), loss = 0.0268625
I0526 20:09:13.342658 30701 solver.cpp:237]     Train net output #0: loss = 0.0268605 (* 1 = 0.0268605 loss)
I0526 20:09:13.342666 30701 sgd_solver.cpp:105] Iteration 53200, lr = 0.00734
I0526 20:09:41.522531 30701 solver.cpp:218] Iteration 53300 (3.54871 iter/s, 28.1792s/100 iters), loss = 0.0618734
I0526 20:09:41.522724 30701 solver.cpp:237]     Train net output #0: loss = 0.0618713 (* 1 = 0.0618713 loss)
I0526 20:09:41.522737 30701 sgd_solver.cpp:105] Iteration 53300, lr = 0.007335
I0526 20:10:09.693208 30701 solver.cpp:218] Iteration 53400 (3.54989 iter/s, 28.1699s/100 iters), loss = 0.000420898
I0526 20:10:09.693265 30701 solver.cpp:237]     Train net output #0: loss = 0.000418841 (* 1 = 0.000418841 loss)
I0526 20:10:09.693279 30701 sgd_solver.cpp:105] Iteration 53400, lr = 0.00733
I0526 20:10:37.887560 30701 solver.cpp:218] Iteration 53500 (3.5469 iter/s, 28.1937s/100 iters), loss = 0.00405056
I0526 20:10:37.887679 30701 solver.cpp:237]     Train net output #0: loss = 0.00404852 (* 1 = 0.00404852 loss)
I0526 20:10:37.887701 30701 sgd_solver.cpp:105] Iteration 53500, lr = 0.007325
I0526 20:11:06.076562 30701 solver.cpp:218] Iteration 53600 (3.54758 iter/s, 28.1882s/100 iters), loss = 0.0108701
I0526 20:11:06.076622 30701 solver.cpp:237]     Train net output #0: loss = 0.0108681 (* 1 = 0.0108681 loss)
I0526 20:11:06.076632 30701 sgd_solver.cpp:105] Iteration 53600, lr = 0.00732
I0526 20:11:34.257961 30701 solver.cpp:218] Iteration 53700 (3.54853 iter/s, 28.1807s/100 iters), loss = 0.0188222
I0526 20:11:34.258162 30701 solver.cpp:237]     Train net output #0: loss = 0.0188202 (* 1 = 0.0188202 loss)
I0526 20:11:34.258179 30701 sgd_solver.cpp:105] Iteration 53700, lr = 0.007315
I0526 20:11:59.631958 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:12:02.435639 30701 solver.cpp:218] Iteration 53800 (3.54901 iter/s, 28.1769s/100 iters), loss = 0.0481622
I0526 20:12:02.435690 30701 solver.cpp:237]     Train net output #0: loss = 0.0481602 (* 1 = 0.0481602 loss)
I0526 20:12:02.435699 30701 sgd_solver.cpp:105] Iteration 53800, lr = 0.00731
I0526 20:12:30.600312 30701 solver.cpp:218] Iteration 53900 (3.55063 iter/s, 28.164s/100 iters), loss = 0.00131037
I0526 20:12:30.600474 30701 solver.cpp:237]     Train net output #0: loss = 0.00130842 (* 1 = 0.00130842 loss)
I0526 20:12:30.600487 30701 sgd_solver.cpp:105] Iteration 53900, lr = 0.007305
I0526 20:12:58.519522 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_54000.caffemodel
I0526 20:12:58.978328 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_54000.solverstate
I0526 20:12:59.128564 30701 solver.cpp:330] Iteration 54000, Testing net (#0)
I0526 20:13:02.092108 30701 solver.cpp:397]     Test net output #0: accuracy = 0.766
I0526 20:13:02.092231 30701 solver.cpp:397]     Test net output #1: loss = 1.24303 (* 1 = 1.24303 loss)
I0526 20:13:02.370507 30701 solver.cpp:218] Iteration 54000 (3.14768 iter/s, 31.7695s/100 iters), loss = 0.0721623
I0526 20:13:02.370553 30701 solver.cpp:237]     Train net output #0: loss = 0.0721604 (* 1 = 0.0721604 loss)
I0526 20:13:02.370563 30701 sgd_solver.cpp:105] Iteration 54000, lr = 0.0073
I0526 20:13:30.577086 30701 solver.cpp:218] Iteration 54100 (3.54532 iter/s, 28.2062s/100 iters), loss = 0.0225082
I0526 20:13:30.577134 30701 solver.cpp:237]     Train net output #0: loss = 0.0225063 (* 1 = 0.0225063 loss)
I0526 20:13:30.577142 30701 sgd_solver.cpp:105] Iteration 54100, lr = 0.007295
I0526 20:13:58.786496 30701 solver.cpp:218] Iteration 54200 (3.54497 iter/s, 28.209s/100 iters), loss = 0.00974749
I0526 20:13:58.786629 30701 solver.cpp:237]     Train net output #0: loss = 0.00974551 (* 1 = 0.00974551 loss)
I0526 20:13:58.786639 30701 sgd_solver.cpp:105] Iteration 54200, lr = 0.00729
I0526 20:14:26.987347 30701 solver.cpp:218] Iteration 54300 (3.54606 iter/s, 28.2003s/100 iters), loss = 0.00188464
I0526 20:14:26.987403 30701 solver.cpp:237]     Train net output #0: loss = 0.00188264 (* 1 = 0.00188264 loss)
I0526 20:14:26.987428 30701 sgd_solver.cpp:105] Iteration 54300, lr = 0.007285
I0526 20:14:49.861238 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:14:55.196777 30701 solver.cpp:218] Iteration 54400 (3.54497 iter/s, 28.209s/100 iters), loss = 0.0482905
I0526 20:14:55.196840 30701 solver.cpp:237]     Train net output #0: loss = 0.0482885 (* 1 = 0.0482885 loss)
I0526 20:14:55.196849 30701 sgd_solver.cpp:105] Iteration 54400, lr = 0.00728
I0526 20:15:23.414757 30701 solver.cpp:218] Iteration 54500 (3.5439 iter/s, 28.2175s/100 iters), loss = 0.0203784
I0526 20:15:23.414872 30701 solver.cpp:237]     Train net output #0: loss = 0.0203764 (* 1 = 0.0203764 loss)
I0526 20:15:23.414882 30701 sgd_solver.cpp:105] Iteration 54500, lr = 0.007275
I0526 20:15:51.631664 30701 solver.cpp:218] Iteration 54600 (3.54404 iter/s, 28.2164s/100 iters), loss = 0.0113833
I0526 20:15:51.631721 30701 solver.cpp:237]     Train net output #0: loss = 0.0113814 (* 1 = 0.0113814 loss)
I0526 20:15:51.631731 30701 sgd_solver.cpp:105] Iteration 54600, lr = 0.00727
I0526 20:16:19.836256 30701 solver.cpp:218] Iteration 54700 (3.54558 iter/s, 28.2041s/100 iters), loss = 0.0645719
I0526 20:16:19.836408 30701 solver.cpp:237]     Train net output #0: loss = 0.0645699 (* 1 = 0.0645699 loss)
I0526 20:16:19.836421 30701 sgd_solver.cpp:105] Iteration 54700, lr = 0.007265
I0526 20:16:48.056309 30701 solver.cpp:218] Iteration 54800 (3.54365 iter/s, 28.2195s/100 iters), loss = 0.0184804
I0526 20:16:48.056375 30701 solver.cpp:237]     Train net output #0: loss = 0.0184784 (* 1 = 0.0184784 loss)
I0526 20:16:48.056385 30701 sgd_solver.cpp:105] Iteration 54800, lr = 0.00726
I0526 20:17:16.285843 30701 solver.cpp:218] Iteration 54900 (3.54246 iter/s, 28.229s/100 iters), loss = 0.00600667
I0526 20:17:16.285995 30701 solver.cpp:237]     Train net output #0: loss = 0.00600465 (* 1 = 0.00600465 loss)
I0526 20:17:16.286015 30701 sgd_solver.cpp:105] Iteration 54900, lr = 0.007255
I0526 20:17:36.626888 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:17:44.228646 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_55000.caffemodel
I0526 20:17:44.637575 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_55000.solverstate
I0526 20:17:44.797613 30701 solver.cpp:330] Iteration 55000, Testing net (#0)
I0526 20:17:47.761940 30701 solver.cpp:397]     Test net output #0: accuracy = 0.75
I0526 20:17:47.762085 30701 solver.cpp:397]     Test net output #1: loss = 1.25087 (* 1 = 1.25087 loss)
I0526 20:17:48.040607 30701 solver.cpp:218] Iteration 55000 (3.1492 iter/s, 31.7541s/100 iters), loss = 0.00753687
I0526 20:17:48.040657 30701 solver.cpp:237]     Train net output #0: loss = 0.00753484 (* 1 = 0.00753484 loss)
I0526 20:17:48.040671 30701 sgd_solver.cpp:105] Iteration 55000, lr = 0.00725
I0526 20:18:16.204807 30701 solver.cpp:218] Iteration 55100 (3.55067 iter/s, 28.1637s/100 iters), loss = 0.0022425
I0526 20:18:16.204869 30701 solver.cpp:237]     Train net output #0: loss = 0.00224045 (* 1 = 0.00224045 loss)
I0526 20:18:16.204877 30701 sgd_solver.cpp:105] Iteration 55100, lr = 0.007245
I0526 20:18:44.369632 30701 solver.cpp:218] Iteration 55200 (3.55059 iter/s, 28.1643s/100 iters), loss = 0.241221
I0526 20:18:44.369801 30701 solver.cpp:237]     Train net output #0: loss = 0.241219 (* 1 = 0.241219 loss)
I0526 20:18:44.369834 30701 sgd_solver.cpp:105] Iteration 55200, lr = 0.00724
I0526 20:19:12.536041 30701 solver.cpp:218] Iteration 55300 (3.55041 iter/s, 28.1658s/100 iters), loss = 0.0132197
I0526 20:19:12.536090 30701 solver.cpp:237]     Train net output #0: loss = 0.0132177 (* 1 = 0.0132177 loss)
I0526 20:19:12.536100 30701 sgd_solver.cpp:105] Iteration 55300, lr = 0.007235
I0526 20:19:40.734524 30701 solver.cpp:218] Iteration 55400 (3.54636 iter/s, 28.198s/100 iters), loss = 0.00362492
I0526 20:19:40.734645 30701 solver.cpp:237]     Train net output #0: loss = 0.00362291 (* 1 = 0.00362291 loss)
I0526 20:19:40.734657 30701 sgd_solver.cpp:105] Iteration 55400, lr = 0.00723
I0526 20:20:08.976104 30701 solver.cpp:218] Iteration 55500 (3.54096 iter/s, 28.241s/100 iters), loss = 0.00284261
I0526 20:20:08.976171 30701 solver.cpp:237]     Train net output #0: loss = 0.00284057 (* 1 = 0.00284057 loss)
I0526 20:20:08.976188 30701 sgd_solver.cpp:105] Iteration 55500, lr = 0.007225
I0526 20:20:27.050746 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:20:37.200436 30701 solver.cpp:218] Iteration 55600 (3.54311 iter/s, 28.2238s/100 iters), loss = 0.000516394
I0526 20:20:37.200505 30701 solver.cpp:237]     Train net output #0: loss = 0.000514363 (* 1 = 0.000514363 loss)
I0526 20:20:37.200516 30701 sgd_solver.cpp:105] Iteration 55600, lr = 0.00722
I0526 20:21:05.420053 30701 solver.cpp:218] Iteration 55700 (3.5437 iter/s, 28.2191s/100 iters), loss = 0.00379198
I0526 20:21:05.420253 30701 solver.cpp:237]     Train net output #0: loss = 0.00378994 (* 1 = 0.00378994 loss)
I0526 20:21:05.420266 30701 sgd_solver.cpp:105] Iteration 55700, lr = 0.007215
I0526 20:21:33.604650 30701 solver.cpp:218] Iteration 55800 (3.54812 iter/s, 28.1839s/100 iters), loss = 0.157796
I0526 20:21:33.604712 30701 solver.cpp:237]     Train net output #0: loss = 0.157794 (* 1 = 0.157794 loss)
I0526 20:21:33.604720 30701 sgd_solver.cpp:105] Iteration 55800, lr = 0.00721
I0526 20:22:01.815199 30701 solver.cpp:218] Iteration 55900 (3.54484 iter/s, 28.21s/100 iters), loss = 0.014449
I0526 20:22:01.815335 30701 solver.cpp:237]     Train net output #0: loss = 0.014447 (* 1 = 0.014447 loss)
I0526 20:22:01.815345 30701 sgd_solver.cpp:105] Iteration 55900, lr = 0.007205
I0526 20:22:29.727818 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_56000.caffemodel
I0526 20:22:30.154577 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_56000.solverstate
I0526 20:22:30.305742 30701 solver.cpp:330] Iteration 56000, Testing net (#0)
I0526 20:22:31.671962 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:22:33.267099 30701 solver.cpp:397]     Test net output #0: accuracy = 0.742
I0526 20:22:33.267287 30701 solver.cpp:397]     Test net output #1: loss = 1.23197 (* 1 = 1.23197 loss)
I0526 20:22:33.545326 30701 solver.cpp:218] Iteration 56000 (3.15165 iter/s, 31.7294s/100 iters), loss = 0.00803291
I0526 20:22:33.545387 30701 solver.cpp:237]     Train net output #0: loss = 0.00803099 (* 1 = 0.00803099 loss)
I0526 20:22:33.545397 30701 sgd_solver.cpp:105] Iteration 56000, lr = 0.0072
I0526 20:23:01.736014 30701 solver.cpp:218] Iteration 56100 (3.54734 iter/s, 28.1901s/100 iters), loss = 0.224316
I0526 20:23:01.736076 30701 solver.cpp:237]     Train net output #0: loss = 0.224314 (* 1 = 0.224314 loss)
I0526 20:23:01.736084 30701 sgd_solver.cpp:105] Iteration 56100, lr = 0.007195
I0526 20:23:17.260507 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:23:29.937257 30701 solver.cpp:218] Iteration 56200 (3.54602 iter/s, 28.2007s/100 iters), loss = 0.00262782
I0526 20:23:29.937325 30701 solver.cpp:237]     Train net output #0: loss = 0.00262588 (* 1 = 0.00262588 loss)
I0526 20:23:29.937335 30701 sgd_solver.cpp:105] Iteration 56200, lr = 0.00719
I0526 20:23:58.171463 30701 solver.cpp:218] Iteration 56300 (3.54188 iter/s, 28.2336s/100 iters), loss = 0.00382461
I0526 20:23:58.171587 30701 solver.cpp:237]     Train net output #0: loss = 0.00382265 (* 1 = 0.00382265 loss)
I0526 20:23:58.171608 30701 sgd_solver.cpp:105] Iteration 56300, lr = 0.007185
I0526 20:24:26.381834 30701 solver.cpp:218] Iteration 56400 (3.54488 iter/s, 28.2097s/100 iters), loss = 0.0652221
I0526 20:24:26.381884 30701 solver.cpp:237]     Train net output #0: loss = 0.0652201 (* 1 = 0.0652201 loss)
I0526 20:24:26.381897 30701 sgd_solver.cpp:105] Iteration 56400, lr = 0.00718
I0526 20:24:54.587252 30701 solver.cpp:218] Iteration 56500 (3.54549 iter/s, 28.2048s/100 iters), loss = 0.0357376
I0526 20:24:54.587448 30701 solver.cpp:237]     Train net output #0: loss = 0.0357356 (* 1 = 0.0357356 loss)
I0526 20:24:54.587461 30701 sgd_solver.cpp:105] Iteration 56500, lr = 0.007175
I0526 20:25:22.773573 30701 solver.cpp:218] Iteration 56600 (3.54791 iter/s, 28.1856s/100 iters), loss = 0.0133298
I0526 20:25:22.773624 30701 solver.cpp:237]     Train net output #0: loss = 0.0133279 (* 1 = 0.0133279 loss)
I0526 20:25:22.773645 30701 sgd_solver.cpp:105] Iteration 56600, lr = 0.00717
I0526 20:25:50.944613 30701 solver.cpp:218] Iteration 56700 (3.54982 iter/s, 28.1705s/100 iters), loss = 0.00776929
I0526 20:25:50.944785 30701 solver.cpp:237]     Train net output #0: loss = 0.00776734 (* 1 = 0.00776734 loss)
I0526 20:25:50.944809 30701 sgd_solver.cpp:105] Iteration 56700, lr = 0.007165
I0526 20:26:03.941089 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:26:19.139830 30701 solver.cpp:218] Iteration 56800 (3.54679 iter/s, 28.1945s/100 iters), loss = 0.483468
I0526 20:26:19.139889 30701 solver.cpp:237]     Train net output #0: loss = 0.483466 (* 1 = 0.483466 loss)
I0526 20:26:19.139899 30701 sgd_solver.cpp:105] Iteration 56800, lr = 0.00716
I0526 20:26:47.318152 30701 solver.cpp:218] Iteration 56900 (3.5489 iter/s, 28.1777s/100 iters), loss = 0.0746843
I0526 20:26:47.318279 30701 solver.cpp:237]     Train net output #0: loss = 0.0746823 (* 1 = 0.0746823 loss)
I0526 20:26:47.318291 30701 sgd_solver.cpp:105] Iteration 56900, lr = 0.007155
I0526 20:27:15.222226 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_57000.caffemodel
I0526 20:27:15.636965 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_57000.solverstate
I0526 20:27:15.788851 30701 solver.cpp:330] Iteration 57000, Testing net (#0)
I0526 20:27:18.751185 30701 solver.cpp:397]     Test net output #0: accuracy = 0.704
I0526 20:27:18.751332 30701 solver.cpp:397]     Test net output #1: loss = 1.33377 (* 1 = 1.33377 loss)
I0526 20:27:19.028934 30701 solver.cpp:218] Iteration 57000 (3.15357 iter/s, 31.7101s/100 iters), loss = 0.00294965
I0526 20:27:19.028982 30701 solver.cpp:237]     Train net output #0: loss = 0.00294772 (* 1 = 0.00294772 loss)
I0526 20:27:19.028991 30701 sgd_solver.cpp:105] Iteration 57000, lr = 0.00715
I0526 20:27:47.197520 30701 solver.cpp:218] Iteration 57100 (3.55013 iter/s, 28.168s/100 iters), loss = 0.0470429
I0526 20:27:47.197578 30701 solver.cpp:237]     Train net output #0: loss = 0.047041 (* 1 = 0.047041 loss)
I0526 20:27:47.197587 30701 sgd_solver.cpp:105] Iteration 57100, lr = 0.007145
I0526 20:28:15.369021 30701 solver.cpp:218] Iteration 57200 (3.54976 iter/s, 28.1709s/100 iters), loss = 0.0299438
I0526 20:28:15.369180 30701 solver.cpp:237]     Train net output #0: loss = 0.0299419 (* 1 = 0.0299419 loss)
I0526 20:28:15.369194 30701 sgd_solver.cpp:105] Iteration 57200, lr = 0.00714
I0526 20:28:43.526661 30701 solver.cpp:218] Iteration 57300 (3.55152 iter/s, 28.1569s/100 iters), loss = 0.0201229
I0526 20:28:43.526716 30701 solver.cpp:237]     Train net output #0: loss = 0.0201209 (* 1 = 0.0201209 loss)
I0526 20:28:43.526726 30701 sgd_solver.cpp:105] Iteration 57300, lr = 0.007135
I0526 20:28:53.971750 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:29:11.699056 30701 solver.cpp:218] Iteration 57400 (3.54965 iter/s, 28.1718s/100 iters), loss = 0.00978885
I0526 20:29:11.699123 30701 solver.cpp:237]     Train net output #0: loss = 0.00978692 (* 1 = 0.00978692 loss)
I0526 20:29:11.699132 30701 sgd_solver.cpp:105] Iteration 57400, lr = 0.00713
I0526 20:29:39.879191 30701 solver.cpp:218] Iteration 57500 (3.54868 iter/s, 28.1795s/100 iters), loss = 0.00948078
I0526 20:29:39.879330 30701 solver.cpp:237]     Train net output #0: loss = 0.00947887 (* 1 = 0.00947887 loss)
I0526 20:29:39.879346 30701 sgd_solver.cpp:105] Iteration 57500, lr = 0.007125
I0526 20:30:08.056789 30701 solver.cpp:218] Iteration 57600 (3.549 iter/s, 28.1769s/100 iters), loss = 0.000942959
I0526 20:30:08.056854 30701 solver.cpp:237]     Train net output #0: loss = 0.000941048 (* 1 = 0.000941048 loss)
I0526 20:30:08.056864 30701 sgd_solver.cpp:105] Iteration 57600, lr = 0.00712
I0526 20:30:36.239020 30701 solver.cpp:218] Iteration 57700 (3.54841 iter/s, 28.1816s/100 iters), loss = 0.04199
I0526 20:30:36.239219 30701 solver.cpp:237]     Train net output #0: loss = 0.0419881 (* 1 = 0.0419881 loss)
I0526 20:30:36.239231 30701 sgd_solver.cpp:105] Iteration 57700, lr = 0.007115
I0526 20:31:04.440441 30701 solver.cpp:218] Iteration 57800 (3.54601 iter/s, 28.2007s/100 iters), loss = 0.00738632
I0526 20:31:04.440501 30701 solver.cpp:237]     Train net output #0: loss = 0.00738442 (* 1 = 0.00738442 loss)
I0526 20:31:04.440511 30701 sgd_solver.cpp:105] Iteration 57800, lr = 0.00711
I0526 20:31:32.605680 30701 solver.cpp:218] Iteration 57900 (3.55055 iter/s, 28.1646s/100 iters), loss = 0.0240083
I0526 20:31:32.605823 30701 solver.cpp:237]     Train net output #0: loss = 0.0240064 (* 1 = 0.0240064 loss)
I0526 20:31:32.605834 30701 sgd_solver.cpp:105] Iteration 57900, lr = 0.007105
I0526 20:31:40.516806 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:32:00.524852 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_58000.caffemodel
I0526 20:32:00.924404 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_58000.solverstate
I0526 20:32:01.076563 30701 solver.cpp:330] Iteration 58000, Testing net (#0)
I0526 20:32:04.040680 30701 solver.cpp:397]     Test net output #0: accuracy = 0.742
I0526 20:32:04.040858 30701 solver.cpp:397]     Test net output #1: loss = 1.25238 (* 1 = 1.25238 loss)
I0526 20:32:04.320503 30701 solver.cpp:218] Iteration 58000 (3.15318 iter/s, 31.7141s/100 iters), loss = 0.01112
I0526 20:32:04.320562 30701 solver.cpp:237]     Train net output #0: loss = 0.0111181 (* 1 = 0.0111181 loss)
I0526 20:32:04.320570 30701 sgd_solver.cpp:105] Iteration 58000, lr = 0.0071
I0526 20:32:32.512652 30701 solver.cpp:218] Iteration 58100 (3.54717 iter/s, 28.1915s/100 iters), loss = 0.000548862
I0526 20:32:32.512712 30701 solver.cpp:237]     Train net output #0: loss = 0.000546957 (* 1 = 0.000546957 loss)
I0526 20:32:32.512720 30701 sgd_solver.cpp:105] Iteration 58100, lr = 0.007095
I0526 20:33:00.699919 30701 solver.cpp:218] Iteration 58200 (3.54778 iter/s, 28.1866s/100 iters), loss = 0.068432
I0526 20:33:00.700127 30701 solver.cpp:237]     Train net output #0: loss = 0.0684301 (* 1 = 0.0684301 loss)
I0526 20:33:00.700141 30701 sgd_solver.cpp:105] Iteration 58200, lr = 0.00709
I0526 20:33:28.912755 30701 solver.cpp:218] Iteration 58300 (3.54458 iter/s, 28.2121s/100 iters), loss = 0.0927192
I0526 20:33:28.912806 30701 solver.cpp:237]     Train net output #0: loss = 0.0927173 (* 1 = 0.0927173 loss)
I0526 20:33:28.912814 30701 sgd_solver.cpp:105] Iteration 58300, lr = 0.007085
I0526 20:33:57.130559 30701 solver.cpp:218] Iteration 58400 (3.54394 iter/s, 28.2172s/100 iters), loss = 0.0812434
I0526 20:33:57.130694 30701 solver.cpp:237]     Train net output #0: loss = 0.0812415 (* 1 = 0.0812415 loss)
I0526 20:33:57.130704 30701 sgd_solver.cpp:105] Iteration 58400, lr = 0.00708
I0526 20:34:25.318395 30701 solver.cpp:218] Iteration 58500 (3.54772 iter/s, 28.1871s/100 iters), loss = 0.00557384
I0526 20:34:25.318447 30701 solver.cpp:237]     Train net output #0: loss = 0.00557193 (* 1 = 0.00557193 loss)
I0526 20:34:25.318456 30701 sgd_solver.cpp:105] Iteration 58500, lr = 0.007075
I0526 20:34:30.695750 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:34:53.538033 30701 solver.cpp:218] Iteration 58600 (3.54371 iter/s, 28.219s/100 iters), loss = 0.0322595
I0526 20:34:53.538094 30701 solver.cpp:237]     Train net output #0: loss = 0.0322576 (* 1 = 0.0322576 loss)
I0526 20:34:53.538102 30701 sgd_solver.cpp:105] Iteration 58600, lr = 0.00707
I0526 20:35:21.770812 30701 solver.cpp:218] Iteration 58700 (3.54206 iter/s, 28.2321s/100 iters), loss = 0.00593442
I0526 20:35:21.771016 30701 solver.cpp:237]     Train net output #0: loss = 0.0059325 (* 1 = 0.0059325 loss)
I0526 20:35:21.771029 30701 sgd_solver.cpp:105] Iteration 58700, lr = 0.007065
I0526 20:35:49.965288 30701 solver.cpp:218] Iteration 58800 (3.54689 iter/s, 28.1937s/100 iters), loss = 0.00140876
I0526 20:35:49.965338 30701 solver.cpp:237]     Train net output #0: loss = 0.00140684 (* 1 = 0.00140684 loss)
I0526 20:35:49.965348 30701 sgd_solver.cpp:105] Iteration 58800, lr = 0.00706
I0526 20:36:18.132390 30701 solver.cpp:218] Iteration 58900 (3.55032 iter/s, 28.1665s/100 iters), loss = 0.00826585
I0526 20:36:18.132547 30701 solver.cpp:237]     Train net output #0: loss = 0.00826391 (* 1 = 0.00826391 loss)
I0526 20:36:18.132560 30701 sgd_solver.cpp:105] Iteration 58900, lr = 0.007055
I0526 20:36:46.009305 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_59000.caffemodel
I0526 20:36:46.412506 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_59000.solverstate
I0526 20:36:46.563283 30701 solver.cpp:330] Iteration 59000, Testing net (#0)
I0526 20:36:46.657579 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:36:49.530282 30701 solver.cpp:397]     Test net output #0: accuracy = 0.734
I0526 20:36:49.530376 30701 solver.cpp:397]     Test net output #1: loss = 1.36602 (* 1 = 1.36602 loss)
I0526 20:36:49.806999 30701 solver.cpp:218] Iteration 59000 (3.15718 iter/s, 31.6738s/100 iters), loss = 0.00400745
I0526 20:36:49.807049 30701 solver.cpp:237]     Train net output #0: loss = 0.0040055 (* 1 = 0.0040055 loss)
I0526 20:36:49.807059 30701 sgd_solver.cpp:105] Iteration 59000, lr = 0.00705
I0526 20:37:18.037475 30701 solver.cpp:218] Iteration 59100 (3.54235 iter/s, 28.2298s/100 iters), loss = 0.0657825
I0526 20:37:18.037525 30701 solver.cpp:237]     Train net output #0: loss = 0.0657806 (* 1 = 0.0657806 loss)
I0526 20:37:18.037549 30701 sgd_solver.cpp:105] Iteration 59100, lr = 0.007045
I0526 20:37:20.885968 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:37:46.275887 30701 solver.cpp:218] Iteration 59200 (3.54135 iter/s, 28.2378s/100 iters), loss = 0.00309663
I0526 20:37:46.275946 30701 solver.cpp:237]     Train net output #0: loss = 0.00309475 (* 1 = 0.00309475 loss)
I0526 20:37:46.275980 30701 sgd_solver.cpp:105] Iteration 59200, lr = 0.00704
I0526 20:38:14.520562 30701 solver.cpp:218] Iteration 59300 (3.54057 iter/s, 28.244s/100 iters), loss = 0.00191586
I0526 20:38:14.520710 30701 solver.cpp:237]     Train net output #0: loss = 0.00191397 (* 1 = 0.00191397 loss)
I0526 20:38:14.520722 30701 sgd_solver.cpp:105] Iteration 59300, lr = 0.007035
I0526 20:38:42.728972 30701 solver.cpp:218] Iteration 59400 (3.54513 iter/s, 28.2077s/100 iters), loss = 0.00354399
I0526 20:38:42.729019 30701 solver.cpp:237]     Train net output #0: loss = 0.00354207 (* 1 = 0.00354207 loss)
I0526 20:38:42.729029 30701 sgd_solver.cpp:105] Iteration 59400, lr = 0.00703
I0526 20:39:10.959794 30701 solver.cpp:218] Iteration 59500 (3.54231 iter/s, 28.2302s/100 iters), loss = 0.00302384
I0526 20:39:10.959939 30701 solver.cpp:237]     Train net output #0: loss = 0.00302191 (* 1 = 0.00302191 loss)
I0526 20:39:10.959961 30701 sgd_solver.cpp:105] Iteration 59500, lr = 0.007025
I0526 20:39:39.119465 30701 solver.cpp:218] Iteration 59600 (3.55127 iter/s, 28.159s/100 iters), loss = 0.0642089
I0526 20:39:39.119518 30701 solver.cpp:237]     Train net output #0: loss = 0.064207 (* 1 = 0.064207 loss)
I0526 20:39:39.119541 30701 sgd_solver.cpp:105] Iteration 59600, lr = 0.00702
I0526 20:40:07.303413 30701 solver.cpp:218] Iteration 59700 (3.5482 iter/s, 28.1833s/100 iters), loss = 0.123059
I0526 20:40:07.303562 30701 solver.cpp:237]     Train net output #0: loss = 0.123057 (* 1 = 0.123057 loss)
I0526 20:40:07.303575 30701 sgd_solver.cpp:105] Iteration 59700, lr = 0.007015
I0526 20:40:07.888072 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:40:35.495712 30701 solver.cpp:218] Iteration 59800 (3.54716 iter/s, 28.1916s/100 iters), loss = 0.0147323
I0526 20:40:35.495777 30701 solver.cpp:237]     Train net output #0: loss = 0.0147304 (* 1 = 0.0147304 loss)
I0526 20:40:35.495786 30701 sgd_solver.cpp:105] Iteration 59800, lr = 0.00701
I0526 20:41:03.684876 30701 solver.cpp:218] Iteration 59900 (3.54754 iter/s, 28.1885s/100 iters), loss = 0.00379125
I0526 20:41:03.685112 30701 solver.cpp:237]     Train net output #0: loss = 0.00378937 (* 1 = 0.00378937 loss)
I0526 20:41:03.685124 30701 sgd_solver.cpp:105] Iteration 59900, lr = 0.007005
I0526 20:41:31.608639 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_60000.caffemodel
I0526 20:41:32.017915 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_60000.solverstate
I0526 20:41:32.170280 30701 solver.cpp:330] Iteration 60000, Testing net (#0)
I0526 20:41:35.133244 30701 solver.cpp:397]     Test net output #0: accuracy = 0.74
I0526 20:41:35.133365 30701 solver.cpp:397]     Test net output #1: loss = 1.22135 (* 1 = 1.22135 loss)
I0526 20:41:35.411876 30701 solver.cpp:218] Iteration 60000 (3.15198 iter/s, 31.7261s/100 iters), loss = 0.0555799
I0526 20:41:35.411924 30701 solver.cpp:237]     Train net output #0: loss = 0.055578 (* 1 = 0.055578 loss)
I0526 20:41:35.411933 30701 sgd_solver.cpp:105] Iteration 60000, lr = 0.007
I0526 20:42:03.625643 30701 solver.cpp:218] Iteration 60100 (3.54445 iter/s, 28.2131s/100 iters), loss = 0.000926256
I0526 20:42:03.625710 30701 solver.cpp:237]     Train net output #0: loss = 0.00092437 (* 1 = 0.00092437 loss)
I0526 20:42:03.625735 30701 sgd_solver.cpp:105] Iteration 60100, lr = 0.006995
I0526 20:42:31.832320 30701 solver.cpp:218] Iteration 60200 (3.54534 iter/s, 28.206s/100 iters), loss = 0.148859
I0526 20:42:31.832454 30701 solver.cpp:237]     Train net output #0: loss = 0.148857 (* 1 = 0.148857 loss)
I0526 20:42:31.832468 30701 sgd_solver.cpp:105] Iteration 60200, lr = 0.00699
I0526 20:42:58.104624 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:43:00.069880 30701 solver.cpp:218] Iteration 60300 (3.54147 iter/s, 28.2368s/100 iters), loss = 0.000575906
I0526 20:43:00.069928 30701 solver.cpp:237]     Train net output #0: loss = 0.000574036 (* 1 = 0.000574036 loss)
I0526 20:43:00.069937 30701 sgd_solver.cpp:105] Iteration 60300, lr = 0.006985
I0526 20:43:28.256520 30701 solver.cpp:218] Iteration 60400 (3.54786 iter/s, 28.186s/100 iters), loss = 0.00208305
I0526 20:43:28.256729 30701 solver.cpp:237]     Train net output #0: loss = 0.00208117 (* 1 = 0.00208117 loss)
I0526 20:43:28.256741 30701 sgd_solver.cpp:105] Iteration 60400, lr = 0.00698
I0526 20:43:56.452843 30701 solver.cpp:218] Iteration 60500 (3.54666 iter/s, 28.1955s/100 iters), loss = 0.00031966
I0526 20:43:56.452906 30701 solver.cpp:237]     Train net output #0: loss = 0.000317773 (* 1 = 0.000317773 loss)
I0526 20:43:56.452916 30701 sgd_solver.cpp:105] Iteration 60500, lr = 0.006975
I0526 20:44:24.649806 30701 solver.cpp:218] Iteration 60600 (3.54656 iter/s, 28.1963s/100 iters), loss = 0.000763951
I0526 20:44:24.649929 30701 solver.cpp:237]     Train net output #0: loss = 0.00076207 (* 1 = 0.00076207 loss)
I0526 20:44:24.649950 30701 sgd_solver.cpp:105] Iteration 60600, lr = 0.00697
I0526 20:44:52.858889 30701 solver.cpp:218] Iteration 60700 (3.54505 iter/s, 28.2084s/100 iters), loss = 0.140934
I0526 20:44:52.858949 30701 solver.cpp:237]     Train net output #0: loss = 0.140932 (* 1 = 0.140932 loss)
I0526 20:44:52.858958 30701 sgd_solver.cpp:105] Iteration 60700, lr = 0.006965
I0526 20:45:21.072530 30701 solver.cpp:218] Iteration 60800 (3.54447 iter/s, 28.213s/100 iters), loss = 0.00575739
I0526 20:45:21.072650 30701 solver.cpp:237]     Train net output #0: loss = 0.00575542 (* 1 = 0.00575542 loss)
I0526 20:45:21.072662 30701 sgd_solver.cpp:105] Iteration 60800, lr = 0.00696
I0526 20:45:44.776340 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:45:49.274447 30701 solver.cpp:218] Iteration 60900 (3.54595 iter/s, 28.2012s/100 iters), loss = 0.130994
I0526 20:45:49.274505 30701 solver.cpp:237]     Train net output #0: loss = 0.130992 (* 1 = 0.130992 loss)
I0526 20:45:49.274514 30701 sgd_solver.cpp:105] Iteration 60900, lr = 0.006955
I0526 20:46:17.199028 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_61000.caffemodel
I0526 20:46:17.602634 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_61000.solverstate
I0526 20:46:17.766798 30701 solver.cpp:330] Iteration 61000, Testing net (#0)
I0526 20:46:19.548372 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:46:20.734046 30701 solver.cpp:397]     Test net output #0: accuracy = 0.716
I0526 20:46:20.734086 30701 solver.cpp:397]     Test net output #1: loss = 1.39102 (* 1 = 1.39102 loss)
I0526 20:46:21.012043 30701 solver.cpp:218] Iteration 61000 (3.15091 iter/s, 31.7369s/100 iters), loss = 0.101885
I0526 20:46:21.012094 30701 solver.cpp:237]     Train net output #0: loss = 0.101883 (* 1 = 0.101883 loss)
I0526 20:46:21.012109 30701 sgd_solver.cpp:105] Iteration 61000, lr = 0.00695
I0526 20:46:49.208310 30701 solver.cpp:218] Iteration 61100 (3.54665 iter/s, 28.1956s/100 iters), loss = 0.00869814
I0526 20:46:49.208467 30701 solver.cpp:237]     Train net output #0: loss = 0.00869607 (* 1 = 0.00869607 loss)
I0526 20:46:49.208478 30701 sgd_solver.cpp:105] Iteration 61100, lr = 0.006945
I0526 20:47:17.388604 30701 solver.cpp:218] Iteration 61200 (3.54869 iter/s, 28.1794s/100 iters), loss = 0.0165883
I0526 20:47:17.388669 30701 solver.cpp:237]     Train net output #0: loss = 0.0165862 (* 1 = 0.0165862 loss)
I0526 20:47:17.388684 30701 sgd_solver.cpp:105] Iteration 61200, lr = 0.00694
I0526 20:47:45.559123 30701 solver.cpp:218] Iteration 61300 (3.54991 iter/s, 28.1697s/100 iters), loss = 0.143189
I0526 20:47:45.559252 30701 solver.cpp:237]     Train net output #0: loss = 0.143187 (* 1 = 0.143187 loss)
I0526 20:47:45.559268 30701 sgd_solver.cpp:105] Iteration 61300, lr = 0.006935
I0526 20:48:13.731040 30701 solver.cpp:218] Iteration 61400 (3.54974 iter/s, 28.1711s/100 iters), loss = 0.0396501
I0526 20:48:13.731099 30701 solver.cpp:237]     Train net output #0: loss = 0.039648 (* 1 = 0.039648 loss)
I0526 20:48:13.731108 30701 sgd_solver.cpp:105] Iteration 61400, lr = 0.00693
I0526 20:48:34.910156 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:48:41.956888 30701 solver.cpp:218] Iteration 61500 (3.54295 iter/s, 28.225s/100 iters), loss = 0.00385932
I0526 20:48:41.956943 30701 solver.cpp:237]     Train net output #0: loss = 0.00385726 (* 1 = 0.00385726 loss)
I0526 20:48:41.956954 30701 sgd_solver.cpp:105] Iteration 61500, lr = 0.006925
I0526 20:49:10.176604 30701 solver.cpp:218] Iteration 61600 (3.54372 iter/s, 28.2189s/100 iters), loss = 0.0512721
I0526 20:49:10.176729 30701 solver.cpp:237]     Train net output #0: loss = 0.05127 (* 1 = 0.05127 loss)
I0526 20:49:10.176739 30701 sgd_solver.cpp:105] Iteration 61600, lr = 0.00692
I0526 20:49:38.407155 30701 solver.cpp:218] Iteration 61700 (3.54237 iter/s, 28.2297s/100 iters), loss = 0.0324521
I0526 20:49:38.407217 30701 solver.cpp:237]     Train net output #0: loss = 0.0324501 (* 1 = 0.0324501 loss)
I0526 20:49:38.407225 30701 sgd_solver.cpp:105] Iteration 61700, lr = 0.006915
I0526 20:50:06.641465 30701 solver.cpp:218] Iteration 61800 (3.54189 iter/s, 28.2335s/100 iters), loss = 0.00619362
I0526 20:50:06.641662 30701 solver.cpp:237]     Train net output #0: loss = 0.00619153 (* 1 = 0.00619153 loss)
I0526 20:50:06.641685 30701 sgd_solver.cpp:105] Iteration 61800, lr = 0.00691
I0526 20:50:34.855603 30701 solver.cpp:218] Iteration 61900 (3.54444 iter/s, 28.2132s/100 iters), loss = 0.00285854
I0526 20:50:34.855653 30701 solver.cpp:237]     Train net output #0: loss = 0.00285644 (* 1 = 0.00285644 loss)
I0526 20:50:34.855674 30701 sgd_solver.cpp:105] Iteration 61900, lr = 0.006905
I0526 20:51:02.800130 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_62000.caffemodel
I0526 20:51:03.182904 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_62000.solverstate
I0526 20:51:03.335773 30701 solver.cpp:330] Iteration 62000, Testing net (#0)
I0526 20:51:06.301013 30701 solver.cpp:397]     Test net output #0: accuracy = 0.708
I0526 20:51:06.301055 30701 solver.cpp:397]     Test net output #1: loss = 1.52133 (* 1 = 1.52133 loss)
I0526 20:51:06.580049 30701 solver.cpp:218] Iteration 62000 (3.15223 iter/s, 31.7236s/100 iters), loss = 0.00246171
I0526 20:51:06.580101 30701 solver.cpp:237]     Train net output #0: loss = 0.0024596 (* 1 = 0.0024596 loss)
I0526 20:51:06.580109 30701 sgd_solver.cpp:105] Iteration 62000, lr = 0.0069
I0526 20:51:25.219887 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:51:34.798322 30701 solver.cpp:218] Iteration 62100 (3.5439 iter/s, 28.2175s/100 iters), loss = 0.0514167
I0526 20:51:34.798442 30701 solver.cpp:237]     Train net output #0: loss = 0.0514145 (* 1 = 0.0514145 loss)
I0526 20:51:34.798460 30701 sgd_solver.cpp:105] Iteration 62100, lr = 0.006895
I0526 20:52:03.012414 30701 solver.cpp:218] Iteration 62200 (3.54443 iter/s, 28.2133s/100 iters), loss = 0.0245533
I0526 20:52:03.012475 30701 solver.cpp:237]     Train net output #0: loss = 0.0245512 (* 1 = 0.0245512 loss)
I0526 20:52:03.012485 30701 sgd_solver.cpp:105] Iteration 62200, lr = 0.00689
I0526 20:52:31.207934 30701 solver.cpp:218] Iteration 62300 (3.54676 iter/s, 28.1947s/100 iters), loss = 0.000415012
I0526 20:52:31.208175 30701 solver.cpp:237]     Train net output #0: loss = 0.000412913 (* 1 = 0.000412913 loss)
I0526 20:52:31.208199 30701 sgd_solver.cpp:105] Iteration 62300, lr = 0.006885
I0526 20:52:59.431707 30701 solver.cpp:218] Iteration 62400 (3.54323 iter/s, 28.2228s/100 iters), loss = 0.0234807
I0526 20:52:59.431761 30701 solver.cpp:237]     Train net output #0: loss = 0.0234786 (* 1 = 0.0234786 loss)
I0526 20:52:59.431769 30701 sgd_solver.cpp:105] Iteration 62400, lr = 0.00688
I0526 20:53:27.640038 30701 solver.cpp:218] Iteration 62500 (3.54515 iter/s, 28.2076s/100 iters), loss = 0.0462732
I0526 20:53:27.640162 30701 solver.cpp:237]     Train net output #0: loss = 0.0462711 (* 1 = 0.0462711 loss)
I0526 20:53:27.640173 30701 sgd_solver.cpp:105] Iteration 62500, lr = 0.006875
I0526 20:53:55.827318 30701 solver.cpp:218] Iteration 62600 (3.5478 iter/s, 28.1865s/100 iters), loss = 0.0496443
I0526 20:53:55.827378 30701 solver.cpp:237]     Train net output #0: loss = 0.0496422 (* 1 = 0.0496422 loss)
I0526 20:53:55.827388 30701 sgd_solver.cpp:105] Iteration 62600, lr = 0.00687
I0526 20:54:11.915845 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:54:24.020859 30701 solver.cpp:218] Iteration 62700 (3.547 iter/s, 28.1928s/100 iters), loss = 0.00838322
I0526 20:54:24.020922 30701 solver.cpp:237]     Train net output #0: loss = 0.00838113 (* 1 = 0.00838113 loss)
I0526 20:54:24.020931 30701 sgd_solver.cpp:105] Iteration 62700, lr = 0.006865
I0526 20:54:52.199517 30701 solver.cpp:218] Iteration 62800 (3.54888 iter/s, 28.1779s/100 iters), loss = 0.00309487
I0526 20:54:52.199651 30701 solver.cpp:237]     Train net output #0: loss = 0.00309279 (* 1 = 0.00309279 loss)
I0526 20:54:52.199666 30701 sgd_solver.cpp:105] Iteration 62800, lr = 0.00686
I0526 20:55:20.423382 30701 solver.cpp:218] Iteration 62900 (3.5432 iter/s, 28.2231s/100 iters), loss = 0.0146697
I0526 20:55:20.423439 30701 solver.cpp:237]     Train net output #0: loss = 0.0146676 (* 1 = 0.0146676 loss)
I0526 20:55:20.423449 30701 sgd_solver.cpp:105] Iteration 62900, lr = 0.006855
I0526 20:55:48.357048 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_63000.caffemodel
I0526 20:55:48.776371 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_63000.solverstate
I0526 20:55:48.928726 30701 solver.cpp:330] Iteration 63000, Testing net (#0)
I0526 20:55:51.888145 30701 solver.cpp:397]     Test net output #0: accuracy = 0.772
I0526 20:55:51.888190 30701 solver.cpp:397]     Test net output #1: loss = 1.23216 (* 1 = 1.23216 loss)
I0526 20:55:52.168323 30701 solver.cpp:218] Iteration 63000 (3.15019 iter/s, 31.7441s/100 iters), loss = 0.00498264
I0526 20:55:52.168388 30701 solver.cpp:237]     Train net output #0: loss = 0.00498057 (* 1 = 0.00498057 loss)
I0526 20:55:52.168398 30701 sgd_solver.cpp:105] Iteration 63000, lr = 0.00685
I0526 20:56:20.372160 30701 solver.cpp:218] Iteration 63100 (3.54571 iter/s, 28.2031s/100 iters), loss = 0.012829
I0526 20:56:20.760864 30701 solver.cpp:237]     Train net output #0: loss = 0.012827 (* 1 = 0.012827 loss)
I0526 20:56:20.760900 30701 sgd_solver.cpp:105] Iteration 63100, lr = 0.006845
I0526 20:56:48.947701 30701 solver.cpp:218] Iteration 63200 (3.54784 iter/s, 28.1862s/100 iters), loss = 0.00186011
I0526 20:56:48.947762 30701 solver.cpp:237]     Train net output #0: loss = 0.00185806 (* 1 = 0.00185806 loss)
I0526 20:56:48.947770 30701 sgd_solver.cpp:105] Iteration 63200, lr = 0.00684
I0526 20:57:02.761867 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 20:57:17.111951 30701 solver.cpp:218] Iteration 63300 (3.55069 iter/s, 28.1635s/100 iters), loss = 0.0520395
I0526 20:57:17.112016 30701 solver.cpp:237]     Train net output #0: loss = 0.0520374 (* 1 = 0.0520374 loss)
I0526 20:57:17.112030 30701 sgd_solver.cpp:105] Iteration 63300, lr = 0.006835
I0526 20:57:45.273358 30701 solver.cpp:218] Iteration 63400 (3.55105 iter/s, 28.1607s/100 iters), loss = 0.00734103
I0526 20:57:45.273524 30701 solver.cpp:237]     Train net output #0: loss = 0.00733893 (* 1 = 0.00733893 loss)
I0526 20:57:45.273537 30701 sgd_solver.cpp:105] Iteration 63400, lr = 0.00683
I0526 20:58:13.443506 30701 solver.cpp:218] Iteration 63500 (3.54996 iter/s, 28.1693s/100 iters), loss = 0.0273969
I0526 20:58:13.443562 30701 solver.cpp:237]     Train net output #0: loss = 0.0273948 (* 1 = 0.0273948 loss)
I0526 20:58:13.443578 30701 sgd_solver.cpp:105] Iteration 63500, lr = 0.006825
I0526 20:58:41.586309 30701 solver.cpp:218] Iteration 63600 (3.55339 iter/s, 28.1421s/100 iters), loss = 0.0010295
I0526 20:58:41.586463 30701 solver.cpp:237]     Train net output #0: loss = 0.00102742 (* 1 = 0.00102742 loss)
I0526 20:58:41.586477 30701 sgd_solver.cpp:105] Iteration 63600, lr = 0.00682
I0526 20:59:09.775837 30701 solver.cpp:218] Iteration 63700 (3.54752 iter/s, 28.1887s/100 iters), loss = 0.00211181
I0526 20:59:09.775890 30701 solver.cpp:237]     Train net output #0: loss = 0.00210972 (* 1 = 0.00210972 loss)
I0526 20:59:09.775913 30701 sgd_solver.cpp:105] Iteration 63700, lr = 0.006815
I0526 20:59:37.967190 30701 solver.cpp:218] Iteration 63800 (3.54728 iter/s, 28.1906s/100 iters), loss = 0.161523
I0526 20:59:37.967376 30701 solver.cpp:237]     Train net output #0: loss = 0.161521 (* 1 = 0.161521 loss)
I0526 20:59:37.967389 30701 sgd_solver.cpp:105] Iteration 63800, lr = 0.00681
I0526 20:59:49.265069 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:00:06.160401 30701 solver.cpp:218] Iteration 63900 (3.54706 iter/s, 28.1924s/100 iters), loss = 0.0517196
I0526 21:00:06.160452 30701 solver.cpp:237]     Train net output #0: loss = 0.0517176 (* 1 = 0.0517176 loss)
I0526 21:00:06.160461 30701 sgd_solver.cpp:105] Iteration 63900, lr = 0.006805
I0526 21:00:34.106581 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_64000.caffemodel
I0526 21:00:34.581439 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_64000.solverstate
I0526 21:00:34.750974 30701 solver.cpp:330] Iteration 64000, Testing net (#0)
I0526 21:00:35.230185 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:00:37.712666 30701 solver.cpp:397]     Test net output #0: accuracy = 0.76
I0526 21:00:37.712713 30701 solver.cpp:397]     Test net output #1: loss = 1.16459 (* 1 = 1.16459 loss)
I0526 21:00:37.991420 30701 solver.cpp:218] Iteration 64000 (3.14167 iter/s, 31.8302s/100 iters), loss = 0.0159072
I0526 21:00:37.991478 30701 solver.cpp:237]     Train net output #0: loss = 0.0159052 (* 1 = 0.0159052 loss)
I0526 21:00:37.991492 30701 sgd_solver.cpp:105] Iteration 64000, lr = 0.0068
I0526 21:01:06.208048 30701 solver.cpp:218] Iteration 64100 (3.5441 iter/s, 28.2159s/100 iters), loss = 0.00165563
I0526 21:01:06.208856 30701 solver.cpp:237]     Train net output #0: loss = 0.00165364 (* 1 = 0.00165364 loss)
I0526 21:01:06.208870 30701 sgd_solver.cpp:105] Iteration 64100, lr = 0.006795
I0526 21:01:34.412192 30701 solver.cpp:218] Iteration 64200 (3.54576 iter/s, 28.2027s/100 iters), loss = 0.00507494
I0526 21:01:34.412271 30701 solver.cpp:237]     Train net output #0: loss = 0.005073 (* 1 = 0.005073 loss)
I0526 21:01:34.412286 30701 sgd_solver.cpp:105] Iteration 64200, lr = 0.00679
I0526 21:02:02.621599 30701 solver.cpp:218] Iteration 64300 (3.54501 iter/s, 28.2087s/100 iters), loss = 0.00427488
I0526 21:02:02.621734 30701 solver.cpp:237]     Train net output #0: loss = 0.00427291 (* 1 = 0.00427291 loss)
I0526 21:02:02.621750 30701 sgd_solver.cpp:105] Iteration 64300, lr = 0.006785
I0526 21:02:30.808055 30701 solver.cpp:218] Iteration 64400 (3.5479 iter/s, 28.1857s/100 iters), loss = 0.000796607
I0526 21:02:30.808115 30701 solver.cpp:237]     Train net output #0: loss = 0.00079464 (* 1 = 0.00079464 loss)
I0526 21:02:30.808123 30701 sgd_solver.cpp:105] Iteration 64400, lr = 0.00678
I0526 21:02:39.573348 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:02:59.013785 30701 solver.cpp:218] Iteration 64500 (3.54547 iter/s, 28.205s/100 iters), loss = 0.00642671
I0526 21:02:59.013835 30701 solver.cpp:237]     Train net output #0: loss = 0.00642473 (* 1 = 0.00642473 loss)
I0526 21:02:59.013844 30701 sgd_solver.cpp:105] Iteration 64500, lr = 0.006775
I0526 21:03:27.254745 30701 solver.cpp:218] Iteration 64600 (3.54104 iter/s, 28.2403s/100 iters), loss = 0.0534803
I0526 21:03:27.254904 30701 solver.cpp:237]     Train net output #0: loss = 0.0534783 (* 1 = 0.0534783 loss)
I0526 21:03:27.254915 30701 sgd_solver.cpp:105] Iteration 64600, lr = 0.00677
I0526 21:03:55.415904 30701 solver.cpp:218] Iteration 64700 (3.55109 iter/s, 28.1604s/100 iters), loss = 0.0018894
I0526 21:03:55.415968 30701 solver.cpp:237]     Train net output #0: loss = 0.00188735 (* 1 = 0.00188735 loss)
I0526 21:03:55.415977 30701 sgd_solver.cpp:105] Iteration 64700, lr = 0.006765
I0526 21:04:23.582005 30701 solver.cpp:218] Iteration 64800 (3.55045 iter/s, 28.1654s/100 iters), loss = 0.0350207
I0526 21:04:23.582171 30701 solver.cpp:237]     Train net output #0: loss = 0.0350186 (* 1 = 0.0350186 loss)
I0526 21:04:23.582185 30701 sgd_solver.cpp:105] Iteration 64800, lr = 0.00676
I0526 21:04:51.779578 30701 solver.cpp:218] Iteration 64900 (3.5465 iter/s, 28.1968s/100 iters), loss = 0.0142281
I0526 21:04:51.779636 30701 solver.cpp:237]     Train net output #0: loss = 0.0142261 (* 1 = 0.0142261 loss)
I0526 21:04:51.779646 30701 sgd_solver.cpp:105] Iteration 64900, lr = 0.006755
I0526 21:05:19.689160 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_65000.caffemodel
I0526 21:05:20.115538 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_65000.solverstate
I0526 21:05:20.269361 30701 solver.cpp:330] Iteration 65000, Testing net (#0)
I0526 21:05:23.233233 30701 solver.cpp:397]     Test net output #0: accuracy = 0.726
I0526 21:05:23.233270 30701 solver.cpp:397]     Test net output #1: loss = 1.37054 (* 1 = 1.37054 loss)
I0526 21:05:23.511343 30701 solver.cpp:218] Iteration 65000 (3.15149 iter/s, 31.731s/100 iters), loss = 0.0258483
I0526 21:05:23.511391 30701 solver.cpp:237]     Train net output #0: loss = 0.0258462 (* 1 = 0.0258462 loss)
I0526 21:05:23.511400 30701 sgd_solver.cpp:105] Iteration 65000, lr = 0.00675
I0526 21:05:29.721230 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:05:51.675783 30701 solver.cpp:218] Iteration 65100 (3.55066 iter/s, 28.1638s/100 iters), loss = 0.0121592
I0526 21:05:51.675940 30701 solver.cpp:237]     Train net output #0: loss = 0.0121572 (* 1 = 0.0121572 loss)
I0526 21:05:51.675962 30701 sgd_solver.cpp:105] Iteration 65100, lr = 0.006745
I0526 21:06:19.843006 30701 solver.cpp:218] Iteration 65200 (3.55032 iter/s, 28.1664s/100 iters), loss = 0.00161555
I0526 21:06:19.843055 30701 solver.cpp:237]     Train net output #0: loss = 0.00161351 (* 1 = 0.00161351 loss)
I0526 21:06:19.843075 30701 sgd_solver.cpp:105] Iteration 65200, lr = 0.00674
I0526 21:06:48.048296 30701 solver.cpp:218] Iteration 65300 (3.54552 iter/s, 28.2046s/100 iters), loss = 0.0127324
I0526 21:06:48.048434 30701 solver.cpp:237]     Train net output #0: loss = 0.0127304 (* 1 = 0.0127304 loss)
I0526 21:06:48.048446 30701 sgd_solver.cpp:105] Iteration 65300, lr = 0.006735
I0526 21:07:16.289149 30701 solver.cpp:218] Iteration 65400 (3.54106 iter/s, 28.2401s/100 iters), loss = 0.0150459
I0526 21:07:16.289199 30701 solver.cpp:237]     Train net output #0: loss = 0.0150439 (* 1 = 0.0150439 loss)
I0526 21:07:16.289208 30701 sgd_solver.cpp:105] Iteration 65400, lr = 0.00673
I0526 21:07:44.505825 30701 solver.cpp:218] Iteration 65500 (3.54409 iter/s, 28.216s/100 iters), loss = 0.00106103
I0526 21:07:44.505973 30701 solver.cpp:237]     Train net output #0: loss = 0.00105904 (* 1 = 0.00105904 loss)
I0526 21:07:44.505986 30701 sgd_solver.cpp:105] Iteration 65500, lr = 0.006725
I0526 21:08:12.723320 30701 solver.cpp:218] Iteration 65600 (3.544 iter/s, 28.2167s/100 iters), loss = 0.00579567
I0526 21:08:12.723376 30701 solver.cpp:237]     Train net output #0: loss = 0.00579372 (* 1 = 0.00579372 loss)
I0526 21:08:12.723387 30701 sgd_solver.cpp:105] Iteration 65600, lr = 0.00672
I0526 21:08:16.411767 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:08:40.900971 30701 solver.cpp:218] Iteration 65700 (3.549 iter/s, 28.177s/100 iters), loss = 0.0114796
I0526 21:08:40.901031 30701 solver.cpp:237]     Train net output #0: loss = 0.0114776 (* 1 = 0.0114776 loss)
I0526 21:08:40.901039 30701 sgd_solver.cpp:105] Iteration 65700, lr = 0.006715
I0526 21:09:09.093264 30701 solver.cpp:218] Iteration 65800 (3.54715 iter/s, 28.1916s/100 iters), loss = 0.00246363
I0526 21:09:09.093430 30701 solver.cpp:237]     Train net output #0: loss = 0.00246169 (* 1 = 0.00246169 loss)
I0526 21:09:09.093442 30701 sgd_solver.cpp:105] Iteration 65800, lr = 0.00671
I0526 21:09:37.264391 30701 solver.cpp:218] Iteration 65900 (3.54983 iter/s, 28.1703s/100 iters), loss = 0.00174981
I0526 21:09:37.264451 30701 solver.cpp:237]     Train net output #0: loss = 0.0017479 (* 1 = 0.0017479 loss)
I0526 21:09:37.264461 30701 sgd_solver.cpp:105] Iteration 65900, lr = 0.006705
I0526 21:10:05.152727 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_66000.caffemodel
I0526 21:10:05.552824 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_66000.solverstate
I0526 21:10:05.705096 30701 solver.cpp:330] Iteration 66000, Testing net (#0)
I0526 21:10:07.881826 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:10:08.681828 30701 solver.cpp:397]     Test net output #0: accuracy = 0.772
I0526 21:10:08.681875 30701 solver.cpp:397]     Test net output #1: loss = 1.00687 (* 1 = 1.00687 loss)
I0526 21:10:08.960871 30701 solver.cpp:218] Iteration 66000 (3.155 iter/s, 31.6957s/100 iters), loss = 0.00188221
I0526 21:10:08.960932 30701 solver.cpp:237]     Train net output #0: loss = 0.00188031 (* 1 = 0.00188031 loss)
I0526 21:10:08.960942 30701 sgd_solver.cpp:105] Iteration 66000, lr = 0.0067
I0526 21:10:37.197512 30701 solver.cpp:218] Iteration 66100 (3.54158 iter/s, 28.236s/100 iters), loss = 0.00873555
I0526 21:10:37.197645 30701 solver.cpp:237]     Train net output #0: loss = 0.00873357 (* 1 = 0.00873357 loss)
I0526 21:10:37.197660 30701 sgd_solver.cpp:105] Iteration 66100, lr = 0.006695
I0526 21:11:05.419101 30701 solver.cpp:218] Iteration 66200 (3.54348 iter/s, 28.2208s/100 iters), loss = 0.011664
I0526 21:11:05.419153 30701 solver.cpp:237]     Train net output #0: loss = 0.0116621 (* 1 = 0.0116621 loss)
I0526 21:11:05.419162 30701 sgd_solver.cpp:105] Iteration 66200, lr = 0.00669
I0526 21:11:06.573442 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:11:33.654597 30701 solver.cpp:218] Iteration 66300 (3.54173 iter/s, 28.2348s/100 iters), loss = 0.0714069
I0526 21:11:33.654759 30701 solver.cpp:237]     Train net output #0: loss = 0.071405 (* 1 = 0.071405 loss)
I0526 21:11:33.654773 30701 sgd_solver.cpp:105] Iteration 66300, lr = 0.006685
I0526 21:12:01.874213 30701 solver.cpp:218] Iteration 66400 (3.54373 iter/s, 28.2188s/100 iters), loss = 0.00296039
I0526 21:12:01.874263 30701 solver.cpp:237]     Train net output #0: loss = 0.00295845 (* 1 = 0.00295845 loss)
I0526 21:12:01.874281 30701 sgd_solver.cpp:105] Iteration 66400, lr = 0.00668
I0526 21:12:30.086130 30701 solver.cpp:218] Iteration 66500 (3.54468 iter/s, 28.2113s/100 iters), loss = 0.00165667
I0526 21:12:30.086307 30701 solver.cpp:237]     Train net output #0: loss = 0.00165476 (* 1 = 0.00165476 loss)
I0526 21:12:30.086318 30701 sgd_solver.cpp:105] Iteration 66500, lr = 0.006675
I0526 21:12:58.206789 30701 solver.cpp:218] Iteration 66600 (3.5562 iter/s, 28.1199s/100 iters), loss = 0.00988872
I0526 21:12:58.206835 30701 solver.cpp:237]     Train net output #0: loss = 0.00988677 (* 1 = 0.00988677 loss)
I0526 21:12:58.206842 30701 sgd_solver.cpp:105] Iteration 66600, lr = 0.00667
I0526 21:13:26.284343 30701 solver.cpp:218] Iteration 66700 (3.56165 iter/s, 28.0769s/100 iters), loss = 0.163716
I0526 21:13:26.284505 30701 solver.cpp:237]     Train net output #0: loss = 0.163714 (* 1 = 0.163714 loss)
I0526 21:13:26.284518 30701 sgd_solver.cpp:105] Iteration 66700, lr = 0.006665
I0526 21:13:52.973289 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:13:54.360150 30701 solver.cpp:218] Iteration 66800 (3.56188 iter/s, 28.075s/100 iters), loss = 0.02383
I0526 21:13:54.360193 30701 solver.cpp:237]     Train net output #0: loss = 0.023828 (* 1 = 0.023828 loss)
I0526 21:13:54.360201 30701 sgd_solver.cpp:105] Iteration 66800, lr = 0.00666
I0526 21:14:22.437178 30701 solver.cpp:218] Iteration 66900 (3.56171 iter/s, 28.0764s/100 iters), loss = 0.00259801
I0526 21:14:22.437330 30701 solver.cpp:237]     Train net output #0: loss = 0.00259608 (* 1 = 0.00259608 loss)
I0526 21:14:22.437341 30701 sgd_solver.cpp:105] Iteration 66900, lr = 0.006655
I0526 21:14:50.238207 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_67000.caffemodel
I0526 21:14:50.658573 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_67000.solverstate
I0526 21:14:50.809243 30701 solver.cpp:330] Iteration 67000, Testing net (#0)
I0526 21:14:53.769786 30701 solver.cpp:397]     Test net output #0: accuracy = 0.772
I0526 21:14:53.769896 30701 solver.cpp:397]     Test net output #1: loss = 1.01441 (* 1 = 1.01441 loss)
I0526 21:14:54.047123 30701 solver.cpp:218] Iteration 67000 (3.16364 iter/s, 31.6091s/100 iters), loss = 0.00324844
I0526 21:14:54.047180 30701 solver.cpp:237]     Train net output #0: loss = 0.00324652 (* 1 = 0.00324652 loss)
I0526 21:14:54.047190 30701 sgd_solver.cpp:105] Iteration 67000, lr = 0.00665
I0526 21:15:22.193812 30701 solver.cpp:218] Iteration 67100 (3.5529 iter/s, 28.146s/100 iters), loss = 0.00269456
I0526 21:15:22.193869 30701 solver.cpp:237]     Train net output #0: loss = 0.00269264 (* 1 = 0.00269264 loss)
I0526 21:15:22.193877 30701 sgd_solver.cpp:105] Iteration 67100, lr = 0.006645
I0526 21:15:50.362751 30701 solver.cpp:218] Iteration 67200 (3.55009 iter/s, 28.1683s/100 iters), loss = 0.0101737
I0526 21:15:50.362939 30701 solver.cpp:237]     Train net output #0: loss = 0.0101718 (* 1 = 0.0101718 loss)
I0526 21:15:50.362963 30701 sgd_solver.cpp:105] Iteration 67200, lr = 0.00664
I0526 21:16:18.492497 30701 solver.cpp:218] Iteration 67300 (3.55506 iter/s, 28.129s/100 iters), loss = 0.0164179
I0526 21:16:18.492554 30701 solver.cpp:237]     Train net output #0: loss = 0.0164159 (* 1 = 0.0164159 loss)
I0526 21:16:18.492563 30701 sgd_solver.cpp:105] Iteration 67300, lr = 0.006635
I0526 21:16:42.967682 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:16:46.613746 30701 solver.cpp:218] Iteration 67400 (3.55611 iter/s, 28.1206s/100 iters), loss = 0.00134134
I0526 21:16:46.613807 30701 solver.cpp:237]     Train net output #0: loss = 0.00133938 (* 1 = 0.00133938 loss)
I0526 21:16:46.613816 30701 sgd_solver.cpp:105] Iteration 67400, lr = 0.00663
I0526 21:17:14.748500 30701 solver.cpp:218] Iteration 67500 (3.55441 iter/s, 28.1341s/100 iters), loss = 0.00332871
I0526 21:17:14.748664 30701 solver.cpp:237]     Train net output #0: loss = 0.00332675 (* 1 = 0.00332675 loss)
I0526 21:17:14.748677 30701 sgd_solver.cpp:105] Iteration 67500, lr = 0.006625
I0526 21:17:42.877796 30701 solver.cpp:218] Iteration 67600 (3.55511 iter/s, 28.1285s/100 iters), loss = 0.00272501
I0526 21:17:42.877840 30701 solver.cpp:237]     Train net output #0: loss = 0.00272303 (* 1 = 0.00272303 loss)
I0526 21:17:42.877848 30701 sgd_solver.cpp:105] Iteration 67600, lr = 0.00662
I0526 21:18:10.960731 30701 solver.cpp:218] Iteration 67700 (3.56096 iter/s, 28.0823s/100 iters), loss = 0.00134731
I0526 21:18:10.960876 30701 solver.cpp:237]     Train net output #0: loss = 0.00134535 (* 1 = 0.00134535 loss)
I0526 21:18:10.960888 30701 sgd_solver.cpp:105] Iteration 67700, lr = 0.006615
I0526 21:18:39.035620 30701 solver.cpp:218] Iteration 67800 (3.562 iter/s, 28.0742s/100 iters), loss = 0.00470606
I0526 21:18:39.035665 30701 solver.cpp:237]     Train net output #0: loss = 0.0047041 (* 1 = 0.0047041 loss)
I0526 21:18:39.035675 30701 sgd_solver.cpp:105] Iteration 67800, lr = 0.00661
I0526 21:19:07.101716 30701 solver.cpp:218] Iteration 67900 (3.5631 iter/s, 28.0654s/100 iters), loss = 0.0211334
I0526 21:19:07.101924 30701 solver.cpp:237]     Train net output #0: loss = 0.0211314 (* 1 = 0.0211314 loss)
I0526 21:19:07.101935 30701 sgd_solver.cpp:105] Iteration 67900, lr = 0.006605
I0526 21:19:29.000072 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:19:34.878696 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_68000.caffemodel
I0526 21:19:35.316685 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_68000.solverstate
I0526 21:19:35.466368 30701 solver.cpp:330] Iteration 68000, Testing net (#0)
I0526 21:19:38.423099 30701 solver.cpp:397]     Test net output #0: accuracy = 0.78
I0526 21:19:38.423285 30701 solver.cpp:397]     Test net output #1: loss = 1.04991 (* 1 = 1.04991 loss)
I0526 21:19:38.701597 30701 solver.cpp:218] Iteration 68000 (3.16465 iter/s, 31.599s/100 iters), loss = 0.000855636
I0526 21:19:38.701652 30701 solver.cpp:237]     Train net output #0: loss = 0.000853722 (* 1 = 0.000853722 loss)
I0526 21:19:38.701675 30701 sgd_solver.cpp:105] Iteration 68000, lr = 0.0066
I0526 21:20:06.859211 30701 solver.cpp:218] Iteration 68100 (3.55152 iter/s, 28.157s/100 iters), loss = 0.00603703
I0526 21:20:06.859266 30701 solver.cpp:237]     Train net output #0: loss = 0.00603511 (* 1 = 0.00603511 loss)
I0526 21:20:06.859278 30701 sgd_solver.cpp:105] Iteration 68100, lr = 0.006595
I0526 21:20:34.978600 30701 solver.cpp:218] Iteration 68200 (3.55635 iter/s, 28.1187s/100 iters), loss = 0.00917772
I0526 21:20:34.978828 30701 solver.cpp:237]     Train net output #0: loss = 0.0091758 (* 1 = 0.0091758 loss)
I0526 21:20:34.978857 30701 sgd_solver.cpp:105] Iteration 68200, lr = 0.00659
I0526 21:21:03.096552 30701 solver.cpp:218] Iteration 68300 (3.55655 iter/s, 28.1171s/100 iters), loss = 0.0120388
I0526 21:21:03.096596 30701 solver.cpp:237]     Train net output #0: loss = 0.0120369 (* 1 = 0.0120369 loss)
I0526 21:21:03.096604 30701 sgd_solver.cpp:105] Iteration 68300, lr = 0.006585
I0526 21:21:31.191234 30701 solver.cpp:218] Iteration 68400 (3.55945 iter/s, 28.0942s/100 iters), loss = 0.0121465
I0526 21:21:31.191393 30701 solver.cpp:237]     Train net output #0: loss = 0.0121445 (* 1 = 0.0121445 loss)
I0526 21:21:31.191404 30701 sgd_solver.cpp:105] Iteration 68400, lr = 0.00658
I0526 21:21:59.324617 30701 solver.cpp:218] Iteration 68500 (3.55457 iter/s, 28.1328s/100 iters), loss = 0.000164623
I0526 21:21:59.324673 30701 solver.cpp:237]     Train net output #0: loss = 0.0001627 (* 1 = 0.0001627 loss)
I0526 21:21:59.324683 30701 sgd_solver.cpp:105] Iteration 68500, lr = 0.006575
I0526 21:22:18.776362 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:22:27.486929 30701 solver.cpp:218] Iteration 68600 (3.5509 iter/s, 28.1618s/100 iters), loss = 0.00279393
I0526 21:22:27.486974 30701 solver.cpp:237]     Train net output #0: loss = 0.002792 (* 1 = 0.002792 loss)
I0526 21:22:27.486982 30701 sgd_solver.cpp:105] Iteration 68600, lr = 0.00657
I0526 21:22:55.635885 30701 solver.cpp:218] Iteration 68700 (3.55259 iter/s, 28.1485s/100 iters), loss = 0.0023193
I0526 21:22:55.635977 30701 solver.cpp:237]     Train net output #0: loss = 0.00231737 (* 1 = 0.00231737 loss)
I0526 21:22:55.635987 30701 sgd_solver.cpp:105] Iteration 68700, lr = 0.006565
I0526 21:23:23.746186 30701 solver.cpp:218] Iteration 68800 (3.55748 iter/s, 28.1098s/100 iters), loss = 0.00203474
I0526 21:23:23.746234 30701 solver.cpp:237]     Train net output #0: loss = 0.0020328 (* 1 = 0.0020328 loss)
I0526 21:23:23.746243 30701 sgd_solver.cpp:105] Iteration 68800, lr = 0.00656
I0526 21:23:51.839845 30701 solver.cpp:218] Iteration 68900 (3.55958 iter/s, 28.0932s/100 iters), loss = 0.0010668
I0526 21:23:51.840006 30701 solver.cpp:237]     Train net output #0: loss = 0.00106486 (* 1 = 0.00106486 loss)
I0526 21:23:51.840018 30701 sgd_solver.cpp:105] Iteration 68900, lr = 0.006555
I0526 21:24:19.662580 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_69000.caffemodel
I0526 21:24:19.985944 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_69000.solverstate
I0526 21:24:20.137536 30701 solver.cpp:330] Iteration 69000, Testing net (#0)
I0526 21:24:21.029289 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:24:23.094372 30701 solver.cpp:397]     Test net output #0: accuracy = 0.774
I0526 21:24:23.094498 30701 solver.cpp:397]     Test net output #1: loss = 1.19133 (* 1 = 1.19133 loss)
I0526 21:24:23.371804 30701 solver.cpp:218] Iteration 69000 (3.17145 iter/s, 31.5313s/100 iters), loss = 0.144186
I0526 21:24:23.371848 30701 solver.cpp:237]     Train net output #0: loss = 0.144184 (* 1 = 0.144184 loss)
I0526 21:24:23.371868 30701 sgd_solver.cpp:105] Iteration 69000, lr = 0.00655
I0526 21:24:51.516496 30701 solver.cpp:218] Iteration 69100 (3.55313 iter/s, 28.1442s/100 iters), loss = 0.00324847
I0526 21:24:51.516552 30701 solver.cpp:237]     Train net output #0: loss = 0.00324663 (* 1 = 0.00324663 loss)
I0526 21:24:51.516561 30701 sgd_solver.cpp:105] Iteration 69100, lr = 0.006545
I0526 21:25:08.387001 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:25:19.603778 30701 solver.cpp:218] Iteration 69200 (3.5604 iter/s, 28.0868s/100 iters), loss = 0.000803706
I0526 21:25:19.603840 30701 solver.cpp:237]     Train net output #0: loss = 0.00080186 (* 1 = 0.00080186 loss)
I0526 21:25:19.603852 30701 sgd_solver.cpp:105] Iteration 69200, lr = 0.00654
I0526 21:25:47.691905 30701 solver.cpp:218] Iteration 69300 (3.56029 iter/s, 28.0876s/100 iters), loss = 0.000432723
I0526 21:25:47.692064 30701 solver.cpp:237]     Train net output #0: loss = 0.00043086 (* 1 = 0.00043086 loss)
I0526 21:25:47.692075 30701 sgd_solver.cpp:105] Iteration 69300, lr = 0.006535
I0526 21:26:15.792253 30701 solver.cpp:218] Iteration 69400 (3.55875 iter/s, 28.0997s/100 iters), loss = 0.00149547
I0526 21:26:15.792301 30701 solver.cpp:237]     Train net output #0: loss = 0.00149362 (* 1 = 0.00149362 loss)
I0526 21:26:15.792321 30701 sgd_solver.cpp:105] Iteration 69400, lr = 0.00653
I0526 21:26:43.883114 30701 solver.cpp:218] Iteration 69500 (3.55994 iter/s, 28.0903s/100 iters), loss = 0.104485
I0526 21:26:43.883302 30701 solver.cpp:237]     Train net output #0: loss = 0.104483 (* 1 = 0.104483 loss)
I0526 21:26:43.883316 30701 sgd_solver.cpp:105] Iteration 69500, lr = 0.006525
I0526 21:27:12.036185 30701 solver.cpp:218] Iteration 69600 (3.55209 iter/s, 28.1524s/100 iters), loss = 0.0103303
I0526 21:27:12.036233 30701 solver.cpp:237]     Train net output #0: loss = 0.0103284 (* 1 = 0.0103284 loss)
I0526 21:27:12.036257 30701 sgd_solver.cpp:105] Iteration 69600, lr = 0.00652
I0526 21:27:40.186209 30701 solver.cpp:218] Iteration 69700 (3.55246 iter/s, 28.1495s/100 iters), loss = 0.0528597
I0526 21:27:40.186367 30701 solver.cpp:237]     Train net output #0: loss = 0.0528578 (* 1 = 0.0528578 loss)
I0526 21:27:40.186379 30701 sgd_solver.cpp:105] Iteration 69700, lr = 0.006515
I0526 21:27:54.568691 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:28:08.351567 30701 solver.cpp:218] Iteration 69800 (3.55054 iter/s, 28.1647s/100 iters), loss = 0.00306338
I0526 21:28:08.351624 30701 solver.cpp:237]     Train net output #0: loss = 0.00306154 (* 1 = 0.00306154 loss)
I0526 21:28:08.351634 30701 sgd_solver.cpp:105] Iteration 69800, lr = 0.00651
I0526 21:28:36.495295 30701 solver.cpp:218] Iteration 69900 (3.55326 iter/s, 28.1432s/100 iters), loss = 0.003319
I0526 21:28:36.495448 30701 solver.cpp:237]     Train net output #0: loss = 0.00331716 (* 1 = 0.00331716 loss)
I0526 21:28:36.495461 30701 sgd_solver.cpp:105] Iteration 69900, lr = 0.006505
I0526 21:29:04.343489 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_70000.caffemodel
I0526 21:29:04.679597 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_70000.solverstate
I0526 21:29:04.829183 30701 solver.cpp:330] Iteration 70000, Testing net (#0)
I0526 21:29:07.788669 30701 solver.cpp:397]     Test net output #0: accuracy = 0.774
I0526 21:29:07.788825 30701 solver.cpp:397]     Test net output #1: loss = 1.25309 (* 1 = 1.25309 loss)
I0526 21:29:08.065544 30701 solver.cpp:218] Iteration 70000 (3.16761 iter/s, 31.5695s/100 iters), loss = 0.00291272
I0526 21:29:08.065587 30701 solver.cpp:237]     Train net output #0: loss = 0.00291088 (* 1 = 0.00291088 loss)
I0526 21:29:08.065596 30701 sgd_solver.cpp:105] Iteration 70000, lr = 0.0065
I0526 21:29:36.187203 30701 solver.cpp:218] Iteration 70100 (3.55605 iter/s, 28.1211s/100 iters), loss = 0.00568816
I0526 21:29:36.187258 30701 solver.cpp:237]     Train net output #0: loss = 0.00568633 (* 1 = 0.00568633 loss)
I0526 21:29:36.187281 30701 sgd_solver.cpp:105] Iteration 70100, lr = 0.006495
I0526 21:30:04.301038 30701 solver.cpp:218] Iteration 70200 (3.55704 iter/s, 28.1133s/100 iters), loss = 0.0104313
I0526 21:30:04.301234 30701 solver.cpp:237]     Train net output #0: loss = 0.0104295 (* 1 = 0.0104295 loss)
I0526 21:30:04.301245 30701 sgd_solver.cpp:105] Iteration 70200, lr = 0.00649
I0526 21:30:32.410960 30701 solver.cpp:218] Iteration 70300 (3.55755 iter/s, 28.1092s/100 iters), loss = 0.00799225
I0526 21:30:32.411005 30701 solver.cpp:237]     Train net output #0: loss = 0.00799039 (* 1 = 0.00799039 loss)
I0526 21:30:32.411015 30701 sgd_solver.cpp:105] Iteration 70300, lr = 0.006485
I0526 21:30:44.233695 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:31:00.528409 30701 solver.cpp:218] Iteration 70400 (3.55658 iter/s, 28.1169s/100 iters), loss = 0.0048542
I0526 21:31:00.528458 30701 solver.cpp:237]     Train net output #0: loss = 0.00485232 (* 1 = 0.00485232 loss)
I0526 21:31:00.528468 30701 sgd_solver.cpp:105] Iteration 70400, lr = 0.00648
I0526 21:31:28.633383 30701 solver.cpp:218] Iteration 70500 (3.55816 iter/s, 28.1044s/100 iters), loss = 0.0018468
I0526 21:31:28.633600 30701 solver.cpp:237]     Train net output #0: loss = 0.00184493 (* 1 = 0.00184493 loss)
I0526 21:31:28.633612 30701 sgd_solver.cpp:105] Iteration 70500, lr = 0.006475
I0526 21:31:56.731389 30701 solver.cpp:218] Iteration 70600 (3.55906 iter/s, 28.0973s/100 iters), loss = 0.00908782
I0526 21:31:56.731436 30701 solver.cpp:237]     Train net output #0: loss = 0.00908594 (* 1 = 0.00908594 loss)
I0526 21:31:56.731446 30701 sgd_solver.cpp:105] Iteration 70600, lr = 0.00647
I0526 21:32:24.832276 30701 solver.cpp:218] Iteration 70700 (3.55868 iter/s, 28.1003s/100 iters), loss = 0.00492472
I0526 21:32:24.832468 30701 solver.cpp:237]     Train net output #0: loss = 0.00492284 (* 1 = 0.00492284 loss)
I0526 21:32:24.832492 30701 sgd_solver.cpp:105] Iteration 70700, lr = 0.006465
I0526 21:32:52.925288 30701 solver.cpp:218] Iteration 70800 (3.55969 iter/s, 28.0923s/100 iters), loss = 0.0107452
I0526 21:32:52.925333 30701 solver.cpp:237]     Train net output #0: loss = 0.0107433 (* 1 = 0.0107433 loss)
I0526 21:32:52.925341 30701 sgd_solver.cpp:105] Iteration 70800, lr = 0.00646
I0526 21:33:21.025573 30701 solver.cpp:218] Iteration 70900 (3.55875 iter/s, 28.0997s/100 iters), loss = 0.000392538
I0526 21:33:21.025759 30701 solver.cpp:237]     Train net output #0: loss = 0.000390624 (* 1 = 0.000390624 loss)
I0526 21:33:21.025799 30701 sgd_solver.cpp:105] Iteration 70900, lr = 0.006455
I0526 21:33:30.317333 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:33:48.865315 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_71000.caffemodel
I0526 21:33:49.192255 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_71000.solverstate
I0526 21:33:49.342125 30701 solver.cpp:330] Iteration 71000, Testing net (#0)
I0526 21:33:51.915797 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:33:52.299810 30701 solver.cpp:397]     Test net output #0: accuracy = 0.8
I0526 21:33:52.299861 30701 solver.cpp:397]     Test net output #1: loss = 0.929585 (* 1 = 0.929585 loss)
I0526 21:33:52.579546 30701 solver.cpp:218] Iteration 71000 (3.16925 iter/s, 31.5532s/100 iters), loss = 0.00214818
I0526 21:33:52.579594 30701 solver.cpp:237]     Train net output #0: loss = 0.00214625 (* 1 = 0.00214625 loss)
I0526 21:33:52.579615 30701 sgd_solver.cpp:105] Iteration 71000, lr = 0.00645
I0526 21:34:20.706209 30701 solver.cpp:218] Iteration 71100 (3.55542 iter/s, 28.1261s/100 iters), loss = 0.00135957
I0526 21:34:20.706255 30701 solver.cpp:237]     Train net output #0: loss = 0.00135763 (* 1 = 0.00135763 loss)
I0526 21:34:20.706264 30701 sgd_solver.cpp:105] Iteration 71100, lr = 0.006445
I0526 21:34:48.839298 30701 solver.cpp:218] Iteration 71200 (3.55461 iter/s, 28.1325s/100 iters), loss = 0.018661
I0526 21:34:48.839488 30701 solver.cpp:237]     Train net output #0: loss = 0.0186591 (* 1 = 0.0186591 loss)
I0526 21:34:48.839510 30701 sgd_solver.cpp:105] Iteration 71200, lr = 0.00644
I0526 21:35:16.962927 30701 solver.cpp:218] Iteration 71300 (3.55582 iter/s, 28.1229s/100 iters), loss = 0.000755399
I0526 21:35:16.962971 30701 solver.cpp:237]     Train net output #0: loss = 0.00075348 (* 1 = 0.00075348 loss)
I0526 21:35:16.962980 30701 sgd_solver.cpp:105] Iteration 71300, lr = 0.006435
I0526 21:35:45.067816 30701 solver.cpp:218] Iteration 71400 (3.55817 iter/s, 28.1043s/100 iters), loss = 0.000335276
I0526 21:35:45.068068 30701 solver.cpp:237]     Train net output #0: loss = 0.000333353 (* 1 = 0.000333353 loss)
I0526 21:35:45.068084 30701 sgd_solver.cpp:105] Iteration 71400, lr = 0.00643
I0526 21:36:13.176384 30701 solver.cpp:218] Iteration 71500 (3.55773 iter/s, 28.1078s/100 iters), loss = 0.00167771
I0526 21:36:13.176431 30701 solver.cpp:237]     Train net output #0: loss = 0.00167579 (* 1 = 0.00167579 loss)
I0526 21:36:13.176440 30701 sgd_solver.cpp:105] Iteration 71500, lr = 0.006425
I0526 21:36:20.225198 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:36:41.305687 30701 solver.cpp:218] Iteration 71600 (3.55509 iter/s, 28.1287s/100 iters), loss = 0.00523245
I0526 21:36:41.305732 30701 solver.cpp:237]     Train net output #0: loss = 0.00523055 (* 1 = 0.00523055 loss)
I0526 21:36:41.305740 30701 sgd_solver.cpp:105] Iteration 71600, lr = 0.00642
I0526 21:37:09.422284 30701 solver.cpp:218] Iteration 71700 (3.55669 iter/s, 28.116s/100 iters), loss = 0.00871389
I0526 21:37:09.422451 30701 solver.cpp:237]     Train net output #0: loss = 0.008712 (* 1 = 0.008712 loss)
I0526 21:37:09.422463 30701 sgd_solver.cpp:105] Iteration 71700, lr = 0.006415
I0526 21:37:37.509696 30701 solver.cpp:218] Iteration 71800 (3.5604 iter/s, 28.0867s/100 iters), loss = 0.00172254
I0526 21:37:37.509739 30701 solver.cpp:237]     Train net output #0: loss = 0.00172067 (* 1 = 0.00172067 loss)
I0526 21:37:37.509748 30701 sgd_solver.cpp:105] Iteration 71800, lr = 0.00641
I0526 21:38:05.607885 30701 solver.cpp:218] Iteration 71900 (3.55902 iter/s, 28.0976s/100 iters), loss = 0.00181828
I0526 21:38:05.608064 30701 solver.cpp:237]     Train net output #0: loss = 0.00181639 (* 1 = 0.00181639 loss)
I0526 21:38:05.608077 30701 sgd_solver.cpp:105] Iteration 71900, lr = 0.006405
I0526 21:38:33.444123 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_72000.caffemodel
I0526 21:38:33.757241 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_72000.solverstate
I0526 21:38:33.907519 30701 solver.cpp:330] Iteration 72000, Testing net (#0)
I0526 21:38:36.868034 30701 solver.cpp:397]     Test net output #0: accuracy = 0.784
I0526 21:38:36.868217 30701 solver.cpp:397]     Test net output #1: loss = 1.241 (* 1 = 1.241 loss)
I0526 21:38:37.145540 30701 solver.cpp:218] Iteration 72000 (3.17089 iter/s, 31.5369s/100 iters), loss = 0.00221761
I0526 21:38:37.145583 30701 solver.cpp:237]     Train net output #0: loss = 0.00221574 (* 1 = 0.00221574 loss)
I0526 21:38:37.145591 30701 sgd_solver.cpp:105] Iteration 72000, lr = 0.0064
I0526 21:39:05.220535 30701 solver.cpp:218] Iteration 72100 (3.56196 iter/s, 28.0744s/100 iters), loss = 0.0125649
I0526 21:39:05.220582 30701 solver.cpp:237]     Train net output #0: loss = 0.0125631 (* 1 = 0.0125631 loss)
I0526 21:39:05.220589 30701 sgd_solver.cpp:105] Iteration 72100, lr = 0.006395
I0526 21:39:09.733402 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:39:33.299702 30701 solver.cpp:218] Iteration 72200 (3.56143 iter/s, 28.0786s/100 iters), loss = 0.000223156
I0526 21:39:33.299748 30701 solver.cpp:237]     Train net output #0: loss = 0.000221264 (* 1 = 0.000221264 loss)
I0526 21:39:33.299768 30701 sgd_solver.cpp:105] Iteration 72200, lr = 0.00639
I0526 21:40:01.386229 30701 solver.cpp:218] Iteration 72300 (3.5605 iter/s, 28.0859s/100 iters), loss = 0.0138747
I0526 21:40:01.386394 30701 solver.cpp:237]     Train net output #0: loss = 0.0138728 (* 1 = 0.0138728 loss)
I0526 21:40:01.386404 30701 sgd_solver.cpp:105] Iteration 72300, lr = 0.006385
I0526 21:40:29.471673 30701 solver.cpp:218] Iteration 72400 (3.56065 iter/s, 28.0847s/100 iters), loss = 0.0124087
I0526 21:40:29.471716 30701 solver.cpp:237]     Train net output #0: loss = 0.0124069 (* 1 = 0.0124069 loss)
I0526 21:40:29.471725 30701 sgd_solver.cpp:105] Iteration 72400, lr = 0.00638
I0526 21:40:57.564586 30701 solver.cpp:218] Iteration 72500 (3.55969 iter/s, 28.0923s/100 iters), loss = 0.00195232
I0526 21:40:57.564777 30701 solver.cpp:237]     Train net output #0: loss = 0.00195042 (* 1 = 0.00195042 loss)
I0526 21:40:57.564790 30701 sgd_solver.cpp:105] Iteration 72500, lr = 0.006375
I0526 21:41:25.647627 30701 solver.cpp:218] Iteration 72600 (3.56096 iter/s, 28.0823s/100 iters), loss = 0.0081778
I0526 21:41:25.647675 30701 solver.cpp:237]     Train net output #0: loss = 0.0081759 (* 1 = 0.0081759 loss)
I0526 21:41:25.647685 30701 sgd_solver.cpp:105] Iteration 72600, lr = 0.00637
I0526 21:41:53.733599 30701 solver.cpp:218] Iteration 72700 (3.56057 iter/s, 28.0854s/100 iters), loss = 0.0065105
I0526 21:41:53.733759 30701 solver.cpp:237]     Train net output #0: loss = 0.00650859 (* 1 = 0.00650859 loss)
I0526 21:41:53.733773 30701 sgd_solver.cpp:105] Iteration 72700, lr = 0.006365
I0526 21:41:55.718727 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:42:21.824395 30701 solver.cpp:218] Iteration 72800 (3.55997 iter/s, 28.0901s/100 iters), loss = 0.000609502
I0526 21:42:21.824442 30701 solver.cpp:237]     Train net output #0: loss = 0.000607616 (* 1 = 0.000607616 loss)
I0526 21:42:21.824450 30701 sgd_solver.cpp:105] Iteration 72800, lr = 0.00636
I0526 21:42:49.924080 30701 solver.cpp:218] Iteration 72900 (3.55883 iter/s, 28.0991s/100 iters), loss = 0.0191413
I0526 21:42:49.924221 30701 solver.cpp:237]     Train net output #0: loss = 0.0191394 (* 1 = 0.0191394 loss)
I0526 21:42:49.924232 30701 sgd_solver.cpp:105] Iteration 72900, lr = 0.006355
I0526 21:43:17.762965 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_73000.caffemodel
I0526 21:43:18.076223 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_73000.solverstate
I0526 21:43:18.226851 30701 solver.cpp:330] Iteration 73000, Testing net (#0)
I0526 21:43:21.186442 30701 solver.cpp:397]     Test net output #0: accuracy = 0.762
I0526 21:43:21.186594 30701 solver.cpp:397]     Test net output #1: loss = 1.29584 (* 1 = 1.29584 loss)
I0526 21:43:21.467111 30701 solver.cpp:218] Iteration 73000 (3.17035 iter/s, 31.5423s/100 iters), loss = 0.00396571
I0526 21:43:21.467154 30701 solver.cpp:237]     Train net output #0: loss = 0.0039638 (* 1 = 0.0039638 loss)
I0526 21:43:21.467162 30701 sgd_solver.cpp:105] Iteration 73000, lr = 0.00635
I0526 21:43:49.577275 30701 solver.cpp:218] Iteration 73100 (3.55751 iter/s, 28.1096s/100 iters), loss = 0.00101746
I0526 21:43:49.577324 30701 solver.cpp:237]     Train net output #0: loss = 0.00101555 (* 1 = 0.00101555 loss)
I0526 21:43:49.577332 30701 sgd_solver.cpp:105] Iteration 73100, lr = 0.006345
I0526 21:44:17.691026 30701 solver.cpp:218] Iteration 73200 (3.55706 iter/s, 28.1131s/100 iters), loss = 0.0273284
I0526 21:44:17.691184 30701 solver.cpp:237]     Train net output #0: loss = 0.0273265 (* 1 = 0.0273265 loss)
I0526 21:44:17.691192 30701 sgd_solver.cpp:105] Iteration 73200, lr = 0.00634
I0526 21:44:45.269584 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:44:45.817356 30701 solver.cpp:218] Iteration 73300 (3.55548 iter/s, 28.1256s/100 iters), loss = 0.000410294
I0526 21:44:45.817402 30701 solver.cpp:237]     Train net output #0: loss = 0.000408387 (* 1 = 0.000408387 loss)
I0526 21:44:45.817410 30701 sgd_solver.cpp:105] Iteration 73300, lr = 0.006335
I0526 21:45:13.936724 30701 solver.cpp:218] Iteration 73400 (3.55634 iter/s, 28.1188s/100 iters), loss = 0.0543292
I0526 21:45:13.936885 30701 solver.cpp:237]     Train net output #0: loss = 0.0543273 (* 1 = 0.0543273 loss)
I0526 21:45:13.936897 30701 sgd_solver.cpp:105] Iteration 73400, lr = 0.00633
I0526 21:45:42.022837 30701 solver.cpp:218] Iteration 73500 (3.56057 iter/s, 28.0854s/100 iters), loss = 0.000248186
I0526 21:45:42.022882 30701 solver.cpp:237]     Train net output #0: loss = 0.000246275 (* 1 = 0.000246275 loss)
I0526 21:45:42.022891 30701 sgd_solver.cpp:105] Iteration 73500, lr = 0.006325
I0526 21:46:10.088898 30701 solver.cpp:218] Iteration 73600 (3.5631 iter/s, 28.0655s/100 iters), loss = 0.00109742
I0526 21:46:10.089095 30701 solver.cpp:237]     Train net output #0: loss = 0.00109551 (* 1 = 0.00109551 loss)
I0526 21:46:10.089118 30701 sgd_solver.cpp:105] Iteration 73600, lr = 0.00632
I0526 21:46:38.146749 30701 solver.cpp:218] Iteration 73700 (3.56416 iter/s, 28.0571s/100 iters), loss = 0.0722632
I0526 21:46:38.146796 30701 solver.cpp:237]     Train net output #0: loss = 0.0722613 (* 1 = 0.0722613 loss)
I0526 21:46:38.146806 30701 sgd_solver.cpp:105] Iteration 73700, lr = 0.006315
I0526 21:47:06.210803 30701 solver.cpp:218] Iteration 73800 (3.56335 iter/s, 28.0634s/100 iters), loss = 0.0299684
I0526 21:47:06.210973 30701 solver.cpp:237]     Train net output #0: loss = 0.0299664 (* 1 = 0.0299664 loss)
I0526 21:47:06.210986 30701 sgd_solver.cpp:105] Iteration 73800, lr = 0.00631
I0526 21:47:31.244057 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:47:34.319829 30701 solver.cpp:218] Iteration 73900 (3.55767 iter/s, 28.1083s/100 iters), loss = 0.00111071
I0526 21:47:34.319875 30701 solver.cpp:237]     Train net output #0: loss = 0.00110876 (* 1 = 0.00110876 loss)
I0526 21:47:34.319885 30701 sgd_solver.cpp:105] Iteration 73900, lr = 0.006305
I0526 21:48:02.146968 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_74000.caffemodel
I0526 21:48:02.460108 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_74000.solverstate
I0526 21:48:02.610828 30701 solver.cpp:330] Iteration 74000, Testing net (#0)
I0526 21:48:03.915851 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:48:05.569946 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0526 21:48:05.569989 30701 solver.cpp:397]     Test net output #1: loss = 0.977549 (* 1 = 0.977549 loss)
I0526 21:48:05.848335 30701 solver.cpp:218] Iteration 74000 (3.1718 iter/s, 31.5278s/100 iters), loss = 0.000699711
I0526 21:48:05.848381 30701 solver.cpp:237]     Train net output #0: loss = 0.00069777 (* 1 = 0.00069777 loss)
I0526 21:48:05.848389 30701 sgd_solver.cpp:105] Iteration 74000, lr = 0.0063
I0526 21:48:33.966691 30701 solver.cpp:218] Iteration 74100 (3.55647 iter/s, 28.1177s/100 iters), loss = 0.0285142
I0526 21:48:33.966903 30701 solver.cpp:237]     Train net output #0: loss = 0.0285123 (* 1 = 0.0285123 loss)
I0526 21:48:33.966914 30701 sgd_solver.cpp:105] Iteration 74100, lr = 0.006295
I0526 21:49:02.107831 30701 solver.cpp:218] Iteration 74200 (3.55361 iter/s, 28.1404s/100 iters), loss = 0.00158307
I0526 21:49:02.107885 30701 solver.cpp:237]     Train net output #0: loss = 0.00158111 (* 1 = 0.00158111 loss)
I0526 21:49:02.107895 30701 sgd_solver.cpp:105] Iteration 74200, lr = 0.00629
I0526 21:49:30.239540 30701 solver.cpp:218] Iteration 74300 (3.55479 iter/s, 28.1311s/100 iters), loss = 0.00693675
I0526 21:49:30.239740 30701 solver.cpp:237]     Train net output #0: loss = 0.00693478 (* 1 = 0.00693478 loss)
I0526 21:49:30.239753 30701 sgd_solver.cpp:105] Iteration 74300, lr = 0.006285
I0526 21:49:58.370192 30701 solver.cpp:218] Iteration 74400 (3.55494 iter/s, 28.1299s/100 iters), loss = 0.00410319
I0526 21:49:58.370288 30701 solver.cpp:237]     Train net output #0: loss = 0.00410121 (* 1 = 0.00410121 loss)
I0526 21:49:58.370299 30701 sgd_solver.cpp:105] Iteration 74400, lr = 0.00628
I0526 21:50:20.893419 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:50:26.498411 30701 solver.cpp:218] Iteration 74500 (3.55523 iter/s, 28.1276s/100 iters), loss = 0.00939631
I0526 21:50:26.498457 30701 solver.cpp:237]     Train net output #0: loss = 0.00939432 (* 1 = 0.00939432 loss)
I0526 21:50:26.498466 30701 sgd_solver.cpp:105] Iteration 74500, lr = 0.006275
I0526 21:50:54.600118 30701 solver.cpp:218] Iteration 74600 (3.55858 iter/s, 28.1011s/100 iters), loss = 0.00127628
I0526 21:50:54.600363 30701 solver.cpp:237]     Train net output #0: loss = 0.0012743 (* 1 = 0.0012743 loss)
I0526 21:50:54.600373 30701 sgd_solver.cpp:105] Iteration 74600, lr = 0.00627
I0526 21:51:22.692708 30701 solver.cpp:218] Iteration 74700 (3.55976 iter/s, 28.0918s/100 iters), loss = 0.00213274
I0526 21:51:22.692756 30701 solver.cpp:237]     Train net output #0: loss = 0.00213075 (* 1 = 0.00213075 loss)
I0526 21:51:22.692764 30701 sgd_solver.cpp:105] Iteration 74700, lr = 0.006265
I0526 21:51:50.782856 30701 solver.cpp:218] Iteration 74800 (3.56004 iter/s, 28.0895s/100 iters), loss = 0.0613886
I0526 21:51:50.783011 30701 solver.cpp:237]     Train net output #0: loss = 0.0613867 (* 1 = 0.0613867 loss)
I0526 21:51:50.783023 30701 sgd_solver.cpp:105] Iteration 74800, lr = 0.00626
I0526 21:52:18.872448 30701 solver.cpp:218] Iteration 74900 (3.56013 iter/s, 28.0889s/100 iters), loss = 0.00114334
I0526 21:52:18.872493 30701 solver.cpp:237]     Train net output #0: loss = 0.00114135 (* 1 = 0.00114135 loss)
I0526 21:52:18.872503 30701 sgd_solver.cpp:105] Iteration 74900, lr = 0.006255
I0526 21:52:46.683236 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_75000.caffemodel
I0526 21:52:46.996440 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_75000.solverstate
I0526 21:52:47.146311 30701 solver.cpp:330] Iteration 75000, Testing net (#0)
I0526 21:52:50.104239 30701 solver.cpp:397]     Test net output #0: accuracy = 0.76
I0526 21:52:50.104280 30701 solver.cpp:397]     Test net output #1: loss = 1.15275 (* 1 = 1.15275 loss)
I0526 21:52:50.381748 30701 solver.cpp:218] Iteration 75000 (3.17373 iter/s, 31.5086s/100 iters), loss = 0.00269452
I0526 21:52:50.381793 30701 solver.cpp:237]     Train net output #0: loss = 0.00269254 (* 1 = 0.00269254 loss)
I0526 21:52:50.381801 30701 sgd_solver.cpp:105] Iteration 75000, lr = 0.00625
I0526 21:53:10.642467 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:53:18.502780 30701 solver.cpp:218] Iteration 75100 (3.55613 iter/s, 28.1204s/100 iters), loss = 0.00778465
I0526 21:53:18.502946 30701 solver.cpp:237]     Train net output #0: loss = 0.00778267 (* 1 = 0.00778267 loss)
I0526 21:53:18.502959 30701 sgd_solver.cpp:105] Iteration 75100, lr = 0.006245
I0526 21:53:46.607337 30701 solver.cpp:218] Iteration 75200 (3.55823 iter/s, 28.1038s/100 iters), loss = 0.0800222
I0526 21:53:46.607381 30701 solver.cpp:237]     Train net output #0: loss = 0.0800202 (* 1 = 0.0800202 loss)
I0526 21:53:46.607390 30701 sgd_solver.cpp:105] Iteration 75200, lr = 0.00624
I0526 21:54:14.713079 30701 solver.cpp:218] Iteration 75300 (3.55807 iter/s, 28.1051s/100 iters), loss = 0.00104575
I0526 21:54:14.713255 30701 solver.cpp:237]     Train net output #0: loss = 0.00104374 (* 1 = 0.00104374 loss)
I0526 21:54:14.713266 30701 sgd_solver.cpp:105] Iteration 75300, lr = 0.006235
I0526 21:54:42.812922 30701 solver.cpp:218] Iteration 75400 (3.55883 iter/s, 28.0991s/100 iters), loss = 0.00300899
I0526 21:54:42.812968 30701 solver.cpp:237]     Train net output #0: loss = 0.00300697 (* 1 = 0.00300697 loss)
I0526 21:54:42.812975 30701 sgd_solver.cpp:105] Iteration 75400, lr = 0.00623
I0526 21:55:10.928357 30701 solver.cpp:218] Iteration 75500 (3.55684 iter/s, 28.1148s/100 iters), loss = 0.0482984
I0526 21:55:10.928525 30701 solver.cpp:237]     Train net output #0: loss = 0.0482964 (* 1 = 0.0482964 loss)
I0526 21:55:10.928537 30701 sgd_solver.cpp:105] Iteration 75500, lr = 0.006225
I0526 21:55:39.027918 30701 solver.cpp:218] Iteration 75600 (3.55891 iter/s, 28.0985s/100 iters), loss = 0.000272691
I0526 21:55:39.027969 30701 solver.cpp:237]     Train net output #0: loss = 0.000270689 (* 1 = 0.000270689 loss)
I0526 21:55:39.027978 30701 sgd_solver.cpp:105] Iteration 75600, lr = 0.00622
I0526 21:55:56.747287 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:56:07.126850 30701 solver.cpp:218] Iteration 75700 (3.55897 iter/s, 28.098s/100 iters), loss = 0.00144154
I0526 21:56:07.126895 30701 solver.cpp:237]     Train net output #0: loss = 0.00143954 (* 1 = 0.00143954 loss)
I0526 21:56:07.126904 30701 sgd_solver.cpp:105] Iteration 75700, lr = 0.006215
I0526 21:56:35.208936 30701 solver.cpp:218] Iteration 75800 (3.56111 iter/s, 28.0812s/100 iters), loss = 0.0795542
I0526 21:56:35.209127 30701 solver.cpp:237]     Train net output #0: loss = 0.0795522 (* 1 = 0.0795522 loss)
I0526 21:56:35.209139 30701 sgd_solver.cpp:105] Iteration 75800, lr = 0.00621
I0526 21:57:03.316320 30701 solver.cpp:218] Iteration 75900 (3.55792 iter/s, 28.1063s/100 iters), loss = 0.00105627
I0526 21:57:03.316364 30701 solver.cpp:237]     Train net output #0: loss = 0.00105427 (* 1 = 0.00105427 loss)
I0526 21:57:03.316371 30701 sgd_solver.cpp:105] Iteration 75900, lr = 0.006205
I0526 21:57:31.165612 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_76000.caffemodel
I0526 21:57:31.480196 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_76000.solverstate
I0526 21:57:31.631047 30701 solver.cpp:330] Iteration 76000, Testing net (#0)
I0526 21:57:34.593411 30701 solver.cpp:397]     Test net output #0: accuracy = 0.77
I0526 21:57:34.593464 30701 solver.cpp:397]     Test net output #1: loss = 1.15713 (* 1 = 1.15713 loss)
I0526 21:57:34.871567 30701 solver.cpp:218] Iteration 76000 (3.16915 iter/s, 31.5542s/100 iters), loss = 0.00750905
I0526 21:57:34.871608 30701 solver.cpp:237]     Train net output #0: loss = 0.00750705 (* 1 = 0.00750705 loss)
I0526 21:57:34.871616 30701 sgd_solver.cpp:105] Iteration 76000, lr = 0.0062
I0526 21:58:02.976738 30701 solver.cpp:218] Iteration 76100 (3.55818 iter/s, 28.1043s/100 iters), loss = 0.0715604
I0526 21:58:03.283794 30701 solver.cpp:237]     Train net output #0: loss = 0.0715584 (* 1 = 0.0715584 loss)
I0526 21:58:03.283826 30701 sgd_solver.cpp:105] Iteration 76100, lr = 0.006195
I0526 21:58:31.405339 30701 solver.cpp:218] Iteration 76200 (3.5561 iter/s, 28.1207s/100 iters), loss = 0.00133128
I0526 21:58:31.405386 30701 solver.cpp:237]     Train net output #0: loss = 0.0013293 (* 1 = 0.0013293 loss)
I0526 21:58:31.405395 30701 sgd_solver.cpp:105] Iteration 76200, lr = 0.00619
I0526 21:58:46.601141 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 21:58:59.525471 30701 solver.cpp:218] Iteration 76300 (3.55628 iter/s, 28.1193s/100 iters), loss = 0.00201119
I0526 21:58:59.525519 30701 solver.cpp:237]     Train net output #0: loss = 0.00200921 (* 1 = 0.00200921 loss)
I0526 21:58:59.525532 30701 sgd_solver.cpp:105] Iteration 76300, lr = 0.006185
I0526 21:59:27.640772 30701 solver.cpp:218] Iteration 76400 (3.55689 iter/s, 28.1144s/100 iters), loss = 0.0112917
I0526 21:59:27.641001 30701 solver.cpp:237]     Train net output #0: loss = 0.0112898 (* 1 = 0.0112898 loss)
I0526 21:59:27.641013 30701 sgd_solver.cpp:105] Iteration 76400, lr = 0.00618
I0526 21:59:55.743309 30701 solver.cpp:218] Iteration 76500 (3.55853 iter/s, 28.1015s/100 iters), loss = 0.00182416
I0526 21:59:55.743355 30701 solver.cpp:237]     Train net output #0: loss = 0.00182218 (* 1 = 0.00182218 loss)
I0526 21:59:55.743365 30701 sgd_solver.cpp:105] Iteration 76500, lr = 0.006175
I0526 22:00:23.847533 30701 solver.cpp:218] Iteration 76600 (3.55829 iter/s, 28.1034s/100 iters), loss = 0.00159216
I0526 22:00:23.847750 30701 solver.cpp:237]     Train net output #0: loss = 0.00159017 (* 1 = 0.00159017 loss)
I0526 22:00:23.847762 30701 sgd_solver.cpp:105] Iteration 76600, lr = 0.00617
I0526 22:00:51.971420 30701 solver.cpp:218] Iteration 76700 (3.55582 iter/s, 28.1229s/100 iters), loss = 0.00407534
I0526 22:00:51.971467 30701 solver.cpp:237]     Train net output #0: loss = 0.00407333 (* 1 = 0.00407333 loss)
I0526 22:00:51.971475 30701 sgd_solver.cpp:105] Iteration 76700, lr = 0.006165
I0526 22:01:20.078644 30701 solver.cpp:218] Iteration 76800 (3.55791 iter/s, 28.1064s/100 iters), loss = 0.00534864
I0526 22:01:20.078806 30701 solver.cpp:237]     Train net output #0: loss = 0.00534664 (* 1 = 0.00534664 loss)
I0526 22:01:20.078819 30701 sgd_solver.cpp:105] Iteration 76800, lr = 0.00616
I0526 22:01:32.735009 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:01:48.167534 30701 solver.cpp:218] Iteration 76900 (3.56024 iter/s, 28.088s/100 iters), loss = 0.00453023
I0526 22:01:48.167580 30701 solver.cpp:237]     Train net output #0: loss = 0.00452825 (* 1 = 0.00452825 loss)
I0526 22:01:48.167589 30701 sgd_solver.cpp:105] Iteration 76900, lr = 0.006155
I0526 22:02:15.997792 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_77000.caffemodel
I0526 22:02:16.309187 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_77000.solverstate
I0526 22:02:16.459357 30701 solver.cpp:330] Iteration 77000, Testing net (#0)
I0526 22:02:16.462924 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:02:19.414782 30701 solver.cpp:397]     Test net output #0: accuracy = 0.788
I0526 22:02:19.414834 30701 solver.cpp:397]     Test net output #1: loss = 1.08809 (* 1 = 1.08809 loss)
I0526 22:02:19.693253 30701 solver.cpp:218] Iteration 77000 (3.1721 iter/s, 31.5248s/100 iters), loss = 0.000226972
I0526 22:02:19.693302 30701 solver.cpp:237]     Train net output #0: loss = 0.000224993 (* 1 = 0.000224993 loss)
I0526 22:02:19.693311 30701 sgd_solver.cpp:105] Iteration 77000, lr = 0.00615
I0526 22:02:47.811789 30701 solver.cpp:218] Iteration 77100 (3.55647 iter/s, 28.1177s/100 iters), loss = 0.00164972
I0526 22:02:47.811964 30701 solver.cpp:237]     Train net output #0: loss = 0.00164775 (* 1 = 0.00164775 loss)
I0526 22:02:47.811976 30701 sgd_solver.cpp:105] Iteration 77100, lr = 0.006145
I0526 22:03:15.931011 30701 solver.cpp:218] Iteration 77200 (3.5564 iter/s, 28.1183s/100 iters), loss = 0.0266066
I0526 22:03:15.931059 30701 solver.cpp:237]     Train net output #0: loss = 0.0266046 (* 1 = 0.0266046 loss)
I0526 22:03:15.931068 30701 sgd_solver.cpp:105] Iteration 77200, lr = 0.00614
I0526 22:03:43.996696 30701 solver.cpp:218] Iteration 77300 (3.56317 iter/s, 28.0649s/100 iters), loss = 0.00166452
I0526 22:03:43.996894 30701 solver.cpp:237]     Train net output #0: loss = 0.00166252 (* 1 = 0.00166252 loss)
I0526 22:03:43.996919 30701 sgd_solver.cpp:105] Iteration 77300, lr = 0.006135
I0526 22:04:12.108391 30701 solver.cpp:218] Iteration 77400 (3.55735 iter/s, 28.1108s/100 iters), loss = 0.0039766
I0526 22:04:12.108446 30701 solver.cpp:237]     Train net output #0: loss = 0.0039746 (* 1 = 0.0039746 loss)
I0526 22:04:12.108455 30701 sgd_solver.cpp:105] Iteration 77400, lr = 0.00613
I0526 22:04:22.249444 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:04:40.228837 30701 solver.cpp:218] Iteration 77500 (3.55623 iter/s, 28.1197s/100 iters), loss = 0.00107448
I0526 22:04:40.228881 30701 solver.cpp:237]     Train net output #0: loss = 0.00107246 (* 1 = 0.00107246 loss)
I0526 22:04:40.228890 30701 sgd_solver.cpp:105] Iteration 77500, lr = 0.006125
I0526 22:05:08.356923 30701 solver.cpp:218] Iteration 77600 (3.55526 iter/s, 28.1273s/100 iters), loss = 0.000812162
I0526 22:05:08.357096 30701 solver.cpp:237]     Train net output #0: loss = 0.000810138 (* 1 = 0.000810138 loss)
I0526 22:05:08.357113 30701 sgd_solver.cpp:105] Iteration 77600, lr = 0.00612
I0526 22:05:36.473376 30701 solver.cpp:218] Iteration 77700 (3.55675 iter/s, 28.1156s/100 iters), loss = 0.0849038
I0526 22:05:36.473420 30701 solver.cpp:237]     Train net output #0: loss = 0.0849018 (* 1 = 0.0849018 loss)
I0526 22:05:36.473428 30701 sgd_solver.cpp:105] Iteration 77700, lr = 0.006115
I0526 22:06:04.584312 30701 solver.cpp:218] Iteration 77800 (3.55743 iter/s, 28.1102s/100 iters), loss = 8.27271e-05
I0526 22:06:04.584528 30701 solver.cpp:237]     Train net output #0: loss = 8.06897e-05 (* 1 = 8.06897e-05 loss)
I0526 22:06:04.584539 30701 sgd_solver.cpp:105] Iteration 77800, lr = 0.00611
I0526 22:06:32.702481 30701 solver.cpp:218] Iteration 77900 (3.55653 iter/s, 28.1173s/100 iters), loss = 0.000120983
I0526 22:06:32.702527 30701 solver.cpp:237]     Train net output #0: loss = 0.000118947 (* 1 = 0.000118947 loss)
I0526 22:06:32.702536 30701 sgd_solver.cpp:105] Iteration 77900, lr = 0.006105
I0526 22:07:00.536561 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_78000.caffemodel
I0526 22:07:00.907656 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_78000.solverstate
I0526 22:07:01.057894 30701 solver.cpp:330] Iteration 78000, Testing net (#0)
I0526 22:07:04.013921 30701 solver.cpp:397]     Test net output #0: accuracy = 0.764
I0526 22:07:04.013962 30701 solver.cpp:397]     Test net output #1: loss = 1.2271 (* 1 = 1.2271 loss)
I0526 22:07:04.290820 30701 solver.cpp:218] Iteration 78000 (3.16581 iter/s, 31.5875s/100 iters), loss = 0.000939012
I0526 22:07:04.290866 30701 solver.cpp:237]     Train net output #0: loss = 0.000936992 (* 1 = 0.000936992 loss)
I0526 22:07:04.290874 30701 sgd_solver.cpp:105] Iteration 78000, lr = 0.0061
I0526 22:07:11.893411 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:07:32.368583 30701 solver.cpp:218] Iteration 78100 (3.56163 iter/s, 28.077s/100 iters), loss = 0.000679793
I0526 22:07:32.368804 30701 solver.cpp:237]     Train net output #0: loss = 0.000677796 (* 1 = 0.000677796 loss)
I0526 22:07:32.368816 30701 sgd_solver.cpp:105] Iteration 78100, lr = 0.006095
I0526 22:08:00.472772 30701 solver.cpp:218] Iteration 78200 (3.5583 iter/s, 28.1033s/100 iters), loss = 0.0109397
I0526 22:08:00.472817 30701 solver.cpp:237]     Train net output #0: loss = 0.0109377 (* 1 = 0.0109377 loss)
I0526 22:08:00.472826 30701 sgd_solver.cpp:105] Iteration 78200, lr = 0.00609
I0526 22:08:28.579097 30701 solver.cpp:218] Iteration 78300 (3.55801 iter/s, 28.1056s/100 iters), loss = 0.00100157
I0526 22:08:28.582480 30701 solver.cpp:237]     Train net output #0: loss = 0.000999593 (* 1 = 0.000999593 loss)
I0526 22:08:28.582491 30701 sgd_solver.cpp:105] Iteration 78300, lr = 0.006085
I0526 22:08:56.719621 30701 solver.cpp:218] Iteration 78400 (3.55411 iter/s, 28.1365s/100 iters), loss = 0.0275121
I0526 22:08:56.719667 30701 solver.cpp:237]     Train net output #0: loss = 0.0275101 (* 1 = 0.0275101 loss)
I0526 22:08:56.719676 30701 sgd_solver.cpp:105] Iteration 78400, lr = 0.00608
I0526 22:09:24.847596 30701 solver.cpp:218] Iteration 78500 (3.55527 iter/s, 28.1273s/100 iters), loss = 0.00121028
I0526 22:09:24.847760 30701 solver.cpp:237]     Train net output #0: loss = 0.00120832 (* 1 = 0.00120832 loss)
I0526 22:09:24.847771 30701 sgd_solver.cpp:105] Iteration 78500, lr = 0.006075
I0526 22:09:52.957463 30701 solver.cpp:218] Iteration 78600 (3.55757 iter/s, 28.109s/100 iters), loss = 0.00606292
I0526 22:09:52.957507 30701 solver.cpp:237]     Train net output #0: loss = 0.00606097 (* 1 = 0.00606097 loss)
I0526 22:09:52.957516 30701 sgd_solver.cpp:105] Iteration 78600, lr = 0.00607
I0526 22:09:58.032318 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:10:21.047736 30701 solver.cpp:218] Iteration 78700 (3.56004 iter/s, 28.0896s/100 iters), loss = 0.00179048
I0526 22:10:21.047785 30701 solver.cpp:237]     Train net output #0: loss = 0.00178855 (* 1 = 0.00178855 loss)
I0526 22:10:21.047798 30701 sgd_solver.cpp:105] Iteration 78700, lr = 0.006065
I0526 22:10:49.121480 30701 solver.cpp:218] Iteration 78800 (3.56214 iter/s, 28.073s/100 iters), loss = 0.0025989
I0526 22:10:49.121650 30701 solver.cpp:237]     Train net output #0: loss = 0.00259695 (* 1 = 0.00259695 loss)
I0526 22:10:49.121667 30701 sgd_solver.cpp:105] Iteration 78800, lr = 0.00606
I0526 22:11:17.192692 30701 solver.cpp:218] Iteration 78900 (3.56247 iter/s, 28.0704s/100 iters), loss = 0.000593229
I0526 22:11:17.192739 30701 solver.cpp:237]     Train net output #0: loss = 0.000591277 (* 1 = 0.000591277 loss)
I0526 22:11:17.192746 30701 sgd_solver.cpp:105] Iteration 78900, lr = 0.006055
I0526 22:11:45.016441 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_79000.caffemodel
I0526 22:11:45.364686 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_79000.solverstate
I0526 22:11:45.513932 30701 solver.cpp:330] Iteration 79000, Testing net (#0)
I0526 22:11:47.207309 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:11:48.477571 30701 solver.cpp:397]     Test net output #0: accuracy = 0.786
I0526 22:11:48.477613 30701 solver.cpp:397]     Test net output #1: loss = 1.07528 (* 1 = 1.07528 loss)
I0526 22:11:48.756225 30701 solver.cpp:218] Iteration 79000 (3.16829 iter/s, 31.5628s/100 iters), loss = 0.00263253
I0526 22:11:48.756278 30701 solver.cpp:237]     Train net output #0: loss = 0.00263058 (* 1 = 0.00263058 loss)
I0526 22:11:48.756290 30701 sgd_solver.cpp:105] Iteration 79000, lr = 0.00605
I0526 22:12:16.865952 30701 solver.cpp:218] Iteration 79100 (3.55758 iter/s, 28.109s/100 iters), loss = 0.00362675
I0526 22:12:16.866143 30701 solver.cpp:237]     Train net output #0: loss = 0.00362478 (* 1 = 0.00362478 loss)
I0526 22:12:16.866161 30701 sgd_solver.cpp:105] Iteration 79100, lr = 0.006045
I0526 22:12:44.996111 30701 solver.cpp:218] Iteration 79200 (3.55501 iter/s, 28.1293s/100 iters), loss = 0.0262747
I0526 22:12:44.996156 30701 solver.cpp:237]     Train net output #0: loss = 0.0262727 (* 1 = 0.0262727 loss)
I0526 22:12:44.996165 30701 sgd_solver.cpp:105] Iteration 79200, lr = 0.00604
I0526 22:12:47.829422 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:13:13.134083 30701 solver.cpp:218] Iteration 79300 (3.554 iter/s, 28.1373s/100 iters), loss = 0.0716757
I0526 22:13:13.134131 30701 solver.cpp:237]     Train net output #0: loss = 0.0716737 (* 1 = 0.0716737 loss)
I0526 22:13:13.134145 30701 sgd_solver.cpp:105] Iteration 79300, lr = 0.006035
I0526 22:13:41.272938 30701 solver.cpp:218] Iteration 79400 (3.55389 iter/s, 28.1382s/100 iters), loss = 0.0285226
I0526 22:13:41.273106 30701 solver.cpp:237]     Train net output #0: loss = 0.0285207 (* 1 = 0.0285207 loss)
I0526 22:13:41.273118 30701 sgd_solver.cpp:105] Iteration 79400, lr = 0.00603
I0526 22:14:09.372336 30701 solver.cpp:218] Iteration 79500 (3.5589 iter/s, 28.0986s/100 iters), loss = 0.00971698
I0526 22:14:09.372381 30701 solver.cpp:237]     Train net output #0: loss = 0.009715 (* 1 = 0.009715 loss)
I0526 22:14:09.372390 30701 sgd_solver.cpp:105] Iteration 79500, lr = 0.006025
I0526 22:14:37.474488 30701 solver.cpp:218] Iteration 79600 (3.55853 iter/s, 28.1015s/100 iters), loss = 0.00880065
I0526 22:14:37.474701 30701 solver.cpp:237]     Train net output #0: loss = 0.00879868 (* 1 = 0.00879868 loss)
I0526 22:14:37.474712 30701 sgd_solver.cpp:105] Iteration 79600, lr = 0.00602
I0526 22:15:05.571411 30701 solver.cpp:218] Iteration 79700 (3.55922 iter/s, 28.0961s/100 iters), loss = 0.000451468
I0526 22:15:05.571457 30701 solver.cpp:237]     Train net output #0: loss = 0.000449494 (* 1 = 0.000449494 loss)
I0526 22:15:05.571466 30701 sgd_solver.cpp:105] Iteration 79700, lr = 0.006015
I0526 22:15:33.655956 30701 solver.cpp:218] Iteration 79800 (3.56077 iter/s, 28.0839s/100 iters), loss = 0.0164004
I0526 22:15:33.656160 30701 solver.cpp:237]     Train net output #0: loss = 0.0163984 (* 1 = 0.0163984 loss)
I0526 22:15:33.656172 30701 sgd_solver.cpp:105] Iteration 79800, lr = 0.00601
I0526 22:15:33.955466 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:16:01.789783 30701 solver.cpp:218] Iteration 79900 (3.55454 iter/s, 28.133s/100 iters), loss = 0.0072557
I0526 22:16:01.789824 30701 solver.cpp:237]     Train net output #0: loss = 0.00725369 (* 1 = 0.00725369 loss)
I0526 22:16:01.789832 30701 sgd_solver.cpp:105] Iteration 79900, lr = 0.006005
I0526 22:16:29.640949 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_80000.caffemodel
I0526 22:16:29.954879 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_80000.solverstate
I0526 22:16:30.105947 30701 solver.cpp:330] Iteration 80000, Testing net (#0)
I0526 22:16:33.064373 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0526 22:16:33.064422 30701 solver.cpp:397]     Test net output #1: loss = 1.01243 (* 1 = 1.01243 loss)
I0526 22:16:33.342520 30701 solver.cpp:218] Iteration 80000 (3.16937 iter/s, 31.552s/100 iters), loss = 0.00418114
I0526 22:16:33.342567 30701 solver.cpp:237]     Train net output #0: loss = 0.00417915 (* 1 = 0.00417915 loss)
I0526 22:16:33.342576 30701 sgd_solver.cpp:105] Iteration 80000, lr = 0.006
I0526 22:17:01.389719 30701 solver.cpp:218] Iteration 80100 (3.56551 iter/s, 28.0465s/100 iters), loss = 0.00481674
I0526 22:17:01.389897 30701 solver.cpp:237]     Train net output #0: loss = 0.00481473 (* 1 = 0.00481473 loss)
I0526 22:17:01.389909 30701 sgd_solver.cpp:105] Iteration 80100, lr = 0.005995
I0526 22:17:29.440589 30701 solver.cpp:218] Iteration 80200 (3.56505 iter/s, 28.0501s/100 iters), loss = 0.000909237
I0526 22:17:29.440635 30701 solver.cpp:237]     Train net output #0: loss = 0.000907234 (* 1 = 0.000907234 loss)
I0526 22:17:29.440644 30701 sgd_solver.cpp:105] Iteration 80200, lr = 0.00599
I0526 22:17:57.500977 30701 solver.cpp:218] Iteration 80300 (3.56383 iter/s, 28.0597s/100 iters), loss = 0.00103827
I0526 22:17:57.501197 30701 solver.cpp:237]     Train net output #0: loss = 0.00103627 (* 1 = 0.00103627 loss)
I0526 22:17:57.501209 30701 sgd_solver.cpp:105] Iteration 80300, lr = 0.005985
I0526 22:18:23.329964 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:18:25.559844 30701 solver.cpp:218] Iteration 80400 (3.56404 iter/s, 28.058s/100 iters), loss = 0.00547911
I0526 22:18:25.559893 30701 solver.cpp:237]     Train net output #0: loss = 0.0054771 (* 1 = 0.0054771 loss)
I0526 22:18:25.559904 30701 sgd_solver.cpp:105] Iteration 80400, lr = 0.00598
I0526 22:18:53.695679 30701 solver.cpp:218] Iteration 80500 (3.55427 iter/s, 28.1352s/100 iters), loss = 0.00910371
I0526 22:18:53.695802 30701 solver.cpp:237]     Train net output #0: loss = 0.00910167 (* 1 = 0.00910167 loss)
I0526 22:18:53.695828 30701 sgd_solver.cpp:105] Iteration 80500, lr = 0.005975
I0526 22:19:21.808239 30701 solver.cpp:218] Iteration 80600 (3.55722 iter/s, 28.1118s/100 iters), loss = 0.000908941
I0526 22:19:21.808284 30701 solver.cpp:237]     Train net output #0: loss = 0.000906903 (* 1 = 0.000906903 loss)
I0526 22:19:21.808292 30701 sgd_solver.cpp:105] Iteration 80600, lr = 0.00597
I0526 22:19:49.917891 30701 solver.cpp:218] Iteration 80700 (3.55758 iter/s, 28.109s/100 iters), loss = 0.000499026
I0526 22:19:49.918063 30701 solver.cpp:237]     Train net output #0: loss = 0.000496982 (* 1 = 0.000496982 loss)
I0526 22:19:49.918076 30701 sgd_solver.cpp:105] Iteration 80700, lr = 0.005965
I0526 22:20:18.040324 30701 solver.cpp:218] Iteration 80800 (3.55598 iter/s, 28.1216s/100 iters), loss = 0.000744639
I0526 22:20:18.040371 30701 solver.cpp:237]     Train net output #0: loss = 0.000742586 (* 1 = 0.000742586 loss)
I0526 22:20:18.040380 30701 sgd_solver.cpp:105] Iteration 80800, lr = 0.00596
I0526 22:20:46.160279 30701 solver.cpp:218] Iteration 80900 (3.55628 iter/s, 28.1193s/100 iters), loss = 0.0164069
I0526 22:20:46.160455 30701 solver.cpp:237]     Train net output #0: loss = 0.0164049 (* 1 = 0.0164049 loss)
I0526 22:20:46.160467 30701 sgd_solver.cpp:105] Iteration 80900, lr = 0.005955
I0526 22:21:09.526420 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:21:14.015394 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_81000.caffemodel
I0526 22:21:14.334045 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_81000.solverstate
I0526 22:21:14.484150 30701 solver.cpp:330] Iteration 81000, Testing net (#0)
I0526 22:21:17.440032 30701 solver.cpp:397]     Test net output #0: accuracy = 0.774
I0526 22:21:17.440244 30701 solver.cpp:397]     Test net output #1: loss = 1.12823 (* 1 = 1.12823 loss)
I0526 22:21:17.718331 30701 solver.cpp:218] Iteration 81000 (3.16885 iter/s, 31.5572s/100 iters), loss = 0.000103134
I0526 22:21:17.718381 30701 solver.cpp:237]     Train net output #0: loss = 0.000101067 (* 1 = 0.000101067 loss)
I0526 22:21:17.718391 30701 sgd_solver.cpp:105] Iteration 81000, lr = 0.00595
I0526 22:21:45.775836 30701 solver.cpp:218] Iteration 81100 (3.56419 iter/s, 28.0568s/100 iters), loss = 0.000405768
I0526 22:21:45.775882 30701 solver.cpp:237]     Train net output #0: loss = 0.000403699 (* 1 = 0.000403699 loss)
I0526 22:21:45.775892 30701 sgd_solver.cpp:105] Iteration 81100, lr = 0.005945
I0526 22:22:13.865595 30701 solver.cpp:218] Iteration 81200 (3.5601 iter/s, 28.0891s/100 iters), loss = 0.00710891
I0526 22:22:13.865836 30701 solver.cpp:237]     Train net output #0: loss = 0.00710683 (* 1 = 0.00710683 loss)
I0526 22:22:13.865847 30701 sgd_solver.cpp:105] Iteration 81200, lr = 0.00594
I0526 22:22:41.946507 30701 solver.cpp:218] Iteration 81300 (3.56125 iter/s, 28.08s/100 iters), loss = 0.00287181
I0526 22:22:41.946550 30701 solver.cpp:237]     Train net output #0: loss = 0.00286972 (* 1 = 0.00286972 loss)
I0526 22:22:41.946559 30701 sgd_solver.cpp:105] Iteration 81300, lr = 0.005935
I0526 22:23:10.069591 30701 solver.cpp:218] Iteration 81400 (3.55588 iter/s, 28.1224s/100 iters), loss = 0.0168354
I0526 22:23:10.069756 30701 solver.cpp:237]     Train net output #0: loss = 0.0168334 (* 1 = 0.0168334 loss)
I0526 22:23:10.069767 30701 sgd_solver.cpp:105] Iteration 81400, lr = 0.00593
I0526 22:23:38.180111 30701 solver.cpp:218] Iteration 81500 (3.55749 iter/s, 28.1097s/100 iters), loss = 0.000456911
I0526 22:23:38.180156 30701 solver.cpp:237]     Train net output #0: loss = 0.00045486 (* 1 = 0.00045486 loss)
I0526 22:23:38.180166 30701 sgd_solver.cpp:105] Iteration 81500, lr = 0.005925
I0526 22:23:59.007606 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:24:06.297431 30701 solver.cpp:218] Iteration 81600 (3.55661 iter/s, 28.1167s/100 iters), loss = 0.00014437
I0526 22:24:06.297477 30701 solver.cpp:237]     Train net output #0: loss = 0.000142327 (* 1 = 0.000142327 loss)
I0526 22:24:06.297485 30701 sgd_solver.cpp:105] Iteration 81600, lr = 0.00592
I0526 22:24:34.378542 30701 solver.cpp:218] Iteration 81700 (3.5612 iter/s, 28.0804s/100 iters), loss = 0.0010839
I0526 22:24:34.378690 30701 solver.cpp:237]     Train net output #0: loss = 0.00108189 (* 1 = 0.00108189 loss)
I0526 22:24:34.378701 30701 sgd_solver.cpp:105] Iteration 81700, lr = 0.005915
I0526 22:25:02.485131 30701 solver.cpp:218] Iteration 81800 (3.55798 iter/s, 28.1058s/100 iters), loss = 0.00251829
I0526 22:25:02.485175 30701 solver.cpp:237]     Train net output #0: loss = 0.00251628 (* 1 = 0.00251628 loss)
I0526 22:25:02.485184 30701 sgd_solver.cpp:105] Iteration 81800, lr = 0.00591
I0526 22:25:30.605624 30701 solver.cpp:218] Iteration 81900 (3.55621 iter/s, 28.1198s/100 iters), loss = 0.000320635
I0526 22:25:30.606426 30701 solver.cpp:237]     Train net output #0: loss = 0.000318627 (* 1 = 0.000318627 loss)
I0526 22:25:30.606438 30701 sgd_solver.cpp:105] Iteration 81900, lr = 0.005905
I0526 22:25:58.454486 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_82000.caffemodel
I0526 22:25:58.834178 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_82000.solverstate
I0526 22:25:58.984356 30701 solver.cpp:330] Iteration 82000, Testing net (#0)
I0526 22:25:59.404191 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:26:01.945339 30701 solver.cpp:397]     Test net output #0: accuracy = 0.772
I0526 22:26:01.945485 30701 solver.cpp:397]     Test net output #1: loss = 1.13492 (* 1 = 1.13492 loss)
I0526 22:26:02.225132 30701 solver.cpp:218] Iteration 82000 (3.16275 iter/s, 31.618s/100 iters), loss = 0.000208132
I0526 22:26:02.225175 30701 solver.cpp:237]     Train net output #0: loss = 0.000206117 (* 1 = 0.000206117 loss)
I0526 22:26:02.225184 30701 sgd_solver.cpp:105] Iteration 82000, lr = 0.0059
I0526 22:26:30.323639 30701 solver.cpp:218] Iteration 82100 (3.55899 iter/s, 28.0978s/100 iters), loss = 0.000587323
I0526 22:26:30.323688 30701 solver.cpp:237]     Train net output #0: loss = 0.000585306 (* 1 = 0.000585306 loss)
I0526 22:26:30.323696 30701 sgd_solver.cpp:105] Iteration 82100, lr = 0.005895
I0526 22:26:48.616621 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:26:58.435477 30701 solver.cpp:218] Iteration 82200 (3.55731 iter/s, 28.1112s/100 iters), loss = 0.00169394
I0526 22:26:58.435523 30701 solver.cpp:237]     Train net output #0: loss = 0.00169193 (* 1 = 0.00169193 loss)
I0526 22:26:58.435530 30701 sgd_solver.cpp:105] Iteration 82200, lr = 0.00589
I0526 22:27:26.544641 30701 solver.cpp:218] Iteration 82300 (3.55764 iter/s, 28.1085s/100 iters), loss = 0.000717319
I0526 22:27:26.544857 30701 solver.cpp:237]     Train net output #0: loss = 0.000715305 (* 1 = 0.000715305 loss)
I0526 22:27:26.544881 30701 sgd_solver.cpp:105] Iteration 82300, lr = 0.005885
I0526 22:27:54.645705 30701 solver.cpp:218] Iteration 82400 (3.55869 iter/s, 28.1002s/100 iters), loss = 0.000387733
I0526 22:27:54.645751 30701 solver.cpp:237]     Train net output #0: loss = 0.000385721 (* 1 = 0.000385721 loss)
I0526 22:27:54.645761 30701 sgd_solver.cpp:105] Iteration 82400, lr = 0.00588
I0526 22:28:22.759620 30701 solver.cpp:218] Iteration 82500 (3.55704 iter/s, 28.1133s/100 iters), loss = 5.77496e-05
I0526 22:28:22.759837 30701 solver.cpp:237]     Train net output #0: loss = 5.57363e-05 (* 1 = 5.57363e-05 loss)
I0526 22:28:22.759850 30701 sgd_solver.cpp:105] Iteration 82500, lr = 0.005875
I0526 22:28:50.874229 30701 solver.cpp:218] Iteration 82600 (3.55697 iter/s, 28.1138s/100 iters), loss = 0.000505461
I0526 22:28:50.874272 30701 solver.cpp:237]     Train net output #0: loss = 0.000503456 (* 1 = 0.000503456 loss)
I0526 22:28:50.874281 30701 sgd_solver.cpp:105] Iteration 82600, lr = 0.00587
I0526 22:29:18.975553 30701 solver.cpp:218] Iteration 82700 (3.55863 iter/s, 28.1007s/100 iters), loss = 0.000395834
I0526 22:29:18.975705 30701 solver.cpp:237]     Train net output #0: loss = 0.000393848 (* 1 = 0.000393848 loss)
I0526 22:29:18.975716 30701 sgd_solver.cpp:105] Iteration 82700, lr = 0.005865
I0526 22:29:34.737355 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:29:47.081364 30701 solver.cpp:218] Iteration 82800 (3.55808 iter/s, 28.1051s/100 iters), loss = 0.00164558
I0526 22:29:47.081413 30701 solver.cpp:237]     Train net output #0: loss = 0.00164359 (* 1 = 0.00164359 loss)
I0526 22:29:47.081423 30701 sgd_solver.cpp:105] Iteration 82800, lr = 0.00586
I0526 22:30:15.211138 30701 solver.cpp:218] Iteration 82900 (3.55504 iter/s, 28.1291s/100 iters), loss = 0.000658996
I0526 22:30:15.211423 30701 solver.cpp:237]     Train net output #0: loss = 0.000657015 (* 1 = 0.000657015 loss)
I0526 22:30:15.211436 30701 sgd_solver.cpp:105] Iteration 82900, lr = 0.005855
I0526 22:30:43.059422 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_83000.caffemodel
I0526 22:30:43.377753 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_83000.solverstate
I0526 22:30:43.529378 30701 solver.cpp:330] Iteration 83000, Testing net (#0)
I0526 22:30:46.486336 30701 solver.cpp:397]     Test net output #0: accuracy = 0.78
I0526 22:30:46.486519 30701 solver.cpp:397]     Test net output #1: loss = 1.14954 (* 1 = 1.14954 loss)
I0526 22:30:46.763954 30701 solver.cpp:218] Iteration 83000 (3.16939 iter/s, 31.5518s/100 iters), loss = 0.00176322
I0526 22:30:46.764012 30701 solver.cpp:237]     Train net output #0: loss = 0.00176126 (* 1 = 0.00176126 loss)
I0526 22:30:46.764021 30701 sgd_solver.cpp:105] Iteration 83000, lr = 0.00585
I0526 22:31:14.834390 30701 solver.cpp:218] Iteration 83100 (3.56255 iter/s, 28.0698s/100 iters), loss = 0.000301088
I0526 22:31:14.834444 30701 solver.cpp:237]     Train net output #0: loss = 0.000299125 (* 1 = 0.000299125 loss)
I0526 22:31:14.834452 30701 sgd_solver.cpp:105] Iteration 83100, lr = 0.005845
I0526 22:31:42.893200 30701 solver.cpp:218] Iteration 83200 (3.56403 iter/s, 28.0581s/100 iters), loss = 0.000171038
I0526 22:31:42.893359 30701 solver.cpp:237]     Train net output #0: loss = 0.000169067 (* 1 = 0.000169067 loss)
I0526 22:31:42.893371 30701 sgd_solver.cpp:105] Iteration 83200, lr = 0.00584
I0526 22:32:10.960139 30701 solver.cpp:218] Iteration 83300 (3.56301 iter/s, 28.0662s/100 iters), loss = 0.00926161
I0526 22:32:10.960186 30701 solver.cpp:237]     Train net output #0: loss = 0.00925963 (* 1 = 0.00925963 loss)
I0526 22:32:10.960194 30701 sgd_solver.cpp:105] Iteration 83300, lr = 0.005835
I0526 22:32:24.449565 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:32:39.029716 30701 solver.cpp:218] Iteration 83400 (3.56266 iter/s, 28.0689s/100 iters), loss = 0.000786225
I0526 22:32:39.029763 30701 solver.cpp:237]     Train net output #0: loss = 0.000784232 (* 1 = 0.000784232 loss)
I0526 22:32:39.029772 30701 sgd_solver.cpp:105] Iteration 83400, lr = 0.00583
I0526 22:33:07.104904 30701 solver.cpp:218] Iteration 83500 (3.56195 iter/s, 28.0745s/100 iters), loss = 0.000802272
I0526 22:33:07.105128 30701 solver.cpp:237]     Train net output #0: loss = 0.000800277 (* 1 = 0.000800277 loss)
I0526 22:33:07.105144 30701 sgd_solver.cpp:105] Iteration 83500, lr = 0.005825
I0526 22:33:35.177042 30701 solver.cpp:218] Iteration 83600 (3.56235 iter/s, 28.0713s/100 iters), loss = 0.00203172
I0526 22:33:35.177099 30701 solver.cpp:237]     Train net output #0: loss = 0.0020297 (* 1 = 0.0020297 loss)
I0526 22:33:35.177112 30701 sgd_solver.cpp:105] Iteration 83600, lr = 0.00582
I0526 22:34:03.281877 30701 solver.cpp:218] Iteration 83700 (3.55819 iter/s, 28.1042s/100 iters), loss = 0.0146217
I0526 22:34:03.282090 30701 solver.cpp:237]     Train net output #0: loss = 0.0146196 (* 1 = 0.0146196 loss)
I0526 22:34:03.282107 30701 sgd_solver.cpp:105] Iteration 83700, lr = 0.005815
I0526 22:34:31.366523 30701 solver.cpp:218] Iteration 83800 (3.56076 iter/s, 28.0839s/100 iters), loss = 0.0110608
I0526 22:34:31.366576 30701 solver.cpp:237]     Train net output #0: loss = 0.0110587 (* 1 = 0.0110587 loss)
I0526 22:34:31.366600 30701 sgd_solver.cpp:105] Iteration 83800, lr = 0.00581
I0526 22:34:59.442685 30701 solver.cpp:218] Iteration 83900 (3.56182 iter/s, 28.0755s/100 iters), loss = 0.0024913
I0526 22:34:59.442970 30701 solver.cpp:237]     Train net output #0: loss = 0.0024892 (* 1 = 0.0024892 loss)
I0526 22:34:59.442986 30701 sgd_solver.cpp:105] Iteration 83900, lr = 0.005805
I0526 22:35:10.418936 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:35:27.243623 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_84000.caffemodel
I0526 22:35:27.565172 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_84000.solverstate
I0526 22:35:27.719993 30701 solver.cpp:330] Iteration 84000, Testing net (#0)
I0526 22:35:29.812674 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:35:30.669320 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0526 22:35:30.669369 30701 solver.cpp:397]     Test net output #1: loss = 1.04599 (* 1 = 1.04599 loss)
I0526 22:35:30.947335 30701 solver.cpp:218] Iteration 84000 (3.17423 iter/s, 31.5037s/100 iters), loss = 0.00362638
I0526 22:35:30.947381 30701 solver.cpp:237]     Train net output #0: loss = 0.00362428 (* 1 = 0.00362428 loss)
I0526 22:35:30.947391 30701 sgd_solver.cpp:105] Iteration 84000, lr = 0.0058
I0526 22:35:59.073181 30701 solver.cpp:218] Iteration 84100 (3.55553 iter/s, 28.1252s/100 iters), loss = 0.000212772
I0526 22:35:59.073241 30701 solver.cpp:237]     Train net output #0: loss = 0.000210703 (* 1 = 0.000210703 loss)
I0526 22:35:59.073251 30701 sgd_solver.cpp:105] Iteration 84100, lr = 0.005795
I0526 22:36:27.226366 30701 solver.cpp:218] Iteration 84200 (3.55208 iter/s, 28.1525s/100 iters), loss = 0.0103616
I0526 22:36:27.226490 30701 solver.cpp:237]     Train net output #0: loss = 0.0103595 (* 1 = 0.0103595 loss)
I0526 22:36:27.226500 30701 sgd_solver.cpp:105] Iteration 84200, lr = 0.00579
I0526 22:36:55.396580 30701 solver.cpp:218] Iteration 84300 (3.54994 iter/s, 28.1695s/100 iters), loss = 0.000587591
I0526 22:36:55.396637 30701 solver.cpp:237]     Train net output #0: loss = 0.000585513 (* 1 = 0.000585513 loss)
I0526 22:36:55.396646 30701 sgd_solver.cpp:105] Iteration 84300, lr = 0.005785
I0526 22:37:23.552461 30701 solver.cpp:218] Iteration 84400 (3.55174 iter/s, 28.1552s/100 iters), loss = 0.136312
I0526 22:37:23.552618 30701 solver.cpp:237]     Train net output #0: loss = 0.13631 (* 1 = 0.13631 loss)
I0526 22:37:23.552628 30701 sgd_solver.cpp:105] Iteration 84400, lr = 0.00578
I0526 22:37:51.649832 30701 solver.cpp:218] Iteration 84500 (3.55915 iter/s, 28.0966s/100 iters), loss = 0.0183519
I0526 22:37:51.649893 30701 solver.cpp:237]     Train net output #0: loss = 0.0183498 (* 1 = 0.0183498 loss)
I0526 22:37:51.649901 30701 sgd_solver.cpp:105] Iteration 84500, lr = 0.005775
I0526 22:38:00.101510 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:38:19.765980 30701 solver.cpp:218] Iteration 84600 (3.55676 iter/s, 28.1155s/100 iters), loss = 0.00858056
I0526 22:38:19.766026 30701 solver.cpp:237]     Train net output #0: loss = 0.00857845 (* 1 = 0.00857845 loss)
I0526 22:38:19.766036 30701 sgd_solver.cpp:105] Iteration 84600, lr = 0.00577
I0526 22:38:47.920359 30701 solver.cpp:218] Iteration 84700 (3.55193 iter/s, 28.1537s/100 iters), loss = 0.003524
I0526 22:38:47.920581 30701 solver.cpp:237]     Train net output #0: loss = 0.0035219 (* 1 = 0.0035219 loss)
I0526 22:38:47.920593 30701 sgd_solver.cpp:105] Iteration 84700, lr = 0.005765
I0526 22:39:16.038810 30701 solver.cpp:218] Iteration 84800 (3.55649 iter/s, 28.1176s/100 iters), loss = 0.0469223
I0526 22:39:16.038856 30701 solver.cpp:237]     Train net output #0: loss = 0.0469202 (* 1 = 0.0469202 loss)
I0526 22:39:16.038864 30701 sgd_solver.cpp:105] Iteration 84800, lr = 0.00576
I0526 22:39:44.130508 30701 solver.cpp:218] Iteration 84900 (3.55985 iter/s, 28.091s/100 iters), loss = 0.00784046
I0526 22:39:44.130702 30701 solver.cpp:237]     Train net output #0: loss = 0.00783841 (* 1 = 0.00783841 loss)
I0526 22:39:44.130714 30701 sgd_solver.cpp:105] Iteration 84900, lr = 0.005755
I0526 22:40:11.978662 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_85000.caffemodel
I0526 22:40:12.293325 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_85000.solverstate
I0526 22:40:12.446063 30701 solver.cpp:330] Iteration 85000, Testing net (#0)
I0526 22:40:15.401332 30701 solver.cpp:397]     Test net output #0: accuracy = 0.794
I0526 22:40:15.401476 30701 solver.cpp:397]     Test net output #1: loss = 1.0832 (* 1 = 1.0832 loss)
I0526 22:40:15.681093 30701 solver.cpp:218] Iteration 85000 (3.1696 iter/s, 31.5497s/100 iters), loss = 0.0413655
I0526 22:40:15.681154 30701 solver.cpp:237]     Train net output #0: loss = 0.0413634 (* 1 = 0.0413634 loss)
I0526 22:40:15.681162 30701 sgd_solver.cpp:105] Iteration 85000, lr = 0.00575
I0526 22:40:43.803148 30701 solver.cpp:218] Iteration 85100 (3.55601 iter/s, 28.1214s/100 iters), loss = 0.00564459
I0526 22:40:43.803191 30701 solver.cpp:237]     Train net output #0: loss = 0.00564253 (* 1 = 0.00564253 loss)
I0526 22:40:43.803200 30701 sgd_solver.cpp:105] Iteration 85100, lr = 0.005745
I0526 22:40:49.732379 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:41:11.928289 30701 solver.cpp:218] Iteration 85200 (3.55562 iter/s, 28.1245s/100 iters), loss = 0.00289175
I0526 22:41:11.928338 30701 solver.cpp:237]     Train net output #0: loss = 0.00288968 (* 1 = 0.00288968 loss)
I0526 22:41:11.928346 30701 sgd_solver.cpp:105] Iteration 85200, lr = 0.00574
I0526 22:41:40.036739 30701 solver.cpp:218] Iteration 85300 (3.55773 iter/s, 28.1078s/100 iters), loss = 0.00415889
I0526 22:41:40.036896 30701 solver.cpp:237]     Train net output #0: loss = 0.0041568 (* 1 = 0.0041568 loss)
I0526 22:41:40.036907 30701 sgd_solver.cpp:105] Iteration 85300, lr = 0.005735
I0526 22:42:08.145370 30701 solver.cpp:218] Iteration 85400 (3.55772 iter/s, 28.1079s/100 iters), loss = 0.000383493
I0526 22:42:08.145414 30701 solver.cpp:237]     Train net output #0: loss = 0.000381389 (* 1 = 0.000381389 loss)
I0526 22:42:08.145423 30701 sgd_solver.cpp:105] Iteration 85400, lr = 0.00573
I0526 22:42:36.262037 30701 solver.cpp:218] Iteration 85500 (3.55669 iter/s, 28.116s/100 iters), loss = 0.000333858
I0526 22:42:36.262212 30701 solver.cpp:237]     Train net output #0: loss = 0.000331747 (* 1 = 0.000331747 loss)
I0526 22:42:36.262223 30701 sgd_solver.cpp:105] Iteration 85500, lr = 0.005725
I0526 22:43:04.399811 30701 solver.cpp:218] Iteration 85600 (3.55404 iter/s, 28.137s/100 iters), loss = 0.0129043
I0526 22:43:04.399855 30701 solver.cpp:237]     Train net output #0: loss = 0.0129021 (* 1 = 0.0129021 loss)
I0526 22:43:04.399864 30701 sgd_solver.cpp:105] Iteration 85600, lr = 0.00572
I0526 22:43:32.507809 30701 solver.cpp:218] Iteration 85700 (3.55779 iter/s, 28.1073s/100 iters), loss = 0.00480441
I0526 22:43:32.508002 30701 solver.cpp:237]     Train net output #0: loss = 0.00480227 (* 1 = 0.00480227 loss)
I0526 22:43:32.508013 30701 sgd_solver.cpp:105] Iteration 85700, lr = 0.005715
I0526 22:43:35.900708 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:44:00.628391 30701 solver.cpp:218] Iteration 85800 (3.55622 iter/s, 28.1198s/100 iters), loss = 0.00417271
I0526 22:44:00.628433 30701 solver.cpp:237]     Train net output #0: loss = 0.00417057 (* 1 = 0.00417057 loss)
I0526 22:44:00.628443 30701 sgd_solver.cpp:105] Iteration 85800, lr = 0.00571
I0526 22:44:28.746510 30701 solver.cpp:218] Iteration 85900 (3.55651 iter/s, 28.1175s/100 iters), loss = 0.0040126
I0526 22:44:28.746670 30701 solver.cpp:237]     Train net output #0: loss = 0.00401046 (* 1 = 0.00401046 loss)
I0526 22:44:28.746682 30701 sgd_solver.cpp:105] Iteration 85900, lr = 0.005705
I0526 22:44:56.588145 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_86000.caffemodel
I0526 22:44:56.926487 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_86000.solverstate
I0526 22:44:57.080081 30701 solver.cpp:330] Iteration 86000, Testing net (#0)
I0526 22:45:00.039100 30701 solver.cpp:397]     Test net output #0: accuracy = 0.762
I0526 22:45:00.039211 30701 solver.cpp:397]     Test net output #1: loss = 1.30024 (* 1 = 1.30024 loss)
I0526 22:45:00.319507 30701 solver.cpp:218] Iteration 86000 (3.16735 iter/s, 31.5722s/100 iters), loss = 0.00476053
I0526 22:45:00.319553 30701 solver.cpp:237]     Train net output #0: loss = 0.0047584 (* 1 = 0.0047584 loss)
I0526 22:45:00.319562 30701 sgd_solver.cpp:105] Iteration 86000, lr = 0.0057
I0526 22:45:28.399622 30701 solver.cpp:218] Iteration 86100 (3.56132 iter/s, 28.0795s/100 iters), loss = 0.00950794
I0526 22:45:28.399684 30701 solver.cpp:237]     Train net output #0: loss = 0.00950583 (* 1 = 0.00950583 loss)
I0526 22:45:28.399693 30701 sgd_solver.cpp:105] Iteration 86100, lr = 0.005695
I0526 22:45:56.475819 30701 solver.cpp:218] Iteration 86200 (3.56182 iter/s, 28.0755s/100 iters), loss = 0.0144084
I0526 22:45:56.475992 30701 solver.cpp:237]     Train net output #0: loss = 0.0144062 (* 1 = 0.0144062 loss)
I0526 22:45:56.476003 30701 sgd_solver.cpp:105] Iteration 86200, lr = 0.00569
I0526 22:46:24.549775 30701 solver.cpp:218] Iteration 86300 (3.56212 iter/s, 28.0732s/100 iters), loss = 0.147387
I0526 22:46:24.549823 30701 solver.cpp:237]     Train net output #0: loss = 0.147385 (* 1 = 0.147385 loss)
I0526 22:46:24.549830 30701 sgd_solver.cpp:105] Iteration 86300, lr = 0.005685
I0526 22:46:25.413300 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:46:52.672613 30701 solver.cpp:218] Iteration 86400 (3.55591 iter/s, 28.1222s/100 iters), loss = 0.000918138
I0526 22:46:52.672829 30701 solver.cpp:237]     Train net output #0: loss = 0.000916019 (* 1 = 0.000916019 loss)
I0526 22:46:52.672842 30701 sgd_solver.cpp:105] Iteration 86400, lr = 0.00568
I0526 22:47:20.792304 30701 solver.cpp:218] Iteration 86500 (3.55633 iter/s, 28.1189s/100 iters), loss = 0.00635797
I0526 22:47:20.792348 30701 solver.cpp:237]     Train net output #0: loss = 0.00635587 (* 1 = 0.00635587 loss)
I0526 22:47:20.792357 30701 sgd_solver.cpp:105] Iteration 86500, lr = 0.005675
I0526 22:47:48.848309 30701 solver.cpp:218] Iteration 86600 (3.56438 iter/s, 28.0553s/100 iters), loss = 0.00255518
I0526 22:47:48.848471 30701 solver.cpp:237]     Train net output #0: loss = 0.00255308 (* 1 = 0.00255308 loss)
I0526 22:47:48.848484 30701 sgd_solver.cpp:105] Iteration 86600, lr = 0.00567
I0526 22:48:16.909884 30701 solver.cpp:218] Iteration 86700 (3.56369 iter/s, 28.0608s/100 iters), loss = 0.120618
I0526 22:48:16.909929 30701 solver.cpp:237]     Train net output #0: loss = 0.120616 (* 1 = 0.120616 loss)
I0526 22:48:16.909937 30701 sgd_solver.cpp:105] Iteration 86700, lr = 0.005665
I0526 22:48:44.973932 30701 solver.cpp:218] Iteration 86800 (3.56336 iter/s, 28.0634s/100 iters), loss = 0.0260586
I0526 22:48:44.974189 30701 solver.cpp:237]     Train net output #0: loss = 0.0260565 (* 1 = 0.0260565 loss)
I0526 22:48:44.974200 30701 sgd_solver.cpp:105] Iteration 86800, lr = 0.00566
I0526 22:49:11.654165 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:49:13.044801 30701 solver.cpp:218] Iteration 86900 (3.56252 iter/s, 28.07s/100 iters), loss = 0.156123
I0526 22:49:13.044855 30701 solver.cpp:237]     Train net output #0: loss = 0.156121 (* 1 = 0.156121 loss)
I0526 22:49:13.044864 30701 sgd_solver.cpp:105] Iteration 86900, lr = 0.005655
I0526 22:49:40.837533 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_87000.caffemodel
I0526 22:49:41.150424 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_87000.solverstate
I0526 22:49:41.301223 30701 solver.cpp:330] Iteration 87000, Testing net (#0)
I0526 22:49:42.134732 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:49:44.259676 30701 solver.cpp:397]     Test net output #0: accuracy = 0.738
I0526 22:49:44.259713 30701 solver.cpp:397]     Test net output #1: loss = 1.18708 (* 1 = 1.18708 loss)
I0526 22:49:44.537948 30701 solver.cpp:218] Iteration 87000 (3.17537 iter/s, 31.4924s/100 iters), loss = 0.00249952
I0526 22:49:44.537992 30701 solver.cpp:237]     Train net output #0: loss = 0.00249753 (* 1 = 0.00249753 loss)
I0526 22:49:44.538000 30701 sgd_solver.cpp:105] Iteration 87000, lr = 0.00565
I0526 22:50:12.613147 30701 solver.cpp:218] Iteration 87100 (3.56195 iter/s, 28.0745s/100 iters), loss = 0.0953455
I0526 22:50:12.613272 30701 solver.cpp:237]     Train net output #0: loss = 0.0953435 (* 1 = 0.0953435 loss)
I0526 22:50:12.613293 30701 sgd_solver.cpp:105] Iteration 87100, lr = 0.005645
I0526 22:50:40.685184 30701 solver.cpp:218] Iteration 87200 (3.56236 iter/s, 28.0713s/100 iters), loss = 0.0295135
I0526 22:50:40.685230 30701 solver.cpp:237]     Train net output #0: loss = 0.0295115 (* 1 = 0.0295115 loss)
I0526 22:50:40.685240 30701 sgd_solver.cpp:105] Iteration 87200, lr = 0.00564
I0526 22:51:08.766772 30701 solver.cpp:218] Iteration 87300 (3.56114 iter/s, 28.0809s/100 iters), loss = 0.00166854
I0526 22:51:08.766934 30701 solver.cpp:237]     Train net output #0: loss = 0.00166658 (* 1 = 0.00166658 loss)
I0526 22:51:08.766945 30701 sgd_solver.cpp:105] Iteration 87300, lr = 0.005635
I0526 22:51:36.842893 30701 solver.cpp:218] Iteration 87400 (3.56184 iter/s, 28.0754s/100 iters), loss = 0.00276345
I0526 22:51:36.842939 30701 solver.cpp:237]     Train net output #0: loss = 0.00276147 (* 1 = 0.00276147 loss)
I0526 22:51:36.842948 30701 sgd_solver.cpp:105] Iteration 87400, lr = 0.00563
I0526 22:52:01.006817 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:52:04.924465 30701 solver.cpp:218] Iteration 87500 (3.56114 iter/s, 28.0809s/100 iters), loss = 0.00223989
I0526 22:52:04.924510 30701 solver.cpp:237]     Train net output #0: loss = 0.00223791 (* 1 = 0.00223791 loss)
I0526 22:52:04.924520 30701 sgd_solver.cpp:105] Iteration 87500, lr = 0.005625
I0526 22:52:33.003288 30701 solver.cpp:218] Iteration 87600 (3.56149 iter/s, 28.0782s/100 iters), loss = 0.000449261
I0526 22:52:33.003499 30701 solver.cpp:237]     Train net output #0: loss = 0.000447285 (* 1 = 0.000447285 loss)
I0526 22:52:33.003511 30701 sgd_solver.cpp:105] Iteration 87600, lr = 0.00562
I0526 22:53:01.122102 30701 solver.cpp:218] Iteration 87700 (3.55644 iter/s, 28.118s/100 iters), loss = 0.042816
I0526 22:53:01.122150 30701 solver.cpp:237]     Train net output #0: loss = 0.042814 (* 1 = 0.042814 loss)
I0526 22:53:01.122161 30701 sgd_solver.cpp:105] Iteration 87700, lr = 0.005615
I0526 22:53:29.249475 30701 solver.cpp:218] Iteration 87800 (3.55534 iter/s, 28.1267s/100 iters), loss = 0.0341345
I0526 22:53:29.249680 30701 solver.cpp:237]     Train net output #0: loss = 0.0341325 (* 1 = 0.0341325 loss)
I0526 22:53:29.249691 30701 sgd_solver.cpp:105] Iteration 87800, lr = 0.00561
I0526 22:53:57.353854 30701 solver.cpp:218] Iteration 87900 (3.55827 iter/s, 28.1036s/100 iters), loss = 0.00156869
I0526 22:53:57.353899 30701 solver.cpp:237]     Train net output #0: loss = 0.00156672 (* 1 = 0.00156672 loss)
I0526 22:53:57.353907 30701 sgd_solver.cpp:105] Iteration 87900, lr = 0.005605
I0526 22:54:25.174373 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_88000.caffemodel
I0526 22:54:25.488620 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_88000.solverstate
I0526 22:54:25.638986 30701 solver.cpp:330] Iteration 88000, Testing net (#0)
I0526 22:54:28.595785 30701 solver.cpp:397]     Test net output #0: accuracy = 0.768
I0526 22:54:28.595837 30701 solver.cpp:397]     Test net output #1: loss = 1.29139 (* 1 = 1.29139 loss)
I0526 22:54:28.872956 30701 solver.cpp:218] Iteration 88000 (3.17275 iter/s, 31.5184s/100 iters), loss = 0.00424739
I0526 22:54:28.873001 30701 solver.cpp:237]     Train net output #0: loss = 0.00424542 (* 1 = 0.00424542 loss)
I0526 22:54:28.873010 30701 sgd_solver.cpp:105] Iteration 88000, lr = 0.0056
I0526 22:54:50.505610 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:54:56.943387 30701 solver.cpp:218] Iteration 88100 (3.56255 iter/s, 28.0698s/100 iters), loss = 0.0119704
I0526 22:54:56.943532 30701 solver.cpp:237]     Train net output #0: loss = 0.0119685 (* 1 = 0.0119685 loss)
I0526 22:54:56.943547 30701 sgd_solver.cpp:105] Iteration 88100, lr = 0.005595
I0526 22:55:25.012989 30701 solver.cpp:218] Iteration 88200 (3.56267 iter/s, 28.0689s/100 iters), loss = 0.00427417
I0526 22:55:25.013032 30701 solver.cpp:237]     Train net output #0: loss = 0.00427223 (* 1 = 0.00427223 loss)
I0526 22:55:25.013041 30701 sgd_solver.cpp:105] Iteration 88200, lr = 0.00559
I0526 22:55:53.092005 30701 solver.cpp:218] Iteration 88300 (3.56146 iter/s, 28.0784s/100 iters), loss = 0.000497586
I0526 22:55:53.092212 30701 solver.cpp:237]     Train net output #0: loss = 0.000495649 (* 1 = 0.000495649 loss)
I0526 22:55:53.092224 30701 sgd_solver.cpp:105] Iteration 88300, lr = 0.005585
I0526 22:56:21.171375 30701 solver.cpp:218] Iteration 88400 (3.56143 iter/s, 28.0786s/100 iters), loss = 0.00177816
I0526 22:56:21.171421 30701 solver.cpp:237]     Train net output #0: loss = 0.00177622 (* 1 = 0.00177622 loss)
I0526 22:56:21.171428 30701 sgd_solver.cpp:105] Iteration 88400, lr = 0.00558
I0526 22:56:49.300248 30701 solver.cpp:218] Iteration 88500 (3.55515 iter/s, 28.1282s/100 iters), loss = 0.0015606
I0526 22:56:49.300416 30701 solver.cpp:237]     Train net output #0: loss = 0.00155866 (* 1 = 0.00155866 loss)
I0526 22:56:49.300427 30701 sgd_solver.cpp:105] Iteration 88500, lr = 0.005575
I0526 22:57:17.389219 30701 solver.cpp:218] Iteration 88600 (3.56021 iter/s, 28.0882s/100 iters), loss = 0.00151679
I0526 22:57:17.389262 30701 solver.cpp:237]     Train net output #0: loss = 0.00151485 (* 1 = 0.00151485 loss)
I0526 22:57:17.389271 30701 sgd_solver.cpp:105] Iteration 88600, lr = 0.00557
I0526 22:57:36.511374 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:57:45.492660 30701 solver.cpp:218] Iteration 88700 (3.55837 iter/s, 28.1028s/100 iters), loss = 0.00770962
I0526 22:57:45.492703 30701 solver.cpp:237]     Train net output #0: loss = 0.00770769 (* 1 = 0.00770769 loss)
I0526 22:57:45.492712 30701 sgd_solver.cpp:105] Iteration 88700, lr = 0.005565
I0526 22:58:13.582027 30701 solver.cpp:218] Iteration 88800 (3.56015 iter/s, 28.0887s/100 iters), loss = 0.0172557
I0526 22:58:13.582240 30701 solver.cpp:237]     Train net output #0: loss = 0.0172538 (* 1 = 0.0172538 loss)
I0526 22:58:13.582252 30701 sgd_solver.cpp:105] Iteration 88800, lr = 0.00556
I0526 22:58:41.682427 30701 solver.cpp:218] Iteration 88900 (3.55877 iter/s, 28.0996s/100 iters), loss = 0.000134129
I0526 22:58:41.682476 30701 solver.cpp:237]     Train net output #0: loss = 0.000132202 (* 1 = 0.000132202 loss)
I0526 22:58:41.682484 30701 sgd_solver.cpp:105] Iteration 88900, lr = 0.005555
I0526 22:59:09.509831 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_89000.caffemodel
I0526 22:59:09.822206 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_89000.solverstate
I0526 22:59:09.972071 30701 solver.cpp:330] Iteration 89000, Testing net (#0)
I0526 22:59:12.460925 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 22:59:12.931382 30701 solver.cpp:397]     Test net output #0: accuracy = 0.824
I0526 22:59:12.931421 30701 solver.cpp:397]     Test net output #1: loss = 0.861308 (* 1 = 0.861308 loss)
I0526 22:59:13.210616 30701 solver.cpp:218] Iteration 89000 (3.17184 iter/s, 31.5275s/100 iters), loss = 0.00511868
I0526 22:59:13.210661 30701 solver.cpp:237]     Train net output #0: loss = 0.00511675 (* 1 = 0.00511675 loss)
I0526 22:59:13.210670 30701 sgd_solver.cpp:105] Iteration 89000, lr = 0.00555
I0526 22:59:41.334590 30701 solver.cpp:218] Iteration 89100 (3.55577 iter/s, 28.1233s/100 iters), loss = 0.000517817
I0526 22:59:41.334811 30701 solver.cpp:237]     Train net output #0: loss = 0.000515891 (* 1 = 0.000515891 loss)
I0526 22:59:41.334823 30701 sgd_solver.cpp:105] Iteration 89100, lr = 0.005545
I0526 23:00:09.462357 30701 solver.cpp:218] Iteration 89200 (3.55531 iter/s, 28.1269s/100 iters), loss = 0.000545211
I0526 23:00:09.462404 30701 solver.cpp:237]     Train net output #0: loss = 0.000543295 (* 1 = 0.000543295 loss)
I0526 23:00:09.462412 30701 sgd_solver.cpp:105] Iteration 89200, lr = 0.00554
I0526 23:00:26.071231 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:00:37.593199 30701 solver.cpp:218] Iteration 89300 (3.5549 iter/s, 28.1302s/100 iters), loss = 0.000502132
I0526 23:00:37.593245 30701 solver.cpp:237]     Train net output #0: loss = 0.00050024 (* 1 = 0.00050024 loss)
I0526 23:00:37.593252 30701 sgd_solver.cpp:105] Iteration 89300, lr = 0.005535
I0526 23:01:05.733052 30701 solver.cpp:218] Iteration 89400 (3.55376 iter/s, 28.1392s/100 iters), loss = 0.00251214
I0526 23:01:05.733220 30701 solver.cpp:237]     Train net output #0: loss = 0.00251025 (* 1 = 0.00251025 loss)
I0526 23:01:05.733232 30701 sgd_solver.cpp:105] Iteration 89400, lr = 0.00553
I0526 23:01:33.862898 30701 solver.cpp:218] Iteration 89500 (3.55504 iter/s, 28.1291s/100 iters), loss = 0.00161202
I0526 23:01:33.862946 30701 solver.cpp:237]     Train net output #0: loss = 0.00161013 (* 1 = 0.00161013 loss)
I0526 23:01:33.862965 30701 sgd_solver.cpp:105] Iteration 89500, lr = 0.005525
I0526 23:02:01.980074 30701 solver.cpp:218] Iteration 89600 (3.55663 iter/s, 28.1165s/100 iters), loss = 0.00184021
I0526 23:02:01.980233 30701 solver.cpp:237]     Train net output #0: loss = 0.00183832 (* 1 = 0.00183832 loss)
I0526 23:02:01.980248 30701 sgd_solver.cpp:105] Iteration 89600, lr = 0.00552
I0526 23:02:30.067500 30701 solver.cpp:218] Iteration 89700 (3.56041 iter/s, 28.0867s/100 iters), loss = 0.00249283
I0526 23:02:30.067544 30701 solver.cpp:237]     Train net output #0: loss = 0.00249094 (* 1 = 0.00249094 loss)
I0526 23:02:30.067553 30701 sgd_solver.cpp:105] Iteration 89700, lr = 0.005515
I0526 23:02:58.131163 30701 solver.cpp:218] Iteration 89800 (3.56341 iter/s, 28.063s/100 iters), loss = 0.00011644
I0526 23:02:58.131374 30701 solver.cpp:237]     Train net output #0: loss = 0.000114535 (* 1 = 0.000114535 loss)
I0526 23:02:58.131386 30701 sgd_solver.cpp:105] Iteration 89800, lr = 0.00551
I0526 23:03:12.188555 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:03:26.198951 30701 solver.cpp:218] Iteration 89900 (3.56291 iter/s, 28.067s/100 iters), loss = 0.037884
I0526 23:03:26.198994 30701 solver.cpp:237]     Train net output #0: loss = 0.0378821 (* 1 = 0.0378821 loss)
I0526 23:03:26.199003 30701 sgd_solver.cpp:105] Iteration 89900, lr = 0.005505
I0526 23:03:53.988358 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_90000.caffemodel
I0526 23:03:54.302506 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_90000.solverstate
I0526 23:03:54.454324 30701 solver.cpp:330] Iteration 90000, Testing net (#0)
I0526 23:03:57.409524 30701 solver.cpp:397]     Test net output #0: accuracy = 0.798
I0526 23:03:57.409559 30701 solver.cpp:397]     Test net output #1: loss = 1.1305 (* 1 = 1.1305 loss)
I0526 23:03:57.687567 30701 solver.cpp:218] Iteration 90000 (3.17581 iter/s, 31.488s/100 iters), loss = 0.00741645
I0526 23:03:57.687615 30701 solver.cpp:237]     Train net output #0: loss = 0.00741455 (* 1 = 0.00741455 loss)
I0526 23:03:57.687624 30701 sgd_solver.cpp:105] Iteration 90000, lr = 0.0055
I0526 23:04:25.764871 30701 solver.cpp:218] Iteration 90100 (3.56166 iter/s, 28.0768s/100 iters), loss = 0.000132878
I0526 23:04:25.765031 30701 solver.cpp:237]     Train net output #0: loss = 0.000130972 (* 1 = 0.000130972 loss)
I0526 23:04:25.765043 30701 sgd_solver.cpp:105] Iteration 90100, lr = 0.005495
I0526 23:04:53.842180 30701 solver.cpp:218] Iteration 90200 (3.56168 iter/s, 28.0767s/100 iters), loss = 0.00058024
I0526 23:04:53.842226 30701 solver.cpp:237]     Train net output #0: loss = 0.000578325 (* 1 = 0.000578325 loss)
I0526 23:04:53.842234 30701 sgd_solver.cpp:105] Iteration 90200, lr = 0.00549
I0526 23:05:21.927937 30701 solver.cpp:218] Iteration 90300 (3.56059 iter/s, 28.0852s/100 iters), loss = 0.00147145
I0526 23:05:21.928104 30701 solver.cpp:237]     Train net output #0: loss = 0.00146954 (* 1 = 0.00146954 loss)
I0526 23:05:21.928115 30701 sgd_solver.cpp:105] Iteration 90300, lr = 0.005485
I0526 23:05:50.020107 30701 solver.cpp:218] Iteration 90400 (3.5598 iter/s, 28.0915s/100 iters), loss = 0.000381829
I0526 23:05:50.020153 30701 solver.cpp:237]     Train net output #0: loss = 0.000379925 (* 1 = 0.000379925 loss)
I0526 23:05:50.020160 30701 sgd_solver.cpp:105] Iteration 90400, lr = 0.00548
I0526 23:06:01.554746 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:06:18.103098 30701 solver.cpp:218] Iteration 90500 (3.56095 iter/s, 28.0824s/100 iters), loss = 0.000423694
I0526 23:06:18.103153 30701 solver.cpp:237]     Train net output #0: loss = 0.000421784 (* 1 = 0.000421784 loss)
I0526 23:06:18.103163 30701 sgd_solver.cpp:105] Iteration 90500, lr = 0.005475
I0526 23:06:46.189587 30701 solver.cpp:218] Iteration 90600 (3.5605 iter/s, 28.0859s/100 iters), loss = 0.00131292
I0526 23:06:46.189757 30701 solver.cpp:237]     Train net output #0: loss = 0.001311 (* 1 = 0.001311 loss)
I0526 23:06:46.189770 30701 sgd_solver.cpp:105] Iteration 90600, lr = 0.00547
I0526 23:07:14.279204 30701 solver.cpp:218] Iteration 90700 (3.56012 iter/s, 28.0889s/100 iters), loss = 0.00488637
I0526 23:07:14.279248 30701 solver.cpp:237]     Train net output #0: loss = 0.00488446 (* 1 = 0.00488446 loss)
I0526 23:07:14.279258 30701 sgd_solver.cpp:105] Iteration 90700, lr = 0.005465
I0526 23:07:42.369946 30701 solver.cpp:218] Iteration 90800 (3.55996 iter/s, 28.0902s/100 iters), loss = 0.00194949
I0526 23:07:42.370107 30701 solver.cpp:237]     Train net output #0: loss = 0.00194757 (* 1 = 0.00194757 loss)
I0526 23:07:42.370118 30701 sgd_solver.cpp:105] Iteration 90800, lr = 0.00546
I0526 23:08:10.468472 30701 solver.cpp:218] Iteration 90900 (3.55899 iter/s, 28.0978s/100 iters), loss = 0.00039843
I0526 23:08:10.468518 30701 solver.cpp:237]     Train net output #0: loss = 0.000396515 (* 1 = 0.000396515 loss)
I0526 23:08:10.468528 30701 sgd_solver.cpp:105] Iteration 90900, lr = 0.005455
I0526 23:08:38.287436 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_91000.caffemodel
I0526 23:08:38.602715 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_91000.solverstate
I0526 23:08:38.754855 30701 solver.cpp:330] Iteration 91000, Testing net (#0)
I0526 23:08:41.718703 30701 solver.cpp:397]     Test net output #0: accuracy = 0.798
I0526 23:08:41.718739 30701 solver.cpp:397]     Test net output #1: loss = 1.04129 (* 1 = 1.04129 loss)
I0526 23:08:41.998212 30701 solver.cpp:218] Iteration 91000 (3.17167 iter/s, 31.5291s/100 iters), loss = 0.000166334
I0526 23:08:41.998256 30701 solver.cpp:237]     Train net output #0: loss = 0.000164414 (* 1 = 0.000164414 loss)
I0526 23:08:41.998265 30701 sgd_solver.cpp:105] Iteration 91000, lr = 0.00545
I0526 23:08:51.282063 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:09:10.086686 30701 solver.cpp:218] Iteration 91100 (3.56025 iter/s, 28.0879s/100 iters), loss = 0.0040249
I0526 23:09:10.086902 30701 solver.cpp:237]     Train net output #0: loss = 0.00402298 (* 1 = 0.00402298 loss)
I0526 23:09:10.086926 30701 sgd_solver.cpp:105] Iteration 91100, lr = 0.005445
I0526 23:09:38.164683 30701 solver.cpp:218] Iteration 91200 (3.5616 iter/s, 28.0772s/100 iters), loss = 0.000539874
I0526 23:09:38.164727 30701 solver.cpp:237]     Train net output #0: loss = 0.000537956 (* 1 = 0.000537956 loss)
I0526 23:09:38.164736 30701 sgd_solver.cpp:105] Iteration 91200, lr = 0.00544
I0526 23:10:06.243605 30701 solver.cpp:218] Iteration 91300 (3.56146 iter/s, 28.0783s/100 iters), loss = 0.00047087
I0526 23:10:06.243780 30701 solver.cpp:237]     Train net output #0: loss = 0.000468972 (* 1 = 0.000468972 loss)
I0526 23:10:06.243791 30701 sgd_solver.cpp:105] Iteration 91300, lr = 0.005435
I0526 23:10:34.307524 30701 solver.cpp:218] Iteration 91400 (3.56339 iter/s, 28.0632s/100 iters), loss = 0.000127335
I0526 23:10:34.307570 30701 solver.cpp:237]     Train net output #0: loss = 0.000125443 (* 1 = 0.000125443 loss)
I0526 23:10:34.307579 30701 sgd_solver.cpp:105] Iteration 91400, lr = 0.00543
I0526 23:11:02.397197 30701 solver.cpp:218] Iteration 91500 (3.5601 iter/s, 28.0891s/100 iters), loss = 0.00160298
I0526 23:11:02.397364 30701 solver.cpp:237]     Train net output #0: loss = 0.00160108 (* 1 = 0.00160108 loss)
I0526 23:11:02.397375 30701 sgd_solver.cpp:105] Iteration 91500, lr = 0.005425
I0526 23:11:30.467125 30701 solver.cpp:218] Iteration 91600 (3.56262 iter/s, 28.0692s/100 iters), loss = 0.000344441
I0526 23:11:30.467171 30701 solver.cpp:237]     Train net output #0: loss = 0.000342543 (* 1 = 0.000342543 loss)
I0526 23:11:30.467180 30701 sgd_solver.cpp:105] Iteration 91600, lr = 0.00542
I0526 23:11:37.230337 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:11:58.555903 30701 solver.cpp:218] Iteration 91700 (3.56022 iter/s, 28.0882s/100 iters), loss = 0.0017987
I0526 23:11:58.555976 30701 solver.cpp:237]     Train net output #0: loss = 0.0017968 (* 1 = 0.0017968 loss)
I0526 23:11:58.555987 30701 sgd_solver.cpp:105] Iteration 91700, lr = 0.005415
I0526 23:12:26.661880 30701 solver.cpp:218] Iteration 91800 (3.55804 iter/s, 28.1054s/100 iters), loss = 0.000580713
I0526 23:12:26.662048 30701 solver.cpp:237]     Train net output #0: loss = 0.000578818 (* 1 = 0.000578818 loss)
I0526 23:12:26.662061 30701 sgd_solver.cpp:105] Iteration 91800, lr = 0.00541
I0526 23:12:54.773391 30701 solver.cpp:218] Iteration 91900 (3.55735 iter/s, 28.1108s/100 iters), loss = 0.000261429
I0526 23:12:54.773437 30701 solver.cpp:237]     Train net output #0: loss = 0.000259533 (* 1 = 0.000259533 loss)
I0526 23:12:54.773447 30701 sgd_solver.cpp:105] Iteration 91900, lr = 0.005405
I0526 23:13:22.597182 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_92000.caffemodel
I0526 23:13:22.951640 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_92000.solverstate
I0526 23:13:23.101799 30701 solver.cpp:330] Iteration 92000, Testing net (#0)
I0526 23:13:24.319556 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:13:26.063254 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0526 23:13:26.063308 30701 solver.cpp:397]     Test net output #1: loss = 0.921133 (* 1 = 0.921133 loss)
I0526 23:13:26.341631 30701 solver.cpp:218] Iteration 92000 (3.16781 iter/s, 31.5676s/100 iters), loss = 0.000312456
I0526 23:13:26.341678 30701 solver.cpp:237]     Train net output #0: loss = 0.000310561 (* 1 = 0.000310561 loss)
I0526 23:13:26.341687 30701 sgd_solver.cpp:105] Iteration 92000, lr = 0.0054
I0526 23:13:54.415506 30701 solver.cpp:218] Iteration 92100 (3.56211 iter/s, 28.0733s/100 iters), loss = 0.0251881
I0526 23:13:54.415745 30701 solver.cpp:237]     Train net output #0: loss = 0.0251863 (* 1 = 0.0251863 loss)
I0526 23:13:54.415760 30701 sgd_solver.cpp:105] Iteration 92100, lr = 0.005395
I0526 23:14:22.495848 30701 solver.cpp:218] Iteration 92200 (3.56131 iter/s, 28.0796s/100 iters), loss = 0.000154592
I0526 23:14:22.495896 30701 solver.cpp:237]     Train net output #0: loss = 0.000152702 (* 1 = 0.000152702 loss)
I0526 23:14:22.495918 30701 sgd_solver.cpp:105] Iteration 92200, lr = 0.00539
I0526 23:14:26.725597 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:14:50.585337 30701 solver.cpp:218] Iteration 92300 (3.56013 iter/s, 28.0889s/100 iters), loss = 0.000255622
I0526 23:14:50.585382 30701 solver.cpp:237]     Train net output #0: loss = 0.00025374 (* 1 = 0.00025374 loss)
I0526 23:14:50.585391 30701 sgd_solver.cpp:105] Iteration 92300, lr = 0.005385
I0526 23:15:18.694245 30701 solver.cpp:218] Iteration 92400 (3.55767 iter/s, 28.1083s/100 iters), loss = 5.77038e-05
I0526 23:15:18.694471 30701 solver.cpp:237]     Train net output #0: loss = 5.58206e-05 (* 1 = 5.58206e-05 loss)
I0526 23:15:18.694483 30701 sgd_solver.cpp:105] Iteration 92400, lr = 0.00538
I0526 23:15:46.829823 30701 solver.cpp:218] Iteration 92500 (3.55432 iter/s, 28.1348s/100 iters), loss = 0.000234394
I0526 23:15:46.829869 30701 solver.cpp:237]     Train net output #0: loss = 0.000232508 (* 1 = 0.000232508 loss)
I0526 23:15:46.829879 30701 sgd_solver.cpp:105] Iteration 92500, lr = 0.005375
I0526 23:16:14.942824 30701 solver.cpp:218] Iteration 92600 (3.55715 iter/s, 28.1124s/100 iters), loss = 0.00100625
I0526 23:16:14.942945 30701 solver.cpp:237]     Train net output #0: loss = 0.00100436 (* 1 = 0.00100436 loss)
I0526 23:16:14.942955 30701 sgd_solver.cpp:105] Iteration 92600, lr = 0.00537
I0526 23:16:43.050961 30701 solver.cpp:218] Iteration 92700 (3.55778 iter/s, 28.1074s/100 iters), loss = 0.00153799
I0526 23:16:43.051007 30701 solver.cpp:237]     Train net output #0: loss = 0.00153607 (* 1 = 0.00153607 loss)
I0526 23:16:43.051015 30701 sgd_solver.cpp:105] Iteration 92700, lr = 0.005365
I0526 23:17:11.168648 30701 solver.cpp:218] Iteration 92800 (3.55656 iter/s, 28.1171s/100 iters), loss = 0.00109217
I0526 23:17:11.168812 30701 solver.cpp:237]     Train net output #0: loss = 0.00109025 (* 1 = 0.00109025 loss)
I0526 23:17:11.168823 30701 sgd_solver.cpp:105] Iteration 92800, lr = 0.00536
I0526 23:17:12.873986 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:17:39.292278 30701 solver.cpp:218] Iteration 92900 (3.55582 iter/s, 28.1229s/100 iters), loss = 0.0122724
I0526 23:17:39.292320 30701 solver.cpp:237]     Train net output #0: loss = 0.0122705 (* 1 = 0.0122705 loss)
I0526 23:17:39.292328 30701 sgd_solver.cpp:105] Iteration 92900, lr = 0.005355
I0526 23:18:07.139153 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_93000.caffemodel
I0526 23:18:07.458077 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_93000.solverstate
I0526 23:18:07.611317 30701 solver.cpp:330] Iteration 93000, Testing net (#0)
I0526 23:18:10.565225 30701 solver.cpp:397]     Test net output #0: accuracy = 0.774
I0526 23:18:10.565277 30701 solver.cpp:397]     Test net output #1: loss = 1.18174 (* 1 = 1.18174 loss)
I0526 23:18:10.844900 30701 solver.cpp:218] Iteration 93000 (3.16938 iter/s, 31.5519s/100 iters), loss = 0.000234362
I0526 23:18:10.844945 30701 solver.cpp:237]     Train net output #0: loss = 0.000232442 (* 1 = 0.000232442 loss)
I0526 23:18:10.844954 30701 sgd_solver.cpp:105] Iteration 93000, lr = 0.00535
I0526 23:18:38.963016 30701 solver.cpp:218] Iteration 93100 (3.55651 iter/s, 28.1175s/100 iters), loss = 0.00783323
I0526 23:18:38.963227 30701 solver.cpp:237]     Train net output #0: loss = 0.00783131 (* 1 = 0.00783131 loss)
I0526 23:18:38.963238 30701 sgd_solver.cpp:105] Iteration 93100, lr = 0.005345
I0526 23:19:07.079265 30701 solver.cpp:218] Iteration 93200 (3.55676 iter/s, 28.1155s/100 iters), loss = 0.00186288
I0526 23:19:07.079316 30701 solver.cpp:237]     Train net output #0: loss = 0.00186096 (* 1 = 0.00186096 loss)
I0526 23:19:07.079339 30701 sgd_solver.cpp:105] Iteration 93200, lr = 0.00534
I0526 23:19:35.193836 30701 solver.cpp:218] Iteration 93300 (3.55695 iter/s, 28.1139s/100 iters), loss = 0.000101328
I0526 23:19:35.194005 30701 solver.cpp:237]     Train net output #0: loss = 9.94005e-05 (* 1 = 9.94005e-05 loss)
I0526 23:19:35.194016 30701 sgd_solver.cpp:105] Iteration 93300, lr = 0.005335
I0526 23:20:02.491811 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:20:03.317978 30701 solver.cpp:218] Iteration 93400 (3.55576 iter/s, 28.1234s/100 iters), loss = 0.00427387
I0526 23:20:03.318022 30701 solver.cpp:237]     Train net output #0: loss = 0.00427195 (* 1 = 0.00427195 loss)
I0526 23:20:03.318032 30701 sgd_solver.cpp:105] Iteration 93400, lr = 0.00533
I0526 23:20:31.445148 30701 solver.cpp:218] Iteration 93500 (3.55536 iter/s, 28.1265s/100 iters), loss = 0.000977709
I0526 23:20:31.445320 30701 solver.cpp:237]     Train net output #0: loss = 0.000975807 (* 1 = 0.000975807 loss)
I0526 23:20:31.445332 30701 sgd_solver.cpp:105] Iteration 93500, lr = 0.005325
I0526 23:20:59.562635 30701 solver.cpp:218] Iteration 93600 (3.5566 iter/s, 28.1167s/100 iters), loss = 0.000324284
I0526 23:20:59.562680 30701 solver.cpp:237]     Train net output #0: loss = 0.00032238 (* 1 = 0.00032238 loss)
I0526 23:20:59.562690 30701 sgd_solver.cpp:105] Iteration 93600, lr = 0.00532
I0526 23:21:27.678042 30701 solver.cpp:218] Iteration 93700 (3.55685 iter/s, 28.1148s/100 iters), loss = 0.000280543
I0526 23:21:27.678241 30701 solver.cpp:237]     Train net output #0: loss = 0.000278635 (* 1 = 0.000278635 loss)
I0526 23:21:27.678268 30701 sgd_solver.cpp:105] Iteration 93700, lr = 0.005315
I0526 23:21:55.777577 30701 solver.cpp:218] Iteration 93800 (3.55887 iter/s, 28.0988s/100 iters), loss = 0.00174475
I0526 23:21:55.777623 30701 solver.cpp:237]     Train net output #0: loss = 0.00174284 (* 1 = 0.00174284 loss)
I0526 23:21:55.777632 30701 sgd_solver.cpp:105] Iteration 93800, lr = 0.00531
I0526 23:22:23.874011 30701 solver.cpp:218] Iteration 93900 (3.55925 iter/s, 28.0958s/100 iters), loss = 0.000816234
I0526 23:22:23.874181 30701 solver.cpp:237]     Train net output #0: loss = 0.000814328 (* 1 = 0.000814328 loss)
I0526 23:22:23.874192 30701 sgd_solver.cpp:105] Iteration 93900, lr = 0.005305
I0526 23:22:48.648542 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:22:51.735749 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_94000.caffemodel
I0526 23:22:52.060736 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_94000.solverstate
I0526 23:22:52.212055 30701 solver.cpp:330] Iteration 94000, Testing net (#0)
I0526 23:22:55.116868 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:22:55.175485 30701 solver.cpp:397]     Test net output #0: accuracy = 0.814
I0526 23:22:55.175530 30701 solver.cpp:397]     Test net output #1: loss = 0.84022 (* 1 = 0.84022 loss)
I0526 23:22:55.453618 30701 solver.cpp:218] Iteration 94000 (3.16668 iter/s, 31.5788s/100 iters), loss = 0.000124924
I0526 23:22:55.453663 30701 solver.cpp:237]     Train net output #0: loss = 0.000123017 (* 1 = 0.000123017 loss)
I0526 23:22:55.453672 30701 sgd_solver.cpp:105] Iteration 94000, lr = 0.0053
I0526 23:23:23.585595 30701 solver.cpp:218] Iteration 94100 (3.55475 iter/s, 28.1313s/100 iters), loss = 0.00022951
I0526 23:23:23.585640 30701 solver.cpp:237]     Train net output #0: loss = 0.000227603 (* 1 = 0.000227603 loss)
I0526 23:23:23.585649 30701 sgd_solver.cpp:105] Iteration 94100, lr = 0.005295
I0526 23:23:51.695719 30701 solver.cpp:218] Iteration 94200 (3.55752 iter/s, 28.1095s/100 iters), loss = 0.000250702
I0526 23:23:51.695889 30701 solver.cpp:237]     Train net output #0: loss = 0.000248797 (* 1 = 0.000248797 loss)
I0526 23:23:51.695901 30701 sgd_solver.cpp:105] Iteration 94200, lr = 0.00529
I0526 23:24:19.791602 30701 solver.cpp:218] Iteration 94300 (3.55934 iter/s, 28.0951s/100 iters), loss = 0.000739877
I0526 23:24:19.791651 30701 solver.cpp:237]     Train net output #0: loss = 0.000737973 (* 1 = 0.000737973 loss)
I0526 23:24:19.791661 30701 sgd_solver.cpp:105] Iteration 94300, lr = 0.005285
I0526 23:24:47.937737 30701 solver.cpp:218] Iteration 94400 (3.55297 iter/s, 28.1455s/100 iters), loss = 0.000279342
I0526 23:24:47.937939 30701 solver.cpp:237]     Train net output #0: loss = 0.000277438 (* 1 = 0.000277438 loss)
I0526 23:24:47.937953 30701 sgd_solver.cpp:105] Iteration 94400, lr = 0.00528
I0526 23:25:16.057735 30701 solver.cpp:218] Iteration 94500 (3.55629 iter/s, 28.1192s/100 iters), loss = 0.00177796
I0526 23:25:16.057780 30701 solver.cpp:237]     Train net output #0: loss = 0.00177605 (* 1 = 0.00177605 loss)
I0526 23:25:16.057788 30701 sgd_solver.cpp:105] Iteration 94500, lr = 0.005275
I0526 23:25:38.292853 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:25:44.182096 30701 solver.cpp:218] Iteration 94600 (3.55572 iter/s, 28.1237s/100 iters), loss = 0.000289926
I0526 23:25:44.182143 30701 solver.cpp:237]     Train net output #0: loss = 0.00028802 (* 1 = 0.00028802 loss)
I0526 23:25:44.182152 30701 sgd_solver.cpp:105] Iteration 94600, lr = 0.00527
I0526 23:26:12.306254 30701 solver.cpp:218] Iteration 94700 (3.55574 iter/s, 28.1235s/100 iters), loss = 0.00574305
I0526 23:26:12.306414 30701 solver.cpp:237]     Train net output #0: loss = 0.00574115 (* 1 = 0.00574115 loss)
I0526 23:26:12.306426 30701 sgd_solver.cpp:105] Iteration 94700, lr = 0.005265
I0526 23:26:40.401803 30701 solver.cpp:218] Iteration 94800 (3.55938 iter/s, 28.0948s/100 iters), loss = 0.0426245
I0526 23:26:40.401851 30701 solver.cpp:237]     Train net output #0: loss = 0.0426226 (* 1 = 0.0426226 loss)
I0526 23:26:40.401859 30701 sgd_solver.cpp:105] Iteration 94800, lr = 0.00526
I0526 23:27:08.480078 30701 solver.cpp:218] Iteration 94900 (3.56155 iter/s, 28.0776s/100 iters), loss = 0.000202651
I0526 23:27:08.480352 30701 solver.cpp:237]     Train net output #0: loss = 0.000200748 (* 1 = 0.000200748 loss)
I0526 23:27:08.480365 30701 sgd_solver.cpp:105] Iteration 94900, lr = 0.005255
I0526 23:27:36.276530 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_95000.caffemodel
I0526 23:27:36.598625 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_95000.solverstate
I0526 23:27:36.749251 30701 solver.cpp:330] Iteration 95000, Testing net (#0)
I0526 23:27:39.705727 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0526 23:27:39.705931 30701 solver.cpp:397]     Test net output #1: loss = 1.04605 (* 1 = 1.04605 loss)
I0526 23:27:39.983124 30701 solver.cpp:218] Iteration 95000 (3.17439 iter/s, 31.5021s/100 iters), loss = 0.000637949
I0526 23:27:39.983170 30701 solver.cpp:237]     Train net output #0: loss = 0.000636043 (* 1 = 0.000636043 loss)
I0526 23:27:39.983178 30701 sgd_solver.cpp:105] Iteration 95000, lr = 0.00525
I0526 23:28:08.075875 30701 solver.cpp:218] Iteration 95100 (3.55972 iter/s, 28.0921s/100 iters), loss = 0.00708674
I0526 23:28:08.075924 30701 solver.cpp:237]     Train net output #0: loss = 0.00708484 (* 1 = 0.00708484 loss)
I0526 23:28:08.075933 30701 sgd_solver.cpp:105] Iteration 95100, lr = 0.005245
I0526 23:28:28.051765 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:28:36.194201 30701 solver.cpp:218] Iteration 95200 (3.55648 iter/s, 28.1177s/100 iters), loss = 0.000189344
I0526 23:28:36.194245 30701 solver.cpp:237]     Train net output #0: loss = 0.00018744 (* 1 = 0.00018744 loss)
I0526 23:28:36.194254 30701 sgd_solver.cpp:105] Iteration 95200, lr = 0.00524
I0526 23:29:04.328455 30701 solver.cpp:218] Iteration 95300 (3.55447 iter/s, 28.1336s/100 iters), loss = 0.000129144
I0526 23:29:04.328626 30701 solver.cpp:237]     Train net output #0: loss = 0.000127237 (* 1 = 0.000127237 loss)
I0526 23:29:04.328639 30701 sgd_solver.cpp:105] Iteration 95300, lr = 0.005235
I0526 23:29:32.453588 30701 solver.cpp:218] Iteration 95400 (3.55563 iter/s, 28.1244s/100 iters), loss = 0.000200037
I0526 23:29:32.453632 30701 solver.cpp:237]     Train net output #0: loss = 0.000198133 (* 1 = 0.000198133 loss)
I0526 23:29:32.453641 30701 sgd_solver.cpp:105] Iteration 95400, lr = 0.00523
I0526 23:30:00.567412 30701 solver.cpp:218] Iteration 95500 (3.55705 iter/s, 28.1132s/100 iters), loss = 0.0020071
I0526 23:30:00.567662 30701 solver.cpp:237]     Train net output #0: loss = 0.0020052 (* 1 = 0.0020052 loss)
I0526 23:30:00.567673 30701 sgd_solver.cpp:105] Iteration 95500, lr = 0.005225
I0526 23:30:28.632743 30701 solver.cpp:218] Iteration 95600 (3.56322 iter/s, 28.0645s/100 iters), loss = 0.00034116
I0526 23:30:28.632800 30701 solver.cpp:237]     Train net output #0: loss = 0.000339258 (* 1 = 0.000339258 loss)
I0526 23:30:28.632809 30701 sgd_solver.cpp:105] Iteration 95600, lr = 0.00522
I0526 23:30:56.698043 30701 solver.cpp:218] Iteration 95700 (3.5632 iter/s, 28.0646s/100 iters), loss = 0.00133481
I0526 23:30:56.698210 30701 solver.cpp:237]     Train net output #0: loss = 0.00133291 (* 1 = 0.00133291 loss)
I0526 23:30:56.698225 30701 sgd_solver.cpp:105] Iteration 95700, lr = 0.005215
I0526 23:31:14.131252 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:31:24.779580 30701 solver.cpp:218] Iteration 95800 (3.56115 iter/s, 28.0808s/100 iters), loss = 0.00303671
I0526 23:31:24.779626 30701 solver.cpp:237]     Train net output #0: loss = 0.0030348 (* 1 = 0.0030348 loss)
I0526 23:31:24.779635 30701 sgd_solver.cpp:105] Iteration 95800, lr = 0.00521
I0526 23:31:52.895408 30701 solver.cpp:218] Iteration 95900 (3.5568 iter/s, 28.1152s/100 iters), loss = 0.000349707
I0526 23:31:52.895613 30701 solver.cpp:237]     Train net output #0: loss = 0.000347807 (* 1 = 0.000347807 loss)
I0526 23:31:52.895625 30701 sgd_solver.cpp:105] Iteration 95900, lr = 0.005205
I0526 23:32:20.707914 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_96000.caffemodel
I0526 23:32:21.031090 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_96000.solverstate
I0526 23:32:21.187515 30701 solver.cpp:330] Iteration 96000, Testing net (#0)
I0526 23:32:24.144716 30701 solver.cpp:397]     Test net output #0: accuracy = 0.788
I0526 23:32:24.144845 30701 solver.cpp:397]     Test net output #1: loss = 1.13956 (* 1 = 1.13956 loss)
I0526 23:32:24.422824 30701 solver.cpp:218] Iteration 96000 (3.17193 iter/s, 31.5266s/100 iters), loss = 0.000725858
I0526 23:32:24.422870 30701 solver.cpp:237]     Train net output #0: loss = 0.000723958 (* 1 = 0.000723958 loss)
I0526 23:32:24.422890 30701 sgd_solver.cpp:105] Iteration 96000, lr = 0.0052
I0526 23:32:52.538514 30701 solver.cpp:218] Iteration 96100 (3.55681 iter/s, 28.115s/100 iters), loss = 0.000684237
I0526 23:32:52.538561 30701 solver.cpp:237]     Train net output #0: loss = 0.000682339 (* 1 = 0.000682339 loss)
I0526 23:32:52.538585 30701 sgd_solver.cpp:105] Iteration 96100, lr = 0.005195
I0526 23:33:20.654685 30701 solver.cpp:218] Iteration 96200 (3.55675 iter/s, 28.1155s/100 iters), loss = 6.52259e-05
I0526 23:33:20.654847 30701 solver.cpp:237]     Train net output #0: loss = 6.33311e-05 (* 1 = 6.33311e-05 loss)
I0526 23:33:20.654860 30701 sgd_solver.cpp:105] Iteration 96200, lr = 0.00519
I0526 23:33:48.774899 30701 solver.cpp:218] Iteration 96300 (3.55626 iter/s, 28.1195s/100 iters), loss = 0.000289574
I0526 23:33:48.774943 30701 solver.cpp:237]     Train net output #0: loss = 0.000287678 (* 1 = 0.000287678 loss)
I0526 23:33:48.774965 30701 sgd_solver.cpp:105] Iteration 96300, lr = 0.005185
I0526 23:34:03.698145 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:34:16.903888 30701 solver.cpp:218] Iteration 96400 (3.55513 iter/s, 28.1283s/100 iters), loss = 0.000671271
I0526 23:34:16.903939 30701 solver.cpp:237]     Train net output #0: loss = 0.000669374 (* 1 = 0.000669374 loss)
I0526 23:34:16.903955 30701 sgd_solver.cpp:105] Iteration 96400, lr = 0.00518
I0526 23:34:44.975342 30701 solver.cpp:218] Iteration 96500 (3.56242 iter/s, 28.0708s/100 iters), loss = 0.000296802
I0526 23:34:44.975503 30701 solver.cpp:237]     Train net output #0: loss = 0.000294906 (* 1 = 0.000294906 loss)
I0526 23:34:44.975513 30701 sgd_solver.cpp:105] Iteration 96500, lr = 0.005175
I0526 23:35:13.044059 30701 solver.cpp:218] Iteration 96600 (3.56278 iter/s, 28.068s/100 iters), loss = 0.000428495
I0526 23:35:13.044116 30701 solver.cpp:237]     Train net output #0: loss = 0.000426597 (* 1 = 0.000426597 loss)
I0526 23:35:13.044124 30701 sgd_solver.cpp:105] Iteration 96600, lr = 0.00517
I0526 23:35:41.103884 30701 solver.cpp:218] Iteration 96700 (3.5639 iter/s, 28.0592s/100 iters), loss = 0.000989343
I0526 23:35:41.104064 30701 solver.cpp:237]     Train net output #0: loss = 0.000987446 (* 1 = 0.000987446 loss)
I0526 23:35:41.104075 30701 sgd_solver.cpp:105] Iteration 96700, lr = 0.005165
I0526 23:36:09.177052 30701 solver.cpp:218] Iteration 96800 (3.56222 iter/s, 28.0724s/100 iters), loss = 0.00157378
I0526 23:36:09.177096 30701 solver.cpp:237]     Train net output #0: loss = 0.00157188 (* 1 = 0.00157188 loss)
I0526 23:36:09.177105 30701 sgd_solver.cpp:105] Iteration 96800, lr = 0.00516
I0526 23:36:37.250067 30701 solver.cpp:218] Iteration 96900 (3.56222 iter/s, 28.0724s/100 iters), loss = 0.000106461
I0526 23:36:37.250226 30701 solver.cpp:237]     Train net output #0: loss = 0.000104563 (* 1 = 0.000104563 loss)
I0526 23:36:37.250237 30701 sgd_solver.cpp:105] Iteration 96900, lr = 0.005155
I0526 23:36:49.611321 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:37:05.029078 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_97000.caffemodel
I0526 23:37:05.342559 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_97000.solverstate
I0526 23:37:05.494026 30701 solver.cpp:330] Iteration 97000, Testing net (#0)
I0526 23:37:07.125851 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:37:08.455803 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0526 23:37:08.455994 30701 solver.cpp:397]     Test net output #1: loss = 0.874417 (* 1 = 0.874417 loss)
I0526 23:37:08.733409 30701 solver.cpp:218] Iteration 97000 (3.17637 iter/s, 31.4825s/100 iters), loss = 0.000590452
I0526 23:37:08.733454 30701 solver.cpp:237]     Train net output #0: loss = 0.000588555 (* 1 = 0.000588555 loss)
I0526 23:37:08.733464 30701 sgd_solver.cpp:105] Iteration 97000, lr = 0.00515
I0526 23:37:36.832078 30701 solver.cpp:218] Iteration 97100 (3.55897 iter/s, 28.098s/100 iters), loss = 0.00176962
I0526 23:37:36.832124 30701 solver.cpp:237]     Train net output #0: loss = 0.00176772 (* 1 = 0.00176772 loss)
I0526 23:37:36.832132 30701 sgd_solver.cpp:105] Iteration 97100, lr = 0.005145
I0526 23:38:04.933789 30701 solver.cpp:218] Iteration 97200 (3.55865 iter/s, 28.1005s/100 iters), loss = 0.00048994
I0526 23:38:04.933977 30701 solver.cpp:237]     Train net output #0: loss = 0.000488043 (* 1 = 0.000488043 loss)
I0526 23:38:04.934000 30701 sgd_solver.cpp:105] Iteration 97200, lr = 0.00514
I0526 23:38:33.042096 30701 solver.cpp:218] Iteration 97300 (3.55784 iter/s, 28.1069s/100 iters), loss = 0.000537384
I0526 23:38:33.042141 30701 solver.cpp:237]     Train net output #0: loss = 0.000535487 (* 1 = 0.000535487 loss)
I0526 23:38:33.042150 30701 sgd_solver.cpp:105] Iteration 97300, lr = 0.005135
I0526 23:39:01.170989 30701 solver.cpp:218] Iteration 97400 (3.55522 iter/s, 28.1277s/100 iters), loss = 0.000210763
I0526 23:39:01.171180 30701 solver.cpp:237]     Train net output #0: loss = 0.000208866 (* 1 = 0.000208866 loss)
I0526 23:39:01.171190 30701 sgd_solver.cpp:105] Iteration 97400, lr = 0.00513
I0526 23:39:29.291273 30701 solver.cpp:218] Iteration 97500 (3.55632 iter/s, 28.1189s/100 iters), loss = 0.000289148
I0526 23:39:29.291321 30701 solver.cpp:237]     Train net output #0: loss = 0.000287251 (* 1 = 0.000287251 loss)
I0526 23:39:29.291342 30701 sgd_solver.cpp:105] Iteration 97500, lr = 0.005125
I0526 23:39:39.151916 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:39:57.402922 30701 solver.cpp:218] Iteration 97600 (3.55739 iter/s, 28.1105s/100 iters), loss = 0.000221085
I0526 23:39:57.402966 30701 solver.cpp:237]     Train net output #0: loss = 0.000219189 (* 1 = 0.000219189 loss)
I0526 23:39:57.402976 30701 sgd_solver.cpp:105] Iteration 97600, lr = 0.00512
I0526 23:40:25.509302 30701 solver.cpp:218] Iteration 97700 (3.55806 iter/s, 28.1052s/100 iters), loss = 0.000208985
I0526 23:40:25.509536 30701 solver.cpp:237]     Train net output #0: loss = 0.000207089 (* 1 = 0.000207089 loss)
I0526 23:40:25.509547 30701 sgd_solver.cpp:105] Iteration 97700, lr = 0.005115
I0526 23:40:53.559520 30701 solver.cpp:218] Iteration 97800 (3.5652 iter/s, 28.0489s/100 iters), loss = 0.00010511
I0526 23:40:53.559566 30701 solver.cpp:237]     Train net output #0: loss = 0.000103214 (* 1 = 0.000103214 loss)
I0526 23:40:53.559576 30701 sgd_solver.cpp:105] Iteration 97800, lr = 0.00511
I0526 23:41:21.621680 30701 solver.cpp:218] Iteration 97900 (3.56366 iter/s, 28.0611s/100 iters), loss = 0.000230149
I0526 23:41:21.621899 30701 solver.cpp:237]     Train net output #0: loss = 0.000228253 (* 1 = 0.000228253 loss)
I0526 23:41:21.621912 30701 sgd_solver.cpp:105] Iteration 97900, lr = 0.005105
I0526 23:41:49.416817 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_98000.caffemodel
I0526 23:41:49.737383 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_98000.solverstate
I0526 23:41:49.888227 30701 solver.cpp:330] Iteration 98000, Testing net (#0)
I0526 23:41:52.847517 30701 solver.cpp:397]     Test net output #0: accuracy = 0.818
I0526 23:41:52.847661 30701 solver.cpp:397]     Test net output #1: loss = 0.98783 (* 1 = 0.98783 loss)
I0526 23:41:53.125589 30701 solver.cpp:218] Iteration 98000 (3.17435 iter/s, 31.5025s/100 iters), loss = 0.000129909
I0526 23:41:53.125634 30701 solver.cpp:237]     Train net output #0: loss = 0.000128014 (* 1 = 0.000128014 loss)
I0526 23:41:53.125643 30701 sgd_solver.cpp:105] Iteration 98000, lr = 0.0051
I0526 23:42:21.248646 30701 solver.cpp:218] Iteration 98100 (3.55594 iter/s, 28.122s/100 iters), loss = 0.000123905
I0526 23:42:21.248692 30701 solver.cpp:237]     Train net output #0: loss = 0.000122011 (* 1 = 0.000122011 loss)
I0526 23:42:21.248702 30701 sgd_solver.cpp:105] Iteration 98100, lr = 0.005095
I0526 23:42:28.579603 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:42:49.383383 30701 solver.cpp:218] Iteration 98200 (3.55446 iter/s, 28.1337s/100 iters), loss = 8.56084e-05
I0526 23:42:49.383430 30701 solver.cpp:237]     Train net output #0: loss = 8.37135e-05 (* 1 = 8.37135e-05 loss)
I0526 23:42:49.383438 30701 sgd_solver.cpp:105] Iteration 98200, lr = 0.00509
I0526 23:43:17.513195 30701 solver.cpp:218] Iteration 98300 (3.55508 iter/s, 28.1288s/100 iters), loss = 9.60752e-05
I0526 23:43:17.513401 30701 solver.cpp:237]     Train net output #0: loss = 9.4183e-05 (* 1 = 9.4183e-05 loss)
I0526 23:43:17.513412 30701 sgd_solver.cpp:105] Iteration 98300, lr = 0.005085
I0526 23:43:45.636644 30701 solver.cpp:218] Iteration 98400 (3.5559 iter/s, 28.1223s/100 iters), loss = 0.000184497
I0526 23:43:45.636703 30701 solver.cpp:237]     Train net output #0: loss = 0.000182606 (* 1 = 0.000182606 loss)
I0526 23:43:45.636711 30701 sgd_solver.cpp:105] Iteration 98400, lr = 0.00508
I0526 23:44:13.773998 30701 solver.cpp:218] Iteration 98500 (3.55412 iter/s, 28.1363s/100 iters), loss = 0.000482678
I0526 23:44:13.774217 30701 solver.cpp:237]     Train net output #0: loss = 0.000480787 (* 1 = 0.000480787 loss)
I0526 23:44:13.774230 30701 sgd_solver.cpp:105] Iteration 98500, lr = 0.005075
I0526 23:44:41.909651 30701 solver.cpp:218] Iteration 98600 (3.55436 iter/s, 28.1345s/100 iters), loss = 0.00146474
I0526 23:44:41.909696 30701 solver.cpp:237]     Train net output #0: loss = 0.00146285 (* 1 = 0.00146285 loss)
I0526 23:44:41.909705 30701 sgd_solver.cpp:105] Iteration 98600, lr = 0.00507
I0526 23:45:10.043655 30701 solver.cpp:218] Iteration 98700 (3.55454 iter/s, 28.133s/100 iters), loss = 0.000266056
I0526 23:45:10.043925 30701 solver.cpp:237]     Train net output #0: loss = 0.000264163 (* 1 = 0.000264163 loss)
I0526 23:45:10.043936 30701 sgd_solver.cpp:105] Iteration 98700, lr = 0.005065
I0526 23:45:15.109809 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:45:38.104526 30701 solver.cpp:218] Iteration 98800 (3.56383 iter/s, 28.0597s/100 iters), loss = 1.4356e-05
I0526 23:45:38.104571 30701 solver.cpp:237]     Train net output #0: loss = 1.24637e-05 (* 1 = 1.24637e-05 loss)
I0526 23:45:38.104593 30701 sgd_solver.cpp:105] Iteration 98800, lr = 0.00506
I0526 23:46:06.172091 30701 solver.cpp:218] Iteration 98900 (3.56295 iter/s, 28.0666s/100 iters), loss = 0.00111762
I0526 23:46:06.172298 30701 solver.cpp:237]     Train net output #0: loss = 0.00111572 (* 1 = 0.00111572 loss)
I0526 23:46:06.172313 30701 sgd_solver.cpp:105] Iteration 98900, lr = 0.005055
I0526 23:46:33.952211 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_99000.caffemodel
I0526 23:46:34.272122 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_99000.solverstate
I0526 23:46:34.423971 30701 solver.cpp:330] Iteration 99000, Testing net (#0)
I0526 23:46:37.385009 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0526 23:46:37.385169 30701 solver.cpp:397]     Test net output #1: loss = 0.967805 (* 1 = 0.967805 loss)
I0526 23:46:37.662333 30701 solver.cpp:218] Iteration 99000 (3.17571 iter/s, 31.4891s/100 iters), loss = 5.82323e-05
I0526 23:46:37.662379 30701 solver.cpp:237]     Train net output #0: loss = 5.63403e-05 (* 1 = 5.63403e-05 loss)
I0526 23:46:37.662386 30701 sgd_solver.cpp:105] Iteration 99000, lr = 0.00505
I0526 23:47:05.798955 30701 solver.cpp:218] Iteration 99100 (3.5542 iter/s, 28.1357s/100 iters), loss = 0.000432848
I0526 23:47:05.799000 30701 solver.cpp:237]     Train net output #0: loss = 0.000430956 (* 1 = 0.000430956 loss)
I0526 23:47:05.799010 30701 sgd_solver.cpp:105] Iteration 99100, lr = 0.005045
I0526 23:47:33.897266 30701 solver.cpp:218] Iteration 99200 (3.55905 iter/s, 28.0974s/100 iters), loss = 0.0028292
I0526 23:47:33.897482 30701 solver.cpp:237]     Train net output #0: loss = 0.00282731 (* 1 = 0.00282731 loss)
I0526 23:47:33.897493 30701 sgd_solver.cpp:105] Iteration 99200, lr = 0.00504
I0526 23:48:01.962254 30701 solver.cpp:218] Iteration 99300 (3.5633 iter/s, 28.0639s/100 iters), loss = 0.000164032
I0526 23:48:01.962299 30701 solver.cpp:237]     Train net output #0: loss = 0.00016214 (* 1 = 0.00016214 loss)
I0526 23:48:01.962308 30701 sgd_solver.cpp:105] Iteration 99300, lr = 0.005035
I0526 23:48:04.503159 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:48:30.019652 30701 solver.cpp:218] Iteration 99400 (3.56424 iter/s, 28.0565s/100 iters), loss = 0.000210082
I0526 23:48:30.019708 30701 solver.cpp:237]     Train net output #0: loss = 0.000208189 (* 1 = 0.000208189 loss)
I0526 23:48:30.019717 30701 sgd_solver.cpp:105] Iteration 99400, lr = 0.00503
I0526 23:48:58.094010 30701 solver.cpp:218] Iteration 99500 (3.56208 iter/s, 28.0735s/100 iters), loss = 0.000378936
I0526 23:48:58.094168 30701 solver.cpp:237]     Train net output #0: loss = 0.000377043 (* 1 = 0.000377043 loss)
I0526 23:48:58.094180 30701 sgd_solver.cpp:105] Iteration 99500, lr = 0.005025
I0526 23:49:26.164149 30701 solver.cpp:218] Iteration 99600 (3.56263 iter/s, 28.0691s/100 iters), loss = 0.000451584
I0526 23:49:26.164206 30701 solver.cpp:237]     Train net output #0: loss = 0.000449693 (* 1 = 0.000449693 loss)
I0526 23:49:26.164214 30701 sgd_solver.cpp:105] Iteration 99600, lr = 0.00502
I0526 23:49:54.238055 30701 solver.cpp:218] Iteration 99700 (3.56214 iter/s, 28.073s/100 iters), loss = 0.000163352
I0526 23:49:54.238219 30701 solver.cpp:237]     Train net output #0: loss = 0.00016146 (* 1 = 0.00016146 loss)
I0526 23:49:54.238230 30701 sgd_solver.cpp:105] Iteration 99700, lr = 0.005015
I0526 23:50:22.357882 30701 solver.cpp:218] Iteration 99800 (3.55633 iter/s, 28.1188s/100 iters), loss = 4.56418e-05
I0526 23:50:22.357928 30701 solver.cpp:237]     Train net output #0: loss = 4.37484e-05 (* 1 = 4.37484e-05 loss)
I0526 23:50:22.357935 30701 sgd_solver.cpp:105] Iteration 99800, lr = 0.00501
I0526 23:50:50.472800 30701 solver.cpp:218] Iteration 99900 (3.55694 iter/s, 28.1141s/100 iters), loss = 0.000804023
I0526 23:50:50.472981 30701 solver.cpp:237]     Train net output #0: loss = 0.00080213 (* 1 = 0.00080213 loss)
I0526 23:50:50.472992 30701 sgd_solver.cpp:105] Iteration 99900, lr = 0.005005
I0526 23:50:50.489639 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:51:18.305804 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_100000.caffemodel
I0526 23:51:18.620095 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_100000.solverstate
I0526 23:51:18.770900 30701 solver.cpp:330] Iteration 100000, Testing net (#0)
I0526 23:51:19.129696 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:51:21.731403 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0526 23:51:21.731560 30701 solver.cpp:397]     Test net output #1: loss = 0.973476 (* 1 = 0.973476 loss)
I0526 23:51:22.009346 30701 solver.cpp:218] Iteration 100000 (3.17103 iter/s, 31.5355s/100 iters), loss = 1.99603e-05
I0526 23:51:22.009392 30701 solver.cpp:237]     Train net output #0: loss = 1.80667e-05 (* 1 = 1.80667e-05 loss)
I0526 23:51:22.009402 30701 sgd_solver.cpp:105] Iteration 100000, lr = 0.005
I0526 23:51:50.082608 30701 solver.cpp:218] Iteration 100100 (3.56222 iter/s, 28.0724s/100 iters), loss = 5.94162e-05
I0526 23:51:50.082653 30701 solver.cpp:237]     Train net output #0: loss = 5.75217e-05 (* 1 = 5.75217e-05 loss)
I0526 23:51:50.082661 30701 sgd_solver.cpp:105] Iteration 100100, lr = 0.004995
I0526 23:52:18.170202 30701 solver.cpp:218] Iteration 100200 (3.5604 iter/s, 28.0867s/100 iters), loss = 0.000208451
I0526 23:52:18.170428 30701 solver.cpp:237]     Train net output #0: loss = 0.000206556 (* 1 = 0.000206556 loss)
I0526 23:52:18.170439 30701 sgd_solver.cpp:105] Iteration 100200, lr = 0.00499
I0526 23:52:46.277346 30701 solver.cpp:218] Iteration 100300 (3.55794 iter/s, 28.1061s/100 iters), loss = 0.00077929
I0526 23:52:46.277403 30701 solver.cpp:237]     Train net output #0: loss = 0.000777394 (* 1 = 0.000777394 loss)
I0526 23:52:46.277412 30701 sgd_solver.cpp:105] Iteration 100300, lr = 0.004985
I0526 23:53:14.385453 30701 solver.cpp:218] Iteration 100400 (3.5578 iter/s, 28.1073s/100 iters), loss = 0.000257391
I0526 23:53:14.385633 30701 solver.cpp:237]     Train net output #0: loss = 0.000255494 (* 1 = 0.000255494 loss)
I0526 23:53:14.385644 30701 sgd_solver.cpp:105] Iteration 100400, lr = 0.00498
I0526 23:53:39.968991 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:53:42.481904 30701 solver.cpp:218] Iteration 100500 (3.55929 iter/s, 28.0955s/100 iters), loss = 0.000207365
I0526 23:53:42.481948 30701 solver.cpp:237]     Train net output #0: loss = 0.00020547 (* 1 = 0.00020547 loss)
I0526 23:53:42.481957 30701 sgd_solver.cpp:105] Iteration 100500, lr = 0.004975
I0526 23:54:10.581720 30701 solver.cpp:218] Iteration 100600 (3.55885 iter/s, 28.099s/100 iters), loss = 6.52811e-05
I0526 23:54:10.581925 30701 solver.cpp:237]     Train net output #0: loss = 6.33859e-05 (* 1 = 6.33859e-05 loss)
I0526 23:54:10.581940 30701 sgd_solver.cpp:105] Iteration 100600, lr = 0.00497
I0526 23:54:38.676281 30701 solver.cpp:218] Iteration 100700 (3.55953 iter/s, 28.0936s/100 iters), loss = 0.000283503
I0526 23:54:38.676327 30701 solver.cpp:237]     Train net output #0: loss = 0.000281608 (* 1 = 0.000281608 loss)
I0526 23:54:38.676336 30701 sgd_solver.cpp:105] Iteration 100700, lr = 0.004965
I0526 23:55:06.786247 30701 solver.cpp:218] Iteration 100800 (3.55756 iter/s, 28.1091s/100 iters), loss = 0.00076517
I0526 23:55:06.786383 30701 solver.cpp:237]     Train net output #0: loss = 0.000763277 (* 1 = 0.000763277 loss)
I0526 23:55:06.786394 30701 sgd_solver.cpp:105] Iteration 100800, lr = 0.00496
I0526 23:55:34.890943 30701 solver.cpp:218] Iteration 100900 (3.55824 iter/s, 28.1038s/100 iters), loss = 0.000431256
I0526 23:55:34.891005 30701 solver.cpp:237]     Train net output #0: loss = 0.000429362 (* 1 = 0.000429362 loss)
I0526 23:55:34.891013 30701 sgd_solver.cpp:105] Iteration 100900, lr = 0.004955
I0526 23:56:02.713135 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_101000.caffemodel
I0526 23:56:03.026892 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_101000.solverstate
I0526 23:56:03.177814 30701 solver.cpp:330] Iteration 101000, Testing net (#0)
I0526 23:56:06.134299 30701 solver.cpp:397]     Test net output #0: accuracy = 0.8
I0526 23:56:06.134341 30701 solver.cpp:397]     Test net output #1: loss = 1.01537 (* 1 = 1.01537 loss)
I0526 23:56:06.411898 30701 solver.cpp:218] Iteration 101000 (3.17259 iter/s, 31.52s/100 iters), loss = 0.000121825
I0526 23:56:06.411944 30701 solver.cpp:237]     Train net output #0: loss = 0.000119931 (* 1 = 0.000119931 loss)
I0526 23:56:06.411957 30701 sgd_solver.cpp:105] Iteration 101000, lr = 0.00495
I0526 23:56:29.485764 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:56:34.533643 30701 solver.cpp:218] Iteration 101100 (3.55607 iter/s, 28.1209s/100 iters), loss = 8.02167e-05
I0526 23:56:34.533814 30701 solver.cpp:237]     Train net output #0: loss = 7.83223e-05 (* 1 = 7.83223e-05 loss)
I0526 23:56:34.533825 30701 sgd_solver.cpp:105] Iteration 101100, lr = 0.004945
I0526 23:57:02.649238 30701 solver.cpp:218] Iteration 101200 (3.55686 iter/s, 28.1147s/100 iters), loss = 0.000198678
I0526 23:57:02.649286 30701 solver.cpp:237]     Train net output #0: loss = 0.000196784 (* 1 = 0.000196784 loss)
I0526 23:57:02.649296 30701 sgd_solver.cpp:105] Iteration 101200, lr = 0.00494
I0526 23:57:30.748939 30701 solver.cpp:218] Iteration 101300 (3.55886 iter/s, 28.0989s/100 iters), loss = 0.00255024
I0526 23:57:30.749078 30701 solver.cpp:237]     Train net output #0: loss = 0.00254835 (* 1 = 0.00254835 loss)
I0526 23:57:30.749101 30701 sgd_solver.cpp:105] Iteration 101300, lr = 0.004935
I0526 23:57:58.857089 30701 solver.cpp:218] Iteration 101400 (3.5578 iter/s, 28.1073s/100 iters), loss = 0.000104965
I0526 23:57:58.857131 30701 solver.cpp:237]     Train net output #0: loss = 0.000103071 (* 1 = 0.000103071 loss)
I0526 23:57:58.857141 30701 sgd_solver.cpp:105] Iteration 101400, lr = 0.00493
I0526 23:58:26.938890 30701 solver.cpp:218] Iteration 101500 (3.56113 iter/s, 28.081s/100 iters), loss = 0.000687573
I0526 23:58:26.939090 30701 solver.cpp:237]     Train net output #0: loss = 0.000685679 (* 1 = 0.000685679 loss)
I0526 23:58:26.939102 30701 sgd_solver.cpp:105] Iteration 101500, lr = 0.004925
I0526 23:58:55.028383 30701 solver.cpp:218] Iteration 101600 (3.56017 iter/s, 28.0886s/100 iters), loss = 0.000280768
I0526 23:58:55.028440 30701 solver.cpp:237]     Train net output #0: loss = 0.000278874 (* 1 = 0.000278874 loss)
I0526 23:58:55.028448 30701 sgd_solver.cpp:105] Iteration 101600, lr = 0.00492
I0526 23:59:15.577599 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0526 23:59:23.151429 30701 solver.cpp:218] Iteration 101700 (3.5559 iter/s, 28.1222s/100 iters), loss = 0.000267072
I0526 23:59:23.151474 30701 solver.cpp:237]     Train net output #0: loss = 0.000265177 (* 1 = 0.000265177 loss)
I0526 23:59:23.151484 30701 sgd_solver.cpp:105] Iteration 101700, lr = 0.004915
I0526 23:59:51.235306 30701 solver.cpp:218] Iteration 101800 (3.56086 iter/s, 28.0831s/100 iters), loss = 0.000561537
I0526 23:59:51.235460 30701 solver.cpp:237]     Train net output #0: loss = 0.000559643 (* 1 = 0.000559643 loss)
I0526 23:59:51.235471 30701 sgd_solver.cpp:105] Iteration 101800, lr = 0.00491
I0527 00:00:19.311282 30701 solver.cpp:218] Iteration 101900 (3.56188 iter/s, 28.0751s/100 iters), loss = 0.00198361
I0527 00:00:19.311339 30701 solver.cpp:237]     Train net output #0: loss = 0.00198172 (* 1 = 0.00198172 loss)
I0527 00:00:19.311348 30701 sgd_solver.cpp:105] Iteration 101900, lr = 0.004905
I0527 00:00:47.105981 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_102000.caffemodel
I0527 00:00:47.419700 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_102000.solverstate
I0527 00:00:47.571910 30701 solver.cpp:330] Iteration 102000, Testing net (#0)
I0527 00:00:49.586055 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:00:50.529570 30701 solver.cpp:397]     Test net output #0: accuracy = 0.824
I0527 00:00:50.529606 30701 solver.cpp:397]     Test net output #1: loss = 0.88738 (* 1 = 0.88738 loss)
I0527 00:00:50.806072 30701 solver.cpp:218] Iteration 102000 (3.17522 iter/s, 31.4939s/100 iters), loss = 0.000100888
I0527 00:00:50.806118 30701 solver.cpp:237]     Train net output #0: loss = 9.89935e-05 (* 1 = 9.89935e-05 loss)
I0527 00:00:50.806125 30701 sgd_solver.cpp:105] Iteration 102000, lr = 0.0049
I0527 00:01:18.898618 30701 solver.cpp:218] Iteration 102100 (3.55976 iter/s, 28.0918s/100 iters), loss = 0.00099402
I0527 00:01:18.898802 30701 solver.cpp:237]     Train net output #0: loss = 0.000992126 (* 1 = 0.000992126 loss)
I0527 00:01:18.898813 30701 sgd_solver.cpp:105] Iteration 102100, lr = 0.004895
I0527 00:01:46.968346 30701 solver.cpp:218] Iteration 102200 (3.56267 iter/s, 28.0688s/100 iters), loss = 0.000144388
I0527 00:01:46.968392 30701 solver.cpp:237]     Train net output #0: loss = 0.000142493 (* 1 = 0.000142493 loss)
I0527 00:01:46.968401 30701 sgd_solver.cpp:105] Iteration 102200, lr = 0.00489
I0527 00:02:04.957309 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:02:15.059047 30701 solver.cpp:218] Iteration 102300 (3.56 iter/s, 28.0899s/100 iters), loss = 2.64081e-05
I0527 00:02:15.059095 30701 solver.cpp:237]     Train net output #0: loss = 2.45139e-05 (* 1 = 2.45139e-05 loss)
I0527 00:02:15.059103 30701 sgd_solver.cpp:105] Iteration 102300, lr = 0.004885
I0527 00:02:43.174868 30701 solver.cpp:218] Iteration 102400 (3.55682 iter/s, 28.115s/100 iters), loss = 0.000520543
I0527 00:02:43.174993 30701 solver.cpp:237]     Train net output #0: loss = 0.000518649 (* 1 = 0.000518649 loss)
I0527 00:02:43.175004 30701 sgd_solver.cpp:105] Iteration 102400, lr = 0.00488
I0527 00:03:11.254356 30701 solver.cpp:218] Iteration 102500 (3.56143 iter/s, 28.0786s/100 iters), loss = 0.000172021
I0527 00:03:11.254401 30701 solver.cpp:237]     Train net output #0: loss = 0.000170127 (* 1 = 0.000170127 loss)
I0527 00:03:11.254410 30701 sgd_solver.cpp:105] Iteration 102500, lr = 0.004875
I0527 00:03:39.334661 30701 solver.cpp:218] Iteration 102600 (3.56131 iter/s, 28.0795s/100 iters), loss = 3.98801e-05
I0527 00:03:39.334868 30701 solver.cpp:237]     Train net output #0: loss = 3.79855e-05 (* 1 = 3.79855e-05 loss)
I0527 00:03:39.334880 30701 sgd_solver.cpp:105] Iteration 102600, lr = 0.00487
I0527 00:04:07.411221 30701 solver.cpp:218] Iteration 102700 (3.5618 iter/s, 28.0757s/100 iters), loss = 4.0181e-05
I0527 00:04:07.411268 30701 solver.cpp:237]     Train net output #0: loss = 3.82864e-05 (* 1 = 3.82864e-05 loss)
I0527 00:04:07.411278 30701 sgd_solver.cpp:105] Iteration 102700, lr = 0.004865
I0527 00:04:35.530831 30701 solver.cpp:218] Iteration 102800 (3.55633 iter/s, 28.1188s/100 iters), loss = 8.32545e-05
I0527 00:04:35.530993 30701 solver.cpp:237]     Train net output #0: loss = 8.13599e-05 (* 1 = 8.13599e-05 loss)
I0527 00:04:35.531005 30701 sgd_solver.cpp:105] Iteration 102800, lr = 0.00486
I0527 00:04:51.313181 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:05:03.669428 30701 solver.cpp:218] Iteration 102900 (3.55395 iter/s, 28.1377s/100 iters), loss = 0.000132979
I0527 00:05:03.669478 30701 solver.cpp:237]     Train net output #0: loss = 0.000131085 (* 1 = 0.000131085 loss)
I0527 00:05:03.669487 30701 sgd_solver.cpp:105] Iteration 102900, lr = 0.004855
I0527 00:05:31.497565 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_103000.caffemodel
I0527 00:05:31.811020 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_103000.solverstate
I0527 00:05:31.961830 30701 solver.cpp:330] Iteration 103000, Testing net (#0)
I0527 00:05:34.921330 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0527 00:05:34.921382 30701 solver.cpp:397]     Test net output #1: loss = 0.933071 (* 1 = 0.933071 loss)
I0527 00:05:35.200954 30701 solver.cpp:218] Iteration 103000 (3.17152 iter/s, 31.5307s/100 iters), loss = 0.000967625
I0527 00:05:35.200997 30701 solver.cpp:237]     Train net output #0: loss = 0.00096573 (* 1 = 0.00096573 loss)
I0527 00:05:35.201005 30701 sgd_solver.cpp:105] Iteration 103000, lr = 0.00485
I0527 00:06:03.313328 30701 solver.cpp:218] Iteration 103100 (3.55725 iter/s, 28.1116s/100 iters), loss = 2.28047e-05
I0527 00:06:03.313505 30701 solver.cpp:237]     Train net output #0: loss = 2.09099e-05 (* 1 = 2.09099e-05 loss)
I0527 00:06:03.313518 30701 sgd_solver.cpp:105] Iteration 103100, lr = 0.004845
I0527 00:06:31.404829 30701 solver.cpp:218] Iteration 103200 (3.55991 iter/s, 28.0906s/100 iters), loss = 0.000276439
I0527 00:06:31.404886 30701 solver.cpp:237]     Train net output #0: loss = 0.000274544 (* 1 = 0.000274544 loss)
I0527 00:06:31.404894 30701 sgd_solver.cpp:105] Iteration 103200, lr = 0.00484
I0527 00:06:59.503161 30701 solver.cpp:218] Iteration 103300 (3.55903 iter/s, 28.0976s/100 iters), loss = 3.73707e-05
I0527 00:06:59.503322 30701 solver.cpp:237]     Train net output #0: loss = 3.54758e-05 (* 1 = 3.54758e-05 loss)
I0527 00:06:59.503334 30701 sgd_solver.cpp:105] Iteration 103300, lr = 0.004835
I0527 00:07:27.574535 30701 solver.cpp:218] Iteration 103400 (3.56246 iter/s, 28.0705s/100 iters), loss = 8.1863e-05
I0527 00:07:27.574579 30701 solver.cpp:237]     Train net output #0: loss = 7.99688e-05 (* 1 = 7.99688e-05 loss)
I0527 00:07:27.574589 30701 sgd_solver.cpp:105] Iteration 103400, lr = 0.00483
I0527 00:07:40.783588 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:07:55.645042 30701 solver.cpp:218] Iteration 103500 (3.56256 iter/s, 28.0697s/100 iters), loss = 3.06235e-05
I0527 00:07:55.645092 30701 solver.cpp:237]     Train net output #0: loss = 2.87291e-05 (* 1 = 2.87291e-05 loss)
I0527 00:07:55.645100 30701 sgd_solver.cpp:105] Iteration 103500, lr = 0.004825
I0527 00:08:23.725621 30701 solver.cpp:218] Iteration 103600 (3.56128 iter/s, 28.0798s/100 iters), loss = 0.000144452
I0527 00:08:23.725795 30701 solver.cpp:237]     Train net output #0: loss = 0.000142558 (* 1 = 0.000142558 loss)
I0527 00:08:23.725805 30701 sgd_solver.cpp:105] Iteration 103600, lr = 0.00482
I0527 00:08:51.792498 30701 solver.cpp:218] Iteration 103700 (3.56303 iter/s, 28.066s/100 iters), loss = 0.000155064
I0527 00:08:51.792542 30701 solver.cpp:237]     Train net output #0: loss = 0.000153169 (* 1 = 0.000153169 loss)
I0527 00:08:51.792551 30701 sgd_solver.cpp:105] Iteration 103700, lr = 0.004815
I0527 00:09:19.868170 30701 solver.cpp:218] Iteration 103800 (3.5619 iter/s, 28.0749s/100 iters), loss = 8.3455e-05
I0527 00:09:19.868341 30701 solver.cpp:237]     Train net output #0: loss = 8.15606e-05 (* 1 = 8.15606e-05 loss)
I0527 00:09:19.868353 30701 sgd_solver.cpp:105] Iteration 103800, lr = 0.00481
I0527 00:09:47.936202 30701 solver.cpp:218] Iteration 103900 (3.56288 iter/s, 28.0671s/100 iters), loss = 0.000551516
I0527 00:09:47.936245 30701 solver.cpp:237]     Train net output #0: loss = 0.000549622 (* 1 = 0.000549622 loss)
I0527 00:09:47.936254 30701 sgd_solver.cpp:105] Iteration 103900, lr = 0.004805
I0527 00:10:15.731479 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_104000.caffemodel
I0527 00:10:16.044450 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_104000.solverstate
I0527 00:10:16.194732 30701 solver.cpp:330] Iteration 104000, Testing net (#0)
I0527 00:10:19.151702 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0527 00:10:19.151743 30701 solver.cpp:397]     Test net output #1: loss = 0.984266 (* 1 = 0.984266 loss)
I0527 00:10:19.429373 30701 solver.cpp:218] Iteration 104000 (3.17538 iter/s, 31.4923s/100 iters), loss = 0.000137793
I0527 00:10:19.429419 30701 solver.cpp:237]     Train net output #0: loss = 0.000135899 (* 1 = 0.000135899 loss)
I0527 00:10:19.429426 30701 sgd_solver.cpp:105] Iteration 104000, lr = 0.0048
I0527 00:10:30.135656 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:10:47.564116 30701 solver.cpp:218] Iteration 104100 (3.55442 iter/s, 28.134s/100 iters), loss = 4.06786e-05
I0527 00:10:47.564337 30701 solver.cpp:237]     Train net output #0: loss = 3.87848e-05 (* 1 = 3.87848e-05 loss)
I0527 00:10:47.564352 30701 sgd_solver.cpp:105] Iteration 104100, lr = 0.004795
I0527 00:11:15.697245 30701 solver.cpp:218] Iteration 104200 (3.55464 iter/s, 28.1322s/100 iters), loss = 4.88617e-05
I0527 00:11:15.697291 30701 solver.cpp:237]     Train net output #0: loss = 4.69682e-05 (* 1 = 4.69682e-05 loss)
I0527 00:11:15.697300 30701 sgd_solver.cpp:105] Iteration 104200, lr = 0.00479
I0527 00:11:43.755945 30701 solver.cpp:218] Iteration 104300 (3.56405 iter/s, 28.0579s/100 iters), loss = 8.83906e-05
I0527 00:11:43.756116 30701 solver.cpp:237]     Train net output #0: loss = 8.64968e-05 (* 1 = 8.64968e-05 loss)
I0527 00:11:43.756129 30701 sgd_solver.cpp:105] Iteration 104300, lr = 0.004785
I0527 00:12:11.803875 30701 solver.cpp:218] Iteration 104400 (3.56537 iter/s, 28.0476s/100 iters), loss = 0.000144849
I0527 00:12:11.803920 30701 solver.cpp:237]     Train net output #0: loss = 0.000142955 (* 1 = 0.000142955 loss)
I0527 00:12:11.803941 30701 sgd_solver.cpp:105] Iteration 104400, lr = 0.00478
I0527 00:12:39.861311 30701 solver.cpp:218] Iteration 104500 (3.56414 iter/s, 28.0573s/100 iters), loss = 0.00117264
I0527 00:12:39.861474 30701 solver.cpp:237]     Train net output #0: loss = 0.00117075 (* 1 = 0.00117075 loss)
I0527 00:12:39.861486 30701 sgd_solver.cpp:105] Iteration 104500, lr = 0.004775
I0527 00:13:07.941730 30701 solver.cpp:218] Iteration 104600 (3.56124 iter/s, 28.0801s/100 iters), loss = 0.000271614
I0527 00:13:07.941776 30701 solver.cpp:237]     Train net output #0: loss = 0.000269723 (* 1 = 0.000269723 loss)
I0527 00:13:07.941786 30701 sgd_solver.cpp:105] Iteration 104600, lr = 0.00477
I0527 00:13:16.102191 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:13:36.037223 30701 solver.cpp:218] Iteration 104700 (3.55931 iter/s, 28.0953s/100 iters), loss = 4.31002e-05
I0527 00:13:36.037271 30701 solver.cpp:237]     Train net output #0: loss = 4.12086e-05 (* 1 = 4.12086e-05 loss)
I0527 00:13:36.037279 30701 sgd_solver.cpp:105] Iteration 104700, lr = 0.004765
I0527 00:14:04.120198 30701 solver.cpp:218] Iteration 104800 (3.5609 iter/s, 28.0828s/100 iters), loss = 0.00019733
I0527 00:14:04.120362 30701 solver.cpp:237]     Train net output #0: loss = 0.000195439 (* 1 = 0.000195439 loss)
I0527 00:14:04.120374 30701 sgd_solver.cpp:105] Iteration 104800, lr = 0.00476
I0527 00:14:32.187352 30701 solver.cpp:218] Iteration 104900 (3.56293 iter/s, 28.0668s/100 iters), loss = 1.85743e-05
I0527 00:14:32.187397 30701 solver.cpp:237]     Train net output #0: loss = 1.66836e-05 (* 1 = 1.66836e-05 loss)
I0527 00:14:32.187404 30701 sgd_solver.cpp:105] Iteration 104900, lr = 0.004755
I0527 00:14:59.989328 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_105000.caffemodel
I0527 00:15:00.372136 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_105000.solverstate
I0527 00:15:00.522662 30701 solver.cpp:330] Iteration 105000, Testing net (#0)
I0527 00:15:01.269805 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:15:03.485527 30701 solver.cpp:397]     Test net output #0: accuracy = 0.832
I0527 00:15:03.485576 30701 solver.cpp:397]     Test net output #1: loss = 0.844011 (* 1 = 0.844011 loss)
I0527 00:15:03.763766 30701 solver.cpp:218] Iteration 105000 (3.16695 iter/s, 31.5761s/100 iters), loss = 5.56953e-05
I0527 00:15:03.763813 30701 solver.cpp:237]     Train net output #0: loss = 5.38047e-05 (* 1 = 5.38047e-05 loss)
I0527 00:15:03.763823 30701 sgd_solver.cpp:105] Iteration 105000, lr = 0.00475
I0527 00:15:31.866843 30701 solver.cpp:218] Iteration 105100 (3.55837 iter/s, 28.1028s/100 iters), loss = 0.0013695
I0527 00:15:31.867040 30701 solver.cpp:237]     Train net output #0: loss = 0.00136761 (* 1 = 0.00136761 loss)
I0527 00:15:31.867053 30701 sgd_solver.cpp:105] Iteration 105100, lr = 0.004745
I0527 00:15:59.949569 30701 solver.cpp:218] Iteration 105200 (3.56097 iter/s, 28.0823s/100 iters), loss = 0.00327312
I0527 00:15:59.949610 30701 solver.cpp:237]     Train net output #0: loss = 0.00327123 (* 1 = 0.00327123 loss)
I0527 00:15:59.949620 30701 sgd_solver.cpp:105] Iteration 105200, lr = 0.00474
I0527 00:16:05.587007 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:16:28.043246 30701 solver.cpp:218] Iteration 105300 (3.55956 iter/s, 28.0933s/100 iters), loss = 9.18133e-05
I0527 00:16:28.043292 30701 solver.cpp:237]     Train net output #0: loss = 8.99225e-05 (* 1 = 8.99225e-05 loss)
I0527 00:16:28.043300 30701 sgd_solver.cpp:105] Iteration 105300, lr = 0.004735
I0527 00:16:56.152561 30701 solver.cpp:218] Iteration 105400 (3.55758 iter/s, 28.109s/100 iters), loss = 0.00013778
I0527 00:16:56.152739 30701 solver.cpp:237]     Train net output #0: loss = 0.000135889 (* 1 = 0.000135889 loss)
I0527 00:16:56.152750 30701 sgd_solver.cpp:105] Iteration 105400, lr = 0.00473
I0527 00:17:24.245854 30701 solver.cpp:218] Iteration 105500 (3.55963 iter/s, 28.0928s/100 iters), loss = 0.00029635
I0527 00:17:24.245898 30701 solver.cpp:237]     Train net output #0: loss = 0.000294459 (* 1 = 0.000294459 loss)
I0527 00:17:24.245908 30701 sgd_solver.cpp:105] Iteration 105500, lr = 0.004725
I0527 00:17:52.333735 30701 solver.cpp:218] Iteration 105600 (3.5603 iter/s, 28.0875s/100 iters), loss = 0.000149593
I0527 00:17:52.333971 30701 solver.cpp:237]     Train net output #0: loss = 0.000147702 (* 1 = 0.000147702 loss)
I0527 00:17:52.333981 30701 sgd_solver.cpp:105] Iteration 105600, lr = 0.00472
I0527 00:18:20.394393 30701 solver.cpp:218] Iteration 105700 (3.56378 iter/s, 28.0601s/100 iters), loss = 0.000144716
I0527 00:18:20.394440 30701 solver.cpp:237]     Train net output #0: loss = 0.000142825 (* 1 = 0.000142825 loss)
I0527 00:18:20.394448 30701 sgd_solver.cpp:105] Iteration 105700, lr = 0.004715
I0527 00:18:48.480655 30701 solver.cpp:218] Iteration 105800 (3.56051 iter/s, 28.0858s/100 iters), loss = 0.000312874
I0527 00:18:48.480814 30701 solver.cpp:237]     Train net output #0: loss = 0.000310983 (* 1 = 0.000310983 loss)
I0527 00:18:48.480826 30701 sgd_solver.cpp:105] Iteration 105800, lr = 0.00471
I0527 00:18:51.592555 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:19:16.591284 30701 solver.cpp:218] Iteration 105900 (3.55744 iter/s, 28.1101s/100 iters), loss = 0.0001443
I0527 00:19:16.591331 30701 solver.cpp:237]     Train net output #0: loss = 0.000142406 (* 1 = 0.000142406 loss)
I0527 00:19:16.591339 30701 sgd_solver.cpp:105] Iteration 105900, lr = 0.004705
I0527 00:19:44.411202 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_106000.caffemodel
I0527 00:19:44.747642 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_106000.solverstate
I0527 00:19:44.898358 30701 solver.cpp:330] Iteration 106000, Testing net (#0)
I0527 00:19:47.853659 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0527 00:19:47.853708 30701 solver.cpp:397]     Test net output #1: loss = 0.989339 (* 1 = 0.989339 loss)
I0527 00:19:48.131953 30701 solver.cpp:218] Iteration 106000 (3.17056 iter/s, 31.5402s/100 iters), loss = 0.000143534
I0527 00:19:48.132011 30701 solver.cpp:237]     Train net output #0: loss = 0.00014164 (* 1 = 0.00014164 loss)
I0527 00:19:48.132020 30701 sgd_solver.cpp:105] Iteration 106000, lr = 0.0047
I0527 00:20:16.234959 30701 solver.cpp:218] Iteration 106100 (3.5584 iter/s, 28.1025s/100 iters), loss = 0.000723073
I0527 00:20:16.235121 30701 solver.cpp:237]     Train net output #0: loss = 0.000721179 (* 1 = 0.000721179 loss)
I0527 00:20:16.235132 30701 sgd_solver.cpp:105] Iteration 106100, lr = 0.004695
I0527 00:20:44.336974 30701 solver.cpp:218] Iteration 106200 (3.55854 iter/s, 28.1014s/100 iters), loss = 0.000538977
I0527 00:20:44.337018 30701 solver.cpp:237]     Train net output #0: loss = 0.000537083 (* 1 = 0.000537083 loss)
I0527 00:20:44.337028 30701 sgd_solver.cpp:105] Iteration 106200, lr = 0.00469
I0527 00:21:12.460593 30701 solver.cpp:218] Iteration 106300 (3.55579 iter/s, 28.1231s/100 iters), loss = 0.000180428
I0527 00:21:12.460793 30701 solver.cpp:237]     Train net output #0: loss = 0.000178533 (* 1 = 0.000178533 loss)
I0527 00:21:12.460804 30701 sgd_solver.cpp:105] Iteration 106300, lr = 0.004685
I0527 00:21:40.557667 30701 solver.cpp:218] Iteration 106400 (3.55917 iter/s, 28.0964s/100 iters), loss = 8.29406e-05
I0527 00:21:40.557711 30701 solver.cpp:237]     Train net output #0: loss = 8.10462e-05 (* 1 = 8.10462e-05 loss)
I0527 00:21:40.557720 30701 sgd_solver.cpp:105] Iteration 106400, lr = 0.00468
I0527 00:21:41.149065 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:22:08.669030 30701 solver.cpp:218] Iteration 106500 (3.55734 iter/s, 28.1109s/100 iters), loss = 6.93448e-05
I0527 00:22:08.669204 30701 solver.cpp:237]     Train net output #0: loss = 6.74504e-05 (* 1 = 6.74504e-05 loss)
I0527 00:22:08.669216 30701 sgd_solver.cpp:105] Iteration 106500, lr = 0.004675
I0527 00:22:36.781785 30701 solver.cpp:218] Iteration 106600 (3.55718 iter/s, 28.1121s/100 iters), loss = 0.00027981
I0527 00:22:36.781829 30701 solver.cpp:237]     Train net output #0: loss = 0.000277916 (* 1 = 0.000277916 loss)
I0527 00:22:36.781838 30701 sgd_solver.cpp:105] Iteration 106600, lr = 0.00467
I0527 00:23:04.900929 30701 solver.cpp:218] Iteration 106700 (3.55636 iter/s, 28.1186s/100 iters), loss = 7.04875e-05
I0527 00:23:04.901154 30701 solver.cpp:237]     Train net output #0: loss = 6.85932e-05 (* 1 = 6.85932e-05 loss)
I0527 00:23:04.901195 30701 sgd_solver.cpp:105] Iteration 106700, lr = 0.004665
I0527 00:23:33.020088 30701 solver.cpp:218] Iteration 106800 (3.55638 iter/s, 28.1185s/100 iters), loss = 0.000278112
I0527 00:23:33.020135 30701 solver.cpp:237]     Train net output #0: loss = 0.000276217 (* 1 = 0.000276217 loss)
I0527 00:23:33.020144 30701 sgd_solver.cpp:105] Iteration 106800, lr = 0.00466
I0527 00:24:01.140148 30701 solver.cpp:218] Iteration 106900 (3.55625 iter/s, 28.1195s/100 iters), loss = 7.09732e-05
I0527 00:24:01.140411 30701 solver.cpp:237]     Train net output #0: loss = 6.90787e-05 (* 1 = 6.90787e-05 loss)
I0527 00:24:01.140424 30701 sgd_solver.cpp:105] Iteration 106900, lr = 0.004655
I0527 00:24:27.582455 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:24:28.980057 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_107000.caffemodel
I0527 00:24:29.293936 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_107000.solverstate
I0527 00:24:29.445601 30701 solver.cpp:330] Iteration 107000, Testing net (#0)
I0527 00:24:31.873924 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:24:32.405127 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 00:24:32.405175 30701 solver.cpp:397]     Test net output #1: loss = 0.770271 (* 1 = 0.770271 loss)
I0527 00:24:32.683362 30701 solver.cpp:218] Iteration 107000 (3.17033 iter/s, 31.5424s/100 iters), loss = 3.38933e-05
I0527 00:24:32.683421 30701 solver.cpp:237]     Train net output #0: loss = 3.19988e-05 (* 1 = 3.19988e-05 loss)
I0527 00:24:32.683430 30701 sgd_solver.cpp:105] Iteration 107000, lr = 0.00465
I0527 00:25:00.801043 30701 solver.cpp:218] Iteration 107100 (3.55655 iter/s, 28.1171s/100 iters), loss = 0.000137638
I0527 00:25:00.801089 30701 solver.cpp:237]     Train net output #0: loss = 0.000135743 (* 1 = 0.000135743 loss)
I0527 00:25:00.801097 30701 sgd_solver.cpp:105] Iteration 107100, lr = 0.004645
I0527 00:25:28.902979 30701 solver.cpp:218] Iteration 107200 (3.55854 iter/s, 28.1014s/100 iters), loss = 0.000100533
I0527 00:25:28.903182 30701 solver.cpp:237]     Train net output #0: loss = 9.86385e-05 (* 1 = 9.86385e-05 loss)
I0527 00:25:28.903193 30701 sgd_solver.cpp:105] Iteration 107200, lr = 0.00464
I0527 00:25:57.010496 30701 solver.cpp:218] Iteration 107300 (3.55786 iter/s, 28.1068s/100 iters), loss = 0.000241376
I0527 00:25:57.010545 30701 solver.cpp:237]     Train net output #0: loss = 0.000239482 (* 1 = 0.000239482 loss)
I0527 00:25:57.010553 30701 sgd_solver.cpp:105] Iteration 107300, lr = 0.004635
I0527 00:26:25.128871 30701 solver.cpp:218] Iteration 107400 (3.55647 iter/s, 28.1178s/100 iters), loss = 0.000494347
I0527 00:26:25.129081 30701 solver.cpp:237]     Train net output #0: loss = 0.000492449 (* 1 = 0.000492449 loss)
I0527 00:26:25.129096 30701 sgd_solver.cpp:105] Iteration 107400, lr = 0.00463
I0527 00:26:53.249372 30701 solver.cpp:218] Iteration 107500 (3.55621 iter/s, 28.1198s/100 iters), loss = 0.000635467
I0527 00:26:53.249416 30701 solver.cpp:237]     Train net output #0: loss = 0.000633569 (* 1 = 0.000633569 loss)
I0527 00:26:53.249425 30701 sgd_solver.cpp:105] Iteration 107500, lr = 0.004625
I0527 00:27:17.170611 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:27:21.372272 30701 solver.cpp:218] Iteration 107600 (3.55589 iter/s, 28.1223s/100 iters), loss = 0.000328214
I0527 00:27:21.372330 30701 solver.cpp:237]     Train net output #0: loss = 0.000326316 (* 1 = 0.000326316 loss)
I0527 00:27:21.372340 30701 sgd_solver.cpp:105] Iteration 107600, lr = 0.00462
I0527 00:27:49.498625 30701 solver.cpp:218] Iteration 107700 (3.55546 iter/s, 28.1258s/100 iters), loss = 5.69352e-05
I0527 00:27:49.498854 30701 solver.cpp:237]     Train net output #0: loss = 5.50367e-05 (* 1 = 5.50367e-05 loss)
I0527 00:27:49.498867 30701 sgd_solver.cpp:105] Iteration 107700, lr = 0.004615
I0527 00:28:17.582054 30701 solver.cpp:218] Iteration 107800 (3.56092 iter/s, 28.0827s/100 iters), loss = 0.000255582
I0527 00:28:17.582099 30701 solver.cpp:237]     Train net output #0: loss = 0.000253684 (* 1 = 0.000253684 loss)
I0527 00:28:17.582108 30701 sgd_solver.cpp:105] Iteration 107800, lr = 0.00461
I0527 00:28:45.670146 30701 solver.cpp:218] Iteration 107900 (3.5603 iter/s, 28.0875s/100 iters), loss = 0.000424313
I0527 00:28:45.670262 30701 solver.cpp:237]     Train net output #0: loss = 0.000422414 (* 1 = 0.000422414 loss)
I0527 00:28:45.670272 30701 sgd_solver.cpp:105] Iteration 107900, lr = 0.004605
I0527 00:29:13.486678 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_108000.caffemodel
I0527 00:29:13.818225 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_108000.solverstate
I0527 00:29:13.968508 30701 solver.cpp:330] Iteration 108000, Testing net (#0)
I0527 00:29:16.924672 30701 solver.cpp:397]     Test net output #0: accuracy = 0.802
I0527 00:29:16.924842 30701 solver.cpp:397]     Test net output #1: loss = 1.01081 (* 1 = 1.01081 loss)
I0527 00:29:17.202487 30701 solver.cpp:218] Iteration 108000 (3.17142 iter/s, 31.5316s/100 iters), loss = 0.000167798
I0527 00:29:17.202533 30701 solver.cpp:237]     Train net output #0: loss = 0.000165899 (* 1 = 0.000165899 loss)
I0527 00:29:17.202543 30701 sgd_solver.cpp:105] Iteration 108000, lr = 0.0046
I0527 00:29:45.308817 30701 solver.cpp:218] Iteration 108100 (3.55799 iter/s, 28.1057s/100 iters), loss = 0.000202488
I0527 00:29:45.308861 30701 solver.cpp:237]     Train net output #0: loss = 0.000200589 (* 1 = 0.000200589 loss)
I0527 00:29:45.308881 30701 sgd_solver.cpp:105] Iteration 108100, lr = 0.004595
I0527 00:30:06.704888 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:30:13.437135 30701 solver.cpp:218] Iteration 108200 (3.55521 iter/s, 28.1277s/100 iters), loss = 8.83711e-05
I0527 00:30:13.437180 30701 solver.cpp:237]     Train net output #0: loss = 8.64724e-05 (* 1 = 8.64724e-05 loss)
I0527 00:30:13.437187 30701 sgd_solver.cpp:105] Iteration 108200, lr = 0.00459
I0527 00:30:41.555780 30701 solver.cpp:218] Iteration 108300 (3.55644 iter/s, 28.118s/100 iters), loss = 0.000245141
I0527 00:30:41.555909 30701 solver.cpp:237]     Train net output #0: loss = 0.000243243 (* 1 = 0.000243243 loss)
I0527 00:30:41.555927 30701 sgd_solver.cpp:105] Iteration 108300, lr = 0.004585
I0527 00:31:09.666877 30701 solver.cpp:218] Iteration 108400 (3.5574 iter/s, 28.1104s/100 iters), loss = 0.000156646
I0527 00:31:09.666930 30701 solver.cpp:237]     Train net output #0: loss = 0.000154747 (* 1 = 0.000154747 loss)
I0527 00:31:09.666942 30701 sgd_solver.cpp:105] Iteration 108400, lr = 0.00458
I0527 00:31:37.776796 30701 solver.cpp:218] Iteration 108500 (3.55754 iter/s, 28.1093s/100 iters), loss = 8.58457e-05
I0527 00:31:37.776970 30701 solver.cpp:237]     Train net output #0: loss = 8.39469e-05 (* 1 = 8.39469e-05 loss)
I0527 00:31:37.776988 30701 sgd_solver.cpp:105] Iteration 108500, lr = 0.004575
I0527 00:32:05.879387 30701 solver.cpp:218] Iteration 108600 (3.55849 iter/s, 28.1018s/100 iters), loss = 0.00022338
I0527 00:32:05.879436 30701 solver.cpp:237]     Train net output #0: loss = 0.000221481 (* 1 = 0.000221481 loss)
I0527 00:32:05.879449 30701 sgd_solver.cpp:105] Iteration 108600, lr = 0.00457
I0527 00:32:33.986695 30701 solver.cpp:218] Iteration 108700 (3.55787 iter/s, 28.1067s/100 iters), loss = 0.000131227
I0527 00:32:33.986861 30701 solver.cpp:237]     Train net output #0: loss = 0.000129328 (* 1 = 0.000129328 loss)
I0527 00:32:33.986879 30701 sgd_solver.cpp:105] Iteration 108700, lr = 0.004565
I0527 00:32:52.858762 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:33:02.130785 30701 solver.cpp:218] Iteration 108800 (3.55324 iter/s, 28.1433s/100 iters), loss = 0.00115624
I0527 00:33:02.130831 30701 solver.cpp:237]     Train net output #0: loss = 0.00115434 (* 1 = 0.00115434 loss)
I0527 00:33:02.130839 30701 sgd_solver.cpp:105] Iteration 108800, lr = 0.00456
I0527 00:33:30.254622 30701 solver.cpp:218] Iteration 108900 (3.55578 iter/s, 28.1232s/100 iters), loss = 0.00115401
I0527 00:33:30.254840 30701 solver.cpp:237]     Train net output #0: loss = 0.00115211 (* 1 = 0.00115211 loss)
I0527 00:33:30.254851 30701 sgd_solver.cpp:105] Iteration 108900, lr = 0.004555
I0527 00:33:58.111510 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_109000.caffemodel
I0527 00:33:58.439489 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_109000.solverstate
I0527 00:33:58.589555 30701 solver.cpp:330] Iteration 109000, Testing net (#0)
I0527 00:34:01.544049 30701 solver.cpp:397]     Test net output #0: accuracy = 0.802
I0527 00:34:01.544222 30701 solver.cpp:397]     Test net output #1: loss = 0.949508 (* 1 = 0.949508 loss)
I0527 00:34:01.823050 30701 solver.cpp:218] Iteration 109000 (3.16781 iter/s, 31.5676s/100 iters), loss = 0.000138225
I0527 00:34:01.823106 30701 solver.cpp:237]     Train net output #0: loss = 0.000136327 (* 1 = 0.000136327 loss)
I0527 00:34:01.823114 30701 sgd_solver.cpp:105] Iteration 109000, lr = 0.00455
I0527 00:34:29.930374 30701 solver.cpp:218] Iteration 109100 (3.55787 iter/s, 28.1067s/100 iters), loss = 9.24728e-05
I0527 00:34:29.930421 30701 solver.cpp:237]     Train net output #0: loss = 9.05746e-05 (* 1 = 9.05746e-05 loss)
I0527 00:34:29.930430 30701 sgd_solver.cpp:105] Iteration 109100, lr = 0.004545
I0527 00:34:58.038897 30701 solver.cpp:218] Iteration 109200 (3.55772 iter/s, 28.1079s/100 iters), loss = 0.000236959
I0527 00:34:58.039060 30701 solver.cpp:237]     Train net output #0: loss = 0.000235061 (* 1 = 0.000235061 loss)
I0527 00:34:58.039077 30701 sgd_solver.cpp:105] Iteration 109200, lr = 0.00454
I0527 00:35:26.145560 30701 solver.cpp:218] Iteration 109300 (3.55797 iter/s, 28.1059s/100 iters), loss = 8.55734e-05
I0527 00:35:26.145620 30701 solver.cpp:237]     Train net output #0: loss = 8.36755e-05 (* 1 = 8.36755e-05 loss)
I0527 00:35:26.145629 30701 sgd_solver.cpp:105] Iteration 109300, lr = 0.004535
I0527 00:35:42.460309 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:35:54.249626 30701 solver.cpp:218] Iteration 109400 (3.55829 iter/s, 28.1034s/100 iters), loss = 0.001266
I0527 00:35:54.249668 30701 solver.cpp:237]     Train net output #0: loss = 0.0012641 (* 1 = 0.0012641 loss)
I0527 00:35:54.249677 30701 sgd_solver.cpp:105] Iteration 109400, lr = 0.00453
I0527 00:36:22.356278 30701 solver.cpp:218] Iteration 109500 (3.55796 iter/s, 28.106s/100 iters), loss = 3.84218e-05
I0527 00:36:22.356472 30701 solver.cpp:237]     Train net output #0: loss = 3.65249e-05 (* 1 = 3.65249e-05 loss)
I0527 00:36:22.356484 30701 sgd_solver.cpp:105] Iteration 109500, lr = 0.004525
I0527 00:36:50.469386 30701 solver.cpp:218] Iteration 109600 (3.55716 iter/s, 28.1123s/100 iters), loss = 0.000317451
I0527 00:36:50.469434 30701 solver.cpp:237]     Train net output #0: loss = 0.000315554 (* 1 = 0.000315554 loss)
I0527 00:36:50.469444 30701 sgd_solver.cpp:105] Iteration 109600, lr = 0.00452
I0527 00:37:18.566696 30701 solver.cpp:218] Iteration 109700 (3.55914 iter/s, 28.0967s/100 iters), loss = 0.000254668
I0527 00:37:18.566860 30701 solver.cpp:237]     Train net output #0: loss = 0.000252769 (* 1 = 0.000252769 loss)
I0527 00:37:18.566872 30701 sgd_solver.cpp:105] Iteration 109700, lr = 0.004515
I0527 00:37:46.670868 30701 solver.cpp:218] Iteration 109800 (3.55829 iter/s, 28.1034s/100 iters), loss = 0.000176643
I0527 00:37:46.670917 30701 solver.cpp:237]     Train net output #0: loss = 0.000174745 (* 1 = 0.000174745 loss)
I0527 00:37:46.670925 30701 sgd_solver.cpp:105] Iteration 109800, lr = 0.00451
I0527 00:38:14.776332 30701 solver.cpp:218] Iteration 109900 (3.55811 iter/s, 28.1048s/100 iters), loss = 0.000316677
I0527 00:38:14.776545 30701 solver.cpp:237]     Train net output #0: loss = 0.000314778 (* 1 = 0.000314778 loss)
I0527 00:38:14.776556 30701 sgd_solver.cpp:105] Iteration 109900, lr = 0.004505
I0527 00:38:28.568378 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:38:42.594599 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_110000.caffemodel
I0527 00:38:42.944592 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_110000.solverstate
I0527 00:38:43.094825 30701 solver.cpp:330] Iteration 110000, Testing net (#0)
I0527 00:38:44.252360 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:38:46.055013 30701 solver.cpp:397]     Test net output #0: accuracy = 0.838
I0527 00:38:46.055191 30701 solver.cpp:397]     Test net output #1: loss = 0.834461 (* 1 = 0.834461 loss)
I0527 00:38:46.334411 30701 solver.cpp:218] Iteration 110000 (3.16885 iter/s, 31.5572s/100 iters), loss = 0.000848016
I0527 00:38:46.334458 30701 solver.cpp:237]     Train net output #0: loss = 0.000846116 (* 1 = 0.000846116 loss)
I0527 00:38:46.334466 30701 sgd_solver.cpp:105] Iteration 110000, lr = 0.0045
I0527 00:39:14.420354 30701 solver.cpp:218] Iteration 110100 (3.56058 iter/s, 28.0853s/100 iters), loss = 0.000122559
I0527 00:39:14.420398 30701 solver.cpp:237]     Train net output #0: loss = 0.000120659 (* 1 = 0.000120659 loss)
I0527 00:39:14.420408 30701 sgd_solver.cpp:105] Iteration 110100, lr = 0.004495
I0527 00:39:42.511387 30701 solver.cpp:218] Iteration 110200 (3.55994 iter/s, 28.0904s/100 iters), loss = 0.000226562
I0527 00:39:42.511540 30701 solver.cpp:237]     Train net output #0: loss = 0.000224661 (* 1 = 0.000224661 loss)
I0527 00:39:42.511553 30701 sgd_solver.cpp:105] Iteration 110200, lr = 0.00449
I0527 00:40:10.602695 30701 solver.cpp:218] Iteration 110300 (3.55992 iter/s, 28.0905s/100 iters), loss = 0.00100151
I0527 00:40:10.602741 30701 solver.cpp:237]     Train net output #0: loss = 0.000999604 (* 1 = 0.000999604 loss)
I0527 00:40:10.602751 30701 sgd_solver.cpp:105] Iteration 110300, lr = 0.004485
I0527 00:40:38.672610 30701 solver.cpp:218] Iteration 110400 (3.56262 iter/s, 28.0693s/100 iters), loss = 0.000250038
I0527 00:40:38.672782 30701 solver.cpp:237]     Train net output #0: loss = 0.000248138 (* 1 = 0.000248138 loss)
I0527 00:40:38.672793 30701 sgd_solver.cpp:105] Iteration 110400, lr = 0.00448
I0527 00:41:06.762029 30701 solver.cpp:218] Iteration 110500 (3.56016 iter/s, 28.0886s/100 iters), loss = 0.000314574
I0527 00:41:06.762073 30701 solver.cpp:237]     Train net output #0: loss = 0.000312674 (* 1 = 0.000312674 loss)
I0527 00:41:06.762081 30701 sgd_solver.cpp:105] Iteration 110500, lr = 0.004475
I0527 00:41:18.296452 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:41:34.844796 30701 solver.cpp:218] Iteration 110600 (3.56099 iter/s, 28.0821s/100 iters), loss = 0.000271928
I0527 00:41:34.844841 30701 solver.cpp:237]     Train net output #0: loss = 0.000270029 (* 1 = 0.000270029 loss)
I0527 00:41:34.844851 30701 sgd_solver.cpp:105] Iteration 110600, lr = 0.00447
I0527 00:42:02.934362 30701 solver.cpp:218] Iteration 110700 (3.56012 iter/s, 28.0889s/100 iters), loss = 0.00388876
I0527 00:42:02.934551 30701 solver.cpp:237]     Train net output #0: loss = 0.00388686 (* 1 = 0.00388686 loss)
I0527 00:42:02.934561 30701 sgd_solver.cpp:105] Iteration 110700, lr = 0.004465
I0527 00:42:31.022553 30701 solver.cpp:218] Iteration 110800 (3.56032 iter/s, 28.0874s/100 iters), loss = 2.35908e-05
I0527 00:42:31.022598 30701 solver.cpp:237]     Train net output #0: loss = 2.16909e-05 (* 1 = 2.16909e-05 loss)
I0527 00:42:31.022606 30701 sgd_solver.cpp:105] Iteration 110800, lr = 0.00446
I0527 00:42:59.108820 30701 solver.cpp:218] Iteration 110900 (3.56054 iter/s, 28.0856s/100 iters), loss = 0.000207806
I0527 00:42:59.108981 30701 solver.cpp:237]     Train net output #0: loss = 0.000205907 (* 1 = 0.000205907 loss)
I0527 00:42:59.108992 30701 sgd_solver.cpp:105] Iteration 110900, lr = 0.004455
I0527 00:43:26.935264 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_111000.caffemodel
I0527 00:43:27.250159 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_111000.solverstate
I0527 00:43:27.400730 30701 solver.cpp:330] Iteration 111000, Testing net (#0)
I0527 00:43:30.360770 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0527 00:43:30.360935 30701 solver.cpp:397]     Test net output #1: loss = 0.92533 (* 1 = 0.92533 loss)
I0527 00:43:30.639120 30701 solver.cpp:218] Iteration 111000 (3.17164 iter/s, 31.5295s/100 iters), loss = 0.000141218
I0527 00:43:30.639165 30701 solver.cpp:237]     Train net output #0: loss = 0.000139319 (* 1 = 0.000139319 loss)
I0527 00:43:30.639173 30701 sgd_solver.cpp:105] Iteration 111000, lr = 0.00445
I0527 00:43:58.757594 30701 solver.cpp:218] Iteration 111100 (3.55647 iter/s, 28.1178s/100 iters), loss = 0.000196229
I0527 00:43:58.757652 30701 solver.cpp:237]     Train net output #0: loss = 0.00019433 (* 1 = 0.00019433 loss)
I0527 00:43:58.757666 30701 sgd_solver.cpp:105] Iteration 111100, lr = 0.004445
I0527 00:44:07.763669 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:44:26.839082 30701 solver.cpp:218] Iteration 111200 (3.56115 iter/s, 28.0808s/100 iters), loss = 0.000394122
I0527 00:44:26.839126 30701 solver.cpp:237]     Train net output #0: loss = 0.000392223 (* 1 = 0.000392223 loss)
I0527 00:44:26.839135 30701 sgd_solver.cpp:105] Iteration 111200, lr = 0.00444
I0527 00:44:54.922248 30701 solver.cpp:218] Iteration 111300 (3.56094 iter/s, 28.0825s/100 iters), loss = 0.000401618
I0527 00:44:54.922410 30701 solver.cpp:237]     Train net output #0: loss = 0.00039972 (* 1 = 0.00039972 loss)
I0527 00:44:54.922422 30701 sgd_solver.cpp:105] Iteration 111300, lr = 0.004435
I0527 00:45:23.008730 30701 solver.cpp:218] Iteration 111400 (3.56053 iter/s, 28.0857s/100 iters), loss = 0.000320431
I0527 00:45:23.008777 30701 solver.cpp:237]     Train net output #0: loss = 0.000318532 (* 1 = 0.000318532 loss)
I0527 00:45:23.008785 30701 sgd_solver.cpp:105] Iteration 111400, lr = 0.00443
I0527 00:45:51.133941 30701 solver.cpp:218] Iteration 111500 (3.55561 iter/s, 28.1245s/100 iters), loss = 0.000116987
I0527 00:45:51.134107 30701 solver.cpp:237]     Train net output #0: loss = 0.000115087 (* 1 = 0.000115087 loss)
I0527 00:45:51.134122 30701 sgd_solver.cpp:105] Iteration 111500, lr = 0.004425
I0527 00:46:19.265779 30701 solver.cpp:218] Iteration 111600 (3.55479 iter/s, 28.1311s/100 iters), loss = 0.000290364
I0527 00:46:19.265822 30701 solver.cpp:237]     Train net output #0: loss = 0.000288465 (* 1 = 0.000288465 loss)
I0527 00:46:19.265831 30701 sgd_solver.cpp:105] Iteration 111600, lr = 0.00442
I0527 00:46:47.399170 30701 solver.cpp:218] Iteration 111700 (3.55468 iter/s, 28.1319s/100 iters), loss = 0.000181801
I0527 00:46:47.399376 30701 solver.cpp:237]     Train net output #0: loss = 0.000179903 (* 1 = 0.000179903 loss)
I0527 00:46:47.399387 30701 sgd_solver.cpp:105] Iteration 111700, lr = 0.004415
I0527 00:46:53.889452 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:47:15.537025 30701 solver.cpp:218] Iteration 111800 (3.55419 iter/s, 28.1358s/100 iters), loss = 0.000803395
I0527 00:47:15.537068 30701 solver.cpp:237]     Train net output #0: loss = 0.000801497 (* 1 = 0.000801497 loss)
I0527 00:47:15.537076 30701 sgd_solver.cpp:105] Iteration 111800, lr = 0.00441
I0527 00:47:43.663497 30701 solver.cpp:218] Iteration 111900 (3.5556 iter/s, 28.1247s/100 iters), loss = 0.000409459
I0527 00:47:43.663700 30701 solver.cpp:237]     Train net output #0: loss = 0.000407561 (* 1 = 0.000407561 loss)
I0527 00:47:43.663718 30701 sgd_solver.cpp:105] Iteration 111900, lr = 0.004405
I0527 00:48:11.495007 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_112000.caffemodel
I0527 00:48:11.807343 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_112000.solverstate
I0527 00:48:11.958045 30701 solver.cpp:330] Iteration 112000, Testing net (#0)
I0527 00:48:14.804342 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:48:14.923015 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 00:48:14.923068 30701 solver.cpp:397]     Test net output #1: loss = 0.838519 (* 1 = 0.838519 loss)
I0527 00:48:15.200541 30701 solver.cpp:218] Iteration 112000 (3.17108 iter/s, 31.5349s/100 iters), loss = 0.000708826
I0527 00:48:15.200583 30701 solver.cpp:237]     Train net output #0: loss = 0.000706928 (* 1 = 0.000706928 loss)
I0527 00:48:15.200592 30701 sgd_solver.cpp:105] Iteration 112000, lr = 0.0044
I0527 00:48:43.273344 30701 solver.cpp:218] Iteration 112100 (3.56238 iter/s, 28.0711s/100 iters), loss = 0.000580752
I0527 00:48:43.273386 30701 solver.cpp:237]     Train net output #0: loss = 0.000578854 (* 1 = 0.000578854 loss)
I0527 00:48:43.273396 30701 sgd_solver.cpp:105] Iteration 112100, lr = 0.004395
I0527 00:49:11.356654 30701 solver.cpp:218] Iteration 112200 (3.56105 iter/s, 28.0816s/100 iters), loss = 0.00017183
I0527 00:49:11.356820 30701 solver.cpp:237]     Train net output #0: loss = 0.000169936 (* 1 = 0.000169936 loss)
I0527 00:49:11.356832 30701 sgd_solver.cpp:105] Iteration 112200, lr = 0.00439
I0527 00:49:39.430923 30701 solver.cpp:218] Iteration 112300 (3.5622 iter/s, 28.0725s/100 iters), loss = 9.85785e-05
I0527 00:49:39.430971 30701 solver.cpp:237]     Train net output #0: loss = 9.66838e-05 (* 1 = 9.66838e-05 loss)
I0527 00:49:39.430980 30701 sgd_solver.cpp:105] Iteration 112300, lr = 0.004385
I0527 00:49:43.380102 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:50:07.516638 30701 solver.cpp:218] Iteration 112400 (3.56073 iter/s, 28.0841s/100 iters), loss = 8.76959e-05
I0527 00:50:07.516686 30701 solver.cpp:237]     Train net output #0: loss = 8.5801e-05 (* 1 = 8.5801e-05 loss)
I0527 00:50:07.516695 30701 sgd_solver.cpp:105] Iteration 112400, lr = 0.00438
I0527 00:50:35.583201 30701 solver.cpp:218] Iteration 112500 (3.56316 iter/s, 28.065s/100 iters), loss = 0.000348835
I0527 00:50:35.583348 30701 solver.cpp:237]     Train net output #0: loss = 0.000346944 (* 1 = 0.000346944 loss)
I0527 00:50:35.583359 30701 sgd_solver.cpp:105] Iteration 112500, lr = 0.004375
I0527 00:51:03.666266 30701 solver.cpp:218] Iteration 112600 (3.56107 iter/s, 28.0815s/100 iters), loss = 7.28811e-05
I0527 00:51:03.666316 30701 solver.cpp:237]     Train net output #0: loss = 7.099e-05 (* 1 = 7.099e-05 loss)
I0527 00:51:03.666324 30701 sgd_solver.cpp:105] Iteration 112600, lr = 0.00437
I0527 00:51:31.750664 30701 solver.cpp:218] Iteration 112700 (3.56088 iter/s, 28.0829s/100 iters), loss = 0.000750969
I0527 00:51:31.750864 30701 solver.cpp:237]     Train net output #0: loss = 0.000749078 (* 1 = 0.000749078 loss)
I0527 00:51:31.750876 30701 sgd_solver.cpp:105] Iteration 112700, lr = 0.004365
I0527 00:51:59.824223 30701 solver.cpp:218] Iteration 112800 (3.56227 iter/s, 28.072s/100 iters), loss = 0.00475123
I0527 00:51:59.824270 30701 solver.cpp:237]     Train net output #0: loss = 0.00474934 (* 1 = 0.00474934 loss)
I0527 00:51:59.824278 30701 sgd_solver.cpp:105] Iteration 112800, lr = 0.00436
I0527 00:52:27.907604 30701 solver.cpp:218] Iteration 112900 (3.561 iter/s, 28.082s/100 iters), loss = 0.000439175
I0527 00:52:27.907830 30701 solver.cpp:237]     Train net output #0: loss = 0.000437283 (* 1 = 0.000437283 loss)
I0527 00:52:27.907841 30701 sgd_solver.cpp:105] Iteration 112900, lr = 0.004355
I0527 00:52:29.331991 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:52:55.705641 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_113000.caffemodel
I0527 00:52:56.019321 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_113000.solverstate
I0527 00:52:56.169867 30701 solver.cpp:330] Iteration 113000, Testing net (#0)
I0527 00:52:59.120120 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 00:52:59.120267 30701 solver.cpp:397]     Test net output #1: loss = 0.947057 (* 1 = 0.947057 loss)
I0527 00:52:59.396647 30701 solver.cpp:218] Iteration 113000 (3.17588 iter/s, 31.4873s/100 iters), loss = 0.00195489
I0527 00:52:59.396697 30701 solver.cpp:237]     Train net output #0: loss = 0.001953 (* 1 = 0.001953 loss)
I0527 00:52:59.396705 30701 sgd_solver.cpp:105] Iteration 113000, lr = 0.00435
I0527 00:53:27.477298 30701 solver.cpp:218] Iteration 113100 (3.56134 iter/s, 28.0793s/100 iters), loss = 0.000146772
I0527 00:53:27.477341 30701 solver.cpp:237]     Train net output #0: loss = 0.000144881 (* 1 = 0.000144881 loss)
I0527 00:53:27.477349 30701 sgd_solver.cpp:105] Iteration 113100, lr = 0.004345
I0527 00:53:55.547026 30701 solver.cpp:218] Iteration 113200 (3.56273 iter/s, 28.0684s/100 iters), loss = 0.000299497
I0527 00:53:55.547231 30701 solver.cpp:237]     Train net output #0: loss = 0.000297606 (* 1 = 0.000297606 loss)
I0527 00:53:55.547242 30701 sgd_solver.cpp:105] Iteration 113200, lr = 0.00434
I0527 00:54:23.609356 30701 solver.cpp:218] Iteration 113300 (3.56368 iter/s, 28.0609s/100 iters), loss = 0.000142515
I0527 00:54:23.609407 30701 solver.cpp:237]     Train net output #0: loss = 0.000140624 (* 1 = 0.000140624 loss)
I0527 00:54:23.609416 30701 sgd_solver.cpp:105] Iteration 113300, lr = 0.004335
I0527 00:54:51.701611 30701 solver.cpp:218] Iteration 113400 (3.55986 iter/s, 28.091s/100 iters), loss = 7.53916e-05
I0527 00:54:51.701819 30701 solver.cpp:237]     Train net output #0: loss = 7.35005e-05 (* 1 = 7.35005e-05 loss)
I0527 00:54:51.701833 30701 sgd_solver.cpp:105] Iteration 113400, lr = 0.00433
I0527 00:55:18.726140 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:55:19.834065 30701 solver.cpp:218] Iteration 113500 (3.55479 iter/s, 28.1311s/100 iters), loss = 3.60077e-05
I0527 00:55:19.834115 30701 solver.cpp:237]     Train net output #0: loss = 3.41166e-05 (* 1 = 3.41166e-05 loss)
I0527 00:55:19.834138 30701 sgd_solver.cpp:105] Iteration 113500, lr = 0.004325
I0527 00:55:47.979576 30701 solver.cpp:218] Iteration 113600 (3.55312 iter/s, 28.1443s/100 iters), loss = 5.72246e-05
I0527 00:55:47.979727 30701 solver.cpp:237]     Train net output #0: loss = 5.53334e-05 (* 1 = 5.53334e-05 loss)
I0527 00:55:47.979740 30701 sgd_solver.cpp:105] Iteration 113600, lr = 0.00432
I0527 00:56:16.109944 30701 solver.cpp:218] Iteration 113700 (3.55504 iter/s, 28.129s/100 iters), loss = 0.000184836
I0527 00:56:16.110000 30701 solver.cpp:237]     Train net output #0: loss = 0.000182944 (* 1 = 0.000182944 loss)
I0527 00:56:16.110009 30701 sgd_solver.cpp:105] Iteration 113700, lr = 0.004315
I0527 00:56:44.227972 30701 solver.cpp:218] Iteration 113800 (3.55659 iter/s, 28.1168s/100 iters), loss = 0.000162228
I0527 00:56:44.228168 30701 solver.cpp:237]     Train net output #0: loss = 0.000160337 (* 1 = 0.000160337 loss)
I0527 00:56:44.228183 30701 sgd_solver.cpp:105] Iteration 113800, lr = 0.00431
I0527 00:57:12.359331 30701 solver.cpp:218] Iteration 113900 (3.55492 iter/s, 28.13s/100 iters), loss = 0.000226386
I0527 00:57:12.359377 30701 solver.cpp:237]     Train net output #0: loss = 0.000224494 (* 1 = 0.000224494 loss)
I0527 00:57:12.359398 30701 sgd_solver.cpp:105] Iteration 113900, lr = 0.004305
I0527 00:57:40.178418 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_114000.caffemodel
I0527 00:57:40.492527 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_114000.solverstate
I0527 00:57:40.642704 30701 solver.cpp:330] Iteration 114000, Testing net (#0)
I0527 00:57:43.597002 30701 solver.cpp:397]     Test net output #0: accuracy = 0.788
I0527 00:57:43.597053 30701 solver.cpp:397]     Test net output #1: loss = 0.974472 (* 1 = 0.974472 loss)
I0527 00:57:43.874158 30701 solver.cpp:218] Iteration 114000 (3.17324 iter/s, 31.5135s/100 iters), loss = 8.37277e-05
I0527 00:57:43.874205 30701 solver.cpp:237]     Train net output #0: loss = 8.18367e-05 (* 1 = 8.18367e-05 loss)
I0527 00:57:43.874225 30701 sgd_solver.cpp:105] Iteration 114000, lr = 0.0043
I0527 00:58:08.330231 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 00:58:11.961628 30701 solver.cpp:218] Iteration 114100 (3.56045 iter/s, 28.0863s/100 iters), loss = 0.000308433
I0527 00:58:11.961766 30701 solver.cpp:237]     Train net output #0: loss = 0.000306541 (* 1 = 0.000306541 loss)
I0527 00:58:11.961779 30701 sgd_solver.cpp:105] Iteration 114100, lr = 0.004295
I0527 00:58:40.056011 30701 solver.cpp:218] Iteration 114200 (3.55959 iter/s, 28.0932s/100 iters), loss = 0.000223544
I0527 00:58:40.056061 30701 solver.cpp:237]     Train net output #0: loss = 0.000221651 (* 1 = 0.000221651 loss)
I0527 00:58:40.056079 30701 sgd_solver.cpp:105] Iteration 114200, lr = 0.00429
I0527 00:59:08.160173 30701 solver.cpp:218] Iteration 114300 (3.55833 iter/s, 28.103s/100 iters), loss = 0.000203969
I0527 00:59:08.160341 30701 solver.cpp:237]     Train net output #0: loss = 0.000202077 (* 1 = 0.000202077 loss)
I0527 00:59:08.160352 30701 sgd_solver.cpp:105] Iteration 114300, lr = 0.004285
I0527 00:59:36.245172 30701 solver.cpp:218] Iteration 114400 (3.56078 iter/s, 28.0838s/100 iters), loss = 0.00026652
I0527 00:59:36.245229 30701 solver.cpp:237]     Train net output #0: loss = 0.000264627 (* 1 = 0.000264627 loss)
I0527 00:59:36.245239 30701 sgd_solver.cpp:105] Iteration 114400, lr = 0.00428
I0527 01:00:04.324378 30701 solver.cpp:218] Iteration 114500 (3.56149 iter/s, 28.0781s/100 iters), loss = 5.48116e-05
I0527 01:00:04.324542 30701 solver.cpp:237]     Train net output #0: loss = 5.29189e-05 (* 1 = 5.29189e-05 loss)
I0527 01:00:04.324556 30701 sgd_solver.cpp:105] Iteration 114500, lr = 0.004275
I0527 01:00:32.391506 30701 solver.cpp:218] Iteration 114600 (3.56304 iter/s, 28.0659s/100 iters), loss = 0.000152239
I0527 01:00:32.391552 30701 solver.cpp:237]     Train net output #0: loss = 0.000150347 (* 1 = 0.000150347 loss)
I0527 01:00:32.391561 30701 sgd_solver.cpp:105] Iteration 114600, lr = 0.00427
I0527 01:00:54.579447 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:01:00.462615 30701 solver.cpp:218] Iteration 114700 (3.56252 iter/s, 28.07s/100 iters), loss = 0.000179173
I0527 01:01:00.462661 30701 solver.cpp:237]     Train net output #0: loss = 0.00017728 (* 1 = 0.00017728 loss)
I0527 01:01:00.462671 30701 sgd_solver.cpp:105] Iteration 114700, lr = 0.004265
I0527 01:01:28.537866 30701 solver.cpp:218] Iteration 114800 (3.56199 iter/s, 28.0742s/100 iters), loss = 0.00018886
I0527 01:01:28.538019 30701 solver.cpp:237]     Train net output #0: loss = 0.000186967 (* 1 = 0.000186967 loss)
I0527 01:01:28.538031 30701 sgd_solver.cpp:105] Iteration 114800, lr = 0.00426
I0527 01:01:56.614538 30701 solver.cpp:218] Iteration 114900 (3.56182 iter/s, 28.0755s/100 iters), loss = 0.00225774
I0527 01:01:56.614599 30701 solver.cpp:237]     Train net output #0: loss = 0.00225584 (* 1 = 0.00225584 loss)
I0527 01:01:56.614609 30701 sgd_solver.cpp:105] Iteration 114900, lr = 0.004255
I0527 01:02:24.462494 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_115000.caffemodel
I0527 01:02:24.779405 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_115000.solverstate
I0527 01:02:24.930027 30701 solver.cpp:330] Iteration 115000, Testing net (#0)
I0527 01:02:26.473597 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:02:27.890700 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 01:02:27.890751 30701 solver.cpp:397]     Test net output #1: loss = 0.820249 (* 1 = 0.820249 loss)
I0527 01:02:28.168299 30701 solver.cpp:218] Iteration 115000 (3.16931 iter/s, 31.5526s/100 iters), loss = 0.00120491
I0527 01:02:28.168341 30701 solver.cpp:237]     Train net output #0: loss = 0.00120302 (* 1 = 0.00120302 loss)
I0527 01:02:28.168349 30701 sgd_solver.cpp:105] Iteration 115000, lr = 0.00425
I0527 01:02:56.254762 30701 solver.cpp:218] Iteration 115100 (3.56056 iter/s, 28.0854s/100 iters), loss = 8.45068e-05
I0527 01:02:56.254922 30701 solver.cpp:237]     Train net output #0: loss = 8.26136e-05 (* 1 = 8.26136e-05 loss)
I0527 01:02:56.254935 30701 sgd_solver.cpp:105] Iteration 115100, lr = 0.004245
I0527 01:03:24.347182 30701 solver.cpp:218] Iteration 115200 (3.55982 iter/s, 28.0913s/100 iters), loss = 0.000402295
I0527 01:03:24.347228 30701 solver.cpp:237]     Train net output #0: loss = 0.000400402 (* 1 = 0.000400402 loss)
I0527 01:03:24.347236 30701 sgd_solver.cpp:105] Iteration 115200, lr = 0.00424
I0527 01:03:44.016999 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:03:52.437592 30701 solver.cpp:218] Iteration 115300 (3.56006 iter/s, 28.0894s/100 iters), loss = 6.39709e-05
I0527 01:03:52.437638 30701 solver.cpp:237]     Train net output #0: loss = 6.20777e-05 (* 1 = 6.20777e-05 loss)
I0527 01:03:52.437646 30701 sgd_solver.cpp:105] Iteration 115300, lr = 0.004235
I0527 01:04:20.517936 30701 solver.cpp:218] Iteration 115400 (3.56134 iter/s, 28.0793s/100 iters), loss = 0.000113654
I0527 01:04:20.518100 30701 solver.cpp:237]     Train net output #0: loss = 0.00011176 (* 1 = 0.00011176 loss)
I0527 01:04:20.518112 30701 sgd_solver.cpp:105] Iteration 115400, lr = 0.00423
I0527 01:04:48.608717 30701 solver.cpp:218] Iteration 115500 (3.56003 iter/s, 28.0897s/100 iters), loss = 0.000141434
I0527 01:04:48.608767 30701 solver.cpp:237]     Train net output #0: loss = 0.000139541 (* 1 = 0.000139541 loss)
I0527 01:04:48.608777 30701 sgd_solver.cpp:105] Iteration 115500, lr = 0.004225
I0527 01:05:16.700837 30701 solver.cpp:218] Iteration 115600 (3.55984 iter/s, 28.0911s/100 iters), loss = 0.000403194
I0527 01:05:16.701042 30701 solver.cpp:237]     Train net output #0: loss = 0.000401301 (* 1 = 0.000401301 loss)
I0527 01:05:16.701055 30701 sgd_solver.cpp:105] Iteration 115600, lr = 0.00422
I0527 01:05:44.792584 30701 solver.cpp:218] Iteration 115700 (3.55991 iter/s, 28.0906s/100 iters), loss = 9.68728e-05
I0527 01:05:44.792628 30701 solver.cpp:237]     Train net output #0: loss = 9.49822e-05 (* 1 = 9.49822e-05 loss)
I0527 01:05:44.792636 30701 sgd_solver.cpp:105] Iteration 115700, lr = 0.004215
I0527 01:06:12.883635 30701 solver.cpp:218] Iteration 115800 (3.55998 iter/s, 28.0901s/100 iters), loss = 7.42601e-05
I0527 01:06:12.883818 30701 solver.cpp:237]     Train net output #0: loss = 7.23695e-05 (* 1 = 7.23695e-05 loss)
I0527 01:06:12.883846 30701 sgd_solver.cpp:105] Iteration 115800, lr = 0.00421
I0527 01:06:30.049134 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:06:40.993203 30701 solver.cpp:218] Iteration 115900 (3.55765 iter/s, 28.1085s/100 iters), loss = 7.35493e-05
I0527 01:06:40.993252 30701 solver.cpp:237]     Train net output #0: loss = 7.16584e-05 (* 1 = 7.16584e-05 loss)
I0527 01:06:40.993260 30701 sgd_solver.cpp:105] Iteration 115900, lr = 0.004205
I0527 01:07:08.803488 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_116000.caffemodel
I0527 01:07:09.116209 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_116000.solverstate
I0527 01:07:09.266242 30701 solver.cpp:330] Iteration 116000, Testing net (#0)
I0527 01:07:12.223986 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 01:07:12.224026 30701 solver.cpp:397]     Test net output #1: loss = 0.882378 (* 1 = 0.882378 loss)
I0527 01:07:12.502125 30701 solver.cpp:218] Iteration 116000 (3.17381 iter/s, 31.5078s/100 iters), loss = 0.000371656
I0527 01:07:12.502182 30701 solver.cpp:237]     Train net output #0: loss = 0.000369763 (* 1 = 0.000369763 loss)
I0527 01:07:12.502189 30701 sgd_solver.cpp:105] Iteration 116000, lr = 0.0042
I0527 01:07:40.561622 30701 solver.cpp:218] Iteration 116100 (3.56398 iter/s, 28.0585s/100 iters), loss = 0.00107272
I0527 01:07:40.561826 30701 solver.cpp:237]     Train net output #0: loss = 0.00107083 (* 1 = 0.00107083 loss)
I0527 01:07:40.561837 30701 sgd_solver.cpp:105] Iteration 116100, lr = 0.004195
I0527 01:08:08.632798 30701 solver.cpp:218] Iteration 116200 (3.56252 iter/s, 28.0701s/100 iters), loss = 0.000137014
I0527 01:08:08.632856 30701 solver.cpp:237]     Train net output #0: loss = 0.000135121 (* 1 = 0.000135121 loss)
I0527 01:08:08.632865 30701 sgd_solver.cpp:105] Iteration 116200, lr = 0.00419
I0527 01:08:36.701138 30701 solver.cpp:218] Iteration 116300 (3.56286 iter/s, 28.0674s/100 iters), loss = 0.000167455
I0527 01:08:36.701373 30701 solver.cpp:237]     Train net output #0: loss = 0.000165559 (* 1 = 0.000165559 loss)
I0527 01:08:36.701385 30701 sgd_solver.cpp:105] Iteration 116300, lr = 0.004185
I0527 01:09:04.778822 30701 solver.cpp:218] Iteration 116400 (3.56169 iter/s, 28.0765s/100 iters), loss = 0.000120419
I0527 01:09:04.778867 30701 solver.cpp:237]     Train net output #0: loss = 0.000118527 (* 1 = 0.000118527 loss)
I0527 01:09:04.778875 30701 sgd_solver.cpp:105] Iteration 116400, lr = 0.00418
I0527 01:09:19.398006 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:09:32.852910 30701 solver.cpp:218] Iteration 116500 (3.56212 iter/s, 28.0731s/100 iters), loss = 0.000132562
I0527 01:09:32.852967 30701 solver.cpp:237]     Train net output #0: loss = 0.000130671 (* 1 = 0.000130671 loss)
I0527 01:09:32.852977 30701 sgd_solver.cpp:105] Iteration 116500, lr = 0.004175
I0527 01:10:00.931884 30701 solver.cpp:218] Iteration 116600 (3.56151 iter/s, 28.078s/100 iters), loss = 0.000705308
I0527 01:10:00.932098 30701 solver.cpp:237]     Train net output #0: loss = 0.000703417 (* 1 = 0.000703417 loss)
I0527 01:10:00.932111 30701 sgd_solver.cpp:105] Iteration 116600, lr = 0.00417
I0527 01:10:28.984717 30701 solver.cpp:218] Iteration 116700 (3.56484 iter/s, 28.0517s/100 iters), loss = 0.000240941
I0527 01:10:28.984763 30701 solver.cpp:237]     Train net output #0: loss = 0.000239051 (* 1 = 0.000239051 loss)
I0527 01:10:28.984771 30701 sgd_solver.cpp:105] Iteration 116700, lr = 0.004165
I0527 01:10:57.040891 30701 solver.cpp:218] Iteration 116800 (3.5644 iter/s, 28.0552s/100 iters), loss = 6.9005e-05
I0527 01:10:57.041046 30701 solver.cpp:237]     Train net output #0: loss = 6.71145e-05 (* 1 = 6.71145e-05 loss)
I0527 01:10:57.041056 30701 sgd_solver.cpp:105] Iteration 116800, lr = 0.00416
I0527 01:11:25.116153 30701 solver.cpp:218] Iteration 116900 (3.56199 iter/s, 28.0742s/100 iters), loss = 5.32323e-05
I0527 01:11:25.116197 30701 solver.cpp:237]     Train net output #0: loss = 5.13417e-05 (* 1 = 5.13417e-05 loss)
I0527 01:11:25.116206 30701 sgd_solver.cpp:105] Iteration 116900, lr = 0.004155
I0527 01:11:52.882992 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_117000.caffemodel
I0527 01:11:53.199071 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_117000.solverstate
I0527 01:11:53.350747 30701 solver.cpp:330] Iteration 117000, Testing net (#0)
I0527 01:11:56.305117 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 01:11:56.305158 30701 solver.cpp:397]     Test net output #1: loss = 0.860145 (* 1 = 0.860145 loss)
I0527 01:11:56.581485 30701 solver.cpp:218] Iteration 117000 (3.17821 iter/s, 31.4643s/100 iters), loss = 0.000547219
I0527 01:11:56.581529 30701 solver.cpp:237]     Train net output #0: loss = 0.000545328 (* 1 = 0.000545328 loss)
I0527 01:11:56.581538 30701 sgd_solver.cpp:105] Iteration 117000, lr = 0.00415
I0527 01:12:08.676867 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:12:24.660625 30701 solver.cpp:218] Iteration 117100 (3.56148 iter/s, 28.0782s/100 iters), loss = 0.000249463
I0527 01:12:24.660815 30701 solver.cpp:237]     Train net output #0: loss = 0.000247571 (* 1 = 0.000247571 loss)
I0527 01:12:24.660826 30701 sgd_solver.cpp:105] Iteration 117100, lr = 0.004145
I0527 01:12:52.732949 30701 solver.cpp:218] Iteration 117200 (3.56236 iter/s, 28.0713s/100 iters), loss = 0.000525686
I0527 01:12:52.732995 30701 solver.cpp:237]     Train net output #0: loss = 0.000523795 (* 1 = 0.000523795 loss)
I0527 01:12:52.733003 30701 sgd_solver.cpp:105] Iteration 117200, lr = 0.00414
I0527 01:13:20.831337 30701 solver.cpp:218] Iteration 117300 (3.55904 iter/s, 28.0975s/100 iters), loss = 0.000263955
I0527 01:13:20.831506 30701 solver.cpp:237]     Train net output #0: loss = 0.000262063 (* 1 = 0.000262063 loss)
I0527 01:13:20.831519 30701 sgd_solver.cpp:105] Iteration 117300, lr = 0.004135
I0527 01:13:48.926383 30701 solver.cpp:218] Iteration 117400 (3.55948 iter/s, 28.094s/100 iters), loss = 0.000365833
I0527 01:13:48.926429 30701 solver.cpp:237]     Train net output #0: loss = 0.000363943 (* 1 = 0.000363943 loss)
I0527 01:13:48.926437 30701 sgd_solver.cpp:105] Iteration 117400, lr = 0.00413
I0527 01:14:17.018088 30701 solver.cpp:218] Iteration 117500 (3.55989 iter/s, 28.0908s/100 iters), loss = 0.000143793
I0527 01:14:17.018255 30701 solver.cpp:237]     Train net output #0: loss = 0.000141902 (* 1 = 0.000141902 loss)
I0527 01:14:17.018266 30701 sgd_solver.cpp:105] Iteration 117500, lr = 0.004125
I0527 01:14:45.112346 30701 solver.cpp:218] Iteration 117600 (3.55958 iter/s, 28.0932s/100 iters), loss = 0.000520915
I0527 01:14:45.112392 30701 solver.cpp:237]     Train net output #0: loss = 0.000519025 (* 1 = 0.000519025 loss)
I0527 01:14:45.112401 30701 sgd_solver.cpp:105] Iteration 117600, lr = 0.00412
I0527 01:14:54.685808 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:15:13.201225 30701 solver.cpp:218] Iteration 117700 (3.56024 iter/s, 28.088s/100 iters), loss = 0.000189581
I0527 01:15:13.201269 30701 solver.cpp:237]     Train net output #0: loss = 0.000187691 (* 1 = 0.000187691 loss)
I0527 01:15:13.201278 30701 sgd_solver.cpp:105] Iteration 117700, lr = 0.004115
I0527 01:15:41.277504 30701 solver.cpp:218] Iteration 117800 (3.56184 iter/s, 28.0754s/100 iters), loss = 0.00053437
I0527 01:15:41.277727 30701 solver.cpp:237]     Train net output #0: loss = 0.00053248 (* 1 = 0.00053248 loss)
I0527 01:15:41.277740 30701 sgd_solver.cpp:105] Iteration 117800, lr = 0.00411
I0527 01:16:09.359400 30701 solver.cpp:218] Iteration 117900 (3.56115 iter/s, 28.0808s/100 iters), loss = 0.00170279
I0527 01:16:09.359444 30701 solver.cpp:237]     Train net output #0: loss = 0.0017009 (* 1 = 0.0017009 loss)
I0527 01:16:09.359452 30701 sgd_solver.cpp:105] Iteration 117900, lr = 0.004105
I0527 01:16:37.153254 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_118000.caffemodel
I0527 01:16:37.467310 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_118000.solverstate
I0527 01:16:37.617950 30701 solver.cpp:330] Iteration 118000, Testing net (#0)
I0527 01:16:37.889153 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:16:40.578444 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 01:16:40.578492 30701 solver.cpp:397]     Test net output #1: loss = 0.896277 (* 1 = 0.896277 loss)
I0527 01:16:40.856863 30701 solver.cpp:218] Iteration 118000 (3.17496 iter/s, 31.4965s/100 iters), loss = 0.000117216
I0527 01:16:40.856909 30701 solver.cpp:237]     Train net output #0: loss = 0.000115325 (* 1 = 0.000115325 loss)
I0527 01:16:40.856919 30701 sgd_solver.cpp:105] Iteration 118000, lr = 0.0041
I0527 01:17:08.982275 30701 solver.cpp:218] Iteration 118100 (3.55562 iter/s, 28.1245s/100 iters), loss = 0.000250579
I0527 01:17:08.982465 30701 solver.cpp:237]     Train net output #0: loss = 0.000248689 (* 1 = 0.000248689 loss)
I0527 01:17:08.982476 30701 sgd_solver.cpp:105] Iteration 118100, lr = 0.004095
I0527 01:17:37.108723 30701 solver.cpp:218] Iteration 118200 (3.55551 iter/s, 28.1254s/100 iters), loss = 0.000565761
I0527 01:17:37.108770 30701 solver.cpp:237]     Train net output #0: loss = 0.000563871 (* 1 = 0.000563871 loss)
I0527 01:17:37.108779 30701 sgd_solver.cpp:105] Iteration 118200, lr = 0.00409
I0527 01:17:44.160396 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:18:05.247875 30701 solver.cpp:218] Iteration 118300 (3.55388 iter/s, 28.1382s/100 iters), loss = 0.000632768
I0527 01:18:05.247920 30701 solver.cpp:237]     Train net output #0: loss = 0.000630877 (* 1 = 0.000630877 loss)
I0527 01:18:05.247939 30701 sgd_solver.cpp:105] Iteration 118300, lr = 0.004085
I0527 01:18:33.371837 30701 solver.cpp:218] Iteration 118400 (3.5558 iter/s, 28.1231s/100 iters), loss = 0.00023631
I0527 01:18:33.372002 30701 solver.cpp:237]     Train net output #0: loss = 0.000234419 (* 1 = 0.000234419 loss)
I0527 01:18:33.372014 30701 sgd_solver.cpp:105] Iteration 118400, lr = 0.00408
I0527 01:19:01.495312 30701 solver.cpp:218] Iteration 118500 (3.55588 iter/s, 28.1225s/100 iters), loss = 0.00018675
I0527 01:19:01.495358 30701 solver.cpp:237]     Train net output #0: loss = 0.00018486 (* 1 = 0.00018486 loss)
I0527 01:19:01.495368 30701 sgd_solver.cpp:105] Iteration 118500, lr = 0.004075
I0527 01:19:29.583417 30701 solver.cpp:218] Iteration 118600 (3.56034 iter/s, 28.0872s/100 iters), loss = 8.95984e-05
I0527 01:19:29.583690 30701 solver.cpp:237]     Train net output #0: loss = 8.77087e-05 (* 1 = 8.77087e-05 loss)
I0527 01:19:29.583701 30701 sgd_solver.cpp:105] Iteration 118600, lr = 0.00407
I0527 01:19:57.654381 30701 solver.cpp:218] Iteration 118700 (3.56254 iter/s, 28.0698s/100 iters), loss = 0.000320299
I0527 01:19:57.654429 30701 solver.cpp:237]     Train net output #0: loss = 0.000318408 (* 1 = 0.000318408 loss)
I0527 01:19:57.654438 30701 sgd_solver.cpp:105] Iteration 118700, lr = 0.004065
I0527 01:20:25.733410 30701 solver.cpp:218] Iteration 118800 (3.56149 iter/s, 28.0781s/100 iters), loss = 0.000427894
I0527 01:20:25.733577 30701 solver.cpp:237]     Train net output #0: loss = 0.000426004 (* 1 = 0.000426004 loss)
I0527 01:20:25.733588 30701 sgd_solver.cpp:105] Iteration 118800, lr = 0.00406
I0527 01:20:30.526502 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:20:53.818687 30701 solver.cpp:218] Iteration 118900 (3.56071 iter/s, 28.0843s/100 iters), loss = 6.33562e-05
I0527 01:20:53.818742 30701 solver.cpp:237]     Train net output #0: loss = 6.14653e-05 (* 1 = 6.14653e-05 loss)
I0527 01:20:53.818752 30701 sgd_solver.cpp:105] Iteration 118900, lr = 0.004055
I0527 01:21:21.633082 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_119000.caffemodel
I0527 01:21:22.117189 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_119000.solverstate
I0527 01:21:22.270155 30701 solver.cpp:330] Iteration 119000, Testing net (#0)
I0527 01:21:25.225409 30701 solver.cpp:397]     Test net output #0: accuracy = 0.802
I0527 01:21:25.225458 30701 solver.cpp:397]     Test net output #1: loss = 0.952031 (* 1 = 0.952031 loss)
I0527 01:21:25.501641 30701 solver.cpp:218] Iteration 119000 (3.15637 iter/s, 31.6819s/100 iters), loss = 0.00143364
I0527 01:21:25.501683 30701 solver.cpp:237]     Train net output #0: loss = 0.00143175 (* 1 = 0.00143175 loss)
I0527 01:21:25.501693 30701 sgd_solver.cpp:105] Iteration 119000, lr = 0.00405
I0527 01:21:53.604233 30701 solver.cpp:218] Iteration 119100 (3.5585 iter/s, 28.1017s/100 iters), loss = 0.0002022
I0527 01:21:53.604907 30701 solver.cpp:237]     Train net output #0: loss = 0.000200309 (* 1 = 0.000200309 loss)
I0527 01:21:53.604918 30701 sgd_solver.cpp:105] Iteration 119100, lr = 0.004045
I0527 01:22:21.708746 30701 solver.cpp:218] Iteration 119200 (3.55834 iter/s, 28.103s/100 iters), loss = 0.000229437
I0527 01:22:21.708822 30701 solver.cpp:237]     Train net output #0: loss = 0.000227546 (* 1 = 0.000227546 loss)
I0527 01:22:21.708832 30701 sgd_solver.cpp:105] Iteration 119200, lr = 0.00404
I0527 01:22:49.817682 30701 solver.cpp:218] Iteration 119300 (3.5577 iter/s, 28.108s/100 iters), loss = 5.05734e-05
I0527 01:22:49.817894 30701 solver.cpp:237]     Train net output #0: loss = 4.86806e-05 (* 1 = 4.86806e-05 loss)
I0527 01:22:49.817906 30701 sgd_solver.cpp:105] Iteration 119300, lr = 0.004035
I0527 01:23:17.921386 30701 solver.cpp:218] Iteration 119400 (3.55838 iter/s, 28.1027s/100 iters), loss = 5.32405e-05
I0527 01:23:17.921430 30701 solver.cpp:237]     Train net output #0: loss = 5.13476e-05 (* 1 = 5.13476e-05 loss)
I0527 01:23:17.921450 30701 sgd_solver.cpp:105] Iteration 119400, lr = 0.00403
I0527 01:23:20.188760 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:23:46.022428 30701 solver.cpp:218] Iteration 119500 (3.5587 iter/s, 28.1001s/100 iters), loss = 0.000246941
I0527 01:23:46.022470 30701 solver.cpp:237]     Train net output #0: loss = 0.000245048 (* 1 = 0.000245048 loss)
I0527 01:23:46.022480 30701 sgd_solver.cpp:105] Iteration 119500, lr = 0.004025
I0527 01:24:14.141973 30701 solver.cpp:218] Iteration 119600 (3.55636 iter/s, 28.1187s/100 iters), loss = 0.000427912
I0527 01:24:14.142127 30701 solver.cpp:237]     Train net output #0: loss = 0.00042602 (* 1 = 0.00042602 loss)
I0527 01:24:14.142138 30701 sgd_solver.cpp:105] Iteration 119600, lr = 0.00402
I0527 01:24:42.250313 30701 solver.cpp:218] Iteration 119700 (3.55779 iter/s, 28.1073s/100 iters), loss = 0.000303267
I0527 01:24:42.250358 30701 solver.cpp:237]     Train net output #0: loss = 0.000301375 (* 1 = 0.000301375 loss)
I0527 01:24:42.250367 30701 sgd_solver.cpp:105] Iteration 119700, lr = 0.004015
I0527 01:25:10.374573 30701 solver.cpp:218] Iteration 119800 (3.55576 iter/s, 28.1234s/100 iters), loss = 0.000122339
I0527 01:25:10.374737 30701 solver.cpp:237]     Train net output #0: loss = 0.000120446 (* 1 = 0.000120446 loss)
I0527 01:25:10.374749 30701 sgd_solver.cpp:105] Iteration 119800, lr = 0.00401
I0527 01:25:38.493333 30701 solver.cpp:218] Iteration 119900 (3.55647 iter/s, 28.1178s/100 iters), loss = 0.000459735
I0527 01:25:38.493382 30701 solver.cpp:237]     Train net output #0: loss = 0.000457843 (* 1 = 0.000457843 loss)
I0527 01:25:38.493391 30701 sgd_solver.cpp:105] Iteration 119900, lr = 0.004005
I0527 01:26:06.331629 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_120000.caffemodel
I0527 01:26:06.784430 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_120000.solverstate
I0527 01:26:06.936324 30701 solver.cpp:330] Iteration 120000, Testing net (#0)
I0527 01:26:08.891830 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:26:09.897320 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 01:26:09.897356 30701 solver.cpp:397]     Test net output #1: loss = 0.780176 (* 1 = 0.780176 loss)
I0527 01:26:09.908313 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:26:10.175601 30701 solver.cpp:218] Iteration 120000 (3.15644 iter/s, 31.6813s/100 iters), loss = 0.000159708
I0527 01:26:10.175643 30701 solver.cpp:237]     Train net output #0: loss = 0.000157816 (* 1 = 0.000157816 loss)
I0527 01:26:10.175653 30701 sgd_solver.cpp:105] Iteration 120000, lr = 0.004
I0527 01:26:38.265656 30701 solver.cpp:218] Iteration 120100 (3.56009 iter/s, 28.0892s/100 iters), loss = 0.00013968
I0527 01:26:38.265820 30701 solver.cpp:237]     Train net output #0: loss = 0.000137789 (* 1 = 0.000137789 loss)
I0527 01:26:38.265833 30701 sgd_solver.cpp:105] Iteration 120100, lr = 0.003995
I0527 01:27:06.415119 30701 solver.cpp:218] Iteration 120200 (3.55259 iter/s, 28.1485s/100 iters), loss = 0.000302247
I0527 01:27:06.415177 30701 solver.cpp:237]     Train net output #0: loss = 0.000300355 (* 1 = 0.000300355 loss)
I0527 01:27:06.415186 30701 sgd_solver.cpp:105] Iteration 120200, lr = 0.00399
I0527 01:27:34.528079 30701 solver.cpp:218] Iteration 120300 (3.55719 iter/s, 28.1121s/100 iters), loss = 8.02403e-05
I0527 01:27:34.528328 30701 solver.cpp:237]     Train net output #0: loss = 7.83486e-05 (* 1 = 7.83486e-05 loss)
I0527 01:27:34.528340 30701 sgd_solver.cpp:105] Iteration 120300, lr = 0.003985
I0527 01:28:02.653810 30701 solver.cpp:218] Iteration 120400 (3.5556 iter/s, 28.1246s/100 iters), loss = 0.000413467
I0527 01:28:02.653856 30701 solver.cpp:237]     Train net output #0: loss = 0.000411576 (* 1 = 0.000411576 loss)
I0527 01:28:02.653867 30701 sgd_solver.cpp:105] Iteration 120400, lr = 0.00398
I0527 01:28:30.731096 30701 solver.cpp:218] Iteration 120500 (3.56171 iter/s, 28.0764s/100 iters), loss = 0.000260162
I0527 01:28:30.731261 30701 solver.cpp:237]     Train net output #0: loss = 0.00025827 (* 1 = 0.00025827 loss)
I0527 01:28:30.731273 30701 sgd_solver.cpp:105] Iteration 120500, lr = 0.003975
I0527 01:28:56.028899 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:28:58.819769 30701 solver.cpp:218] Iteration 120600 (3.56028 iter/s, 28.0877s/100 iters), loss = 0.000124558
I0527 01:28:58.819813 30701 solver.cpp:237]     Train net output #0: loss = 0.000122666 (* 1 = 0.000122666 loss)
I0527 01:28:58.819821 30701 sgd_solver.cpp:105] Iteration 120600, lr = 0.00397
I0527 01:29:26.898932 30701 solver.cpp:218] Iteration 120700 (3.56147 iter/s, 28.0783s/100 iters), loss = 0.000215016
I0527 01:29:26.899099 30701 solver.cpp:237]     Train net output #0: loss = 0.000213125 (* 1 = 0.000213125 loss)
I0527 01:29:26.899111 30701 sgd_solver.cpp:105] Iteration 120700, lr = 0.003965
I0527 01:29:54.997723 30701 solver.cpp:218] Iteration 120800 (3.559 iter/s, 28.0978s/100 iters), loss = 9.30716e-05
I0527 01:29:54.997764 30701 solver.cpp:237]     Train net output #0: loss = 9.11799e-05 (* 1 = 9.11799e-05 loss)
I0527 01:29:54.997772 30701 sgd_solver.cpp:105] Iteration 120800, lr = 0.00396
I0527 01:30:23.104830 30701 solver.cpp:218] Iteration 120900 (3.55793 iter/s, 28.1062s/100 iters), loss = 5.45494e-05
I0527 01:30:23.105036 30701 solver.cpp:237]     Train net output #0: loss = 5.26576e-05 (* 1 = 5.26576e-05 loss)
I0527 01:30:23.105048 30701 sgd_solver.cpp:105] Iteration 120900, lr = 0.003955
I0527 01:30:50.953133 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_121000.caffemodel
I0527 01:30:51.418056 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_121000.solverstate
I0527 01:30:51.570763 30701 solver.cpp:330] Iteration 121000, Testing net (#0)
I0527 01:30:54.530735 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 01:30:54.530859 30701 solver.cpp:397]     Test net output #1: loss = 0.892289 (* 1 = 0.892289 loss)
I0527 01:30:54.807641 30701 solver.cpp:218] Iteration 121000 (3.15441 iter/s, 31.7017s/100 iters), loss = 0.000376854
I0527 01:30:54.807687 30701 solver.cpp:237]     Train net output #0: loss = 0.000374962 (* 1 = 0.000374962 loss)
I0527 01:30:54.807695 30701 sgd_solver.cpp:105] Iteration 121000, lr = 0.00395
I0527 01:31:22.943537 30701 solver.cpp:218] Iteration 121100 (3.55429 iter/s, 28.135s/100 iters), loss = 7.38598e-05
I0527 01:31:22.943581 30701 solver.cpp:237]     Train net output #0: loss = 7.19681e-05 (* 1 = 7.19681e-05 loss)
I0527 01:31:22.943590 30701 sgd_solver.cpp:105] Iteration 121100, lr = 0.003945
I0527 01:31:45.723145 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:31:51.044596 30701 solver.cpp:218] Iteration 121200 (3.5587 iter/s, 28.1002s/100 iters), loss = 0.000488437
I0527 01:31:51.044652 30701 solver.cpp:237]     Train net output #0: loss = 0.000486545 (* 1 = 0.000486545 loss)
I0527 01:31:51.044661 30701 sgd_solver.cpp:105] Iteration 121200, lr = 0.00394
I0527 01:32:19.124635 30701 solver.cpp:218] Iteration 121300 (3.56136 iter/s, 28.0791s/100 iters), loss = 0.000191794
I0527 01:32:19.124892 30701 solver.cpp:237]     Train net output #0: loss = 0.000189902 (* 1 = 0.000189902 loss)
I0527 01:32:19.124904 30701 sgd_solver.cpp:105] Iteration 121300, lr = 0.003935
I0527 01:32:47.207826 30701 solver.cpp:218] Iteration 121400 (3.56099 iter/s, 28.0821s/100 iters), loss = 7.83837e-05
I0527 01:32:47.207870 30701 solver.cpp:237]     Train net output #0: loss = 7.64917e-05 (* 1 = 7.64917e-05 loss)
I0527 01:32:47.207880 30701 sgd_solver.cpp:105] Iteration 121400, lr = 0.00393
I0527 01:33:15.275331 30701 solver.cpp:218] Iteration 121500 (3.56295 iter/s, 28.0666s/100 iters), loss = 0.000181133
I0527 01:33:15.275504 30701 solver.cpp:237]     Train net output #0: loss = 0.000179241 (* 1 = 0.000179241 loss)
I0527 01:33:15.275516 30701 sgd_solver.cpp:105] Iteration 121500, lr = 0.003925
I0527 01:33:43.338304 30701 solver.cpp:218] Iteration 121600 (3.56354 iter/s, 28.062s/100 iters), loss = 0.000257583
I0527 01:33:43.338351 30701 solver.cpp:237]     Train net output #0: loss = 0.000255691 (* 1 = 0.000255691 loss)
I0527 01:33:43.338361 30701 sgd_solver.cpp:105] Iteration 121600, lr = 0.00392
I0527 01:34:11.410815 30701 solver.cpp:218] Iteration 121700 (3.56232 iter/s, 28.0716s/100 iters), loss = 0.000223603
I0527 01:34:11.411008 30701 solver.cpp:237]     Train net output #0: loss = 0.000221711 (* 1 = 0.000221711 loss)
I0527 01:34:11.411022 30701 sgd_solver.cpp:105] Iteration 121700, lr = 0.003915
I0527 01:34:31.636313 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:34:39.479614 30701 solver.cpp:218] Iteration 121800 (3.5628 iter/s, 28.0678s/100 iters), loss = 0.000144485
I0527 01:34:39.479660 30701 solver.cpp:237]     Train net output #0: loss = 0.000142594 (* 1 = 0.000142594 loss)
I0527 01:34:39.479668 30701 sgd_solver.cpp:105] Iteration 121800, lr = 0.00391
I0527 01:35:07.552048 30701 solver.cpp:218] Iteration 121900 (3.56233 iter/s, 28.0716s/100 iters), loss = 0.000829691
I0527 01:35:07.552251 30701 solver.cpp:237]     Train net output #0: loss = 0.0008278 (* 1 = 0.0008278 loss)
I0527 01:35:07.552261 30701 sgd_solver.cpp:105] Iteration 121900, lr = 0.003905
I0527 01:35:35.339095 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_122000.caffemodel
I0527 01:35:35.859191 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_122000.solverstate
I0527 01:35:36.013161 30701 solver.cpp:330] Iteration 122000, Testing net (#0)
I0527 01:35:38.976147 30701 solver.cpp:397]     Test net output #0: accuracy = 0.814
I0527 01:35:38.976315 30701 solver.cpp:397]     Test net output #1: loss = 0.854438 (* 1 = 0.854438 loss)
I0527 01:35:39.252856 30701 solver.cpp:218] Iteration 122000 (3.15461 iter/s, 31.6997s/100 iters), loss = 0.000419119
I0527 01:35:39.252902 30701 solver.cpp:237]     Train net output #0: loss = 0.000417227 (* 1 = 0.000417227 loss)
I0527 01:35:39.252910 30701 sgd_solver.cpp:105] Iteration 122000, lr = 0.0039
I0527 01:36:07.350958 30701 solver.cpp:218] Iteration 122100 (3.55907 iter/s, 28.0972s/100 iters), loss = 0.000135679
I0527 01:36:07.351004 30701 solver.cpp:237]     Train net output #0: loss = 0.000133787 (* 1 = 0.000133787 loss)
I0527 01:36:07.351013 30701 sgd_solver.cpp:105] Iteration 122100, lr = 0.003895
I0527 01:36:35.431188 30701 solver.cpp:218] Iteration 122200 (3.56134 iter/s, 28.0793s/100 iters), loss = 0.000117325
I0527 01:36:35.431352 30701 solver.cpp:237]     Train net output #0: loss = 0.000115434 (* 1 = 0.000115434 loss)
I0527 01:36:35.431365 30701 sgd_solver.cpp:105] Iteration 122200, lr = 0.00389
I0527 01:37:03.518937 30701 solver.cpp:218] Iteration 122300 (3.5604 iter/s, 28.0868s/100 iters), loss = 0.00218067
I0527 01:37:03.518983 30701 solver.cpp:237]     Train net output #0: loss = 0.00217877 (* 1 = 0.00217877 loss)
I0527 01:37:03.518992 30701 sgd_solver.cpp:105] Iteration 122300, lr = 0.003885
I0527 01:37:21.503609 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:37:31.609961 30701 solver.cpp:218] Iteration 122400 (3.55997 iter/s, 28.0901s/100 iters), loss = 7.4044e-05
I0527 01:37:31.610014 30701 solver.cpp:237]     Train net output #0: loss = 7.21519e-05 (* 1 = 7.21519e-05 loss)
I0527 01:37:31.610023 30701 sgd_solver.cpp:105] Iteration 122400, lr = 0.00388
I0527 01:37:59.714468 30701 solver.cpp:218] Iteration 122500 (3.55826 iter/s, 28.1036s/100 iters), loss = 0.000210919
I0527 01:37:59.714696 30701 solver.cpp:237]     Train net output #0: loss = 0.000209027 (* 1 = 0.000209027 loss)
I0527 01:37:59.714709 30701 sgd_solver.cpp:105] Iteration 122500, lr = 0.003875
I0527 01:38:27.812857 30701 solver.cpp:218] Iteration 122600 (3.55906 iter/s, 28.0973s/100 iters), loss = 0.000171051
I0527 01:38:27.812904 30701 solver.cpp:237]     Train net output #0: loss = 0.000169159 (* 1 = 0.000169159 loss)
I0527 01:38:27.812913 30701 sgd_solver.cpp:105] Iteration 122600, lr = 0.00387
I0527 01:38:55.922394 30701 solver.cpp:218] Iteration 122700 (3.55762 iter/s, 28.1087s/100 iters), loss = 0.000246901
I0527 01:38:55.922580 30701 solver.cpp:237]     Train net output #0: loss = 0.000245008 (* 1 = 0.000245008 loss)
I0527 01:38:55.922603 30701 sgd_solver.cpp:105] Iteration 122700, lr = 0.003865
I0527 01:39:24.035434 30701 solver.cpp:218] Iteration 122800 (3.5572 iter/s, 28.112s/100 iters), loss = 0.000116568
I0527 01:39:24.035478 30701 solver.cpp:237]     Train net output #0: loss = 0.000114675 (* 1 = 0.000114675 loss)
I0527 01:39:24.035486 30701 sgd_solver.cpp:105] Iteration 122800, lr = 0.00386
I0527 01:39:52.133548 30701 solver.cpp:218] Iteration 122900 (3.55907 iter/s, 28.0972s/100 iters), loss = 0.000200802
I0527 01:39:52.133702 30701 solver.cpp:237]     Train net output #0: loss = 0.000198909 (* 1 = 0.000198909 loss)
I0527 01:39:52.133713 30701 sgd_solver.cpp:105] Iteration 122900, lr = 0.003855
I0527 01:40:07.601984 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:40:19.955312 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_123000.caffemodel
I0527 01:40:20.485715 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_123000.solverstate
I0527 01:40:20.639274 30701 solver.cpp:330] Iteration 123000, Testing net (#0)
I0527 01:40:21.319999 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:40:23.599287 30701 solver.cpp:397]     Test net output #0: accuracy = 0.838
I0527 01:40:23.599469 30701 solver.cpp:397]     Test net output #1: loss = 0.857958 (* 1 = 0.857958 loss)
I0527 01:40:23.876555 30701 solver.cpp:218] Iteration 123000 (3.15041 iter/s, 31.7419s/100 iters), loss = 9.60628e-05
I0527 01:40:23.876601 30701 solver.cpp:237]     Train net output #0: loss = 9.41704e-05 (* 1 = 9.41704e-05 loss)
I0527 01:40:23.876610 30701 sgd_solver.cpp:105] Iteration 123000, lr = 0.00385
I0527 01:40:51.985569 30701 solver.cpp:218] Iteration 123100 (3.55769 iter/s, 28.1081s/100 iters), loss = 7.26292e-05
I0527 01:40:51.985615 30701 solver.cpp:237]     Train net output #0: loss = 7.07369e-05 (* 1 = 7.07369e-05 loss)
I0527 01:40:51.985623 30701 sgd_solver.cpp:105] Iteration 123100, lr = 0.003845
I0527 01:41:20.097554 30701 solver.cpp:218] Iteration 123200 (3.55731 iter/s, 28.1111s/100 iters), loss = 0.000352285
I0527 01:41:20.097780 30701 solver.cpp:237]     Train net output #0: loss = 0.000350393 (* 1 = 0.000350393 loss)
I0527 01:41:20.097792 30701 sgd_solver.cpp:105] Iteration 123200, lr = 0.00384
I0527 01:41:48.183048 30701 solver.cpp:218] Iteration 123300 (3.56069 iter/s, 28.0844s/100 iters), loss = 8.22656e-05
I0527 01:41:48.183106 30701 solver.cpp:237]     Train net output #0: loss = 8.03732e-05 (* 1 = 8.03732e-05 loss)
I0527 01:41:48.183116 30701 sgd_solver.cpp:105] Iteration 123300, lr = 0.003835
I0527 01:42:16.282171 30701 solver.cpp:218] Iteration 123400 (3.55894 iter/s, 28.0982s/100 iters), loss = 9.60392e-05
I0527 01:42:16.282358 30701 solver.cpp:237]     Train net output #0: loss = 9.41468e-05 (* 1 = 9.41468e-05 loss)
I0527 01:42:16.282382 30701 sgd_solver.cpp:105] Iteration 123400, lr = 0.00383
I0527 01:42:44.383311 30701 solver.cpp:218] Iteration 123500 (3.5587 iter/s, 28.1001s/100 iters), loss = 7.1331e-05
I0527 01:42:44.383358 30701 solver.cpp:237]     Train net output #0: loss = 6.94388e-05 (* 1 = 6.94388e-05 loss)
I0527 01:42:44.383365 30701 sgd_solver.cpp:105] Iteration 123500, lr = 0.003825
I0527 01:42:57.331970 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:43:12.480367 30701 solver.cpp:218] Iteration 123600 (3.5592 iter/s, 28.0962s/100 iters), loss = 0.000175494
I0527 01:43:12.480413 30701 solver.cpp:237]     Train net output #0: loss = 0.000173602 (* 1 = 0.000173602 loss)
I0527 01:43:12.480422 30701 sgd_solver.cpp:105] Iteration 123600, lr = 0.00382
I0527 01:43:40.567107 30701 solver.cpp:218] Iteration 123700 (3.56051 iter/s, 28.0859s/100 iters), loss = 0.000187529
I0527 01:43:40.567327 30701 solver.cpp:237]     Train net output #0: loss = 0.000185637 (* 1 = 0.000185637 loss)
I0527 01:43:40.567338 30701 sgd_solver.cpp:105] Iteration 123700, lr = 0.003815
I0527 01:44:08.649755 30701 solver.cpp:218] Iteration 123800 (3.56105 iter/s, 28.0816s/100 iters), loss = 0.000167953
I0527 01:44:08.649816 30701 solver.cpp:237]     Train net output #0: loss = 0.000166061 (* 1 = 0.000166061 loss)
I0527 01:44:08.649827 30701 sgd_solver.cpp:105] Iteration 123800, lr = 0.00381
I0527 01:44:36.728621 30701 solver.cpp:218] Iteration 123900 (3.56151 iter/s, 28.078s/100 iters), loss = 4.97481e-05
I0527 01:44:36.728751 30701 solver.cpp:237]     Train net output #0: loss = 4.7856e-05 (* 1 = 4.7856e-05 loss)
I0527 01:44:36.728763 30701 sgd_solver.cpp:105] Iteration 123900, lr = 0.003805
I0527 01:45:04.531123 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_124000.caffemodel
I0527 01:45:05.074214 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_124000.solverstate
I0527 01:45:05.229271 30701 solver.cpp:330] Iteration 124000, Testing net (#0)
I0527 01:45:08.186758 30701 solver.cpp:397]     Test net output #0: accuracy = 0.806
I0527 01:45:08.186935 30701 solver.cpp:397]     Test net output #1: loss = 0.893297 (* 1 = 0.893297 loss)
I0527 01:45:08.464345 30701 solver.cpp:218] Iteration 124000 (3.15113 iter/s, 31.7347s/100 iters), loss = 0.00022635
I0527 01:45:08.464390 30701 solver.cpp:237]     Train net output #0: loss = 0.000224458 (* 1 = 0.000224458 loss)
I0527 01:45:08.464399 30701 sgd_solver.cpp:105] Iteration 124000, lr = 0.0038
I0527 01:45:36.572001 30701 solver.cpp:218] Iteration 124100 (3.55786 iter/s, 28.1068s/100 iters), loss = 0.000131279
I0527 01:45:36.572046 30701 solver.cpp:237]     Train net output #0: loss = 0.000129387 (* 1 = 0.000129387 loss)
I0527 01:45:36.572054 30701 sgd_solver.cpp:105] Iteration 124100, lr = 0.003795
I0527 01:45:46.994170 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:46:04.693456 30701 solver.cpp:218] Iteration 124200 (3.55612 iter/s, 28.1206s/100 iters), loss = 0.000397345
I0527 01:46:04.693503 30701 solver.cpp:237]     Train net output #0: loss = 0.000395452 (* 1 = 0.000395452 loss)
I0527 01:46:04.693512 30701 sgd_solver.cpp:105] Iteration 124200, lr = 0.00379
I0527 01:46:32.819207 30701 solver.cpp:218] Iteration 124300 (3.55557 iter/s, 28.1249s/100 iters), loss = 7.16093e-05
I0527 01:46:32.819371 30701 solver.cpp:237]     Train net output #0: loss = 6.97169e-05 (* 1 = 6.97169e-05 loss)
I0527 01:46:32.819383 30701 sgd_solver.cpp:105] Iteration 124300, lr = 0.003785
I0527 01:47:00.933143 30701 solver.cpp:218] Iteration 124400 (3.55708 iter/s, 28.1129s/100 iters), loss = 0.000265169
I0527 01:47:00.933199 30701 solver.cpp:237]     Train net output #0: loss = 0.000263276 (* 1 = 0.000263276 loss)
I0527 01:47:00.933208 30701 sgd_solver.cpp:105] Iteration 124400, lr = 0.00378
I0527 01:47:29.039506 30701 solver.cpp:218] Iteration 124500 (3.55802 iter/s, 28.1055s/100 iters), loss = 0.000103957
I0527 01:47:29.039650 30701 solver.cpp:237]     Train net output #0: loss = 0.000102063 (* 1 = 0.000102063 loss)
I0527 01:47:29.039665 30701 sgd_solver.cpp:105] Iteration 124500, lr = 0.003775
I0527 01:47:57.152384 30701 solver.cpp:218] Iteration 124600 (3.55721 iter/s, 28.1119s/100 iters), loss = 0.000524376
I0527 01:47:57.152427 30701 solver.cpp:237]     Train net output #0: loss = 0.000522483 (* 1 = 0.000522483 loss)
I0527 01:47:57.152437 30701 sgd_solver.cpp:105] Iteration 124600, lr = 0.00377
I0527 01:48:25.256121 30701 solver.cpp:218] Iteration 124700 (3.55836 iter/s, 28.1029s/100 iters), loss = 0.000705906
I0527 01:48:25.256325 30701 solver.cpp:237]     Train net output #0: loss = 0.000704014 (* 1 = 0.000704014 loss)
I0527 01:48:25.256336 30701 sgd_solver.cpp:105] Iteration 124700, lr = 0.003765
I0527 01:48:33.150192 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:48:53.386050 30701 solver.cpp:218] Iteration 124800 (3.55506 iter/s, 28.1289s/100 iters), loss = 0.000173143
I0527 01:48:53.386096 30701 solver.cpp:237]     Train net output #0: loss = 0.00017125 (* 1 = 0.00017125 loss)
I0527 01:48:53.386104 30701 sgd_solver.cpp:105] Iteration 124800, lr = 0.00376
I0527 01:49:21.507264 30701 solver.cpp:218] Iteration 124900 (3.55615 iter/s, 28.1203s/100 iters), loss = 0.000165402
I0527 01:49:21.507422 30701 solver.cpp:237]     Train net output #0: loss = 0.000163509 (* 1 = 0.000163509 loss)
I0527 01:49:21.507436 30701 sgd_solver.cpp:105] Iteration 124900, lr = 0.003755
I0527 01:49:49.339465 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_125000.caffemodel
I0527 01:49:49.861866 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_125000.solverstate
I0527 01:49:50.015538 30701 solver.cpp:330] Iteration 125000, Testing net (#0)
I0527 01:49:52.384994 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:49:52.977419 30701 solver.cpp:397]     Test net output #0: accuracy = 0.832
I0527 01:49:52.977455 30701 solver.cpp:397]     Test net output #1: loss = 0.763954 (* 1 = 0.763954 loss)
I0527 01:49:53.255496 30701 solver.cpp:218] Iteration 125000 (3.14989 iter/s, 31.7471s/100 iters), loss = 0.000120659
I0527 01:49:53.255540 30701 solver.cpp:237]     Train net output #0: loss = 0.000118766 (* 1 = 0.000118766 loss)
I0527 01:49:53.255549 30701 sgd_solver.cpp:105] Iteration 125000, lr = 0.00375
I0527 01:50:21.321528 30701 solver.cpp:218] Iteration 125100 (3.56314 iter/s, 28.0652s/100 iters), loss = 0.000189654
I0527 01:50:21.321573 30701 solver.cpp:237]     Train net output #0: loss = 0.000187761 (* 1 = 0.000187761 loss)
I0527 01:50:21.321583 30701 sgd_solver.cpp:105] Iteration 125100, lr = 0.003745
I0527 01:50:49.404659 30701 solver.cpp:218] Iteration 125200 (3.56097 iter/s, 28.0823s/100 iters), loss = 0.000218681
I0527 01:50:49.404829 30701 solver.cpp:237]     Train net output #0: loss = 0.000216788 (* 1 = 0.000216788 loss)
I0527 01:50:49.404841 30701 sgd_solver.cpp:105] Iteration 125200, lr = 0.00374
I0527 01:51:17.507839 30701 solver.cpp:218] Iteration 125300 (3.55844 iter/s, 28.1022s/100 iters), loss = 0.00108417
I0527 01:51:17.507884 30701 solver.cpp:237]     Train net output #0: loss = 0.00108228 (* 1 = 0.00108228 loss)
I0527 01:51:17.507891 30701 sgd_solver.cpp:105] Iteration 125300, lr = 0.003735
I0527 01:51:22.872494 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:51:45.635817 30701 solver.cpp:218] Iteration 125400 (3.55529 iter/s, 28.1271s/100 iters), loss = 0.00108694
I0527 01:51:45.635875 30701 solver.cpp:237]     Train net output #0: loss = 0.00108505 (* 1 = 0.00108505 loss)
I0527 01:51:45.635890 30701 sgd_solver.cpp:105] Iteration 125400, lr = 0.00373
I0527 01:52:13.773953 30701 solver.cpp:218] Iteration 125500 (3.55401 iter/s, 28.1372s/100 iters), loss = 0.00041684
I0527 01:52:13.774109 30701 solver.cpp:237]     Train net output #0: loss = 0.000414947 (* 1 = 0.000414947 loss)
I0527 01:52:13.774121 30701 sgd_solver.cpp:105] Iteration 125500, lr = 0.003725
I0527 01:52:41.894703 30701 solver.cpp:218] Iteration 125600 (3.55622 iter/s, 28.1198s/100 iters), loss = 7.89743e-05
I0527 01:52:41.894748 30701 solver.cpp:237]     Train net output #0: loss = 7.70815e-05 (* 1 = 7.70815e-05 loss)
I0527 01:52:41.894757 30701 sgd_solver.cpp:105] Iteration 125600, lr = 0.00372
I0527 01:53:10.016866 30701 solver.cpp:218] Iteration 125700 (3.55603 iter/s, 28.1213s/100 iters), loss = 0.000416703
I0527 01:53:10.017067 30701 solver.cpp:237]     Train net output #0: loss = 0.000414811 (* 1 = 0.000414811 loss)
I0527 01:53:10.017078 30701 sgd_solver.cpp:105] Iteration 125700, lr = 0.003715
I0527 01:53:38.147630 30701 solver.cpp:218] Iteration 125800 (3.55496 iter/s, 28.1297s/100 iters), loss = 0.000400757
I0527 01:53:38.147673 30701 solver.cpp:237]     Train net output #0: loss = 0.000398864 (* 1 = 0.000398864 loss)
I0527 01:53:38.147682 30701 sgd_solver.cpp:105] Iteration 125800, lr = 0.00371
I0527 01:54:06.282143 30701 solver.cpp:218] Iteration 125900 (3.55446 iter/s, 28.1336s/100 iters), loss = 0.00044274
I0527 01:54:06.282408 30701 solver.cpp:237]     Train net output #0: loss = 0.000440848 (* 1 = 0.000440848 loss)
I0527 01:54:06.282420 30701 sgd_solver.cpp:105] Iteration 125900, lr = 0.003705
I0527 01:54:09.115686 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:54:34.118993 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_126000.caffemodel
I0527 01:54:34.654358 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_126000.solverstate
I0527 01:54:34.808442 30701 solver.cpp:330] Iteration 126000, Testing net (#0)
I0527 01:54:37.766041 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 01:54:37.766187 30701 solver.cpp:397]     Test net output #1: loss = 0.898623 (* 1 = 0.898623 loss)
I0527 01:54:38.043736 30701 solver.cpp:218] Iteration 126000 (3.14857 iter/s, 31.7604s/100 iters), loss = 6.88011e-05
I0527 01:54:38.043794 30701 solver.cpp:237]     Train net output #0: loss = 6.69091e-05 (* 1 = 6.69091e-05 loss)
I0527 01:54:38.043804 30701 sgd_solver.cpp:105] Iteration 126000, lr = 0.0037
I0527 01:55:06.164942 30701 solver.cpp:218] Iteration 126100 (3.55615 iter/s, 28.1203s/100 iters), loss = 0.000537627
I0527 01:55:06.164986 30701 solver.cpp:237]     Train net output #0: loss = 0.000535734 (* 1 = 0.000535734 loss)
I0527 01:55:06.164995 30701 sgd_solver.cpp:105] Iteration 126100, lr = 0.003695
I0527 01:55:34.216462 30701 solver.cpp:218] Iteration 126200 (3.56498 iter/s, 28.0506s/100 iters), loss = 9.45734e-05
I0527 01:55:34.216624 30701 solver.cpp:237]     Train net output #0: loss = 9.26811e-05 (* 1 = 9.26811e-05 loss)
I0527 01:55:34.216641 30701 sgd_solver.cpp:105] Iteration 126200, lr = 0.00369
I0527 01:56:02.290433 30701 solver.cpp:218] Iteration 126300 (3.56214 iter/s, 28.073s/100 iters), loss = 0.000287296
I0527 01:56:02.290493 30701 solver.cpp:237]     Train net output #0: loss = 0.000285403 (* 1 = 0.000285403 loss)
I0527 01:56:02.290506 30701 sgd_solver.cpp:105] Iteration 126300, lr = 0.003685
I0527 01:56:30.379349 30701 solver.cpp:218] Iteration 126400 (3.56013 iter/s, 28.0888s/100 iters), loss = 0.000193708
I0527 01:56:30.379509 30701 solver.cpp:237]     Train net output #0: loss = 0.000191816 (* 1 = 0.000191816 loss)
I0527 01:56:30.379526 30701 sgd_solver.cpp:105] Iteration 126400, lr = 0.00368
I0527 01:56:58.456182 30701 solver.cpp:218] Iteration 126500 (3.56141 iter/s, 28.0788s/100 iters), loss = 0.000192685
I0527 01:56:58.456231 30701 solver.cpp:237]     Train net output #0: loss = 0.000190793 (* 1 = 0.000190793 loss)
I0527 01:56:58.456243 30701 sgd_solver.cpp:105] Iteration 126500, lr = 0.003675
I0527 01:56:59.033593 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:57:26.539033 30701 solver.cpp:218] Iteration 126600 (3.56065 iter/s, 28.0848s/100 iters), loss = 0.000308015
I0527 01:57:26.539235 30701 solver.cpp:237]     Train net output #0: loss = 0.000306122 (* 1 = 0.000306122 loss)
I0527 01:57:26.539252 30701 sgd_solver.cpp:105] Iteration 126600, lr = 0.00367
I0527 01:57:54.610065 30701 solver.cpp:218] Iteration 126700 (3.56218 iter/s, 28.0727s/100 iters), loss = 0.000179071
I0527 01:57:54.610121 30701 solver.cpp:237]     Train net output #0: loss = 0.000177179 (* 1 = 0.000177179 loss)
I0527 01:57:54.610133 30701 sgd_solver.cpp:105] Iteration 126700, lr = 0.003665
I0527 01:58:22.683954 30701 solver.cpp:218] Iteration 126800 (3.56182 iter/s, 28.0756s/100 iters), loss = 0.000105882
I0527 01:58:22.684207 30701 solver.cpp:237]     Train net output #0: loss = 0.000103989 (* 1 = 0.000103989 loss)
I0527 01:58:22.684224 30701 sgd_solver.cpp:105] Iteration 126800, lr = 0.00366
I0527 01:58:50.758365 30701 solver.cpp:218] Iteration 126900 (3.56179 iter/s, 28.0758s/100 iters), loss = 0.000411347
I0527 01:58:50.758414 30701 solver.cpp:237]     Train net output #0: loss = 0.000409455 (* 1 = 0.000409455 loss)
I0527 01:58:50.758426 30701 sgd_solver.cpp:105] Iteration 126900, lr = 0.003655
I0527 01:59:18.560885 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_127000.caffemodel
I0527 01:59:19.092990 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_127000.solverstate
I0527 01:59:19.246630 30701 solver.cpp:330] Iteration 127000, Testing net (#0)
I0527 01:59:22.206410 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0527 01:59:22.206460 30701 solver.cpp:397]     Test net output #1: loss = 0.868709 (* 1 = 0.868709 loss)
I0527 01:59:22.483610 30701 solver.cpp:218] Iteration 127000 (3.1519 iter/s, 31.7269s/100 iters), loss = 0.000113072
I0527 01:59:22.483666 30701 solver.cpp:237]     Train net output #0: loss = 0.00011118 (* 1 = 0.00011118 loss)
I0527 01:59:22.483676 30701 sgd_solver.cpp:105] Iteration 127000, lr = 0.00365
I0527 01:59:48.651446 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 01:59:50.605531 30701 solver.cpp:218] Iteration 127100 (3.55578 iter/s, 28.1233s/100 iters), loss = 0.000169856
I0527 01:59:50.605593 30701 solver.cpp:237]     Train net output #0: loss = 0.000167963 (* 1 = 0.000167963 loss)
I0527 01:59:50.605602 30701 sgd_solver.cpp:105] Iteration 127100, lr = 0.003645
I0527 02:00:18.698920 30701 solver.cpp:218] Iteration 127200 (3.5594 iter/s, 28.0946s/100 iters), loss = 0.000577292
I0527 02:00:18.699136 30701 solver.cpp:237]     Train net output #0: loss = 0.000575399 (* 1 = 0.000575399 loss)
I0527 02:00:18.699154 30701 sgd_solver.cpp:105] Iteration 127200, lr = 0.00364
I0527 02:00:46.758584 30701 solver.cpp:218] Iteration 127300 (3.56371 iter/s, 28.0607s/100 iters), loss = 0.00020171
I0527 02:00:46.758635 30701 solver.cpp:237]     Train net output #0: loss = 0.000199817 (* 1 = 0.000199817 loss)
I0527 02:00:46.758647 30701 sgd_solver.cpp:105] Iteration 127300, lr = 0.003635
I0527 02:01:14.816392 30701 solver.cpp:218] Iteration 127400 (3.56394 iter/s, 28.0589s/100 iters), loss = 0.000249407
I0527 02:01:14.816555 30701 solver.cpp:237]     Train net output #0: loss = 0.000247515 (* 1 = 0.000247515 loss)
I0527 02:01:14.816571 30701 sgd_solver.cpp:105] Iteration 127400, lr = 0.00363
I0527 02:01:42.881203 30701 solver.cpp:218] Iteration 127500 (3.56307 iter/s, 28.0657s/100 iters), loss = 0.000467817
I0527 02:01:42.881256 30701 solver.cpp:237]     Train net output #0: loss = 0.000465925 (* 1 = 0.000465925 loss)
I0527 02:01:42.881269 30701 sgd_solver.cpp:105] Iteration 127500, lr = 0.003625
I0527 02:02:10.923418 30701 solver.cpp:218] Iteration 127600 (3.56594 iter/s, 28.0431s/100 iters), loss = 6.73287e-05
I0527 02:02:10.923588 30701 solver.cpp:237]     Train net output #0: loss = 6.54371e-05 (* 1 = 6.54371e-05 loss)
I0527 02:02:10.923605 30701 sgd_solver.cpp:105] Iteration 127600, lr = 0.00362
I0527 02:02:34.518039 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:02:38.997174 30701 solver.cpp:218] Iteration 127700 (3.56195 iter/s, 28.0745s/100 iters), loss = 0.000466755
I0527 02:02:38.997225 30701 solver.cpp:237]     Train net output #0: loss = 0.000464864 (* 1 = 0.000464864 loss)
I0527 02:02:38.997248 30701 sgd_solver.cpp:105] Iteration 127700, lr = 0.003615
I0527 02:03:07.065915 30701 solver.cpp:218] Iteration 127800 (3.56259 iter/s, 28.0695s/100 iters), loss = 0.000136485
I0527 02:03:07.066077 30701 solver.cpp:237]     Train net output #0: loss = 0.000134594 (* 1 = 0.000134594 loss)
I0527 02:03:07.066094 30701 sgd_solver.cpp:105] Iteration 127800, lr = 0.00361
I0527 02:03:35.144803 30701 solver.cpp:218] Iteration 127900 (3.56132 iter/s, 28.0795s/100 iters), loss = 6.64635e-05
I0527 02:03:35.144846 30701 solver.cpp:237]     Train net output #0: loss = 6.4572e-05 (* 1 = 6.4572e-05 loss)
I0527 02:03:35.144855 30701 sgd_solver.cpp:105] Iteration 127900, lr = 0.003605
I0527 02:04:02.934867 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_128000.caffemodel
I0527 02:04:03.561525 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_128000.solverstate
I0527 02:04:03.715582 30701 solver.cpp:330] Iteration 128000, Testing net (#0)
I0527 02:04:04.784373 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:04:06.674754 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 02:04:06.674803 30701 solver.cpp:397]     Test net output #1: loss = 0.807944 (* 1 = 0.807944 loss)
I0527 02:04:06.952448 30701 solver.cpp:218] Iteration 128000 (3.14383 iter/s, 31.8084s/100 iters), loss = 0.000327735
I0527 02:04:06.952494 30701 solver.cpp:237]     Train net output #0: loss = 0.000325844 (* 1 = 0.000325844 loss)
I0527 02:04:06.952503 30701 sgd_solver.cpp:105] Iteration 128000, lr = 0.0036
I0527 02:04:35.054801 30701 solver.cpp:218] Iteration 128100 (3.55835 iter/s, 28.1029s/100 iters), loss = 0.000194585
I0527 02:04:35.055016 30701 solver.cpp:237]     Train net output #0: loss = 0.000192694 (* 1 = 0.000192694 loss)
I0527 02:04:35.055029 30701 sgd_solver.cpp:105] Iteration 128100, lr = 0.003595
I0527 02:05:03.156008 30701 solver.cpp:218] Iteration 128200 (3.55852 iter/s, 28.1016s/100 iters), loss = 0.000452293
I0527 02:05:03.156054 30701 solver.cpp:237]     Train net output #0: loss = 0.000450402 (* 1 = 0.000450402 loss)
I0527 02:05:03.156062 30701 sgd_solver.cpp:105] Iteration 128200, lr = 0.00359
I0527 02:05:24.246340 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:05:31.252015 30701 solver.cpp:218] Iteration 128300 (3.55917 iter/s, 28.0965s/100 iters), loss = 0.00057334
I0527 02:05:31.252063 30701 solver.cpp:237]     Train net output #0: loss = 0.000571449 (* 1 = 0.000571449 loss)
I0527 02:05:31.252073 30701 sgd_solver.cpp:105] Iteration 128300, lr = 0.003585
I0527 02:05:59.361845 30701 solver.cpp:218] Iteration 128400 (3.55742 iter/s, 28.1102s/100 iters), loss = 0.000164193
I0527 02:05:59.362068 30701 solver.cpp:237]     Train net output #0: loss = 0.000162302 (* 1 = 0.000162302 loss)
I0527 02:05:59.362081 30701 sgd_solver.cpp:105] Iteration 128400, lr = 0.00358
I0527 02:06:27.485193 30701 solver.cpp:218] Iteration 128500 (3.55574 iter/s, 28.1236s/100 iters), loss = 0.000399446
I0527 02:06:27.485239 30701 solver.cpp:237]     Train net output #0: loss = 0.000397556 (* 1 = 0.000397556 loss)
I0527 02:06:27.485249 30701 sgd_solver.cpp:105] Iteration 128500, lr = 0.003575
I0527 02:06:55.597661 30701 solver.cpp:218] Iteration 128600 (3.5571 iter/s, 28.1128s/100 iters), loss = 0.000204226
I0527 02:06:55.597872 30701 solver.cpp:237]     Train net output #0: loss = 0.000202335 (* 1 = 0.000202335 loss)
I0527 02:06:55.597883 30701 sgd_solver.cpp:105] Iteration 128600, lr = 0.00357
I0527 02:07:23.720041 30701 solver.cpp:218] Iteration 128700 (3.55587 iter/s, 28.1225s/100 iters), loss = 0.000490948
I0527 02:07:23.720088 30701 solver.cpp:237]     Train net output #0: loss = 0.000489056 (* 1 = 0.000489056 loss)
I0527 02:07:23.720098 30701 sgd_solver.cpp:105] Iteration 128700, lr = 0.003565
I0527 02:07:51.847301 30701 solver.cpp:218] Iteration 128800 (3.55524 iter/s, 28.1275s/100 iters), loss = 0.000370408
I0527 02:07:51.847512 30701 solver.cpp:237]     Train net output #0: loss = 0.000368516 (* 1 = 0.000368516 loss)
I0527 02:07:51.847524 30701 sgd_solver.cpp:105] Iteration 128800, lr = 0.00356
I0527 02:08:10.430691 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:08:19.978451 30701 solver.cpp:218] Iteration 128900 (3.55477 iter/s, 28.1312s/100 iters), loss = 0.000163907
I0527 02:08:19.978495 30701 solver.cpp:237]     Train net output #0: loss = 0.000162016 (* 1 = 0.000162016 loss)
I0527 02:08:19.978503 30701 sgd_solver.cpp:105] Iteration 128900, lr = 0.003555
I0527 02:08:47.818274 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_129000.caffemodel
I0527 02:08:48.350803 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_129000.solverstate
I0527 02:08:48.505304 30701 solver.cpp:330] Iteration 129000, Testing net (#0)
I0527 02:08:51.467767 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0527 02:08:51.467806 30701 solver.cpp:397]     Test net output #1: loss = 0.906309 (* 1 = 0.906309 loss)
I0527 02:08:51.744695 30701 solver.cpp:218] Iteration 129000 (3.14798 iter/s, 31.7664s/100 iters), loss = 0.000846977
I0527 02:08:51.744741 30701 solver.cpp:237]     Train net output #0: loss = 0.000845086 (* 1 = 0.000845086 loss)
I0527 02:08:51.744750 30701 sgd_solver.cpp:105] Iteration 129000, lr = 0.00355
I0527 02:09:19.865463 30701 solver.cpp:218] Iteration 129100 (3.55607 iter/s, 28.1209s/100 iters), loss = 0.000209819
I0527 02:09:19.865669 30701 solver.cpp:237]     Train net output #0: loss = 0.000207928 (* 1 = 0.000207928 loss)
I0527 02:09:19.865680 30701 sgd_solver.cpp:105] Iteration 129100, lr = 0.003545
I0527 02:09:47.930869 30701 solver.cpp:218] Iteration 129200 (3.56311 iter/s, 28.0654s/100 iters), loss = 0.000497888
I0527 02:09:47.930927 30701 solver.cpp:237]     Train net output #0: loss = 0.000495997 (* 1 = 0.000495997 loss)
I0527 02:09:47.930935 30701 sgd_solver.cpp:105] Iteration 129200, lr = 0.00354
I0527 02:10:16.006222 30701 solver.cpp:218] Iteration 129300 (3.56184 iter/s, 28.0754s/100 iters), loss = 0.000306868
I0527 02:10:16.006393 30701 solver.cpp:237]     Train net output #0: loss = 0.000304977 (* 1 = 0.000304977 loss)
I0527 02:10:16.006405 30701 sgd_solver.cpp:105] Iteration 129300, lr = 0.003535
I0527 02:10:44.064759 30701 solver.cpp:218] Iteration 129400 (3.56399 iter/s, 28.0585s/100 iters), loss = 0.000136867
I0527 02:10:44.064805 30701 solver.cpp:237]     Train net output #0: loss = 0.000134975 (* 1 = 0.000134975 loss)
I0527 02:10:44.064813 30701 sgd_solver.cpp:105] Iteration 129400, lr = 0.00353
I0527 02:11:00.090304 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:11:12.135090 30701 solver.cpp:218] Iteration 129500 (3.56248 iter/s, 28.0703s/100 iters), loss = 0.00038665
I0527 02:11:12.135134 30701 solver.cpp:237]     Train net output #0: loss = 0.000384758 (* 1 = 0.000384758 loss)
I0527 02:11:12.135143 30701 sgd_solver.cpp:105] Iteration 129500, lr = 0.003525
I0527 02:11:40.232290 30701 solver.cpp:218] Iteration 129600 (3.55908 iter/s, 28.0972s/100 iters), loss = 8.7915e-05
I0527 02:11:40.232460 30701 solver.cpp:237]     Train net output #0: loss = 8.60231e-05 (* 1 = 8.60231e-05 loss)
I0527 02:11:40.232471 30701 sgd_solver.cpp:105] Iteration 129600, lr = 0.00352
I0527 02:12:08.353729 30701 solver.cpp:218] Iteration 129700 (3.55603 iter/s, 28.1213s/100 iters), loss = 0.000319267
I0527 02:12:08.353786 30701 solver.cpp:237]     Train net output #0: loss = 0.000317375 (* 1 = 0.000317375 loss)
I0527 02:12:08.353796 30701 sgd_solver.cpp:105] Iteration 129700, lr = 0.003515
I0527 02:12:36.470494 30701 solver.cpp:218] Iteration 129800 (3.55661 iter/s, 28.1167s/100 iters), loss = 0.00128446
I0527 02:12:36.470664 30701 solver.cpp:237]     Train net output #0: loss = 0.00128257 (* 1 = 0.00128257 loss)
I0527 02:12:36.470675 30701 sgd_solver.cpp:105] Iteration 129800, lr = 0.00351
I0527 02:13:04.604185 30701 solver.cpp:218] Iteration 129900 (3.55448 iter/s, 28.1335s/100 iters), loss = 0.0006078
I0527 02:13:04.604257 30701 solver.cpp:237]     Train net output #0: loss = 0.000605908 (* 1 = 0.000605908 loss)
I0527 02:13:04.604270 30701 sgd_solver.cpp:105] Iteration 129900, lr = 0.003505
I0527 02:13:32.460454 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_130000.caffemodel
I0527 02:13:32.992908 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_130000.solverstate
I0527 02:13:33.147615 30701 solver.cpp:330] Iteration 130000, Testing net (#0)
I0527 02:13:35.897572 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:13:36.103390 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 02:13:36.103441 30701 solver.cpp:397]     Test net output #1: loss = 0.692617 (* 1 = 0.692617 loss)
I0527 02:13:36.381292 30701 solver.cpp:218] Iteration 130000 (3.14693 iter/s, 31.777s/100 iters), loss = 0.000285757
I0527 02:13:36.381338 30701 solver.cpp:237]     Train net output #0: loss = 0.000283865 (* 1 = 0.000283865 loss)
I0527 02:13:36.381347 30701 sgd_solver.cpp:105] Iteration 130000, lr = 0.0035
I0527 02:13:49.876909 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:14:04.453699 30701 solver.cpp:218] Iteration 130100 (3.56223 iter/s, 28.0723s/100 iters), loss = 0.000735541
I0527 02:14:04.453927 30701 solver.cpp:237]     Train net output #0: loss = 0.000733649 (* 1 = 0.000733649 loss)
I0527 02:14:04.453939 30701 sgd_solver.cpp:105] Iteration 130100, lr = 0.003495
I0527 02:14:32.549110 30701 solver.cpp:218] Iteration 130200 (3.55934 iter/s, 28.0951s/100 iters), loss = 0.000128597
I0527 02:14:32.549154 30701 solver.cpp:237]     Train net output #0: loss = 0.000126705 (* 1 = 0.000126705 loss)
I0527 02:14:32.549163 30701 sgd_solver.cpp:105] Iteration 130200, lr = 0.00349
I0527 02:15:00.677955 30701 solver.cpp:218] Iteration 130300 (3.55509 iter/s, 28.1287s/100 iters), loss = 0.000129153
I0527 02:15:00.678082 30701 solver.cpp:237]     Train net output #0: loss = 0.000127261 (* 1 = 0.000127261 loss)
I0527 02:15:00.678097 30701 sgd_solver.cpp:105] Iteration 130300, lr = 0.003485
I0527 02:15:28.791198 30701 solver.cpp:218] Iteration 130400 (3.55708 iter/s, 28.113s/100 iters), loss = 3.55059e-05
I0527 02:15:28.791256 30701 solver.cpp:237]     Train net output #0: loss = 3.36139e-05 (* 1 = 3.36139e-05 loss)
I0527 02:15:28.791265 30701 sgd_solver.cpp:105] Iteration 130400, lr = 0.00348
I0527 02:15:56.872489 30701 solver.cpp:218] Iteration 130500 (3.56111 iter/s, 28.0811s/100 iters), loss = 0.000132746
I0527 02:15:56.872653 30701 solver.cpp:237]     Train net output #0: loss = 0.000130854 (* 1 = 0.000130854 loss)
I0527 02:15:56.872664 30701 sgd_solver.cpp:105] Iteration 130500, lr = 0.003475
I0527 02:16:24.952560 30701 solver.cpp:218] Iteration 130600 (3.56129 iter/s, 28.0798s/100 iters), loss = 9.49781e-05
I0527 02:16:24.952605 30701 solver.cpp:237]     Train net output #0: loss = 9.30876e-05 (* 1 = 9.30876e-05 loss)
I0527 02:16:24.952625 30701 sgd_solver.cpp:105] Iteration 130600, lr = 0.00347
I0527 02:16:36.200201 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:16:53.059548 30701 solver.cpp:218] Iteration 130700 (3.55786 iter/s, 28.1068s/100 iters), loss = 0.00100605
I0527 02:16:53.059592 30701 solver.cpp:237]     Train net output #0: loss = 0.00100416 (* 1 = 0.00100416 loss)
I0527 02:16:53.059602 30701 sgd_solver.cpp:105] Iteration 130700, lr = 0.003465
I0527 02:17:21.177770 30701 solver.cpp:218] Iteration 130800 (3.55644 iter/s, 28.118s/100 iters), loss = 0.000205355
I0527 02:17:21.177932 30701 solver.cpp:237]     Train net output #0: loss = 0.000203465 (* 1 = 0.000203465 loss)
I0527 02:17:21.177943 30701 sgd_solver.cpp:105] Iteration 130800, lr = 0.00346
I0527 02:17:49.298506 30701 solver.cpp:218] Iteration 130900 (3.55614 iter/s, 28.1204s/100 iters), loss = 0.000129803
I0527 02:17:49.298549 30701 solver.cpp:237]     Train net output #0: loss = 0.000127913 (* 1 = 0.000127913 loss)
I0527 02:17:49.298558 30701 sgd_solver.cpp:105] Iteration 130900, lr = 0.003455
I0527 02:18:17.115512 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_131000.caffemodel
I0527 02:18:17.643029 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_131000.solverstate
I0527 02:18:17.796056 30701 solver.cpp:330] Iteration 131000, Testing net (#0)
I0527 02:18:20.756098 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 02:18:20.756148 30701 solver.cpp:397]     Test net output #1: loss = 0.883727 (* 1 = 0.883727 loss)
I0527 02:18:21.033795 30701 solver.cpp:218] Iteration 131000 (3.15109 iter/s, 31.735s/100 iters), loss = 7.87402e-05
I0527 02:18:21.033841 30701 solver.cpp:237]     Train net output #0: loss = 7.68503e-05 (* 1 = 7.68503e-05 loss)
I0527 02:18:21.033850 30701 sgd_solver.cpp:105] Iteration 131000, lr = 0.00345
I0527 02:18:49.146167 30701 solver.cpp:218] Iteration 131100 (3.55719 iter/s, 28.1121s/100 iters), loss = 0.00012845
I0527 02:18:49.146358 30701 solver.cpp:237]     Train net output #0: loss = 0.000126564 (* 1 = 0.000126564 loss)
I0527 02:18:49.146369 30701 sgd_solver.cpp:105] Iteration 131100, lr = 0.003445
I0527 02:19:17.260746 30701 solver.cpp:218] Iteration 131200 (3.55693 iter/s, 28.1142s/100 iters), loss = 0.000422945
I0527 02:19:17.260789 30701 solver.cpp:237]     Train net output #0: loss = 0.000421045 (* 1 = 0.000421045 loss)
I0527 02:19:17.260798 30701 sgd_solver.cpp:105] Iteration 131200, lr = 0.00344
I0527 02:19:25.993065 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:19:45.368144 30701 solver.cpp:218] Iteration 131300 (3.55782 iter/s, 28.1071s/100 iters), loss = 9.73778e-05
I0527 02:19:45.368201 30701 solver.cpp:237]     Train net output #0: loss = 9.54779e-05 (* 1 = 9.54779e-05 loss)
I0527 02:19:45.368209 30701 sgd_solver.cpp:105] Iteration 131300, lr = 0.003435
I0527 02:20:13.476567 30701 solver.cpp:218] Iteration 131400 (3.55769 iter/s, 28.1081s/100 iters), loss = 0.000142386
I0527 02:20:13.476721 30701 solver.cpp:237]     Train net output #0: loss = 0.000140486 (* 1 = 0.000140486 loss)
I0527 02:20:13.476732 30701 sgd_solver.cpp:105] Iteration 131400, lr = 0.00343
I0527 02:20:41.584035 30701 solver.cpp:218] Iteration 131500 (3.55783 iter/s, 28.1071s/100 iters), loss = 0.000141733
I0527 02:20:41.584080 30701 solver.cpp:237]     Train net output #0: loss = 0.000139833 (* 1 = 0.000139833 loss)
I0527 02:20:41.584089 30701 sgd_solver.cpp:105] Iteration 131500, lr = 0.003425
I0527 02:21:09.688968 30701 solver.cpp:218] Iteration 131600 (3.55814 iter/s, 28.1046s/100 iters), loss = 0.000597372
I0527 02:21:09.689137 30701 solver.cpp:237]     Train net output #0: loss = 0.000595471 (* 1 = 0.000595471 loss)
I0527 02:21:09.689149 30701 sgd_solver.cpp:105] Iteration 131600, lr = 0.00342
I0527 02:21:37.779935 30701 solver.cpp:218] Iteration 131700 (3.55992 iter/s, 28.0905s/100 iters), loss = 0.000342628
I0527 02:21:37.779985 30701 solver.cpp:237]     Train net output #0: loss = 0.000340727 (* 1 = 0.000340727 loss)
I0527 02:21:37.779995 30701 sgd_solver.cpp:105] Iteration 131700, lr = 0.003415
I0527 02:22:05.890681 30701 solver.cpp:218] Iteration 131800 (3.5574 iter/s, 28.1104s/100 iters), loss = 0.000223137
I0527 02:22:05.890841 30701 solver.cpp:237]     Train net output #0: loss = 0.000221236 (* 1 = 0.000221236 loss)
I0527 02:22:05.890852 30701 sgd_solver.cpp:105] Iteration 131800, lr = 0.00341
I0527 02:22:12.094959 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:22:33.988035 30701 solver.cpp:218] Iteration 131900 (3.55911 iter/s, 28.0969s/100 iters), loss = 9.68532e-05
I0527 02:22:33.988081 30701 solver.cpp:237]     Train net output #0: loss = 9.49526e-05 (* 1 = 9.49526e-05 loss)
I0527 02:22:33.988090 30701 sgd_solver.cpp:105] Iteration 131900, lr = 0.003405
I0527 02:23:01.796257 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_132000.caffemodel
I0527 02:23:02.329375 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_132000.solverstate
I0527 02:23:02.484273 30701 solver.cpp:330] Iteration 132000, Testing net (#0)
I0527 02:23:05.441174 30701 solver.cpp:397]     Test net output #0: accuracy = 0.79
I0527 02:23:05.441213 30701 solver.cpp:397]     Test net output #1: loss = 0.949724 (* 1 = 0.949724 loss)
I0527 02:23:05.719902 30701 solver.cpp:218] Iteration 132000 (3.15145 iter/s, 31.7315s/100 iters), loss = 0.000130904
I0527 02:23:05.719955 30701 solver.cpp:237]     Train net output #0: loss = 0.000129003 (* 1 = 0.000129003 loss)
I0527 02:23:05.719965 30701 sgd_solver.cpp:105] Iteration 132000, lr = 0.0034
I0527 02:23:33.804425 30701 solver.cpp:218] Iteration 132100 (3.56073 iter/s, 28.0842s/100 iters), loss = 0.00522572
I0527 02:23:33.804625 30701 solver.cpp:237]     Train net output #0: loss = 0.00522381 (* 1 = 0.00522381 loss)
I0527 02:23:33.804636 30701 sgd_solver.cpp:105] Iteration 132100, lr = 0.003395
I0527 02:24:01.906338 30701 solver.cpp:218] Iteration 132200 (3.55854 iter/s, 28.1014s/100 iters), loss = 0.000111958
I0527 02:24:01.906383 30701 solver.cpp:237]     Train net output #0: loss = 0.000110059 (* 1 = 0.000110059 loss)
I0527 02:24:01.906393 30701 sgd_solver.cpp:105] Iteration 132200, lr = 0.00339
I0527 02:24:30.006012 30701 solver.cpp:218] Iteration 132300 (3.55881 iter/s, 28.0993s/100 iters), loss = 0.000596717
I0527 02:24:30.006182 30701 solver.cpp:237]     Train net output #0: loss = 0.000594818 (* 1 = 0.000594818 loss)
I0527 02:24:30.006198 30701 sgd_solver.cpp:105] Iteration 132300, lr = 0.003385
I0527 02:24:58.096405 30701 solver.cpp:218] Iteration 132400 (3.56 iter/s, 28.0899s/100 iters), loss = 0.000721491
I0527 02:24:58.096463 30701 solver.cpp:237]     Train net output #0: loss = 0.000719592 (* 1 = 0.000719592 loss)
I0527 02:24:58.096474 30701 sgd_solver.cpp:105] Iteration 132400, lr = 0.00338
I0527 02:25:01.772855 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:25:26.206846 30701 solver.cpp:218] Iteration 132500 (3.55745 iter/s, 28.1101s/100 iters), loss = 0.000200504
I0527 02:25:26.206903 30701 solver.cpp:237]     Train net output #0: loss = 0.000198604 (* 1 = 0.000198604 loss)
I0527 02:25:26.206912 30701 sgd_solver.cpp:105] Iteration 132500, lr = 0.003375
I0527 02:25:54.348233 30701 solver.cpp:218] Iteration 132600 (3.55353 iter/s, 28.141s/100 iters), loss = 0.000719731
I0527 02:25:54.348389 30701 solver.cpp:237]     Train net output #0: loss = 0.000717832 (* 1 = 0.000717832 loss)
I0527 02:25:54.348402 30701 sgd_solver.cpp:105] Iteration 132600, lr = 0.00337
I0527 02:26:22.502946 30701 solver.cpp:218] Iteration 132700 (3.55187 iter/s, 28.1542s/100 iters), loss = 0.000440917
I0527 02:26:22.502996 30701 solver.cpp:237]     Train net output #0: loss = 0.000439017 (* 1 = 0.000439017 loss)
I0527 02:26:22.503021 30701 sgd_solver.cpp:105] Iteration 132700, lr = 0.003365
I0527 02:26:50.647927 30701 solver.cpp:218] Iteration 132800 (3.55308 iter/s, 28.1446s/100 iters), loss = 0.000151903
I0527 02:26:50.648078 30701 solver.cpp:237]     Train net output #0: loss = 0.000150004 (* 1 = 0.000150004 loss)
I0527 02:26:50.648097 30701 sgd_solver.cpp:105] Iteration 132800, lr = 0.00336
I0527 02:27:18.775876 30701 solver.cpp:218] Iteration 132900 (3.55525 iter/s, 28.1275s/100 iters), loss = 0.000134593
I0527 02:27:18.775926 30701 solver.cpp:237]     Train net output #0: loss = 0.000132694 (* 1 = 0.000132694 loss)
I0527 02:27:18.775954 30701 sgd_solver.cpp:105] Iteration 132900, lr = 0.003355
I0527 02:27:46.626286 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_133000.caffemodel
I0527 02:27:47.148862 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_133000.solverstate
I0527 02:27:47.301810 30701 solver.cpp:330] Iteration 133000, Testing net (#0)
I0527 02:27:48.786747 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:27:50.263782 30701 solver.cpp:397]     Test net output #0: accuracy = 0.85
I0527 02:27:50.263823 30701 solver.cpp:397]     Test net output #1: loss = 0.702725 (* 1 = 0.702725 loss)
I0527 02:27:50.541153 30701 solver.cpp:218] Iteration 133000 (3.14814 iter/s, 31.7648s/100 iters), loss = 0.000227649
I0527 02:27:50.541203 30701 solver.cpp:237]     Train net output #0: loss = 0.000225749 (* 1 = 0.000225749 loss)
I0527 02:27:50.541227 30701 sgd_solver.cpp:105] Iteration 133000, lr = 0.00335
I0527 02:27:51.690062 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:28:18.700525 30701 solver.cpp:218] Iteration 133100 (3.55127 iter/s, 28.159s/100 iters), loss = 0.000123494
I0527 02:28:18.700731 30701 solver.cpp:237]     Train net output #0: loss = 0.000121594 (* 1 = 0.000121594 loss)
I0527 02:28:18.700747 30701 sgd_solver.cpp:105] Iteration 133100, lr = 0.003345
I0527 02:28:46.860741 30701 solver.cpp:218] Iteration 133200 (3.55118 iter/s, 28.1597s/100 iters), loss = 0.000127115
I0527 02:28:46.860800 30701 solver.cpp:237]     Train net output #0: loss = 0.000125216 (* 1 = 0.000125216 loss)
I0527 02:28:46.860810 30701 sgd_solver.cpp:105] Iteration 133200, lr = 0.00334
I0527 02:29:14.985093 30701 solver.cpp:218] Iteration 133300 (3.55569 iter/s, 28.1239s/100 iters), loss = 0.000378738
I0527 02:29:14.985252 30701 solver.cpp:237]     Train net output #0: loss = 0.000376838 (* 1 = 0.000376838 loss)
I0527 02:29:14.985263 30701 sgd_solver.cpp:105] Iteration 133300, lr = 0.003335
I0527 02:29:43.110725 30701 solver.cpp:218] Iteration 133400 (3.55554 iter/s, 28.1251s/100 iters), loss = 0.000413413
I0527 02:29:43.110783 30701 solver.cpp:237]     Train net output #0: loss = 0.000411513 (* 1 = 0.000411513 loss)
I0527 02:29:43.110793 30701 sgd_solver.cpp:105] Iteration 133400, lr = 0.00333
I0527 02:30:11.208184 30701 solver.cpp:218] Iteration 133500 (3.5591 iter/s, 28.097s/100 iters), loss = 0.000366124
I0527 02:30:11.208341 30701 solver.cpp:237]     Train net output #0: loss = 0.000364225 (* 1 = 0.000364225 loss)
I0527 02:30:11.208353 30701 sgd_solver.cpp:105] Iteration 133500, lr = 0.003325
I0527 02:30:37.960340 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:30:39.351265 30701 solver.cpp:218] Iteration 133600 (3.55334 iter/s, 28.1426s/100 iters), loss = 0.00010288
I0527 02:30:39.351322 30701 solver.cpp:237]     Train net output #0: loss = 0.000100981 (* 1 = 0.000100981 loss)
I0527 02:30:39.351332 30701 sgd_solver.cpp:105] Iteration 133600, lr = 0.00332
I0527 02:31:07.521880 30701 solver.cpp:218] Iteration 133700 (3.54986 iter/s, 28.1702s/100 iters), loss = 9.0462e-05
I0527 02:31:07.522064 30701 solver.cpp:237]     Train net output #0: loss = 8.85626e-05 (* 1 = 8.85626e-05 loss)
I0527 02:31:07.522088 30701 sgd_solver.cpp:105] Iteration 133700, lr = 0.003315
I0527 02:31:35.687968 30701 solver.cpp:218] Iteration 133800 (3.55047 iter/s, 28.1653s/100 iters), loss = 0.000412678
I0527 02:31:35.688033 30701 solver.cpp:237]     Train net output #0: loss = 0.000410779 (* 1 = 0.000410779 loss)
I0527 02:31:35.688043 30701 sgd_solver.cpp:105] Iteration 133800, lr = 0.00331
I0527 02:32:03.825350 30701 solver.cpp:218] Iteration 133900 (3.55408 iter/s, 28.1367s/100 iters), loss = 7.27171e-05
I0527 02:32:03.825517 30701 solver.cpp:237]     Train net output #0: loss = 7.0818e-05 (* 1 = 7.0818e-05 loss)
I0527 02:32:03.825528 30701 sgd_solver.cpp:105] Iteration 133900, lr = 0.003305
I0527 02:32:31.680951 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_134000.caffemodel
I0527 02:32:32.190882 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_134000.solverstate
I0527 02:32:32.344602 30701 solver.cpp:330] Iteration 134000, Testing net (#0)
I0527 02:32:35.299448 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 02:32:35.299571 30701 solver.cpp:397]     Test net output #1: loss = 0.865164 (* 1 = 0.865164 loss)
I0527 02:32:35.577155 30701 solver.cpp:218] Iteration 134000 (3.14951 iter/s, 31.751s/100 iters), loss = 0.000212643
I0527 02:32:35.577214 30701 solver.cpp:237]     Train net output #0: loss = 0.000210744 (* 1 = 0.000210744 loss)
I0527 02:32:35.577222 30701 sgd_solver.cpp:105] Iteration 134000, lr = 0.0033
I0527 02:33:03.739127 30701 solver.cpp:218] Iteration 134100 (3.55097 iter/s, 28.1613s/100 iters), loss = 0.000147183
I0527 02:33:03.739189 30701 solver.cpp:237]     Train net output #0: loss = 0.000145283 (* 1 = 0.000145283 loss)
I0527 02:33:03.739198 30701 sgd_solver.cpp:105] Iteration 134100, lr = 0.003295
I0527 02:33:28.247848 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:33:31.893448 30701 solver.cpp:218] Iteration 134200 (3.55194 iter/s, 28.1537s/100 iters), loss = 0.000385425
I0527 02:33:31.893499 30701 solver.cpp:237]     Train net output #0: loss = 0.000383525 (* 1 = 0.000383525 loss)
I0527 02:33:31.893524 30701 sgd_solver.cpp:105] Iteration 134200, lr = 0.00329
I0527 02:34:00.029408 30701 solver.cpp:218] Iteration 134300 (3.55425 iter/s, 28.1353s/100 iters), loss = 0.000632974
I0527 02:34:00.029605 30701 solver.cpp:237]     Train net output #0: loss = 0.000631075 (* 1 = 0.000631075 loss)
I0527 02:34:00.029621 30701 sgd_solver.cpp:105] Iteration 134300, lr = 0.003285
I0527 02:34:28.159714 30701 solver.cpp:218] Iteration 134400 (3.55498 iter/s, 28.1295s/100 iters), loss = 0.000271509
I0527 02:34:28.159771 30701 solver.cpp:237]     Train net output #0: loss = 0.000269609 (* 1 = 0.000269609 loss)
I0527 02:34:28.159780 30701 sgd_solver.cpp:105] Iteration 134400, lr = 0.00328
I0527 02:34:56.286314 30701 solver.cpp:218] Iteration 134500 (3.55543 iter/s, 28.126s/100 iters), loss = 9.3342e-05
I0527 02:34:56.286494 30701 solver.cpp:237]     Train net output #0: loss = 9.14419e-05 (* 1 = 9.14419e-05 loss)
I0527 02:34:56.286517 30701 sgd_solver.cpp:105] Iteration 134500, lr = 0.003275
I0527 02:35:24.392241 30701 solver.cpp:218] Iteration 134600 (3.55806 iter/s, 28.1052s/100 iters), loss = 0.000195376
I0527 02:35:24.392298 30701 solver.cpp:237]     Train net output #0: loss = 0.000193475 (* 1 = 0.000193475 loss)
I0527 02:35:24.392308 30701 sgd_solver.cpp:105] Iteration 134600, lr = 0.00327
I0527 02:35:52.513226 30701 solver.cpp:218] Iteration 134700 (3.55614 iter/s, 28.1204s/100 iters), loss = 0.000122744
I0527 02:35:52.513380 30701 solver.cpp:237]     Train net output #0: loss = 0.000120843 (* 1 = 0.000120843 loss)
I0527 02:35:52.513391 30701 sgd_solver.cpp:105] Iteration 134700, lr = 0.003265
I0527 02:36:14.458972 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:36:20.629201 30701 solver.cpp:218] Iteration 134800 (3.55679 iter/s, 28.1153s/100 iters), loss = 0.000195447
I0527 02:36:20.629261 30701 solver.cpp:237]     Train net output #0: loss = 0.000193547 (* 1 = 0.000193547 loss)
I0527 02:36:20.629272 30701 sgd_solver.cpp:105] Iteration 134800, lr = 0.00326
I0527 02:36:48.782377 30701 solver.cpp:218] Iteration 134900 (3.55207 iter/s, 28.1526s/100 iters), loss = 7.24946e-05
I0527 02:36:48.782528 30701 solver.cpp:237]     Train net output #0: loss = 7.0594e-05 (* 1 = 7.0594e-05 loss)
I0527 02:36:48.782539 30701 sgd_solver.cpp:105] Iteration 134900, lr = 0.003255
I0527 02:37:16.618504 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_135000.caffemodel
I0527 02:37:17.041276 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_135000.solverstate
I0527 02:37:17.192133 30701 solver.cpp:330] Iteration 135000, Testing net (#0)
I0527 02:37:20.152482 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 02:37:20.152621 30701 solver.cpp:397]     Test net output #1: loss = 0.771803 (* 1 = 0.771803 loss)
I0527 02:37:20.431903 30701 solver.cpp:218] Iteration 135000 (3.15968 iter/s, 31.6488s/100 iters), loss = 0.000169351
I0527 02:37:20.431951 30701 solver.cpp:237]     Train net output #0: loss = 0.000167451 (* 1 = 0.000167451 loss)
I0527 02:37:20.431962 30701 sgd_solver.cpp:105] Iteration 135000, lr = 0.00325
I0527 02:37:48.518008 30701 solver.cpp:218] Iteration 135100 (3.56055 iter/s, 28.0855s/100 iters), loss = 0.000164523
I0527 02:37:48.518065 30701 solver.cpp:237]     Train net output #0: loss = 0.000162623 (* 1 = 0.000162623 loss)
I0527 02:37:48.518074 30701 sgd_solver.cpp:105] Iteration 135100, lr = 0.003245
I0527 02:38:16.603880 30701 solver.cpp:218] Iteration 135200 (3.56058 iter/s, 28.0853s/100 iters), loss = 0.00189346
I0527 02:38:16.604084 30701 solver.cpp:237]     Train net output #0: loss = 0.00189156 (* 1 = 0.00189156 loss)
I0527 02:38:16.604097 30701 sgd_solver.cpp:105] Iteration 135200, lr = 0.00324
I0527 02:38:44.684182 30701 solver.cpp:218] Iteration 135300 (3.56131 iter/s, 28.0796s/100 iters), loss = 0.000205245
I0527 02:38:44.684237 30701 solver.cpp:237]     Train net output #0: loss = 0.000203344 (* 1 = 0.000203344 loss)
I0527 02:38:44.684252 30701 sgd_solver.cpp:105] Iteration 135300, lr = 0.003235
I0527 02:39:04.078030 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:39:12.766671 30701 solver.cpp:218] Iteration 135400 (3.56101 iter/s, 28.0819s/100 iters), loss = 0.000356379
I0527 02:39:12.766716 30701 solver.cpp:237]     Train net output #0: loss = 0.000354478 (* 1 = 0.000354478 loss)
I0527 02:39:12.766726 30701 sgd_solver.cpp:105] Iteration 135400, lr = 0.00323
I0527 02:39:40.849550 30701 solver.cpp:218] Iteration 135500 (3.56096 iter/s, 28.0823s/100 iters), loss = 0.000111623
I0527 02:39:40.849725 30701 solver.cpp:237]     Train net output #0: loss = 0.000109722 (* 1 = 0.000109722 loss)
I0527 02:39:40.849737 30701 sgd_solver.cpp:105] Iteration 135500, lr = 0.003225
I0527 02:40:08.959250 30701 solver.cpp:218] Iteration 135600 (3.55758 iter/s, 28.109s/100 iters), loss = 0.000343903
I0527 02:40:08.959295 30701 solver.cpp:237]     Train net output #0: loss = 0.000342002 (* 1 = 0.000342002 loss)
I0527 02:40:08.959305 30701 sgd_solver.cpp:105] Iteration 135600, lr = 0.00322
I0527 02:40:37.042943 30701 solver.cpp:218] Iteration 135700 (3.56086 iter/s, 28.0831s/100 iters), loss = 0.000170956
I0527 02:40:37.043099 30701 solver.cpp:237]     Train net output #0: loss = 0.000169056 (* 1 = 0.000169056 loss)
I0527 02:40:37.043110 30701 sgd_solver.cpp:105] Iteration 135700, lr = 0.003215
I0527 02:41:05.135898 30701 solver.cpp:218] Iteration 135800 (3.5597 iter/s, 28.0923s/100 iters), loss = 0.000610871
I0527 02:41:05.135957 30701 solver.cpp:237]     Train net output #0: loss = 0.00060897 (* 1 = 0.00060897 loss)
I0527 02:41:05.135967 30701 sgd_solver.cpp:105] Iteration 135800, lr = 0.00321
I0527 02:41:33.207120 30701 solver.cpp:218] Iteration 135900 (3.56244 iter/s, 28.0707s/100 iters), loss = 0.000234731
I0527 02:41:33.207298 30701 solver.cpp:237]     Train net output #0: loss = 0.000232831 (* 1 = 0.000232831 loss)
I0527 02:41:33.207310 30701 sgd_solver.cpp:105] Iteration 135900, lr = 0.003205
I0527 02:41:50.076985 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:42:01.013502 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_136000.caffemodel
I0527 02:42:01.374348 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_136000.solverstate
I0527 02:42:01.524644 30701 solver.cpp:330] Iteration 136000, Testing net (#0)
I0527 02:42:01.736307 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:42:04.481001 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 02:42:04.481133 30701 solver.cpp:397]     Test net output #1: loss = 0.841227 (* 1 = 0.841227 loss)
I0527 02:42:04.758759 30701 solver.cpp:218] Iteration 136000 (3.16948 iter/s, 31.5509s/100 iters), loss = 0.00039221
I0527 02:42:04.758816 30701 solver.cpp:237]     Train net output #0: loss = 0.00039031 (* 1 = 0.00039031 loss)
I0527 02:42:04.758826 30701 sgd_solver.cpp:105] Iteration 136000, lr = 0.0032
I0527 02:42:32.819548 30701 solver.cpp:218] Iteration 136100 (3.56376 iter/s, 28.0602s/100 iters), loss = 9.53466e-05
I0527 02:42:32.819595 30701 solver.cpp:237]     Train net output #0: loss = 9.34464e-05 (* 1 = 9.34464e-05 loss)
I0527 02:42:32.819603 30701 sgd_solver.cpp:105] Iteration 136100, lr = 0.003195
I0527 02:43:00.900141 30701 solver.cpp:218] Iteration 136200 (3.56125 iter/s, 28.08s/100 iters), loss = 6.57497e-05
I0527 02:43:00.900346 30701 solver.cpp:237]     Train net output #0: loss = 6.38495e-05 (* 1 = 6.38495e-05 loss)
I0527 02:43:00.900358 30701 sgd_solver.cpp:105] Iteration 136200, lr = 0.00319
I0527 02:43:28.969974 30701 solver.cpp:218] Iteration 136300 (3.56263 iter/s, 28.0692s/100 iters), loss = 0.000974161
I0527 02:43:28.970019 30701 solver.cpp:237]     Train net output #0: loss = 0.000972261 (* 1 = 0.000972261 loss)
I0527 02:43:28.970027 30701 sgd_solver.cpp:105] Iteration 136300, lr = 0.003185
I0527 02:43:57.066234 30701 solver.cpp:218] Iteration 136400 (3.55926 iter/s, 28.0957s/100 iters), loss = 0.00010103
I0527 02:43:57.066426 30701 solver.cpp:237]     Train net output #0: loss = 9.91305e-05 (* 1 = 9.91305e-05 loss)
I0527 02:43:57.066437 30701 sgd_solver.cpp:105] Iteration 136400, lr = 0.00318
I0527 02:44:25.165233 30701 solver.cpp:218] Iteration 136500 (3.55893 iter/s, 28.0983s/100 iters), loss = 4.23564e-05
I0527 02:44:25.165282 30701 solver.cpp:237]     Train net output #0: loss = 4.04563e-05 (* 1 = 4.04563e-05 loss)
I0527 02:44:25.165290 30701 sgd_solver.cpp:105] Iteration 136500, lr = 0.003175
I0527 02:44:39.516388 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:44:53.277956 30701 solver.cpp:218] Iteration 136600 (3.55718 iter/s, 28.1122s/100 iters), loss = 0.00032325
I0527 02:44:53.278012 30701 solver.cpp:237]     Train net output #0: loss = 0.00032135 (* 1 = 0.00032135 loss)
I0527 02:44:53.278022 30701 sgd_solver.cpp:105] Iteration 136600, lr = 0.00317
I0527 02:45:21.395889 30701 solver.cpp:218] Iteration 136700 (3.55652 iter/s, 28.1174s/100 iters), loss = 4.47675e-05
I0527 02:45:21.396072 30701 solver.cpp:237]     Train net output #0: loss = 4.28673e-05 (* 1 = 4.28673e-05 loss)
I0527 02:45:21.396085 30701 sgd_solver.cpp:105] Iteration 136700, lr = 0.003165
I0527 02:45:49.501492 30701 solver.cpp:218] Iteration 136800 (3.55809 iter/s, 28.1049s/100 iters), loss = 0.000210204
I0527 02:45:49.501538 30701 solver.cpp:237]     Train net output #0: loss = 0.000208304 (* 1 = 0.000208304 loss)
I0527 02:45:49.501545 30701 sgd_solver.cpp:105] Iteration 136800, lr = 0.00316
I0527 02:46:17.607866 30701 solver.cpp:218] Iteration 136900 (3.55798 iter/s, 28.1058s/100 iters), loss = 0.000165423
I0527 02:46:17.608001 30701 solver.cpp:237]     Train net output #0: loss = 0.000163523 (* 1 = 0.000163523 loss)
I0527 02:46:17.608011 30701 sgd_solver.cpp:105] Iteration 136900, lr = 0.003155
I0527 02:46:45.413609 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_137000.caffemodel
I0527 02:46:45.725970 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_137000.solverstate
I0527 02:46:45.876864 30701 solver.cpp:330] Iteration 137000, Testing net (#0)
I0527 02:46:48.835114 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0527 02:46:48.835233 30701 solver.cpp:397]     Test net output #1: loss = 0.887348 (* 1 = 0.887348 loss)
I0527 02:46:49.112790 30701 solver.cpp:218] Iteration 137000 (3.17418 iter/s, 31.5042s/100 iters), loss = 0.000178129
I0527 02:46:49.112851 30701 solver.cpp:237]     Train net output #0: loss = 0.000176229 (* 1 = 0.000176229 loss)
I0527 02:46:49.112860 30701 sgd_solver.cpp:105] Iteration 137000, lr = 0.00315
I0527 02:47:17.240530 30701 solver.cpp:218] Iteration 137100 (3.55528 iter/s, 28.1272s/100 iters), loss = 0.000187139
I0527 02:47:17.240573 30701 solver.cpp:237]     Train net output #0: loss = 0.000185239 (* 1 = 0.000185239 loss)
I0527 02:47:17.240582 30701 sgd_solver.cpp:105] Iteration 137100, lr = 0.003145
I0527 02:47:29.062875 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:47:45.347980 30701 solver.cpp:218] Iteration 137200 (3.55784 iter/s, 28.1069s/100 iters), loss = 0.000577104
I0527 02:47:45.348028 30701 solver.cpp:237]     Train net output #0: loss = 0.000575204 (* 1 = 0.000575204 loss)
I0527 02:47:45.348037 30701 sgd_solver.cpp:105] Iteration 137200, lr = 0.00314
I0527 02:48:13.465931 30701 solver.cpp:218] Iteration 137300 (3.55651 iter/s, 28.1174s/100 iters), loss = 0.000454027
I0527 02:48:13.466161 30701 solver.cpp:237]     Train net output #0: loss = 0.000452127 (* 1 = 0.000452127 loss)
I0527 02:48:13.466172 30701 sgd_solver.cpp:105] Iteration 137300, lr = 0.003135
I0527 02:48:41.555761 30701 solver.cpp:218] Iteration 137400 (3.5601 iter/s, 28.0891s/100 iters), loss = 0.000113474
I0527 02:48:41.555805 30701 solver.cpp:237]     Train net output #0: loss = 0.000111573 (* 1 = 0.000111573 loss)
I0527 02:48:41.555814 30701 sgd_solver.cpp:105] Iteration 137400, lr = 0.00313
I0527 02:49:09.646772 30701 solver.cpp:218] Iteration 137500 (3.55992 iter/s, 28.0905s/100 iters), loss = 0.000171902
I0527 02:49:09.646968 30701 solver.cpp:237]     Train net output #0: loss = 0.000170001 (* 1 = 0.000170001 loss)
I0527 02:49:09.646980 30701 sgd_solver.cpp:105] Iteration 137500, lr = 0.003125
I0527 02:49:37.748474 30701 solver.cpp:218] Iteration 137600 (3.55859 iter/s, 28.101s/100 iters), loss = 0.00031103
I0527 02:49:37.748522 30701 solver.cpp:237]     Train net output #0: loss = 0.000309129 (* 1 = 0.000309129 loss)
I0527 02:49:37.748530 30701 sgd_solver.cpp:105] Iteration 137600, lr = 0.00312
I0527 02:50:05.843912 30701 solver.cpp:218] Iteration 137700 (3.55936 iter/s, 28.0949s/100 iters), loss = 0.000197798
I0527 02:50:05.844084 30701 solver.cpp:237]     Train net output #0: loss = 0.000195897 (* 1 = 0.000195897 loss)
I0527 02:50:05.844099 30701 sgd_solver.cpp:105] Iteration 137700, lr = 0.003115
I0527 02:50:15.133191 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:50:33.929076 30701 solver.cpp:218] Iteration 137800 (3.56068 iter/s, 28.0845s/100 iters), loss = 0.000850639
I0527 02:50:33.929121 30701 solver.cpp:237]     Train net output #0: loss = 0.000848738 (* 1 = 0.000848738 loss)
I0527 02:50:33.929131 30701 sgd_solver.cpp:105] Iteration 137800, lr = 0.00311
I0527 02:51:02.031111 30701 solver.cpp:218] Iteration 137900 (3.55853 iter/s, 28.1015s/100 iters), loss = 0.000391573
I0527 02:51:02.031325 30701 solver.cpp:237]     Train net output #0: loss = 0.000389672 (* 1 = 0.000389672 loss)
I0527 02:51:02.031337 30701 sgd_solver.cpp:105] Iteration 137900, lr = 0.003105
I0527 02:51:29.862844 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_138000.caffemodel
I0527 02:51:30.176856 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_138000.solverstate
I0527 02:51:30.327697 30701 solver.cpp:330] Iteration 138000, Testing net (#0)
I0527 02:51:32.226114 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:51:33.290660 30701 solver.cpp:397]     Test net output #0: accuracy = 0.842
I0527 02:51:33.290712 30701 solver.cpp:397]     Test net output #1: loss = 0.75793 (* 1 = 0.75793 loss)
I0527 02:51:33.568006 30701 solver.cpp:218] Iteration 138000 (3.17096 iter/s, 31.5362s/100 iters), loss = 0.000266664
I0527 02:51:33.568053 30701 solver.cpp:237]     Train net output #0: loss = 0.000264763 (* 1 = 0.000264763 loss)
I0527 02:51:33.568060 30701 sgd_solver.cpp:105] Iteration 138000, lr = 0.0031
I0527 02:52:01.667841 30701 solver.cpp:218] Iteration 138100 (3.55881 iter/s, 28.0993s/100 iters), loss = 3.97253e-05
I0527 02:52:01.667896 30701 solver.cpp:237]     Train net output #0: loss = 3.78242e-05 (* 1 = 3.78242e-05 loss)
I0527 02:52:01.667907 30701 sgd_solver.cpp:105] Iteration 138100, lr = 0.003095
I0527 02:52:29.752110 30701 solver.cpp:218] Iteration 138200 (3.56078 iter/s, 28.0837s/100 iters), loss = 0.000158994
I0527 02:52:29.752274 30701 solver.cpp:237]     Train net output #0: loss = 0.000157093 (* 1 = 0.000157093 loss)
I0527 02:52:29.752286 30701 sgd_solver.cpp:105] Iteration 138200, lr = 0.00309
I0527 02:52:57.833664 30701 solver.cpp:218] Iteration 138300 (3.56114 iter/s, 28.0809s/100 iters), loss = 0.000337216
I0527 02:52:57.833709 30701 solver.cpp:237]     Train net output #0: loss = 0.000335315 (* 1 = 0.000335315 loss)
I0527 02:52:57.833717 30701 sgd_solver.cpp:105] Iteration 138300, lr = 0.003085
I0527 02:53:04.872268 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:53:25.935521 30701 solver.cpp:218] Iteration 138400 (3.55855 iter/s, 28.1013s/100 iters), loss = 0.000488275
I0527 02:53:25.935570 30701 solver.cpp:237]     Train net output #0: loss = 0.000486375 (* 1 = 0.000486375 loss)
I0527 02:53:25.935581 30701 sgd_solver.cpp:105] Iteration 138400, lr = 0.00308
I0527 02:53:54.024854 30701 solver.cpp:218] Iteration 138500 (3.56014 iter/s, 28.0888s/100 iters), loss = 0.000318342
I0527 02:53:54.025053 30701 solver.cpp:237]     Train net output #0: loss = 0.000316441 (* 1 = 0.000316441 loss)
I0527 02:53:54.025064 30701 sgd_solver.cpp:105] Iteration 138500, lr = 0.003075
I0527 02:54:22.102074 30701 solver.cpp:218] Iteration 138600 (3.56169 iter/s, 28.0766s/100 iters), loss = 0.000249136
I0527 02:54:22.102118 30701 solver.cpp:237]     Train net output #0: loss = 0.000247235 (* 1 = 0.000247235 loss)
I0527 02:54:22.102125 30701 sgd_solver.cpp:105] Iteration 138600, lr = 0.00307
I0527 02:54:50.191676 30701 solver.cpp:218] Iteration 138700 (3.5601 iter/s, 28.0891s/100 iters), loss = 0.000289256
I0527 02:54:50.191864 30701 solver.cpp:237]     Train net output #0: loss = 0.000287355 (* 1 = 0.000287355 loss)
I0527 02:54:50.191875 30701 sgd_solver.cpp:105] Iteration 138700, lr = 0.003065
I0527 02:55:18.312010 30701 solver.cpp:218] Iteration 138800 (3.55623 iter/s, 28.1197s/100 iters), loss = 0.000906202
I0527 02:55:18.312067 30701 solver.cpp:237]     Train net output #0: loss = 0.000904301 (* 1 = 0.000904301 loss)
I0527 02:55:18.312077 30701 sgd_solver.cpp:105] Iteration 138800, lr = 0.00306
I0527 02:55:46.428573 30701 solver.cpp:218] Iteration 138900 (3.55669 iter/s, 28.116s/100 iters), loss = 7.14109e-05
I0527 02:55:46.428761 30701 solver.cpp:237]     Train net output #0: loss = 6.95103e-05 (* 1 = 6.95103e-05 loss)
I0527 02:55:46.428791 30701 sgd_solver.cpp:105] Iteration 138900, lr = 0.003055
I0527 02:55:50.945351 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:56:14.276929 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_139000.caffemodel
I0527 02:56:14.608597 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_139000.solverstate
I0527 02:56:14.758654 30701 solver.cpp:330] Iteration 139000, Testing net (#0)
I0527 02:56:17.712435 30701 solver.cpp:397]     Test net output #0: accuracy = 0.832
I0527 02:56:17.712591 30701 solver.cpp:397]     Test net output #1: loss = 0.841167 (* 1 = 0.841167 loss)
I0527 02:56:17.991427 30701 solver.cpp:218] Iteration 139000 (3.16835 iter/s, 31.5622s/100 iters), loss = 0.000273246
I0527 02:56:17.991484 30701 solver.cpp:237]     Train net output #0: loss = 0.000271345 (* 1 = 0.000271345 loss)
I0527 02:56:17.991493 30701 sgd_solver.cpp:105] Iteration 139000, lr = 0.00305
I0527 02:56:46.108790 30701 solver.cpp:218] Iteration 139100 (3.55659 iter/s, 28.1168s/100 iters), loss = 0.000409399
I0527 02:56:46.108837 30701 solver.cpp:237]     Train net output #0: loss = 0.000407497 (* 1 = 0.000407497 loss)
I0527 02:56:46.108845 30701 sgd_solver.cpp:105] Iteration 139100, lr = 0.003045
I0527 02:57:14.230370 30701 solver.cpp:218] Iteration 139200 (3.55605 iter/s, 28.1211s/100 iters), loss = 0.000582501
I0527 02:57:14.230532 30701 solver.cpp:237]     Train net output #0: loss = 0.0005806 (* 1 = 0.0005806 loss)
I0527 02:57:14.230546 30701 sgd_solver.cpp:105] Iteration 139200, lr = 0.00304
I0527 02:57:42.340217 30701 solver.cpp:218] Iteration 139300 (3.55755 iter/s, 28.1092s/100 iters), loss = 0.000220283
I0527 02:57:42.340261 30701 solver.cpp:237]     Train net output #0: loss = 0.000218382 (* 1 = 0.000218382 loss)
I0527 02:57:42.340270 30701 sgd_solver.cpp:105] Iteration 139300, lr = 0.003035
I0527 02:58:10.443372 30701 solver.cpp:218] Iteration 139400 (3.55838 iter/s, 28.1026s/100 iters), loss = 0.000159806
I0527 02:58:10.443603 30701 solver.cpp:237]     Train net output #0: loss = 0.000157904 (* 1 = 0.000157904 loss)
I0527 02:58:10.443620 30701 sgd_solver.cpp:105] Iteration 139400, lr = 0.00303
I0527 02:58:38.534521 30701 solver.cpp:218] Iteration 139500 (3.55993 iter/s, 28.0905s/100 iters), loss = 0.000869897
I0527 02:58:38.534562 30701 solver.cpp:237]     Train net output #0: loss = 0.000867996 (* 1 = 0.000867996 loss)
I0527 02:58:38.534571 30701 sgd_solver.cpp:105] Iteration 139500, lr = 0.003025
I0527 02:58:40.520385 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 02:59:06.636374 30701 solver.cpp:218] Iteration 139600 (3.55855 iter/s, 28.1013s/100 iters), loss = 0.0001932
I0527 02:59:06.636421 30701 solver.cpp:237]     Train net output #0: loss = 0.000191299 (* 1 = 0.000191299 loss)
I0527 02:59:06.636430 30701 sgd_solver.cpp:105] Iteration 139600, lr = 0.00302
I0527 02:59:34.716280 30701 solver.cpp:218] Iteration 139700 (3.56133 iter/s, 28.0794s/100 iters), loss = 0.000491401
I0527 02:59:34.716437 30701 solver.cpp:237]     Train net output #0: loss = 0.0004895 (* 1 = 0.0004895 loss)
I0527 02:59:34.716459 30701 sgd_solver.cpp:105] Iteration 139700, lr = 0.003015
I0527 03:00:02.790822 30701 solver.cpp:218] Iteration 139800 (3.56202 iter/s, 28.0739s/100 iters), loss = 0.0003574
I0527 03:00:02.790868 30701 solver.cpp:237]     Train net output #0: loss = 0.000355499 (* 1 = 0.000355499 loss)
I0527 03:00:02.790875 30701 sgd_solver.cpp:105] Iteration 139800, lr = 0.00301
I0527 03:00:30.909895 30701 solver.cpp:218] Iteration 139900 (3.55637 iter/s, 28.1186s/100 iters), loss = 0.00022432
I0527 03:00:30.910111 30701 solver.cpp:237]     Train net output #0: loss = 0.000222418 (* 1 = 0.000222418 loss)
I0527 03:00:30.910122 30701 sgd_solver.cpp:105] Iteration 139900, lr = 0.003005
I0527 03:00:58.719853 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_140000.caffemodel
I0527 03:00:59.058414 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_140000.solverstate
I0527 03:00:59.210753 30701 solver.cpp:330] Iteration 140000, Testing net (#0)
I0527 03:01:02.178053 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 03:01:02.178197 30701 solver.cpp:397]     Test net output #1: loss = 0.814078 (* 1 = 0.814078 loss)
I0527 03:01:02.455142 30701 solver.cpp:218] Iteration 140000 (3.17012 iter/s, 31.5445s/100 iters), loss = 0.000371923
I0527 03:01:02.455189 30701 solver.cpp:237]     Train net output #0: loss = 0.000370022 (* 1 = 0.000370022 loss)
I0527 03:01:02.455209 30701 sgd_solver.cpp:105] Iteration 140000, lr = 0.003
I0527 03:01:29.976377 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:01:30.520690 30701 solver.cpp:218] Iteration 140100 (3.56315 iter/s, 28.065s/100 iters), loss = 0.000170947
I0527 03:01:30.520736 30701 solver.cpp:237]     Train net output #0: loss = 0.000169046 (* 1 = 0.000169046 loss)
I0527 03:01:30.520745 30701 sgd_solver.cpp:105] Iteration 140100, lr = 0.002995
I0527 03:01:58.588737 30701 solver.cpp:218] Iteration 140200 (3.56283 iter/s, 28.0675s/100 iters), loss = 0.000379207
I0527 03:01:58.588894 30701 solver.cpp:237]     Train net output #0: loss = 0.000377307 (* 1 = 0.000377307 loss)
I0527 03:01:58.588907 30701 sgd_solver.cpp:105] Iteration 140200, lr = 0.00299
I0527 03:02:26.658093 30701 solver.cpp:218] Iteration 140300 (3.56268 iter/s, 28.0687s/100 iters), loss = 0.00014968
I0527 03:02:26.658140 30701 solver.cpp:237]     Train net output #0: loss = 0.000147779 (* 1 = 0.000147779 loss)
I0527 03:02:26.658149 30701 sgd_solver.cpp:105] Iteration 140300, lr = 0.002985
I0527 03:02:54.727882 30701 solver.cpp:218] Iteration 140400 (3.56261 iter/s, 28.0693s/100 iters), loss = 0.000437125
I0527 03:02:54.728004 30701 solver.cpp:237]     Train net output #0: loss = 0.000435224 (* 1 = 0.000435224 loss)
I0527 03:02:54.728025 30701 sgd_solver.cpp:105] Iteration 140400, lr = 0.00298
I0527 03:03:22.807371 30701 solver.cpp:218] Iteration 140500 (3.56139 iter/s, 28.0789s/100 iters), loss = 0.000382517
I0527 03:03:22.807417 30701 solver.cpp:237]     Train net output #0: loss = 0.000380616 (* 1 = 0.000380616 loss)
I0527 03:03:22.807426 30701 sgd_solver.cpp:105] Iteration 140500, lr = 0.002975
I0527 03:03:50.911960 30701 solver.cpp:218] Iteration 140600 (3.5582 iter/s, 28.1041s/100 iters), loss = 0.000196953
I0527 03:03:50.912164 30701 solver.cpp:237]     Train net output #0: loss = 0.000195052 (* 1 = 0.000195052 loss)
I0527 03:03:50.912176 30701 sgd_solver.cpp:105] Iteration 140600, lr = 0.00297
I0527 03:04:15.946662 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:04:19.023507 30701 solver.cpp:218] Iteration 140700 (3.55734 iter/s, 28.1109s/100 iters), loss = 0.000157963
I0527 03:04:19.023552 30701 solver.cpp:237]     Train net output #0: loss = 0.000156062 (* 1 = 0.000156062 loss)
I0527 03:04:19.023561 30701 sgd_solver.cpp:105] Iteration 140700, lr = 0.002965
I0527 03:04:47.129472 30701 solver.cpp:218] Iteration 140800 (3.55803 iter/s, 28.1055s/100 iters), loss = 0.000154648
I0527 03:04:47.129669 30701 solver.cpp:237]     Train net output #0: loss = 0.000152747 (* 1 = 0.000152747 loss)
I0527 03:04:47.129684 30701 sgd_solver.cpp:105] Iteration 140800, lr = 0.00296
I0527 03:05:15.258677 30701 solver.cpp:218] Iteration 140900 (3.55512 iter/s, 28.1284s/100 iters), loss = 0.000163738
I0527 03:05:15.258734 30701 solver.cpp:237]     Train net output #0: loss = 0.000161838 (* 1 = 0.000161838 loss)
I0527 03:05:15.258744 30701 sgd_solver.cpp:105] Iteration 140900, lr = 0.002955
I0527 03:05:43.099272 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_141000.caffemodel
I0527 03:05:43.412451 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_141000.solverstate
I0527 03:05:43.562831 30701 solver.cpp:330] Iteration 141000, Testing net (#0)
I0527 03:05:44.160297 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:05:46.519281 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 03:05:46.519330 30701 solver.cpp:397]     Test net output #1: loss = 0.836845 (* 1 = 0.836845 loss)
I0527 03:05:46.796277 30701 solver.cpp:218] Iteration 141000 (3.17103 iter/s, 31.5355s/100 iters), loss = 0.000202701
I0527 03:05:46.796324 30701 solver.cpp:237]     Train net output #0: loss = 0.000200801 (* 1 = 0.000200801 loss)
I0527 03:05:46.796334 30701 sgd_solver.cpp:105] Iteration 141000, lr = 0.00295
I0527 03:06:14.888295 30701 solver.cpp:218] Iteration 141100 (3.55996 iter/s, 28.0902s/100 iters), loss = 0.000109472
I0527 03:06:14.888411 30701 solver.cpp:237]     Train net output #0: loss = 0.000107572 (* 1 = 0.000107572 loss)
I0527 03:06:14.888424 30701 sgd_solver.cpp:105] Iteration 141100, lr = 0.002945
I0527 03:06:42.978919 30701 solver.cpp:218] Iteration 141200 (3.56014 iter/s, 28.0888s/100 iters), loss = 0.000199506
I0527 03:06:42.978965 30701 solver.cpp:237]     Train net output #0: loss = 0.000197607 (* 1 = 0.000197607 loss)
I0527 03:06:42.978983 30701 sgd_solver.cpp:105] Iteration 141200, lr = 0.00294
I0527 03:07:05.496115 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:07:11.109320 30701 solver.cpp:218] Iteration 141300 (3.55509 iter/s, 28.1287s/100 iters), loss = 0.000235737
I0527 03:07:11.109369 30701 solver.cpp:237]     Train net output #0: loss = 0.000233838 (* 1 = 0.000233838 loss)
I0527 03:07:11.109390 30701 sgd_solver.cpp:105] Iteration 141300, lr = 0.002935
I0527 03:07:39.251582 30701 solver.cpp:218] Iteration 141400 (3.55359 iter/s, 28.1406s/100 iters), loss = 0.000694881
I0527 03:07:39.251736 30701 solver.cpp:237]     Train net output #0: loss = 0.000692981 (* 1 = 0.000692981 loss)
I0527 03:07:39.251749 30701 sgd_solver.cpp:105] Iteration 141400, lr = 0.00293
I0527 03:08:07.409436 30701 solver.cpp:218] Iteration 141500 (3.55163 iter/s, 28.1561s/100 iters), loss = 0.00058908
I0527 03:08:07.409487 30701 solver.cpp:237]     Train net output #0: loss = 0.000587182 (* 1 = 0.000587182 loss)
I0527 03:08:07.409509 30701 sgd_solver.cpp:105] Iteration 141500, lr = 0.002925
I0527 03:08:35.563729 30701 solver.cpp:218] Iteration 141600 (3.55206 iter/s, 28.1527s/100 iters), loss = 0.000142358
I0527 03:08:35.563935 30701 solver.cpp:237]     Train net output #0: loss = 0.000140459 (* 1 = 0.000140459 loss)
I0527 03:08:35.563972 30701 sgd_solver.cpp:105] Iteration 141600, lr = 0.00292
I0527 03:09:03.730537 30701 solver.cpp:218] Iteration 141700 (3.55049 iter/s, 28.1651s/100 iters), loss = 0.000142117
I0527 03:09:03.730584 30701 solver.cpp:237]     Train net output #0: loss = 0.000140219 (* 1 = 0.000140219 loss)
I0527 03:09:03.730607 30701 sgd_solver.cpp:105] Iteration 141700, lr = 0.002915
I0527 03:09:31.887207 30701 solver.cpp:218] Iteration 141800 (3.55174 iter/s, 28.1552s/100 iters), loss = 0.000131198
I0527 03:09:31.887370 30701 solver.cpp:237]     Train net output #0: loss = 0.000129299 (* 1 = 0.000129299 loss)
I0527 03:09:31.887385 30701 sgd_solver.cpp:105] Iteration 141800, lr = 0.00291
I0527 03:09:51.898640 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:10:00.035631 30701 solver.cpp:218] Iteration 141900 (3.55279 iter/s, 28.1469s/100 iters), loss = 0.000403338
I0527 03:10:00.035676 30701 solver.cpp:237]     Train net output #0: loss = 0.000401439 (* 1 = 0.000401439 loss)
I0527 03:10:00.035684 30701 sgd_solver.cpp:105] Iteration 141900, lr = 0.002905
I0527 03:10:27.880436 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_142000.caffemodel
I0527 03:10:28.196808 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_142000.solverstate
I0527 03:10:28.346390 30701 solver.cpp:330] Iteration 142000, Testing net (#0)
I0527 03:10:31.302449 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0527 03:10:31.302489 30701 solver.cpp:397]     Test net output #1: loss = 0.854958 (* 1 = 0.854958 loss)
I0527 03:10:31.580788 30701 solver.cpp:218] Iteration 142000 (3.17022 iter/s, 31.5436s/100 iters), loss = 0.000378889
I0527 03:10:31.580849 30701 solver.cpp:237]     Train net output #0: loss = 0.00037699 (* 1 = 0.00037699 loss)
I0527 03:10:31.580862 30701 sgd_solver.cpp:105] Iteration 142000, lr = 0.0029
I0527 03:10:59.739668 30701 solver.cpp:218] Iteration 142100 (3.55145 iter/s, 28.1575s/100 iters), loss = 7.51695e-05
I0527 03:10:59.739800 30701 solver.cpp:237]     Train net output #0: loss = 7.32708e-05 (* 1 = 7.32708e-05 loss)
I0527 03:10:59.739817 30701 sgd_solver.cpp:105] Iteration 142100, lr = 0.002895
I0527 03:11:27.853075 30701 solver.cpp:218] Iteration 142200 (3.5572 iter/s, 28.112s/100 iters), loss = 0.000124371
I0527 03:11:27.853123 30701 solver.cpp:237]     Train net output #0: loss = 0.000122472 (* 1 = 0.000122472 loss)
I0527 03:11:27.853137 30701 sgd_solver.cpp:105] Iteration 142200, lr = 0.00289
I0527 03:11:55.975474 30701 solver.cpp:218] Iteration 142300 (3.55605 iter/s, 28.1211s/100 iters), loss = 0.000275248
I0527 03:11:55.975625 30701 solver.cpp:237]     Train net output #0: loss = 0.000273349 (* 1 = 0.000273349 loss)
I0527 03:11:55.975636 30701 sgd_solver.cpp:105] Iteration 142300, lr = 0.002885
I0527 03:12:24.097551 30701 solver.cpp:218] Iteration 142400 (3.5561 iter/s, 28.1207s/100 iters), loss = 0.000152248
I0527 03:12:24.097596 30701 solver.cpp:237]     Train net output #0: loss = 0.000150349 (* 1 = 0.000150349 loss)
I0527 03:12:24.097605 30701 sgd_solver.cpp:105] Iteration 142400, lr = 0.00288
I0527 03:12:41.834424 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:12:52.232187 30701 solver.cpp:218] Iteration 142500 (3.5545 iter/s, 28.1334s/100 iters), loss = 0.000118642
I0527 03:12:52.232231 30701 solver.cpp:237]     Train net output #0: loss = 0.000116743 (* 1 = 0.000116743 loss)
I0527 03:12:52.232240 30701 sgd_solver.cpp:105] Iteration 142500, lr = 0.002875
I0527 03:13:20.358244 30701 solver.cpp:218] Iteration 142600 (3.55558 iter/s, 28.1248s/100 iters), loss = 0.000264176
I0527 03:13:20.358430 30701 solver.cpp:237]     Train net output #0: loss = 0.000262276 (* 1 = 0.000262276 loss)
I0527 03:13:20.358475 30701 sgd_solver.cpp:105] Iteration 142600, lr = 0.00287
I0527 03:13:48.429105 30701 solver.cpp:218] Iteration 142700 (3.56258 iter/s, 28.0695s/100 iters), loss = 0.000461188
I0527 03:13:48.429152 30701 solver.cpp:237]     Train net output #0: loss = 0.000459289 (* 1 = 0.000459289 loss)
I0527 03:13:48.429160 30701 sgd_solver.cpp:105] Iteration 142700, lr = 0.002865
I0527 03:14:16.499575 30701 solver.cpp:218] Iteration 142800 (3.56261 iter/s, 28.0693s/100 iters), loss = 0.0020064
I0527 03:14:16.499707 30701 solver.cpp:237]     Train net output #0: loss = 0.0020045 (* 1 = 0.0020045 loss)
I0527 03:14:16.499723 30701 sgd_solver.cpp:105] Iteration 142800, lr = 0.00286
I0527 03:14:44.576612 30701 solver.cpp:218] Iteration 142900 (3.56178 iter/s, 28.0758s/100 iters), loss = 0.000299843
I0527 03:14:44.576654 30701 solver.cpp:237]     Train net output #0: loss = 0.000297943 (* 1 = 0.000297943 loss)
I0527 03:14:44.576663 30701 sgd_solver.cpp:105] Iteration 142900, lr = 0.002855
I0527 03:15:12.386287 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_143000.caffemodel
I0527 03:15:12.698642 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_143000.solverstate
I0527 03:15:12.848657 30701 solver.cpp:330] Iteration 143000, Testing net (#0)
I0527 03:15:15.127192 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:15:15.805454 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 03:15:15.805507 30701 solver.cpp:397]     Test net output #1: loss = 0.715312 (* 1 = 0.715312 loss)
I0527 03:15:16.083832 30701 solver.cpp:218] Iteration 143000 (3.174 iter/s, 31.506s/100 iters), loss = 0.000125343
I0527 03:15:16.083874 30701 solver.cpp:237]     Train net output #0: loss = 0.000123444 (* 1 = 0.000123444 loss)
I0527 03:15:16.083884 30701 sgd_solver.cpp:105] Iteration 143000, lr = 0.00285
I0527 03:15:31.278515 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:15:44.196236 30701 solver.cpp:218] Iteration 143100 (3.55729 iter/s, 28.1113s/100 iters), loss = 0.000168965
I0527 03:15:44.196451 30701 solver.cpp:237]     Train net output #0: loss = 0.000167066 (* 1 = 0.000167066 loss)
I0527 03:15:44.196463 30701 sgd_solver.cpp:105] Iteration 143100, lr = 0.002845
I0527 03:16:12.296934 30701 solver.cpp:218] Iteration 143200 (3.55879 iter/s, 28.0995s/100 iters), loss = 0.000158425
I0527 03:16:12.296982 30701 solver.cpp:237]     Train net output #0: loss = 0.000156526 (* 1 = 0.000156526 loss)
I0527 03:16:12.296990 30701 sgd_solver.cpp:105] Iteration 143200, lr = 0.00284
I0527 03:16:40.401896 30701 solver.cpp:218] Iteration 143300 (3.55822 iter/s, 28.1039s/100 iters), loss = 0.000125854
I0527 03:16:40.402060 30701 solver.cpp:237]     Train net output #0: loss = 0.000123955 (* 1 = 0.000123955 loss)
I0527 03:16:40.402071 30701 sgd_solver.cpp:105] Iteration 143300, lr = 0.002835
I0527 03:17:08.507796 30701 solver.cpp:218] Iteration 143400 (3.55812 iter/s, 28.1047s/100 iters), loss = 0.000441323
I0527 03:17:08.507840 30701 solver.cpp:237]     Train net output #0: loss = 0.000439424 (* 1 = 0.000439424 loss)
I0527 03:17:08.507849 30701 sgd_solver.cpp:105] Iteration 143400, lr = 0.00283
I0527 03:17:36.598317 30701 solver.cpp:218] Iteration 143500 (3.56005 iter/s, 28.0895s/100 iters), loss = 0.000132633
I0527 03:17:36.598538 30701 solver.cpp:237]     Train net output #0: loss = 0.000130734 (* 1 = 0.000130734 loss)
I0527 03:17:36.598552 30701 sgd_solver.cpp:105] Iteration 143500, lr = 0.002825
I0527 03:18:04.696210 30701 solver.cpp:218] Iteration 143600 (3.55914 iter/s, 28.0967s/100 iters), loss = 0.000282664
I0527 03:18:04.696267 30701 solver.cpp:237]     Train net output #0: loss = 0.000280766 (* 1 = 0.000280766 loss)
I0527 03:18:04.696276 30701 sgd_solver.cpp:105] Iteration 143600, lr = 0.00282
I0527 03:18:17.356237 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:18:32.791744 30701 solver.cpp:218] Iteration 143700 (3.55941 iter/s, 28.0945s/100 iters), loss = 0.00022071
I0527 03:18:32.791790 30701 solver.cpp:237]     Train net output #0: loss = 0.000218811 (* 1 = 0.000218811 loss)
I0527 03:18:32.791800 30701 sgd_solver.cpp:105] Iteration 143700, lr = 0.002815
I0527 03:19:00.855317 30701 solver.cpp:218] Iteration 143800 (3.56346 iter/s, 28.0626s/100 iters), loss = 0.00030848
I0527 03:19:00.855533 30701 solver.cpp:237]     Train net output #0: loss = 0.000306581 (* 1 = 0.000306581 loss)
I0527 03:19:00.855545 30701 sgd_solver.cpp:105] Iteration 143800, lr = 0.00281
I0527 03:19:28.930408 30701 solver.cpp:218] Iteration 143900 (3.56202 iter/s, 28.074s/100 iters), loss = 9.79565e-05
I0527 03:19:28.930451 30701 solver.cpp:237]     Train net output #0: loss = 9.60575e-05 (* 1 = 9.60575e-05 loss)
I0527 03:19:28.930460 30701 sgd_solver.cpp:105] Iteration 143900, lr = 0.002805
I0527 03:19:56.711859 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_144000.caffemodel
I0527 03:19:57.025197 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_144000.solverstate
I0527 03:19:57.174577 30701 solver.cpp:330] Iteration 144000, Testing net (#0)
I0527 03:20:00.133038 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 03:20:00.133077 30701 solver.cpp:397]     Test net output #1: loss = 0.882079 (* 1 = 0.882079 loss)
I0527 03:20:00.409083 30701 solver.cpp:218] Iteration 144000 (3.17686 iter/s, 31.4776s/100 iters), loss = 0.00093232
I0527 03:20:00.409128 30701 solver.cpp:237]     Train net output #0: loss = 0.000930422 (* 1 = 0.000930422 loss)
I0527 03:20:00.409137 30701 sgd_solver.cpp:105] Iteration 144000, lr = 0.0028
I0527 03:20:28.483098 30701 solver.cpp:218] Iteration 144100 (3.56213 iter/s, 28.0731s/100 iters), loss = 0.000843409
I0527 03:20:28.483321 30701 solver.cpp:237]     Train net output #0: loss = 0.00084151 (* 1 = 0.00084151 loss)
I0527 03:20:28.483332 30701 sgd_solver.cpp:105] Iteration 144100, lr = 0.002795
I0527 03:20:56.569033 30701 solver.cpp:218] Iteration 144200 (3.56064 iter/s, 28.0848s/100 iters), loss = 0.000815406
I0527 03:20:56.569077 30701 solver.cpp:237]     Train net output #0: loss = 0.000813508 (* 1 = 0.000813508 loss)
I0527 03:20:56.569087 30701 sgd_solver.cpp:105] Iteration 144200, lr = 0.00279
I0527 03:21:06.697031 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:21:24.638991 30701 solver.cpp:218] Iteration 144300 (3.56264 iter/s, 28.069s/100 iters), loss = 0.000186061
I0527 03:21:24.639039 30701 solver.cpp:237]     Train net output #0: loss = 0.000184163 (* 1 = 0.000184163 loss)
I0527 03:21:24.639047 30701 sgd_solver.cpp:105] Iteration 144300, lr = 0.002785
I0527 03:21:52.717700 30701 solver.cpp:218] Iteration 144400 (3.56153 iter/s, 28.0778s/100 iters), loss = 0.000190139
I0527 03:21:52.717854 30701 solver.cpp:237]     Train net output #0: loss = 0.000188241 (* 1 = 0.000188241 loss)
I0527 03:21:52.717869 30701 sgd_solver.cpp:105] Iteration 144400, lr = 0.00278
I0527 03:22:20.820801 30701 solver.cpp:218] Iteration 144500 (3.55845 iter/s, 28.1021s/100 iters), loss = 0.00060234
I0527 03:22:20.820844 30701 solver.cpp:237]     Train net output #0: loss = 0.000600442 (* 1 = 0.000600442 loss)
I0527 03:22:20.820852 30701 sgd_solver.cpp:105] Iteration 144500, lr = 0.002775
I0527 03:22:48.954139 30701 solver.cpp:218] Iteration 144600 (3.55461 iter/s, 28.1325s/100 iters), loss = 0.000127923
I0527 03:22:48.954304 30701 solver.cpp:237]     Train net output #0: loss = 0.000126025 (* 1 = 0.000126025 loss)
I0527 03:22:48.954315 30701 sgd_solver.cpp:105] Iteration 144600, lr = 0.00277
I0527 03:23:17.081406 30701 solver.cpp:218] Iteration 144700 (3.5554 iter/s, 28.1263s/100 iters), loss = 6.77926e-05
I0527 03:23:17.081463 30701 solver.cpp:237]     Train net output #0: loss = 6.58946e-05 (* 1 = 6.58946e-05 loss)
I0527 03:23:17.081472 30701 sgd_solver.cpp:105] Iteration 144700, lr = 0.002765
I0527 03:23:45.202895 30701 solver.cpp:218] Iteration 144800 (3.55611 iter/s, 28.1206s/100 iters), loss = 0.000187336
I0527 03:23:45.203061 30701 solver.cpp:237]     Train net output #0: loss = 0.000185438 (* 1 = 0.000185438 loss)
I0527 03:23:45.203073 30701 sgd_solver.cpp:105] Iteration 144800, lr = 0.00276
I0527 03:23:52.816560 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:24:13.333329 30701 solver.cpp:218] Iteration 144900 (3.55499 iter/s, 28.1294s/100 iters), loss = 0.000190978
I0527 03:24:13.333386 30701 solver.cpp:237]     Train net output #0: loss = 0.00018908 (* 1 = 0.00018908 loss)
I0527 03:24:13.333395 30701 sgd_solver.cpp:105] Iteration 144900, lr = 0.002755
I0527 03:24:41.171972 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_145000.caffemodel
I0527 03:24:41.484397 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_145000.solverstate
I0527 03:24:41.634093 30701 solver.cpp:330] Iteration 145000, Testing net (#0)
I0527 03:24:44.596590 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 03:24:44.596632 30701 solver.cpp:397]     Test net output #1: loss = 0.806671 (* 1 = 0.806671 loss)
I0527 03:24:44.873239 30701 solver.cpp:218] Iteration 145000 (3.17068 iter/s, 31.5389s/100 iters), loss = 0.000197377
I0527 03:24:44.873283 30701 solver.cpp:237]     Train net output #0: loss = 0.000195479 (* 1 = 0.000195479 loss)
I0527 03:24:44.873292 30701 sgd_solver.cpp:105] Iteration 145000, lr = 0.00275
I0527 03:25:12.993665 30701 solver.cpp:218] Iteration 145100 (3.55624 iter/s, 28.1196s/100 iters), loss = 0.000236776
I0527 03:25:12.993813 30701 solver.cpp:237]     Train net output #0: loss = 0.000234878 (* 1 = 0.000234878 loss)
I0527 03:25:12.993824 30701 sgd_solver.cpp:105] Iteration 145100, lr = 0.002745
I0527 03:25:41.124331 30701 solver.cpp:218] Iteration 145200 (3.55496 iter/s, 28.1297s/100 iters), loss = 0.000138002
I0527 03:25:41.124382 30701 solver.cpp:237]     Train net output #0: loss = 0.000136104 (* 1 = 0.000136104 loss)
I0527 03:25:41.124390 30701 sgd_solver.cpp:105] Iteration 145200, lr = 0.00274
I0527 03:26:09.247622 30701 solver.cpp:218] Iteration 145300 (3.55588 iter/s, 28.1224s/100 iters), loss = 0.000763648
I0527 03:26:09.247795 30701 solver.cpp:237]     Train net output #0: loss = 0.000761751 (* 1 = 0.000761751 loss)
I0527 03:26:09.247807 30701 sgd_solver.cpp:105] Iteration 145300, lr = 0.002735
I0527 03:26:37.357973 30701 solver.cpp:218] Iteration 145400 (3.55753 iter/s, 28.1094s/100 iters), loss = 5.1475e-05
I0527 03:26:37.358017 30701 solver.cpp:237]     Train net output #0: loss = 4.95774e-05 (* 1 = 4.95774e-05 loss)
I0527 03:26:37.358026 30701 sgd_solver.cpp:105] Iteration 145400, lr = 0.00273
I0527 03:26:42.439719 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:27:05.489387 30701 solver.cpp:218] Iteration 145500 (3.55485 iter/s, 28.1306s/100 iters), loss = 0.000247282
I0527 03:27:05.489434 30701 solver.cpp:237]     Train net output #0: loss = 0.000245384 (* 1 = 0.000245384 loss)
I0527 03:27:05.489442 30701 sgd_solver.cpp:105] Iteration 145500, lr = 0.002725
I0527 03:27:33.591809 30701 solver.cpp:218] Iteration 145600 (3.55852 iter/s, 28.1016s/100 iters), loss = 0.000141048
I0527 03:27:33.591981 30701 solver.cpp:237]     Train net output #0: loss = 0.00013915 (* 1 = 0.00013915 loss)
I0527 03:27:33.591994 30701 sgd_solver.cpp:105] Iteration 145600, lr = 0.00272
I0527 03:28:01.691754 30701 solver.cpp:218] Iteration 145700 (3.55885 iter/s, 28.099s/100 iters), loss = 0.000162681
I0527 03:28:01.691804 30701 solver.cpp:237]     Train net output #0: loss = 0.000160783 (* 1 = 0.000160783 loss)
I0527 03:28:01.691813 30701 sgd_solver.cpp:105] Iteration 145700, lr = 0.002715
I0527 03:28:29.788403 30701 solver.cpp:218] Iteration 145800 (3.55925 iter/s, 28.0958s/100 iters), loss = 0.000248237
I0527 03:28:29.788619 30701 solver.cpp:237]     Train net output #0: loss = 0.000246339 (* 1 = 0.000246339 loss)
I0527 03:28:29.788630 30701 sgd_solver.cpp:105] Iteration 145800, lr = 0.00271
I0527 03:28:57.906426 30701 solver.cpp:218] Iteration 145900 (3.55656 iter/s, 28.1171s/100 iters), loss = 0.000334156
I0527 03:28:57.906472 30701 solver.cpp:237]     Train net output #0: loss = 0.000332259 (* 1 = 0.000332259 loss)
I0527 03:28:57.906481 30701 sgd_solver.cpp:105] Iteration 145900, lr = 0.002705
I0527 03:29:25.735548 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_146000.caffemodel
I0527 03:29:26.047624 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_146000.solverstate
I0527 03:29:26.197057 30701 solver.cpp:330] Iteration 146000, Testing net (#0)
I0527 03:29:27.206395 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:29:29.153991 30701 solver.cpp:397]     Test net output #0: accuracy = 0.844
I0527 03:29:29.154038 30701 solver.cpp:397]     Test net output #1: loss = 0.775425 (* 1 = 0.775425 loss)
I0527 03:29:29.430686 30701 solver.cpp:218] Iteration 146000 (3.17225 iter/s, 31.5234s/100 iters), loss = 0.000127976
I0527 03:29:29.430732 30701 solver.cpp:237]     Train net output #0: loss = 0.000126079 (* 1 = 0.000126079 loss)
I0527 03:29:29.430740 30701 sgd_solver.cpp:105] Iteration 146000, lr = 0.0027
I0527 03:29:32.261194 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:29:57.571915 30701 solver.cpp:218] Iteration 146100 (3.55361 iter/s, 28.1404s/100 iters), loss = 0.000365653
I0527 03:29:57.572154 30701 solver.cpp:237]     Train net output #0: loss = 0.000363755 (* 1 = 0.000363755 loss)
I0527 03:29:57.572165 30701 sgd_solver.cpp:105] Iteration 146100, lr = 0.002695
I0527 03:30:25.704710 30701 solver.cpp:218] Iteration 146200 (3.5547 iter/s, 28.1318s/100 iters), loss = 9.8854e-05
I0527 03:30:25.704759 30701 solver.cpp:237]     Train net output #0: loss = 9.69567e-05 (* 1 = 9.69567e-05 loss)
I0527 03:30:25.704768 30701 sgd_solver.cpp:105] Iteration 146200, lr = 0.00269
I0527 03:30:53.839195 30701 solver.cpp:218] Iteration 146300 (3.55446 iter/s, 28.1337s/100 iters), loss = 0.000443505
I0527 03:30:53.839372 30701 solver.cpp:237]     Train net output #0: loss = 0.000441608 (* 1 = 0.000441608 loss)
I0527 03:30:53.839385 30701 sgd_solver.cpp:105] Iteration 146300, lr = 0.002685
I0527 03:31:21.984074 30701 solver.cpp:218] Iteration 146400 (3.55316 iter/s, 28.144s/100 iters), loss = 9.34204e-05
I0527 03:31:21.984129 30701 solver.cpp:237]     Train net output #0: loss = 9.15241e-05 (* 1 = 9.15241e-05 loss)
I0527 03:31:21.984138 30701 sgd_solver.cpp:105] Iteration 146400, lr = 0.00268
I0527 03:31:50.133718 30701 solver.cpp:218] Iteration 146500 (3.55254 iter/s, 28.1488s/100 iters), loss = 0.000238528
I0527 03:31:50.133929 30701 solver.cpp:237]     Train net output #0: loss = 0.000236631 (* 1 = 0.000236631 loss)
I0527 03:31:50.133941 30701 sgd_solver.cpp:105] Iteration 146500, lr = 0.002675
I0527 03:32:18.251687 30701 solver.cpp:218] Iteration 146600 (3.55656 iter/s, 28.1171s/100 iters), loss = 0.000652378
I0527 03:32:18.251739 30701 solver.cpp:237]     Train net output #0: loss = 0.000650482 (* 1 = 0.000650482 loss)
I0527 03:32:18.251750 30701 sgd_solver.cpp:105] Iteration 146600, lr = 0.00267
I0527 03:32:18.549340 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:32:46.345654 30701 solver.cpp:218] Iteration 146700 (3.55958 iter/s, 28.0932s/100 iters), loss = 0.000145193
I0527 03:32:46.345844 30701 solver.cpp:237]     Train net output #0: loss = 0.000143297 (* 1 = 0.000143297 loss)
I0527 03:32:46.345870 30701 sgd_solver.cpp:105] Iteration 146700, lr = 0.002665
I0527 03:33:14.448002 30701 solver.cpp:218] Iteration 146800 (3.55854 iter/s, 28.1014s/100 iters), loss = 0.00120597
I0527 03:33:14.448053 30701 solver.cpp:237]     Train net output #0: loss = 0.00120408 (* 1 = 0.00120408 loss)
I0527 03:33:14.448066 30701 sgd_solver.cpp:105] Iteration 146800, lr = 0.00266
I0527 03:33:42.522372 30701 solver.cpp:218] Iteration 146900 (3.56207 iter/s, 28.0736s/100 iters), loss = 0.000327253
I0527 03:33:42.522574 30701 solver.cpp:237]     Train net output #0: loss = 0.000325357 (* 1 = 0.000325357 loss)
I0527 03:33:42.522586 30701 sgd_solver.cpp:105] Iteration 146900, lr = 0.002655
I0527 03:34:10.300137 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_147000.caffemodel
I0527 03:34:10.612721 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_147000.solverstate
I0527 03:34:10.762356 30701 solver.cpp:330] Iteration 147000, Testing net (#0)
I0527 03:34:13.716914 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0527 03:34:13.717064 30701 solver.cpp:397]     Test net output #1: loss = 0.901935 (* 1 = 0.901935 loss)
I0527 03:34:13.994670 30701 solver.cpp:218] Iteration 147000 (3.1775 iter/s, 31.4713s/100 iters), loss = 0.000139798
I0527 03:34:13.994721 30701 solver.cpp:237]     Train net output #0: loss = 0.000137902 (* 1 = 0.000137902 loss)
I0527 03:34:13.994730 30701 sgd_solver.cpp:105] Iteration 147000, lr = 0.00265
I0527 03:34:42.066246 30701 solver.cpp:218] Iteration 147100 (3.56242 iter/s, 28.0708s/100 iters), loss = 0.000260755
I0527 03:34:42.066293 30701 solver.cpp:237]     Train net output #0: loss = 0.000258859 (* 1 = 0.000258859 loss)
I0527 03:34:42.066314 30701 sgd_solver.cpp:105] Iteration 147100, lr = 0.002645
I0527 03:35:07.909991 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:35:10.141645 30701 solver.cpp:218] Iteration 147200 (3.56193 iter/s, 28.0746s/100 iters), loss = 0.000770798
I0527 03:35:10.141686 30701 solver.cpp:237]     Train net output #0: loss = 0.000768902 (* 1 = 0.000768902 loss)
I0527 03:35:10.141695 30701 sgd_solver.cpp:105] Iteration 147200, lr = 0.00264
I0527 03:35:38.219107 30701 solver.cpp:218] Iteration 147300 (3.56167 iter/s, 28.0767s/100 iters), loss = 0.000221083
I0527 03:35:38.219233 30701 solver.cpp:237]     Train net output #0: loss = 0.000219187 (* 1 = 0.000219187 loss)
I0527 03:35:38.219254 30701 sgd_solver.cpp:105] Iteration 147300, lr = 0.002635
I0527 03:36:06.293392 30701 solver.cpp:218] Iteration 147400 (3.56209 iter/s, 28.0734s/100 iters), loss = 0.000190531
I0527 03:36:06.293437 30701 solver.cpp:237]     Train net output #0: loss = 0.000188635 (* 1 = 0.000188635 loss)
I0527 03:36:06.293444 30701 sgd_solver.cpp:105] Iteration 147400, lr = 0.00263
I0527 03:36:34.371640 30701 solver.cpp:218] Iteration 147500 (3.56157 iter/s, 28.0775s/100 iters), loss = 0.000261845
I0527 03:36:34.371811 30701 solver.cpp:237]     Train net output #0: loss = 0.00025995 (* 1 = 0.00025995 loss)
I0527 03:36:34.371829 30701 sgd_solver.cpp:105] Iteration 147500, lr = 0.002625
I0527 03:37:02.474845 30701 solver.cpp:218] Iteration 147600 (3.55842 iter/s, 28.1023s/100 iters), loss = 0.00120821
I0527 03:37:02.474891 30701 solver.cpp:237]     Train net output #0: loss = 0.00120631 (* 1 = 0.00120631 loss)
I0527 03:37:02.474900 30701 sgd_solver.cpp:105] Iteration 147600, lr = 0.00262
I0527 03:37:30.574741 30701 solver.cpp:218] Iteration 147700 (3.55883 iter/s, 28.0991s/100 iters), loss = 6.9231e-05
I0527 03:37:30.574975 30701 solver.cpp:237]     Train net output #0: loss = 6.73354e-05 (* 1 = 6.73354e-05 loss)
I0527 03:37:30.574987 30701 sgd_solver.cpp:105] Iteration 147700, lr = 0.002615
I0527 03:37:53.910853 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:37:58.668809 30701 solver.cpp:218] Iteration 147800 (3.55959 iter/s, 28.0931s/100 iters), loss = 0.000301805
I0527 03:37:58.668855 30701 solver.cpp:237]     Train net output #0: loss = 0.000299909 (* 1 = 0.000299909 loss)
I0527 03:37:58.668864 30701 sgd_solver.cpp:105] Iteration 147800, lr = 0.00261
I0527 03:38:26.740589 30701 solver.cpp:218] Iteration 147900 (3.56239 iter/s, 28.071s/100 iters), loss = 0.000171789
I0527 03:38:26.740797 30701 solver.cpp:237]     Train net output #0: loss = 0.000169893 (* 1 = 0.000169893 loss)
I0527 03:38:26.740813 30701 sgd_solver.cpp:105] Iteration 147900, lr = 0.002605
I0527 03:38:54.521880 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_148000.caffemodel
I0527 03:38:54.834802 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_148000.solverstate
I0527 03:38:54.985566 30701 solver.cpp:330] Iteration 148000, Testing net (#0)
I0527 03:38:57.683346 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:38:57.949471 30701 solver.cpp:397]     Test net output #0: accuracy = 0.838
I0527 03:38:57.949514 30701 solver.cpp:397]     Test net output #1: loss = 0.677223 (* 1 = 0.677223 loss)
I0527 03:38:58.227990 30701 solver.cpp:218] Iteration 148000 (3.17597 iter/s, 31.4864s/100 iters), loss = 0.00016216
I0527 03:38:58.228039 30701 solver.cpp:237]     Train net output #0: loss = 0.000160264 (* 1 = 0.000160264 loss)
I0527 03:38:58.228051 30701 sgd_solver.cpp:105] Iteration 148000, lr = 0.0026
I0527 03:39:26.346439 30701 solver.cpp:218] Iteration 148100 (3.55645 iter/s, 28.1179s/100 iters), loss = 0.000238612
I0527 03:39:26.346493 30701 solver.cpp:237]     Train net output #0: loss = 0.000236716 (* 1 = 0.000236716 loss)
I0527 03:39:26.346518 30701 sgd_solver.cpp:105] Iteration 148100, lr = 0.002595
I0527 03:39:54.458935 30701 solver.cpp:218] Iteration 148200 (3.5571 iter/s, 28.1128s/100 iters), loss = 0.000169165
I0527 03:39:54.459054 30701 solver.cpp:237]     Train net output #0: loss = 0.000167269 (* 1 = 0.000167269 loss)
I0527 03:39:54.459064 30701 sgd_solver.cpp:105] Iteration 148200, lr = 0.00259
I0527 03:40:22.562290 30701 solver.cpp:218] Iteration 148300 (3.55828 iter/s, 28.1035s/100 iters), loss = 0.00032259
I0527 03:40:22.562335 30701 solver.cpp:237]     Train net output #0: loss = 0.000320694 (* 1 = 0.000320694 loss)
I0527 03:40:22.562343 30701 sgd_solver.cpp:105] Iteration 148300, lr = 0.002585
I0527 03:40:43.367787 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:40:50.641738 30701 solver.cpp:218] Iteration 148400 (3.5613 iter/s, 28.0796s/100 iters), loss = 5.44384e-05
I0527 03:40:50.641785 30701 solver.cpp:237]     Train net output #0: loss = 5.25421e-05 (* 1 = 5.25421e-05 loss)
I0527 03:40:50.641794 30701 sgd_solver.cpp:105] Iteration 148400, lr = 0.00258
I0527 03:41:18.714944 30701 solver.cpp:218] Iteration 148500 (3.5621 iter/s, 28.0733s/100 iters), loss = 0.000216122
I0527 03:41:18.715108 30701 solver.cpp:237]     Train net output #0: loss = 0.000214226 (* 1 = 0.000214226 loss)
I0527 03:41:18.715119 30701 sgd_solver.cpp:105] Iteration 148500, lr = 0.002575
I0527 03:41:46.793836 30701 solver.cpp:218] Iteration 148600 (3.5614 iter/s, 28.0789s/100 iters), loss = 0.000762511
I0527 03:41:46.793884 30701 solver.cpp:237]     Train net output #0: loss = 0.000760615 (* 1 = 0.000760615 loss)
I0527 03:41:46.793892 30701 sgd_solver.cpp:105] Iteration 148600, lr = 0.00257
I0527 03:42:14.865528 30701 solver.cpp:218] Iteration 148700 (3.5623 iter/s, 28.0717s/100 iters), loss = 0.000323776
I0527 03:42:14.865741 30701 solver.cpp:237]     Train net output #0: loss = 0.00032188 (* 1 = 0.00032188 loss)
I0527 03:42:14.865752 30701 sgd_solver.cpp:105] Iteration 148700, lr = 0.002565
I0527 03:42:42.933779 30701 solver.cpp:218] Iteration 148800 (3.56276 iter/s, 28.0681s/100 iters), loss = 0.000214944
I0527 03:42:42.933822 30701 solver.cpp:237]     Train net output #0: loss = 0.000213048 (* 1 = 0.000213048 loss)
I0527 03:42:42.933831 30701 sgd_solver.cpp:105] Iteration 148800, lr = 0.00256
I0527 03:43:11.036340 30701 solver.cpp:218] Iteration 148900 (3.5584 iter/s, 28.1025s/100 iters), loss = 0.000191121
I0527 03:43:11.036507 30701 solver.cpp:237]     Train net output #0: loss = 0.000189225 (* 1 = 0.000189225 loss)
I0527 03:43:11.036521 30701 sgd_solver.cpp:105] Iteration 148900, lr = 0.002555
I0527 03:43:29.344502 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:43:38.898751 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_149000.caffemodel
I0527 03:43:39.353963 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_149000.solverstate
I0527 03:43:39.505018 30701 solver.cpp:330] Iteration 149000, Testing net (#0)
I0527 03:43:42.466131 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 03:43:42.466279 30701 solver.cpp:397]     Test net output #1: loss = 0.884533 (* 1 = 0.884533 loss)
I0527 03:43:42.743479 30701 solver.cpp:218] Iteration 149000 (3.15388 iter/s, 31.707s/100 iters), loss = 0.000213479
I0527 03:43:42.743523 30701 solver.cpp:237]     Train net output #0: loss = 0.000211583 (* 1 = 0.000211583 loss)
I0527 03:43:42.743531 30701 sgd_solver.cpp:105] Iteration 149000, lr = 0.00255
I0527 03:44:10.854320 30701 solver.cpp:218] Iteration 149100 (3.55736 iter/s, 28.1108s/100 iters), loss = 0.000474102
I0527 03:44:10.854363 30701 solver.cpp:237]     Train net output #0: loss = 0.000472205 (* 1 = 0.000472205 loss)
I0527 03:44:10.854372 30701 sgd_solver.cpp:105] Iteration 149100, lr = 0.002545
I0527 03:44:38.956392 30701 solver.cpp:218] Iteration 149200 (3.55847 iter/s, 28.102s/100 iters), loss = 8.88962e-05
I0527 03:44:38.956612 30701 solver.cpp:237]     Train net output #0: loss = 8.69996e-05 (* 1 = 8.69996e-05 loss)
I0527 03:44:38.956624 30701 sgd_solver.cpp:105] Iteration 149200, lr = 0.00254
I0527 03:45:07.082485 30701 solver.cpp:218] Iteration 149300 (3.55546 iter/s, 28.1258s/100 iters), loss = 0.000197316
I0527 03:45:07.082538 30701 solver.cpp:237]     Train net output #0: loss = 0.000195419 (* 1 = 0.000195419 loss)
I0527 03:45:07.082547 30701 sgd_solver.cpp:105] Iteration 149300, lr = 0.002535
I0527 03:45:35.225507 30701 solver.cpp:218] Iteration 149400 (3.5533 iter/s, 28.1429s/100 iters), loss = 9.8949e-05
I0527 03:45:35.225706 30701 solver.cpp:237]     Train net output #0: loss = 9.70527e-05 (* 1 = 9.70527e-05 loss)
I0527 03:45:35.225723 30701 sgd_solver.cpp:105] Iteration 149400, lr = 0.00253
I0527 03:46:03.367810 30701 solver.cpp:218] Iteration 149500 (3.55341 iter/s, 28.142s/100 iters), loss = 0.000597564
I0527 03:46:03.367867 30701 solver.cpp:237]     Train net output #0: loss = 0.000595668 (* 1 = 0.000595668 loss)
I0527 03:46:03.367877 30701 sgd_solver.cpp:105] Iteration 149500, lr = 0.002525
I0527 03:46:19.146255 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:46:31.492688 30701 solver.cpp:218] Iteration 149600 (3.5556 iter/s, 28.1247s/100 iters), loss = 0.000854354
I0527 03:46:31.492745 30701 solver.cpp:237]     Train net output #0: loss = 0.000852457 (* 1 = 0.000852457 loss)
I0527 03:46:31.492754 30701 sgd_solver.cpp:105] Iteration 149600, lr = 0.00252
I0527 03:46:59.624135 30701 solver.cpp:218] Iteration 149700 (3.55477 iter/s, 28.1312s/100 iters), loss = 0.000354687
I0527 03:46:59.624282 30701 solver.cpp:237]     Train net output #0: loss = 0.000352791 (* 1 = 0.000352791 loss)
I0527 03:46:59.624294 30701 sgd_solver.cpp:105] Iteration 149700, lr = 0.002515
I0527 03:47:27.750103 30701 solver.cpp:218] Iteration 149800 (3.55548 iter/s, 28.1256s/100 iters), loss = 0.000533981
I0527 03:47:27.750160 30701 solver.cpp:237]     Train net output #0: loss = 0.000532085 (* 1 = 0.000532085 loss)
I0527 03:47:27.750169 30701 sgd_solver.cpp:105] Iteration 149800, lr = 0.00251
I0527 03:47:55.878176 30701 solver.cpp:218] Iteration 149900 (3.5552 iter/s, 28.1278s/100 iters), loss = 0.000717446
I0527 03:47:55.878329 30701 solver.cpp:237]     Train net output #0: loss = 0.00071555 (* 1 = 0.00071555 loss)
I0527 03:47:55.878341 30701 sgd_solver.cpp:105] Iteration 149900, lr = 0.002505
I0527 03:48:23.727053 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_150000.caffemodel
I0527 03:48:24.245373 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_150000.solverstate
I0527 03:48:24.398879 30701 solver.cpp:330] Iteration 150000, Testing net (#0)
I0527 03:48:27.355024 30701 solver.cpp:397]     Test net output #0: accuracy = 0.788
I0527 03:48:27.355182 30701 solver.cpp:397]     Test net output #1: loss = 0.891747 (* 1 = 0.891747 loss)
I0527 03:48:27.632498 30701 solver.cpp:218] Iteration 150000 (3.14922 iter/s, 31.7539s/100 iters), loss = 0.000115583
I0527 03:48:27.632547 30701 solver.cpp:237]     Train net output #0: loss = 0.000113687 (* 1 = 0.000113687 loss)
I0527 03:48:27.632556 30701 sgd_solver.cpp:105] Iteration 150000, lr = 0.0025
I0527 03:48:55.683076 30701 solver.cpp:218] Iteration 150100 (3.56503 iter/s, 28.0503s/100 iters), loss = 0.000498612
I0527 03:48:55.683123 30701 solver.cpp:237]     Train net output #0: loss = 0.000496716 (* 1 = 0.000496716 loss)
I0527 03:48:55.683132 30701 sgd_solver.cpp:105] Iteration 150100, lr = 0.002495
I0527 03:49:09.168119 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:49:23.764164 30701 solver.cpp:218] Iteration 150200 (3.56116 iter/s, 28.0808s/100 iters), loss = 0.000194449
I0527 03:49:23.764212 30701 solver.cpp:237]     Train net output #0: loss = 0.000192553 (* 1 = 0.000192553 loss)
I0527 03:49:23.764225 30701 sgd_solver.cpp:105] Iteration 150200, lr = 0.00249
I0527 03:49:51.847702 30701 solver.cpp:218] Iteration 150300 (3.56085 iter/s, 28.0832s/100 iters), loss = 0.000418094
I0527 03:49:51.847869 30701 solver.cpp:237]     Train net output #0: loss = 0.000416199 (* 1 = 0.000416199 loss)
I0527 03:49:51.847880 30701 sgd_solver.cpp:105] Iteration 150300, lr = 0.002485
I0527 03:50:19.922917 30701 solver.cpp:218] Iteration 150400 (3.56192 iter/s, 28.0747s/100 iters), loss = 0.000179333
I0527 03:50:19.922960 30701 solver.cpp:237]     Train net output #0: loss = 0.000177438 (* 1 = 0.000177438 loss)
I0527 03:50:19.922968 30701 sgd_solver.cpp:105] Iteration 150400, lr = 0.00248
I0527 03:50:48.006433 30701 solver.cpp:218] Iteration 150500 (3.56085 iter/s, 28.0831s/100 iters), loss = 0.000543846
I0527 03:50:48.006670 30701 solver.cpp:237]     Train net output #0: loss = 0.00054195 (* 1 = 0.00054195 loss)
I0527 03:50:48.006682 30701 sgd_solver.cpp:105] Iteration 150500, lr = 0.002475
I0527 03:51:16.076009 30701 solver.cpp:218] Iteration 150600 (3.56265 iter/s, 28.069s/100 iters), loss = 0.00023279
I0527 03:51:16.076052 30701 solver.cpp:237]     Train net output #0: loss = 0.000230895 (* 1 = 0.000230895 loss)
I0527 03:51:16.076061 30701 sgd_solver.cpp:105] Iteration 150600, lr = 0.00247
I0527 03:51:44.162824 30701 solver.cpp:218] Iteration 150700 (3.56044 iter/s, 28.0864s/100 iters), loss = 5.49037e-05
I0527 03:51:44.162992 30701 solver.cpp:237]     Train net output #0: loss = 5.3008e-05 (* 1 = 5.3008e-05 loss)
I0527 03:51:44.163008 30701 sgd_solver.cpp:105] Iteration 150700, lr = 0.002465
I0527 03:51:55.136809 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:52:12.263967 30701 solver.cpp:218] Iteration 150800 (3.55864 iter/s, 28.1006s/100 iters), loss = 0.000455921
I0527 03:52:12.264010 30701 solver.cpp:237]     Train net output #0: loss = 0.000454025 (* 1 = 0.000454025 loss)
I0527 03:52:12.264019 30701 sgd_solver.cpp:105] Iteration 150800, lr = 0.00246
I0527 03:52:40.373358 30701 solver.cpp:218] Iteration 150900 (3.55758 iter/s, 28.109s/100 iters), loss = 0.000220304
I0527 03:52:40.373515 30701 solver.cpp:237]     Train net output #0: loss = 0.000218409 (* 1 = 0.000218409 loss)
I0527 03:52:40.373527 30701 sgd_solver.cpp:105] Iteration 150900, lr = 0.002455
I0527 03:53:08.208166 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_151000.caffemodel
I0527 03:53:08.722515 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_151000.solverstate
I0527 03:53:08.876534 30701 solver.cpp:330] Iteration 151000, Testing net (#0)
I0527 03:53:10.298466 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:53:11.834018 30701 solver.cpp:397]     Test net output #0: accuracy = 0.852
I0527 03:53:11.834188 30701 solver.cpp:397]     Test net output #1: loss = 0.705641 (* 1 = 0.705641 loss)
I0527 03:53:12.113071 30701 solver.cpp:218] Iteration 151000 (3.15069 iter/s, 31.7391s/100 iters), loss = 0.000330517
I0527 03:53:12.113116 30701 solver.cpp:237]     Train net output #0: loss = 0.000328622 (* 1 = 0.000328622 loss)
I0527 03:53:12.113124 30701 sgd_solver.cpp:105] Iteration 151000, lr = 0.00245
I0527 03:53:40.223456 30701 solver.cpp:218] Iteration 151100 (3.55746 iter/s, 28.1099s/100 iters), loss = 0.000384888
I0527 03:53:40.223520 30701 solver.cpp:237]     Train net output #0: loss = 0.000382993 (* 1 = 0.000382993 loss)
I0527 03:53:40.223529 30701 sgd_solver.cpp:105] Iteration 151100, lr = 0.002445
I0527 03:54:08.334182 30701 solver.cpp:218] Iteration 151200 (3.55742 iter/s, 28.1103s/100 iters), loss = 0.000363302
I0527 03:54:08.334404 30701 solver.cpp:237]     Train net output #0: loss = 0.000361407 (* 1 = 0.000361407 loss)
I0527 03:54:08.334416 30701 sgd_solver.cpp:105] Iteration 151200, lr = 0.00244
I0527 03:54:36.442658 30701 solver.cpp:218] Iteration 151300 (3.55773 iter/s, 28.1078s/100 iters), loss = 0.000335232
I0527 03:54:36.442714 30701 solver.cpp:237]     Train net output #0: loss = 0.000333337 (* 1 = 0.000333337 loss)
I0527 03:54:36.442723 30701 sgd_solver.cpp:105] Iteration 151300, lr = 0.002435
I0527 03:54:44.906412 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:55:04.592877 30701 solver.cpp:218] Iteration 151400 (3.55243 iter/s, 28.1497s/100 iters), loss = 0.0001773
I0527 03:55:04.592937 30701 solver.cpp:237]     Train net output #0: loss = 0.000175406 (* 1 = 0.000175406 loss)
I0527 03:55:04.592947 30701 sgd_solver.cpp:105] Iteration 151400, lr = 0.00243
I0527 03:55:32.694612 30701 solver.cpp:218] Iteration 151500 (3.55856 iter/s, 28.1012s/100 iters), loss = 0.000362708
I0527 03:55:32.694814 30701 solver.cpp:237]     Train net output #0: loss = 0.000360813 (* 1 = 0.000360813 loss)
I0527 03:55:32.694849 30701 sgd_solver.cpp:105] Iteration 151500, lr = 0.002425
I0527 03:56:00.816443 30701 solver.cpp:218] Iteration 151600 (3.55603 iter/s, 28.1212s/100 iters), loss = 0.000450686
I0527 03:56:00.816491 30701 solver.cpp:237]     Train net output #0: loss = 0.000448791 (* 1 = 0.000448791 loss)
I0527 03:56:00.816500 30701 sgd_solver.cpp:105] Iteration 151600, lr = 0.00242
I0527 03:56:28.932827 30701 solver.cpp:218] Iteration 151700 (3.55671 iter/s, 28.1159s/100 iters), loss = 0.000363134
I0527 03:56:28.933009 30701 solver.cpp:237]     Train net output #0: loss = 0.00036124 (* 1 = 0.00036124 loss)
I0527 03:56:28.933020 30701 sgd_solver.cpp:105] Iteration 151700, lr = 0.002415
I0527 03:56:57.074561 30701 solver.cpp:218] Iteration 151800 (3.55352 iter/s, 28.1411s/100 iters), loss = 0.000510739
I0527 03:56:57.074605 30701 solver.cpp:237]     Train net output #0: loss = 0.000508845 (* 1 = 0.000508845 loss)
I0527 03:56:57.074615 30701 sgd_solver.cpp:105] Iteration 151800, lr = 0.00241
I0527 03:57:25.212931 30701 solver.cpp:218] Iteration 151900 (3.55393 iter/s, 28.1379s/100 iters), loss = 0.000433096
I0527 03:57:25.213155 30701 solver.cpp:237]     Train net output #0: loss = 0.000431202 (* 1 = 0.000431202 loss)
I0527 03:57:25.213166 30701 sgd_solver.cpp:105] Iteration 151900, lr = 0.002405
I0527 03:57:31.141230 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 03:57:53.065634 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_152000.caffemodel
I0527 03:57:53.378806 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_152000.solverstate
I0527 03:57:53.528728 30701 solver.cpp:330] Iteration 152000, Testing net (#0)
I0527 03:57:56.488570 30701 solver.cpp:397]     Test net output #0: accuracy = 0.82
I0527 03:57:56.488694 30701 solver.cpp:397]     Test net output #1: loss = 0.864294 (* 1 = 0.864294 loss)
I0527 03:57:56.765725 30701 solver.cpp:218] Iteration 152000 (3.16937 iter/s, 31.5521s/100 iters), loss = 0.000572688
I0527 03:57:56.765770 30701 solver.cpp:237]     Train net output #0: loss = 0.000570794 (* 1 = 0.000570794 loss)
I0527 03:57:56.765780 30701 sgd_solver.cpp:105] Iteration 152000, lr = 0.0024
I0527 03:58:24.894727 30701 solver.cpp:218] Iteration 152100 (3.55512 iter/s, 28.1285s/100 iters), loss = 0.000322982
I0527 03:58:24.894790 30701 solver.cpp:237]     Train net output #0: loss = 0.000321088 (* 1 = 0.000321088 loss)
I0527 03:58:24.894800 30701 sgd_solver.cpp:105] Iteration 152100, lr = 0.002395
I0527 03:58:53.026259 30701 solver.cpp:218] Iteration 152200 (3.5548 iter/s, 28.131s/100 iters), loss = 0.000162229
I0527 03:58:53.026473 30701 solver.cpp:237]     Train net output #0: loss = 0.000160335 (* 1 = 0.000160335 loss)
I0527 03:58:53.026485 30701 sgd_solver.cpp:105] Iteration 152200, lr = 0.00239
I0527 03:59:21.160157 30701 solver.cpp:218] Iteration 152300 (3.55452 iter/s, 28.1332s/100 iters), loss = 0.000130794
I0527 03:59:21.160200 30701 solver.cpp:237]     Train net output #0: loss = 0.0001289 (* 1 = 0.0001289 loss)
I0527 03:59:21.160208 30701 sgd_solver.cpp:105] Iteration 152300, lr = 0.002385
I0527 03:59:49.286134 30701 solver.cpp:218] Iteration 152400 (3.5555 iter/s, 28.1254s/100 iters), loss = 0.000215103
I0527 03:59:49.286298 30701 solver.cpp:237]     Train net output #0: loss = 0.000213209 (* 1 = 0.000213209 loss)
I0527 03:59:49.286315 30701 sgd_solver.cpp:105] Iteration 152400, lr = 0.00238
I0527 04:00:17.391974 30701 solver.cpp:218] Iteration 152500 (3.55806 iter/s, 28.1052s/100 iters), loss = 0.000272165
I0527 04:00:17.392035 30701 solver.cpp:237]     Train net output #0: loss = 0.000270271 (* 1 = 0.000270271 loss)
I0527 04:00:17.392048 30701 sgd_solver.cpp:105] Iteration 152500, lr = 0.002375
I0527 04:00:20.781986 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:00:45.490260 30701 solver.cpp:218] Iteration 152600 (3.55901 iter/s, 28.0977s/100 iters), loss = 0.000213195
I0527 04:00:45.490306 30701 solver.cpp:237]     Train net output #0: loss = 0.000211301 (* 1 = 0.000211301 loss)
I0527 04:00:45.490315 30701 sgd_solver.cpp:105] Iteration 152600, lr = 0.00237
I0527 04:01:13.600884 30701 solver.cpp:218] Iteration 152700 (3.55744 iter/s, 28.1101s/100 iters), loss = 9.86579e-05
I0527 04:01:13.601083 30701 solver.cpp:237]     Train net output #0: loss = 9.6764e-05 (* 1 = 9.6764e-05 loss)
I0527 04:01:13.601110 30701 sgd_solver.cpp:105] Iteration 152700, lr = 0.002365
I0527 04:01:41.733042 30701 solver.cpp:218] Iteration 152800 (3.55474 iter/s, 28.1315s/100 iters), loss = 0.00103728
I0527 04:01:41.733090 30701 solver.cpp:237]     Train net output #0: loss = 0.00103538 (* 1 = 0.00103538 loss)
I0527 04:01:41.733099 30701 sgd_solver.cpp:105] Iteration 152800, lr = 0.00236
I0527 04:02:09.854617 30701 solver.cpp:218] Iteration 152900 (3.55606 iter/s, 28.121s/100 iters), loss = 0.000765462
I0527 04:02:09.854841 30701 solver.cpp:237]     Train net output #0: loss = 0.000763568 (* 1 = 0.000763568 loss)
I0527 04:02:09.854853 30701 sgd_solver.cpp:105] Iteration 152900, lr = 0.002355
I0527 04:02:37.686266 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_153000.caffemodel
I0527 04:02:37.997822 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_153000.solverstate
I0527 04:02:38.148370 30701 solver.cpp:330] Iteration 153000, Testing net (#0)
I0527 04:02:41.105613 30701 solver.cpp:397]     Test net output #0: accuracy = 0.824
I0527 04:02:41.105831 30701 solver.cpp:397]     Test net output #1: loss = 0.76495 (* 1 = 0.76495 loss)
I0527 04:02:41.384083 30701 solver.cpp:218] Iteration 153000 (3.17172 iter/s, 31.5287s/100 iters), loss = 0.000664957
I0527 04:02:41.384138 30701 solver.cpp:237]     Train net output #0: loss = 0.000663063 (* 1 = 0.000663063 loss)
I0527 04:02:41.384146 30701 sgd_solver.cpp:105] Iteration 153000, lr = 0.00235
I0527 04:03:09.503106 30701 solver.cpp:218] Iteration 153100 (3.55638 iter/s, 28.1184s/100 iters), loss = 0.000251004
I0527 04:03:09.503151 30701 solver.cpp:237]     Train net output #0: loss = 0.00024911 (* 1 = 0.00024911 loss)
I0527 04:03:09.503160 30701 sgd_solver.cpp:105] Iteration 153100, lr = 0.002345
I0527 04:03:10.368850 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:03:37.636775 30701 solver.cpp:218] Iteration 153200 (3.55453 iter/s, 28.1331s/100 iters), loss = 0.000244992
I0527 04:03:37.636940 30701 solver.cpp:237]     Train net output #0: loss = 0.000243098 (* 1 = 0.000243098 loss)
I0527 04:03:37.636952 30701 sgd_solver.cpp:105] Iteration 153200, lr = 0.00234
I0527 04:04:05.719784 30701 solver.cpp:218] Iteration 153300 (3.56096 iter/s, 28.0823s/100 iters), loss = 0.000314176
I0527 04:04:05.719830 30701 solver.cpp:237]     Train net output #0: loss = 0.000312283 (* 1 = 0.000312283 loss)
I0527 04:04:05.719840 30701 sgd_solver.cpp:105] Iteration 153300, lr = 0.002335
I0527 04:04:33.811045 30701 solver.cpp:218] Iteration 153400 (3.5599 iter/s, 28.0907s/100 iters), loss = 0.000125091
I0527 04:04:33.811255 30701 solver.cpp:237]     Train net output #0: loss = 0.000123197 (* 1 = 0.000123197 loss)
I0527 04:04:33.811269 30701 sgd_solver.cpp:105] Iteration 153400, lr = 0.00233
I0527 04:05:01.879350 30701 solver.cpp:218] Iteration 153500 (3.56283 iter/s, 28.0676s/100 iters), loss = 6.30223e-05
I0527 04:05:01.879395 30701 solver.cpp:237]     Train net output #0: loss = 6.1129e-05 (* 1 = 6.1129e-05 loss)
I0527 04:05:01.879405 30701 sgd_solver.cpp:105] Iteration 153500, lr = 0.002325
I0527 04:05:29.977982 30701 solver.cpp:218] Iteration 153600 (3.55896 iter/s, 28.0981s/100 iters), loss = 8.5868e-05
I0527 04:05:29.978137 30701 solver.cpp:237]     Train net output #0: loss = 8.39743e-05 (* 1 = 8.39743e-05 loss)
I0527 04:05:29.978149 30701 sgd_solver.cpp:105] Iteration 153600, lr = 0.00232
I0527 04:05:56.400254 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:05:58.070844 30701 solver.cpp:218] Iteration 153700 (3.55971 iter/s, 28.0922s/100 iters), loss = 0.000126023
I0527 04:05:58.070889 30701 solver.cpp:237]     Train net output #0: loss = 0.000124129 (* 1 = 0.000124129 loss)
I0527 04:05:58.070899 30701 sgd_solver.cpp:105] Iteration 153700, lr = 0.002315
I0527 04:06:26.171074 30701 solver.cpp:218] Iteration 153800 (3.55876 iter/s, 28.0997s/100 iters), loss = 0.000353698
I0527 04:06:26.171274 30701 solver.cpp:237]     Train net output #0: loss = 0.000351804 (* 1 = 0.000351804 loss)
I0527 04:06:26.171288 30701 sgd_solver.cpp:105] Iteration 153800, lr = 0.00231
I0527 04:06:54.223381 30701 solver.cpp:218] Iteration 153900 (3.56486 iter/s, 28.0516s/100 iters), loss = 0.000621823
I0527 04:06:54.223428 30701 solver.cpp:237]     Train net output #0: loss = 0.000619929 (* 1 = 0.000619929 loss)
I0527 04:06:54.223438 30701 sgd_solver.cpp:105] Iteration 153900, lr = 0.002305
I0527 04:07:22.001483 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_154000.caffemodel
I0527 04:07:22.313478 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_154000.solverstate
I0527 04:07:22.464004 30701 solver.cpp:330] Iteration 154000, Testing net (#0)
I0527 04:07:22.587927 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:07:25.418081 30701 solver.cpp:397]     Test net output #0: accuracy = 0.832
I0527 04:07:25.418118 30701 solver.cpp:397]     Test net output #1: loss = 0.853436 (* 1 = 0.853436 loss)
I0527 04:07:25.694628 30701 solver.cpp:218] Iteration 154000 (3.17757 iter/s, 31.4706s/100 iters), loss = 8.64594e-05
I0527 04:07:25.694687 30701 solver.cpp:237]     Train net output #0: loss = 8.45651e-05 (* 1 = 8.45651e-05 loss)
I0527 04:07:25.694697 30701 sgd_solver.cpp:105] Iteration 154000, lr = 0.0023
I0527 04:07:53.806785 30701 solver.cpp:218] Iteration 154100 (3.55726 iter/s, 28.1116s/100 iters), loss = 0.000321604
I0527 04:07:53.806946 30701 solver.cpp:237]     Train net output #0: loss = 0.000319709 (* 1 = 0.000319709 loss)
I0527 04:07:53.806958 30701 sgd_solver.cpp:105] Iteration 154100, lr = 0.002295
I0527 04:08:21.914296 30701 solver.cpp:218] Iteration 154200 (3.55785 iter/s, 28.1068s/100 iters), loss = 0.000417033
I0527 04:08:21.914340 30701 solver.cpp:237]     Train net output #0: loss = 0.000415139 (* 1 = 0.000415139 loss)
I0527 04:08:21.914350 30701 sgd_solver.cpp:105] Iteration 154200, lr = 0.00229
I0527 04:08:46.087260 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:08:50.006388 30701 solver.cpp:218] Iteration 154300 (3.5598 iter/s, 28.0915s/100 iters), loss = 0.000148442
I0527 04:08:50.006435 30701 solver.cpp:237]     Train net output #0: loss = 0.000146547 (* 1 = 0.000146547 loss)
I0527 04:08:50.006443 30701 sgd_solver.cpp:105] Iteration 154300, lr = 0.002285
I0527 04:09:18.113174 30701 solver.cpp:218] Iteration 154400 (3.55793 iter/s, 28.1062s/100 iters), loss = 8.46799e-05
I0527 04:09:18.113333 30701 solver.cpp:237]     Train net output #0: loss = 8.27851e-05 (* 1 = 8.27851e-05 loss)
I0527 04:09:18.113344 30701 sgd_solver.cpp:105] Iteration 154400, lr = 0.00228
I0527 04:09:46.204213 30701 solver.cpp:218] Iteration 154500 (3.55994 iter/s, 28.0903s/100 iters), loss = 0.000632752
I0527 04:09:46.204258 30701 solver.cpp:237]     Train net output #0: loss = 0.000630858 (* 1 = 0.000630858 loss)
I0527 04:09:46.204267 30701 sgd_solver.cpp:105] Iteration 154500, lr = 0.002275
I0527 04:10:14.314105 30701 solver.cpp:218] Iteration 154600 (3.55754 iter/s, 28.1093s/100 iters), loss = 0.000421225
I0527 04:10:14.314267 30701 solver.cpp:237]     Train net output #0: loss = 0.00041933 (* 1 = 0.00041933 loss)
I0527 04:10:14.314280 30701 sgd_solver.cpp:105] Iteration 154600, lr = 0.00227
I0527 04:10:42.431442 30701 solver.cpp:218] Iteration 154700 (3.55661 iter/s, 28.1166s/100 iters), loss = 0.000354294
I0527 04:10:42.431488 30701 solver.cpp:237]     Train net output #0: loss = 0.0003524 (* 1 = 0.0003524 loss)
I0527 04:10:42.431495 30701 sgd_solver.cpp:105] Iteration 154700, lr = 0.002265
I0527 04:11:10.523833 30701 solver.cpp:218] Iteration 154800 (3.55976 iter/s, 28.0918s/100 iters), loss = 0.00028803
I0527 04:11:10.524044 30701 solver.cpp:237]     Train net output #0: loss = 0.000286136 (* 1 = 0.000286136 loss)
I0527 04:11:10.524071 30701 sgd_solver.cpp:105] Iteration 154800, lr = 0.00226
I0527 04:11:32.166096 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:11:38.617594 30701 solver.cpp:218] Iteration 154900 (3.5596 iter/s, 28.093s/100 iters), loss = 0.000465834
I0527 04:11:38.617641 30701 solver.cpp:237]     Train net output #0: loss = 0.00046394 (* 1 = 0.00046394 loss)
I0527 04:11:38.617650 30701 sgd_solver.cpp:105] Iteration 154900, lr = 0.002255
I0527 04:12:06.464154 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_155000.caffemodel
I0527 04:12:06.778359 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_155000.solverstate
I0527 04:12:06.929265 30701 solver.cpp:330] Iteration 155000, Testing net (#0)
I0527 04:12:09.883225 30701 solver.cpp:397]     Test net output #0: accuracy = 0.81
I0527 04:12:09.883277 30701 solver.cpp:397]     Test net output #1: loss = 0.857872 (* 1 = 0.857872 loss)
I0527 04:12:10.160687 30701 solver.cpp:218] Iteration 155000 (3.17033 iter/s, 31.5424s/100 iters), loss = 0.000180242
I0527 04:12:10.160732 30701 solver.cpp:237]     Train net output #0: loss = 0.000178347 (* 1 = 0.000178347 loss)
I0527 04:12:10.160742 30701 sgd_solver.cpp:105] Iteration 155000, lr = 0.00225
I0527 04:12:38.266052 30701 solver.cpp:218] Iteration 155100 (3.55812 iter/s, 28.1048s/100 iters), loss = 0.000423431
I0527 04:12:38.266218 30701 solver.cpp:237]     Train net output #0: loss = 0.000421537 (* 1 = 0.000421537 loss)
I0527 04:12:38.266238 30701 sgd_solver.cpp:105] Iteration 155100, lr = 0.002245
I0527 04:13:06.380771 30701 solver.cpp:218] Iteration 155200 (3.55695 iter/s, 28.114s/100 iters), loss = 0.000108548
I0527 04:13:06.380820 30701 solver.cpp:237]     Train net output #0: loss = 0.000106654 (* 1 = 0.000106654 loss)
I0527 04:13:06.380828 30701 sgd_solver.cpp:105] Iteration 155200, lr = 0.00224
I0527 04:13:34.487334 30701 solver.cpp:218] Iteration 155300 (3.55797 iter/s, 28.1059s/100 iters), loss = 0.000143023
I0527 04:13:34.487543 30701 solver.cpp:237]     Train net output #0: loss = 0.000141129 (* 1 = 0.000141129 loss)
I0527 04:13:34.487555 30701 sgd_solver.cpp:105] Iteration 155300, lr = 0.002235
I0527 04:14:02.552448 30701 solver.cpp:218] Iteration 155400 (3.56329 iter/s, 28.0639s/100 iters), loss = 0.000291984
I0527 04:14:02.552492 30701 solver.cpp:237]     Train net output #0: loss = 0.00029009 (* 1 = 0.00029009 loss)
I0527 04:14:02.552501 30701 sgd_solver.cpp:105] Iteration 155400, lr = 0.00223
I0527 04:14:21.682138 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:14:30.662559 30701 solver.cpp:218] Iteration 155500 (3.55757 iter/s, 28.1091s/100 iters), loss = 0.000211422
I0527 04:14:30.662608 30701 solver.cpp:237]     Train net output #0: loss = 0.000209527 (* 1 = 0.000209527 loss)
I0527 04:14:30.662617 30701 sgd_solver.cpp:105] Iteration 155500, lr = 0.002225
I0527 04:14:58.775199 30701 solver.cpp:218] Iteration 155600 (3.55725 iter/s, 28.1116s/100 iters), loss = 0.000500701
I0527 04:14:58.775372 30701 solver.cpp:237]     Train net output #0: loss = 0.000498807 (* 1 = 0.000498807 loss)
I0527 04:14:58.775390 30701 sgd_solver.cpp:105] Iteration 155600, lr = 0.00222
I0527 04:15:26.906157 30701 solver.cpp:218] Iteration 155700 (3.55494 iter/s, 28.1298s/100 iters), loss = 0.00015592
I0527 04:15:26.906208 30701 solver.cpp:237]     Train net output #0: loss = 0.000154025 (* 1 = 0.000154025 loss)
I0527 04:15:26.906220 30701 sgd_solver.cpp:105] Iteration 155700, lr = 0.002215
I0527 04:15:55.019201 30701 solver.cpp:218] Iteration 155800 (3.55719 iter/s, 28.1121s/100 iters), loss = 0.000251622
I0527 04:15:55.019367 30701 solver.cpp:237]     Train net output #0: loss = 0.000249727 (* 1 = 0.000249727 loss)
I0527 04:15:55.019378 30701 sgd_solver.cpp:105] Iteration 155800, lr = 0.00221
I0527 04:16:23.090097 30701 solver.cpp:218] Iteration 155900 (3.56254 iter/s, 28.0698s/100 iters), loss = 0.000231448
I0527 04:16:23.090147 30701 solver.cpp:237]     Train net output #0: loss = 0.000229553 (* 1 = 0.000229553 loss)
I0527 04:16:23.090155 30701 sgd_solver.cpp:105] Iteration 155900, lr = 0.002205
I0527 04:16:50.874277 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_156000.caffemodel
I0527 04:16:51.187777 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_156000.solverstate
I0527 04:16:51.337463 30701 solver.cpp:330] Iteration 156000, Testing net (#0)
I0527 04:16:53.147965 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:16:54.299111 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 04:16:54.299155 30701 solver.cpp:397]     Test net output #1: loss = 0.754574 (* 1 = 0.754574 loss)
I0527 04:16:54.577111 30701 solver.cpp:218] Iteration 156000 (3.17602 iter/s, 31.486s/100 iters), loss = 0.00114154
I0527 04:16:54.577162 30701 solver.cpp:237]     Train net output #0: loss = 0.00113964 (* 1 = 0.00113964 loss)
I0527 04:16:54.577175 30701 sgd_solver.cpp:105] Iteration 156000, lr = 0.0022
I0527 04:17:11.179872 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:17:22.683265 30701 solver.cpp:218] Iteration 156100 (3.55806 iter/s, 28.1052s/100 iters), loss = 9.7066e-05
I0527 04:17:22.683406 30701 solver.cpp:237]     Train net output #0: loss = 9.51708e-05 (* 1 = 9.51708e-05 loss)
I0527 04:17:22.683429 30701 sgd_solver.cpp:105] Iteration 156100, lr = 0.002195
I0527 04:17:50.765661 30701 solver.cpp:218] Iteration 156200 (3.56108 iter/s, 28.0814s/100 iters), loss = 0.000249814
I0527 04:17:50.765708 30701 solver.cpp:237]     Train net output #0: loss = 0.000247919 (* 1 = 0.000247919 loss)
I0527 04:17:50.765717 30701 sgd_solver.cpp:105] Iteration 156200, lr = 0.00219
I0527 04:18:18.844336 30701 solver.cpp:218] Iteration 156300 (3.56154 iter/s, 28.0778s/100 iters), loss = 0.000434451
I0527 04:18:18.844494 30701 solver.cpp:237]     Train net output #0: loss = 0.000432556 (* 1 = 0.000432556 loss)
I0527 04:18:18.844514 30701 sgd_solver.cpp:105] Iteration 156300, lr = 0.002185
I0527 04:18:46.944229 30701 solver.cpp:218] Iteration 156400 (3.55886 iter/s, 28.0989s/100 iters), loss = 0.000210429
I0527 04:18:46.944279 30701 solver.cpp:237]     Train net output #0: loss = 0.000208534 (* 1 = 0.000208534 loss)
I0527 04:18:46.944293 30701 sgd_solver.cpp:105] Iteration 156400, lr = 0.00218
I0527 04:19:15.065613 30701 solver.cpp:218] Iteration 156500 (3.55612 iter/s, 28.1205s/100 iters), loss = 0.000379205
I0527 04:19:15.065767 30701 solver.cpp:237]     Train net output #0: loss = 0.00037731 (* 1 = 0.00037731 loss)
I0527 04:19:15.065780 30701 sgd_solver.cpp:105] Iteration 156500, lr = 0.002175
I0527 04:19:43.173434 30701 solver.cpp:218] Iteration 156600 (3.55785 iter/s, 28.1069s/100 iters), loss = 0.000257935
I0527 04:19:43.173478 30701 solver.cpp:237]     Train net output #0: loss = 0.00025604 (* 1 = 0.00025604 loss)
I0527 04:19:43.173487 30701 sgd_solver.cpp:105] Iteration 156600, lr = 0.00217
I0527 04:19:57.238880 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:20:11.265297 30701 solver.cpp:218] Iteration 156700 (3.55986 iter/s, 28.091s/100 iters), loss = 0.000500719
I0527 04:20:11.265343 30701 solver.cpp:237]     Train net output #0: loss = 0.000498824 (* 1 = 0.000498824 loss)
I0527 04:20:11.265352 30701 sgd_solver.cpp:105] Iteration 156700, lr = 0.002165
I0527 04:20:39.347154 30701 solver.cpp:218] Iteration 156800 (3.56113 iter/s, 28.081s/100 iters), loss = 0.000131248
I0527 04:20:39.347331 30701 solver.cpp:237]     Train net output #0: loss = 0.000129353 (* 1 = 0.000129353 loss)
I0527 04:20:39.347348 30701 sgd_solver.cpp:105] Iteration 156800, lr = 0.00216
I0527 04:21:07.437645 30701 solver.cpp:218] Iteration 156900 (3.56005 iter/s, 28.0895s/100 iters), loss = 0.000148492
I0527 04:21:07.437696 30701 solver.cpp:237]     Train net output #0: loss = 0.000146597 (* 1 = 0.000146597 loss)
I0527 04:21:07.437710 30701 sgd_solver.cpp:105] Iteration 156900, lr = 0.002155
I0527 04:21:35.259904 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_157000.caffemodel
I0527 04:21:35.572767 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_157000.solverstate
I0527 04:21:35.768728 30701 solver.cpp:330] Iteration 157000, Testing net (#0)
I0527 04:21:38.725503 30701 solver.cpp:397]     Test net output #0: accuracy = 0.83
I0527 04:21:38.725553 30701 solver.cpp:397]     Test net output #1: loss = 0.824702 (* 1 = 0.824702 loss)
I0527 04:21:39.002249 30701 solver.cpp:218] Iteration 157000 (3.1682 iter/s, 31.5637s/100 iters), loss = 0.000288112
I0527 04:21:39.002296 30701 solver.cpp:237]     Train net output #0: loss = 0.000286217 (* 1 = 0.000286217 loss)
I0527 04:21:39.002305 30701 sgd_solver.cpp:105] Iteration 157000, lr = 0.00215
I0527 04:22:07.058964 30701 solver.cpp:218] Iteration 157100 (3.56431 iter/s, 28.0559s/100 iters), loss = 0.000203674
I0527 04:22:07.059183 30701 solver.cpp:237]     Train net output #0: loss = 0.00020178 (* 1 = 0.00020178 loss)
I0527 04:22:07.059195 30701 sgd_solver.cpp:105] Iteration 157100, lr = 0.002145
I0527 04:22:35.126159 30701 solver.cpp:218] Iteration 157200 (3.563 iter/s, 28.0662s/100 iters), loss = 0.000177419
I0527 04:22:35.126202 30701 solver.cpp:237]     Train net output #0: loss = 0.000175525 (* 1 = 0.000175525 loss)
I0527 04:22:35.126211 30701 sgd_solver.cpp:105] Iteration 157200, lr = 0.00214
I0527 04:22:46.656669 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:23:03.186254 30701 solver.cpp:218] Iteration 157300 (3.56388 iter/s, 28.0593s/100 iters), loss = 8.83573e-05
I0527 04:23:03.186296 30701 solver.cpp:237]     Train net output #0: loss = 8.64627e-05 (* 1 = 8.64627e-05 loss)
I0527 04:23:03.186305 30701 sgd_solver.cpp:105] Iteration 157300, lr = 0.002135
I0527 04:23:31.241606 30701 solver.cpp:218] Iteration 157400 (3.56448 iter/s, 28.0545s/100 iters), loss = 0.000397443
I0527 04:23:31.241780 30701 solver.cpp:237]     Train net output #0: loss = 0.000395548 (* 1 = 0.000395548 loss)
I0527 04:23:31.241791 30701 sgd_solver.cpp:105] Iteration 157400, lr = 0.00213
I0527 04:23:59.300818 30701 solver.cpp:218] Iteration 157500 (3.56401 iter/s, 28.0583s/100 iters), loss = 0.000144307
I0527 04:23:59.300863 30701 solver.cpp:237]     Train net output #0: loss = 0.000142411 (* 1 = 0.000142411 loss)
I0527 04:23:59.300871 30701 sgd_solver.cpp:105] Iteration 157500, lr = 0.002125
I0527 04:24:27.381105 30701 solver.cpp:218] Iteration 157600 (3.56132 iter/s, 28.0795s/100 iters), loss = 9.61593e-05
I0527 04:24:27.381319 30701 solver.cpp:237]     Train net output #0: loss = 9.42641e-05 (* 1 = 9.42641e-05 loss)
I0527 04:24:27.381330 30701 sgd_solver.cpp:105] Iteration 157600, lr = 0.00212
I0527 04:24:55.453197 30701 solver.cpp:218] Iteration 157700 (3.56238 iter/s, 28.0711s/100 iters), loss = 0.000217497
I0527 04:24:55.453244 30701 solver.cpp:237]     Train net output #0: loss = 0.000215601 (* 1 = 0.000215601 loss)
I0527 04:24:55.453254 30701 sgd_solver.cpp:105] Iteration 157700, lr = 0.002115
I0527 04:25:23.575306 30701 solver.cpp:218] Iteration 157800 (3.55602 iter/s, 28.1213s/100 iters), loss = 7.82322e-05
I0527 04:25:23.575527 30701 solver.cpp:237]     Train net output #0: loss = 7.63371e-05 (* 1 = 7.63371e-05 loss)
I0527 04:25:23.575538 30701 sgd_solver.cpp:105] Iteration 157800, lr = 0.00211
I0527 04:25:32.876757 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:25:51.693784 30701 solver.cpp:218] Iteration 157900 (3.5565 iter/s, 28.1175s/100 iters), loss = 0.000657624
I0527 04:25:51.693831 30701 solver.cpp:237]     Train net output #0: loss = 0.000655729 (* 1 = 0.000655729 loss)
I0527 04:25:51.693841 30701 sgd_solver.cpp:105] Iteration 157900, lr = 0.002105
I0527 04:26:19.538355 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_158000.caffemodel
I0527 04:26:19.852479 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_158000.solverstate
I0527 04:26:20.003080 30701 solver.cpp:330] Iteration 158000, Testing net (#0)
I0527 04:26:22.959329 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0527 04:26:22.959377 30701 solver.cpp:397]     Test net output #1: loss = 0.801315 (* 1 = 0.801315 loss)
I0527 04:26:23.237376 30701 solver.cpp:218] Iteration 158000 (3.1703 iter/s, 31.5427s/100 iters), loss = 0.000633959
I0527 04:26:23.237422 30701 solver.cpp:237]     Train net output #0: loss = 0.000632064 (* 1 = 0.000632064 loss)
I0527 04:26:23.237432 30701 sgd_solver.cpp:105] Iteration 158000, lr = 0.0021
I0527 04:26:51.300825 30701 solver.cpp:218] Iteration 158100 (3.56345 iter/s, 28.0627s/100 iters), loss = 0.000288524
I0527 04:26:51.301020 30701 solver.cpp:237]     Train net output #0: loss = 0.000286629 (* 1 = 0.000286629 loss)
I0527 04:26:51.301031 30701 sgd_solver.cpp:105] Iteration 158100, lr = 0.002095
I0527 04:27:19.383162 30701 solver.cpp:218] Iteration 158200 (3.56107 iter/s, 28.0814s/100 iters), loss = 6.5181e-05
I0527 04:27:19.383208 30701 solver.cpp:237]     Train net output #0: loss = 6.3286e-05 (* 1 = 6.3286e-05 loss)
I0527 04:27:19.383215 30701 sgd_solver.cpp:105] Iteration 158200, lr = 0.00209
I0527 04:27:47.437227 30701 solver.cpp:218] Iteration 158300 (3.56464 iter/s, 28.0533s/100 iters), loss = 0.000391834
I0527 04:27:47.437439 30701 solver.cpp:237]     Train net output #0: loss = 0.000389938 (* 1 = 0.000389938 loss)
I0527 04:27:47.437450 30701 sgd_solver.cpp:105] Iteration 158300, lr = 0.002085
I0527 04:28:15.504089 30701 solver.cpp:218] Iteration 158400 (3.56304 iter/s, 28.0659s/100 iters), loss = 0.000219127
I0527 04:28:15.504133 30701 solver.cpp:237]     Train net output #0: loss = 0.000217231 (* 1 = 0.000217231 loss)
I0527 04:28:15.504142 30701 sgd_solver.cpp:105] Iteration 158400, lr = 0.00208
I0527 04:28:22.263689 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:28:43.604288 30701 solver.cpp:218] Iteration 158500 (3.55879 iter/s, 28.0994s/100 iters), loss = 0.000159306
I0527 04:28:43.604358 30701 solver.cpp:237]     Train net output #0: loss = 0.000157411 (* 1 = 0.000157411 loss)
I0527 04:28:43.604374 30701 sgd_solver.cpp:105] Iteration 158500, lr = 0.002075
I0527 04:29:11.700064 30701 solver.cpp:218] Iteration 158600 (3.55935 iter/s, 28.095s/100 iters), loss = 0.000225724
I0527 04:29:11.700223 30701 solver.cpp:237]     Train net output #0: loss = 0.000223829 (* 1 = 0.000223829 loss)
I0527 04:29:11.700235 30701 sgd_solver.cpp:105] Iteration 158600, lr = 0.00207
I0527 04:29:39.780738 30701 solver.cpp:218] Iteration 158700 (3.56128 iter/s, 28.0798s/100 iters), loss = 0.000675776
I0527 04:29:39.780786 30701 solver.cpp:237]     Train net output #0: loss = 0.000673881 (* 1 = 0.000673881 loss)
I0527 04:29:39.780794 30701 sgd_solver.cpp:105] Iteration 158700, lr = 0.002065
I0527 04:30:07.898234 30701 solver.cpp:218] Iteration 158800 (3.5566 iter/s, 28.1168s/100 iters), loss = 0.000800077
I0527 04:30:07.898455 30701 solver.cpp:237]     Train net output #0: loss = 0.000798181 (* 1 = 0.000798181 loss)
I0527 04:30:07.898468 30701 sgd_solver.cpp:105] Iteration 158800, lr = 0.00206
I0527 04:30:36.025229 30701 solver.cpp:218] Iteration 158900 (3.55542 iter/s, 28.1261s/100 iters), loss = 0.000351224
I0527 04:30:36.025274 30701 solver.cpp:237]     Train net output #0: loss = 0.000349329 (* 1 = 0.000349329 loss)
I0527 04:30:36.025282 30701 sgd_solver.cpp:105] Iteration 158900, lr = 0.002055
I0527 04:31:03.880672 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_159000.caffemodel
I0527 04:31:04.195592 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_159000.solverstate
I0527 04:31:04.347388 30701 solver.cpp:330] Iteration 159000, Testing net (#0)
I0527 04:31:04.884889 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:31:07.309666 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 04:31:07.309718 30701 solver.cpp:397]     Test net output #1: loss = 0.815992 (* 1 = 0.815992 loss)
I0527 04:31:07.588752 30701 solver.cpp:218] Iteration 159000 (3.1683 iter/s, 31.5627s/100 iters), loss = 0.000389407
I0527 04:31:07.588796 30701 solver.cpp:237]     Train net output #0: loss = 0.000387512 (* 1 = 0.000387512 loss)
I0527 04:31:07.588805 30701 sgd_solver.cpp:105] Iteration 159000, lr = 0.00205
I0527 04:31:11.829610 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:31:35.714522 30701 solver.cpp:218] Iteration 159100 (3.55555 iter/s, 28.125s/100 iters), loss = 0.000136317
I0527 04:31:35.714694 30701 solver.cpp:237]     Train net output #0: loss = 0.000134422 (* 1 = 0.000134422 loss)
I0527 04:31:35.714704 30701 sgd_solver.cpp:105] Iteration 159100, lr = 0.002045
I0527 04:32:03.840009 30701 solver.cpp:218] Iteration 159200 (3.5556 iter/s, 28.1246s/100 iters), loss = 0.000126384
I0527 04:32:03.840055 30701 solver.cpp:237]     Train net output #0: loss = 0.000124489 (* 1 = 0.000124489 loss)
I0527 04:32:03.840076 30701 sgd_solver.cpp:105] Iteration 159200, lr = 0.00204
I0527 04:32:31.983387 30701 solver.cpp:218] Iteration 159300 (3.55333 iter/s, 28.1426s/100 iters), loss = 0.000386762
I0527 04:32:31.983566 30701 solver.cpp:237]     Train net output #0: loss = 0.000384867 (* 1 = 0.000384867 loss)
I0527 04:32:31.983578 30701 sgd_solver.cpp:105] Iteration 159300, lr = 0.002035
I0527 04:33:00.114246 30701 solver.cpp:218] Iteration 159400 (3.55492 iter/s, 28.13s/100 iters), loss = 0.000459732
I0527 04:33:00.114295 30701 solver.cpp:237]     Train net output #0: loss = 0.000457837 (* 1 = 0.000457837 loss)
I0527 04:33:00.114303 30701 sgd_solver.cpp:105] Iteration 159400, lr = 0.00203
I0527 04:33:28.252570 30701 solver.cpp:218] Iteration 159500 (3.55396 iter/s, 28.1376s/100 iters), loss = 0.000143078
I0527 04:33:28.252710 30701 solver.cpp:237]     Train net output #0: loss = 0.000141182 (* 1 = 0.000141182 loss)
I0527 04:33:28.252720 30701 sgd_solver.cpp:105] Iteration 159500, lr = 0.002025
I0527 04:33:56.380244 30701 solver.cpp:218] Iteration 159600 (3.55532 iter/s, 28.1269s/100 iters), loss = 0.00101906
I0527 04:33:56.380290 30701 solver.cpp:237]     Train net output #0: loss = 0.00101716 (* 1 = 0.00101716 loss)
I0527 04:33:56.380298 30701 sgd_solver.cpp:105] Iteration 159600, lr = 0.00202
I0527 04:33:58.087251 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:34:24.514230 30701 solver.cpp:218] Iteration 159700 (3.55451 iter/s, 28.1333s/100 iters), loss = 0.000146679
I0527 04:34:24.514348 30701 solver.cpp:237]     Train net output #0: loss = 0.000144783 (* 1 = 0.000144783 loss)
I0527 04:34:24.514360 30701 sgd_solver.cpp:105] Iteration 159700, lr = 0.002015
I0527 04:34:52.636572 30701 solver.cpp:218] Iteration 159800 (3.55599 iter/s, 28.1215s/100 iters), loss = 0.000225003
I0527 04:34:52.636621 30701 solver.cpp:237]     Train net output #0: loss = 0.000223108 (* 1 = 0.000223108 loss)
I0527 04:34:52.636631 30701 sgd_solver.cpp:105] Iteration 159800, lr = 0.00201
I0527 04:35:20.773133 30701 solver.cpp:218] Iteration 159900 (3.55419 iter/s, 28.1358s/100 iters), loss = 0.00144049
I0527 04:35:20.773300 30701 solver.cpp:237]     Train net output #0: loss = 0.00143859 (* 1 = 0.00143859 loss)
I0527 04:35:20.773313 30701 sgd_solver.cpp:105] Iteration 159900, lr = 0.002005
I0527 04:35:48.612846 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_160000.caffemodel
I0527 04:35:48.926136 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_160000.solverstate
I0527 04:35:49.076740 30701 solver.cpp:330] Iteration 160000, Testing net (#0)
I0527 04:35:52.034821 30701 solver.cpp:397]     Test net output #0: accuracy = 0.814
I0527 04:35:52.034935 30701 solver.cpp:397]     Test net output #1: loss = 0.847797 (* 1 = 0.847797 loss)
I0527 04:35:52.313971 30701 solver.cpp:218] Iteration 160000 (3.17058 iter/s, 31.5399s/100 iters), loss = 0.000202366
I0527 04:35:52.314013 30701 solver.cpp:237]     Train net output #0: loss = 0.000200471 (* 1 = 0.000200471 loss)
I0527 04:35:52.314021 30701 sgd_solver.cpp:105] Iteration 160000, lr = 0.002
I0527 04:36:20.376433 30701 solver.cpp:218] Iteration 160100 (3.56357 iter/s, 28.0618s/100 iters), loss = 0.000187033
I0527 04:36:20.376482 30701 solver.cpp:237]     Train net output #0: loss = 0.000185137 (* 1 = 0.000185137 loss)
I0527 04:36:20.376492 30701 sgd_solver.cpp:105] Iteration 160100, lr = 0.001995
I0527 04:36:47.640592 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:36:48.466033 30701 solver.cpp:218] Iteration 160200 (3.56013 iter/s, 28.0889s/100 iters), loss = 0.000237406
I0527 04:36:48.466091 30701 solver.cpp:237]     Train net output #0: loss = 0.00023551 (* 1 = 0.00023551 loss)
I0527 04:36:48.466100 30701 sgd_solver.cpp:105] Iteration 160200, lr = 0.00199
I0527 04:37:16.579617 30701 solver.cpp:218] Iteration 160300 (3.55709 iter/s, 28.1129s/100 iters), loss = 0.000339933
I0527 04:37:16.579661 30701 solver.cpp:237]     Train net output #0: loss = 0.000338037 (* 1 = 0.000338037 loss)
I0527 04:37:16.579670 30701 sgd_solver.cpp:105] Iteration 160300, lr = 0.001985
I0527 04:37:44.694483 30701 solver.cpp:218] Iteration 160400 (3.55693 iter/s, 28.1142s/100 iters), loss = 9.38705e-05
I0527 04:37:44.694703 30701 solver.cpp:237]     Train net output #0: loss = 9.19746e-05 (* 1 = 9.19746e-05 loss)
I0527 04:37:44.694715 30701 sgd_solver.cpp:105] Iteration 160400, lr = 0.00198
I0527 04:38:12.796033 30701 solver.cpp:218] Iteration 160500 (3.55863 iter/s, 28.1007s/100 iters), loss = 0.000213693
I0527 04:38:12.796077 30701 solver.cpp:237]     Train net output #0: loss = 0.000211797 (* 1 = 0.000211797 loss)
I0527 04:38:12.796087 30701 sgd_solver.cpp:105] Iteration 160500, lr = 0.001975
I0527 04:38:40.876955 30701 solver.cpp:218] Iteration 160600 (3.56123 iter/s, 28.0802s/100 iters), loss = 0.000394935
I0527 04:38:40.877104 30701 solver.cpp:237]     Train net output #0: loss = 0.000393039 (* 1 = 0.000393039 loss)
I0527 04:38:40.877117 30701 sgd_solver.cpp:105] Iteration 160600, lr = 0.00197
I0527 04:39:08.973341 30701 solver.cpp:218] Iteration 160700 (3.55928 iter/s, 28.0956s/100 iters), loss = 0.000145583
I0527 04:39:08.973387 30701 solver.cpp:237]     Train net output #0: loss = 0.000143687 (* 1 = 0.000143687 loss)
I0527 04:39:08.973395 30701 sgd_solver.cpp:105] Iteration 160700, lr = 0.001965
I0527 04:39:33.716879 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:39:37.067478 30701 solver.cpp:218] Iteration 160800 (3.55955 iter/s, 28.0934s/100 iters), loss = 0.000235932
I0527 04:39:37.067523 30701 solver.cpp:237]     Train net output #0: loss = 0.000234035 (* 1 = 0.000234035 loss)
I0527 04:39:37.067531 30701 sgd_solver.cpp:105] Iteration 160800, lr = 0.00196
I0527 04:40:05.150773 30701 solver.cpp:218] Iteration 160900 (3.56093 iter/s, 28.0826s/100 iters), loss = 0.000220891
I0527 04:40:05.150934 30701 solver.cpp:237]     Train net output #0: loss = 0.000218995 (* 1 = 0.000218995 loss)
I0527 04:40:05.150945 30701 sgd_solver.cpp:105] Iteration 160900, lr = 0.001955
I0527 04:40:32.952955 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_161000.caffemodel
I0527 04:40:33.267701 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_161000.solverstate
I0527 04:40:33.418313 30701 solver.cpp:330] Iteration 161000, Testing net (#0)
I0527 04:40:35.640270 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:40:36.379016 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 04:40:36.379067 30701 solver.cpp:397]     Test net output #1: loss = 0.754865 (* 1 = 0.754865 loss)
I0527 04:40:36.657425 30701 solver.cpp:218] Iteration 161000 (3.17402 iter/s, 31.5058s/100 iters), loss = 0.000227679
I0527 04:40:36.657470 30701 solver.cpp:237]     Train net output #0: loss = 0.000225782 (* 1 = 0.000225782 loss)
I0527 04:40:36.657480 30701 sgd_solver.cpp:105] Iteration 161000, lr = 0.00195
I0527 04:41:04.731966 30701 solver.cpp:218] Iteration 161100 (3.56204 iter/s, 28.0738s/100 iters), loss = 0.00187037
I0527 04:41:04.732012 30701 solver.cpp:237]     Train net output #0: loss = 0.00186847 (* 1 = 0.00186847 loss)
I0527 04:41:04.732022 30701 sgd_solver.cpp:105] Iteration 161100, lr = 0.001945
I0527 04:41:32.838835 30701 solver.cpp:218] Iteration 161200 (3.55794 iter/s, 28.1062s/100 iters), loss = 7.96237e-05
I0527 04:41:32.839028 30701 solver.cpp:237]     Train net output #0: loss = 7.77266e-05 (* 1 = 7.77266e-05 loss)
I0527 04:41:32.839040 30701 sgd_solver.cpp:105] Iteration 161200, lr = 0.00194
I0527 04:42:00.947289 30701 solver.cpp:218] Iteration 161300 (3.55776 iter/s, 28.1076s/100 iters), loss = 0.000914538
I0527 04:42:00.947334 30701 solver.cpp:237]     Train net output #0: loss = 0.000912641 (* 1 = 0.000912641 loss)
I0527 04:42:00.947341 30701 sgd_solver.cpp:105] Iteration 161300, lr = 0.001935
I0527 04:42:23.177652 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:42:29.064481 30701 solver.cpp:218] Iteration 161400 (3.55663 iter/s, 28.1165s/100 iters), loss = 0.000359046
I0527 04:42:29.064528 30701 solver.cpp:237]     Train net output #0: loss = 0.00035715 (* 1 = 0.00035715 loss)
I0527 04:42:29.064538 30701 sgd_solver.cpp:105] Iteration 161400, lr = 0.00193
I0527 04:42:57.177546 30701 solver.cpp:218] Iteration 161500 (3.55715 iter/s, 28.1124s/100 iters), loss = 0.000571488
I0527 04:42:57.177711 30701 solver.cpp:237]     Train net output #0: loss = 0.000569591 (* 1 = 0.000569591 loss)
I0527 04:42:57.177723 30701 sgd_solver.cpp:105] Iteration 161500, lr = 0.001925
I0527 04:43:25.302976 30701 solver.cpp:218] Iteration 161600 (3.5556 iter/s, 28.1246s/100 iters), loss = 0.00117343
I0527 04:43:25.303035 30701 solver.cpp:237]     Train net output #0: loss = 0.00117153 (* 1 = 0.00117153 loss)
I0527 04:43:25.303043 30701 sgd_solver.cpp:105] Iteration 161600, lr = 0.00192
I0527 04:43:53.404569 30701 solver.cpp:218] Iteration 161700 (3.55861 iter/s, 28.1009s/100 iters), loss = 0.000109961
I0527 04:43:53.404774 30701 solver.cpp:237]     Train net output #0: loss = 0.000108064 (* 1 = 0.000108064 loss)
I0527 04:43:53.404786 30701 sgd_solver.cpp:105] Iteration 161700, lr = 0.001915
I0527 04:44:21.515673 30701 solver.cpp:218] Iteration 161800 (3.55742 iter/s, 28.1102s/100 iters), loss = 0.000494344
I0527 04:44:21.515719 30701 solver.cpp:237]     Train net output #0: loss = 0.000492447 (* 1 = 0.000492447 loss)
I0527 04:44:21.515727 30701 sgd_solver.cpp:105] Iteration 161800, lr = 0.00191
I0527 04:44:49.588181 30701 solver.cpp:218] Iteration 161900 (3.56229 iter/s, 28.0718s/100 iters), loss = 0.000416059
I0527 04:44:49.588348 30701 solver.cpp:237]     Train net output #0: loss = 0.000414162 (* 1 = 0.000414162 loss)
I0527 04:44:49.588359 30701 sgd_solver.cpp:105] Iteration 161900, lr = 0.001905
I0527 04:45:09.545686 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:45:17.401862 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_162000.caffemodel
I0527 04:45:17.715240 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_162000.solverstate
I0527 04:45:17.865344 30701 solver.cpp:330] Iteration 162000, Testing net (#0)
I0527 04:45:20.816615 30701 solver.cpp:397]     Test net output #0: accuracy = 0.83
I0527 04:45:20.816733 30701 solver.cpp:397]     Test net output #1: loss = 0.843112 (* 1 = 0.843112 loss)
I0527 04:45:21.094329 30701 solver.cpp:218] Iteration 162000 (3.17407 iter/s, 31.5053s/100 iters), loss = 0.000121277
I0527 04:45:21.094388 30701 solver.cpp:237]     Train net output #0: loss = 0.00011938 (* 1 = 0.00011938 loss)
I0527 04:45:21.094398 30701 sgd_solver.cpp:105] Iteration 162000, lr = 0.0019
I0527 04:45:49.167366 30701 solver.cpp:218] Iteration 162100 (3.56223 iter/s, 28.0723s/100 iters), loss = 0.000178781
I0527 04:45:49.167423 30701 solver.cpp:237]     Train net output #0: loss = 0.000176885 (* 1 = 0.000176885 loss)
I0527 04:45:49.167433 30701 sgd_solver.cpp:105] Iteration 162100, lr = 0.001895
I0527 04:46:17.254479 30701 solver.cpp:218] Iteration 162200 (3.56044 iter/s, 28.0864s/100 iters), loss = 0.000273228
I0527 04:46:17.254642 30701 solver.cpp:237]     Train net output #0: loss = 0.000271332 (* 1 = 0.000271332 loss)
I0527 04:46:17.254653 30701 sgd_solver.cpp:105] Iteration 162200, lr = 0.00189
I0527 04:46:45.338716 30701 solver.cpp:218] Iteration 162300 (3.56082 iter/s, 28.0834s/100 iters), loss = 0.00197487
I0527 04:46:45.338762 30701 solver.cpp:237]     Train net output #0: loss = 0.00197298 (* 1 = 0.00197298 loss)
I0527 04:46:45.338771 30701 sgd_solver.cpp:105] Iteration 162300, lr = 0.001885
I0527 04:47:13.418747 30701 solver.cpp:218] Iteration 162400 (3.56134 iter/s, 28.0793s/100 iters), loss = 0.000226032
I0527 04:47:13.418942 30701 solver.cpp:237]     Train net output #0: loss = 0.000224135 (* 1 = 0.000224135 loss)
I0527 04:47:13.418954 30701 sgd_solver.cpp:105] Iteration 162400, lr = 0.00188
I0527 04:47:41.498900 30701 solver.cpp:218] Iteration 162500 (3.56134 iter/s, 28.0793s/100 iters), loss = 0.000210511
I0527 04:47:41.498957 30701 solver.cpp:237]     Train net output #0: loss = 0.000208614 (* 1 = 0.000208614 loss)
I0527 04:47:41.498965 30701 sgd_solver.cpp:105] Iteration 162500, lr = 0.001875
I0527 04:47:58.921530 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:48:09.571866 30701 solver.cpp:218] Iteration 162600 (3.56221 iter/s, 28.0725s/100 iters), loss = 0.000395364
I0527 04:48:09.571913 30701 solver.cpp:237]     Train net output #0: loss = 0.000393467 (* 1 = 0.000393467 loss)
I0527 04:48:09.571923 30701 sgd_solver.cpp:105] Iteration 162600, lr = 0.00187
I0527 04:48:37.652676 30701 solver.cpp:218] Iteration 162700 (3.56122 iter/s, 28.0803s/100 iters), loss = 0.000277368
I0527 04:48:37.652858 30701 solver.cpp:237]     Train net output #0: loss = 0.000275471 (* 1 = 0.000275471 loss)
I0527 04:48:37.652869 30701 sgd_solver.cpp:105] Iteration 162700, lr = 0.001865
I0527 04:49:05.722236 30701 solver.cpp:218] Iteration 162800 (3.56266 iter/s, 28.0689s/100 iters), loss = 0.000274591
I0527 04:49:05.722285 30701 solver.cpp:237]     Train net output #0: loss = 0.000272693 (* 1 = 0.000272693 loss)
I0527 04:49:05.722293 30701 sgd_solver.cpp:105] Iteration 162800, lr = 0.00186
I0527 04:49:33.797703 30701 solver.cpp:218] Iteration 162900 (3.5619 iter/s, 28.0749s/100 iters), loss = 0.000245756
I0527 04:49:33.797893 30701 solver.cpp:237]     Train net output #0: loss = 0.000243859 (* 1 = 0.000243859 loss)
I0527 04:49:33.797919 30701 sgd_solver.cpp:105] Iteration 162900, lr = 0.001855
I0527 04:50:01.589072 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_163000.caffemodel
I0527 04:50:02.118541 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_163000.solverstate
I0527 04:50:02.272564 30701 solver.cpp:330] Iteration 163000, Testing net (#0)
I0527 04:50:05.224782 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 04:50:05.224907 30701 solver.cpp:397]     Test net output #1: loss = 0.799407 (* 1 = 0.799407 loss)
I0527 04:50:05.502210 30701 solver.cpp:218] Iteration 163000 (3.1542 iter/s, 31.7038s/100 iters), loss = 0.000245508
I0527 04:50:05.502256 30701 solver.cpp:237]     Train net output #0: loss = 0.000243611 (* 1 = 0.000243611 loss)
I0527 04:50:05.502265 30701 sgd_solver.cpp:105] Iteration 163000, lr = 0.00185
I0527 04:50:33.592187 30701 solver.cpp:218] Iteration 163100 (3.56006 iter/s, 28.0894s/100 iters), loss = 0.000126588
I0527 04:50:33.592245 30701 solver.cpp:237]     Train net output #0: loss = 0.000124691 (* 1 = 0.000124691 loss)
I0527 04:50:33.592254 30701 sgd_solver.cpp:105] Iteration 163100, lr = 0.001845
I0527 04:50:48.500680 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:51:01.683939 30701 solver.cpp:218] Iteration 163200 (3.55984 iter/s, 28.0912s/100 iters), loss = 0.000274556
I0527 04:51:01.683998 30701 solver.cpp:237]     Train net output #0: loss = 0.000272659 (* 1 = 0.000272659 loss)
I0527 04:51:01.684008 30701 sgd_solver.cpp:105] Iteration 163200, lr = 0.00184
I0527 04:51:29.810060 30701 solver.cpp:218] Iteration 163300 (3.55549 iter/s, 28.1255s/100 iters), loss = 0.000191826
I0527 04:51:29.810268 30701 solver.cpp:237]     Train net output #0: loss = 0.000189928 (* 1 = 0.000189928 loss)
I0527 04:51:29.810279 30701 sgd_solver.cpp:105] Iteration 163300, lr = 0.001835
I0527 04:51:57.939059 30701 solver.cpp:218] Iteration 163400 (3.55514 iter/s, 28.1283s/100 iters), loss = 0.000180953
I0527 04:51:57.939102 30701 solver.cpp:237]     Train net output #0: loss = 0.000179055 (* 1 = 0.000179055 loss)
I0527 04:51:57.939111 30701 sgd_solver.cpp:105] Iteration 163400, lr = 0.00183
I0527 04:52:26.057780 30701 solver.cpp:218] Iteration 163500 (3.55642 iter/s, 28.1182s/100 iters), loss = 0.000225201
I0527 04:52:26.057979 30701 solver.cpp:237]     Train net output #0: loss = 0.000223304 (* 1 = 0.000223304 loss)
I0527 04:52:26.057991 30701 sgd_solver.cpp:105] Iteration 163500, lr = 0.001825
I0527 04:52:54.191771 30701 solver.cpp:218] Iteration 163600 (3.55451 iter/s, 28.1333s/100 iters), loss = 0.000190686
I0527 04:52:54.191826 30701 solver.cpp:237]     Train net output #0: loss = 0.000188788 (* 1 = 0.000188788 loss)
I0527 04:52:54.191834 30701 sgd_solver.cpp:105] Iteration 163600, lr = 0.00182
I0527 04:53:22.328246 30701 solver.cpp:218] Iteration 163700 (3.55418 iter/s, 28.1359s/100 iters), loss = 0.000119487
I0527 04:53:22.328411 30701 solver.cpp:237]     Train net output #0: loss = 0.000117589 (* 1 = 0.000117589 loss)
I0527 04:53:22.328423 30701 sgd_solver.cpp:105] Iteration 163700, lr = 0.001815
I0527 04:53:34.731842 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:53:50.471158 30701 solver.cpp:218] Iteration 163800 (3.55338 iter/s, 28.1422s/100 iters), loss = 9.09918e-05
I0527 04:53:50.471201 30701 solver.cpp:237]     Train net output #0: loss = 8.90941e-05 (* 1 = 8.90941e-05 loss)
I0527 04:53:50.471210 30701 sgd_solver.cpp:105] Iteration 163800, lr = 0.00181
I0527 04:54:18.604203 30701 solver.cpp:218] Iteration 163900 (3.55461 iter/s, 28.1325s/100 iters), loss = 0.000334646
I0527 04:54:18.606168 30701 solver.cpp:237]     Train net output #0: loss = 0.000332748 (* 1 = 0.000332748 loss)
I0527 04:54:18.606180 30701 sgd_solver.cpp:105] Iteration 163900, lr = 0.001805
I0527 04:54:46.434620 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_164000.caffemodel
I0527 04:54:46.944620 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_164000.solverstate
I0527 04:54:47.098211 30701 solver.cpp:330] Iteration 164000, Testing net (#0)
I0527 04:54:48.047693 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:54:50.060120 30701 solver.cpp:397]     Test net output #0: accuracy = 0.842
I0527 04:54:50.060272 30701 solver.cpp:397]     Test net output #1: loss = 0.767698 (* 1 = 0.767698 loss)
I0527 04:54:50.339169 30701 solver.cpp:218] Iteration 164000 (3.15135 iter/s, 31.7324s/100 iters), loss = 0.000116752
I0527 04:54:50.339220 30701 solver.cpp:237]     Train net output #0: loss = 0.000114854 (* 1 = 0.000114854 loss)
I0527 04:54:50.339232 30701 sgd_solver.cpp:105] Iteration 164000, lr = 0.0018
I0527 04:55:18.430860 30701 solver.cpp:218] Iteration 164100 (3.55985 iter/s, 28.0911s/100 iters), loss = 9.07826e-05
I0527 04:55:18.430903 30701 solver.cpp:237]     Train net output #0: loss = 8.88852e-05 (* 1 = 8.88852e-05 loss)
I0527 04:55:18.430912 30701 sgd_solver.cpp:105] Iteration 164100, lr = 0.001795
I0527 04:55:46.499173 30701 solver.cpp:218] Iteration 164200 (3.56281 iter/s, 28.0677s/100 iters), loss = 0.000175944
I0527 04:55:46.499310 30701 solver.cpp:237]     Train net output #0: loss = 0.000174046 (* 1 = 0.000174046 loss)
I0527 04:55:46.499330 30701 sgd_solver.cpp:105] Iteration 164200, lr = 0.00179
I0527 04:56:14.571351 30701 solver.cpp:218] Iteration 164300 (3.56233 iter/s, 28.0715s/100 iters), loss = 0.000190734
I0527 04:56:14.571398 30701 solver.cpp:237]     Train net output #0: loss = 0.000188837 (* 1 = 0.000188837 loss)
I0527 04:56:14.571408 30701 sgd_solver.cpp:105] Iteration 164300, lr = 0.001785
I0527 04:56:24.408720 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:56:42.640059 30701 solver.cpp:218] Iteration 164400 (3.56276 iter/s, 28.0681s/100 iters), loss = 0.000211764
I0527 04:56:42.640105 30701 solver.cpp:237]     Train net output #0: loss = 0.000209867 (* 1 = 0.000209867 loss)
I0527 04:56:42.640115 30701 sgd_solver.cpp:105] Iteration 164400, lr = 0.00178
I0527 04:57:10.719527 30701 solver.cpp:218] Iteration 164500 (3.5614 iter/s, 28.0789s/100 iters), loss = 0.000808855
I0527 04:57:10.719724 30701 solver.cpp:237]     Train net output #0: loss = 0.000806958 (* 1 = 0.000806958 loss)
I0527 04:57:10.719736 30701 sgd_solver.cpp:105] Iteration 164500, lr = 0.001775
I0527 04:57:38.796505 30701 solver.cpp:218] Iteration 164600 (3.56173 iter/s, 28.0762s/100 iters), loss = 0.000809228
I0527 04:57:38.796550 30701 solver.cpp:237]     Train net output #0: loss = 0.00080733 (* 1 = 0.00080733 loss)
I0527 04:57:38.796558 30701 sgd_solver.cpp:105] Iteration 164600, lr = 0.00177
I0527 04:58:06.884492 30701 solver.cpp:218] Iteration 164700 (3.56032 iter/s, 28.0874s/100 iters), loss = 0.000204579
I0527 04:58:06.884670 30701 solver.cpp:237]     Train net output #0: loss = 0.000202682 (* 1 = 0.000202682 loss)
I0527 04:58:06.884682 30701 sgd_solver.cpp:105] Iteration 164700, lr = 0.001765
I0527 04:58:35.007530 30701 solver.cpp:218] Iteration 164800 (3.5559 iter/s, 28.1223s/100 iters), loss = 0.000112584
I0527 04:58:35.007576 30701 solver.cpp:237]     Train net output #0: loss = 0.000110687 (* 1 = 0.000110687 loss)
I0527 04:58:35.007585 30701 sgd_solver.cpp:105] Iteration 164800, lr = 0.00176
I0527 04:59:03.107237 30701 solver.cpp:218] Iteration 164900 (3.55884 iter/s, 28.0991s/100 iters), loss = 0.000476539
I0527 04:59:03.107395 30701 solver.cpp:237]     Train net output #0: loss = 0.000474643 (* 1 = 0.000474643 loss)
I0527 04:59:03.107408 30701 sgd_solver.cpp:105] Iteration 164900, lr = 0.001755
I0527 04:59:10.434227 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 04:59:30.940151 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_165000.caffemodel
I0527 04:59:31.471560 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_165000.solverstate
I0527 04:59:31.625710 30701 solver.cpp:330] Iteration 165000, Testing net (#0)
I0527 04:59:34.586324 30701 solver.cpp:397]     Test net output #0: accuracy = 0.816
I0527 04:59:34.586457 30701 solver.cpp:397]     Test net output #1: loss = 0.909778 (* 1 = 0.909778 loss)
I0527 04:59:34.864609 30701 solver.cpp:218] Iteration 165000 (3.14896 iter/s, 31.7566s/100 iters), loss = 0.000138001
I0527 04:59:34.864655 30701 solver.cpp:237]     Train net output #0: loss = 0.000136105 (* 1 = 0.000136105 loss)
I0527 04:59:34.864663 30701 sgd_solver.cpp:105] Iteration 165000, lr = 0.00175
I0527 05:00:02.962410 30701 solver.cpp:218] Iteration 165100 (3.55908 iter/s, 28.0972s/100 iters), loss = 0.000528364
I0527 05:00:02.962463 30701 solver.cpp:237]     Train net output #0: loss = 0.000526467 (* 1 = 0.000526467 loss)
I0527 05:00:02.962476 30701 sgd_solver.cpp:105] Iteration 165100, lr = 0.001745
I0527 05:00:31.052701 30701 solver.cpp:218] Iteration 165200 (3.56003 iter/s, 28.0897s/100 iters), loss = 0.00049289
I0527 05:00:31.052932 30701 solver.cpp:237]     Train net output #0: loss = 0.000490994 (* 1 = 0.000490994 loss)
I0527 05:00:31.052948 30701 sgd_solver.cpp:105] Iteration 165200, lr = 0.00174
I0527 05:00:59.128592 30701 solver.cpp:218] Iteration 165300 (3.56188 iter/s, 28.0751s/100 iters), loss = 0.000733287
I0527 05:00:59.128636 30701 solver.cpp:237]     Train net output #0: loss = 0.00073139 (* 1 = 0.00073139 loss)
I0527 05:00:59.128645 30701 sgd_solver.cpp:105] Iteration 165300, lr = 0.001735
I0527 05:01:27.213624 30701 solver.cpp:218] Iteration 165400 (3.5607 iter/s, 28.0844s/100 iters), loss = 0.000524879
I0527 05:01:27.213783 30701 solver.cpp:237]     Train net output #0: loss = 0.000522982 (* 1 = 0.000522982 loss)
I0527 05:01:27.213793 30701 sgd_solver.cpp:105] Iteration 165400, lr = 0.00173
I0527 05:01:55.273977 30701 solver.cpp:218] Iteration 165500 (3.56384 iter/s, 28.0596s/100 iters), loss = 0.000565635
I0527 05:01:55.274022 30701 solver.cpp:237]     Train net output #0: loss = 0.000563738 (* 1 = 0.000563738 loss)
I0527 05:01:55.274030 30701 sgd_solver.cpp:105] Iteration 165500, lr = 0.001725
I0527 05:02:00.066373 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:02:23.343262 30701 solver.cpp:218] Iteration 165600 (3.56269 iter/s, 28.0686s/100 iters), loss = 0.000116439
I0527 05:02:23.343305 30701 solver.cpp:237]     Train net output #0: loss = 0.000114543 (* 1 = 0.000114543 loss)
I0527 05:02:23.343314 30701 sgd_solver.cpp:105] Iteration 165600, lr = 0.00172
I0527 05:02:51.459163 30701 solver.cpp:218] Iteration 165700 (3.55679 iter/s, 28.1153s/100 iters), loss = 0.000202711
I0527 05:02:51.459327 30701 solver.cpp:237]     Train net output #0: loss = 0.000200814 (* 1 = 0.000200814 loss)
I0527 05:02:51.459339 30701 sgd_solver.cpp:105] Iteration 165700, lr = 0.001715
I0527 05:03:19.536765 30701 solver.cpp:218] Iteration 165800 (3.56165 iter/s, 28.0768s/100 iters), loss = 0.00012137
I0527 05:03:19.536809 30701 solver.cpp:237]     Train net output #0: loss = 0.000119473 (* 1 = 0.000119473 loss)
I0527 05:03:19.536818 30701 sgd_solver.cpp:105] Iteration 165800, lr = 0.00171
I0527 05:03:47.619823 30701 solver.cpp:218] Iteration 165900 (3.56095 iter/s, 28.0824s/100 iters), loss = 0.00159801
I0527 05:03:47.619999 30701 solver.cpp:237]     Train net output #0: loss = 0.00159611 (* 1 = 0.00159611 loss)
I0527 05:03:47.620012 30701 sgd_solver.cpp:105] Iteration 165900, lr = 0.001705
I0527 05:04:15.458034 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_166000.caffemodel
I0527 05:04:15.959105 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_166000.solverstate
I0527 05:04:16.112949 30701 solver.cpp:330] Iteration 166000, Testing net (#0)
I0527 05:04:18.718688 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:04:19.072597 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 05:04:19.072649 30701 solver.cpp:397]     Test net output #1: loss = 0.657797 (* 1 = 0.657797 loss)
I0527 05:04:19.349953 30701 solver.cpp:218] Iteration 166000 (3.15166 iter/s, 31.7293s/100 iters), loss = 0.000151122
I0527 05:04:19.350002 30701 solver.cpp:237]     Train net output #0: loss = 0.000149225 (* 1 = 0.000149225 loss)
I0527 05:04:19.350010 30701 sgd_solver.cpp:105] Iteration 166000, lr = 0.0017
I0527 05:04:47.465528 30701 solver.cpp:218] Iteration 166100 (3.55683 iter/s, 28.1149s/100 iters), loss = 0.000182182
I0527 05:04:47.465576 30701 solver.cpp:237]     Train net output #0: loss = 0.000180286 (* 1 = 0.000180286 loss)
I0527 05:04:47.465585 30701 sgd_solver.cpp:105] Iteration 166100, lr = 0.001695
I0527 05:04:50.012441 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:05:15.571604 30701 solver.cpp:218] Iteration 166200 (3.55803 iter/s, 28.1054s/100 iters), loss = 0.000222202
I0527 05:05:15.571652 30701 solver.cpp:237]     Train net output #0: loss = 0.000220305 (* 1 = 0.000220305 loss)
I0527 05:05:15.571666 30701 sgd_solver.cpp:105] Iteration 166200, lr = 0.00169
I0527 05:05:43.687695 30701 solver.cpp:218] Iteration 166300 (3.55676 iter/s, 28.1154s/100 iters), loss = 0.000315369
I0527 05:05:43.687818 30701 solver.cpp:237]     Train net output #0: loss = 0.000313473 (* 1 = 0.000313473 loss)
I0527 05:05:43.687827 30701 sgd_solver.cpp:105] Iteration 166300, lr = 0.001685
I0527 05:06:11.810745 30701 solver.cpp:218] Iteration 166400 (3.55589 iter/s, 28.1223s/100 iters), loss = 0.000129936
I0527 05:06:11.810793 30701 solver.cpp:237]     Train net output #0: loss = 0.00012804 (* 1 = 0.00012804 loss)
I0527 05:06:11.810803 30701 sgd_solver.cpp:105] Iteration 166400, lr = 0.00168
I0527 05:06:39.931088 30701 solver.cpp:218] Iteration 166500 (3.55623 iter/s, 28.1197s/100 iters), loss = 0.000249703
I0527 05:06:39.931280 30701 solver.cpp:237]     Train net output #0: loss = 0.000247806 (* 1 = 0.000247806 loss)
I0527 05:06:39.931293 30701 sgd_solver.cpp:105] Iteration 166500, lr = 0.001675
I0527 05:07:08.057091 30701 solver.cpp:218] Iteration 166600 (3.55553 iter/s, 28.1252s/100 iters), loss = 0.000180723
I0527 05:07:08.057137 30701 solver.cpp:237]     Train net output #0: loss = 0.000178827 (* 1 = 0.000178827 loss)
I0527 05:07:08.057145 30701 sgd_solver.cpp:105] Iteration 166600, lr = 0.00167
I0527 05:07:36.199664 30701 solver.cpp:218] Iteration 166700 (3.55342 iter/s, 28.1419s/100 iters), loss = 0.000476103
I0527 05:07:36.199864 30701 solver.cpp:237]     Train net output #0: loss = 0.000474207 (* 1 = 0.000474207 loss)
I0527 05:07:36.199875 30701 sgd_solver.cpp:105] Iteration 166700, lr = 0.001665
I0527 05:07:36.217223 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:08:04.278316 30701 solver.cpp:218] Iteration 166800 (3.56153 iter/s, 28.0779s/100 iters), loss = 0.000340296
I0527 05:08:04.278360 30701 solver.cpp:237]     Train net output #0: loss = 0.0003384 (* 1 = 0.0003384 loss)
I0527 05:08:04.278368 30701 sgd_solver.cpp:105] Iteration 166800, lr = 0.00166
I0527 05:08:32.399325 30701 solver.cpp:218] Iteration 166900 (3.55614 iter/s, 28.1204s/100 iters), loss = 0.000171212
I0527 05:08:32.399484 30701 solver.cpp:237]     Train net output #0: loss = 0.000169316 (* 1 = 0.000169316 loss)
I0527 05:08:32.399497 30701 sgd_solver.cpp:105] Iteration 166900, lr = 0.001655
I0527 05:09:00.220454 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_167000.caffemodel
I0527 05:09:00.746296 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_167000.solverstate
I0527 05:09:00.900115 30701 solver.cpp:330] Iteration 167000, Testing net (#0)
I0527 05:09:03.854696 30701 solver.cpp:397]     Test net output #0: accuracy = 0.83
I0527 05:09:03.854956 30701 solver.cpp:397]     Test net output #1: loss = 0.906538 (* 1 = 0.906538 loss)
I0527 05:09:04.132906 30701 solver.cpp:218] Iteration 167000 (3.15132 iter/s, 31.7327s/100 iters), loss = 0.000397185
I0527 05:09:04.132952 30701 solver.cpp:237]     Train net output #0: loss = 0.000395289 (* 1 = 0.000395289 loss)
I0527 05:09:04.132961 30701 sgd_solver.cpp:105] Iteration 167000, lr = 0.00165
I0527 05:09:32.253882 30701 solver.cpp:218] Iteration 167100 (3.55615 iter/s, 28.1203s/100 iters), loss = 0.000171288
I0527 05:09:32.253929 30701 solver.cpp:237]     Train net output #0: loss = 0.000169392 (* 1 = 0.000169392 loss)
I0527 05:09:32.253937 30701 sgd_solver.cpp:105] Iteration 167100, lr = 0.001645
I0527 05:10:00.366533 30701 solver.cpp:218] Iteration 167200 (3.5572 iter/s, 28.112s/100 iters), loss = 0.00107302
I0527 05:10:00.366686 30701 solver.cpp:237]     Train net output #0: loss = 0.00107113 (* 1 = 0.00107113 loss)
I0527 05:10:00.366701 30701 sgd_solver.cpp:105] Iteration 167200, lr = 0.00164
I0527 05:10:25.979097 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:10:28.494508 30701 solver.cpp:218] Iteration 167300 (3.55528 iter/s, 28.1272s/100 iters), loss = 0.000216725
I0527 05:10:28.494554 30701 solver.cpp:237]     Train net output #0: loss = 0.000214828 (* 1 = 0.000214828 loss)
I0527 05:10:28.494561 30701 sgd_solver.cpp:105] Iteration 167300, lr = 0.001635
I0527 05:10:56.617595 30701 solver.cpp:218] Iteration 167400 (3.55588 iter/s, 28.1224s/100 iters), loss = 0.000226709
I0527 05:10:56.617755 30701 solver.cpp:237]     Train net output #0: loss = 0.000224813 (* 1 = 0.000224813 loss)
I0527 05:10:56.617768 30701 sgd_solver.cpp:105] Iteration 167400, lr = 0.00163
I0527 05:11:24.735491 30701 solver.cpp:218] Iteration 167500 (3.55655 iter/s, 28.1171s/100 iters), loss = 0.00141854
I0527 05:11:24.735538 30701 solver.cpp:237]     Train net output #0: loss = 0.00141664 (* 1 = 0.00141664 loss)
I0527 05:11:24.735545 30701 sgd_solver.cpp:105] Iteration 167500, lr = 0.001625
I0527 05:11:52.859357 30701 solver.cpp:218] Iteration 167600 (3.55578 iter/s, 28.1232s/100 iters), loss = 0.00200419
I0527 05:11:52.859532 30701 solver.cpp:237]     Train net output #0: loss = 0.0020023 (* 1 = 0.0020023 loss)
I0527 05:11:52.859560 30701 sgd_solver.cpp:105] Iteration 167600, lr = 0.00162
I0527 05:12:20.992986 30701 solver.cpp:218] Iteration 167700 (3.55456 iter/s, 28.1328s/100 iters), loss = 0.000376334
I0527 05:12:20.993031 30701 solver.cpp:237]     Train net output #0: loss = 0.000374438 (* 1 = 0.000374438 loss)
I0527 05:12:20.993043 30701 sgd_solver.cpp:105] Iteration 167700, lr = 0.001615
I0527 05:12:49.099663 30701 solver.cpp:218] Iteration 167800 (3.55796 iter/s, 28.106s/100 iters), loss = 0.00028125
I0527 05:12:49.099843 30701 solver.cpp:237]     Train net output #0: loss = 0.000279353 (* 1 = 0.000279353 loss)
I0527 05:12:49.099854 30701 sgd_solver.cpp:105] Iteration 167800, lr = 0.00161
I0527 05:13:12.174443 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:13:17.220798 30701 solver.cpp:218] Iteration 167900 (3.55614 iter/s, 28.1203s/100 iters), loss = 0.00013931
I0527 05:13:17.220839 30701 solver.cpp:237]     Train net output #0: loss = 0.000137413 (* 1 = 0.000137413 loss)
I0527 05:13:17.220847 30701 sgd_solver.cpp:105] Iteration 167900, lr = 0.001605
I0527 05:13:45.069882 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_168000.caffemodel
I0527 05:13:45.526479 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_168000.solverstate
I0527 05:13:45.679806 30701 solver.cpp:330] Iteration 168000, Testing net (#0)
I0527 05:13:48.636704 30701 solver.cpp:397]     Test net output #0: accuracy = 0.798
I0527 05:13:48.636740 30701 solver.cpp:397]     Test net output #1: loss = 0.870571 (* 1 = 0.870571 loss)
I0527 05:13:48.914038 30701 solver.cpp:218] Iteration 168000 (3.15532 iter/s, 31.6925s/100 iters), loss = 0.00100419
I0527 05:13:48.914083 30701 solver.cpp:237]     Train net output #0: loss = 0.0010023 (* 1 = 0.0010023 loss)
I0527 05:13:48.914091 30701 sgd_solver.cpp:105] Iteration 168000, lr = 0.0016
I0527 05:14:17.011555 30701 solver.cpp:218] Iteration 168100 (3.55912 iter/s, 28.0969s/100 iters), loss = 6.86431e-05
I0527 05:14:17.011754 30701 solver.cpp:237]     Train net output #0: loss = 6.67461e-05 (* 1 = 6.67461e-05 loss)
I0527 05:14:17.011766 30701 sgd_solver.cpp:105] Iteration 168100, lr = 0.001595
I0527 05:14:45.105654 30701 solver.cpp:218] Iteration 168200 (3.55957 iter/s, 28.0933s/100 iters), loss = 0.000212906
I0527 05:14:45.105696 30701 solver.cpp:237]     Train net output #0: loss = 0.000211009 (* 1 = 0.000211009 loss)
I0527 05:14:45.105705 30701 sgd_solver.cpp:105] Iteration 168200, lr = 0.00159
I0527 05:15:13.205428 30701 solver.cpp:218] Iteration 168300 (3.55883 iter/s, 28.0991s/100 iters), loss = 0.000522599
I0527 05:15:13.205647 30701 solver.cpp:237]     Train net output #0: loss = 0.000520702 (* 1 = 0.000520702 loss)
I0527 05:15:13.205658 30701 sgd_solver.cpp:105] Iteration 168300, lr = 0.001585
I0527 05:15:41.298930 30701 solver.cpp:218] Iteration 168400 (3.55965 iter/s, 28.0927s/100 iters), loss = 0.000414144
I0527 05:15:41.298979 30701 solver.cpp:237]     Train net output #0: loss = 0.000412247 (* 1 = 0.000412247 loss)
I0527 05:15:41.298987 30701 sgd_solver.cpp:105] Iteration 168400, lr = 0.00158
I0527 05:16:01.829886 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:16:09.389168 30701 solver.cpp:218] Iteration 168500 (3.56004 iter/s, 28.0896s/100 iters), loss = 0.000261397
I0527 05:16:09.389212 30701 solver.cpp:237]     Train net output #0: loss = 0.0002595 (* 1 = 0.0002595 loss)
I0527 05:16:09.389220 30701 sgd_solver.cpp:105] Iteration 168500, lr = 0.001575
I0527 05:16:37.470199 30701 solver.cpp:218] Iteration 168600 (3.56121 iter/s, 28.0804s/100 iters), loss = 0.000399602
I0527 05:16:37.470404 30701 solver.cpp:237]     Train net output #0: loss = 0.000397704 (* 1 = 0.000397704 loss)
I0527 05:16:37.470417 30701 sgd_solver.cpp:105] Iteration 168600, lr = 0.00157
I0527 05:17:05.547579 30701 solver.cpp:218] Iteration 168700 (3.56169 iter/s, 28.0766s/100 iters), loss = 0.00029859
I0527 05:17:05.547624 30701 solver.cpp:237]     Train net output #0: loss = 0.000296693 (* 1 = 0.000296693 loss)
I0527 05:17:05.547632 30701 sgd_solver.cpp:105] Iteration 168700, lr = 0.001565
I0527 05:17:33.613931 30701 solver.cpp:218] Iteration 168800 (3.56307 iter/s, 28.0657s/100 iters), loss = 0.000646935
I0527 05:17:33.614087 30701 solver.cpp:237]     Train net output #0: loss = 0.000645038 (* 1 = 0.000645038 loss)
I0527 05:17:33.614099 30701 sgd_solver.cpp:105] Iteration 168800, lr = 0.00156
I0527 05:18:01.669667 30701 solver.cpp:218] Iteration 168900 (3.56443 iter/s, 28.055s/100 iters), loss = 9.28167e-05
I0527 05:18:01.669714 30701 solver.cpp:237]     Train net output #0: loss = 9.09196e-05 (* 1 = 9.09196e-05 loss)
I0527 05:18:01.669723 30701 sgd_solver.cpp:105] Iteration 168900, lr = 0.001555
I0527 05:18:29.457705 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_169000.caffemodel
I0527 05:18:29.812386 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_169000.solverstate
I0527 05:18:29.964844 30701 solver.cpp:330] Iteration 169000, Testing net (#0)
I0527 05:18:31.298496 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:18:32.923938 30701 solver.cpp:397]     Test net output #0: accuracy = 0.85
I0527 05:18:32.923993 30701 solver.cpp:397]     Test net output #1: loss = 0.703389 (* 1 = 0.703389 loss)
I0527 05:18:33.201943 30701 solver.cpp:218] Iteration 169000 (3.17143 iter/s, 31.5315s/100 iters), loss = 0.000121247
I0527 05:18:33.201992 30701 solver.cpp:237]     Train net output #0: loss = 0.00011935 (* 1 = 0.00011935 loss)
I0527 05:18:33.202000 30701 sgd_solver.cpp:105] Iteration 169000, lr = 0.00155
I0527 05:18:51.217270 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:19:01.333178 30701 solver.cpp:218] Iteration 169100 (3.55485 iter/s, 28.1306s/100 iters), loss = 0.000313092
I0527 05:19:01.333344 30701 solver.cpp:237]     Train net output #0: loss = 0.000311195 (* 1 = 0.000311195 loss)
I0527 05:19:01.333355 30701 sgd_solver.cpp:105] Iteration 169100, lr = 0.001545
I0527 05:19:29.472795 30701 solver.cpp:218] Iteration 169200 (3.55381 iter/s, 28.1388s/100 iters), loss = 0.000771742
I0527 05:19:29.472852 30701 solver.cpp:237]     Train net output #0: loss = 0.000769845 (* 1 = 0.000769845 loss)
I0527 05:19:29.472862 30701 sgd_solver.cpp:105] Iteration 169200, lr = 0.00154
I0527 05:19:57.609894 30701 solver.cpp:218] Iteration 169300 (3.55411 iter/s, 28.1364s/100 iters), loss = 0.000405608
I0527 05:19:57.610065 30701 solver.cpp:237]     Train net output #0: loss = 0.00040371 (* 1 = 0.00040371 loss)
I0527 05:19:57.610077 30701 sgd_solver.cpp:105] Iteration 169300, lr = 0.001535
I0527 05:20:25.749560 30701 solver.cpp:218] Iteration 169400 (3.5538 iter/s, 28.1389s/100 iters), loss = 9.6398e-05
I0527 05:20:25.749620 30701 solver.cpp:237]     Train net output #0: loss = 9.44994e-05 (* 1 = 9.44994e-05 loss)
I0527 05:20:25.749629 30701 sgd_solver.cpp:105] Iteration 169400, lr = 0.00153
I0527 05:20:53.879092 30701 solver.cpp:218] Iteration 169500 (3.55507 iter/s, 28.1289s/100 iters), loss = 7.71671e-05
I0527 05:20:53.879202 30701 solver.cpp:237]     Train net output #0: loss = 7.52679e-05 (* 1 = 7.52679e-05 loss)
I0527 05:20:53.879223 30701 sgd_solver.cpp:105] Iteration 169500, lr = 0.001525
I0527 05:21:22.028987 30701 solver.cpp:218] Iteration 169600 (3.5525 iter/s, 28.1492s/100 iters), loss = 0.000194369
I0527 05:21:22.029042 30701 solver.cpp:237]     Train net output #0: loss = 0.00019247 (* 1 = 0.00019247 loss)
I0527 05:21:22.029052 30701 sgd_solver.cpp:105] Iteration 169600, lr = 0.00152
I0527 05:21:37.795941 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:21:50.142427 30701 solver.cpp:218] Iteration 169700 (3.5571 iter/s, 28.1128s/100 iters), loss = 0.000237439
I0527 05:21:50.142472 30701 solver.cpp:237]     Train net output #0: loss = 0.00023554 (* 1 = 0.00023554 loss)
I0527 05:21:50.142480 30701 sgd_solver.cpp:105] Iteration 169700, lr = 0.001515
I0527 05:22:18.232796 30701 solver.cpp:218] Iteration 169800 (3.56 iter/s, 28.0899s/100 iters), loss = 0.00161241
I0527 05:22:18.232964 30701 solver.cpp:237]     Train net output #0: loss = 0.00161051 (* 1 = 0.00161051 loss)
I0527 05:22:18.232975 30701 sgd_solver.cpp:105] Iteration 169800, lr = 0.00151
I0527 05:22:46.324079 30701 solver.cpp:218] Iteration 169900 (3.5599 iter/s, 28.0907s/100 iters), loss = 0.000129223
I0527 05:22:46.324123 30701 solver.cpp:237]     Train net output #0: loss = 0.000127324 (* 1 = 0.000127324 loss)
I0527 05:22:46.324132 30701 sgd_solver.cpp:105] Iteration 169900, lr = 0.001505
I0527 05:23:14.148968 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_170000.caffemodel
I0527 05:23:14.521232 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_170000.solverstate
I0527 05:23:14.671792 30701 solver.cpp:330] Iteration 170000, Testing net (#0)
I0527 05:23:17.628439 30701 solver.cpp:397]     Test net output #0: accuracy = 0.82
I0527 05:23:17.628489 30701 solver.cpp:397]     Test net output #1: loss = 0.854115 (* 1 = 0.854115 loss)
I0527 05:23:17.905668 30701 solver.cpp:218] Iteration 170000 (3.16646 iter/s, 31.581s/100 iters), loss = 0.000661424
I0527 05:23:17.905717 30701 solver.cpp:237]     Train net output #0: loss = 0.000659525 (* 1 = 0.000659525 loss)
I0527 05:23:17.905728 30701 sgd_solver.cpp:105] Iteration 170000, lr = 0.0015
I0527 05:23:45.985111 30701 solver.cpp:218] Iteration 170100 (3.56139 iter/s, 28.0789s/100 iters), loss = 0.000134922
I0527 05:23:45.985317 30701 solver.cpp:237]     Train net output #0: loss = 0.000133023 (* 1 = 0.000133023 loss)
I0527 05:23:45.985335 30701 sgd_solver.cpp:105] Iteration 170100, lr = 0.001495
I0527 05:24:14.081867 30701 solver.cpp:218] Iteration 170200 (3.55921 iter/s, 28.0961s/100 iters), loss = 0.000328452
I0527 05:24:14.081918 30701 solver.cpp:237]     Train net output #0: loss = 0.000326553 (* 1 = 0.000326553 loss)
I0527 05:24:14.081926 30701 sgd_solver.cpp:105] Iteration 170200, lr = 0.00149
I0527 05:24:27.294394 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:24:42.150171 30701 solver.cpp:218] Iteration 170300 (3.5628 iter/s, 28.0678s/100 iters), loss = 0.000204055
I0527 05:24:42.150213 30701 solver.cpp:237]     Train net output #0: loss = 0.000202156 (* 1 = 0.000202156 loss)
I0527 05:24:42.150223 30701 sgd_solver.cpp:105] Iteration 170300, lr = 0.001485
I0527 05:25:10.194784 30701 solver.cpp:218] Iteration 170400 (3.56581 iter/s, 28.0441s/100 iters), loss = 0.000122893
I0527 05:25:10.194948 30701 solver.cpp:237]     Train net output #0: loss = 0.000120994 (* 1 = 0.000120994 loss)
I0527 05:25:10.194959 30701 sgd_solver.cpp:105] Iteration 170400, lr = 0.00148
I0527 05:25:38.279455 30701 solver.cpp:218] Iteration 170500 (3.56074 iter/s, 28.084s/100 iters), loss = 0.000506837
I0527 05:25:38.279503 30701 solver.cpp:237]     Train net output #0: loss = 0.000504937 (* 1 = 0.000504937 loss)
I0527 05:25:38.279511 30701 sgd_solver.cpp:105] Iteration 170500, lr = 0.001475
I0527 05:26:06.348170 30701 solver.cpp:218] Iteration 170600 (3.56275 iter/s, 28.0682s/100 iters), loss = 0.000186409
I0527 05:26:06.348387 30701 solver.cpp:237]     Train net output #0: loss = 0.000184509 (* 1 = 0.000184509 loss)
I0527 05:26:06.348399 30701 sgd_solver.cpp:105] Iteration 170600, lr = 0.00147
I0527 05:26:34.413449 30701 solver.cpp:218] Iteration 170700 (3.56321 iter/s, 28.0646s/100 iters), loss = 0.000471369
I0527 05:26:34.413493 30701 solver.cpp:237]     Train net output #0: loss = 0.000469469 (* 1 = 0.000469469 loss)
I0527 05:26:34.413502 30701 sgd_solver.cpp:105] Iteration 170700, lr = 0.001465
I0527 05:27:02.488365 30701 solver.cpp:218] Iteration 170800 (3.56197 iter/s, 28.0744s/100 iters), loss = 0.000573215
I0527 05:27:02.488564 30701 solver.cpp:237]     Train net output #0: loss = 0.000571316 (* 1 = 0.000571316 loss)
I0527 05:27:02.488574 30701 sgd_solver.cpp:105] Iteration 170800, lr = 0.00146
I0527 05:27:13.173955 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:27:30.600360 30701 solver.cpp:218] Iteration 170900 (3.55729 iter/s, 28.1113s/100 iters), loss = 0.000489426
I0527 05:27:30.600404 30701 solver.cpp:237]     Train net output #0: loss = 0.000487526 (* 1 = 0.000487526 loss)
I0527 05:27:30.600412 30701 sgd_solver.cpp:105] Iteration 170900, lr = 0.001455
I0527 05:27:58.443395 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_171000.caffemodel
I0527 05:27:58.756886 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_171000.solverstate
I0527 05:27:58.907649 30701 solver.cpp:330] Iteration 171000, Testing net (#0)
I0527 05:28:01.865559 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 05:28:01.865608 30701 solver.cpp:397]     Test net output #1: loss = 0.750018 (* 1 = 0.750018 loss)
I0527 05:28:02.144177 30701 solver.cpp:218] Iteration 171000 (3.17026 iter/s, 31.5432s/100 iters), loss = 0.000137198
I0527 05:28:02.144220 30701 solver.cpp:237]     Train net output #0: loss = 0.000135298 (* 1 = 0.000135298 loss)
I0527 05:28:02.144229 30701 sgd_solver.cpp:105] Iteration 171000, lr = 0.00145
I0527 05:28:30.251741 30701 solver.cpp:218] Iteration 171100 (3.55783 iter/s, 28.107s/100 iters), loss = 0.000183797
I0527 05:28:30.251935 30701 solver.cpp:237]     Train net output #0: loss = 0.000181898 (* 1 = 0.000181898 loss)
I0527 05:28:30.251976 30701 sgd_solver.cpp:105] Iteration 171100, lr = 0.001445
I0527 05:28:58.349918 30701 solver.cpp:218] Iteration 171200 (3.55904 iter/s, 28.0975s/100 iters), loss = 0.000895762
I0527 05:28:58.349964 30701 solver.cpp:237]     Train net output #0: loss = 0.000893862 (* 1 = 0.000893862 loss)
I0527 05:28:58.349972 30701 sgd_solver.cpp:105] Iteration 171200, lr = 0.00144
I0527 05:29:26.447949 30701 solver.cpp:218] Iteration 171300 (3.55904 iter/s, 28.0975s/100 iters), loss = 0.00103963
I0527 05:29:26.448135 30701 solver.cpp:237]     Train net output #0: loss = 0.00103773 (* 1 = 0.00103773 loss)
I0527 05:29:26.448163 30701 sgd_solver.cpp:105] Iteration 171300, lr = 0.001435
I0527 05:29:54.540637 30701 solver.cpp:218] Iteration 171400 (3.55973 iter/s, 28.092s/100 iters), loss = 0.00011577
I0527 05:29:54.540680 30701 solver.cpp:237]     Train net output #0: loss = 0.00011387 (* 1 = 0.00011387 loss)
I0527 05:29:54.540688 30701 sgd_solver.cpp:105] Iteration 171400, lr = 0.00143
I0527 05:30:02.709836 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:30:22.623886 30701 solver.cpp:218] Iteration 171500 (3.56092 iter/s, 28.0827s/100 iters), loss = 0.000135259
I0527 05:30:22.623946 30701 solver.cpp:237]     Train net output #0: loss = 0.000133359 (* 1 = 0.000133359 loss)
I0527 05:30:22.623961 30701 sgd_solver.cpp:105] Iteration 171500, lr = 0.001425
I0527 05:30:50.688803 30701 solver.cpp:218] Iteration 171600 (3.56324 iter/s, 28.0643s/100 iters), loss = 0.000207627
I0527 05:30:50.688978 30701 solver.cpp:237]     Train net output #0: loss = 0.000205728 (* 1 = 0.000205728 loss)
I0527 05:30:50.688990 30701 sgd_solver.cpp:105] Iteration 171600, lr = 0.00142
I0527 05:31:18.764669 30701 solver.cpp:218] Iteration 171700 (3.56187 iter/s, 28.0752s/100 iters), loss = 0.000114893
I0527 05:31:18.764711 30701 solver.cpp:237]     Train net output #0: loss = 0.000112994 (* 1 = 0.000112994 loss)
I0527 05:31:18.764720 30701 sgd_solver.cpp:105] Iteration 171700, lr = 0.001415
I0527 05:31:46.834713 30701 solver.cpp:218] Iteration 171800 (3.56259 iter/s, 28.0695s/100 iters), loss = 8.42488e-05
I0527 05:31:46.834940 30701 solver.cpp:237]     Train net output #0: loss = 8.2349e-05 (* 1 = 8.2349e-05 loss)
I0527 05:31:46.834952 30701 sgd_solver.cpp:105] Iteration 171800, lr = 0.00141
I0527 05:32:14.953374 30701 solver.cpp:218] Iteration 171900 (3.55645 iter/s, 28.1179s/100 iters), loss = 0.000557695
I0527 05:32:14.953419 30701 solver.cpp:237]     Train net output #0: loss = 0.000555796 (* 1 = 0.000555796 loss)
I0527 05:32:14.953428 30701 sgd_solver.cpp:105] Iteration 171900, lr = 0.001405
I0527 05:32:42.757113 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_172000.caffemodel
I0527 05:32:43.069815 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_172000.solverstate
I0527 05:32:43.221480 30701 solver.cpp:330] Iteration 172000, Testing net (#0)
I0527 05:32:43.285280 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:32:46.177553 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 05:32:46.177599 30701 solver.cpp:397]     Test net output #1: loss = 0.836752 (* 1 = 0.836752 loss)
I0527 05:32:46.456357 30701 solver.cpp:218] Iteration 172000 (3.17437 iter/s, 31.5023s/100 iters), loss = 0.000163104
I0527 05:32:46.456403 30701 solver.cpp:237]     Train net output #0: loss = 0.000161205 (* 1 = 0.000161205 loss)
I0527 05:32:46.456413 30701 sgd_solver.cpp:105] Iteration 172000, lr = 0.0014
I0527 05:32:52.097915 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:33:14.577973 30701 solver.cpp:218] Iteration 172100 (3.55606 iter/s, 28.121s/100 iters), loss = 0.000225259
I0527 05:33:14.578157 30701 solver.cpp:237]     Train net output #0: loss = 0.000223359 (* 1 = 0.000223359 loss)
I0527 05:33:14.578168 30701 sgd_solver.cpp:105] Iteration 172100, lr = 0.001395
I0527 05:33:42.689661 30701 solver.cpp:218] Iteration 172200 (3.55733 iter/s, 28.111s/100 iters), loss = 0.000191632
I0527 05:33:42.689719 30701 solver.cpp:237]     Train net output #0: loss = 0.000189732 (* 1 = 0.000189732 loss)
I0527 05:33:42.689728 30701 sgd_solver.cpp:105] Iteration 172200, lr = 0.00139
I0527 05:34:10.800073 30701 solver.cpp:218] Iteration 172300 (3.55748 iter/s, 28.1098s/100 iters), loss = 0.00118853
I0527 05:34:10.800249 30701 solver.cpp:237]     Train net output #0: loss = 0.00118663 (* 1 = 0.00118663 loss)
I0527 05:34:10.800262 30701 sgd_solver.cpp:105] Iteration 172300, lr = 0.001385
I0527 05:34:38.922441 30701 solver.cpp:218] Iteration 172400 (3.55598 iter/s, 28.1216s/100 iters), loss = 0.000118346
I0527 05:34:38.922487 30701 solver.cpp:237]     Train net output #0: loss = 0.000116446 (* 1 = 0.000116446 loss)
I0527 05:34:38.922494 30701 sgd_solver.cpp:105] Iteration 172400, lr = 0.00138
I0527 05:35:07.046360 30701 solver.cpp:218] Iteration 172500 (3.55577 iter/s, 28.1233s/100 iters), loss = 0.000124214
I0527 05:35:07.046515 30701 solver.cpp:237]     Train net output #0: loss = 0.000122314 (* 1 = 0.000122314 loss)
I0527 05:35:07.046527 30701 sgd_solver.cpp:105] Iteration 172500, lr = 0.001375
I0527 05:35:35.149873 30701 solver.cpp:218] Iteration 172600 (3.55836 iter/s, 28.1028s/100 iters), loss = 0.000313061
I0527 05:35:35.149917 30701 solver.cpp:237]     Train net output #0: loss = 0.000311161 (* 1 = 0.000311161 loss)
I0527 05:35:35.149926 30701 sgd_solver.cpp:105] Iteration 172600, lr = 0.00137
I0527 05:35:38.262008 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:36:03.246702 30701 solver.cpp:218] Iteration 172700 (3.5592 iter/s, 28.0962s/100 iters), loss = 0.000278576
I0527 05:36:03.246747 30701 solver.cpp:237]     Train net output #0: loss = 0.000276676 (* 1 = 0.000276676 loss)
I0527 05:36:03.246757 30701 sgd_solver.cpp:105] Iteration 172700, lr = 0.001365
I0527 05:36:31.300340 30701 solver.cpp:218] Iteration 172800 (3.56468 iter/s, 28.053s/100 iters), loss = 0.000730555
I0527 05:36:31.300554 30701 solver.cpp:237]     Train net output #0: loss = 0.000728656 (* 1 = 0.000728656 loss)
I0527 05:36:31.300571 30701 sgd_solver.cpp:105] Iteration 172800, lr = 0.00136
I0527 05:36:59.351039 30701 solver.cpp:218] Iteration 172900 (3.56507 iter/s, 28.0499s/100 iters), loss = 0.00035645
I0527 05:36:59.351104 30701 solver.cpp:237]     Train net output #0: loss = 0.00035455 (* 1 = 0.00035455 loss)
I0527 05:36:59.351116 30701 sgd_solver.cpp:105] Iteration 172900, lr = 0.001355
I0527 05:37:27.161474 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_173000.caffemodel
I0527 05:37:27.476943 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_173000.solverstate
I0527 05:37:27.629041 30701 solver.cpp:330] Iteration 173000, Testing net (#0)
I0527 05:37:30.586434 30701 solver.cpp:397]     Test net output #0: accuracy = 0.804
I0527 05:37:30.586474 30701 solver.cpp:397]     Test net output #1: loss = 0.860674 (* 1 = 0.860674 loss)
I0527 05:37:30.863637 30701 solver.cpp:218] Iteration 173000 (3.1734 iter/s, 31.5119s/100 iters), loss = 0.000855867
I0527 05:37:30.863687 30701 solver.cpp:237]     Train net output #0: loss = 0.000853967 (* 1 = 0.000853967 loss)
I0527 05:37:30.863695 30701 sgd_solver.cpp:105] Iteration 173000, lr = 0.00135
I0527 05:37:58.946940 30701 solver.cpp:218] Iteration 173100 (3.56091 iter/s, 28.0827s/100 iters), loss = 0.000483404
I0527 05:37:58.947100 30701 solver.cpp:237]     Train net output #0: loss = 0.000481505 (* 1 = 0.000481505 loss)
I0527 05:37:58.947113 30701 sgd_solver.cpp:105] Iteration 173100, lr = 0.001345
I0527 05:38:27.046926 30701 solver.cpp:218] Iteration 173200 (3.55881 iter/s, 28.0993s/100 iters), loss = 0.000509364
I0527 05:38:27.046969 30701 solver.cpp:237]     Train net output #0: loss = 0.000507464 (* 1 = 0.000507464 loss)
I0527 05:38:27.046977 30701 sgd_solver.cpp:105] Iteration 173200, lr = 0.00134
I0527 05:38:27.631098 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:38:55.133335 30701 solver.cpp:218] Iteration 173300 (3.56052 iter/s, 28.0858s/100 iters), loss = 9.02028e-05
I0527 05:38:55.133514 30701 solver.cpp:237]     Train net output #0: loss = 8.83027e-05 (* 1 = 8.83027e-05 loss)
I0527 05:38:55.133527 30701 sgd_solver.cpp:105] Iteration 173300, lr = 0.001335
I0527 05:39:23.217584 30701 solver.cpp:218] Iteration 173400 (3.56081 iter/s, 28.0835s/100 iters), loss = 0.0160733
I0527 05:39:23.217633 30701 solver.cpp:237]     Train net output #0: loss = 0.0160714 (* 1 = 0.0160714 loss)
I0527 05:39:23.217641 30701 sgd_solver.cpp:105] Iteration 173400, lr = 0.00133
I0527 05:39:51.305619 30701 solver.cpp:218] Iteration 173500 (3.56031 iter/s, 28.0874s/100 iters), loss = 0.000150153
I0527 05:39:51.305820 30701 solver.cpp:237]     Train net output #0: loss = 0.000148253 (* 1 = 0.000148253 loss)
I0527 05:39:51.305835 30701 sgd_solver.cpp:105] Iteration 173500, lr = 0.001325
I0527 05:40:19.363045 30701 solver.cpp:218] Iteration 173600 (3.56421 iter/s, 28.0567s/100 iters), loss = 0.000429261
I0527 05:40:19.363095 30701 solver.cpp:237]     Train net output #0: loss = 0.000427361 (* 1 = 0.000427361 loss)
I0527 05:40:19.363108 30701 sgd_solver.cpp:105] Iteration 173600, lr = 0.00132
I0527 05:40:47.445685 30701 solver.cpp:218] Iteration 173700 (3.561 iter/s, 28.082s/100 iters), loss = 0.000119911
I0527 05:40:47.446010 30701 solver.cpp:237]     Train net output #0: loss = 0.000118012 (* 1 = 0.000118012 loss)
I0527 05:40:47.446027 30701 sgd_solver.cpp:105] Iteration 173700, lr = 0.001315
I0527 05:41:13.858129 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:41:15.529809 30701 solver.cpp:218] Iteration 173800 (3.56084 iter/s, 28.0832s/100 iters), loss = 0.000117046
I0527 05:41:15.529857 30701 solver.cpp:237]     Train net output #0: loss = 0.000115147 (* 1 = 0.000115147 loss)
I0527 05:41:15.529865 30701 sgd_solver.cpp:105] Iteration 173800, lr = 0.00131
I0527 05:41:43.605573 30701 solver.cpp:218] Iteration 173900 (3.56187 iter/s, 28.0751s/100 iters), loss = 0.000530655
I0527 05:41:43.606176 30701 solver.cpp:237]     Train net output #0: loss = 0.000528756 (* 1 = 0.000528756 loss)
I0527 05:41:43.606189 30701 sgd_solver.cpp:105] Iteration 173900, lr = 0.001305
I0527 05:42:11.413988 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_174000.caffemodel
I0527 05:42:11.728330 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_174000.solverstate
I0527 05:42:11.878424 30701 solver.cpp:330] Iteration 174000, Testing net (#0)
I0527 05:42:13.627188 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:42:14.837218 30701 solver.cpp:397]     Test net output #0: accuracy = 0.832
I0527 05:42:14.837266 30701 solver.cpp:397]     Test net output #1: loss = 0.745983 (* 1 = 0.745983 loss)
I0527 05:42:15.114312 30701 solver.cpp:218] Iteration 174000 (3.17385 iter/s, 31.5075s/100 iters), loss = 0.000223709
I0527 05:42:15.114358 30701 solver.cpp:237]     Train net output #0: loss = 0.00022181 (* 1 = 0.00022181 loss)
I0527 05:42:15.114367 30701 sgd_solver.cpp:105] Iteration 174000, lr = 0.0013
I0527 05:42:43.201676 30701 solver.cpp:218] Iteration 174100 (3.5604 iter/s, 28.0867s/100 iters), loss = 0.000401865
I0527 05:42:43.201719 30701 solver.cpp:237]     Train net output #0: loss = 0.000399966 (* 1 = 0.000399966 loss)
I0527 05:42:43.201727 30701 sgd_solver.cpp:105] Iteration 174100, lr = 0.001295
I0527 05:43:11.298643 30701 solver.cpp:218] Iteration 174200 (3.55918 iter/s, 28.0963s/100 iters), loss = 0.000557306
I0527 05:43:11.298851 30701 solver.cpp:237]     Train net output #0: loss = 0.000555406 (* 1 = 0.000555406 loss)
I0527 05:43:11.298868 30701 sgd_solver.cpp:105] Iteration 174200, lr = 0.00129
I0527 05:43:39.384181 30701 solver.cpp:218] Iteration 174300 (3.56065 iter/s, 28.0847s/100 iters), loss = 0.000936279
I0527 05:43:39.384230 30701 solver.cpp:237]     Train net output #0: loss = 0.000934379 (* 1 = 0.000934379 loss)
I0527 05:43:39.384244 30701 sgd_solver.cpp:105] Iteration 174300, lr = 0.001285
I0527 05:44:03.255703 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:44:07.444514 30701 solver.cpp:218] Iteration 174400 (3.56383 iter/s, 28.0597s/100 iters), loss = 0.000247876
I0527 05:44:07.444557 30701 solver.cpp:237]     Train net output #0: loss = 0.000245977 (* 1 = 0.000245977 loss)
I0527 05:44:07.444566 30701 sgd_solver.cpp:105] Iteration 174400, lr = 0.00128
I0527 05:44:35.509357 30701 solver.cpp:218] Iteration 174500 (3.56326 iter/s, 28.0642s/100 iters), loss = 0.000203897
I0527 05:44:35.509574 30701 solver.cpp:237]     Train net output #0: loss = 0.000201997 (* 1 = 0.000201997 loss)
I0527 05:44:35.509585 30701 sgd_solver.cpp:105] Iteration 174500, lr = 0.001275
I0527 05:45:03.589536 30701 solver.cpp:218] Iteration 174600 (3.56133 iter/s, 28.0794s/100 iters), loss = 0.000254539
I0527 05:45:03.589584 30701 solver.cpp:237]     Train net output #0: loss = 0.000252639 (* 1 = 0.000252639 loss)
I0527 05:45:03.589596 30701 sgd_solver.cpp:105] Iteration 174600, lr = 0.00127
I0527 05:45:31.680299 30701 solver.cpp:218] Iteration 174700 (3.55997 iter/s, 28.0901s/100 iters), loss = 0.000456299
I0527 05:45:31.680465 30701 solver.cpp:237]     Train net output #0: loss = 0.000454399 (* 1 = 0.000454399 loss)
I0527 05:45:31.680480 30701 sgd_solver.cpp:105] Iteration 174700, lr = 0.001265
I0527 05:45:59.762259 30701 solver.cpp:218] Iteration 174800 (3.5611 iter/s, 28.0812s/100 iters), loss = 0.000325739
I0527 05:45:59.762302 30701 solver.cpp:237]     Train net output #0: loss = 0.00032384 (* 1 = 0.00032384 loss)
I0527 05:45:59.762311 30701 sgd_solver.cpp:105] Iteration 174800, lr = 0.00126
I0527 05:46:27.837003 30701 solver.cpp:218] Iteration 174900 (3.562 iter/s, 28.0741s/100 iters), loss = 0.00048033
I0527 05:46:27.837229 30701 solver.cpp:237]     Train net output #0: loss = 0.00047843 (* 1 = 0.00047843 loss)
I0527 05:46:27.837242 30701 sgd_solver.cpp:105] Iteration 174900, lr = 0.001255
I0527 05:46:49.187027 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:46:55.629979 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_175000.caffemodel
I0527 05:46:55.942570 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_175000.solverstate
I0527 05:46:56.093305 30701 solver.cpp:330] Iteration 175000, Testing net (#0)
I0527 05:46:59.056686 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 05:46:59.056844 30701 solver.cpp:397]     Test net output #1: loss = 0.817005 (* 1 = 0.817005 loss)
I0527 05:46:59.333740 30701 solver.cpp:218] Iteration 175000 (3.17502 iter/s, 31.4959s/100 iters), loss = 0.000153471
I0527 05:46:59.333786 30701 solver.cpp:237]     Train net output #0: loss = 0.000151572 (* 1 = 0.000151572 loss)
I0527 05:46:59.333793 30701 sgd_solver.cpp:105] Iteration 175000, lr = 0.00125
I0527 05:47:27.411185 30701 solver.cpp:218] Iteration 175100 (3.56166 iter/s, 28.0768s/100 iters), loss = 0.000118732
I0527 05:47:27.411231 30701 solver.cpp:237]     Train net output #0: loss = 0.000116832 (* 1 = 0.000116832 loss)
I0527 05:47:27.411238 30701 sgd_solver.cpp:105] Iteration 175100, lr = 0.001245
I0527 05:47:55.485416 30701 solver.cpp:218] Iteration 175200 (3.56207 iter/s, 28.0736s/100 iters), loss = 0.000662376
I0527 05:47:55.485611 30701 solver.cpp:237]     Train net output #0: loss = 0.000660477 (* 1 = 0.000660477 loss)
I0527 05:47:55.485623 30701 sgd_solver.cpp:105] Iteration 175200, lr = 0.00124
I0527 05:48:23.599247 30701 solver.cpp:218] Iteration 175300 (3.55707 iter/s, 28.1131s/100 iters), loss = 0.00052942
I0527 05:48:23.599292 30701 solver.cpp:237]     Train net output #0: loss = 0.00052752 (* 1 = 0.00052752 loss)
I0527 05:48:23.599301 30701 sgd_solver.cpp:105] Iteration 175300, lr = 0.001235
I0527 05:48:51.674872 30701 solver.cpp:218] Iteration 175400 (3.56189 iter/s, 28.075s/100 iters), loss = 0.00147213
I0527 05:48:51.675045 30701 solver.cpp:237]     Train net output #0: loss = 0.00147023 (* 1 = 0.00147023 loss)
I0527 05:48:51.675057 30701 sgd_solver.cpp:105] Iteration 175400, lr = 0.00123
I0527 05:49:19.740458 30701 solver.cpp:218] Iteration 175500 (3.56318 iter/s, 28.0648s/100 iters), loss = 0.00010401
I0527 05:49:19.740504 30701 solver.cpp:237]     Train net output #0: loss = 0.00010211 (* 1 = 0.00010211 loss)
I0527 05:49:19.740512 30701 sgd_solver.cpp:105] Iteration 175500, lr = 0.001225
I0527 05:49:38.580900 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:49:47.834084 30701 solver.cpp:218] Iteration 175600 (3.55961 iter/s, 28.093s/100 iters), loss = 0.000231141
I0527 05:49:47.834130 30701 solver.cpp:237]     Train net output #0: loss = 0.000229241 (* 1 = 0.000229241 loss)
I0527 05:49:47.834138 30701 sgd_solver.cpp:105] Iteration 175600, lr = 0.00122
I0527 05:50:15.957293 30701 solver.cpp:218] Iteration 175700 (3.55586 iter/s, 28.1226s/100 iters), loss = 0.000635417
I0527 05:50:15.957500 30701 solver.cpp:237]     Train net output #0: loss = 0.000633517 (* 1 = 0.000633517 loss)
I0527 05:50:15.957517 30701 sgd_solver.cpp:105] Iteration 175700, lr = 0.001215
I0527 05:50:44.034899 30701 solver.cpp:218] Iteration 175800 (3.56166 iter/s, 28.0768s/100 iters), loss = 0.000465128
I0527 05:50:44.034956 30701 solver.cpp:237]     Train net output #0: loss = 0.000463228 (* 1 = 0.000463228 loss)
I0527 05:50:44.034966 30701 sgd_solver.cpp:105] Iteration 175800, lr = 0.00121
I0527 05:51:12.147778 30701 solver.cpp:218] Iteration 175900 (3.55717 iter/s, 28.1122s/100 iters), loss = 0.00103969
I0527 05:51:12.148000 30701 solver.cpp:237]     Train net output #0: loss = 0.00103779 (* 1 = 0.00103779 loss)
I0527 05:51:12.148013 30701 sgd_solver.cpp:105] Iteration 175900, lr = 0.001205
I0527 05:51:39.987565 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_176000.caffemodel
I0527 05:51:40.300743 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_176000.solverstate
I0527 05:51:40.450920 30701 solver.cpp:330] Iteration 176000, Testing net (#0)
I0527 05:51:43.403348 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 05:51:43.403503 30701 solver.cpp:397]     Test net output #1: loss = 0.805933 (* 1 = 0.805933 loss)
I0527 05:51:43.680716 30701 solver.cpp:218] Iteration 176000 (3.17138 iter/s, 31.5321s/100 iters), loss = 0.000440521
I0527 05:51:43.680766 30701 solver.cpp:237]     Train net output #0: loss = 0.000438622 (* 1 = 0.000438622 loss)
I0527 05:51:43.680776 30701 sgd_solver.cpp:105] Iteration 176000, lr = 0.0012
I0527 05:52:11.802754 30701 solver.cpp:218] Iteration 176100 (3.55601 iter/s, 28.1214s/100 iters), loss = 0.000275381
I0527 05:52:11.802805 30701 solver.cpp:237]     Train net output #0: loss = 0.000273481 (* 1 = 0.000273481 loss)
I0527 05:52:11.802814 30701 sgd_solver.cpp:105] Iteration 176100, lr = 0.001195
I0527 05:52:28.125650 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:52:39.921347 30701 solver.cpp:218] Iteration 176200 (3.55645 iter/s, 28.118s/100 iters), loss = 0.000535847
I0527 05:52:39.921393 30701 solver.cpp:237]     Train net output #0: loss = 0.000533948 (* 1 = 0.000533948 loss)
I0527 05:52:39.921402 30701 sgd_solver.cpp:105] Iteration 176200, lr = 0.00119
I0527 05:53:08.039733 30701 solver.cpp:218] Iteration 176300 (3.55647 iter/s, 28.1177s/100 iters), loss = 0.000183572
I0527 05:53:08.039894 30701 solver.cpp:237]     Train net output #0: loss = 0.000181673 (* 1 = 0.000181673 loss)
I0527 05:53:08.039906 30701 sgd_solver.cpp:105] Iteration 176300, lr = 0.001185
I0527 05:53:36.136826 30701 solver.cpp:218] Iteration 176400 (3.55918 iter/s, 28.0963s/100 iters), loss = 0.000587096
I0527 05:53:36.136868 30701 solver.cpp:237]     Train net output #0: loss = 0.000585196 (* 1 = 0.000585196 loss)
I0527 05:53:36.136878 30701 sgd_solver.cpp:105] Iteration 176400, lr = 0.00118
I0527 05:54:04.203603 30701 solver.cpp:218] Iteration 176500 (3.56301 iter/s, 28.0661s/100 iters), loss = 0.00028276
I0527 05:54:04.203791 30701 solver.cpp:237]     Train net output #0: loss = 0.00028086 (* 1 = 0.00028086 loss)
I0527 05:54:04.203810 30701 sgd_solver.cpp:105] Iteration 176500, lr = 0.001175
I0527 05:54:32.268918 30701 solver.cpp:218] Iteration 176600 (3.56321 iter/s, 28.0645s/100 iters), loss = 0.00175732
I0527 05:54:32.268975 30701 solver.cpp:237]     Train net output #0: loss = 0.00175542 (* 1 = 0.00175542 loss)
I0527 05:54:32.268985 30701 sgd_solver.cpp:105] Iteration 176600, lr = 0.00117
I0527 05:55:00.361894 30701 solver.cpp:218] Iteration 176700 (3.55969 iter/s, 28.0923s/100 iters), loss = 0.000309416
I0527 05:55:00.362062 30701 solver.cpp:237]     Train net output #0: loss = 0.000307516 (* 1 = 0.000307516 loss)
I0527 05:55:00.362073 30701 sgd_solver.cpp:105] Iteration 176700, lr = 0.001165
I0527 05:55:14.140457 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:55:28.455318 30701 solver.cpp:218] Iteration 176800 (3.55965 iter/s, 28.0927s/100 iters), loss = 0.00111485
I0527 05:55:28.455363 30701 solver.cpp:237]     Train net output #0: loss = 0.00111295 (* 1 = 0.00111295 loss)
I0527 05:55:28.455371 30701 sgd_solver.cpp:105] Iteration 176800, lr = 0.00116
I0527 05:55:56.548902 30701 solver.cpp:218] Iteration 176900 (3.55961 iter/s, 28.093s/100 iters), loss = 0.000227347
I0527 05:55:56.549110 30701 solver.cpp:237]     Train net output #0: loss = 0.000225447 (* 1 = 0.000225447 loss)
I0527 05:55:56.549123 30701 sgd_solver.cpp:105] Iteration 176900, lr = 0.001155
I0527 05:56:24.365754 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_177000.caffemodel
I0527 05:56:24.679281 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_177000.solverstate
I0527 05:56:24.829435 30701 solver.cpp:330] Iteration 177000, Testing net (#0)
I0527 05:56:25.306958 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:56:27.783707 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 05:56:27.783849 30701 solver.cpp:397]     Test net output #1: loss = 0.80025 (* 1 = 0.80025 loss)
I0527 05:56:28.061168 30701 solver.cpp:218] Iteration 177000 (3.17345 iter/s, 31.5114s/100 iters), loss = 0.000167363
I0527 05:56:28.061228 30701 solver.cpp:237]     Train net output #0: loss = 0.000165463 (* 1 = 0.000165463 loss)
I0527 05:56:28.061238 30701 sgd_solver.cpp:105] Iteration 177000, lr = 0.00115
I0527 05:56:56.153266 30701 solver.cpp:218] Iteration 177100 (3.55982 iter/s, 28.0913s/100 iters), loss = 0.000604971
I0527 05:56:56.153311 30701 solver.cpp:237]     Train net output #0: loss = 0.00060307 (* 1 = 0.00060307 loss)
I0527 05:56:56.153318 30701 sgd_solver.cpp:105] Iteration 177100, lr = 0.001145
I0527 05:57:24.268035 30701 solver.cpp:218] Iteration 177200 (3.55695 iter/s, 28.114s/100 iters), loss = 0.000140471
I0527 05:57:24.268244 30701 solver.cpp:237]     Train net output #0: loss = 0.000138571 (* 1 = 0.000138571 loss)
I0527 05:57:24.268275 30701 sgd_solver.cpp:105] Iteration 177200, lr = 0.00114
I0527 05:57:52.365094 30701 solver.cpp:218] Iteration 177300 (3.55921 iter/s, 28.0961s/100 iters), loss = 0.00051575
I0527 05:57:52.365139 30701 solver.cpp:237]     Train net output #0: loss = 0.00051385 (* 1 = 0.00051385 loss)
I0527 05:57:52.365147 30701 sgd_solver.cpp:105] Iteration 177300, lr = 0.001135
I0527 05:58:03.637198 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 05:58:20.488098 30701 solver.cpp:218] Iteration 177400 (3.55591 iter/s, 28.1222s/100 iters), loss = 7.88501e-05
I0527 05:58:20.488147 30701 solver.cpp:237]     Train net output #0: loss = 7.69503e-05 (* 1 = 7.69503e-05 loss)
I0527 05:58:20.488157 30701 sgd_solver.cpp:105] Iteration 177400, lr = 0.00113
I0527 05:58:48.623417 30701 solver.cpp:218] Iteration 177500 (3.55435 iter/s, 28.1345s/100 iters), loss = 0.0002843
I0527 05:58:48.623631 30701 solver.cpp:237]     Train net output #0: loss = 0.0002824 (* 1 = 0.0002824 loss)
I0527 05:58:48.623659 30701 sgd_solver.cpp:105] Iteration 177500, lr = 0.001125
I0527 05:59:16.742174 30701 solver.cpp:218] Iteration 177600 (3.55646 iter/s, 28.1179s/100 iters), loss = 0.000528375
I0527 05:59:16.742220 30701 solver.cpp:237]     Train net output #0: loss = 0.000526475 (* 1 = 0.000526475 loss)
I0527 05:59:16.742229 30701 sgd_solver.cpp:105] Iteration 177600, lr = 0.00112
I0527 05:59:44.839164 30701 solver.cpp:218] Iteration 177700 (3.5592 iter/s, 28.0962s/100 iters), loss = 0.000344409
I0527 05:59:44.839323 30701 solver.cpp:237]     Train net output #0: loss = 0.000342509 (* 1 = 0.000342509 loss)
I0527 05:59:44.839336 30701 sgd_solver.cpp:105] Iteration 177700, lr = 0.001115
I0527 06:00:12.906368 30701 solver.cpp:218] Iteration 177800 (3.56299 iter/s, 28.0663s/100 iters), loss = 0.000246905
I0527 06:00:12.906414 30701 solver.cpp:237]     Train net output #0: loss = 0.000245005 (* 1 = 0.000245005 loss)
I0527 06:00:12.906422 30701 sgd_solver.cpp:105] Iteration 177800, lr = 0.00111
I0527 06:00:40.980046 30701 solver.cpp:218] Iteration 177900 (3.56215 iter/s, 28.0729s/100 iters), loss = 0.000344937
I0527 06:00:40.980268 30701 solver.cpp:237]     Train net output #0: loss = 0.000343037 (* 1 = 0.000343037 loss)
I0527 06:00:40.980279 30701 sgd_solver.cpp:105] Iteration 177900, lr = 0.001105
I0527 06:00:49.993239 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:01:08.825973 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_178000.caffemodel
I0527 06:01:09.139156 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_178000.solverstate
I0527 06:01:09.289345 30701 solver.cpp:330] Iteration 178000, Testing net (#0)
I0527 06:01:12.251727 30701 solver.cpp:397]     Test net output #0: accuracy = 0.806
I0527 06:01:12.251855 30701 solver.cpp:397]     Test net output #1: loss = 0.887412 (* 1 = 0.887412 loss)
I0527 06:01:12.528692 30701 solver.cpp:218] Iteration 178000 (3.16981 iter/s, 31.5476s/100 iters), loss = 8.68609e-05
I0527 06:01:12.528738 30701 solver.cpp:237]     Train net output #0: loss = 8.49608e-05 (* 1 = 8.49608e-05 loss)
I0527 06:01:12.528745 30701 sgd_solver.cpp:105] Iteration 178000, lr = 0.0011
I0527 06:01:40.604665 30701 solver.cpp:218] Iteration 178100 (3.56186 iter/s, 28.0752s/100 iters), loss = 0.000502555
I0527 06:01:40.604715 30701 solver.cpp:237]     Train net output #0: loss = 0.000500655 (* 1 = 0.000500655 loss)
I0527 06:01:40.604724 30701 sgd_solver.cpp:105] Iteration 178100, lr = 0.001095
I0527 06:02:08.689820 30701 solver.cpp:218] Iteration 178200 (3.56069 iter/s, 28.0844s/100 iters), loss = 0.000347332
I0527 06:02:08.689986 30701 solver.cpp:237]     Train net output #0: loss = 0.000345433 (* 1 = 0.000345433 loss)
I0527 06:02:08.689997 30701 sgd_solver.cpp:105] Iteration 178200, lr = 0.00109
I0527 06:02:36.756801 30701 solver.cpp:218] Iteration 178300 (3.56301 iter/s, 28.0661s/100 iters), loss = 0.000461262
I0527 06:02:36.756847 30701 solver.cpp:237]     Train net output #0: loss = 0.000459363 (* 1 = 0.000459363 loss)
I0527 06:02:36.756856 30701 sgd_solver.cpp:105] Iteration 178300, lr = 0.001085
I0527 06:03:04.833540 30701 solver.cpp:218] Iteration 178400 (3.56176 iter/s, 28.076s/100 iters), loss = 0.000731278
I0527 06:03:04.833763 30701 solver.cpp:237]     Train net output #0: loss = 0.000729378 (* 1 = 0.000729378 loss)
I0527 06:03:04.833775 30701 sgd_solver.cpp:105] Iteration 178400, lr = 0.00108
I0527 06:03:32.910949 30701 solver.cpp:218] Iteration 178500 (3.56169 iter/s, 28.0765s/100 iters), loss = 0.00038768
I0527 06:03:32.911000 30701 solver.cpp:237]     Train net output #0: loss = 0.00038578 (* 1 = 0.00038578 loss)
I0527 06:03:32.911008 30701 sgd_solver.cpp:105] Iteration 178500, lr = 0.001075
I0527 06:03:39.387040 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:04:00.990381 30701 solver.cpp:218] Iteration 178600 (3.56142 iter/s, 28.0787s/100 iters), loss = 0.000165138
I0527 06:04:00.990427 30701 solver.cpp:237]     Train net output #0: loss = 0.000163239 (* 1 = 0.000163239 loss)
I0527 06:04:00.990435 30701 sgd_solver.cpp:105] Iteration 178600, lr = 0.00107
I0527 06:04:29.098397 30701 solver.cpp:218] Iteration 178700 (3.5578 iter/s, 28.1073s/100 iters), loss = 0.00138393
I0527 06:04:29.098549 30701 solver.cpp:237]     Train net output #0: loss = 0.00138203 (* 1 = 0.00138203 loss)
I0527 06:04:29.098562 30701 sgd_solver.cpp:105] Iteration 178700, lr = 0.001065
I0527 06:04:57.220944 30701 solver.cpp:218] Iteration 178800 (3.55597 iter/s, 28.1217s/100 iters), loss = 0.000380776
I0527 06:04:57.220988 30701 solver.cpp:237]     Train net output #0: loss = 0.000378876 (* 1 = 0.000378876 loss)
I0527 06:04:57.220996 30701 sgd_solver.cpp:105] Iteration 178800, lr = 0.00106
I0527 06:05:25.351084 30701 solver.cpp:218] Iteration 178900 (3.555 iter/s, 28.1294s/100 iters), loss = 0.000396213
I0527 06:05:25.351248 30701 solver.cpp:237]     Train net output #0: loss = 0.000394313 (* 1 = 0.000394313 loss)
I0527 06:05:25.351260 30701 sgd_solver.cpp:105] Iteration 178900, lr = 0.001055
I0527 06:05:53.171413 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_179000.caffemodel
I0527 06:05:53.532305 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_179000.solverstate
I0527 06:05:53.683773 30701 solver.cpp:330] Iteration 179000, Testing net (#0)
I0527 06:05:55.818542 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:05:56.644814 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 06:05:56.644862 30701 solver.cpp:397]     Test net output #1: loss = 0.702401 (* 1 = 0.702401 loss)
I0527 06:05:56.922034 30701 solver.cpp:218] Iteration 179000 (3.16756 iter/s, 31.57s/100 iters), loss = 0.00017755
I0527 06:05:56.922089 30701 solver.cpp:237]     Train net output #0: loss = 0.00017565 (* 1 = 0.00017565 loss)
I0527 06:05:56.922099 30701 sgd_solver.cpp:105] Iteration 179000, lr = 0.00105
I0527 06:06:25.045622 30701 solver.cpp:218] Iteration 179100 (3.55582 iter/s, 28.1229s/100 iters), loss = 0.000240638
I0527 06:06:25.045668 30701 solver.cpp:237]     Train net output #0: loss = 0.000238738 (* 1 = 0.000238738 loss)
I0527 06:06:25.045677 30701 sgd_solver.cpp:105] Iteration 179100, lr = 0.001045
I0527 06:06:29.001605 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:06:53.171397 30701 solver.cpp:218] Iteration 179200 (3.55555 iter/s, 28.1251s/100 iters), loss = 0.000218195
I0527 06:06:53.171442 30701 solver.cpp:237]     Train net output #0: loss = 0.000216295 (* 1 = 0.000216295 loss)
I0527 06:06:53.171450 30701 sgd_solver.cpp:105] Iteration 179200, lr = 0.00104
I0527 06:07:21.286159 30701 solver.cpp:218] Iteration 179300 (3.55694 iter/s, 28.1141s/100 iters), loss = 0.000414031
I0527 06:07:21.286378 30701 solver.cpp:237]     Train net output #0: loss = 0.00041213 (* 1 = 0.00041213 loss)
I0527 06:07:21.286389 30701 sgd_solver.cpp:105] Iteration 179300, lr = 0.001035
I0527 06:07:49.385635 30701 solver.cpp:218] Iteration 179400 (3.5589 iter/s, 28.0986s/100 iters), loss = 0.00058355
I0527 06:07:49.385677 30701 solver.cpp:237]     Train net output #0: loss = 0.00058165 (* 1 = 0.00058165 loss)
I0527 06:07:49.385685 30701 sgd_solver.cpp:105] Iteration 179400, lr = 0.00103
I0527 06:08:17.469213 30701 solver.cpp:218] Iteration 179500 (3.56089 iter/s, 28.0829s/100 iters), loss = 0.000677547
I0527 06:08:17.469368 30701 solver.cpp:237]     Train net output #0: loss = 0.000675647 (* 1 = 0.000675647 loss)
I0527 06:08:17.469380 30701 sgd_solver.cpp:105] Iteration 179500, lr = 0.001025
I0527 06:08:45.555183 30701 solver.cpp:218] Iteration 179600 (3.5606 iter/s, 28.0852s/100 iters), loss = 0.000940721
I0527 06:08:45.555225 30701 solver.cpp:237]     Train net output #0: loss = 0.000938822 (* 1 = 0.000938822 loss)
I0527 06:08:45.555233 30701 sgd_solver.cpp:105] Iteration 179600, lr = 0.00102
I0527 06:09:13.641548 30701 solver.cpp:218] Iteration 179700 (3.56053 iter/s, 28.0857s/100 iters), loss = 0.000396905
I0527 06:09:13.641739 30701 solver.cpp:237]     Train net output #0: loss = 0.000395005 (* 1 = 0.000395005 loss)
I0527 06:09:13.641752 30701 sgd_solver.cpp:105] Iteration 179700, lr = 0.001015
I0527 06:09:15.067680 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:09:41.733206 30701 solver.cpp:218] Iteration 179800 (3.55988 iter/s, 28.0908s/100 iters), loss = 0.000747873
I0527 06:09:41.733253 30701 solver.cpp:237]     Train net output #0: loss = 0.000745974 (* 1 = 0.000745974 loss)
I0527 06:09:41.733263 30701 sgd_solver.cpp:105] Iteration 179800, lr = 0.00101
I0527 06:10:09.843358 30701 solver.cpp:218] Iteration 179900 (3.55752 iter/s, 28.1095s/100 iters), loss = 0.000526525
I0527 06:10:09.843480 30701 solver.cpp:237]     Train net output #0: loss = 0.000524625 (* 1 = 0.000524625 loss)
I0527 06:10:09.843490 30701 sgd_solver.cpp:105] Iteration 179900, lr = 0.001005
I0527 06:10:37.671377 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_180000.caffemodel
I0527 06:10:37.984169 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_180000.solverstate
I0527 06:10:38.133481 30701 solver.cpp:330] Iteration 180000, Testing net (#0)
I0527 06:10:41.092252 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 06:10:41.092404 30701 solver.cpp:397]     Test net output #1: loss = 0.847552 (* 1 = 0.847552 loss)
I0527 06:10:41.369006 30701 solver.cpp:218] Iteration 180000 (3.1721 iter/s, 31.5248s/100 iters), loss = 0.000128106
I0527 06:10:41.369052 30701 solver.cpp:237]     Train net output #0: loss = 0.000126207 (* 1 = 0.000126207 loss)
I0527 06:10:41.369061 30701 sgd_solver.cpp:105] Iteration 180000, lr = 0.001
I0527 06:11:09.464212 30701 solver.cpp:218] Iteration 180100 (3.55941 iter/s, 28.0945s/100 iters), loss = 0.000165025
I0527 06:11:09.464254 30701 solver.cpp:237]     Train net output #0: loss = 0.000163126 (* 1 = 0.000163126 loss)
I0527 06:11:09.464264 30701 sgd_solver.cpp:105] Iteration 180100, lr = 0.000995
I0527 06:11:37.561025 30701 solver.cpp:218] Iteration 180200 (3.55921 iter/s, 28.0961s/100 iters), loss = 0.000444947
I0527 06:11:37.561389 30701 solver.cpp:237]     Train net output #0: loss = 0.000443048 (* 1 = 0.000443048 loss)
I0527 06:11:37.561401 30701 sgd_solver.cpp:105] Iteration 180200, lr = 0.00099
I0527 06:12:04.559420 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:12:05.666352 30701 solver.cpp:218] Iteration 180300 (3.55817 iter/s, 28.1043s/100 iters), loss = 0.000111613
I0527 06:12:05.666414 30701 solver.cpp:237]     Train net output #0: loss = 0.000109714 (* 1 = 0.000109714 loss)
I0527 06:12:05.666424 30701 sgd_solver.cpp:105] Iteration 180300, lr = 0.000985
I0527 06:12:33.762243 30701 solver.cpp:218] Iteration 180400 (3.55933 iter/s, 28.0952s/100 iters), loss = 7.72012e-05
I0527 06:12:33.762457 30701 solver.cpp:237]     Train net output #0: loss = 7.5302e-05 (* 1 = 7.5302e-05 loss)
I0527 06:12:33.762468 30701 sgd_solver.cpp:105] Iteration 180400, lr = 0.00098
I0527 06:13:01.853893 30701 solver.cpp:218] Iteration 180500 (3.55988 iter/s, 28.0908s/100 iters), loss = 0.000314899
I0527 06:13:01.853938 30701 solver.cpp:237]     Train net output #0: loss = 0.000313 (* 1 = 0.000313 loss)
I0527 06:13:01.853947 30701 sgd_solver.cpp:105] Iteration 180500, lr = 0.000975
I0527 06:13:29.953076 30701 solver.cpp:218] Iteration 180600 (3.55891 iter/s, 28.0985s/100 iters), loss = 0.000644514
I0527 06:13:29.953280 30701 solver.cpp:237]     Train net output #0: loss = 0.000642615 (* 1 = 0.000642615 loss)
I0527 06:13:29.953291 30701 sgd_solver.cpp:105] Iteration 180600, lr = 0.00097
I0527 06:13:58.042951 30701 solver.cpp:218] Iteration 180700 (3.5601 iter/s, 28.0891s/100 iters), loss = 0.000369178
I0527 06:13:58.042996 30701 solver.cpp:237]     Train net output #0: loss = 0.000367279 (* 1 = 0.000367279 loss)
I0527 06:13:58.043005 30701 sgd_solver.cpp:105] Iteration 180700, lr = 0.000965
I0527 06:14:26.139402 30701 solver.cpp:218] Iteration 180800 (3.55925 iter/s, 28.0958s/100 iters), loss = 0.000281205
I0527 06:14:26.139560 30701 solver.cpp:237]     Train net output #0: loss = 0.000279306 (* 1 = 0.000279306 loss)
I0527 06:14:26.139580 30701 sgd_solver.cpp:105] Iteration 180800, lr = 0.00096
I0527 06:14:50.594879 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:14:54.232942 30701 solver.cpp:218] Iteration 180900 (3.55964 iter/s, 28.0928s/100 iters), loss = 0.000588499
I0527 06:14:54.232987 30701 solver.cpp:237]     Train net output #0: loss = 0.000586601 (* 1 = 0.000586601 loss)
I0527 06:14:54.232996 30701 sgd_solver.cpp:105] Iteration 180900, lr = 0.000955
I0527 06:15:22.057828 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_181000.caffemodel
I0527 06:15:22.421180 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_181000.solverstate
I0527 06:15:22.572034 30701 solver.cpp:330] Iteration 181000, Testing net (#0)
I0527 06:15:25.530892 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 06:15:25.530928 30701 solver.cpp:397]     Test net output #1: loss = 0.791614 (* 1 = 0.791614 loss)
I0527 06:15:25.809006 30701 solver.cpp:218] Iteration 181000 (3.16703 iter/s, 31.5753s/100 iters), loss = 0.000228632
I0527 06:15:25.809058 30701 solver.cpp:237]     Train net output #0: loss = 0.000226733 (* 1 = 0.000226733 loss)
I0527 06:15:25.809069 30701 sgd_solver.cpp:105] Iteration 181000, lr = 0.00095
I0527 06:15:53.894922 30701 solver.cpp:218] Iteration 181100 (3.56059 iter/s, 28.0852s/100 iters), loss = 0.000206229
I0527 06:15:53.895084 30701 solver.cpp:237]     Train net output #0: loss = 0.00020433 (* 1 = 0.00020433 loss)
I0527 06:15:53.895100 30701 sgd_solver.cpp:105] Iteration 181100, lr = 0.000945
I0527 06:16:22.022248 30701 solver.cpp:218] Iteration 181200 (3.55536 iter/s, 28.1265s/100 iters), loss = 0.000355592
I0527 06:16:22.022295 30701 solver.cpp:237]     Train net output #0: loss = 0.000353693 (* 1 = 0.000353693 loss)
I0527 06:16:22.022316 30701 sgd_solver.cpp:105] Iteration 181200, lr = 0.00094
I0527 06:16:50.128815 30701 solver.cpp:218] Iteration 181300 (3.55797 iter/s, 28.1059s/100 iters), loss = 0.000249189
I0527 06:16:50.128968 30701 solver.cpp:237]     Train net output #0: loss = 0.00024729 (* 1 = 0.00024729 loss)
I0527 06:16:50.128980 30701 sgd_solver.cpp:105] Iteration 181300, lr = 0.000935
I0527 06:17:18.261251 30701 solver.cpp:218] Iteration 181400 (3.55471 iter/s, 28.1317s/100 iters), loss = 0.000470819
I0527 06:17:18.261307 30701 solver.cpp:237]     Train net output #0: loss = 0.00046892 (* 1 = 0.00046892 loss)
I0527 06:17:18.261317 30701 sgd_solver.cpp:105] Iteration 181400, lr = 0.00093
I0527 06:17:40.490965 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:17:46.387908 30701 solver.cpp:218] Iteration 181500 (3.55543 iter/s, 28.126s/100 iters), loss = 0.00039236
I0527 06:17:46.387955 30701 solver.cpp:237]     Train net output #0: loss = 0.000390461 (* 1 = 0.000390461 loss)
I0527 06:17:46.387977 30701 sgd_solver.cpp:105] Iteration 181500, lr = 0.000925
I0527 06:18:14.461549 30701 solver.cpp:218] Iteration 181600 (3.56215 iter/s, 28.073s/100 iters), loss = 0.000496142
I0527 06:18:14.461758 30701 solver.cpp:237]     Train net output #0: loss = 0.000494243 (* 1 = 0.000494243 loss)
I0527 06:18:14.461769 30701 sgd_solver.cpp:105] Iteration 181600, lr = 0.00092
I0527 06:18:42.559578 30701 solver.cpp:218] Iteration 181700 (3.55907 iter/s, 28.0972s/100 iters), loss = 0.000426967
I0527 06:18:42.559633 30701 solver.cpp:237]     Train net output #0: loss = 0.000425068 (* 1 = 0.000425068 loss)
I0527 06:18:42.559641 30701 sgd_solver.cpp:105] Iteration 181700, lr = 0.000915
I0527 06:19:10.644312 30701 solver.cpp:218] Iteration 181800 (3.56074 iter/s, 28.0841s/100 iters), loss = 0.00133588
I0527 06:19:10.644556 30701 solver.cpp:237]     Train net output #0: loss = 0.00133398 (* 1 = 0.00133398 loss)
I0527 06:19:10.644567 30701 sgd_solver.cpp:105] Iteration 181800, lr = 0.00091
I0527 06:19:38.738099 30701 solver.cpp:218] Iteration 181900 (3.55962 iter/s, 28.0929s/100 iters), loss = 0.000840271
I0527 06:19:38.738144 30701 solver.cpp:237]     Train net output #0: loss = 0.000838371 (* 1 = 0.000838371 loss)
I0527 06:19:38.738153 30701 sgd_solver.cpp:105] Iteration 181900, lr = 0.000905
I0527 06:20:06.551215 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_182000.caffemodel
I0527 06:20:06.884979 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_182000.solverstate
I0527 06:20:07.035634 30701 solver.cpp:330] Iteration 182000, Testing net (#0)
I0527 06:20:07.897101 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:20:09.992190 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 06:20:09.992226 30701 solver.cpp:397]     Test net output #1: loss = 0.785101 (* 1 = 0.785101 loss)
I0527 06:20:10.269340 30701 solver.cpp:218] Iteration 182000 (3.17153 iter/s, 31.5305s/100 iters), loss = 0.000273946
I0527 06:20:10.269385 30701 solver.cpp:237]     Train net output #0: loss = 0.000272047 (* 1 = 0.000272047 loss)
I0527 06:20:10.269393 30701 sgd_solver.cpp:105] Iteration 182000, lr = 0.0009
I0527 06:20:29.895807 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:20:38.282006 30701 solver.cpp:218] Iteration 182100 (3.5699 iter/s, 28.012s/100 iters), loss = 0.000164698
I0527 06:20:38.282320 30701 solver.cpp:237]     Train net output #0: loss = 0.000162799 (* 1 = 0.000162799 loss)
I0527 06:20:38.282331 30701 sgd_solver.cpp:105] Iteration 182100, lr = 0.000895
I0527 06:21:06.358304 30701 solver.cpp:218] Iteration 182200 (3.56184 iter/s, 28.0754s/100 iters), loss = 0.000497282
I0527 06:21:06.358361 30701 solver.cpp:237]     Train net output #0: loss = 0.000495383 (* 1 = 0.000495383 loss)
I0527 06:21:06.358369 30701 sgd_solver.cpp:105] Iteration 182200, lr = 0.00089
I0527 06:21:34.434124 30701 solver.cpp:218] Iteration 182300 (3.56187 iter/s, 28.0751s/100 iters), loss = 0.000105248
I0527 06:21:34.434288 30701 solver.cpp:237]     Train net output #0: loss = 0.000103348 (* 1 = 0.000103348 loss)
I0527 06:21:34.434299 30701 sgd_solver.cpp:105] Iteration 182300, lr = 0.000885
I0527 06:22:02.506963 30701 solver.cpp:218] Iteration 182400 (3.56226 iter/s, 28.0721s/100 iters), loss = 0.000508174
I0527 06:22:02.507007 30701 solver.cpp:237]     Train net output #0: loss = 0.000506274 (* 1 = 0.000506274 loss)
I0527 06:22:02.507016 30701 sgd_solver.cpp:105] Iteration 182400, lr = 0.00088
I0527 06:22:30.577898 30701 solver.cpp:218] Iteration 182500 (3.56249 iter/s, 28.0703s/100 iters), loss = 0.000486329
I0527 06:22:30.578049 30701 solver.cpp:237]     Train net output #0: loss = 0.000484429 (* 1 = 0.000484429 loss)
I0527 06:22:30.578061 30701 sgd_solver.cpp:105] Iteration 182500, lr = 0.000875
I0527 06:22:58.650059 30701 solver.cpp:218] Iteration 182600 (3.56235 iter/s, 28.0714s/100 iters), loss = 0.000240342
I0527 06:22:58.650104 30701 solver.cpp:237]     Train net output #0: loss = 0.000238443 (* 1 = 0.000238443 loss)
I0527 06:22:58.650113 30701 sgd_solver.cpp:105] Iteration 182600, lr = 0.00087
I0527 06:23:15.788347 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:23:26.735168 30701 solver.cpp:218] Iteration 182700 (3.56069 iter/s, 28.0844s/100 iters), loss = 0.000429505
I0527 06:23:26.735213 30701 solver.cpp:237]     Train net output #0: loss = 0.000427605 (* 1 = 0.000427605 loss)
I0527 06:23:26.735221 30701 sgd_solver.cpp:105] Iteration 182700, lr = 0.000865
I0527 06:23:54.831907 30701 solver.cpp:218] Iteration 182800 (3.55922 iter/s, 28.0961s/100 iters), loss = 0.000987821
I0527 06:23:54.832047 30701 solver.cpp:237]     Train net output #0: loss = 0.000985921 (* 1 = 0.000985921 loss)
I0527 06:23:54.832074 30701 sgd_solver.cpp:105] Iteration 182800, lr = 0.00086
I0527 06:24:22.923458 30701 solver.cpp:218] Iteration 182900 (3.55989 iter/s, 28.0908s/100 iters), loss = 0.000912932
I0527 06:24:22.923511 30701 solver.cpp:237]     Train net output #0: loss = 0.000911032 (* 1 = 0.000911032 loss)
I0527 06:24:22.923523 30701 sgd_solver.cpp:105] Iteration 182900, lr = 0.000855
I0527 06:24:50.724158 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_183000.caffemodel
I0527 06:24:51.048925 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_183000.solverstate
I0527 06:24:51.201122 30701 solver.cpp:330] Iteration 183000, Testing net (#0)
I0527 06:24:54.140913 30701 solver.cpp:397]     Test net output #0: accuracy = 0.814
I0527 06:24:54.140954 30701 solver.cpp:397]     Test net output #1: loss = 0.886398 (* 1 = 0.886398 loss)
I0527 06:24:54.420416 30701 solver.cpp:218] Iteration 183000 (3.17498 iter/s, 31.4962s/100 iters), loss = 0.00041479
I0527 06:24:54.420461 30701 solver.cpp:237]     Train net output #0: loss = 0.00041289 (* 1 = 0.00041289 loss)
I0527 06:24:54.420469 30701 sgd_solver.cpp:105] Iteration 183000, lr = 0.00085
I0527 06:25:22.503511 30701 solver.cpp:218] Iteration 183100 (3.56095 iter/s, 28.0824s/100 iters), loss = 0.000863097
I0527 06:25:22.503667 30701 solver.cpp:237]     Train net output #0: loss = 0.000861197 (* 1 = 0.000861197 loss)
I0527 06:25:22.503679 30701 sgd_solver.cpp:105] Iteration 183100, lr = 0.000845
I0527 06:25:50.566968 30701 solver.cpp:218] Iteration 183200 (3.56345 iter/s, 28.0627s/100 iters), loss = 0.000392944
I0527 06:25:50.567024 30701 solver.cpp:237]     Train net output #0: loss = 0.000391044 (* 1 = 0.000391044 loss)
I0527 06:25:50.567034 30701 sgd_solver.cpp:105] Iteration 183200, lr = 0.00084
I0527 06:26:05.193435 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:26:18.657938 30701 solver.cpp:218] Iteration 183300 (3.55995 iter/s, 28.0903s/100 iters), loss = 0.000152231
I0527 06:26:18.657984 30701 solver.cpp:237]     Train net output #0: loss = 0.00015033 (* 1 = 0.00015033 loss)
I0527 06:26:18.657992 30701 sgd_solver.cpp:105] Iteration 183300, lr = 0.000835
I0527 06:26:46.748366 30701 solver.cpp:218] Iteration 183400 (3.56002 iter/s, 28.0898s/100 iters), loss = 0.000377094
I0527 06:26:46.748579 30701 solver.cpp:237]     Train net output #0: loss = 0.000375194 (* 1 = 0.000375194 loss)
I0527 06:26:46.748590 30701 sgd_solver.cpp:105] Iteration 183400, lr = 0.00083
I0527 06:27:14.864361 30701 solver.cpp:218] Iteration 183500 (3.5568 iter/s, 28.1152s/100 iters), loss = 0.000371761
I0527 06:27:14.864437 30701 solver.cpp:237]     Train net output #0: loss = 0.00036986 (* 1 = 0.00036986 loss)
I0527 06:27:14.864449 30701 sgd_solver.cpp:105] Iteration 183500, lr = 0.000825
I0527 06:27:42.992079 30701 solver.cpp:218] Iteration 183600 (3.5553 iter/s, 28.127s/100 iters), loss = 0.000126336
I0527 06:27:42.992302 30701 solver.cpp:237]     Train net output #0: loss = 0.000124435 (* 1 = 0.000124435 loss)
I0527 06:27:42.992313 30701 sgd_solver.cpp:105] Iteration 183600, lr = 0.00082
I0527 06:28:11.126144 30701 solver.cpp:218] Iteration 183700 (3.55452 iter/s, 28.1332s/100 iters), loss = 0.000159004
I0527 06:28:11.126189 30701 solver.cpp:237]     Train net output #0: loss = 0.000157103 (* 1 = 0.000157103 loss)
I0527 06:28:11.126199 30701 sgd_solver.cpp:105] Iteration 183700, lr = 0.000815
I0527 06:28:39.241521 30701 solver.cpp:218] Iteration 183800 (3.55686 iter/s, 28.1147s/100 iters), loss = 0.000265658
I0527 06:28:39.241681 30701 solver.cpp:237]     Train net output #0: loss = 0.000263758 (* 1 = 0.000263758 loss)
I0527 06:28:39.241693 30701 sgd_solver.cpp:105] Iteration 183800, lr = 0.00081
I0527 06:28:51.350080 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:29:07.352675 30701 solver.cpp:218] Iteration 183900 (3.5574 iter/s, 28.1104s/100 iters), loss = 0.000186527
I0527 06:29:07.352726 30701 solver.cpp:237]     Train net output #0: loss = 0.000184627 (* 1 = 0.000184627 loss)
I0527 06:29:07.352749 30701 sgd_solver.cpp:105] Iteration 183900, lr = 0.000805
I0527 06:29:35.196605 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_184000.caffemodel
I0527 06:29:35.571708 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_184000.solverstate
I0527 06:29:35.724062 30701 solver.cpp:330] Iteration 184000, Testing net (#0)
I0527 06:29:38.267652 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:29:38.680691 30701 solver.cpp:397]     Test net output #0: accuracy = 0.838
I0527 06:29:38.680742 30701 solver.cpp:397]     Test net output #1: loss = 0.646864 (* 1 = 0.646864 loss)
I0527 06:29:38.958573 30701 solver.cpp:218] Iteration 184000 (3.16404 iter/s, 31.6052s/100 iters), loss = 0.000588509
I0527 06:29:38.958631 30701 solver.cpp:237]     Train net output #0: loss = 0.000586609 (* 1 = 0.000586609 loss)
I0527 06:29:38.958640 30701 sgd_solver.cpp:105] Iteration 184000, lr = 0.0008
I0527 06:30:07.067924 30701 solver.cpp:218] Iteration 184100 (3.55762 iter/s, 28.1087s/100 iters), loss = 0.000398892
I0527 06:30:07.068140 30701 solver.cpp:237]     Train net output #0: loss = 0.000396991 (* 1 = 0.000396991 loss)
I0527 06:30:07.068151 30701 sgd_solver.cpp:105] Iteration 184100, lr = 0.000795
I0527 06:30:35.160233 30701 solver.cpp:218] Iteration 184200 (3.5598 iter/s, 28.0915s/100 iters), loss = 8.35824e-05
I0527 06:30:35.160277 30701 solver.cpp:237]     Train net output #0: loss = 8.1682e-05 (* 1 = 8.1682e-05 loss)
I0527 06:30:35.160286 30701 sgd_solver.cpp:105] Iteration 184200, lr = 0.00079
I0527 06:31:03.247700 30701 solver.cpp:218] Iteration 184300 (3.56043 iter/s, 28.0865s/100 iters), loss = 9.01389e-05
I0527 06:31:03.247920 30701 solver.cpp:237]     Train net output #0: loss = 8.82386e-05 (* 1 = 8.82386e-05 loss)
I0527 06:31:03.247931 30701 sgd_solver.cpp:105] Iteration 184300, lr = 0.000785
I0527 06:31:31.320477 30701 solver.cpp:218] Iteration 184400 (3.56231 iter/s, 28.0717s/100 iters), loss = 0.000473254
I0527 06:31:31.320519 30701 solver.cpp:237]     Train net output #0: loss = 0.000471354 (* 1 = 0.000471354 loss)
I0527 06:31:31.320528 30701 sgd_solver.cpp:105] Iteration 184400, lr = 0.00078
I0527 06:31:40.883237 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:31:59.399543 30701 solver.cpp:218] Iteration 184500 (3.56149 iter/s, 28.0781s/100 iters), loss = 0.000208632
I0527 06:31:59.399590 30701 solver.cpp:237]     Train net output #0: loss = 0.000206732 (* 1 = 0.000206732 loss)
I0527 06:31:59.399598 30701 sgd_solver.cpp:105] Iteration 184500, lr = 0.000775
I0527 06:32:27.486636 30701 solver.cpp:218] Iteration 184600 (3.56047 iter/s, 28.0862s/100 iters), loss = 0.000403657
I0527 06:32:27.486851 30701 solver.cpp:237]     Train net output #0: loss = 0.000401757 (* 1 = 0.000401757 loss)
I0527 06:32:27.486862 30701 sgd_solver.cpp:105] Iteration 184600, lr = 0.00077
I0527 06:32:55.571274 30701 solver.cpp:218] Iteration 184700 (3.5608 iter/s, 28.0836s/100 iters), loss = 0.000189706
I0527 06:32:55.571317 30701 solver.cpp:237]     Train net output #0: loss = 0.000187805 (* 1 = 0.000187805 loss)
I0527 06:32:55.571326 30701 sgd_solver.cpp:105] Iteration 184700, lr = 0.000765
I0527 06:33:23.671319 30701 solver.cpp:218] Iteration 184800 (3.55883 iter/s, 28.0991s/100 iters), loss = 0.000177366
I0527 06:33:23.671480 30701 solver.cpp:237]     Train net output #0: loss = 0.000175466 (* 1 = 0.000175466 loss)
I0527 06:33:23.671492 30701 sgd_solver.cpp:105] Iteration 184800, lr = 0.00076
I0527 06:33:51.777459 30701 solver.cpp:218] Iteration 184900 (3.55807 iter/s, 28.1051s/100 iters), loss = 0.000833194
I0527 06:33:51.777506 30701 solver.cpp:237]     Train net output #0: loss = 0.000831293 (* 1 = 0.000831293 loss)
I0527 06:33:51.777515 30701 sgd_solver.cpp:105] Iteration 184900, lr = 0.000755
I0527 06:34:19.625510 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_185000.caffemodel
I0527 06:34:19.958258 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_185000.solverstate
I0527 06:34:20.109158 30701 solver.cpp:330] Iteration 185000, Testing net (#0)
I0527 06:34:23.066316 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 06:34:23.066352 30701 solver.cpp:397]     Test net output #1: loss = 0.903125 (* 1 = 0.903125 loss)
I0527 06:34:23.343552 30701 solver.cpp:218] Iteration 185000 (3.16806 iter/s, 31.5651s/100 iters), loss = 0.00120339
I0527 06:34:23.343595 30701 solver.cpp:237]     Train net output #0: loss = 0.00120149 (* 1 = 0.00120149 loss)
I0527 06:34:23.343603 30701 sgd_solver.cpp:105] Iteration 185000, lr = 0.00075
I0527 06:34:30.391680 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:34:51.449877 30701 solver.cpp:218] Iteration 185100 (3.55803 iter/s, 28.1054s/100 iters), loss = 0.00045596
I0527 06:34:51.450067 30701 solver.cpp:237]     Train net output #0: loss = 0.000454059 (* 1 = 0.000454059 loss)
I0527 06:34:51.450079 30701 sgd_solver.cpp:105] Iteration 185100, lr = 0.000745
I0527 06:35:19.566627 30701 solver.cpp:218] Iteration 185200 (3.55672 iter/s, 28.1158s/100 iters), loss = 0.00088069
I0527 06:35:19.566671 30701 solver.cpp:237]     Train net output #0: loss = 0.000878789 (* 1 = 0.000878789 loss)
I0527 06:35:19.566680 30701 sgd_solver.cpp:105] Iteration 185200, lr = 0.00074
I0527 06:35:47.674243 30701 solver.cpp:218] Iteration 185300 (3.55786 iter/s, 28.1068s/100 iters), loss = 0.000219855
I0527 06:35:47.674453 30701 solver.cpp:237]     Train net output #0: loss = 0.000217954 (* 1 = 0.000217954 loss)
I0527 06:35:47.674468 30701 sgd_solver.cpp:105] Iteration 185300, lr = 0.000735
I0527 06:36:15.755762 30701 solver.cpp:218] Iteration 185400 (3.56118 iter/s, 28.0805s/100 iters), loss = 0.000178477
I0527 06:36:15.755815 30701 solver.cpp:237]     Train net output #0: loss = 0.000176575 (* 1 = 0.000176575 loss)
I0527 06:36:15.755825 30701 sgd_solver.cpp:105] Iteration 185400, lr = 0.00073
I0527 06:36:43.873558 30701 solver.cpp:218] Iteration 185500 (3.55657 iter/s, 28.1169s/100 iters), loss = 0.000162126
I0527 06:36:43.873769 30701 solver.cpp:237]     Train net output #0: loss = 0.000160224 (* 1 = 0.000160224 loss)
I0527 06:36:43.873780 30701 sgd_solver.cpp:105] Iteration 185500, lr = 0.000725
I0527 06:37:11.989997 30701 solver.cpp:218] Iteration 185600 (3.55676 iter/s, 28.1155s/100 iters), loss = 6.82536e-05
I0527 06:37:11.990042 30701 solver.cpp:237]     Train net output #0: loss = 6.6352e-05 (* 1 = 6.6352e-05 loss)
I0527 06:37:11.990051 30701 sgd_solver.cpp:105] Iteration 185600, lr = 0.00072
I0527 06:37:16.787614 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:37:40.094983 30701 solver.cpp:218] Iteration 185700 (3.55819 iter/s, 28.1042s/100 iters), loss = 0.000178525
I0527 06:37:40.095028 30701 solver.cpp:237]     Train net output #0: loss = 0.000176624 (* 1 = 0.000176624 loss)
I0527 06:37:40.095037 30701 sgd_solver.cpp:105] Iteration 185700, lr = 0.000715
I0527 06:38:08.189424 30701 solver.cpp:218] Iteration 185800 (3.55953 iter/s, 28.0936s/100 iters), loss = 0.000265541
I0527 06:38:08.189599 30701 solver.cpp:237]     Train net output #0: loss = 0.00026364 (* 1 = 0.00026364 loss)
I0527 06:38:08.189610 30701 sgd_solver.cpp:105] Iteration 185800, lr = 0.00071
I0527 06:38:36.266283 30701 solver.cpp:218] Iteration 185900 (3.56177 iter/s, 28.0759s/100 iters), loss = 0.000253968
I0527 06:38:36.266327 30701 solver.cpp:237]     Train net output #0: loss = 0.000252067 (* 1 = 0.000252067 loss)
I0527 06:38:36.266335 30701 sgd_solver.cpp:105] Iteration 185900, lr = 0.000705
I0527 06:39:04.076901 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_186000.caffemodel
I0527 06:39:04.389246 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_186000.solverstate
I0527 06:39:04.539090 30701 solver.cpp:330] Iteration 186000, Testing net (#0)
I0527 06:39:07.492960 30701 solver.cpp:397]     Test net output #0: accuracy = 0.804
I0527 06:39:07.493011 30701 solver.cpp:397]     Test net output #1: loss = 0.84666 (* 1 = 0.84666 loss)
I0527 06:39:07.770767 30701 solver.cpp:218] Iteration 186000 (3.17424 iter/s, 31.5036s/100 iters), loss = 0.000284074
I0527 06:39:07.770813 30701 solver.cpp:237]     Train net output #0: loss = 0.000282173 (* 1 = 0.000282173 loss)
I0527 06:39:07.770823 30701 sgd_solver.cpp:105] Iteration 186000, lr = 0.0007
I0527 06:39:35.905542 30701 solver.cpp:218] Iteration 186100 (3.55442 iter/s, 28.134s/100 iters), loss = 0.000975902
I0527 06:39:35.905751 30701 solver.cpp:237]     Train net output #0: loss = 0.000974 (* 1 = 0.000974 loss)
I0527 06:39:35.905762 30701 sgd_solver.cpp:105] Iteration 186100, lr = 0.000695
I0527 06:40:04.027459 30701 solver.cpp:218] Iteration 186200 (3.55607 iter/s, 28.121s/100 iters), loss = 0.000249258
I0527 06:40:04.027515 30701 solver.cpp:237]     Train net output #0: loss = 0.000247357 (* 1 = 0.000247357 loss)
I0527 06:40:04.027524 30701 sgd_solver.cpp:105] Iteration 186200, lr = 0.00069
I0527 06:40:06.291651 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:40:32.135601 30701 solver.cpp:218] Iteration 186300 (3.55779 iter/s, 28.1073s/100 iters), loss = 8.02895e-05
I0527 06:40:32.135644 30701 solver.cpp:237]     Train net output #0: loss = 7.83878e-05 (* 1 = 7.83878e-05 loss)
I0527 06:40:32.135653 30701 sgd_solver.cpp:105] Iteration 186300, lr = 0.000685
I0527 06:41:00.223306 30701 solver.cpp:218] Iteration 186400 (3.56038 iter/s, 28.0869s/100 iters), loss = 0.000347691
I0527 06:41:00.223455 30701 solver.cpp:237]     Train net output #0: loss = 0.00034579 (* 1 = 0.00034579 loss)
I0527 06:41:00.223464 30701 sgd_solver.cpp:105] Iteration 186400, lr = 0.00068
I0527 06:41:28.311700 30701 solver.cpp:218] Iteration 186500 (3.5603 iter/s, 28.0875s/100 iters), loss = 0.000120113
I0527 06:41:28.311755 30701 solver.cpp:237]     Train net output #0: loss = 0.000118211 (* 1 = 0.000118211 loss)
I0527 06:41:28.311764 30701 sgd_solver.cpp:105] Iteration 186500, lr = 0.000675
I0527 06:41:56.404139 30701 solver.cpp:218] Iteration 186600 (3.55978 iter/s, 28.0916s/100 iters), loss = 0.000142425
I0527 06:41:56.404332 30701 solver.cpp:237]     Train net output #0: loss = 0.000140524 (* 1 = 0.000140524 loss)
I0527 06:41:56.404356 30701 sgd_solver.cpp:105] Iteration 186600, lr = 0.00067
I0527 06:42:24.487319 30701 solver.cpp:218] Iteration 186700 (3.56097 iter/s, 28.0823s/100 iters), loss = 0.000176371
I0527 06:42:24.487363 30701 solver.cpp:237]     Train net output #0: loss = 0.00017447 (* 1 = 0.00017447 loss)
I0527 06:42:24.487372 30701 sgd_solver.cpp:105] Iteration 186700, lr = 0.000665
I0527 06:42:52.290541 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:42:52.557354 30701 solver.cpp:218] Iteration 186800 (3.56262 iter/s, 28.0693s/100 iters), loss = 0.00028677
I0527 06:42:52.557399 30701 solver.cpp:237]     Train net output #0: loss = 0.000284868 (* 1 = 0.000284868 loss)
I0527 06:42:52.557407 30701 sgd_solver.cpp:105] Iteration 186800, lr = 0.00066
I0527 06:43:20.616788 30701 solver.cpp:218] Iteration 186900 (3.56396 iter/s, 28.0587s/100 iters), loss = 0.00016682
I0527 06:43:20.616834 30701 solver.cpp:237]     Train net output #0: loss = 0.000164918 (* 1 = 0.000164918 loss)
I0527 06:43:20.616842 30701 sgd_solver.cpp:105] Iteration 186900, lr = 0.000655
I0527 06:43:48.424226 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_187000.caffemodel
I0527 06:43:48.735996 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_187000.solverstate
I0527 06:43:48.885962 30701 solver.cpp:330] Iteration 187000, Testing net (#0)
I0527 06:43:50.161012 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:43:51.842268 30701 solver.cpp:397]     Test net output #0: accuracy = 0.84
I0527 06:43:51.842319 30701 solver.cpp:397]     Test net output #1: loss = 0.757671 (* 1 = 0.757671 loss)
I0527 06:43:52.119726 30701 solver.cpp:218] Iteration 187000 (3.17439 iter/s, 31.5021s/100 iters), loss = 0.000210418
I0527 06:43:52.119771 30701 solver.cpp:237]     Train net output #0: loss = 0.000208516 (* 1 = 0.000208516 loss)
I0527 06:43:52.119779 30701 sgd_solver.cpp:105] Iteration 187000, lr = 0.00065
I0527 06:44:20.203130 30701 solver.cpp:218] Iteration 187100 (3.56092 iter/s, 28.0826s/100 iters), loss = 0.000159469
I0527 06:44:20.203323 30701 solver.cpp:237]     Train net output #0: loss = 0.000157567 (* 1 = 0.000157567 loss)
I0527 06:44:20.203336 30701 sgd_solver.cpp:105] Iteration 187100, lr = 0.000645
I0527 06:44:48.288789 30701 solver.cpp:218] Iteration 187200 (3.56065 iter/s, 28.0848s/100 iters), loss = 0.000466883
I0527 06:44:48.288835 30701 solver.cpp:237]     Train net output #0: loss = 0.000464981 (* 1 = 0.000464981 loss)
I0527 06:44:48.288843 30701 sgd_solver.cpp:105] Iteration 187200, lr = 0.00064
I0527 06:45:16.387449 30701 solver.cpp:218] Iteration 187300 (3.55898 iter/s, 28.0979s/100 iters), loss = 0.000644181
I0527 06:45:16.387624 30701 solver.cpp:237]     Train net output #0: loss = 0.000642279 (* 1 = 0.000642279 loss)
I0527 06:45:16.387651 30701 sgd_solver.cpp:105] Iteration 187300, lr = 0.000635
I0527 06:45:41.676532 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:45:44.467689 30701 solver.cpp:218] Iteration 187400 (3.56133 iter/s, 28.0794s/100 iters), loss = 0.00010776
I0527 06:45:44.467733 30701 solver.cpp:237]     Train net output #0: loss = 0.000105857 (* 1 = 0.000105857 loss)
I0527 06:45:44.467742 30701 sgd_solver.cpp:105] Iteration 187400, lr = 0.00063
I0527 06:46:12.527823 30701 solver.cpp:218] Iteration 187500 (3.56387 iter/s, 28.0594s/100 iters), loss = 0.000167669
I0527 06:46:12.527981 30701 solver.cpp:237]     Train net output #0: loss = 0.000165767 (* 1 = 0.000165767 loss)
I0527 06:46:12.527993 30701 sgd_solver.cpp:105] Iteration 187500, lr = 0.000625
I0527 06:46:40.644027 30701 solver.cpp:218] Iteration 187600 (3.55678 iter/s, 28.1153s/100 iters), loss = 0.000109194
I0527 06:46:40.644073 30701 solver.cpp:237]     Train net output #0: loss = 0.000107291 (* 1 = 0.000107291 loss)
I0527 06:46:40.644083 30701 sgd_solver.cpp:105] Iteration 187600, lr = 0.00062
I0527 06:47:08.751538 30701 solver.cpp:218] Iteration 187700 (3.55786 iter/s, 28.1068s/100 iters), loss = 5.71052e-05
I0527 06:47:08.751693 30701 solver.cpp:237]     Train net output #0: loss = 5.52026e-05 (* 1 = 5.52026e-05 loss)
I0527 06:47:08.751701 30701 sgd_solver.cpp:105] Iteration 187700, lr = 0.000615
I0527 06:47:36.839874 30701 solver.cpp:218] Iteration 187800 (3.5603 iter/s, 28.0875s/100 iters), loss = 0.000131109
I0527 06:47:36.839916 30701 solver.cpp:237]     Train net output #0: loss = 0.000129207 (* 1 = 0.000129207 loss)
I0527 06:47:36.839926 30701 sgd_solver.cpp:105] Iteration 187800, lr = 0.00061
I0527 06:48:04.944571 30701 solver.cpp:218] Iteration 187900 (3.55822 iter/s, 28.104s/100 iters), loss = 0.000159221
I0527 06:48:04.944725 30701 solver.cpp:237]     Train net output #0: loss = 0.000157319 (* 1 = 0.000157319 loss)
I0527 06:48:04.944736 30701 sgd_solver.cpp:105] Iteration 187900, lr = 0.000605
I0527 06:48:27.733278 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:48:32.784348 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_188000.caffemodel
I0527 06:48:33.097970 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_188000.solverstate
I0527 06:48:33.248152 30701 solver.cpp:330] Iteration 188000, Testing net (#0)
I0527 06:48:36.200266 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 06:48:36.200425 30701 solver.cpp:397]     Test net output #1: loss = 0.811764 (* 1 = 0.811764 loss)
I0527 06:48:36.478991 30701 solver.cpp:218] Iteration 188000 (3.17123 iter/s, 31.5335s/100 iters), loss = 0.000411046
I0527 06:48:36.479038 30701 solver.cpp:237]     Train net output #0: loss = 0.000409144 (* 1 = 0.000409144 loss)
I0527 06:48:36.479046 30701 sgd_solver.cpp:105] Iteration 188000, lr = 0.0006
I0527 06:49:04.586983 30701 solver.cpp:218] Iteration 188100 (3.5578 iter/s, 28.1072s/100 iters), loss = 0.000201988
I0527 06:49:04.587047 30701 solver.cpp:237]     Train net output #0: loss = 0.000200086 (* 1 = 0.000200086 loss)
I0527 06:49:04.587056 30701 sgd_solver.cpp:105] Iteration 188100, lr = 0.000595
I0527 06:49:32.719694 30701 solver.cpp:218] Iteration 188200 (3.55468 iter/s, 28.1319s/100 iters), loss = 0.000161334
I0527 06:49:32.719887 30701 solver.cpp:237]     Train net output #0: loss = 0.000159432 (* 1 = 0.000159432 loss)
I0527 06:49:32.719899 30701 sgd_solver.cpp:105] Iteration 188200, lr = 0.00059
I0527 06:50:00.787853 30701 solver.cpp:218] Iteration 188300 (3.56287 iter/s, 28.0673s/100 iters), loss = 0.00049743
I0527 06:50:00.787899 30701 solver.cpp:237]     Train net output #0: loss = 0.000495528 (* 1 = 0.000495528 loss)
I0527 06:50:00.787907 30701 sgd_solver.cpp:105] Iteration 188300, lr = 0.000585
I0527 06:50:28.853978 30701 solver.cpp:218] Iteration 188400 (3.56311 iter/s, 28.0654s/100 iters), loss = 0.000316124
I0527 06:50:28.854192 30701 solver.cpp:237]     Train net output #0: loss = 0.000314222 (* 1 = 0.000314222 loss)
I0527 06:50:28.854203 30701 sgd_solver.cpp:105] Iteration 188400, lr = 0.00058
I0527 06:50:56.938004 30701 solver.cpp:218] Iteration 188500 (3.56085 iter/s, 28.0832s/100 iters), loss = 0.000279312
I0527 06:50:56.938052 30701 solver.cpp:237]     Train net output #0: loss = 0.00027741 (* 1 = 0.00027741 loss)
I0527 06:50:56.938061 30701 sgd_solver.cpp:105] Iteration 188500, lr = 0.000575
I0527 06:51:17.179894 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:51:25.019357 30701 solver.cpp:218] Iteration 188600 (3.56118 iter/s, 28.0806s/100 iters), loss = 0.00019495
I0527 06:51:25.019400 30701 solver.cpp:237]     Train net output #0: loss = 0.000193049 (* 1 = 0.000193049 loss)
I0527 06:51:25.019408 30701 sgd_solver.cpp:105] Iteration 188600, lr = 0.00057
I0527 06:51:53.080384 30701 solver.cpp:218] Iteration 188700 (3.56375 iter/s, 28.0603s/100 iters), loss = 0.00137394
I0527 06:51:53.080569 30701 solver.cpp:237]     Train net output #0: loss = 0.00137204 (* 1 = 0.00137204 loss)
I0527 06:51:53.080592 30701 sgd_solver.cpp:105] Iteration 188700, lr = 0.000565
I0527 06:52:21.155895 30701 solver.cpp:218] Iteration 188800 (3.56193 iter/s, 28.0746s/100 iters), loss = 0.000204626
I0527 06:52:21.155939 30701 solver.cpp:237]     Train net output #0: loss = 0.000202725 (* 1 = 0.000202725 loss)
I0527 06:52:21.155951 30701 sgd_solver.cpp:105] Iteration 188800, lr = 0.00056
I0527 06:52:49.220037 30701 solver.cpp:218] Iteration 188900 (3.56336 iter/s, 28.0634s/100 iters), loss = 0.000146387
I0527 06:52:49.220345 30701 solver.cpp:237]     Train net output #0: loss = 0.000144486 (* 1 = 0.000144486 loss)
I0527 06:52:49.220355 30701 sgd_solver.cpp:105] Iteration 188900, lr = 0.000555
I0527 06:53:17.016288 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_189000.caffemodel
I0527 06:53:17.329656 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_189000.solverstate
I0527 06:53:17.480577 30701 solver.cpp:330] Iteration 189000, Testing net (#0)
I0527 06:53:20.430001 30701 solver.cpp:397]     Test net output #0: accuracy = 0.82
I0527 06:53:20.430131 30701 solver.cpp:397]     Test net output #1: loss = 0.763423 (* 1 = 0.763423 loss)
I0527 06:53:20.707839 30701 solver.cpp:218] Iteration 189000 (3.17594 iter/s, 31.4867s/100 iters), loss = 0.00017267
I0527 06:53:20.707885 30701 solver.cpp:237]     Train net output #0: loss = 0.000170769 (* 1 = 0.000170769 loss)
I0527 06:53:20.707895 30701 sgd_solver.cpp:105] Iteration 189000, lr = 0.00055
I0527 06:53:48.829613 30701 solver.cpp:218] Iteration 189100 (3.55606 iter/s, 28.121s/100 iters), loss = 0.000710062
I0527 06:53:48.829658 30701 solver.cpp:237]     Train net output #0: loss = 0.00070816 (* 1 = 0.00070816 loss)
I0527 06:53:48.829665 30701 sgd_solver.cpp:105] Iteration 189100, lr = 0.000545
I0527 06:54:06.574421 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:54:16.957135 30701 solver.cpp:218] Iteration 189200 (3.55533 iter/s, 28.1268s/100 iters), loss = 0.000111172
I0527 06:54:16.957181 30701 solver.cpp:237]     Train net output #0: loss = 0.000109271 (* 1 = 0.000109271 loss)
I0527 06:54:16.957190 30701 sgd_solver.cpp:105] Iteration 189200, lr = 0.00054
I0527 06:54:45.049036 30701 solver.cpp:218] Iteration 189300 (3.55984 iter/s, 28.0912s/100 iters), loss = 0.000139263
I0527 06:54:45.049223 30701 solver.cpp:237]     Train net output #0: loss = 0.000137361 (* 1 = 0.000137361 loss)
I0527 06:54:45.049235 30701 sgd_solver.cpp:105] Iteration 189300, lr = 0.000535
I0527 06:55:13.138447 30701 solver.cpp:218] Iteration 189400 (3.56017 iter/s, 28.0885s/100 iters), loss = 0.000335027
I0527 06:55:13.138509 30701 solver.cpp:237]     Train net output #0: loss = 0.000333126 (* 1 = 0.000333126 loss)
I0527 06:55:13.138520 30701 sgd_solver.cpp:105] Iteration 189400, lr = 0.00053
I0527 06:55:41.227403 30701 solver.cpp:218] Iteration 189500 (3.56021 iter/s, 28.0882s/100 iters), loss = 0.000511679
I0527 06:55:41.227563 30701 solver.cpp:237]     Train net output #0: loss = 0.000509778 (* 1 = 0.000509778 loss)
I0527 06:55:41.227576 30701 sgd_solver.cpp:105] Iteration 189500, lr = 0.000525
I0527 06:56:09.323288 30701 solver.cpp:218] Iteration 189600 (3.55935 iter/s, 28.0951s/100 iters), loss = 9.34868e-05
I0527 06:56:09.323333 30701 solver.cpp:237]     Train net output #0: loss = 9.1586e-05 (* 1 = 9.1586e-05 loss)
I0527 06:56:09.323343 30701 sgd_solver.cpp:105] Iteration 189600, lr = 0.00052
I0527 06:56:37.415405 30701 solver.cpp:218] Iteration 189700 (3.55981 iter/s, 28.0914s/100 iters), loss = 0.000610104
I0527 06:56:37.415570 30701 solver.cpp:237]     Train net output #0: loss = 0.000608204 (* 1 = 0.000608204 loss)
I0527 06:56:37.415581 30701 sgd_solver.cpp:105] Iteration 189700, lr = 0.000515
I0527 06:56:52.871899 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:57:05.505758 30701 solver.cpp:218] Iteration 189800 (3.56005 iter/s, 28.0895s/100 iters), loss = 0.00018435
I0527 06:57:05.505803 30701 solver.cpp:237]     Train net output #0: loss = 0.000182449 (* 1 = 0.000182449 loss)
I0527 06:57:05.505811 30701 sgd_solver.cpp:105] Iteration 189800, lr = 0.00051
I0527 06:57:33.592533 30701 solver.cpp:218] Iteration 189900 (3.56049 iter/s, 28.0861s/100 iters), loss = 0.000153291
I0527 06:57:33.592697 30701 solver.cpp:237]     Train net output #0: loss = 0.00015139 (* 1 = 0.00015139 loss)
I0527 06:57:33.592710 30701 sgd_solver.cpp:105] Iteration 189900, lr = 0.000505
I0527 06:58:01.395202 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_190000.caffemodel
I0527 06:58:01.709357 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_190000.solverstate
I0527 06:58:01.860394 30701 solver.cpp:330] Iteration 190000, Testing net (#0)
I0527 06:58:01.862598 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:58:04.810945 30701 solver.cpp:397]     Test net output #0: accuracy = 0.836
I0527 06:58:04.811157 30701 solver.cpp:397]     Test net output #1: loss = 0.834 (* 1 = 0.834 loss)
I0527 06:58:05.090749 30701 solver.cpp:218] Iteration 190000 (3.17488 iter/s, 31.4973s/100 iters), loss = 6.98818e-05
I0527 06:58:05.090806 30701 solver.cpp:237]     Train net output #0: loss = 6.79812e-05 (* 1 = 6.79812e-05 loss)
I0527 06:58:05.090816 30701 sgd_solver.cpp:105] Iteration 190000, lr = 0.0005
I0527 06:58:33.223834 30701 solver.cpp:218] Iteration 190100 (3.55463 iter/s, 28.1324s/100 iters), loss = 0.000279296
I0527 06:58:33.223889 30701 solver.cpp:237]     Train net output #0: loss = 0.000277395 (* 1 = 0.000277395 loss)
I0527 06:58:33.223898 30701 sgd_solver.cpp:105] Iteration 190100, lr = 0.000495
I0527 06:59:01.340891 30701 solver.cpp:218] Iteration 190200 (3.55665 iter/s, 28.1163s/100 iters), loss = 9.35927e-05
I0527 06:59:01.341064 30701 solver.cpp:237]     Train net output #0: loss = 9.1692e-05 (* 1 = 9.1692e-05 loss)
I0527 06:59:01.341075 30701 sgd_solver.cpp:105] Iteration 190200, lr = 0.00049
I0527 06:59:29.440218 30701 solver.cpp:218] Iteration 190300 (3.55891 iter/s, 28.0985s/100 iters), loss = 0.000112539
I0527 06:59:29.440263 30701 solver.cpp:237]     Train net output #0: loss = 0.000110639 (* 1 = 0.000110639 loss)
I0527 06:59:29.440273 30701 sgd_solver.cpp:105] Iteration 190300, lr = 0.000485
I0527 06:59:42.379451 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 06:59:57.531443 30701 solver.cpp:218] Iteration 190400 (3.55992 iter/s, 28.0905s/100 iters), loss = 0.000220636
I0527 06:59:57.531488 30701 solver.cpp:237]     Train net output #0: loss = 0.000218736 (* 1 = 0.000218736 loss)
I0527 06:59:57.531497 30701 sgd_solver.cpp:105] Iteration 190400, lr = 0.00048
I0527 07:00:25.613557 30701 solver.cpp:218] Iteration 190500 (3.56108 iter/s, 28.0814s/100 iters), loss = 0.000209659
I0527 07:00:25.613734 30701 solver.cpp:237]     Train net output #0: loss = 0.000207759 (* 1 = 0.000207759 loss)
I0527 07:00:25.613744 30701 sgd_solver.cpp:105] Iteration 190500, lr = 0.000475
I0527 07:00:53.709918 30701 solver.cpp:218] Iteration 190600 (3.55929 iter/s, 28.0955s/100 iters), loss = 0.000138389
I0527 07:00:53.709966 30701 solver.cpp:237]     Train net output #0: loss = 0.000136489 (* 1 = 0.000136489 loss)
I0527 07:00:53.709975 30701 sgd_solver.cpp:105] Iteration 190600, lr = 0.00047
I0527 07:01:21.827409 30701 solver.cpp:218] Iteration 190700 (3.5566 iter/s, 28.1168s/100 iters), loss = 0.000165667
I0527 07:01:21.827534 30701 solver.cpp:237]     Train net output #0: loss = 0.000163767 (* 1 = 0.000163767 loss)
I0527 07:01:21.827558 30701 sgd_solver.cpp:105] Iteration 190700, lr = 0.000465
I0527 07:01:49.933703 30701 solver.cpp:218] Iteration 190800 (3.55802 iter/s, 28.1055s/100 iters), loss = 0.000353304
I0527 07:01:49.933748 30701 solver.cpp:237]     Train net output #0: loss = 0.000351404 (* 1 = 0.000351404 loss)
I0527 07:01:49.933758 30701 sgd_solver.cpp:105] Iteration 190800, lr = 0.00046
I0527 07:02:18.039031 30701 solver.cpp:218] Iteration 190900 (3.55814 iter/s, 28.1046s/100 iters), loss = 0.00015565
I0527 07:02:18.039198 30701 solver.cpp:237]     Train net output #0: loss = 0.000153749 (* 1 = 0.000153749 loss)
I0527 07:02:18.039209 30701 sgd_solver.cpp:105] Iteration 190900, lr = 0.000455
I0527 07:02:28.456332 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:02:45.878111 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_191000.caffemodel
I0527 07:02:46.193976 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_191000.solverstate
I0527 07:02:46.345867 30701 solver.cpp:330] Iteration 191000, Testing net (#0)
I0527 07:02:49.293251 30701 solver.cpp:397]     Test net output #0: accuracy = 0.802
I0527 07:02:49.293442 30701 solver.cpp:397]     Test net output #1: loss = 0.873862 (* 1 = 0.873862 loss)
I0527 07:02:49.571430 30701 solver.cpp:218] Iteration 191000 (3.17143 iter/s, 31.5315s/100 iters), loss = 0.000671586
I0527 07:02:49.571477 30701 solver.cpp:237]     Train net output #0: loss = 0.000669685 (* 1 = 0.000669685 loss)
I0527 07:02:49.571486 30701 sgd_solver.cpp:105] Iteration 191000, lr = 0.00045
I0527 07:03:17.663594 30701 solver.cpp:218] Iteration 191100 (3.5598 iter/s, 28.0914s/100 iters), loss = 0.000286148
I0527 07:03:17.663645 30701 solver.cpp:237]     Train net output #0: loss = 0.000284248 (* 1 = 0.000284248 loss)
I0527 07:03:17.663666 30701 sgd_solver.cpp:105] Iteration 191100, lr = 0.000445
I0527 07:03:45.748554 30701 solver.cpp:218] Iteration 191200 (3.56072 iter/s, 28.0842s/100 iters), loss = 0.00059273
I0527 07:03:45.748718 30701 solver.cpp:237]     Train net output #0: loss = 0.000590829 (* 1 = 0.000590829 loss)
I0527 07:03:45.748729 30701 sgd_solver.cpp:105] Iteration 191200, lr = 0.00044
I0527 07:04:13.847898 30701 solver.cpp:218] Iteration 191300 (3.55891 iter/s, 28.0985s/100 iters), loss = 0.000136484
I0527 07:04:13.847955 30701 solver.cpp:237]     Train net output #0: loss = 0.000134583 (* 1 = 0.000134583 loss)
I0527 07:04:13.847967 30701 sgd_solver.cpp:105] Iteration 191300, lr = 0.000435
I0527 07:04:41.936118 30701 solver.cpp:218] Iteration 191400 (3.5603 iter/s, 28.0875s/100 iters), loss = 0.000329033
I0527 07:04:41.936332 30701 solver.cpp:237]     Train net output #0: loss = 0.000327132 (* 1 = 0.000327132 loss)
I0527 07:04:41.936348 30701 sgd_solver.cpp:105] Iteration 191400, lr = 0.00043
I0527 07:05:10.025296 30701 solver.cpp:218] Iteration 191500 (3.56023 iter/s, 28.088s/100 iters), loss = 0.000366234
I0527 07:05:10.025344 30701 solver.cpp:237]     Train net output #0: loss = 0.000364333 (* 1 = 0.000364333 loss)
I0527 07:05:10.025353 30701 sgd_solver.cpp:105] Iteration 191500, lr = 0.000425
I0527 07:05:17.917232 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:05:38.122262 30701 solver.cpp:218] Iteration 191600 (3.55923 iter/s, 28.096s/100 iters), loss = 0.000235218
I0527 07:05:38.122308 30701 solver.cpp:237]     Train net output #0: loss = 0.000233318 (* 1 = 0.000233318 loss)
I0527 07:05:38.122316 30701 sgd_solver.cpp:105] Iteration 191600, lr = 0.00042
I0527 07:06:06.214229 30701 solver.cpp:218] Iteration 191700 (3.55986 iter/s, 28.091s/100 iters), loss = 0.000129345
I0527 07:06:06.214378 30701 solver.cpp:237]     Train net output #0: loss = 0.000127444 (* 1 = 0.000127444 loss)
I0527 07:06:06.214388 30701 sgd_solver.cpp:105] Iteration 191700, lr = 0.000415
I0527 07:06:34.289527 30701 solver.cpp:218] Iteration 191800 (3.56199 iter/s, 28.0742s/100 iters), loss = 0.000109876
I0527 07:06:34.289575 30701 solver.cpp:237]     Train net output #0: loss = 0.000107975 (* 1 = 0.000107975 loss)
I0527 07:06:34.289584 30701 sgd_solver.cpp:105] Iteration 191800, lr = 0.00041
I0527 07:07:02.383764 30701 solver.cpp:218] Iteration 191900 (3.55957 iter/s, 28.0933s/100 iters), loss = 0.000897097
I0527 07:07:02.384023 30701 solver.cpp:237]     Train net output #0: loss = 0.000895197 (* 1 = 0.000895197 loss)
I0527 07:07:02.384042 30701 sgd_solver.cpp:105] Iteration 191900, lr = 0.000405
I0527 07:07:30.209499 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_192000.caffemodel
I0527 07:07:30.551328 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_192000.solverstate
I0527 07:07:30.701609 30701 solver.cpp:330] Iteration 192000, Testing net (#0)
I0527 07:07:32.354221 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:07:33.648525 30701 solver.cpp:397]     Test net output #0: accuracy = 0.842
I0527 07:07:33.648803 30701 solver.cpp:397]     Test net output #1: loss = 0.712029 (* 1 = 0.712029 loss)
I0527 07:07:33.926290 30701 solver.cpp:218] Iteration 192000 (3.17045 iter/s, 31.5413s/100 iters), loss = 0.000353417
I0527 07:07:33.926337 30701 solver.cpp:237]     Train net output #0: loss = 0.000351516 (* 1 = 0.000351516 loss)
I0527 07:07:33.926345 30701 sgd_solver.cpp:105] Iteration 192000, lr = 0.0004
I0527 07:08:02.004103 30701 solver.cpp:218] Iteration 192100 (3.56165 iter/s, 28.0769s/100 iters), loss = 0.000249786
I0527 07:08:02.004148 30701 solver.cpp:237]     Train net output #0: loss = 0.000247886 (* 1 = 0.000247886 loss)
I0527 07:08:02.004156 30701 sgd_solver.cpp:105] Iteration 192100, lr = 0.000395
I0527 07:08:07.358198 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:08:30.088418 30701 solver.cpp:218] Iteration 192200 (3.56082 iter/s, 28.0834s/100 iters), loss = 0.000404059
I0527 07:08:30.088464 30701 solver.cpp:237]     Train net output #0: loss = 0.000402159 (* 1 = 0.000402159 loss)
I0527 07:08:30.088472 30701 sgd_solver.cpp:105] Iteration 192200, lr = 0.00039
I0527 07:08:58.162665 30701 solver.cpp:218] Iteration 192300 (3.5621 iter/s, 28.0733s/100 iters), loss = 0.000263759
I0527 07:08:58.162817 30701 solver.cpp:237]     Train net output #0: loss = 0.000261859 (* 1 = 0.000261859 loss)
I0527 07:08:58.162828 30701 sgd_solver.cpp:105] Iteration 192300, lr = 0.000385
I0527 07:09:26.285158 30701 solver.cpp:218] Iteration 192400 (3.556 iter/s, 28.1215s/100 iters), loss = 0.000258661
I0527 07:09:26.285204 30701 solver.cpp:237]     Train net output #0: loss = 0.00025676 (* 1 = 0.00025676 loss)
I0527 07:09:26.285214 30701 sgd_solver.cpp:105] Iteration 192400, lr = 0.00038
I0527 07:09:54.405964 30701 solver.cpp:218] Iteration 192500 (3.5562 iter/s, 28.1199s/100 iters), loss = 0.000335981
I0527 07:09:54.406126 30701 solver.cpp:237]     Train net output #0: loss = 0.00033408 (* 1 = 0.00033408 loss)
I0527 07:09:54.406137 30701 sgd_solver.cpp:105] Iteration 192500, lr = 0.000375
I0527 07:10:22.525712 30701 solver.cpp:218] Iteration 192600 (3.55635 iter/s, 28.1187s/100 iters), loss = 6.43418e-05
I0527 07:10:22.525758 30701 solver.cpp:237]     Train net output #0: loss = 6.24418e-05 (* 1 = 6.24418e-05 loss)
I0527 07:10:22.525766 30701 sgd_solver.cpp:105] Iteration 192600, lr = 0.00037
I0527 07:10:50.645828 30701 solver.cpp:218] Iteration 192700 (3.55629 iter/s, 28.1192s/100 iters), loss = 0.000701071
I0527 07:10:50.646026 30701 solver.cpp:237]     Train net output #0: loss = 0.000699171 (* 1 = 0.000699171 loss)
I0527 07:10:50.646037 30701 sgd_solver.cpp:105] Iteration 192700, lr = 0.000365
I0527 07:10:53.479614 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:11:18.781527 30701 solver.cpp:218] Iteration 192800 (3.55433 iter/s, 28.1347s/100 iters), loss = 0.000176207
I0527 07:11:18.781571 30701 solver.cpp:237]     Train net output #0: loss = 0.000174307 (* 1 = 0.000174307 loss)
I0527 07:11:18.781580 30701 sgd_solver.cpp:105] Iteration 192800, lr = 0.00036
I0527 07:11:46.908603 30701 solver.cpp:218] Iteration 192900 (3.5554 iter/s, 28.1262s/100 iters), loss = 0.000191928
I0527 07:11:46.908841 30701 solver.cpp:237]     Train net output #0: loss = 0.000190027 (* 1 = 0.000190027 loss)
I0527 07:11:46.908857 30701 sgd_solver.cpp:105] Iteration 192900, lr = 0.000355
I0527 07:12:14.758270 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_193000.caffemodel
I0527 07:12:15.105731 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_193000.solverstate
I0527 07:12:15.301271 30701 solver.cpp:330] Iteration 193000, Testing net (#0)
I0527 07:12:18.250279 30701 solver.cpp:397]     Test net output #0: accuracy = 0.822
I0527 07:12:18.250423 30701 solver.cpp:397]     Test net output #1: loss = 0.85779 (* 1 = 0.85779 loss)
I0527 07:12:18.528131 30701 solver.cpp:218] Iteration 193000 (3.16272 iter/s, 31.6184s/100 iters), loss = 0.000110803
I0527 07:12:18.528188 30701 solver.cpp:237]     Train net output #0: loss = 0.000108903 (* 1 = 0.000108903 loss)
I0527 07:12:18.528198 30701 sgd_solver.cpp:105] Iteration 193000, lr = 0.00035
I0527 07:12:46.645653 30701 solver.cpp:218] Iteration 193100 (3.55661 iter/s, 28.1166s/100 iters), loss = 0.000269237
I0527 07:12:46.645697 30701 solver.cpp:237]     Train net output #0: loss = 0.000267337 (* 1 = 0.000267337 loss)
I0527 07:12:46.645706 30701 sgd_solver.cpp:105] Iteration 193100, lr = 0.000345
I0527 07:13:14.762915 30701 solver.cpp:218] Iteration 193200 (3.55664 iter/s, 28.1164s/100 iters), loss = 0.000470024
I0527 07:13:14.763073 30701 solver.cpp:237]     Train net output #0: loss = 0.000468124 (* 1 = 0.000468124 loss)
I0527 07:13:14.763087 30701 sgd_solver.cpp:105] Iteration 193200, lr = 0.00034
I0527 07:13:42.889917 30701 solver.cpp:218] Iteration 193300 (3.55542 iter/s, 28.126s/100 iters), loss = 0.000213098
I0527 07:13:42.889962 30701 solver.cpp:237]     Train net output #0: loss = 0.000211199 (* 1 = 0.000211199 loss)
I0527 07:13:42.889971 30701 sgd_solver.cpp:105] Iteration 193300, lr = 0.000335
I0527 07:13:43.467425 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:14:10.984539 30701 solver.cpp:218] Iteration 193400 (3.55951 iter/s, 28.0938s/100 iters), loss = 0.000330364
I0527 07:14:10.984683 30701 solver.cpp:237]     Train net output #0: loss = 0.000328464 (* 1 = 0.000328464 loss)
I0527 07:14:10.984694 30701 sgd_solver.cpp:105] Iteration 193400, lr = 0.00033
I0527 07:14:39.067828 30701 solver.cpp:218] Iteration 193500 (3.56095 iter/s, 28.0824s/100 iters), loss = 0.000151584
I0527 07:14:39.067875 30701 solver.cpp:237]     Train net output #0: loss = 0.000149684 (* 1 = 0.000149684 loss)
I0527 07:14:39.067883 30701 sgd_solver.cpp:105] Iteration 193500, lr = 0.000325
I0527 07:15:07.166689 30701 solver.cpp:218] Iteration 193600 (3.55897 iter/s, 28.098s/100 iters), loss = 0.000177675
I0527 07:15:07.166848 30701 solver.cpp:237]     Train net output #0: loss = 0.000175776 (* 1 = 0.000175776 loss)
I0527 07:15:07.166860 30701 sgd_solver.cpp:105] Iteration 193600, lr = 0.00032
I0527 07:15:35.276231 30701 solver.cpp:218] Iteration 193700 (3.55763 iter/s, 28.1086s/100 iters), loss = 0.000396229
I0527 07:15:35.276273 30701 solver.cpp:237]     Train net output #0: loss = 0.000394329 (* 1 = 0.000394329 loss)
I0527 07:15:35.276280 30701 sgd_solver.cpp:105] Iteration 193700, lr = 0.000315
I0527 07:16:03.360395 30701 solver.cpp:218] Iteration 193800 (3.56083 iter/s, 28.0833s/100 iters), loss = 0.000173058
I0527 07:16:03.360635 30701 solver.cpp:237]     Train net output #0: loss = 0.000171158 (* 1 = 0.000171158 loss)
I0527 07:16:03.360647 30701 sgd_solver.cpp:105] Iteration 193800, lr = 0.00031
I0527 07:16:29.501869 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:16:31.455211 30701 solver.cpp:218] Iteration 193900 (3.5595 iter/s, 28.0938s/100 iters), loss = 8.03265e-05
I0527 07:16:31.455256 30701 solver.cpp:237]     Train net output #0: loss = 7.84266e-05 (* 1 = 7.84266e-05 loss)
I0527 07:16:31.455265 30701 sgd_solver.cpp:105] Iteration 193900, lr = 0.000305
I0527 07:16:59.292080 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_194000.caffemodel
I0527 07:16:59.651015 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_194000.solverstate
I0527 07:16:59.802192 30701 solver.cpp:330] Iteration 194000, Testing net (#0)
I0527 07:17:02.738045 30701 solver.cpp:397]     Test net output #0: accuracy = 0.826
I0527 07:17:02.738081 30701 solver.cpp:397]     Test net output #1: loss = 0.767615 (* 1 = 0.767615 loss)
I0527 07:17:03.015877 30701 solver.cpp:218] Iteration 194000 (3.16859 iter/s, 31.5598s/100 iters), loss = 0.000312126
I0527 07:17:03.015923 30701 solver.cpp:237]     Train net output #0: loss = 0.000310226 (* 1 = 0.000310226 loss)
I0527 07:17:03.015933 30701 sgd_solver.cpp:105] Iteration 194000, lr = 0.0003
I0527 07:17:31.120241 30701 solver.cpp:218] Iteration 194100 (3.55827 iter/s, 28.1035s/100 iters), loss = 0.000336416
I0527 07:17:31.120398 30701 solver.cpp:237]     Train net output #0: loss = 0.000334516 (* 1 = 0.000334516 loss)
I0527 07:17:31.120410 30701 sgd_solver.cpp:105] Iteration 194100, lr = 0.000295
I0527 07:17:59.219883 30701 solver.cpp:218] Iteration 194200 (3.55888 iter/s, 28.0987s/100 iters), loss = 0.000334938
I0527 07:17:59.219943 30701 solver.cpp:237]     Train net output #0: loss = 0.000333038 (* 1 = 0.000333038 loss)
I0527 07:17:59.219955 30701 sgd_solver.cpp:105] Iteration 194200, lr = 0.00029
I0527 07:18:27.322808 30701 solver.cpp:218] Iteration 194300 (3.55845 iter/s, 28.1021s/100 iters), loss = 0.00027453
I0527 07:18:27.322979 30701 solver.cpp:237]     Train net output #0: loss = 0.00027263 (* 1 = 0.00027263 loss)
I0527 07:18:27.322990 30701 sgd_solver.cpp:105] Iteration 194300, lr = 0.000285
I0527 07:18:55.424125 30701 solver.cpp:218] Iteration 194400 (3.55867 iter/s, 28.1004s/100 iters), loss = 0.00012522
I0527 07:18:55.424170 30701 solver.cpp:237]     Train net output #0: loss = 0.00012332 (* 1 = 0.00012332 loss)
I0527 07:18:55.424178 30701 sgd_solver.cpp:105] Iteration 194400, lr = 0.00028
I0527 07:19:19.032888 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:19:23.507246 30701 solver.cpp:218] Iteration 194500 (3.56096 iter/s, 28.0823s/100 iters), loss = 0.000573153
I0527 07:19:23.507293 30701 solver.cpp:237]     Train net output #0: loss = 0.000571253 (* 1 = 0.000571253 loss)
I0527 07:19:23.507302 30701 sgd_solver.cpp:105] Iteration 194500, lr = 0.000275
I0527 07:19:51.597914 30701 solver.cpp:218] Iteration 194600 (3.56 iter/s, 28.0899s/100 iters), loss = 0.00167204
I0527 07:19:51.598062 30701 solver.cpp:237]     Train net output #0: loss = 0.00167014 (* 1 = 0.00167014 loss)
I0527 07:19:51.598074 30701 sgd_solver.cpp:105] Iteration 194600, lr = 0.00027
I0527 07:20:19.687952 30701 solver.cpp:218] Iteration 194700 (3.5601 iter/s, 28.0891s/100 iters), loss = 8.97523e-05
I0527 07:20:19.688015 30701 solver.cpp:237]     Train net output #0: loss = 8.7852e-05 (* 1 = 8.7852e-05 loss)
I0527 07:20:19.688024 30701 sgd_solver.cpp:105] Iteration 194700, lr = 0.000265
I0527 07:20:47.769840 30701 solver.cpp:218] Iteration 194800 (3.56112 iter/s, 28.0811s/100 iters), loss = 0.000266379
I0527 07:20:47.770042 30701 solver.cpp:237]     Train net output #0: loss = 0.000264478 (* 1 = 0.000264478 loss)
I0527 07:20:47.770053 30701 sgd_solver.cpp:105] Iteration 194800, lr = 0.00026
I0527 07:21:15.855980 30701 solver.cpp:218] Iteration 194900 (3.56059 iter/s, 28.0852s/100 iters), loss = 0.000243817
I0527 07:21:15.856037 30701 solver.cpp:237]     Train net output #0: loss = 0.000241916 (* 1 = 0.000241916 loss)
I0527 07:21:15.856046 30701 sgd_solver.cpp:105] Iteration 194900, lr = 0.000255
I0527 07:21:43.646364 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_195000.caffemodel
I0527 07:21:43.963563 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_195000.solverstate
I0527 07:21:44.115329 30701 solver.cpp:330] Iteration 195000, Testing net (#0)
I0527 07:21:44.503396 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:21:47.068836 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 07:21:47.068887 30701 solver.cpp:397]     Test net output #1: loss = 0.812664 (* 1 = 0.812664 loss)
I0527 07:21:47.346679 30701 solver.cpp:218] Iteration 195000 (3.17563 iter/s, 31.4898s/100 iters), loss = 0.000168964
I0527 07:21:47.346721 30701 solver.cpp:237]     Train net output #0: loss = 0.000167063 (* 1 = 0.000167063 loss)
I0527 07:21:47.346730 30701 sgd_solver.cpp:105] Iteration 195000, lr = 0.00025
I0527 07:22:08.440592 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:22:15.448390 30701 solver.cpp:218] Iteration 195100 (3.5586 iter/s, 28.1009s/100 iters), loss = 0.000222297
I0527 07:22:15.448684 30701 solver.cpp:237]     Train net output #0: loss = 0.000220396 (* 1 = 0.000220396 loss)
I0527 07:22:15.448695 30701 sgd_solver.cpp:105] Iteration 195100, lr = 0.000245
I0527 07:22:43.537525 30701 solver.cpp:218] Iteration 195200 (3.56023 iter/s, 28.0881s/100 iters), loss = 0.000168616
I0527 07:22:43.537569 30701 solver.cpp:237]     Train net output #0: loss = 0.000166716 (* 1 = 0.000166716 loss)
I0527 07:22:43.537577 30701 sgd_solver.cpp:105] Iteration 195200, lr = 0.00024
I0527 07:23:11.614642 30701 solver.cpp:218] Iteration 195300 (3.56172 iter/s, 28.0763s/100 iters), loss = 0.000126679
I0527 07:23:11.614862 30701 solver.cpp:237]     Train net output #0: loss = 0.000124779 (* 1 = 0.000124779 loss)
I0527 07:23:11.614873 30701 sgd_solver.cpp:105] Iteration 195300, lr = 0.000235
I0527 07:23:39.705807 30701 solver.cpp:218] Iteration 195400 (3.55996 iter/s, 28.0902s/100 iters), loss = 0.000185671
I0527 07:23:39.705858 30701 solver.cpp:237]     Train net output #0: loss = 0.000183771 (* 1 = 0.000183771 loss)
I0527 07:23:39.705868 30701 sgd_solver.cpp:105] Iteration 195400, lr = 0.00023
I0527 07:24:07.790763 30701 solver.cpp:218] Iteration 195500 (3.56072 iter/s, 28.0842s/100 iters), loss = 0.000394329
I0527 07:24:07.790967 30701 solver.cpp:237]     Train net output #0: loss = 0.000392429 (* 1 = 0.000392429 loss)
I0527 07:24:07.790979 30701 sgd_solver.cpp:105] Iteration 195500, lr = 0.000225
I0527 07:24:35.878495 30701 solver.cpp:218] Iteration 195600 (3.56039 iter/s, 28.0868s/100 iters), loss = 0.00045122
I0527 07:24:35.878538 30701 solver.cpp:237]     Train net output #0: loss = 0.000449319 (* 1 = 0.000449319 loss)
I0527 07:24:35.878546 30701 sgd_solver.cpp:105] Iteration 195600, lr = 0.00022
I0527 07:24:54.454998 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:25:03.996620 30701 solver.cpp:218] Iteration 195700 (3.55652 iter/s, 28.1174s/100 iters), loss = 0.000306647
I0527 07:25:03.996666 30701 solver.cpp:237]     Train net output #0: loss = 0.000304746 (* 1 = 0.000304746 loss)
I0527 07:25:03.996675 30701 sgd_solver.cpp:105] Iteration 195700, lr = 0.000215
I0527 07:25:32.112749 30701 solver.cpp:218] Iteration 195800 (3.55677 iter/s, 28.1154s/100 iters), loss = 0.00027612
I0527 07:25:32.113001 30701 solver.cpp:237]     Train net output #0: loss = 0.00027422 (* 1 = 0.00027422 loss)
I0527 07:25:32.113023 30701 sgd_solver.cpp:105] Iteration 195800, lr = 0.00021
I0527 07:26:00.233570 30701 solver.cpp:218] Iteration 195900 (3.55621 iter/s, 28.1199s/100 iters), loss = 0.000206995
I0527 07:26:00.233616 30701 solver.cpp:237]     Train net output #0: loss = 0.000205095 (* 1 = 0.000205095 loss)
I0527 07:26:00.233624 30701 sgd_solver.cpp:105] Iteration 195900, lr = 0.000205
I0527 07:26:28.077114 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_196000.caffemodel
I0527 07:26:28.424521 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_196000.solverstate
I0527 07:26:28.575212 30701 solver.cpp:330] Iteration 196000, Testing net (#0)
I0527 07:26:31.532588 30701 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0527 07:26:31.532629 30701 solver.cpp:397]     Test net output #1: loss = 0.896355 (* 1 = 0.896355 loss)
I0527 07:26:31.810963 30701 solver.cpp:218] Iteration 196000 (3.16691 iter/s, 31.5765s/100 iters), loss = 0.00026404
I0527 07:26:31.811012 30701 solver.cpp:237]     Train net output #0: loss = 0.000262139 (* 1 = 0.000262139 loss)
I0527 07:26:31.811019 30701 sgd_solver.cpp:105] Iteration 196000, lr = 0.0002
I0527 07:26:59.931951 30701 solver.cpp:218] Iteration 196100 (3.55616 iter/s, 28.1202s/100 iters), loss = 0.0010721
I0527 07:26:59.932118 30701 solver.cpp:237]     Train net output #0: loss = 0.0010702 (* 1 = 0.0010702 loss)
I0527 07:26:59.932132 30701 sgd_solver.cpp:105] Iteration 196100, lr = 0.000195
I0527 07:27:28.078070 30701 solver.cpp:218] Iteration 196200 (3.553 iter/s, 28.1452s/100 iters), loss = 0.000258858
I0527 07:27:28.078114 30701 solver.cpp:237]     Train net output #0: loss = 0.000256958 (* 1 = 0.000256958 loss)
I0527 07:27:28.078124 30701 sgd_solver.cpp:105] Iteration 196200, lr = 0.00019
I0527 07:27:44.128193 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:27:56.203215 30701 solver.cpp:218] Iteration 196300 (3.55563 iter/s, 28.1244s/100 iters), loss = 0.000796927
I0527 07:27:56.203274 30701 solver.cpp:237]     Train net output #0: loss = 0.000795027 (* 1 = 0.000795027 loss)
I0527 07:27:56.203284 30701 sgd_solver.cpp:105] Iteration 196300, lr = 0.000185
I0527 07:28:24.333088 30701 solver.cpp:218] Iteration 196400 (3.55504 iter/s, 28.1291s/100 iters), loss = 0.00043187
I0527 07:28:24.333287 30701 solver.cpp:237]     Train net output #0: loss = 0.00042997 (* 1 = 0.00042997 loss)
I0527 07:28:24.333297 30701 sgd_solver.cpp:105] Iteration 196400, lr = 0.00018
I0527 07:28:52.434607 30701 solver.cpp:218] Iteration 196500 (3.55864 iter/s, 28.1006s/100 iters), loss = 0.000669321
I0527 07:28:52.434656 30701 solver.cpp:237]     Train net output #0: loss = 0.000667422 (* 1 = 0.000667422 loss)
I0527 07:28:52.434669 30701 sgd_solver.cpp:105] Iteration 196500, lr = 0.000175
I0527 07:29:20.499434 30701 solver.cpp:218] Iteration 196600 (3.56328 iter/s, 28.0641s/100 iters), loss = 0.000729171
I0527 07:29:20.499588 30701 solver.cpp:237]     Train net output #0: loss = 0.000727271 (* 1 = 0.000727271 loss)
I0527 07:29:20.499603 30701 sgd_solver.cpp:105] Iteration 196600, lr = 0.00017
I0527 07:29:48.570016 30701 solver.cpp:218] Iteration 196700 (3.56256 iter/s, 28.0697s/100 iters), loss = 0.000521596
I0527 07:29:48.570061 30701 solver.cpp:237]     Train net output #0: loss = 0.000519696 (* 1 = 0.000519696 loss)
I0527 07:29:48.570070 30701 sgd_solver.cpp:105] Iteration 196700, lr = 0.000165
I0527 07:30:16.669466 30701 solver.cpp:218] Iteration 196800 (3.55888 iter/s, 28.0987s/100 iters), loss = 0.000353791
I0527 07:30:16.669687 30701 solver.cpp:237]     Train net output #0: loss = 0.000351891 (* 1 = 0.000351891 loss)
I0527 07:30:16.669700 30701 sgd_solver.cpp:105] Iteration 196800, lr = 0.00016
I0527 07:30:30.183820 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:30:44.770531 30701 solver.cpp:218] Iteration 196900 (3.5587 iter/s, 28.1001s/100 iters), loss = 0.000256967
I0527 07:30:44.770576 30701 solver.cpp:237]     Train net output #0: loss = 0.000255068 (* 1 = 0.000255068 loss)
I0527 07:30:44.770586 30701 sgd_solver.cpp:105] Iteration 196900, lr = 0.000155
I0527 07:31:12.595090 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_197000.caffemodel
I0527 07:31:12.914561 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_197000.solverstate
I0527 07:31:13.066323 30701 solver.cpp:330] Iteration 197000, Testing net (#0)
I0527 07:31:15.143357 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:31:16.031345 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 07:31:16.031396 30701 solver.cpp:397]     Test net output #1: loss = 0.75005 (* 1 = 0.75005 loss)
I0527 07:31:16.307734 30701 solver.cpp:218] Iteration 197000 (3.17094 iter/s, 31.5364s/100 iters), loss = 0.000173552
I0527 07:31:16.307790 30701 solver.cpp:237]     Train net output #0: loss = 0.000171653 (* 1 = 0.000171653 loss)
I0527 07:31:16.307799 30701 sgd_solver.cpp:105] Iteration 197000, lr = 0.00015
I0527 07:31:44.417171 30701 solver.cpp:218] Iteration 197100 (3.55762 iter/s, 28.1087s/100 iters), loss = 0.00034268
I0527 07:31:44.417333 30701 solver.cpp:237]     Train net output #0: loss = 0.00034078 (* 1 = 0.00034078 loss)
I0527 07:31:44.417346 30701 sgd_solver.cpp:105] Iteration 197100, lr = 0.000145
I0527 07:32:12.522123 30701 solver.cpp:218] Iteration 197200 (3.5582 iter/s, 28.1041s/100 iters), loss = 0.000400239
I0527 07:32:12.522171 30701 solver.cpp:237]     Train net output #0: loss = 0.00039834 (* 1 = 0.00039834 loss)
I0527 07:32:12.522178 30701 sgd_solver.cpp:105] Iteration 197200, lr = 0.00014
I0527 07:32:40.607815 30701 solver.cpp:218] Iteration 197300 (3.56063 iter/s, 28.0849s/100 iters), loss = 0.000132924
I0527 07:32:40.608000 30701 solver.cpp:237]     Train net output #0: loss = 0.000131025 (* 1 = 0.000131025 loss)
I0527 07:32:40.608029 30701 sgd_solver.cpp:105] Iteration 197300, lr = 0.000135
I0527 07:33:08.684283 30701 solver.cpp:218] Iteration 197400 (3.56182 iter/s, 28.0756s/100 iters), loss = 0.00030504
I0527 07:33:08.684337 30701 solver.cpp:237]     Train net output #0: loss = 0.00030314 (* 1 = 0.00030314 loss)
I0527 07:33:08.684363 30701 sgd_solver.cpp:105] Iteration 197400, lr = 0.00013
I0527 07:33:19.942265 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:33:36.784538 30701 solver.cpp:218] Iteration 197500 (3.55878 iter/s, 28.0995s/100 iters), loss = 0.000370768
I0527 07:33:36.784584 30701 solver.cpp:237]     Train net output #0: loss = 0.000368869 (* 1 = 0.000368869 loss)
I0527 07:33:36.784591 30701 sgd_solver.cpp:105] Iteration 197500, lr = 0.000125
I0527 07:34:04.869478 30701 solver.cpp:218] Iteration 197600 (3.56072 iter/s, 28.0842s/100 iters), loss = 0.000240522
I0527 07:34:04.869640 30701 solver.cpp:237]     Train net output #0: loss = 0.000238622 (* 1 = 0.000238622 loss)
I0527 07:34:04.869652 30701 sgd_solver.cpp:105] Iteration 197600, lr = 0.00012
I0527 07:34:32.951285 30701 solver.cpp:218] Iteration 197700 (3.56113 iter/s, 28.0809s/100 iters), loss = 0.000102976
I0527 07:34:32.951330 30701 solver.cpp:237]     Train net output #0: loss = 0.000101077 (* 1 = 0.000101077 loss)
I0527 07:34:32.951339 30701 sgd_solver.cpp:105] Iteration 197700, lr = 0.000115
I0527 07:35:01.038301 30701 solver.cpp:218] Iteration 197800 (3.56046 iter/s, 28.0863s/100 iters), loss = 0.000199079
I0527 07:35:01.038460 30701 solver.cpp:237]     Train net output #0: loss = 0.00019718 (* 1 = 0.00019718 loss)
I0527 07:35:01.038471 30701 sgd_solver.cpp:105] Iteration 197800, lr = 0.00011
I0527 07:35:29.149688 30701 solver.cpp:218] Iteration 197900 (3.55739 iter/s, 28.1105s/100 iters), loss = 0.000277412
I0527 07:35:29.149731 30701 solver.cpp:237]     Train net output #0: loss = 0.000275513 (* 1 = 0.000275513 loss)
I0527 07:35:29.149752 30701 sgd_solver.cpp:105] Iteration 197900, lr = 0.000105
I0527 07:35:56.968202 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_198000.caffemodel
I0527 07:35:57.282692 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_198000.solverstate
I0527 07:35:57.434566 30701 solver.cpp:330] Iteration 198000, Testing net (#0)
I0527 07:36:00.391075 30701 solver.cpp:397]     Test net output #0: accuracy = 0.834
I0527 07:36:00.391111 30701 solver.cpp:397]     Test net output #1: loss = 0.78941 (* 1 = 0.78941 loss)
I0527 07:36:00.669200 30701 solver.cpp:218] Iteration 198000 (3.17272 iter/s, 31.5187s/100 iters), loss = 0.000459062
I0527 07:36:00.669245 30701 solver.cpp:237]     Train net output #0: loss = 0.000457162 (* 1 = 0.000457162 loss)
I0527 07:36:00.669253 30701 sgd_solver.cpp:105] Iteration 198000, lr = 9.99999e-05
I0527 07:36:09.388826 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:36:28.734320 30701 solver.cpp:218] Iteration 198100 (3.56324 iter/s, 28.0644s/100 iters), loss = 0.000176035
I0527 07:36:28.734534 30701 solver.cpp:237]     Train net output #0: loss = 0.000174136 (* 1 = 0.000174136 loss)
I0527 07:36:28.734545 30701 sgd_solver.cpp:105] Iteration 198100, lr = 9.50003e-05
I0527 07:36:56.849403 30701 solver.cpp:218] Iteration 198200 (3.55693 iter/s, 28.1142s/100 iters), loss = 0.00019144
I0527 07:36:56.849449 30701 solver.cpp:237]     Train net output #0: loss = 0.00018954 (* 1 = 0.00018954 loss)
I0527 07:36:56.849457 30701 sgd_solver.cpp:105] Iteration 198200, lr = 9e-05
I0527 07:37:24.973721 30701 solver.cpp:218] Iteration 198300 (3.55574 iter/s, 28.1236s/100 iters), loss = 9.71486e-05
I0527 07:37:24.973878 30701 solver.cpp:237]     Train net output #0: loss = 9.52489e-05 (* 1 = 9.52489e-05 loss)
I0527 07:37:24.973891 30701 sgd_solver.cpp:105] Iteration 198300, lr = 8.49998e-05
I0527 07:37:53.090541 30701 solver.cpp:218] Iteration 198400 (3.5567 iter/s, 28.116s/100 iters), loss = 0.000477994
I0527 07:37:53.090586 30701 solver.cpp:237]     Train net output #0: loss = 0.000476095 (* 1 = 0.000476095 loss)
I0527 07:37:53.090595 30701 sgd_solver.cpp:105] Iteration 198400, lr = 8.00002e-05
I0527 07:38:21.209692 30701 solver.cpp:218] Iteration 198500 (3.55639 iter/s, 28.1184s/100 iters), loss = 0.000230294
I0527 07:38:21.209842 30701 solver.cpp:237]     Train net output #0: loss = 0.000228394 (* 1 = 0.000228394 loss)
I0527 07:38:21.209856 30701 sgd_solver.cpp:105] Iteration 198500, lr = 7.49999e-05
I0527 07:38:49.341863 30701 solver.cpp:218] Iteration 198600 (3.55476 iter/s, 28.1313s/100 iters), loss = 0.000258026
I0527 07:38:49.341910 30701 solver.cpp:237]     Train net output #0: loss = 0.000256127 (* 1 = 0.000256127 loss)
I0527 07:38:49.341919 30701 sgd_solver.cpp:105] Iteration 198600, lr = 7.00003e-05
I0527 07:38:55.550035 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:39:17.480154 30701 solver.cpp:218] Iteration 198700 (3.55388 iter/s, 28.1383s/100 iters), loss = 0.000116604
I0527 07:39:17.480196 30701 solver.cpp:237]     Train net output #0: loss = 0.000114704 (* 1 = 0.000114704 loss)
I0527 07:39:17.480206 30701 sgd_solver.cpp:105] Iteration 198700, lr = 6.50001e-05
I0527 07:39:45.621604 30701 solver.cpp:218] Iteration 198800 (3.55347 iter/s, 28.1415s/100 iters), loss = 4.80984e-05
I0527 07:39:45.621772 30701 solver.cpp:237]     Train net output #0: loss = 4.61988e-05 (* 1 = 4.61988e-05 loss)
I0527 07:39:45.621788 30701 sgd_solver.cpp:105] Iteration 198800, lr = 5.99998e-05
I0527 07:40:13.754281 30701 solver.cpp:218] Iteration 198900 (3.5546 iter/s, 28.1326s/100 iters), loss = 0.000619608
I0527 07:40:13.754328 30701 solver.cpp:237]     Train net output #0: loss = 0.000617708 (* 1 = 0.000617708 loss)
I0527 07:40:13.754338 30701 sgd_solver.cpp:105] Iteration 198900, lr = 5.50002e-05
I0527 07:40:41.611563 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_199000.caffemodel
I0527 07:40:42.113049 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_199000.solverstate
I0527 07:40:42.267038 30701 solver.cpp:330] Iteration 199000, Testing net (#0)
I0527 07:40:45.222718 30701 solver.cpp:397]     Test net output #0: accuracy = 0.812
I0527 07:40:45.222770 30701 solver.cpp:397]     Test net output #1: loss = 0.845457 (* 1 = 0.845457 loss)
I0527 07:40:45.500339 30701 solver.cpp:218] Iteration 199000 (3.15 iter/s, 31.7461s/100 iters), loss = 0.000202682
I0527 07:40:45.500385 30701 solver.cpp:237]     Train net output #0: loss = 0.000200782 (* 1 = 0.000200782 loss)
I0527 07:40:45.500394 30701 sgd_solver.cpp:105] Iteration 199000, lr = 5e-05
I0527 07:41:13.573643 30701 solver.cpp:218] Iteration 199100 (3.56211 iter/s, 28.0733s/100 iters), loss = 0.000786006
I0527 07:41:13.573837 30701 solver.cpp:237]     Train net output #0: loss = 0.000784106 (* 1 = 0.000784106 loss)
I0527 07:41:13.573853 30701 sgd_solver.cpp:105] Iteration 199100, lr = 4.49997e-05
I0527 07:41:41.676753 30701 solver.cpp:218] Iteration 199200 (3.55835 iter/s, 28.1029s/100 iters), loss = 0.000227508
I0527 07:41:41.676800 30701 solver.cpp:237]     Train net output #0: loss = 0.000225608 (* 1 = 0.000225608 loss)
I0527 07:41:41.676808 30701 sgd_solver.cpp:105] Iteration 199200, lr = 4.00001e-05
I0527 07:41:45.345551 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:42:09.771890 30701 solver.cpp:218] Iteration 199300 (3.55935 iter/s, 28.095s/100 iters), loss = 0.000132888
I0527 07:42:09.771936 30701 solver.cpp:237]     Train net output #0: loss = 0.000130989 (* 1 = 0.000130989 loss)
I0527 07:42:09.771945 30701 sgd_solver.cpp:105] Iteration 199300, lr = 3.49998e-05
I0527 07:42:37.861181 30701 solver.cpp:218] Iteration 199400 (3.56009 iter/s, 28.0892s/100 iters), loss = 0.000473256
I0527 07:42:37.861397 30701 solver.cpp:237]     Train net output #0: loss = 0.000471356 (* 1 = 0.000471356 loss)
I0527 07:42:37.861408 30701 sgd_solver.cpp:105] Iteration 199400, lr = 3.00002e-05
I0527 07:43:05.975778 30701 solver.cpp:218] Iteration 199500 (3.55691 iter/s, 28.1143s/100 iters), loss = 0.000232259
I0527 07:43:05.975822 30701 solver.cpp:237]     Train net output #0: loss = 0.000230359 (* 1 = 0.000230359 loss)
I0527 07:43:05.975831 30701 sgd_solver.cpp:105] Iteration 199500, lr = 2.5e-05
I0527 07:43:34.081593 30701 solver.cpp:218] Iteration 199600 (3.558 iter/s, 28.1056s/100 iters), loss = 0.0003556
I0527 07:43:34.081763 30701 solver.cpp:237]     Train net output #0: loss = 0.000353701 (* 1 = 0.000353701 loss)
I0527 07:43:34.081773 30701 sgd_solver.cpp:105] Iteration 199600, lr = 1.99997e-05
I0527 07:44:02.193701 30701 solver.cpp:218] Iteration 199700 (3.55723 iter/s, 28.1118s/100 iters), loss = 0.000214311
I0527 07:44:02.193754 30701 solver.cpp:237]     Train net output #0: loss = 0.000212411 (* 1 = 0.000212411 loss)
I0527 07:44:02.193763 30701 sgd_solver.cpp:105] Iteration 199700, lr = 1.50001e-05
I0527 07:44:30.305464 30701 solver.cpp:218] Iteration 199800 (3.55726 iter/s, 28.1115s/100 iters), loss = 0.00014283
I0527 07:44:30.305694 30701 solver.cpp:237]     Train net output #0: loss = 0.00014093 (* 1 = 0.00014093 loss)
I0527 07:44:30.305706 30701 sgd_solver.cpp:105] Iteration 199800, lr = 9.99987e-06
I0527 07:44:31.450654 30711 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:44:58.421308 30701 solver.cpp:218] Iteration 199900 (3.55677 iter/s, 28.1154s/100 iters), loss = 9.5911e-05
I0527 07:44:58.421352 30701 solver.cpp:237]     Train net output #0: loss = 9.40113e-05 (* 1 = 9.40113e-05 loss)
I0527 07:44:58.421361 30701 sgd_solver.cpp:105] Iteration 199900, lr = 5.00023e-06
I0527 07:45:26.268031 30701 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_200000.caffemodel
I0527 07:45:26.741457 30701 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_200000.solverstate
I0527 07:45:26.996341 30701 solver.cpp:310] Iteration 200000, loss = 0.000239187
I0527 07:45:26.996379 30701 solver.cpp:330] Iteration 200000, Testing net (#0)
I0527 07:45:27.794078 30712 data_layer.cpp:73] Restarting data prefetching from start.
I0527 07:45:29.945602 30701 solver.cpp:397]     Test net output #0: accuracy = 0.842
I0527 07:45:29.945642 30701 solver.cpp:397]     Test net output #1: loss = 0.759796 (* 1 = 0.759796 loss)
I0527 07:45:29.945648 30701 solver.cpp:315] Optimization Done.
I0527 07:45:29.956949 30701 caffe.cpp:259] Optimization Done.
