I0528 19:00:46.594187 11123 caffe.cpp:218] Using GPUs 0
I0528 19:00:46.692769 11123 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I0528 19:00:47.027892 11123 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 200000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "pre-resnet-50"
solver_mode: GPU
device_id: 0
random_seed: 0
net: "50_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0528 19:00:47.028065 11123 solver.cpp:87] Creating training net from net file: 50_train_val_test_fold_is_0.prototxt
I0528 19:00:47.029361 11123 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 50_train_val_test_fold_is_0.prototxt
I0528 19:00:47.029376 11123 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 19:00:47.029631 11123 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0528 19:00:47.029721 11123 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0528 19:00:47.030879 11123 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-50"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto"
  }
  data_param {
    source: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/gender_train_lmdb"
    batch_size: 20
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn3"
  type: "BatchNorm"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale3"
  type: "Scale"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu3"
  type: "ReLU"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
}
layer {
  name: "layer_256_1_conv3"
  type: "Convolution"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv3"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn3"
  type: "BatchNorm"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale3"
  type: "Scale"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu3"
  type: "ReLU"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
}
layer {
  name: "layer_256_2_conv3"
  type: "Convolution
I0528 19:00:47.031599 11123 layer_factory.hpp:77] Creating layer data
I0528 19:00:47.031702 11123 db_lmdb.cpp:35] Opened lmdb /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/gender_train_lmdb
I0528 19:00:47.031730 11123 net.cpp:84] Creating Layer data
I0528 19:00:47.031738 11123 net.cpp:380] data -> data
I0528 19:00:47.031759 11123 net.cpp:380] data -> label
I0528 19:00:47.031770 11123 data_transformer.cpp:25] Loading mean file from: /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto
I0528 19:00:47.034524 11123 data_layer.cpp:45] output data size: 20,3,224,224
I0528 19:00:47.061758 11123 net.cpp:122] Setting up data
I0528 19:00:47.061787 11123 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 19:00:47.061792 11123 net.cpp:129] Top shape: 20 (20)
I0528 19:00:47.061795 11123 net.cpp:137] Memory required for data: 12042320
I0528 19:00:47.061816 11123 layer_factory.hpp:77] Creating layer data_bn
I0528 19:00:47.061830 11123 net.cpp:84] Creating Layer data_bn
I0528 19:00:47.061837 11123 net.cpp:406] data_bn <- data
I0528 19:00:47.061849 11123 net.cpp:380] data_bn -> data_bn
I0528 19:00:47.062752 11123 net.cpp:122] Setting up data_bn
I0528 19:00:47.062763 11123 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 19:00:47.062767 11123 net.cpp:137] Memory required for data: 24084560
I0528 19:00:47.062800 11123 layer_factory.hpp:77] Creating layer data_scale
I0528 19:00:47.062809 11123 net.cpp:84] Creating Layer data_scale
I0528 19:00:47.062813 11123 net.cpp:406] data_scale <- data_bn
I0528 19:00:47.062819 11123 net.cpp:367] data_scale -> data_bn (in-place)
I0528 19:00:47.062857 11123 layer_factory.hpp:77] Creating layer data_scale
I0528 19:00:47.062999 11123 net.cpp:122] Setting up data_scale
I0528 19:00:47.063009 11123 net.cpp:129] Top shape: 20 3 224 224 (3010560)
I0528 19:00:47.063012 11123 net.cpp:137] Memory required for data: 36126800
I0528 19:00:47.063019 11123 layer_factory.hpp:77] Creating layer conv1
I0528 19:00:47.063035 11123 net.cpp:84] Creating Layer conv1
I0528 19:00:47.063038 11123 net.cpp:406] conv1 <- data_bn
I0528 19:00:47.063045 11123 net.cpp:380] conv1 -> conv1
I0528 19:00:47.283148 11123 net.cpp:122] Setting up conv1
I0528 19:00:47.283177 11123 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 19:00:47.283181 11123 net.cpp:137] Memory required for data: 100352080
I0528 19:00:47.283205 11123 layer_factory.hpp:77] Creating layer conv1_bn
I0528 19:00:47.283218 11123 net.cpp:84] Creating Layer conv1_bn
I0528 19:00:47.283222 11123 net.cpp:406] conv1_bn <- conv1
I0528 19:00:47.283229 11123 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 19:00:47.283393 11123 net.cpp:122] Setting up conv1_bn
I0528 19:00:47.283402 11123 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 19:00:47.283406 11123 net.cpp:137] Memory required for data: 164577360
I0528 19:00:47.283427 11123 layer_factory.hpp:77] Creating layer conv1_scale
I0528 19:00:47.283437 11123 net.cpp:84] Creating Layer conv1_scale
I0528 19:00:47.283440 11123 net.cpp:406] conv1_scale <- conv1
I0528 19:00:47.283445 11123 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 19:00:47.283483 11123 layer_factory.hpp:77] Creating layer conv1_scale
I0528 19:00:47.283604 11123 net.cpp:122] Setting up conv1_scale
I0528 19:00:47.283613 11123 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 19:00:47.283627 11123 net.cpp:137] Memory required for data: 228802640
I0528 19:00:47.283633 11123 layer_factory.hpp:77] Creating layer conv1_relu
I0528 19:00:47.283639 11123 net.cpp:84] Creating Layer conv1_relu
I0528 19:00:47.283644 11123 net.cpp:406] conv1_relu <- conv1
I0528 19:00:47.283648 11123 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 19:00:47.283808 11123 net.cpp:122] Setting up conv1_relu
I0528 19:00:47.283818 11123 net.cpp:129] Top shape: 20 64 112 112 (16056320)
I0528 19:00:47.283821 11123 net.cpp:137] Memory required for data: 293027920
I0528 19:00:47.283824 11123 layer_factory.hpp:77] Creating layer conv1_pool
I0528 19:00:47.283843 11123 net.cpp:84] Creating Layer conv1_pool
I0528 19:00:47.283848 11123 net.cpp:406] conv1_pool <- conv1
I0528 19:00:47.283852 11123 net.cpp:380] conv1_pool -> conv1_pool
I0528 19:00:47.283908 11123 net.cpp:122] Setting up conv1_pool
I0528 19:00:47.283917 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.283921 11123 net.cpp:137] Memory required for data: 309084240
I0528 19:00:47.283923 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 19:00:47.283933 11123 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 19:00:47.283938 11123 net.cpp:406] layer_64_1_conv1 <- conv1_pool
I0528 19:00:47.283943 11123 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 19:00:47.285729 11123 net.cpp:122] Setting up layer_64_1_conv1
I0528 19:00:47.285742 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.285758 11123 net.cpp:137] Memory required for data: 325140560
I0528 19:00:47.285764 11123 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 19:00:47.285770 11123 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 19:00:47.285775 11123 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 19:00:47.285781 11123 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.285928 11123 net.cpp:122] Setting up layer_64_1_bn2
I0528 19:00:47.285935 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.285938 11123 net.cpp:137] Memory required for data: 341196880
I0528 19:00:47.285956 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 19:00:47.285964 11123 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 19:00:47.285969 11123 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 19:00:47.285974 11123 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.286020 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 19:00:47.286131 11123 net.cpp:122] Setting up layer_64_1_scale2
I0528 19:00:47.286140 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.286144 11123 net.cpp:137] Memory required for data: 357253200
I0528 19:00:47.286151 11123 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 19:00:47.286159 11123 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 19:00:47.286161 11123 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 19:00:47.286166 11123 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.286775 11123 net.cpp:122] Setting up layer_64_1_relu2
I0528 19:00:47.286787 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.286792 11123 net.cpp:137] Memory required for data: 373309520
I0528 19:00:47.286806 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.286813 11123 net.cpp:84] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.286816 11123 net.cpp:406] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0528 19:00:47.286821 11123 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0528 19:00:47.286828 11123 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0528 19:00:47.286862 11123 net.cpp:122] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.286870 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.286873 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.286876 11123 net.cpp:137] Memory required for data: 405422160
I0528 19:00:47.286880 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 19:00:47.286888 11123 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 19:00:47.286892 11123 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0528 19:00:47.286898 11123 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 19:00:47.288262 11123 net.cpp:122] Setting up layer_64_1_conv2
I0528 19:00:47.288275 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.288280 11123 net.cpp:137] Memory required for data: 421478480
I0528 19:00:47.288285 11123 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0528 19:00:47.288291 11123 net.cpp:84] Creating Layer layer_64_1_bn3
I0528 19:00:47.288296 11123 net.cpp:406] layer_64_1_bn3 <- layer_64_1_conv2
I0528 19:00:47.288302 11123 net.cpp:367] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.288450 11123 net.cpp:122] Setting up layer_64_1_bn3
I0528 19:00:47.288458 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.288461 11123 net.cpp:137] Memory required for data: 437534800
I0528 19:00:47.288470 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0528 19:00:47.288476 11123 net.cpp:84] Creating Layer layer_64_1_scale3
I0528 19:00:47.288481 11123 net.cpp:406] layer_64_1_scale3 <- layer_64_1_conv2
I0528 19:00:47.288486 11123 net.cpp:367] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.288518 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0528 19:00:47.288609 11123 net.cpp:122] Setting up layer_64_1_scale3
I0528 19:00:47.288617 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.288620 11123 net.cpp:137] Memory required for data: 453591120
I0528 19:00:47.288626 11123 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0528 19:00:47.288635 11123 net.cpp:84] Creating Layer layer_64_1_relu3
I0528 19:00:47.288638 11123 net.cpp:406] layer_64_1_relu3 <- layer_64_1_conv2
I0528 19:00:47.288643 11123 net.cpp:367] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.289252 11123 net.cpp:122] Setting up layer_64_1_relu3
I0528 19:00:47.289264 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.289268 11123 net.cpp:137] Memory required for data: 469647440
I0528 19:00:47.289271 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0528 19:00:47.289290 11123 net.cpp:84] Creating Layer layer_64_1_conv3
I0528 19:00:47.289295 11123 net.cpp:406] layer_64_1_conv3 <- layer_64_1_conv2
I0528 19:00:47.289301 11123 net.cpp:380] layer_64_1_conv3 -> layer_64_1_conv3
I0528 19:00:47.290477 11123 net.cpp:122] Setting up layer_64_1_conv3
I0528 19:00:47.290488 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.290493 11123 net.cpp:137] Memory required for data: 533872720
I0528 19:00:47.290498 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0528 19:00:47.290508 11123 net.cpp:84] Creating Layer layer_64_1_conv_expand
I0528 19:00:47.290511 11123 net.cpp:406] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0528 19:00:47.290518 11123 net.cpp:380] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0528 19:00:47.291705 11123 net.cpp:122] Setting up layer_64_1_conv_expand
I0528 19:00:47.291719 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.291724 11123 net.cpp:137] Memory required for data: 598098000
I0528 19:00:47.291729 11123 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 19:00:47.291735 11123 net.cpp:84] Creating Layer layer_64_1_sum
I0528 19:00:47.291739 11123 net.cpp:406] layer_64_1_sum <- layer_64_1_conv3
I0528 19:00:47.291743 11123 net.cpp:406] layer_64_1_sum <- layer_64_1_conv_expand
I0528 19:00:47.291748 11123 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 19:00:47.291774 11123 net.cpp:122] Setting up layer_64_1_sum
I0528 19:00:47.291781 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.291785 11123 net.cpp:137] Memory required for data: 662323280
I0528 19:00:47.291788 11123 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.291795 11123 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.291797 11123 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 19:00:47.291802 11123 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 19:00:47.291808 11123 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 19:00:47.291839 11123 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.291846 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.291851 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.291853 11123 net.cpp:137] Memory required for data: 790773840
I0528 19:00:47.291857 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 19:00:47.291863 11123 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 19:00:47.291867 11123 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 19:00:47.291872 11123 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 19:00:47.292023 11123 net.cpp:122] Setting up layer_64_2_bn1
I0528 19:00:47.292032 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.292035 11123 net.cpp:137] Memory required for data: 854999120
I0528 19:00:47.292042 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 19:00:47.292049 11123 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 19:00:47.292052 11123 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 19:00:47.292057 11123 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 19:00:47.292093 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 19:00:47.292183 11123 net.cpp:122] Setting up layer_64_2_scale1
I0528 19:00:47.292191 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.292196 11123 net.cpp:137] Memory required for data: 919224400
I0528 19:00:47.292201 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 19:00:47.292206 11123 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 19:00:47.292210 11123 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 19:00:47.292217 11123 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 19:00:47.292358 11123 net.cpp:122] Setting up layer_64_2_relu1
I0528 19:00:47.292369 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.292382 11123 net.cpp:137] Memory required for data: 983449680
I0528 19:00:47.292385 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 19:00:47.292397 11123 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 19:00:47.292402 11123 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 19:00:47.292407 11123 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 19:00:47.293643 11123 net.cpp:122] Setting up layer_64_2_conv1
I0528 19:00:47.293655 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.293660 11123 net.cpp:137] Memory required for data: 999506000
I0528 19:00:47.293665 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 19:00:47.293673 11123 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 19:00:47.293678 11123 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 19:00:47.293684 11123 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.293839 11123 net.cpp:122] Setting up layer_64_2_bn2
I0528 19:00:47.293848 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.293851 11123 net.cpp:137] Memory required for data: 1015562320
I0528 19:00:47.293862 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 19:00:47.293870 11123 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 19:00:47.293874 11123 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 19:00:47.293879 11123 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.293915 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 19:00:47.294010 11123 net.cpp:122] Setting up layer_64_2_scale2
I0528 19:00:47.294020 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.294023 11123 net.cpp:137] Memory required for data: 1031618640
I0528 19:00:47.294029 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 19:00:47.294034 11123 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 19:00:47.294039 11123 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 19:00:47.294044 11123 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.294184 11123 net.cpp:122] Setting up layer_64_2_relu2
I0528 19:00:47.294193 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.294196 11123 net.cpp:137] Memory required for data: 1047674960
I0528 19:00:47.294200 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 19:00:47.294209 11123 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 19:00:47.294214 11123 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 19:00:47.294220 11123 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 19:00:47.295693 11123 net.cpp:122] Setting up layer_64_2_conv2
I0528 19:00:47.295709 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.295713 11123 net.cpp:137] Memory required for data: 1063731280
I0528 19:00:47.295718 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0528 19:00:47.295724 11123 net.cpp:84] Creating Layer layer_64_2_bn3
I0528 19:00:47.295728 11123 net.cpp:406] layer_64_2_bn3 <- layer_64_2_conv2
I0528 19:00:47.295735 11123 net.cpp:367] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.295897 11123 net.cpp:122] Setting up layer_64_2_bn3
I0528 19:00:47.295907 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.295910 11123 net.cpp:137] Memory required for data: 1079787600
I0528 19:00:47.295918 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0528 19:00:47.295925 11123 net.cpp:84] Creating Layer layer_64_2_scale3
I0528 19:00:47.295930 11123 net.cpp:406] layer_64_2_scale3 <- layer_64_2_conv2
I0528 19:00:47.295935 11123 net.cpp:367] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.295972 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0528 19:00:47.296072 11123 net.cpp:122] Setting up layer_64_2_scale3
I0528 19:00:47.296082 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.296084 11123 net.cpp:137] Memory required for data: 1095843920
I0528 19:00:47.296089 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0528 19:00:47.296105 11123 net.cpp:84] Creating Layer layer_64_2_relu3
I0528 19:00:47.296110 11123 net.cpp:406] layer_64_2_relu3 <- layer_64_2_conv2
I0528 19:00:47.296114 11123 net.cpp:367] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.296258 11123 net.cpp:122] Setting up layer_64_2_relu3
I0528 19:00:47.296267 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.296272 11123 net.cpp:137] Memory required for data: 1111900240
I0528 19:00:47.296274 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0528 19:00:47.296288 11123 net.cpp:84] Creating Layer layer_64_2_conv3
I0528 19:00:47.296293 11123 net.cpp:406] layer_64_2_conv3 <- layer_64_2_conv2
I0528 19:00:47.296299 11123 net.cpp:380] layer_64_2_conv3 -> layer_64_2_conv3
I0528 19:00:47.298002 11123 net.cpp:122] Setting up layer_64_2_conv3
I0528 19:00:47.298017 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298022 11123 net.cpp:137] Memory required for data: 1176125520
I0528 19:00:47.298027 11123 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 19:00:47.298032 11123 net.cpp:84] Creating Layer layer_64_2_sum
I0528 19:00:47.298036 11123 net.cpp:406] layer_64_2_sum <- layer_64_2_conv3
I0528 19:00:47.298041 11123 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 19:00:47.298049 11123 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 19:00:47.298074 11123 net.cpp:122] Setting up layer_64_2_sum
I0528 19:00:47.298081 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298086 11123 net.cpp:137] Memory required for data: 1240350800
I0528 19:00:47.298089 11123 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.298096 11123 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.298101 11123 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0528 19:00:47.298107 11123 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 19:00:47.298115 11123 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 19:00:47.298144 11123 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.298152 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298157 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298159 11123 net.cpp:137] Memory required for data: 1368801360
I0528 19:00:47.298162 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0528 19:00:47.298168 11123 net.cpp:84] Creating Layer layer_64_3_bn1
I0528 19:00:47.298171 11123 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 19:00:47.298177 11123 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0528 19:00:47.298332 11123 net.cpp:122] Setting up layer_64_3_bn1
I0528 19:00:47.298341 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298343 11123 net.cpp:137] Memory required for data: 1433026640
I0528 19:00:47.298351 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 19:00:47.298357 11123 net.cpp:84] Creating Layer layer_64_3_scale1
I0528 19:00:47.298362 11123 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0528 19:00:47.298367 11123 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0528 19:00:47.298403 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 19:00:47.298501 11123 net.cpp:122] Setting up layer_64_3_scale1
I0528 19:00:47.298511 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298514 11123 net.cpp:137] Memory required for data: 1497251920
I0528 19:00:47.298519 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0528 19:00:47.298527 11123 net.cpp:84] Creating Layer layer_64_3_relu1
I0528 19:00:47.298532 11123 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0528 19:00:47.298537 11123 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0528 19:00:47.298681 11123 net.cpp:122] Setting up layer_64_3_relu1
I0528 19:00:47.298691 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.298705 11123 net.cpp:137] Memory required for data: 1561477200
I0528 19:00:47.298709 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0528 19:00:47.298718 11123 net.cpp:84] Creating Layer layer_64_3_conv1
I0528 19:00:47.298723 11123 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0528 19:00:47.298730 11123 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0528 19:00:47.299964 11123 net.cpp:122] Setting up layer_64_3_conv1
I0528 19:00:47.299978 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.299983 11123 net.cpp:137] Memory required for data: 1577533520
I0528 19:00:47.299988 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0528 19:00:47.299994 11123 net.cpp:84] Creating Layer layer_64_3_bn2
I0528 19:00:47.299998 11123 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0528 19:00:47.300004 11123 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.300163 11123 net.cpp:122] Setting up layer_64_3_bn2
I0528 19:00:47.300171 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.300174 11123 net.cpp:137] Memory required for data: 1593589840
I0528 19:00:47.300181 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 19:00:47.300187 11123 net.cpp:84] Creating Layer layer_64_3_scale2
I0528 19:00:47.300191 11123 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0528 19:00:47.300195 11123 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.300232 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 19:00:47.300333 11123 net.cpp:122] Setting up layer_64_3_scale2
I0528 19:00:47.300341 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.300344 11123 net.cpp:137] Memory required for data: 1609646160
I0528 19:00:47.300350 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0528 19:00:47.300355 11123 net.cpp:84] Creating Layer layer_64_3_relu2
I0528 19:00:47.300359 11123 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0528 19:00:47.300364 11123 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.300511 11123 net.cpp:122] Setting up layer_64_3_relu2
I0528 19:00:47.300521 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.300524 11123 net.cpp:137] Memory required for data: 1625702480
I0528 19:00:47.300528 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0528 19:00:47.300537 11123 net.cpp:84] Creating Layer layer_64_3_conv2
I0528 19:00:47.300542 11123 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0528 19:00:47.300549 11123 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0528 19:00:47.302465 11123 net.cpp:122] Setting up layer_64_3_conv2
I0528 19:00:47.302480 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.302484 11123 net.cpp:137] Memory required for data: 1641758800
I0528 19:00:47.302490 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0528 19:00:47.302496 11123 net.cpp:84] Creating Layer layer_64_3_bn3
I0528 19:00:47.302501 11123 net.cpp:406] layer_64_3_bn3 <- layer_64_3_conv2
I0528 19:00:47.302507 11123 net.cpp:367] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.302672 11123 net.cpp:122] Setting up layer_64_3_bn3
I0528 19:00:47.302681 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.302685 11123 net.cpp:137] Memory required for data: 1657815120
I0528 19:00:47.302692 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0528 19:00:47.302700 11123 net.cpp:84] Creating Layer layer_64_3_scale3
I0528 19:00:47.302703 11123 net.cpp:406] layer_64_3_scale3 <- layer_64_3_conv2
I0528 19:00:47.302709 11123 net.cpp:367] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.302747 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0528 19:00:47.302848 11123 net.cpp:122] Setting up layer_64_3_scale3
I0528 19:00:47.302856 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.302860 11123 net.cpp:137] Memory required for data: 1673871440
I0528 19:00:47.302866 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0528 19:00:47.302882 11123 net.cpp:84] Creating Layer layer_64_3_relu3
I0528 19:00:47.302887 11123 net.cpp:406] layer_64_3_relu3 <- layer_64_3_conv2
I0528 19:00:47.302892 11123 net.cpp:367] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.303514 11123 net.cpp:122] Setting up layer_64_3_relu3
I0528 19:00:47.303526 11123 net.cpp:129] Top shape: 20 64 56 56 (4014080)
I0528 19:00:47.303530 11123 net.cpp:137] Memory required for data: 1689927760
I0528 19:00:47.303534 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0528 19:00:47.303544 11123 net.cpp:84] Creating Layer layer_64_3_conv3
I0528 19:00:47.303549 11123 net.cpp:406] layer_64_3_conv3 <- layer_64_3_conv2
I0528 19:00:47.303555 11123 net.cpp:380] layer_64_3_conv3 -> layer_64_3_conv3
I0528 19:00:47.304792 11123 net.cpp:122] Setting up layer_64_3_conv3
I0528 19:00:47.304805 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.304810 11123 net.cpp:137] Memory required for data: 1754153040
I0528 19:00:47.304814 11123 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0528 19:00:47.304821 11123 net.cpp:84] Creating Layer layer_64_3_sum
I0528 19:00:47.304826 11123 net.cpp:406] layer_64_3_sum <- layer_64_3_conv3
I0528 19:00:47.304829 11123 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 19:00:47.304837 11123 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0528 19:00:47.304862 11123 net.cpp:122] Setting up layer_64_3_sum
I0528 19:00:47.304870 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.304874 11123 net.cpp:137] Memory required for data: 1818378320
I0528 19:00:47.304877 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 19:00:47.304883 11123 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 19:00:47.304888 11123 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0528 19:00:47.304894 11123 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 19:00:47.305068 11123 net.cpp:122] Setting up layer_128_1_bn1
I0528 19:00:47.305078 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.305083 11123 net.cpp:137] Memory required for data: 1882603600
I0528 19:00:47.305096 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 19:00:47.305105 11123 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 19:00:47.305109 11123 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 19:00:47.305114 11123 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 19:00:47.305151 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 19:00:47.305248 11123 net.cpp:122] Setting up layer_128_1_scale1
I0528 19:00:47.305258 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.305261 11123 net.cpp:137] Memory required for data: 1946828880
I0528 19:00:47.305268 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 19:00:47.305274 11123 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 19:00:47.305279 11123 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 19:00:47.305284 11123 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 19:00:47.305429 11123 net.cpp:122] Setting up layer_128_1_relu1
I0528 19:00:47.305439 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.305444 11123 net.cpp:137] Memory required for data: 2011054160
I0528 19:00:47.305446 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.305454 11123 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.305457 11123 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 19:00:47.305462 11123 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 19:00:47.305471 11123 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 19:00:47.305505 11123 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.305513 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.305527 11123 net.cpp:129] Top shape: 20 256 56 56 (16056320)
I0528 19:00:47.305531 11123 net.cpp:137] Memory required for data: 2139504720
I0528 19:00:47.305534 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 19:00:47.305544 11123 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 19:00:47.305549 11123 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 19:00:47.305554 11123 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 19:00:47.306960 11123 net.cpp:122] Setting up layer_128_1_conv1
I0528 19:00:47.306972 11123 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0528 19:00:47.306977 11123 net.cpp:137] Memory required for data: 2171617360
I0528 19:00:47.306982 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 19:00:47.306990 11123 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 19:00:47.306994 11123 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 19:00:47.307001 11123 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.307157 11123 net.cpp:122] Setting up layer_128_1_bn2
I0528 19:00:47.307166 11123 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0528 19:00:47.307170 11123 net.cpp:137] Memory required for data: 2203730000
I0528 19:00:47.307178 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 19:00:47.307185 11123 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 19:00:47.307190 11123 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 19:00:47.307195 11123 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.307230 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 19:00:47.307328 11123 net.cpp:122] Setting up layer_128_1_scale2
I0528 19:00:47.307337 11123 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0528 19:00:47.307340 11123 net.cpp:137] Memory required for data: 2235842640
I0528 19:00:47.307346 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 19:00:47.307354 11123 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 19:00:47.307358 11123 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 19:00:47.307364 11123 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.307509 11123 net.cpp:122] Setting up layer_128_1_relu2
I0528 19:00:47.307519 11123 net.cpp:129] Top shape: 20 128 56 56 (8028160)
I0528 19:00:47.307523 11123 net.cpp:137] Memory required for data: 2267955280
I0528 19:00:47.307526 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 19:00:47.307536 11123 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 19:00:47.307540 11123 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 19:00:47.307548 11123 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 19:00:47.311069 11123 net.cpp:122] Setting up layer_128_1_conv2
I0528 19:00:47.311081 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.311085 11123 net.cpp:137] Memory required for data: 2275983440
I0528 19:00:47.311091 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0528 19:00:47.311100 11123 net.cpp:84] Creating Layer layer_128_1_bn3
I0528 19:00:47.311105 11123 net.cpp:406] layer_128_1_bn3 <- layer_128_1_conv2
I0528 19:00:47.311110 11123 net.cpp:367] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.312005 11123 net.cpp:122] Setting up layer_128_1_bn3
I0528 19:00:47.312021 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.312024 11123 net.cpp:137] Memory required for data: 2284011600
I0528 19:00:47.312033 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0528 19:00:47.312042 11123 net.cpp:84] Creating Layer layer_128_1_scale3
I0528 19:00:47.312047 11123 net.cpp:406] layer_128_1_scale3 <- layer_128_1_conv2
I0528 19:00:47.312053 11123 net.cpp:367] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.312096 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0528 19:00:47.312194 11123 net.cpp:122] Setting up layer_128_1_scale3
I0528 19:00:47.312204 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.312219 11123 net.cpp:137] Memory required for data: 2292039760
I0528 19:00:47.312227 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0528 19:00:47.312232 11123 net.cpp:84] Creating Layer layer_128_1_relu3
I0528 19:00:47.312237 11123 net.cpp:406] layer_128_1_relu3 <- layer_128_1_conv2
I0528 19:00:47.312242 11123 net.cpp:367] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.312419 11123 net.cpp:122] Setting up layer_128_1_relu3
I0528 19:00:47.312428 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.312433 11123 net.cpp:137] Memory required for data: 2300067920
I0528 19:00:47.312436 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0528 19:00:47.312446 11123 net.cpp:84] Creating Layer layer_128_1_conv3
I0528 19:00:47.312451 11123 net.cpp:406] layer_128_1_conv3 <- layer_128_1_conv2
I0528 19:00:47.312458 11123 net.cpp:380] layer_128_1_conv3 -> layer_128_1_conv3
I0528 19:00:47.314561 11123 net.cpp:122] Setting up layer_128_1_conv3
I0528 19:00:47.314579 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.314584 11123 net.cpp:137] Memory required for data: 2332180560
I0528 19:00:47.314589 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 19:00:47.314601 11123 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 19:00:47.314605 11123 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 19:00:47.314612 11123 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 19:00:47.317370 11123 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 19:00:47.317387 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317391 11123 net.cpp:137] Memory required for data: 2364293200
I0528 19:00:47.317397 11123 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 19:00:47.317404 11123 net.cpp:84] Creating Layer layer_128_1_sum
I0528 19:00:47.317409 11123 net.cpp:406] layer_128_1_sum <- layer_128_1_conv3
I0528 19:00:47.317414 11123 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 19:00:47.317425 11123 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 19:00:47.317451 11123 net.cpp:122] Setting up layer_128_1_sum
I0528 19:00:47.317461 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317466 11123 net.cpp:137] Memory required for data: 2396405840
I0528 19:00:47.317468 11123 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.317474 11123 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.317477 11123 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 19:00:47.317482 11123 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 19:00:47.317489 11123 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 19:00:47.317523 11123 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.317531 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317535 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317538 11123 net.cpp:137] Memory required for data: 2460631120
I0528 19:00:47.317541 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 19:00:47.317559 11123 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 19:00:47.317564 11123 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 19:00:47.317569 11123 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 19:00:47.317734 11123 net.cpp:122] Setting up layer_128_2_bn1
I0528 19:00:47.317744 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317746 11123 net.cpp:137] Memory required for data: 2492743760
I0528 19:00:47.317754 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 19:00:47.317764 11123 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 19:00:47.317767 11123 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 19:00:47.317772 11123 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 19:00:47.317823 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 19:00:47.317921 11123 net.cpp:122] Setting up layer_128_2_scale1
I0528 19:00:47.317930 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.317934 11123 net.cpp:137] Memory required for data: 2524856400
I0528 19:00:47.317939 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 19:00:47.317945 11123 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 19:00:47.317950 11123 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 19:00:47.317955 11123 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 19:00:47.318114 11123 net.cpp:122] Setting up layer_128_2_relu1
I0528 19:00:47.318125 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.318127 11123 net.cpp:137] Memory required for data: 2556969040
I0528 19:00:47.318131 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 19:00:47.318140 11123 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 19:00:47.318145 11123 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 19:00:47.318153 11123 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 19:00:47.323379 11123 net.cpp:122] Setting up layer_128_2_conv1
I0528 19:00:47.323395 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.323398 11123 net.cpp:137] Memory required for data: 2564997200
I0528 19:00:47.323403 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 19:00:47.323411 11123 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 19:00:47.323415 11123 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 19:00:47.323421 11123 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.323585 11123 net.cpp:122] Setting up layer_128_2_bn2
I0528 19:00:47.323593 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.323596 11123 net.cpp:137] Memory required for data: 2573025360
I0528 19:00:47.323604 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 19:00:47.323611 11123 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 19:00:47.323616 11123 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 19:00:47.323621 11123 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.323658 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 19:00:47.323753 11123 net.cpp:122] Setting up layer_128_2_scale2
I0528 19:00:47.323761 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.323766 11123 net.cpp:137] Memory required for data: 2581053520
I0528 19:00:47.323772 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 19:00:47.323777 11123 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 19:00:47.323781 11123 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 19:00:47.323786 11123 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.323935 11123 net.cpp:122] Setting up layer_128_2_relu2
I0528 19:00:47.323945 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.323949 11123 net.cpp:137] Memory required for data: 2589081680
I0528 19:00:47.323952 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 19:00:47.323962 11123 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 19:00:47.323966 11123 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 19:00:47.323973 11123 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 19:00:47.327715 11123 net.cpp:122] Setting up layer_128_2_conv2
I0528 19:00:47.327729 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.327733 11123 net.cpp:137] Memory required for data: 2597109840
I0528 19:00:47.327739 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0528 19:00:47.327745 11123 net.cpp:84] Creating Layer layer_128_2_bn3
I0528 19:00:47.327749 11123 net.cpp:406] layer_128_2_bn3 <- layer_128_2_conv2
I0528 19:00:47.327755 11123 net.cpp:367] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.327924 11123 net.cpp:122] Setting up layer_128_2_bn3
I0528 19:00:47.327932 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.327946 11123 net.cpp:137] Memory required for data: 2605138000
I0528 19:00:47.327955 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0528 19:00:47.327961 11123 net.cpp:84] Creating Layer layer_128_2_scale3
I0528 19:00:47.327965 11123 net.cpp:406] layer_128_2_scale3 <- layer_128_2_conv2
I0528 19:00:47.327971 11123 net.cpp:367] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.328008 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0528 19:00:47.328109 11123 net.cpp:122] Setting up layer_128_2_scale3
I0528 19:00:47.328117 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.328120 11123 net.cpp:137] Memory required for data: 2613166160
I0528 19:00:47.328126 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0528 19:00:47.328131 11123 net.cpp:84] Creating Layer layer_128_2_relu3
I0528 19:00:47.328135 11123 net.cpp:406] layer_128_2_relu3 <- layer_128_2_conv2
I0528 19:00:47.328140 11123 net.cpp:367] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.328768 11123 net.cpp:122] Setting up layer_128_2_relu3
I0528 19:00:47.328779 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.328784 11123 net.cpp:137] Memory required for data: 2621194320
I0528 19:00:47.328788 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0528 19:00:47.328799 11123 net.cpp:84] Creating Layer layer_128_2_conv3
I0528 19:00:47.328802 11123 net.cpp:406] layer_128_2_conv3 <- layer_128_2_conv2
I0528 19:00:47.328809 11123 net.cpp:380] layer_128_2_conv3 -> layer_128_2_conv3
I0528 19:00:47.330101 11123 net.cpp:122] Setting up layer_128_2_conv3
I0528 19:00:47.330112 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330116 11123 net.cpp:137] Memory required for data: 2653306960
I0528 19:00:47.330121 11123 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 19:00:47.330128 11123 net.cpp:84] Creating Layer layer_128_2_sum
I0528 19:00:47.330133 11123 net.cpp:406] layer_128_2_sum <- layer_128_2_conv3
I0528 19:00:47.330137 11123 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 19:00:47.330142 11123 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 19:00:47.330168 11123 net.cpp:122] Setting up layer_128_2_sum
I0528 19:00:47.330176 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330179 11123 net.cpp:137] Memory required for data: 2685419600
I0528 19:00:47.330183 11123 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.330188 11123 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.330191 11123 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0528 19:00:47.330199 11123 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 19:00:47.330204 11123 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 19:00:47.330240 11123 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.330247 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330251 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330255 11123 net.cpp:137] Memory required for data: 2749644880
I0528 19:00:47.330257 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0528 19:00:47.330263 11123 net.cpp:84] Creating Layer layer_128_3_bn1
I0528 19:00:47.330268 11123 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 19:00:47.330273 11123 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0528 19:00:47.330436 11123 net.cpp:122] Setting up layer_128_3_bn1
I0528 19:00:47.330446 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330448 11123 net.cpp:137] Memory required for data: 2781757520
I0528 19:00:47.330456 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 19:00:47.330462 11123 net.cpp:84] Creating Layer layer_128_3_scale1
I0528 19:00:47.330467 11123 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0528 19:00:47.330483 11123 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0528 19:00:47.330525 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 19:00:47.330626 11123 net.cpp:122] Setting up layer_128_3_scale1
I0528 19:00:47.330634 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.330638 11123 net.cpp:137] Memory required for data: 2813870160
I0528 19:00:47.330644 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0528 19:00:47.330649 11123 net.cpp:84] Creating Layer layer_128_3_relu1
I0528 19:00:47.330653 11123 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0528 19:00:47.330659 11123 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0528 19:00:47.331285 11123 net.cpp:122] Setting up layer_128_3_relu1
I0528 19:00:47.331296 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.331300 11123 net.cpp:137] Memory required for data: 2845982800
I0528 19:00:47.331305 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0528 19:00:47.331313 11123 net.cpp:84] Creating Layer layer_128_3_conv1
I0528 19:00:47.331318 11123 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0528 19:00:47.331326 11123 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0528 19:00:47.333778 11123 net.cpp:122] Setting up layer_128_3_conv1
I0528 19:00:47.333791 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.333796 11123 net.cpp:137] Memory required for data: 2854010960
I0528 19:00:47.333801 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0528 19:00:47.333808 11123 net.cpp:84] Creating Layer layer_128_3_bn2
I0528 19:00:47.333814 11123 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0528 19:00:47.333822 11123 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.333987 11123 net.cpp:122] Setting up layer_128_3_bn2
I0528 19:00:47.333997 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.333999 11123 net.cpp:137] Memory required for data: 2862039120
I0528 19:00:47.334007 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 19:00:47.334015 11123 net.cpp:84] Creating Layer layer_128_3_scale2
I0528 19:00:47.334019 11123 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0528 19:00:47.334024 11123 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.334062 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 19:00:47.334161 11123 net.cpp:122] Setting up layer_128_3_scale2
I0528 19:00:47.334169 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.334172 11123 net.cpp:137] Memory required for data: 2870067280
I0528 19:00:47.334177 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0528 19:00:47.334183 11123 net.cpp:84] Creating Layer layer_128_3_relu2
I0528 19:00:47.334188 11123 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0528 19:00:47.334194 11123 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.334344 11123 net.cpp:122] Setting up layer_128_3_relu2
I0528 19:00:47.334354 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.334358 11123 net.cpp:137] Memory required for data: 2878095440
I0528 19:00:47.334362 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0528 19:00:47.334372 11123 net.cpp:84] Creating Layer layer_128_3_conv2
I0528 19:00:47.334377 11123 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0528 19:00:47.334383 11123 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0528 19:00:47.337419 11123 net.cpp:122] Setting up layer_128_3_conv2
I0528 19:00:47.337432 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.337436 11123 net.cpp:137] Memory required for data: 2886123600
I0528 19:00:47.337441 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0528 19:00:47.337448 11123 net.cpp:84] Creating Layer layer_128_3_bn3
I0528 19:00:47.337452 11123 net.cpp:406] layer_128_3_bn3 <- layer_128_3_conv2
I0528 19:00:47.337457 11123 net.cpp:367] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.337637 11123 net.cpp:122] Setting up layer_128_3_bn3
I0528 19:00:47.337646 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.337649 11123 net.cpp:137] Memory required for data: 2894151760
I0528 19:00:47.337656 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0528 19:00:47.337662 11123 net.cpp:84] Creating Layer layer_128_3_scale3
I0528 19:00:47.337667 11123 net.cpp:406] layer_128_3_scale3 <- layer_128_3_conv2
I0528 19:00:47.337676 11123 net.cpp:367] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.337714 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0528 19:00:47.337813 11123 net.cpp:122] Setting up layer_128_3_scale3
I0528 19:00:47.337822 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.337826 11123 net.cpp:137] Memory required for data: 2902179920
I0528 19:00:47.337831 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0528 19:00:47.337836 11123 net.cpp:84] Creating Layer layer_128_3_relu3
I0528 19:00:47.337841 11123 net.cpp:406] layer_128_3_relu3 <- layer_128_3_conv2
I0528 19:00:47.337847 11123 net.cpp:367] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.338001 11123 net.cpp:122] Setting up layer_128_3_relu3
I0528 19:00:47.338011 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.338014 11123 net.cpp:137] Memory required for data: 2910208080
I0528 19:00:47.338017 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0528 19:00:47.338027 11123 net.cpp:84] Creating Layer layer_128_3_conv3
I0528 19:00:47.338032 11123 net.cpp:406] layer_128_3_conv3 <- layer_128_3_conv2
I0528 19:00:47.338038 11123 net.cpp:380] layer_128_3_conv3 -> layer_128_3_conv3
I0528 19:00:47.339792 11123 net.cpp:122] Setting up layer_128_3_conv3
I0528 19:00:47.339805 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.339809 11123 net.cpp:137] Memory required for data: 2942320720
I0528 19:00:47.339815 11123 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0528 19:00:47.339820 11123 net.cpp:84] Creating Layer layer_128_3_sum
I0528 19:00:47.339824 11123 net.cpp:406] layer_128_3_sum <- layer_128_3_conv3
I0528 19:00:47.339828 11123 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 19:00:47.339835 11123 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0528 19:00:47.339860 11123 net.cpp:122] Setting up layer_128_3_sum
I0528 19:00:47.339869 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.339871 11123 net.cpp:137] Memory required for data: 2974433360
I0528 19:00:47.339874 11123 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.339881 11123 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.339884 11123 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0528 19:00:47.339890 11123 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 19:00:47.339897 11123 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 19:00:47.339931 11123 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.339938 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.339942 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.339946 11123 net.cpp:137] Memory required for data: 3038658640
I0528 19:00:47.339948 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0528 19:00:47.339954 11123 net.cpp:84] Creating Layer layer_128_4_bn1
I0528 19:00:47.339958 11123 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 19:00:47.339964 11123 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0528 19:00:47.340132 11123 net.cpp:122] Setting up layer_128_4_bn1
I0528 19:00:47.340142 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.340144 11123 net.cpp:137] Memory required for data: 3070771280
I0528 19:00:47.340152 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 19:00:47.340168 11123 net.cpp:84] Creating Layer layer_128_4_scale1
I0528 19:00:47.340173 11123 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0528 19:00:47.340178 11123 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0528 19:00:47.340217 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 19:00:47.340315 11123 net.cpp:122] Setting up layer_128_4_scale1
I0528 19:00:47.340324 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.340327 11123 net.cpp:137] Memory required for data: 3102883920
I0528 19:00:47.340332 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0528 19:00:47.340339 11123 net.cpp:84] Creating Layer layer_128_4_relu1
I0528 19:00:47.340344 11123 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0528 19:00:47.340350 11123 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0528 19:00:47.340499 11123 net.cpp:122] Setting up layer_128_4_relu1
I0528 19:00:47.340509 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.340513 11123 net.cpp:137] Memory required for data: 3134996560
I0528 19:00:47.340517 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0528 19:00:47.340526 11123 net.cpp:84] Creating Layer layer_128_4_conv1
I0528 19:00:47.340531 11123 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0528 19:00:47.340538 11123 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0528 19:00:47.342293 11123 net.cpp:122] Setting up layer_128_4_conv1
I0528 19:00:47.342306 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.342309 11123 net.cpp:137] Memory required for data: 3143024720
I0528 19:00:47.342314 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0528 19:00:47.342322 11123 net.cpp:84] Creating Layer layer_128_4_bn2
I0528 19:00:47.342327 11123 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0528 19:00:47.342334 11123 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.342500 11123 net.cpp:122] Setting up layer_128_4_bn2
I0528 19:00:47.342509 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.342514 11123 net.cpp:137] Memory required for data: 3151052880
I0528 19:00:47.342520 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 19:00:47.342530 11123 net.cpp:84] Creating Layer layer_128_4_scale2
I0528 19:00:47.342535 11123 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0528 19:00:47.342540 11123 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.342578 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 19:00:47.342679 11123 net.cpp:122] Setting up layer_128_4_scale2
I0528 19:00:47.342686 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.342690 11123 net.cpp:137] Memory required for data: 3159081040
I0528 19:00:47.342695 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0528 19:00:47.342701 11123 net.cpp:84] Creating Layer layer_128_4_relu2
I0528 19:00:47.342705 11123 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0528 19:00:47.342711 11123 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.342864 11123 net.cpp:122] Setting up layer_128_4_relu2
I0528 19:00:47.342874 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.342876 11123 net.cpp:137] Memory required for data: 3167109200
I0528 19:00:47.342880 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0528 19:00:47.342890 11123 net.cpp:84] Creating Layer layer_128_4_conv2
I0528 19:00:47.342893 11123 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0528 19:00:47.342900 11123 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0528 19:00:47.345942 11123 net.cpp:122] Setting up layer_128_4_conv2
I0528 19:00:47.345954 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.345957 11123 net.cpp:137] Memory required for data: 3175137360
I0528 19:00:47.345978 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0528 19:00:47.345988 11123 net.cpp:84] Creating Layer layer_128_4_bn3
I0528 19:00:47.345993 11123 net.cpp:406] layer_128_4_bn3 <- layer_128_4_conv2
I0528 19:00:47.346009 11123 net.cpp:367] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.346179 11123 net.cpp:122] Setting up layer_128_4_bn3
I0528 19:00:47.346189 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.346194 11123 net.cpp:137] Memory required for data: 3183165520
I0528 19:00:47.346200 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0528 19:00:47.346207 11123 net.cpp:84] Creating Layer layer_128_4_scale3
I0528 19:00:47.346211 11123 net.cpp:406] layer_128_4_scale3 <- layer_128_4_conv2
I0528 19:00:47.346216 11123 net.cpp:367] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.346256 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0528 19:00:47.346356 11123 net.cpp:122] Setting up layer_128_4_scale3
I0528 19:00:47.346365 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.346369 11123 net.cpp:137] Memory required for data: 3191193680
I0528 19:00:47.346375 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0528 19:00:47.346381 11123 net.cpp:84] Creating Layer layer_128_4_relu3
I0528 19:00:47.346385 11123 net.cpp:406] layer_128_4_relu3 <- layer_128_4_conv2
I0528 19:00:47.346392 11123 net.cpp:367] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.347020 11123 net.cpp:122] Setting up layer_128_4_relu3
I0528 19:00:47.347031 11123 net.cpp:129] Top shape: 20 128 28 28 (2007040)
I0528 19:00:47.347035 11123 net.cpp:137] Memory required for data: 3199221840
I0528 19:00:47.347039 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0528 19:00:47.347050 11123 net.cpp:84] Creating Layer layer_128_4_conv3
I0528 19:00:47.347055 11123 net.cpp:406] layer_128_4_conv3 <- layer_128_4_conv2
I0528 19:00:47.347061 11123 net.cpp:380] layer_128_4_conv3 -> layer_128_4_conv3
I0528 19:00:47.349426 11123 net.cpp:122] Setting up layer_128_4_conv3
I0528 19:00:47.349439 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.349442 11123 net.cpp:137] Memory required for data: 3231334480
I0528 19:00:47.349447 11123 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0528 19:00:47.349453 11123 net.cpp:84] Creating Layer layer_128_4_sum
I0528 19:00:47.349457 11123 net.cpp:406] layer_128_4_sum <- layer_128_4_conv3
I0528 19:00:47.349462 11123 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 19:00:47.349467 11123 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0528 19:00:47.349494 11123 net.cpp:122] Setting up layer_128_4_sum
I0528 19:00:47.349504 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.349508 11123 net.cpp:137] Memory required for data: 3263447120
I0528 19:00:47.349510 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 19:00:47.349515 11123 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 19:00:47.349519 11123 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0528 19:00:47.349525 11123 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 19:00:47.349704 11123 net.cpp:122] Setting up layer_256_1_bn1
I0528 19:00:47.349712 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.349715 11123 net.cpp:137] Memory required for data: 3295559760
I0528 19:00:47.349722 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 19:00:47.349731 11123 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 19:00:47.349735 11123 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 19:00:47.349740 11123 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 19:00:47.349781 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 19:00:47.349884 11123 net.cpp:122] Setting up layer_256_1_scale1
I0528 19:00:47.349892 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.349895 11123 net.cpp:137] Memory required for data: 3327672400
I0528 19:00:47.349900 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 19:00:47.349906 11123 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 19:00:47.349910 11123 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 19:00:47.349926 11123 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 19:00:47.350575 11123 net.cpp:122] Setting up layer_256_1_relu1
I0528 19:00:47.350589 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.350592 11123 net.cpp:137] Memory required for data: 3359785040
I0528 19:00:47.350595 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.350601 11123 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.350605 11123 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 19:00:47.350610 11123 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 19:00:47.350620 11123 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 19:00:47.350661 11123 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.350668 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.350673 11123 net.cpp:129] Top shape: 20 512 28 28 (8028160)
I0528 19:00:47.350677 11123 net.cpp:137] Memory required for data: 3424010320
I0528 19:00:47.350680 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 19:00:47.350692 11123 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 19:00:47.350697 11123 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 19:00:47.350702 11123 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 19:00:47.353844 11123 net.cpp:122] Setting up layer_256_1_conv1
I0528 19:00:47.353858 11123 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0528 19:00:47.353863 11123 net.cpp:137] Memory required for data: 3440066640
I0528 19:00:47.353868 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 19:00:47.353875 11123 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 19:00:47.353880 11123 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 19:00:47.353886 11123 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.354060 11123 net.cpp:122] Setting up layer_256_1_bn2
I0528 19:00:47.354068 11123 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0528 19:00:47.354073 11123 net.cpp:137] Memory required for data: 3456122960
I0528 19:00:47.354079 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 19:00:47.354086 11123 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 19:00:47.354091 11123 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 19:00:47.354095 11123 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.354135 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 19:00:47.354240 11123 net.cpp:122] Setting up layer_256_1_scale2
I0528 19:00:47.354250 11123 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0528 19:00:47.354254 11123 net.cpp:137] Memory required for data: 3472179280
I0528 19:00:47.354260 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 19:00:47.354266 11123 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 19:00:47.354271 11123 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 19:00:47.354275 11123 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.354431 11123 net.cpp:122] Setting up layer_256_1_relu2
I0528 19:00:47.354441 11123 net.cpp:129] Top shape: 20 256 28 28 (4014080)
I0528 19:00:47.354445 11123 net.cpp:137] Memory required for data: 3488235600
I0528 19:00:47.354449 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 19:00:47.354459 11123 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 19:00:47.354463 11123 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 19:00:47.354470 11123 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 19:00:47.362171 11123 net.cpp:122] Setting up layer_256_1_conv2
I0528 19:00:47.362187 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.362192 11123 net.cpp:137] Memory required for data: 3492249680
I0528 19:00:47.362198 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn3
I0528 19:00:47.362215 11123 net.cpp:84] Creating Layer layer_256_1_bn3
I0528 19:00:47.362220 11123 net.cpp:406] layer_256_1_bn3 <- layer_256_1_conv2
I0528 19:00:47.362226 11123 net.cpp:367] layer_256_1_bn3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.362403 11123 net.cpp:122] Setting up layer_256_1_bn3
I0528 19:00:47.362412 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.362416 11123 net.cpp:137] Memory required for data: 3496263760
I0528 19:00:47.362423 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0528 19:00:47.362431 11123 net.cpp:84] Creating Layer layer_256_1_scale3
I0528 19:00:47.362434 11123 net.cpp:406] layer_256_1_scale3 <- layer_256_1_conv2
I0528 19:00:47.362439 11123 net.cpp:367] layer_256_1_scale3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.362480 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0528 19:00:47.362581 11123 net.cpp:122] Setting up layer_256_1_scale3
I0528 19:00:47.362592 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.362596 11123 net.cpp:137] Memory required for data: 3500277840
I0528 19:00:47.362602 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu3
I0528 19:00:47.362608 11123 net.cpp:84] Creating Layer layer_256_1_relu3
I0528 19:00:47.362612 11123 net.cpp:406] layer_256_1_relu3 <- layer_256_1_conv2
I0528 19:00:47.362617 11123 net.cpp:367] layer_256_1_relu3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.362769 11123 net.cpp:122] Setting up layer_256_1_relu3
I0528 19:00:47.362779 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.362783 11123 net.cpp:137] Memory required for data: 3504291920
I0528 19:00:47.362787 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv3
I0528 19:00:47.362797 11123 net.cpp:84] Creating Layer layer_256_1_conv3
I0528 19:00:47.362802 11123 net.cpp:406] layer_256_1_conv3 <- layer_256_1_conv2
I0528 19:00:47.362808 11123 net.cpp:380] layer_256_1_conv3 -> layer_256_1_conv3
I0528 19:00:47.366541 11123 net.cpp:122] Setting up layer_256_1_conv3
I0528 19:00:47.366554 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.366557 11123 net.cpp:137] Memory required for data: 3520348240
I0528 19:00:47.366564 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 19:00:47.366572 11123 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 19:00:47.366577 11123 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 19:00:47.366585 11123 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 19:00:47.373598 11123 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 19:00:47.373611 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.373615 11123 net.cpp:137] Memory required for data: 3536404560
I0528 19:00:47.373621 11123 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 19:00:47.373631 11123 net.cpp:84] Creating Layer layer_256_1_sum
I0528 19:00:47.373636 11123 net.cpp:406] layer_256_1_sum <- layer_256_1_conv3
I0528 19:00:47.373639 11123 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 19:00:47.373646 11123 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 19:00:47.373675 11123 net.cpp:122] Setting up layer_256_1_sum
I0528 19:00:47.373683 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.373687 11123 net.cpp:137] Memory required for data: 3552460880
I0528 19:00:47.373690 11123 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.373695 11123 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.373700 11123 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 19:00:47.373706 11123 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 19:00:47.373713 11123 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 19:00:47.373762 11123 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.373770 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.373785 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.373790 11123 net.cpp:137] Memory required for data: 3584573520
I0528 19:00:47.373792 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 19:00:47.373798 11123 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 19:00:47.373802 11123 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 19:00:47.373811 11123 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 19:00:47.374001 11123 net.cpp:122] Setting up layer_256_2_bn1
I0528 19:00:47.374011 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.374013 11123 net.cpp:137] Memory required for data: 3600629840
I0528 19:00:47.374022 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 19:00:47.374029 11123 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 19:00:47.374034 11123 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 19:00:47.374039 11123 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 19:00:47.374079 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 19:00:47.374187 11123 net.cpp:122] Setting up layer_256_2_scale1
I0528 19:00:47.374195 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.374199 11123 net.cpp:137] Memory required for data: 3616686160
I0528 19:00:47.374205 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 19:00:47.374213 11123 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 19:00:47.374217 11123 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 19:00:47.374222 11123 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 19:00:47.374858 11123 net.cpp:122] Setting up layer_256_2_relu1
I0528 19:00:47.374871 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.374874 11123 net.cpp:137] Memory required for data: 3632742480
I0528 19:00:47.374877 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 19:00:47.374887 11123 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 19:00:47.374892 11123 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 19:00:47.374900 11123 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 19:00:47.379329 11123 net.cpp:122] Setting up layer_256_2_conv1
I0528 19:00:47.379344 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.379348 11123 net.cpp:137] Memory required for data: 3636756560
I0528 19:00:47.379354 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 19:00:47.379361 11123 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 19:00:47.379365 11123 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 19:00:47.379372 11123 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.379549 11123 net.cpp:122] Setting up layer_256_2_bn2
I0528 19:00:47.379557 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.379561 11123 net.cpp:137] Memory required for data: 3640770640
I0528 19:00:47.379568 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 19:00:47.379575 11123 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 19:00:47.379580 11123 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 19:00:47.379586 11123 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.379626 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 19:00:47.379726 11123 net.cpp:122] Setting up layer_256_2_scale2
I0528 19:00:47.379736 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.379739 11123 net.cpp:137] Memory required for data: 3644784720
I0528 19:00:47.379745 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 19:00:47.379751 11123 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 19:00:47.379755 11123 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 19:00:47.379760 11123 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.379909 11123 net.cpp:122] Setting up layer_256_2_relu2
I0528 19:00:47.379920 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.379931 11123 net.cpp:137] Memory required for data: 3648798800
I0528 19:00:47.379935 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 19:00:47.379967 11123 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 19:00:47.379972 11123 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 19:00:47.379978 11123 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 19:00:47.388291 11123 net.cpp:122] Setting up layer_256_2_conv2
I0528 19:00:47.388312 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.388315 11123 net.cpp:137] Memory required for data: 3652812880
I0528 19:00:47.388324 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn3
I0528 19:00:47.388334 11123 net.cpp:84] Creating Layer layer_256_2_bn3
I0528 19:00:47.388339 11123 net.cpp:406] layer_256_2_bn3 <- layer_256_2_conv2
I0528 19:00:47.388345 11123 net.cpp:367] layer_256_2_bn3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.388531 11123 net.cpp:122] Setting up layer_256_2_bn3
I0528 19:00:47.388540 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.388543 11123 net.cpp:137] Memory required for data: 3656826960
I0528 19:00:47.388551 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0528 19:00:47.388561 11123 net.cpp:84] Creating Layer layer_256_2_scale3
I0528 19:00:47.388566 11123 net.cpp:406] layer_256_2_scale3 <- layer_256_2_conv2
I0528 19:00:47.388571 11123 net.cpp:367] layer_256_2_scale3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.388617 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0528 19:00:47.388723 11123 net.cpp:122] Setting up layer_256_2_scale3
I0528 19:00:47.388731 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.388736 11123 net.cpp:137] Memory required for data: 3660841040
I0528 19:00:47.388741 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu3
I0528 19:00:47.388747 11123 net.cpp:84] Creating Layer layer_256_2_relu3
I0528 19:00:47.388751 11123 net.cpp:406] layer_256_2_relu3 <- layer_256_2_conv2
I0528 19:00:47.388757 11123 net.cpp:367] layer_256_2_relu3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.388912 11123 net.cpp:122] Setting up layer_256_2_relu3
I0528 19:00:47.388922 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.388931 11123 net.cpp:137] Memory required for data: 3664855120
I0528 19:00:47.388936 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv3
I0528 19:00:47.388945 11123 net.cpp:84] Creating Layer layer_256_2_conv3
I0528 19:00:47.388950 11123 net.cpp:406] layer_256_2_conv3 <- layer_256_2_conv2
I0528 19:00:47.388957 11123 net.cpp:380] layer_256_2_conv3 -> layer_256_2_conv3
I0528 19:00:47.392727 11123 net.cpp:122] Setting up layer_256_2_conv3
I0528 19:00:47.392740 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.392743 11123 net.cpp:137] Memory required for data: 3680911440
I0528 19:00:47.392748 11123 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 19:00:47.392757 11123 net.cpp:84] Creating Layer layer_256_2_sum
I0528 19:00:47.392762 11123 net.cpp:406] layer_256_2_sum <- layer_256_2_conv3
I0528 19:00:47.392766 11123 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 19:00:47.392772 11123 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 19:00:47.392803 11123 net.cpp:122] Setting up layer_256_2_sum
I0528 19:00:47.392810 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.392814 11123 net.cpp:137] Memory required for data: 3696967760
I0528 19:00:47.392817 11123 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.392823 11123 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.392827 11123 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0528 19:00:47.392834 11123 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 19:00:47.392841 11123 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 19:00:47.392894 11123 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.392902 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.392907 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.392910 11123 net.cpp:137] Memory required for data: 3729080400
I0528 19:00:47.392913 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0528 19:00:47.392920 11123 net.cpp:84] Creating Layer layer_256_3_bn1
I0528 19:00:47.392927 11123 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 19:00:47.392935 11123 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0528 19:00:47.393121 11123 net.cpp:122] Setting up layer_256_3_bn1
I0528 19:00:47.393131 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.393133 11123 net.cpp:137] Memory required for data: 3745136720
I0528 19:00:47.393141 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 19:00:47.393149 11123 net.cpp:84] Creating Layer layer_256_3_scale1
I0528 19:00:47.393153 11123 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0528 19:00:47.393158 11123 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0528 19:00:47.393198 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 19:00:47.393307 11123 net.cpp:122] Setting up layer_256_3_scale1
I0528 19:00:47.393316 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.393321 11123 net.cpp:137] Memory required for data: 3761193040
I0528 19:00:47.393326 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0528 19:00:47.393335 11123 net.cpp:84] Creating Layer layer_256_3_relu1
I0528 19:00:47.393339 11123 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0528 19:00:47.393344 11123 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0528 19:00:47.393985 11123 net.cpp:122] Setting up layer_256_3_relu1
I0528 19:00:47.393996 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.393999 11123 net.cpp:137] Memory required for data: 3777249360
I0528 19:00:47.394003 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0528 19:00:47.394013 11123 net.cpp:84] Creating Layer layer_256_3_conv1
I0528 19:00:47.394017 11123 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0528 19:00:47.394026 11123 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0528 19:00:47.397975 11123 net.cpp:122] Setting up layer_256_3_conv1
I0528 19:00:47.397989 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.397994 11123 net.cpp:137] Memory required for data: 3781263440
I0528 19:00:47.398000 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0528 19:00:47.398007 11123 net.cpp:84] Creating Layer layer_256_3_bn2
I0528 19:00:47.398012 11123 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0528 19:00:47.398018 11123 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.398196 11123 net.cpp:122] Setting up layer_256_3_bn2
I0528 19:00:47.398205 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.398208 11123 net.cpp:137] Memory required for data: 3785277520
I0528 19:00:47.398216 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 19:00:47.398223 11123 net.cpp:84] Creating Layer layer_256_3_scale2
I0528 19:00:47.398228 11123 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0528 19:00:47.398233 11123 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.398274 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 19:00:47.398380 11123 net.cpp:122] Setting up layer_256_3_scale2
I0528 19:00:47.398387 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.398391 11123 net.cpp:137] Memory required for data: 3789291600
I0528 19:00:47.398397 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0528 19:00:47.398404 11123 net.cpp:84] Creating Layer layer_256_3_relu2
I0528 19:00:47.398409 11123 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0528 19:00:47.398413 11123 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.399075 11123 net.cpp:122] Setting up layer_256_3_relu2
I0528 19:00:47.399087 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.399091 11123 net.cpp:137] Memory required for data: 3793305680
I0528 19:00:47.399094 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0528 19:00:47.399104 11123 net.cpp:84] Creating Layer layer_256_3_conv2
I0528 19:00:47.399108 11123 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0528 19:00:47.399116 11123 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0528 19:00:47.407308 11123 net.cpp:122] Setting up layer_256_3_conv2
I0528 19:00:47.407321 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.407325 11123 net.cpp:137] Memory required for data: 3797319760
I0528 19:00:47.407330 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn3
I0528 19:00:47.407337 11123 net.cpp:84] Creating Layer layer_256_3_bn3
I0528 19:00:47.407342 11123 net.cpp:406] layer_256_3_bn3 <- layer_256_3_conv2
I0528 19:00:47.407349 11123 net.cpp:367] layer_256_3_bn3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.407532 11123 net.cpp:122] Setting up layer_256_3_bn3
I0528 19:00:47.407541 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.407546 11123 net.cpp:137] Memory required for data: 3801333840
I0528 19:00:47.407553 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0528 19:00:47.407560 11123 net.cpp:84] Creating Layer layer_256_3_scale3
I0528 19:00:47.407564 11123 net.cpp:406] layer_256_3_scale3 <- layer_256_3_conv2
I0528 19:00:47.407572 11123 net.cpp:367] layer_256_3_scale3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.407613 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0528 19:00:47.407718 11123 net.cpp:122] Setting up layer_256_3_scale3
I0528 19:00:47.407727 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.407730 11123 net.cpp:137] Memory required for data: 3805347920
I0528 19:00:47.407737 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu3
I0528 19:00:47.407743 11123 net.cpp:84] Creating Layer layer_256_3_relu3
I0528 19:00:47.407747 11123 net.cpp:406] layer_256_3_relu3 <- layer_256_3_conv2
I0528 19:00:47.407752 11123 net.cpp:367] layer_256_3_relu3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.407910 11123 net.cpp:122] Setting up layer_256_3_relu3
I0528 19:00:47.407920 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.407923 11123 net.cpp:137] Memory required for data: 3809362000
I0528 19:00:47.407927 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv3
I0528 19:00:47.407937 11123 net.cpp:84] Creating Layer layer_256_3_conv3
I0528 19:00:47.407941 11123 net.cpp:406] layer_256_3_conv3 <- layer_256_3_conv2
I0528 19:00:47.407949 11123 net.cpp:380] layer_256_3_conv3 -> layer_256_3_conv3
I0528 19:00:47.411700 11123 net.cpp:122] Setting up layer_256_3_conv3
I0528 19:00:47.411712 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.411718 11123 net.cpp:137] Memory required for data: 3825418320
I0528 19:00:47.411725 11123 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0528 19:00:47.411731 11123 net.cpp:84] Creating Layer layer_256_3_sum
I0528 19:00:47.411736 11123 net.cpp:406] layer_256_3_sum <- layer_256_3_conv3
I0528 19:00:47.411739 11123 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 19:00:47.411747 11123 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0528 19:00:47.411778 11123 net.cpp:122] Setting up layer_256_3_sum
I0528 19:00:47.411787 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.411789 11123 net.cpp:137] Memory required for data: 3841474640
I0528 19:00:47.411793 11123 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.411798 11123 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.411803 11123 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0528 19:00:47.411809 11123 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 19:00:47.411826 11123 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 19:00:47.411866 11123 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.411875 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.411880 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.411882 11123 net.cpp:137] Memory required for data: 3873587280
I0528 19:00:47.411885 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0528 19:00:47.411892 11123 net.cpp:84] Creating Layer layer_256_4_bn1
I0528 19:00:47.411896 11123 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 19:00:47.411905 11123 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0528 19:00:47.412096 11123 net.cpp:122] Setting up layer_256_4_bn1
I0528 19:00:47.412104 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.412108 11123 net.cpp:137] Memory required for data: 3889643600
I0528 19:00:47.412116 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 19:00:47.412122 11123 net.cpp:84] Creating Layer layer_256_4_scale1
I0528 19:00:47.412127 11123 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0528 19:00:47.412132 11123 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0528 19:00:47.412173 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 19:00:47.412283 11123 net.cpp:122] Setting up layer_256_4_scale1
I0528 19:00:47.412292 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.412295 11123 net.cpp:137] Memory required for data: 3905699920
I0528 19:00:47.412302 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0528 19:00:47.412308 11123 net.cpp:84] Creating Layer layer_256_4_relu1
I0528 19:00:47.412313 11123 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0528 19:00:47.412317 11123 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0528 19:00:47.412472 11123 net.cpp:122] Setting up layer_256_4_relu1
I0528 19:00:47.412482 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.412484 11123 net.cpp:137] Memory required for data: 3921756240
I0528 19:00:47.412488 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0528 19:00:47.412497 11123 net.cpp:84] Creating Layer layer_256_4_conv1
I0528 19:00:47.412503 11123 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0528 19:00:47.412509 11123 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0528 19:00:47.417362 11123 net.cpp:122] Setting up layer_256_4_conv1
I0528 19:00:47.417379 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.417382 11123 net.cpp:137] Memory required for data: 3925770320
I0528 19:00:47.417388 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0528 19:00:47.417399 11123 net.cpp:84] Creating Layer layer_256_4_bn2
I0528 19:00:47.417404 11123 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0528 19:00:47.417410 11123 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.417594 11123 net.cpp:122] Setting up layer_256_4_bn2
I0528 19:00:47.417603 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.417606 11123 net.cpp:137] Memory required for data: 3929784400
I0528 19:00:47.417613 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 19:00:47.417623 11123 net.cpp:84] Creating Layer layer_256_4_scale2
I0528 19:00:47.417626 11123 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0528 19:00:47.417631 11123 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.417677 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 19:00:47.417784 11123 net.cpp:122] Setting up layer_256_4_scale2
I0528 19:00:47.417793 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.417796 11123 net.cpp:137] Memory required for data: 3933798480
I0528 19:00:47.417803 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0528 19:00:47.417809 11123 net.cpp:84] Creating Layer layer_256_4_relu2
I0528 19:00:47.417814 11123 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0528 19:00:47.417830 11123 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.417985 11123 net.cpp:122] Setting up layer_256_4_relu2
I0528 19:00:47.417996 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.418000 11123 net.cpp:137] Memory required for data: 3937812560
I0528 19:00:47.418004 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0528 19:00:47.418012 11123 net.cpp:84] Creating Layer layer_256_4_conv2
I0528 19:00:47.418017 11123 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0528 19:00:47.418025 11123 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0528 19:00:47.426270 11123 net.cpp:122] Setting up layer_256_4_conv2
I0528 19:00:47.426285 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.426288 11123 net.cpp:137] Memory required for data: 3941826640
I0528 19:00:47.426295 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn3
I0528 19:00:47.426301 11123 net.cpp:84] Creating Layer layer_256_4_bn3
I0528 19:00:47.426306 11123 net.cpp:406] layer_256_4_bn3 <- layer_256_4_conv2
I0528 19:00:47.426313 11123 net.cpp:367] layer_256_4_bn3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.426499 11123 net.cpp:122] Setting up layer_256_4_bn3
I0528 19:00:47.426508 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.426512 11123 net.cpp:137] Memory required for data: 3945840720
I0528 19:00:47.426519 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0528 19:00:47.426527 11123 net.cpp:84] Creating Layer layer_256_4_scale3
I0528 19:00:47.426530 11123 net.cpp:406] layer_256_4_scale3 <- layer_256_4_conv2
I0528 19:00:47.426537 11123 net.cpp:367] layer_256_4_scale3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.426578 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0528 19:00:47.426687 11123 net.cpp:122] Setting up layer_256_4_scale3
I0528 19:00:47.426695 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.426699 11123 net.cpp:137] Memory required for data: 3949854800
I0528 19:00:47.426705 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu3
I0528 19:00:47.426712 11123 net.cpp:84] Creating Layer layer_256_4_relu3
I0528 19:00:47.426715 11123 net.cpp:406] layer_256_4_relu3 <- layer_256_4_conv2
I0528 19:00:47.426720 11123 net.cpp:367] layer_256_4_relu3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.426880 11123 net.cpp:122] Setting up layer_256_4_relu3
I0528 19:00:47.426890 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.426893 11123 net.cpp:137] Memory required for data: 3953868880
I0528 19:00:47.426898 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv3
I0528 19:00:47.426906 11123 net.cpp:84] Creating Layer layer_256_4_conv3
I0528 19:00:47.426911 11123 net.cpp:406] layer_256_4_conv3 <- layer_256_4_conv2
I0528 19:00:47.426918 11123 net.cpp:380] layer_256_4_conv3 -> layer_256_4_conv3
I0528 19:00:47.430704 11123 net.cpp:122] Setting up layer_256_4_conv3
I0528 19:00:47.430717 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.430722 11123 net.cpp:137] Memory required for data: 3969925200
I0528 19:00:47.430727 11123 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0528 19:00:47.430734 11123 net.cpp:84] Creating Layer layer_256_4_sum
I0528 19:00:47.430739 11123 net.cpp:406] layer_256_4_sum <- layer_256_4_conv3
I0528 19:00:47.430743 11123 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 19:00:47.430752 11123 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0528 19:00:47.430780 11123 net.cpp:122] Setting up layer_256_4_sum
I0528 19:00:47.430790 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.430794 11123 net.cpp:137] Memory required for data: 3985981520
I0528 19:00:47.430797 11123 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.430804 11123 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.430807 11123 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0528 19:00:47.430824 11123 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 19:00:47.430832 11123 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 19:00:47.430872 11123 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.430879 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.430884 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.430887 11123 net.cpp:137] Memory required for data: 4018094160
I0528 19:00:47.430891 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0528 19:00:47.430897 11123 net.cpp:84] Creating Layer layer_256_5_bn1
I0528 19:00:47.430902 11123 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 19:00:47.430908 11123 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0528 19:00:47.431102 11123 net.cpp:122] Setting up layer_256_5_bn1
I0528 19:00:47.431110 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.431114 11123 net.cpp:137] Memory required for data: 4034150480
I0528 19:00:47.431121 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 19:00:47.431128 11123 net.cpp:84] Creating Layer layer_256_5_scale1
I0528 19:00:47.431133 11123 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0528 19:00:47.431138 11123 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0528 19:00:47.431179 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 19:00:47.431290 11123 net.cpp:122] Setting up layer_256_5_scale1
I0528 19:00:47.431299 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.431303 11123 net.cpp:137] Memory required for data: 4050206800
I0528 19:00:47.431309 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0528 19:00:47.431316 11123 net.cpp:84] Creating Layer layer_256_5_relu1
I0528 19:00:47.431320 11123 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0528 19:00:47.431325 11123 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0528 19:00:47.431975 11123 net.cpp:122] Setting up layer_256_5_relu1
I0528 19:00:47.431988 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.431993 11123 net.cpp:137] Memory required for data: 4066263120
I0528 19:00:47.431996 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0528 19:00:47.432006 11123 net.cpp:84] Creating Layer layer_256_5_conv1
I0528 19:00:47.432010 11123 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0528 19:00:47.432018 11123 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0528 19:00:47.435987 11123 net.cpp:122] Setting up layer_256_5_conv1
I0528 19:00:47.436000 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.436004 11123 net.cpp:137] Memory required for data: 4070277200
I0528 19:00:47.436010 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0528 19:00:47.436018 11123 net.cpp:84] Creating Layer layer_256_5_bn2
I0528 19:00:47.436023 11123 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0528 19:00:47.436028 11123 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.436210 11123 net.cpp:122] Setting up layer_256_5_bn2
I0528 19:00:47.436218 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.436223 11123 net.cpp:137] Memory required for data: 4074291280
I0528 19:00:47.436230 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 19:00:47.436239 11123 net.cpp:84] Creating Layer layer_256_5_scale2
I0528 19:00:47.436244 11123 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0528 19:00:47.436249 11123 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.436290 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 19:00:47.436398 11123 net.cpp:122] Setting up layer_256_5_scale2
I0528 19:00:47.436408 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.436411 11123 net.cpp:137] Memory required for data: 4078305360
I0528 19:00:47.436416 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0528 19:00:47.436432 11123 net.cpp:84] Creating Layer layer_256_5_relu2
I0528 19:00:47.436436 11123 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0528 19:00:47.436444 11123 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.437094 11123 net.cpp:122] Setting up layer_256_5_relu2
I0528 19:00:47.437105 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.437110 11123 net.cpp:137] Memory required for data: 4082319440
I0528 19:00:47.437114 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0528 19:00:47.437124 11123 net.cpp:84] Creating Layer layer_256_5_conv2
I0528 19:00:47.437129 11123 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0528 19:00:47.437135 11123 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0528 19:00:47.445379 11123 net.cpp:122] Setting up layer_256_5_conv2
I0528 19:00:47.445394 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.445399 11123 net.cpp:137] Memory required for data: 4086333520
I0528 19:00:47.445405 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn3
I0528 19:00:47.445411 11123 net.cpp:84] Creating Layer layer_256_5_bn3
I0528 19:00:47.445415 11123 net.cpp:406] layer_256_5_bn3 <- layer_256_5_conv2
I0528 19:00:47.445422 11123 net.cpp:367] layer_256_5_bn3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.445610 11123 net.cpp:122] Setting up layer_256_5_bn3
I0528 19:00:47.445618 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.445621 11123 net.cpp:137] Memory required for data: 4090347600
I0528 19:00:47.445629 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0528 19:00:47.445637 11123 net.cpp:84] Creating Layer layer_256_5_scale3
I0528 19:00:47.445641 11123 net.cpp:406] layer_256_5_scale3 <- layer_256_5_conv2
I0528 19:00:47.445647 11123 net.cpp:367] layer_256_5_scale3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.445691 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0528 19:00:47.445802 11123 net.cpp:122] Setting up layer_256_5_scale3
I0528 19:00:47.445811 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.445816 11123 net.cpp:137] Memory required for data: 4094361680
I0528 19:00:47.445821 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu3
I0528 19:00:47.445828 11123 net.cpp:84] Creating Layer layer_256_5_relu3
I0528 19:00:47.445832 11123 net.cpp:406] layer_256_5_relu3 <- layer_256_5_conv2
I0528 19:00:47.445837 11123 net.cpp:367] layer_256_5_relu3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.445998 11123 net.cpp:122] Setting up layer_256_5_relu3
I0528 19:00:47.446008 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.446012 11123 net.cpp:137] Memory required for data: 4098375760
I0528 19:00:47.446015 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv3
I0528 19:00:47.446024 11123 net.cpp:84] Creating Layer layer_256_5_conv3
I0528 19:00:47.446029 11123 net.cpp:406] layer_256_5_conv3 <- layer_256_5_conv2
I0528 19:00:47.446036 11123 net.cpp:380] layer_256_5_conv3 -> layer_256_5_conv3
I0528 19:00:47.449834 11123 net.cpp:122] Setting up layer_256_5_conv3
I0528 19:00:47.449849 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.449852 11123 net.cpp:137] Memory required for data: 4114432080
I0528 19:00:47.449858 11123 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0528 19:00:47.449865 11123 net.cpp:84] Creating Layer layer_256_5_sum
I0528 19:00:47.449869 11123 net.cpp:406] layer_256_5_sum <- layer_256_5_conv3
I0528 19:00:47.449874 11123 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 19:00:47.449880 11123 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0528 19:00:47.449909 11123 net.cpp:122] Setting up layer_256_5_sum
I0528 19:00:47.449918 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.449920 11123 net.cpp:137] Memory required for data: 4130488400
I0528 19:00:47.449924 11123 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.449931 11123 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.449946 11123 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0528 19:00:47.449952 11123 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 19:00:47.449960 11123 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 19:00:47.450000 11123 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.450008 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.450013 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.450016 11123 net.cpp:137] Memory required for data: 4162601040
I0528 19:00:47.450021 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0528 19:00:47.450027 11123 net.cpp:84] Creating Layer layer_256_6_bn1
I0528 19:00:47.450031 11123 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 19:00:47.450037 11123 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0528 19:00:47.450235 11123 net.cpp:122] Setting up layer_256_6_bn1
I0528 19:00:47.450244 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.450248 11123 net.cpp:137] Memory required for data: 4178657360
I0528 19:00:47.450255 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 19:00:47.450263 11123 net.cpp:84] Creating Layer layer_256_6_scale1
I0528 19:00:47.450268 11123 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0528 19:00:47.450273 11123 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0528 19:00:47.450314 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 19:00:47.450429 11123 net.cpp:122] Setting up layer_256_6_scale1
I0528 19:00:47.450438 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.450441 11123 net.cpp:137] Memory required for data: 4194713680
I0528 19:00:47.450448 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0528 19:00:47.450453 11123 net.cpp:84] Creating Layer layer_256_6_relu1
I0528 19:00:47.450458 11123 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0528 19:00:47.450464 11123 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0528 19:00:47.450619 11123 net.cpp:122] Setting up layer_256_6_relu1
I0528 19:00:47.450629 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.450634 11123 net.cpp:137] Memory required for data: 4210770000
I0528 19:00:47.450636 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0528 19:00:47.450646 11123 net.cpp:84] Creating Layer layer_256_6_conv1
I0528 19:00:47.450651 11123 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0528 19:00:47.450657 11123 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0528 19:00:47.455214 11123 net.cpp:122] Setting up layer_256_6_conv1
I0528 19:00:47.455230 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.455235 11123 net.cpp:137] Memory required for data: 4214784080
I0528 19:00:47.455245 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0528 19:00:47.455256 11123 net.cpp:84] Creating Layer layer_256_6_bn2
I0528 19:00:47.455265 11123 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0528 19:00:47.455277 11123 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.455476 11123 net.cpp:122] Setting up layer_256_6_bn2
I0528 19:00:47.455485 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.455493 11123 net.cpp:137] Memory required for data: 4218798160
I0528 19:00:47.455507 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 19:00:47.455516 11123 net.cpp:84] Creating Layer layer_256_6_scale2
I0528 19:00:47.455523 11123 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0528 19:00:47.455535 11123 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.455585 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 19:00:47.455701 11123 net.cpp:122] Setting up layer_256_6_scale2
I0528 19:00:47.455711 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.455718 11123 net.cpp:137] Memory required for data: 4222812240
I0528 19:00:47.455739 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0528 19:00:47.455749 11123 net.cpp:84] Creating Layer layer_256_6_relu2
I0528 19:00:47.455756 11123 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0528 19:00:47.455766 11123 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.455930 11123 net.cpp:122] Setting up layer_256_6_relu2
I0528 19:00:47.455941 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.455948 11123 net.cpp:137] Memory required for data: 4226826320
I0528 19:00:47.455955 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0528 19:00:47.455971 11123 net.cpp:84] Creating Layer layer_256_6_conv2
I0528 19:00:47.455976 11123 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0528 19:00:47.455989 11123 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0528 19:00:47.464251 11123 net.cpp:122] Setting up layer_256_6_conv2
I0528 19:00:47.464264 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.464272 11123 net.cpp:137] Memory required for data: 4230840400
I0528 19:00:47.464282 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn3
I0528 19:00:47.464294 11123 net.cpp:84] Creating Layer layer_256_6_bn3
I0528 19:00:47.464300 11123 net.cpp:406] layer_256_6_bn3 <- layer_256_6_conv2
I0528 19:00:47.464311 11123 net.cpp:367] layer_256_6_bn3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.464509 11123 net.cpp:122] Setting up layer_256_6_bn3
I0528 19:00:47.464519 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.464524 11123 net.cpp:137] Memory required for data: 4234854480
I0528 19:00:47.464539 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0528 19:00:47.464550 11123 net.cpp:84] Creating Layer layer_256_6_scale3
I0528 19:00:47.464555 11123 net.cpp:406] layer_256_6_scale3 <- layer_256_6_conv2
I0528 19:00:47.464565 11123 net.cpp:367] layer_256_6_scale3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.464617 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0528 19:00:47.464736 11123 net.cpp:122] Setting up layer_256_6_scale3
I0528 19:00:47.464746 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.464753 11123 net.cpp:137] Memory required for data: 4238868560
I0528 19:00:47.464766 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu3
I0528 19:00:47.464776 11123 net.cpp:84] Creating Layer layer_256_6_relu3
I0528 19:00:47.464782 11123 net.cpp:406] layer_256_6_relu3 <- layer_256_6_conv2
I0528 19:00:47.464792 11123 net.cpp:367] layer_256_6_relu3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.464969 11123 net.cpp:122] Setting up layer_256_6_relu3
I0528 19:00:47.464980 11123 net.cpp:129] Top shape: 20 256 14 14 (1003520)
I0528 19:00:47.464987 11123 net.cpp:137] Memory required for data: 4242882640
I0528 19:00:47.464994 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv3
I0528 19:00:47.465009 11123 net.cpp:84] Creating Layer layer_256_6_conv3
I0528 19:00:47.465015 11123 net.cpp:406] layer_256_6_conv3 <- layer_256_6_conv2
I0528 19:00:47.465029 11123 net.cpp:380] layer_256_6_conv3 -> layer_256_6_conv3
I0528 19:00:47.468824 11123 net.cpp:122] Setting up layer_256_6_conv3
I0528 19:00:47.468838 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.468847 11123 net.cpp:137] Memory required for data: 4258938960
I0528 19:00:47.468857 11123 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0528 19:00:47.468869 11123 net.cpp:84] Creating Layer layer_256_6_sum
I0528 19:00:47.468875 11123 net.cpp:406] layer_256_6_sum <- layer_256_6_conv3
I0528 19:00:47.468884 11123 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 19:00:47.468894 11123 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0528 19:00:47.468935 11123 net.cpp:122] Setting up layer_256_6_sum
I0528 19:00:47.468945 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.468951 11123 net.cpp:137] Memory required for data: 4274995280
I0528 19:00:47.468958 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 19:00:47.468981 11123 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 19:00:47.468987 11123 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0528 19:00:47.468997 11123 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 19:00:47.469208 11123 net.cpp:122] Setting up layer_512_1_bn1
I0528 19:00:47.469218 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.469224 11123 net.cpp:137] Memory required for data: 4291051600
I0528 19:00:47.469238 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 19:00:47.469249 11123 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 19:00:47.469255 11123 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 19:00:47.469265 11123 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 19:00:47.469312 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 19:00:47.469439 11123 net.cpp:122] Setting up layer_512_1_scale1
I0528 19:00:47.469449 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.469455 11123 net.cpp:137] Memory required for data: 4307107920
I0528 19:00:47.469467 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 19:00:47.469475 11123 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 19:00:47.469482 11123 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 19:00:47.469493 11123 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 19:00:47.470160 11123 net.cpp:122] Setting up layer_512_1_relu1
I0528 19:00:47.470173 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.470180 11123 net.cpp:137] Memory required for data: 4323164240
I0528 19:00:47.470188 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.470198 11123 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.470206 11123 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 19:00:47.470218 11123 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 19:00:47.470229 11123 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 19:00:47.470281 11123 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.470290 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.470299 11123 net.cpp:129] Top shape: 20 1024 14 14 (4014080)
I0528 19:00:47.470305 11123 net.cpp:137] Memory required for data: 4355276880
I0528 19:00:47.470312 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 19:00:47.470327 11123 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 19:00:47.470333 11123 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 19:00:47.470346 11123 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 19:00:47.476902 11123 net.cpp:122] Setting up layer_512_1_conv1
I0528 19:00:47.476915 11123 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0528 19:00:47.476920 11123 net.cpp:137] Memory required for data: 4363305040
I0528 19:00:47.476934 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 19:00:47.476948 11123 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 19:00:47.476955 11123 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 19:00:47.476968 11123 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.477174 11123 net.cpp:122] Setting up layer_512_1_bn2
I0528 19:00:47.477185 11123 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0528 19:00:47.477191 11123 net.cpp:137] Memory required for data: 4371333200
I0528 19:00:47.477205 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 19:00:47.477214 11123 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 19:00:47.477221 11123 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 19:00:47.477231 11123 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.477279 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 19:00:47.477404 11123 net.cpp:122] Setting up layer_512_1_scale2
I0528 19:00:47.477423 11123 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0528 19:00:47.477430 11123 net.cpp:137] Memory required for data: 4379361360
I0528 19:00:47.477442 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 19:00:47.477453 11123 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 19:00:47.477459 11123 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 19:00:47.477468 11123 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.478634 11123 net.cpp:122] Setting up layer_512_1_relu2
I0528 19:00:47.478649 11123 net.cpp:129] Top shape: 20 512 14 14 (2007040)
I0528 19:00:47.478657 11123 net.cpp:137] Memory required for data: 4387389520
I0528 19:00:47.478663 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 19:00:47.478679 11123 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 19:00:47.478685 11123 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 19:00:47.478698 11123 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 19:00:47.506172 11123 net.cpp:122] Setting up layer_512_1_conv2
I0528 19:00:47.506203 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.506208 11123 net.cpp:137] Memory required for data: 4389396560
I0528 19:00:47.506222 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn3
I0528 19:00:47.506237 11123 net.cpp:84] Creating Layer layer_512_1_bn3
I0528 19:00:47.506245 11123 net.cpp:406] layer_512_1_bn3 <- layer_512_1_conv2
I0528 19:00:47.506258 11123 net.cpp:367] layer_512_1_bn3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.506489 11123 net.cpp:122] Setting up layer_512_1_bn3
I0528 19:00:47.506497 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.506503 11123 net.cpp:137] Memory required for data: 4391403600
I0528 19:00:47.506552 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0528 19:00:47.506564 11123 net.cpp:84] Creating Layer layer_512_1_scale3
I0528 19:00:47.506572 11123 net.cpp:406] layer_512_1_scale3 <- layer_512_1_conv2
I0528 19:00:47.506590 11123 net.cpp:367] layer_512_1_scale3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.506651 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0528 19:00:47.506791 11123 net.cpp:122] Setting up layer_512_1_scale3
I0528 19:00:47.506800 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.506808 11123 net.cpp:137] Memory required for data: 4393410640
I0528 19:00:47.506829 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu3
I0528 19:00:47.506839 11123 net.cpp:84] Creating Layer layer_512_1_relu3
I0528 19:00:47.506845 11123 net.cpp:406] layer_512_1_relu3 <- layer_512_1_conv2
I0528 19:00:47.506856 11123 net.cpp:367] layer_512_1_relu3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.507030 11123 net.cpp:122] Setting up layer_512_1_relu3
I0528 19:00:47.507040 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.507056 11123 net.cpp:137] Memory required for data: 4395417680
I0528 19:00:47.507061 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv3
I0528 19:00:47.507074 11123 net.cpp:84] Creating Layer layer_512_1_conv3
I0528 19:00:47.507081 11123 net.cpp:406] layer_512_1_conv3 <- layer_512_1_conv2
I0528 19:00:47.507091 11123 net.cpp:380] layer_512_1_conv3 -> layer_512_1_conv3
I0528 19:00:47.519778 11123 net.cpp:122] Setting up layer_512_1_conv3
I0528 19:00:47.519798 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.519803 11123 net.cpp:137] Memory required for data: 4403445840
I0528 19:00:47.519809 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 19:00:47.519824 11123 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 19:00:47.519832 11123 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 19:00:47.519855 11123 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 19:00:47.544137 11123 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 19:00:47.544164 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.544168 11123 net.cpp:137] Memory required for data: 4411474000
I0528 19:00:47.544201 11123 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 19:00:47.544225 11123 net.cpp:84] Creating Layer layer_512_1_sum
I0528 19:00:47.544234 11123 net.cpp:406] layer_512_1_sum <- layer_512_1_conv3
I0528 19:00:47.544245 11123 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 19:00:47.544252 11123 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 19:00:47.544301 11123 net.cpp:122] Setting up layer_512_1_sum
I0528 19:00:47.544312 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.544315 11123 net.cpp:137] Memory required for data: 4419502160
I0528 19:00:47.544318 11123 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.544324 11123 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.544328 11123 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 19:00:47.544334 11123 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 19:00:47.544358 11123 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 19:00:47.544405 11123 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.544425 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.544428 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.544431 11123 net.cpp:137] Memory required for data: 4435558480
I0528 19:00:47.544435 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 19:00:47.544442 11123 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 19:00:47.544446 11123 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 19:00:47.544452 11123 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 19:00:47.544706 11123 net.cpp:122] Setting up layer_512_2_bn1
I0528 19:00:47.544715 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.544718 11123 net.cpp:137] Memory required for data: 4443586640
I0528 19:00:47.544725 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 19:00:47.544733 11123 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 19:00:47.544736 11123 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 19:00:47.544742 11123 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 19:00:47.544811 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 19:00:47.544987 11123 net.cpp:122] Setting up layer_512_2_scale1
I0528 19:00:47.545008 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.545012 11123 net.cpp:137] Memory required for data: 4451614800
I0528 19:00:47.545018 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 19:00:47.545024 11123 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 19:00:47.545027 11123 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 19:00:47.545033 11123 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 19:00:47.545212 11123 net.cpp:122] Setting up layer_512_2_relu1
I0528 19:00:47.545220 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.545224 11123 net.cpp:137] Memory required for data: 4459642960
I0528 19:00:47.545228 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 19:00:47.545238 11123 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 19:00:47.545241 11123 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 19:00:47.545249 11123 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 19:00:47.558078 11123 net.cpp:122] Setting up layer_512_2_conv1
I0528 19:00:47.558101 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.558105 11123 net.cpp:137] Memory required for data: 4461650000
I0528 19:00:47.558113 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 19:00:47.558125 11123 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 19:00:47.558130 11123 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 19:00:47.558151 11123 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.558396 11123 net.cpp:122] Setting up layer_512_2_bn2
I0528 19:00:47.558405 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.558408 11123 net.cpp:137] Memory required for data: 4463657040
I0528 19:00:47.558416 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 19:00:47.558423 11123 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 19:00:47.558426 11123 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 19:00:47.558430 11123 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.558497 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 19:00:47.558639 11123 net.cpp:122] Setting up layer_512_2_scale2
I0528 19:00:47.558647 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.558650 11123 net.cpp:137] Memory required for data: 4465664080
I0528 19:00:47.558656 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 19:00:47.558662 11123 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 19:00:47.558665 11123 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 19:00:47.558671 11123 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.558856 11123 net.cpp:122] Setting up layer_512_2_relu2
I0528 19:00:47.558867 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.558871 11123 net.cpp:137] Memory required for data: 4467671120
I0528 19:00:47.558873 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 19:00:47.558884 11123 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 19:00:47.558904 11123 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 19:00:47.558913 11123 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 19:00:47.586211 11123 net.cpp:122] Setting up layer_512_2_conv2
I0528 19:00:47.586241 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.586244 11123 net.cpp:137] Memory required for data: 4469678160
I0528 19:00:47.586256 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn3
I0528 19:00:47.586268 11123 net.cpp:84] Creating Layer layer_512_2_bn3
I0528 19:00:47.586279 11123 net.cpp:406] layer_512_2_bn3 <- layer_512_2_conv2
I0528 19:00:47.586292 11123 net.cpp:367] layer_512_2_bn3 -> layer_512_2_conv2 (in-place)
I0528 19:00:47.586520 11123 net.cpp:122] Setting up layer_512_2_bn3
I0528 19:00:47.586529 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.586532 11123 net.cpp:137] Memory required for data: 4471685200
I0528 19:00:47.586539 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0528 19:00:47.586549 11123 net.cpp:84] Creating Layer layer_512_2_scale3
I0528 19:00:47.586551 11123 net.cpp:406] layer_512_2_scale3 <- layer_512_2_conv2
I0528 19:00:47.586558 11123 net.cpp:367] layer_512_2_scale3 -> layer_512_2_conv2 (in-place)
I0528 19:00:47.586634 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0528 19:00:47.586793 11123 net.cpp:122] Setting up layer_512_2_scale3
I0528 19:00:47.586802 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.586805 11123 net.cpp:137] Memory required for data: 4473692240
I0528 19:00:47.586812 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu3
I0528 19:00:47.586819 11123 net.cpp:84] Creating Layer layer_512_2_relu3
I0528 19:00:47.586822 11123 net.cpp:406] layer_512_2_relu3 <- layer_512_2_conv2
I0528 19:00:47.586828 11123 net.cpp:367] layer_512_2_relu3 -> layer_512_2_conv2 (in-place)
I0528 19:00:47.587013 11123 net.cpp:122] Setting up layer_512_2_relu3
I0528 19:00:47.587023 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.587026 11123 net.cpp:137] Memory required for data: 4475699280
I0528 19:00:47.587029 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv3
I0528 19:00:47.587041 11123 net.cpp:84] Creating Layer layer_512_2_conv3
I0528 19:00:47.587044 11123 net.cpp:406] layer_512_2_conv3 <- layer_512_2_conv2
I0528 19:00:47.587054 11123 net.cpp:380] layer_512_2_conv3 -> layer_512_2_conv3
I0528 19:00:47.600129 11123 net.cpp:122] Setting up layer_512_2_conv3
I0528 19:00:47.600158 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.600183 11123 net.cpp:137] Memory required for data: 4483727440
I0528 19:00:47.600201 11123 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 19:00:47.600214 11123 net.cpp:84] Creating Layer layer_512_2_sum
I0528 19:00:47.600222 11123 net.cpp:406] layer_512_2_sum <- layer_512_2_conv3
I0528 19:00:47.600236 11123 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 19:00:47.600247 11123 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 19:00:47.600289 11123 net.cpp:122] Setting up layer_512_2_sum
I0528 19:00:47.600311 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.600317 11123 net.cpp:137] Memory required for data: 4491755600
I0528 19:00:47.600323 11123 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:47.600333 11123 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:47.600338 11123 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0528 19:00:47.600349 11123 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 19:00:47.600371 11123 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 19:00:47.600420 11123 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:47.600440 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.600450 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.600455 11123 net.cpp:137] Memory required for data: 4507811920
I0528 19:00:47.600461 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0528 19:00:47.600473 11123 net.cpp:84] Creating Layer layer_512_3_bn1
I0528 19:00:47.600478 11123 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 19:00:47.600498 11123 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0528 19:00:47.600738 11123 net.cpp:122] Setting up layer_512_3_bn1
I0528 19:00:47.600747 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.600754 11123 net.cpp:137] Memory required for data: 4515840080
I0528 19:00:47.600778 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 19:00:47.600788 11123 net.cpp:84] Creating Layer layer_512_3_scale1
I0528 19:00:47.600795 11123 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0528 19:00:47.600805 11123 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0528 19:00:47.600870 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 19:00:47.601028 11123 net.cpp:122] Setting up layer_512_3_scale1
I0528 19:00:47.601039 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.601043 11123 net.cpp:137] Memory required for data: 4523868240
I0528 19:00:47.601061 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0528 19:00:47.601068 11123 net.cpp:84] Creating Layer layer_512_3_relu1
I0528 19:00:47.601073 11123 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0528 19:00:47.601078 11123 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0528 19:00:47.601253 11123 net.cpp:122] Setting up layer_512_3_relu1
I0528 19:00:47.601263 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.601270 11123 net.cpp:137] Memory required for data: 4531896400
I0528 19:00:47.601286 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0528 19:00:47.601302 11123 net.cpp:84] Creating Layer layer_512_3_conv1
I0528 19:00:47.601307 11123 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0528 19:00:47.601320 11123 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0528 19:00:47.614068 11123 net.cpp:122] Setting up layer_512_3_conv1
I0528 19:00:47.614092 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.614096 11123 net.cpp:137] Memory required for data: 4533903440
I0528 19:00:47.614104 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0528 19:00:47.614114 11123 net.cpp:84] Creating Layer layer_512_3_bn2
I0528 19:00:47.614118 11123 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0528 19:00:47.614163 11123 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0528 19:00:47.614395 11123 net.cpp:122] Setting up layer_512_3_bn2
I0528 19:00:47.614405 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.614408 11123 net.cpp:137] Memory required for data: 4535910480
I0528 19:00:47.614415 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 19:00:47.614424 11123 net.cpp:84] Creating Layer layer_512_3_scale2
I0528 19:00:47.614428 11123 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0528 19:00:47.614434 11123 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0528 19:00:47.614498 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 19:00:47.614666 11123 net.cpp:122] Setting up layer_512_3_scale2
I0528 19:00:47.614676 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.614679 11123 net.cpp:137] Memory required for data: 4537917520
I0528 19:00:47.614697 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0528 19:00:47.614704 11123 net.cpp:84] Creating Layer layer_512_3_relu2
I0528 19:00:47.614708 11123 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0528 19:00:47.614713 11123 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0528 19:00:47.615392 11123 net.cpp:122] Setting up layer_512_3_relu2
I0528 19:00:47.615403 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.615406 11123 net.cpp:137] Memory required for data: 4539924560
I0528 19:00:47.615411 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0528 19:00:47.615422 11123 net.cpp:84] Creating Layer layer_512_3_conv2
I0528 19:00:47.615427 11123 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0528 19:00:47.615434 11123 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0528 19:00:47.642783 11123 net.cpp:122] Setting up layer_512_3_conv2
I0528 19:00:47.642810 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.642814 11123 net.cpp:137] Memory required for data: 4541931600
I0528 19:00:47.642822 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn3
I0528 19:00:47.642833 11123 net.cpp:84] Creating Layer layer_512_3_bn3
I0528 19:00:47.642838 11123 net.cpp:406] layer_512_3_bn3 <- layer_512_3_conv2
I0528 19:00:47.642851 11123 net.cpp:367] layer_512_3_bn3 -> layer_512_3_conv2 (in-place)
I0528 19:00:47.643100 11123 net.cpp:122] Setting up layer_512_3_bn3
I0528 19:00:47.643110 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.643112 11123 net.cpp:137] Memory required for data: 4543938640
I0528 19:00:47.643120 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0528 19:00:47.643126 11123 net.cpp:84] Creating Layer layer_512_3_scale3
I0528 19:00:47.643131 11123 net.cpp:406] layer_512_3_scale3 <- layer_512_3_conv2
I0528 19:00:47.643137 11123 net.cpp:367] layer_512_3_scale3 -> layer_512_3_conv2 (in-place)
I0528 19:00:47.643203 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0528 19:00:47.643373 11123 net.cpp:122] Setting up layer_512_3_scale3
I0528 19:00:47.643381 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.643384 11123 net.cpp:137] Memory required for data: 4545945680
I0528 19:00:47.643390 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu3
I0528 19:00:47.643396 11123 net.cpp:84] Creating Layer layer_512_3_relu3
I0528 19:00:47.643400 11123 net.cpp:406] layer_512_3_relu3 <- layer_512_3_conv2
I0528 19:00:47.643404 11123 net.cpp:367] layer_512_3_relu3 -> layer_512_3_conv2 (in-place)
I0528 19:00:47.643592 11123 net.cpp:122] Setting up layer_512_3_relu3
I0528 19:00:47.643602 11123 net.cpp:129] Top shape: 20 512 7 7 (501760)
I0528 19:00:47.643605 11123 net.cpp:137] Memory required for data: 4547952720
I0528 19:00:47.643609 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv3
I0528 19:00:47.643621 11123 net.cpp:84] Creating Layer layer_512_3_conv3
I0528 19:00:47.643625 11123 net.cpp:406] layer_512_3_conv3 <- layer_512_3_conv2
I0528 19:00:47.643635 11123 net.cpp:380] layer_512_3_conv3 -> layer_512_3_conv3
I0528 19:00:47.656627 11123 net.cpp:122] Setting up layer_512_3_conv3
I0528 19:00:47.656672 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.656677 11123 net.cpp:137] Memory required for data: 4555980880
I0528 19:00:47.656688 11123 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0528 19:00:47.656716 11123 net.cpp:84] Creating Layer layer_512_3_sum
I0528 19:00:47.656723 11123 net.cpp:406] layer_512_3_sum <- layer_512_3_conv3
I0528 19:00:47.656735 11123 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 19:00:47.656744 11123 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0528 19:00:47.656786 11123 net.cpp:122] Setting up layer_512_3_sum
I0528 19:00:47.656807 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.656810 11123 net.cpp:137] Memory required for data: 4564009040
I0528 19:00:47.656814 11123 layer_factory.hpp:77] Creating layer last_bn
I0528 19:00:47.656822 11123 net.cpp:84] Creating Layer last_bn
I0528 19:00:47.656826 11123 net.cpp:406] last_bn <- layer_512_3_sum
I0528 19:00:47.656832 11123 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0528 19:00:47.657090 11123 net.cpp:122] Setting up last_bn
I0528 19:00:47.657100 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.657104 11123 net.cpp:137] Memory required for data: 4572037200
I0528 19:00:47.657122 11123 layer_factory.hpp:77] Creating layer last_scale
I0528 19:00:47.657135 11123 net.cpp:84] Creating Layer last_scale
I0528 19:00:47.657140 11123 net.cpp:406] last_scale <- layer_512_3_sum
I0528 19:00:47.657150 11123 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0528 19:00:47.657217 11123 layer_factory.hpp:77] Creating layer last_scale
I0528 19:00:47.657372 11123 net.cpp:122] Setting up last_scale
I0528 19:00:47.657382 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.657387 11123 net.cpp:137] Memory required for data: 4580065360
I0528 19:00:47.657408 11123 layer_factory.hpp:77] Creating layer last_relu
I0528 19:00:47.657418 11123 net.cpp:84] Creating Layer last_relu
I0528 19:00:47.657425 11123 net.cpp:406] last_relu <- layer_512_3_sum
I0528 19:00:47.657434 11123 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0528 19:00:47.657605 11123 net.cpp:122] Setting up last_relu
I0528 19:00:47.657616 11123 net.cpp:129] Top shape: 20 2048 7 7 (2007040)
I0528 19:00:47.657634 11123 net.cpp:137] Memory required for data: 4588093520
I0528 19:00:47.657641 11123 layer_factory.hpp:77] Creating layer global_pool
I0528 19:00:47.657652 11123 net.cpp:84] Creating Layer global_pool
I0528 19:00:47.657660 11123 net.cpp:406] global_pool <- layer_512_3_sum
I0528 19:00:47.657670 11123 net.cpp:380] global_pool -> global_pool
I0528 19:00:47.657876 11123 net.cpp:122] Setting up global_pool
I0528 19:00:47.657886 11123 net.cpp:129] Top shape: 20 2048 1 1 (40960)
I0528 19:00:47.657903 11123 net.cpp:137] Memory required for data: 4588257360
I0528 19:00:47.657910 11123 layer_factory.hpp:77] Creating layer score
I0528 19:00:47.657923 11123 net.cpp:84] Creating Layer score
I0528 19:00:47.657928 11123 net.cpp:406] score <- global_pool
I0528 19:00:47.657941 11123 net.cpp:380] score -> score
I0528 19:00:47.658077 11123 net.cpp:122] Setting up score
I0528 19:00:47.658089 11123 net.cpp:129] Top shape: 20 2 (40)
I0528 19:00:47.658107 11123 net.cpp:137] Memory required for data: 4588257520
I0528 19:00:47.658118 11123 layer_factory.hpp:77] Creating layer loss
I0528 19:00:47.658126 11123 net.cpp:84] Creating Layer loss
I0528 19:00:47.658133 11123 net.cpp:406] loss <- score
I0528 19:00:47.658141 11123 net.cpp:406] loss <- label
I0528 19:00:47.658152 11123 net.cpp:380] loss -> loss
I0528 19:00:47.658165 11123 layer_factory.hpp:77] Creating layer loss
I0528 19:00:47.658957 11123 net.cpp:122] Setting up loss
I0528 19:00:47.658968 11123 net.cpp:129] Top shape: (1)
I0528 19:00:47.658972 11123 net.cpp:132]     with loss weight 1
I0528 19:00:47.658993 11123 net.cpp:137] Memory required for data: 4588257524
I0528 19:00:47.658995 11123 net.cpp:198] loss needs backward computation.
I0528 19:00:47.659003 11123 net.cpp:198] score needs backward computation.
I0528 19:00:47.659018 11123 net.cpp:198] global_pool needs backward computation.
I0528 19:00:47.659021 11123 net.cpp:198] last_relu needs backward computation.
I0528 19:00:47.659024 11123 net.cpp:198] last_scale needs backward computation.
I0528 19:00:47.659026 11123 net.cpp:198] last_bn needs backward computation.
I0528 19:00:47.659030 11123 net.cpp:198] layer_512_3_sum needs backward computation.
I0528 19:00:47.659034 11123 net.cpp:198] layer_512_3_conv3 needs backward computation.
I0528 19:00:47.659037 11123 net.cpp:198] layer_512_3_relu3 needs backward computation.
I0528 19:00:47.659041 11123 net.cpp:198] layer_512_3_scale3 needs backward computation.
I0528 19:00:47.659044 11123 net.cpp:198] layer_512_3_bn3 needs backward computation.
I0528 19:00:47.659047 11123 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0528 19:00:47.659052 11123 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0528 19:00:47.659060 11123 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0528 19:00:47.659066 11123 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0528 19:00:47.659073 11123 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0528 19:00:47.659080 11123 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0528 19:00:47.659088 11123 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0528 19:00:47.659096 11123 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0528 19:00:47.659102 11123 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0528 19:00:47.659111 11123 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 19:00:47.659118 11123 net.cpp:198] layer_512_2_conv3 needs backward computation.
I0528 19:00:47.659126 11123 net.cpp:198] layer_512_2_relu3 needs backward computation.
I0528 19:00:47.659132 11123 net.cpp:198] layer_512_2_scale3 needs backward computation.
I0528 19:00:47.659138 11123 net.cpp:198] layer_512_2_bn3 needs backward computation.
I0528 19:00:47.659145 11123 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 19:00:47.659153 11123 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 19:00:47.659162 11123 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 19:00:47.659168 11123 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 19:00:47.659175 11123 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 19:00:47.659183 11123 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 19:00:47.659190 11123 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 19:00:47.659198 11123 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 19:00:47.659204 11123 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 19:00:47.659212 11123 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 19:00:47.659219 11123 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 19:00:47.659227 11123 net.cpp:198] layer_512_1_conv3 needs backward computation.
I0528 19:00:47.659235 11123 net.cpp:198] layer_512_1_relu3 needs backward computation.
I0528 19:00:47.659242 11123 net.cpp:198] layer_512_1_scale3 needs backward computation.
I0528 19:00:47.659250 11123 net.cpp:198] layer_512_1_bn3 needs backward computation.
I0528 19:00:47.659255 11123 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 19:00:47.659263 11123 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 19:00:47.659271 11123 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 19:00:47.659277 11123 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 19:00:47.659284 11123 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 19:00:47.659291 11123 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 19:00:47.659299 11123 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 19:00:47.659307 11123 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 19:00:47.659313 11123 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 19:00:47.659328 11123 net.cpp:198] layer_256_6_sum needs backward computation.
I0528 19:00:47.659337 11123 net.cpp:198] layer_256_6_conv3 needs backward computation.
I0528 19:00:47.659344 11123 net.cpp:198] layer_256_6_relu3 needs backward computation.
I0528 19:00:47.659351 11123 net.cpp:198] layer_256_6_scale3 needs backward computation.
I0528 19:00:47.659358 11123 net.cpp:198] layer_256_6_bn3 needs backward computation.
I0528 19:00:47.659365 11123 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0528 19:00:47.659373 11123 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0528 19:00:47.659380 11123 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0528 19:00:47.659386 11123 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0528 19:00:47.659394 11123 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0528 19:00:47.659401 11123 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0528 19:00:47.659409 11123 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0528 19:00:47.659415 11123 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0528 19:00:47.659422 11123 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0528 19:00:47.659430 11123 net.cpp:198] layer_256_5_sum needs backward computation.
I0528 19:00:47.659438 11123 net.cpp:198] layer_256_5_conv3 needs backward computation.
I0528 19:00:47.659447 11123 net.cpp:198] layer_256_5_relu3 needs backward computation.
I0528 19:00:47.659454 11123 net.cpp:198] layer_256_5_scale3 needs backward computation.
I0528 19:00:47.659461 11123 net.cpp:198] layer_256_5_bn3 needs backward computation.
I0528 19:00:47.659468 11123 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0528 19:00:47.659476 11123 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0528 19:00:47.659483 11123 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0528 19:00:47.659490 11123 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0528 19:00:47.659497 11123 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0528 19:00:47.659505 11123 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0528 19:00:47.659512 11123 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0528 19:00:47.659518 11123 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0528 19:00:47.659526 11123 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0528 19:00:47.659533 11123 net.cpp:198] layer_256_4_sum needs backward computation.
I0528 19:00:47.659541 11123 net.cpp:198] layer_256_4_conv3 needs backward computation.
I0528 19:00:47.659548 11123 net.cpp:198] layer_256_4_relu3 needs backward computation.
I0528 19:00:47.659555 11123 net.cpp:198] layer_256_4_scale3 needs backward computation.
I0528 19:00:47.659562 11123 net.cpp:198] layer_256_4_bn3 needs backward computation.
I0528 19:00:47.659569 11123 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0528 19:00:47.659577 11123 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0528 19:00:47.659584 11123 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0528 19:00:47.659591 11123 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0528 19:00:47.659597 11123 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0528 19:00:47.659605 11123 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0528 19:00:47.659612 11123 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0528 19:00:47.659620 11123 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0528 19:00:47.659626 11123 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0528 19:00:47.659633 11123 net.cpp:198] layer_256_3_sum needs backward computation.
I0528 19:00:47.659642 11123 net.cpp:198] layer_256_3_conv3 needs backward computation.
I0528 19:00:47.659649 11123 net.cpp:198] layer_256_3_relu3 needs backward computation.
I0528 19:00:47.659657 11123 net.cpp:198] layer_256_3_scale3 needs backward computation.
I0528 19:00:47.659669 11123 net.cpp:198] layer_256_3_bn3 needs backward computation.
I0528 19:00:47.659675 11123 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0528 19:00:47.659683 11123 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0528 19:00:47.659690 11123 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0528 19:00:47.659698 11123 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0528 19:00:47.659704 11123 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0528 19:00:47.659713 11123 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0528 19:00:47.659720 11123 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0528 19:00:47.659728 11123 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0528 19:00:47.659734 11123 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0528 19:00:47.659742 11123 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 19:00:47.659750 11123 net.cpp:198] layer_256_2_conv3 needs backward computation.
I0528 19:00:47.659757 11123 net.cpp:198] layer_256_2_relu3 needs backward computation.
I0528 19:00:47.659765 11123 net.cpp:198] layer_256_2_scale3 needs backward computation.
I0528 19:00:47.659771 11123 net.cpp:198] layer_256_2_bn3 needs backward computation.
I0528 19:00:47.659780 11123 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 19:00:47.659786 11123 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 19:00:47.659793 11123 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 19:00:47.659801 11123 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 19:00:47.659807 11123 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 19:00:47.659816 11123 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 19:00:47.659822 11123 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 19:00:47.659829 11123 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 19:00:47.659837 11123 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 19:00:47.659843 11123 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 19:00:47.659852 11123 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 19:00:47.659859 11123 net.cpp:198] layer_256_1_conv3 needs backward computation.
I0528 19:00:47.659867 11123 net.cpp:198] layer_256_1_relu3 needs backward computation.
I0528 19:00:47.659873 11123 net.cpp:198] layer_256_1_scale3 needs backward computation.
I0528 19:00:47.659880 11123 net.cpp:198] layer_256_1_bn3 needs backward computation.
I0528 19:00:47.659888 11123 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 19:00:47.659895 11123 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 19:00:47.659901 11123 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 19:00:47.659909 11123 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 19:00:47.659915 11123 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 19:00:47.659922 11123 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 19:00:47.659930 11123 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 19:00:47.659937 11123 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 19:00:47.659945 11123 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 19:00:47.659951 11123 net.cpp:198] layer_128_4_sum needs backward computation.
I0528 19:00:47.659960 11123 net.cpp:198] layer_128_4_conv3 needs backward computation.
I0528 19:00:47.659966 11123 net.cpp:198] layer_128_4_relu3 needs backward computation.
I0528 19:00:47.659974 11123 net.cpp:198] layer_128_4_scale3 needs backward computation.
I0528 19:00:47.659981 11123 net.cpp:198] layer_128_4_bn3 needs backward computation.
I0528 19:00:47.659987 11123 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0528 19:00:47.659997 11123 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0528 19:00:47.660004 11123 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0528 19:00:47.660017 11123 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0528 19:00:47.660024 11123 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0528 19:00:47.660032 11123 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0528 19:00:47.660038 11123 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0528 19:00:47.660045 11123 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0528 19:00:47.660053 11123 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0528 19:00:47.660060 11123 net.cpp:198] layer_128_3_sum needs backward computation.
I0528 19:00:47.660068 11123 net.cpp:198] layer_128_3_conv3 needs backward computation.
I0528 19:00:47.660076 11123 net.cpp:198] layer_128_3_relu3 needs backward computation.
I0528 19:00:47.660084 11123 net.cpp:198] layer_128_3_scale3 needs backward computation.
I0528 19:00:47.660090 11123 net.cpp:198] layer_128_3_bn3 needs backward computation.
I0528 19:00:47.660097 11123 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0528 19:00:47.660104 11123 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0528 19:00:47.660111 11123 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0528 19:00:47.660116 11123 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0528 19:00:47.660120 11123 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0528 19:00:47.660125 11123 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0528 19:00:47.660131 11123 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0528 19:00:47.660138 11123 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0528 19:00:47.660145 11123 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0528 19:00:47.660152 11123 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 19:00:47.660161 11123 net.cpp:198] layer_128_2_conv3 needs backward computation.
I0528 19:00:47.660167 11123 net.cpp:198] layer_128_2_relu3 needs backward computation.
I0528 19:00:47.660174 11123 net.cpp:198] layer_128_2_scale3 needs backward computation.
I0528 19:00:47.660181 11123 net.cpp:198] layer_128_2_bn3 needs backward computation.
I0528 19:00:47.660188 11123 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 19:00:47.660195 11123 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 19:00:47.660202 11123 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 19:00:47.660209 11123 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 19:00:47.660217 11123 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 19:00:47.660221 11123 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 19:00:47.660224 11123 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 19:00:47.660230 11123 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 19:00:47.660243 11123 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 19:00:47.660248 11123 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 19:00:47.660256 11123 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 19:00:47.660264 11123 net.cpp:198] layer_128_1_conv3 needs backward computation.
I0528 19:00:47.660270 11123 net.cpp:198] layer_128_1_relu3 needs backward computation.
I0528 19:00:47.660277 11123 net.cpp:198] layer_128_1_scale3 needs backward computation.
I0528 19:00:47.660284 11123 net.cpp:198] layer_128_1_bn3 needs backward computation.
I0528 19:00:47.660291 11123 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 19:00:47.660298 11123 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 19:00:47.660305 11123 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 19:00:47.660311 11123 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 19:00:47.660320 11123 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 19:00:47.660326 11123 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 19:00:47.660339 11123 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 19:00:47.660347 11123 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 19:00:47.660354 11123 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 19:00:47.660362 11123 net.cpp:198] layer_64_3_sum needs backward computation.
I0528 19:00:47.660370 11123 net.cpp:198] layer_64_3_conv3 needs backward computation.
I0528 19:00:47.660377 11123 net.cpp:198] layer_64_3_relu3 needs backward computation.
I0528 19:00:47.660384 11123 net.cpp:198] layer_64_3_scale3 needs backward computation.
I0528 19:00:47.660392 11123 net.cpp:198] layer_64_3_bn3 needs backward computation.
I0528 19:00:47.660398 11123 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0528 19:00:47.660406 11123 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0528 19:00:47.660413 11123 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0528 19:00:47.660419 11123 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0528 19:00:47.660426 11123 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0528 19:00:47.660434 11123 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0528 19:00:47.660440 11123 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0528 19:00:47.660447 11123 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0528 19:00:47.660455 11123 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0528 19:00:47.660462 11123 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 19:00:47.660470 11123 net.cpp:198] layer_64_2_conv3 needs backward computation.
I0528 19:00:47.660477 11123 net.cpp:198] layer_64_2_relu3 needs backward computation.
I0528 19:00:47.660485 11123 net.cpp:198] layer_64_2_scale3 needs backward computation.
I0528 19:00:47.660491 11123 net.cpp:198] layer_64_2_bn3 needs backward computation.
I0528 19:00:47.660498 11123 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 19:00:47.660506 11123 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 19:00:47.660513 11123 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 19:00:47.660521 11123 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 19:00:47.660527 11123 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 19:00:47.660537 11123 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 19:00:47.660543 11123 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 19:00:47.660549 11123 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 19:00:47.660557 11123 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 19:00:47.660564 11123 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 19:00:47.660573 11123 net.cpp:198] layer_64_1_conv_expand needs backward computation.
I0528 19:00:47.660580 11123 net.cpp:198] layer_64_1_conv3 needs backward computation.
I0528 19:00:47.660588 11123 net.cpp:198] layer_64_1_relu3 needs backward computation.
I0528 19:00:47.660594 11123 net.cpp:198] layer_64_1_scale3 needs backward computation.
I0528 19:00:47.660601 11123 net.cpp:198] layer_64_1_bn3 needs backward computation.
I0528 19:00:47.660609 11123 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 19:00:47.660615 11123 net.cpp:198] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0528 19:00:47.660624 11123 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 19:00:47.660630 11123 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 19:00:47.660637 11123 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 19:00:47.660645 11123 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 19:00:47.660651 11123 net.cpp:198] conv1_pool needs backward computation.
I0528 19:00:47.660658 11123 net.cpp:198] conv1_relu needs backward computation.
I0528 19:00:47.660666 11123 net.cpp:198] conv1_scale needs backward computation.
I0528 19:00:47.660672 11123 net.cpp:198] conv1_bn needs backward computation.
I0528 19:00:47.660686 11123 net.cpp:198] conv1 needs backward computation.
I0528 19:00:47.660693 11123 net.cpp:198] data_scale needs backward computation.
I0528 19:00:47.660701 11123 net.cpp:200] data_bn does not need backward computation.
I0528 19:00:47.660708 11123 net.cpp:200] data does not need backward computation.
I0528 19:00:47.660714 11123 net.cpp:242] This network produces output loss
I0528 19:00:47.660832 11123 net.cpp:255] Network initialization done.
I0528 19:00:47.662526 11123 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 50_train_val_test_fold_is_0.prototxt
I0528 19:00:47.662545 11123 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 19:00:47.662556 11123 solver.cpp:172] Creating test net (#0) specified by net file: 50_train_val_test_fold_is_0.prototxt
I0528 19:00:47.662708 11123 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0528 19:00:47.663892 11123 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-50"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto"
  }
  data_param {
    source: "/home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/gender_val_lmdb"
    batch_size: 10
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn3"
  type: "BatchNorm"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale3"
  type: "Scale"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu3"
  type: "ReLU"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv2"
}
layer {
  name: "layer_64_1_conv3"
  type: "Convolution"
  bottom: "layer_64_1_conv2"
  top: "layer_64_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_conv_expand"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv3"
  bottom: "layer_64_1_conv_expand"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn3"
  type: "BatchNorm"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale3"
  type: "Scale"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu3"
  type: "ReLU"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv2"
}
layer {
  name: "layer_64_2_conv3"
  type: "Convolution"
  bottom: "layer_64_2_conv2"
  top: "layer_64_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv3"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_64_3_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale1"
  type: "Scale"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu1"
  type: "ReLU"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_bn1"
}
layer {
  name: "layer_64_3_conv1"
  type: "Convolution"
  bottom: "layer_64_3_bn1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn2"
  type: "BatchNorm"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale2"
  type: "Scale"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu2"
  type: "ReLU"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv1"
}
layer {
  name: "layer_64_3_conv2"
  type: "Convolution"
  bottom: "layer_64_3_conv1"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_bn3"
  type: "BatchNorm"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_3_scale3"
  type: "Scale"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_3_relu3"
  type: "ReLU"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv2"
}
layer {
  name: "layer_64_3_conv3"
  type: "Convolution"
  bottom: "layer_64_3_conv2"
  top: "layer_64_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_3_sum"
  type: "Eltwise"
  bottom: "layer_64_3_conv3"
  bottom: "layer_64_2_sum"
  top: "layer_64_3_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_3_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn3"
  type: "BatchNorm"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale3"
  type: "Scale"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu3"
  type: "ReLU"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv2"
}
layer {
  name: "layer_128_1_conv3"
  type: "Convolution"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv3"
  bottom: "layer_128_1_conv_expand"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn3"
  type: "BatchNorm"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale3"
  type: "Scale"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu3"
  type: "ReLU"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv2"
}
layer {
  name: "layer_128_2_conv3"
  type: "Convolution"
  bottom: "layer_128_2_conv2"
  top: "layer_128_2_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv3"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_128_3_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale1"
  type: "Scale"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu1"
  type: "ReLU"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_bn1"
}
layer {
  name: "layer_128_3_conv1"
  type: "Convolution"
  bottom: "layer_128_3_bn1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn2"
  type: "BatchNorm"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale2"
  type: "Scale"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu2"
  type: "ReLU"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv1"
}
layer {
  name: "layer_128_3_conv2"
  type: "Convolution"
  bottom: "layer_128_3_conv1"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_bn3"
  type: "BatchNorm"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_3_scale3"
  type: "Scale"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_3_relu3"
  type: "ReLU"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv2"
}
layer {
  name: "layer_128_3_conv3"
  type: "Convolution"
  bottom: "layer_128_3_conv2"
  top: "layer_128_3_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_3_sum"
  type: "Eltwise"
  bottom: "layer_128_3_conv3"
  bottom: "layer_128_2_sum"
  top: "layer_128_3_sum"
}
layer {
  name: "layer_128_4_bn1"
  type: "BatchNorm"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale1"
  type: "Scale"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu1"
  type: "ReLU"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_bn1"
}
layer {
  name: "layer_128_4_conv1"
  type: "Convolution"
  bottom: "layer_128_4_bn1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn2"
  type: "BatchNorm"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale2"
  type: "Scale"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu2"
  type: "ReLU"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv1"
}
layer {
  name: "layer_128_4_conv2"
  type: "Convolution"
  bottom: "layer_128_4_conv1"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_bn3"
  type: "BatchNorm"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_4_scale3"
  type: "Scale"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_4_relu3"
  type: "ReLU"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv2"
}
layer {
  name: "layer_128_4_conv3"
  type: "Convolution"
  bottom: "layer_128_4_conv2"
  top: "layer_128_4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_4_sum"
  type: "Eltwise"
  bottom: "layer_128_4_conv3"
  bottom: "layer_128_3_sum"
  top: "layer_128_4_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_4_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn3"
  type: "BatchNorm"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale3"
  type: "Scale"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu3"
  type: "ReLU"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv2"
}
layer {
  name: "layer_256_1_conv3"
  type: "Convolution"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv3"
  bottom: "layer_256_1_conv_expand"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn3"
  type: "BatchNorm"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale3"
  type: "Scale"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu3"
  type: "ReLU"
  bottom: "layer_256_2_conv2"
  top: "layer_256_2_conv2"
}
layer {
  name: "layer_256_2_conv3"
  type: "Convolution"
  bottom: "layer_256_2_c
I0528 19:00:47.664698 11123 layer_factory.hpp:77] Creating layer data
I0528 19:00:47.664767 11123 db_lmdb.cpp:35] Opened lmdb /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/gender_val_lmdb
I0528 19:00:47.664788 11123 net.cpp:84] Creating Layer data
I0528 19:00:47.664796 11123 net.cpp:380] data -> data
I0528 19:00:47.664810 11123 net.cpp:380] data -> label
I0528 19:00:47.664821 11123 data_transformer.cpp:25] Loading mean file from: /home/k/PycharmProjects/AgeGenderDeepLearning-master/Folds/lmdb/Test_fold_is_0/mean.binaryproto
I0528 19:00:47.666939 11123 data_layer.cpp:45] output data size: 10,3,224,224
I0528 19:00:47.681061 11123 net.cpp:122] Setting up data
I0528 19:00:47.681094 11123 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0528 19:00:47.681099 11123 net.cpp:129] Top shape: 10 (10)
I0528 19:00:47.681102 11123 net.cpp:137] Memory required for data: 6021160
I0528 19:00:47.681109 11123 layer_factory.hpp:77] Creating layer label_data_1_split
I0528 19:00:47.681123 11123 net.cpp:84] Creating Layer label_data_1_split
I0528 19:00:47.681128 11123 net.cpp:406] label_data_1_split <- label
I0528 19:00:47.681135 11123 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0528 19:00:47.681146 11123 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0528 19:00:47.681228 11123 net.cpp:122] Setting up label_data_1_split
I0528 19:00:47.681237 11123 net.cpp:129] Top shape: 10 (10)
I0528 19:00:47.681242 11123 net.cpp:129] Top shape: 10 (10)
I0528 19:00:47.681246 11123 net.cpp:137] Memory required for data: 6021240
I0528 19:00:47.681248 11123 layer_factory.hpp:77] Creating layer data_bn
I0528 19:00:47.681257 11123 net.cpp:84] Creating Layer data_bn
I0528 19:00:47.681262 11123 net.cpp:406] data_bn <- data
I0528 19:00:47.681284 11123 net.cpp:380] data_bn -> data_bn
I0528 19:00:47.681566 11123 net.cpp:122] Setting up data_bn
I0528 19:00:47.681578 11123 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0528 19:00:47.681586 11123 net.cpp:137] Memory required for data: 12042360
I0528 19:00:47.681604 11123 layer_factory.hpp:77] Creating layer data_scale
I0528 19:00:47.681614 11123 net.cpp:84] Creating Layer data_scale
I0528 19:00:47.681620 11123 net.cpp:406] data_scale <- data_bn
I0528 19:00:47.681630 11123 net.cpp:367] data_scale -> data_bn (in-place)
I0528 19:00:47.681684 11123 layer_factory.hpp:77] Creating layer data_scale
I0528 19:00:47.681897 11123 net.cpp:122] Setting up data_scale
I0528 19:00:47.681907 11123 net.cpp:129] Top shape: 10 3 224 224 (1505280)
I0528 19:00:47.681915 11123 net.cpp:137] Memory required for data: 18063480
I0528 19:00:47.681928 11123 layer_factory.hpp:77] Creating layer conv1
I0528 19:00:47.681944 11123 net.cpp:84] Creating Layer conv1
I0528 19:00:47.681951 11123 net.cpp:406] conv1 <- data_bn
I0528 19:00:47.681959 11123 net.cpp:380] conv1 -> conv1
I0528 19:00:47.683866 11123 net.cpp:122] Setting up conv1
I0528 19:00:47.683881 11123 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0528 19:00:47.683886 11123 net.cpp:137] Memory required for data: 50176120
I0528 19:00:47.683892 11123 layer_factory.hpp:77] Creating layer conv1_bn
I0528 19:00:47.683899 11123 net.cpp:84] Creating Layer conv1_bn
I0528 19:00:47.683904 11123 net.cpp:406] conv1_bn <- conv1
I0528 19:00:47.683909 11123 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 19:00:47.684123 11123 net.cpp:122] Setting up conv1_bn
I0528 19:00:47.684134 11123 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0528 19:00:47.684137 11123 net.cpp:137] Memory required for data: 82288760
I0528 19:00:47.684147 11123 layer_factory.hpp:77] Creating layer conv1_scale
I0528 19:00:47.684154 11123 net.cpp:84] Creating Layer conv1_scale
I0528 19:00:47.684159 11123 net.cpp:406] conv1_scale <- conv1
I0528 19:00:47.684164 11123 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 19:00:47.684211 11123 layer_factory.hpp:77] Creating layer conv1_scale
I0528 19:00:47.684352 11123 net.cpp:122] Setting up conv1_scale
I0528 19:00:47.684361 11123 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0528 19:00:47.684365 11123 net.cpp:137] Memory required for data: 114401400
I0528 19:00:47.684371 11123 layer_factory.hpp:77] Creating layer conv1_relu
I0528 19:00:47.684378 11123 net.cpp:84] Creating Layer conv1_relu
I0528 19:00:47.684382 11123 net.cpp:406] conv1_relu <- conv1
I0528 19:00:47.684387 11123 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 19:00:47.685219 11123 net.cpp:122] Setting up conv1_relu
I0528 19:00:47.685233 11123 net.cpp:129] Top shape: 10 64 112 112 (8028160)
I0528 19:00:47.685236 11123 net.cpp:137] Memory required for data: 146514040
I0528 19:00:47.685240 11123 layer_factory.hpp:77] Creating layer conv1_pool
I0528 19:00:47.685250 11123 net.cpp:84] Creating Layer conv1_pool
I0528 19:00:47.685255 11123 net.cpp:406] conv1_pool <- conv1
I0528 19:00:47.685261 11123 net.cpp:380] conv1_pool -> conv1_pool
I0528 19:00:47.685317 11123 net.cpp:122] Setting up conv1_pool
I0528 19:00:47.685324 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.685328 11123 net.cpp:137] Memory required for data: 154542200
I0528 19:00:47.685331 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 19:00:47.685341 11123 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 19:00:47.685346 11123 net.cpp:406] layer_64_1_conv1 <- conv1_pool
I0528 19:00:47.685353 11123 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 19:00:47.686671 11123 net.cpp:122] Setting up layer_64_1_conv1
I0528 19:00:47.686686 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.686691 11123 net.cpp:137] Memory required for data: 162570360
I0528 19:00:47.686697 11123 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 19:00:47.686705 11123 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 19:00:47.686709 11123 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 19:00:47.686715 11123 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.686949 11123 net.cpp:122] Setting up layer_64_1_bn2
I0528 19:00:47.686957 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.686961 11123 net.cpp:137] Memory required for data: 170598520
I0528 19:00:47.686969 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 19:00:47.686976 11123 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 19:00:47.686980 11123 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 19:00:47.686986 11123 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.687036 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 19:00:47.687175 11123 net.cpp:122] Setting up layer_64_1_scale2
I0528 19:00:47.687185 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.687188 11123 net.cpp:137] Memory required for data: 178626680
I0528 19:00:47.687197 11123 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 19:00:47.687203 11123 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 19:00:47.687208 11123 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 19:00:47.687213 11123 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 19:00:47.687377 11123 net.cpp:122] Setting up layer_64_1_relu2
I0528 19:00:47.687387 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.687391 11123 net.cpp:137] Memory required for data: 186654840
I0528 19:00:47.687394 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.687400 11123 net.cpp:84] Creating Layer layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.687404 11123 net.cpp:406] layer_64_1_conv1_layer_64_1_relu2_0_split <- layer_64_1_conv1
I0528 19:00:47.687409 11123 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0528 19:00:47.687418 11123 net.cpp:380] layer_64_1_conv1_layer_64_1_relu2_0_split -> layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0528 19:00:47.687463 11123 net.cpp:122] Setting up layer_64_1_conv1_layer_64_1_relu2_0_split
I0528 19:00:47.687472 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.687477 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.687479 11123 net.cpp:137] Memory required for data: 202711160
I0528 19:00:47.687484 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 19:00:47.687491 11123 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 19:00:47.687495 11123 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1_layer_64_1_relu2_0_split_0
I0528 19:00:47.687501 11123 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 19:00:47.690145 11123 net.cpp:122] Setting up layer_64_1_conv2
I0528 19:00:47.690165 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.690170 11123 net.cpp:137] Memory required for data: 210739320
I0528 19:00:47.690177 11123 layer_factory.hpp:77] Creating layer layer_64_1_bn3
I0528 19:00:47.690186 11123 net.cpp:84] Creating Layer layer_64_1_bn3
I0528 19:00:47.690191 11123 net.cpp:406] layer_64_1_bn3 <- layer_64_1_conv2
I0528 19:00:47.690197 11123 net.cpp:367] layer_64_1_bn3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.690428 11123 net.cpp:122] Setting up layer_64_1_bn3
I0528 19:00:47.690436 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.690440 11123 net.cpp:137] Memory required for data: 218767480
I0528 19:00:47.690448 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0528 19:00:47.690460 11123 net.cpp:84] Creating Layer layer_64_1_scale3
I0528 19:00:47.690464 11123 net.cpp:406] layer_64_1_scale3 <- layer_64_1_conv2
I0528 19:00:47.690469 11123 net.cpp:367] layer_64_1_scale3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.690522 11123 layer_factory.hpp:77] Creating layer layer_64_1_scale3
I0528 19:00:47.690665 11123 net.cpp:122] Setting up layer_64_1_scale3
I0528 19:00:47.690673 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.690677 11123 net.cpp:137] Memory required for data: 226795640
I0528 19:00:47.690683 11123 layer_factory.hpp:77] Creating layer layer_64_1_relu3
I0528 19:00:47.690701 11123 net.cpp:84] Creating Layer layer_64_1_relu3
I0528 19:00:47.690706 11123 net.cpp:406] layer_64_1_relu3 <- layer_64_1_conv2
I0528 19:00:47.690711 11123 net.cpp:367] layer_64_1_relu3 -> layer_64_1_conv2 (in-place)
I0528 19:00:47.690868 11123 net.cpp:122] Setting up layer_64_1_relu3
I0528 19:00:47.690877 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.690881 11123 net.cpp:137] Memory required for data: 234823800
I0528 19:00:47.690884 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv3
I0528 19:00:47.690893 11123 net.cpp:84] Creating Layer layer_64_1_conv3
I0528 19:00:47.690898 11123 net.cpp:406] layer_64_1_conv3 <- layer_64_1_conv2
I0528 19:00:47.690903 11123 net.cpp:380] layer_64_1_conv3 -> layer_64_1_conv3
I0528 19:00:47.692384 11123 net.cpp:122] Setting up layer_64_1_conv3
I0528 19:00:47.692401 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.692405 11123 net.cpp:137] Memory required for data: 266936440
I0528 19:00:47.692411 11123 layer_factory.hpp:77] Creating layer layer_64_1_conv_expand
I0528 19:00:47.692421 11123 net.cpp:84] Creating Layer layer_64_1_conv_expand
I0528 19:00:47.692428 11123 net.cpp:406] layer_64_1_conv_expand <- layer_64_1_conv1_layer_64_1_relu2_0_split_1
I0528 19:00:47.692440 11123 net.cpp:380] layer_64_1_conv_expand -> layer_64_1_conv_expand
I0528 19:00:47.694872 11123 net.cpp:122] Setting up layer_64_1_conv_expand
I0528 19:00:47.694890 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.694896 11123 net.cpp:137] Memory required for data: 299049080
I0528 19:00:47.694905 11123 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 19:00:47.694918 11123 net.cpp:84] Creating Layer layer_64_1_sum
I0528 19:00:47.694927 11123 net.cpp:406] layer_64_1_sum <- layer_64_1_conv3
I0528 19:00:47.694936 11123 net.cpp:406] layer_64_1_sum <- layer_64_1_conv_expand
I0528 19:00:47.694947 11123 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 19:00:47.694989 11123 net.cpp:122] Setting up layer_64_1_sum
I0528 19:00:47.695000 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695006 11123 net.cpp:137] Memory required for data: 331161720
I0528 19:00:47.695013 11123 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.695025 11123 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.695034 11123 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 19:00:47.695042 11123 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 19:00:47.695055 11123 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 19:00:47.695107 11123 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 19:00:47.695119 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695127 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695134 11123 net.cpp:137] Memory required for data: 395387000
I0528 19:00:47.695140 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 19:00:47.695150 11123 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 19:00:47.695158 11123 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 19:00:47.695168 11123 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 19:00:47.695407 11123 net.cpp:122] Setting up layer_64_2_bn1
I0528 19:00:47.695420 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695426 11123 net.cpp:137] Memory required for data: 427499640
I0528 19:00:47.695441 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 19:00:47.695451 11123 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 19:00:47.695459 11123 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 19:00:47.695469 11123 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 19:00:47.695530 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 19:00:47.695669 11123 net.cpp:122] Setting up layer_64_2_scale1
I0528 19:00:47.695696 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695703 11123 net.cpp:137] Memory required for data: 459612280
I0528 19:00:47.695715 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 19:00:47.695726 11123 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 19:00:47.695734 11123 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 19:00:47.695744 11123 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 19:00:47.695919 11123 net.cpp:122] Setting up layer_64_2_relu1
I0528 19:00:47.695932 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.695938 11123 net.cpp:137] Memory required for data: 491724920
I0528 19:00:47.695945 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 19:00:47.695958 11123 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 19:00:47.695966 11123 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 19:00:47.695976 11123 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 19:00:47.698041 11123 net.cpp:122] Setting up layer_64_2_conv1
I0528 19:00:47.698060 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.698066 11123 net.cpp:137] Memory required for data: 499753080
I0528 19:00:47.698076 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 19:00:47.698089 11123 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 19:00:47.698099 11123 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 19:00:47.698110 11123 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.698351 11123 net.cpp:122] Setting up layer_64_2_bn2
I0528 19:00:47.698364 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.698369 11123 net.cpp:137] Memory required for data: 507781240
I0528 19:00:47.698387 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 19:00:47.698398 11123 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 19:00:47.698406 11123 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 19:00:47.698416 11123 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.698478 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 19:00:47.698626 11123 net.cpp:122] Setting up layer_64_2_scale2
I0528 19:00:47.698638 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.698644 11123 net.cpp:137] Memory required for data: 515809400
I0528 19:00:47.698655 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 19:00:47.698668 11123 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 19:00:47.698675 11123 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 19:00:47.698685 11123 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 19:00:47.698905 11123 net.cpp:122] Setting up layer_64_2_relu2
I0528 19:00:47.698917 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.698923 11123 net.cpp:137] Memory required for data: 523837560
I0528 19:00:47.698930 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 19:00:47.698945 11123 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 19:00:47.698952 11123 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 19:00:47.698962 11123 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 19:00:47.701510 11123 net.cpp:122] Setting up layer_64_2_conv2
I0528 19:00:47.701529 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.701535 11123 net.cpp:137] Memory required for data: 531865720
I0528 19:00:47.701546 11123 layer_factory.hpp:77] Creating layer layer_64_2_bn3
I0528 19:00:47.701560 11123 net.cpp:84] Creating Layer layer_64_2_bn3
I0528 19:00:47.701568 11123 net.cpp:406] layer_64_2_bn3 <- layer_64_2_conv2
I0528 19:00:47.701578 11123 net.cpp:367] layer_64_2_bn3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.701818 11123 net.cpp:122] Setting up layer_64_2_bn3
I0528 19:00:47.701830 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.701836 11123 net.cpp:137] Memory required for data: 539893880
I0528 19:00:47.701851 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0528 19:00:47.701863 11123 net.cpp:84] Creating Layer layer_64_2_scale3
I0528 19:00:47.701882 11123 net.cpp:406] layer_64_2_scale3 <- layer_64_2_conv2
I0528 19:00:47.701895 11123 net.cpp:367] layer_64_2_scale3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.701959 11123 layer_factory.hpp:77] Creating layer layer_64_2_scale3
I0528 19:00:47.702108 11123 net.cpp:122] Setting up layer_64_2_scale3
I0528 19:00:47.702121 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.702126 11123 net.cpp:137] Memory required for data: 547922040
I0528 19:00:47.702137 11123 layer_factory.hpp:77] Creating layer layer_64_2_relu3
I0528 19:00:47.702157 11123 net.cpp:84] Creating Layer layer_64_2_relu3
I0528 19:00:47.702163 11123 net.cpp:406] layer_64_2_relu3 <- layer_64_2_conv2
I0528 19:00:47.702172 11123 net.cpp:367] layer_64_2_relu3 -> layer_64_2_conv2 (in-place)
I0528 19:00:47.702338 11123 net.cpp:122] Setting up layer_64_2_relu3
I0528 19:00:47.702350 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.702356 11123 net.cpp:137] Memory required for data: 555950200
I0528 19:00:47.702363 11123 layer_factory.hpp:77] Creating layer layer_64_2_conv3
I0528 19:00:47.702378 11123 net.cpp:84] Creating Layer layer_64_2_conv3
I0528 19:00:47.702384 11123 net.cpp:406] layer_64_2_conv3 <- layer_64_2_conv2
I0528 19:00:47.702395 11123 net.cpp:380] layer_64_2_conv3 -> layer_64_2_conv3
I0528 19:00:47.703909 11123 net.cpp:122] Setting up layer_64_2_conv3
I0528 19:00:47.703924 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.703932 11123 net.cpp:137] Memory required for data: 588062840
I0528 19:00:47.703940 11123 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 19:00:47.703958 11123 net.cpp:84] Creating Layer layer_64_2_sum
I0528 19:00:47.703966 11123 net.cpp:406] layer_64_2_sum <- layer_64_2_conv3
I0528 19:00:47.703974 11123 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 19:00:47.703985 11123 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 19:00:47.704028 11123 net.cpp:122] Setting up layer_64_2_sum
I0528 19:00:47.704040 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.704046 11123 net.cpp:137] Memory required for data: 620175480
I0528 19:00:47.704051 11123 layer_factory.hpp:77] Creating layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.704061 11123 net.cpp:84] Creating Layer layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.704068 11123 net.cpp:406] layer_64_2_sum_layer_64_2_sum_0_split <- layer_64_2_sum
I0528 19:00:47.704080 11123 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 19:00:47.704093 11123 net.cpp:380] layer_64_2_sum_layer_64_2_sum_0_split -> layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 19:00:47.704150 11123 net.cpp:122] Setting up layer_64_2_sum_layer_64_2_sum_0_split
I0528 19:00:47.704161 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.704169 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.704176 11123 net.cpp:137] Memory required for data: 684400760
I0528 19:00:47.704182 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn1
I0528 19:00:47.704195 11123 net.cpp:84] Creating Layer layer_64_3_bn1
I0528 19:00:47.704203 11123 net.cpp:406] layer_64_3_bn1 <- layer_64_2_sum_layer_64_2_sum_0_split_0
I0528 19:00:47.704213 11123 net.cpp:380] layer_64_3_bn1 -> layer_64_3_bn1
I0528 19:00:47.704453 11123 net.cpp:122] Setting up layer_64_3_bn1
I0528 19:00:47.704465 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.704471 11123 net.cpp:137] Memory required for data: 716513400
I0528 19:00:47.704485 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 19:00:47.704495 11123 net.cpp:84] Creating Layer layer_64_3_scale1
I0528 19:00:47.704504 11123 net.cpp:406] layer_64_3_scale1 <- layer_64_3_bn1
I0528 19:00:47.704515 11123 net.cpp:367] layer_64_3_scale1 -> layer_64_3_bn1 (in-place)
I0528 19:00:47.704574 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale1
I0528 19:00:47.704720 11123 net.cpp:122] Setting up layer_64_3_scale1
I0528 19:00:47.704731 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.704746 11123 net.cpp:137] Memory required for data: 748626040
I0528 19:00:47.704759 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu1
I0528 19:00:47.704769 11123 net.cpp:84] Creating Layer layer_64_3_relu1
I0528 19:00:47.704777 11123 net.cpp:406] layer_64_3_relu1 <- layer_64_3_bn1
I0528 19:00:47.704787 11123 net.cpp:367] layer_64_3_relu1 -> layer_64_3_bn1 (in-place)
I0528 19:00:47.705513 11123 net.cpp:122] Setting up layer_64_3_relu1
I0528 19:00:47.705528 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.705534 11123 net.cpp:137] Memory required for data: 780738680
I0528 19:00:47.705540 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv1
I0528 19:00:47.705555 11123 net.cpp:84] Creating Layer layer_64_3_conv1
I0528 19:00:47.705564 11123 net.cpp:406] layer_64_3_conv1 <- layer_64_3_bn1
I0528 19:00:47.705576 11123 net.cpp:380] layer_64_3_conv1 -> layer_64_3_conv1
I0528 19:00:47.707005 11123 net.cpp:122] Setting up layer_64_3_conv1
I0528 19:00:47.707018 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.707025 11123 net.cpp:137] Memory required for data: 788766840
I0528 19:00:47.707034 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn2
I0528 19:00:47.707051 11123 net.cpp:84] Creating Layer layer_64_3_bn2
I0528 19:00:47.707059 11123 net.cpp:406] layer_64_3_bn2 <- layer_64_3_conv1
I0528 19:00:47.707068 11123 net.cpp:367] layer_64_3_bn2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.707314 11123 net.cpp:122] Setting up layer_64_3_bn2
I0528 19:00:47.707325 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.707331 11123 net.cpp:137] Memory required for data: 796795000
I0528 19:00:47.707345 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 19:00:47.707356 11123 net.cpp:84] Creating Layer layer_64_3_scale2
I0528 19:00:47.707365 11123 net.cpp:406] layer_64_3_scale2 <- layer_64_3_conv1
I0528 19:00:47.707376 11123 net.cpp:367] layer_64_3_scale2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.707437 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale2
I0528 19:00:47.707594 11123 net.cpp:122] Setting up layer_64_3_scale2
I0528 19:00:47.707607 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.707612 11123 net.cpp:137] Memory required for data: 804823160
I0528 19:00:47.707623 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu2
I0528 19:00:47.707634 11123 net.cpp:84] Creating Layer layer_64_3_relu2
I0528 19:00:47.707643 11123 net.cpp:406] layer_64_3_relu2 <- layer_64_3_conv1
I0528 19:00:47.707653 11123 net.cpp:367] layer_64_3_relu2 -> layer_64_3_conv1 (in-place)
I0528 19:00:47.707828 11123 net.cpp:122] Setting up layer_64_3_relu2
I0528 19:00:47.707840 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.707847 11123 net.cpp:137] Memory required for data: 812851320
I0528 19:00:47.707854 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv2
I0528 19:00:47.707870 11123 net.cpp:84] Creating Layer layer_64_3_conv2
I0528 19:00:47.707876 11123 net.cpp:406] layer_64_3_conv2 <- layer_64_3_conv1
I0528 19:00:47.707887 11123 net.cpp:380] layer_64_3_conv2 -> layer_64_3_conv2
I0528 19:00:47.709534 11123 net.cpp:122] Setting up layer_64_3_conv2
I0528 19:00:47.709552 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.709558 11123 net.cpp:137] Memory required for data: 820879480
I0528 19:00:47.709568 11123 layer_factory.hpp:77] Creating layer layer_64_3_bn3
I0528 19:00:47.709578 11123 net.cpp:84] Creating Layer layer_64_3_bn3
I0528 19:00:47.709589 11123 net.cpp:406] layer_64_3_bn3 <- layer_64_3_conv2
I0528 19:00:47.709602 11123 net.cpp:367] layer_64_3_bn3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.709846 11123 net.cpp:122] Setting up layer_64_3_bn3
I0528 19:00:47.709857 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.709864 11123 net.cpp:137] Memory required for data: 828907640
I0528 19:00:47.709879 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0528 19:00:47.709889 11123 net.cpp:84] Creating Layer layer_64_3_scale3
I0528 19:00:47.709906 11123 net.cpp:406] layer_64_3_scale3 <- layer_64_3_conv2
I0528 19:00:47.709918 11123 net.cpp:367] layer_64_3_scale3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.709980 11123 layer_factory.hpp:77] Creating layer layer_64_3_scale3
I0528 19:00:47.710139 11123 net.cpp:122] Setting up layer_64_3_scale3
I0528 19:00:47.710150 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.710156 11123 net.cpp:137] Memory required for data: 836935800
I0528 19:00:47.710168 11123 layer_factory.hpp:77] Creating layer layer_64_3_relu3
I0528 19:00:47.710178 11123 net.cpp:84] Creating Layer layer_64_3_relu3
I0528 19:00:47.710187 11123 net.cpp:406] layer_64_3_relu3 <- layer_64_3_conv2
I0528 19:00:47.710198 11123 net.cpp:367] layer_64_3_relu3 -> layer_64_3_conv2 (in-place)
I0528 19:00:47.710371 11123 net.cpp:122] Setting up layer_64_3_relu3
I0528 19:00:47.710382 11123 net.cpp:129] Top shape: 10 64 56 56 (2007040)
I0528 19:00:47.710388 11123 net.cpp:137] Memory required for data: 844963960
I0528 19:00:47.710394 11123 layer_factory.hpp:77] Creating layer layer_64_3_conv3
I0528 19:00:47.710409 11123 net.cpp:84] Creating Layer layer_64_3_conv3
I0528 19:00:47.710417 11123 net.cpp:406] layer_64_3_conv3 <- layer_64_3_conv2
I0528 19:00:47.710429 11123 net.cpp:380] layer_64_3_conv3 -> layer_64_3_conv3
I0528 19:00:47.711863 11123 net.cpp:122] Setting up layer_64_3_conv3
I0528 19:00:47.711876 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.711882 11123 net.cpp:137] Memory required for data: 877076600
I0528 19:00:47.711891 11123 layer_factory.hpp:77] Creating layer layer_64_3_sum
I0528 19:00:47.711904 11123 net.cpp:84] Creating Layer layer_64_3_sum
I0528 19:00:47.711913 11123 net.cpp:406] layer_64_3_sum <- layer_64_3_conv3
I0528 19:00:47.711922 11123 net.cpp:406] layer_64_3_sum <- layer_64_2_sum_layer_64_2_sum_0_split_1
I0528 19:00:47.711935 11123 net.cpp:380] layer_64_3_sum -> layer_64_3_sum
I0528 19:00:47.711977 11123 net.cpp:122] Setting up layer_64_3_sum
I0528 19:00:47.711988 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.711994 11123 net.cpp:137] Memory required for data: 909189240
I0528 19:00:47.711999 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 19:00:47.712011 11123 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 19:00:47.712019 11123 net.cpp:406] layer_128_1_bn1 <- layer_64_3_sum
I0528 19:00:47.712031 11123 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 19:00:47.712272 11123 net.cpp:122] Setting up layer_128_1_bn1
I0528 19:00:47.712285 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.712291 11123 net.cpp:137] Memory required for data: 941301880
I0528 19:00:47.712312 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 19:00:47.712326 11123 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 19:00:47.712333 11123 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 19:00:47.712343 11123 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 19:00:47.712404 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 19:00:47.712550 11123 net.cpp:122] Setting up layer_128_1_scale1
I0528 19:00:47.712563 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.712568 11123 net.cpp:137] Memory required for data: 973414520
I0528 19:00:47.712579 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 19:00:47.712589 11123 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 19:00:47.712597 11123 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 19:00:47.712606 11123 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 19:00:47.712779 11123 net.cpp:122] Setting up layer_128_1_relu1
I0528 19:00:47.712793 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.712800 11123 net.cpp:137] Memory required for data: 1005527160
I0528 19:00:47.712807 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.712817 11123 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.712824 11123 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 19:00:47.712844 11123 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 19:00:47.712862 11123 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 19:00:47.712919 11123 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 19:00:47.712935 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.712944 11123 net.cpp:129] Top shape: 10 256 56 56 (8028160)
I0528 19:00:47.712950 11123 net.cpp:137] Memory required for data: 1069752440
I0528 19:00:47.712956 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 19:00:47.712972 11123 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 19:00:47.712980 11123 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 19:00:47.712991 11123 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 19:00:47.714591 11123 net.cpp:122] Setting up layer_128_1_conv1
I0528 19:00:47.714606 11123 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0528 19:00:47.714612 11123 net.cpp:137] Memory required for data: 1085808760
I0528 19:00:47.714620 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 19:00:47.714635 11123 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 19:00:47.714644 11123 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 19:00:47.714656 11123 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.714892 11123 net.cpp:122] Setting up layer_128_1_bn2
I0528 19:00:47.714905 11123 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0528 19:00:47.714910 11123 net.cpp:137] Memory required for data: 1101865080
I0528 19:00:47.714925 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 19:00:47.714937 11123 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 19:00:47.714946 11123 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 19:00:47.714956 11123 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.715013 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 19:00:47.715163 11123 net.cpp:122] Setting up layer_128_1_scale2
I0528 19:00:47.715175 11123 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0528 19:00:47.715181 11123 net.cpp:137] Memory required for data: 1117921400
I0528 19:00:47.715193 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 19:00:47.715204 11123 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 19:00:47.715212 11123 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 19:00:47.715221 11123 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 19:00:47.715392 11123 net.cpp:122] Setting up layer_128_1_relu2
I0528 19:00:47.715404 11123 net.cpp:129] Top shape: 10 128 56 56 (4014080)
I0528 19:00:47.715411 11123 net.cpp:137] Memory required for data: 1133977720
I0528 19:00:47.715417 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 19:00:47.715432 11123 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 19:00:47.715440 11123 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 19:00:47.715452 11123 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 19:00:47.718214 11123 net.cpp:122] Setting up layer_128_1_conv2
I0528 19:00:47.718230 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.718237 11123 net.cpp:137] Memory required for data: 1137991800
I0528 19:00:47.718246 11123 layer_factory.hpp:77] Creating layer layer_128_1_bn3
I0528 19:00:47.718261 11123 net.cpp:84] Creating Layer layer_128_1_bn3
I0528 19:00:47.718269 11123 net.cpp:406] layer_128_1_bn3 <- layer_128_1_conv2
I0528 19:00:47.718281 11123 net.cpp:367] layer_128_1_bn3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.718509 11123 net.cpp:122] Setting up layer_128_1_bn3
I0528 19:00:47.718521 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.718528 11123 net.cpp:137] Memory required for data: 1142005880
I0528 19:00:47.718540 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0528 19:00:47.718561 11123 net.cpp:84] Creating Layer layer_128_1_scale3
I0528 19:00:47.718570 11123 net.cpp:406] layer_128_1_scale3 <- layer_128_1_conv2
I0528 19:00:47.718582 11123 net.cpp:367] layer_128_1_scale3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.718641 11123 layer_factory.hpp:77] Creating layer layer_128_1_scale3
I0528 19:00:47.718786 11123 net.cpp:122] Setting up layer_128_1_scale3
I0528 19:00:47.718798 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.718804 11123 net.cpp:137] Memory required for data: 1146019960
I0528 19:00:47.718816 11123 layer_factory.hpp:77] Creating layer layer_128_1_relu3
I0528 19:00:47.718827 11123 net.cpp:84] Creating Layer layer_128_1_relu3
I0528 19:00:47.718834 11123 net.cpp:406] layer_128_1_relu3 <- layer_128_1_conv2
I0528 19:00:47.718845 11123 net.cpp:367] layer_128_1_relu3 -> layer_128_1_conv2 (in-place)
I0528 19:00:47.719019 11123 net.cpp:122] Setting up layer_128_1_relu3
I0528 19:00:47.719032 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.719038 11123 net.cpp:137] Memory required for data: 1150034040
I0528 19:00:47.719044 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv3
I0528 19:00:47.719060 11123 net.cpp:84] Creating Layer layer_128_1_conv3
I0528 19:00:47.719069 11123 net.cpp:406] layer_128_1_conv3 <- layer_128_1_conv2
I0528 19:00:47.719080 11123 net.cpp:380] layer_128_1_conv3 -> layer_128_1_conv3
I0528 19:00:47.721771 11123 net.cpp:122] Setting up layer_128_1_conv3
I0528 19:00:47.721788 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.721796 11123 net.cpp:137] Memory required for data: 1166090360
I0528 19:00:47.721804 11123 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 19:00:47.721822 11123 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 19:00:47.721829 11123 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 19:00:47.721842 11123 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 19:00:47.724437 11123 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 19:00:47.724452 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.724458 11123 net.cpp:137] Memory required for data: 1182146680
I0528 19:00:47.724467 11123 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 19:00:47.724478 11123 net.cpp:84] Creating Layer layer_128_1_sum
I0528 19:00:47.724484 11123 net.cpp:406] layer_128_1_sum <- layer_128_1_conv3
I0528 19:00:47.724493 11123 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 19:00:47.724505 11123 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 19:00:47.724547 11123 net.cpp:122] Setting up layer_128_1_sum
I0528 19:00:47.724561 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.724568 11123 net.cpp:137] Memory required for data: 1198203000
I0528 19:00:47.724575 11123 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.724598 11123 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.724606 11123 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 19:00:47.724616 11123 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 19:00:47.724629 11123 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 19:00:47.724685 11123 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 19:00:47.724697 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.724705 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.724712 11123 net.cpp:137] Memory required for data: 1230315640
I0528 19:00:47.724720 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 19:00:47.724731 11123 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 19:00:47.724738 11123 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 19:00:47.724747 11123 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 19:00:47.725018 11123 net.cpp:122] Setting up layer_128_2_bn1
I0528 19:00:47.725029 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.725036 11123 net.cpp:137] Memory required for data: 1246371960
I0528 19:00:47.725050 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 19:00:47.725064 11123 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 19:00:47.725071 11123 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 19:00:47.725081 11123 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 19:00:47.725142 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 19:00:47.725283 11123 net.cpp:122] Setting up layer_128_2_scale1
I0528 19:00:47.725296 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.725301 11123 net.cpp:137] Memory required for data: 1262428280
I0528 19:00:47.725312 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 19:00:47.725325 11123 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 19:00:47.725333 11123 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 19:00:47.725342 11123 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 19:00:47.726052 11123 net.cpp:122] Setting up layer_128_2_relu1
I0528 19:00:47.726066 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.726073 11123 net.cpp:137] Memory required for data: 1278484600
I0528 19:00:47.726079 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 19:00:47.726094 11123 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 19:00:47.726102 11123 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 19:00:47.726115 11123 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 19:00:47.727494 11123 net.cpp:122] Setting up layer_128_2_conv1
I0528 19:00:47.727509 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.727514 11123 net.cpp:137] Memory required for data: 1282498680
I0528 19:00:47.727524 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 19:00:47.727536 11123 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 19:00:47.727545 11123 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 19:00:47.727555 11123 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.727793 11123 net.cpp:122] Setting up layer_128_2_bn2
I0528 19:00:47.727805 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.727811 11123 net.cpp:137] Memory required for data: 1286512760
I0528 19:00:47.727824 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 19:00:47.727836 11123 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 19:00:47.727844 11123 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 19:00:47.727856 11123 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.727917 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 19:00:47.728061 11123 net.cpp:122] Setting up layer_128_2_scale2
I0528 19:00:47.728073 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.728080 11123 net.cpp:137] Memory required for data: 1290526840
I0528 19:00:47.728091 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 19:00:47.728101 11123 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 19:00:47.728108 11123 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 19:00:47.728121 11123 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 19:00:47.728837 11123 net.cpp:122] Setting up layer_128_2_relu2
I0528 19:00:47.728852 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.728859 11123 net.cpp:137] Memory required for data: 1294540920
I0528 19:00:47.728866 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 19:00:47.728883 11123 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 19:00:47.728891 11123 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 19:00:47.728902 11123 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 19:00:47.732931 11123 net.cpp:122] Setting up layer_128_2_conv2
I0528 19:00:47.732949 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.732964 11123 net.cpp:137] Memory required for data: 1298555000
I0528 19:00:47.732977 11123 layer_factory.hpp:77] Creating layer layer_128_2_bn3
I0528 19:00:47.732992 11123 net.cpp:84] Creating Layer layer_128_2_bn3
I0528 19:00:47.733001 11123 net.cpp:406] layer_128_2_bn3 <- layer_128_2_conv2
I0528 19:00:47.733011 11123 net.cpp:367] layer_128_2_bn3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.733249 11123 net.cpp:122] Setting up layer_128_2_bn3
I0528 19:00:47.733261 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.733268 11123 net.cpp:137] Memory required for data: 1302569080
I0528 19:00:47.733281 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0528 19:00:47.733294 11123 net.cpp:84] Creating Layer layer_128_2_scale3
I0528 19:00:47.733304 11123 net.cpp:406] layer_128_2_scale3 <- layer_128_2_conv2
I0528 19:00:47.733314 11123 net.cpp:367] layer_128_2_scale3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.733372 11123 layer_factory.hpp:77] Creating layer layer_128_2_scale3
I0528 19:00:47.733518 11123 net.cpp:122] Setting up layer_128_2_scale3
I0528 19:00:47.733530 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.733536 11123 net.cpp:137] Memory required for data: 1306583160
I0528 19:00:47.733547 11123 layer_factory.hpp:77] Creating layer layer_128_2_relu3
I0528 19:00:47.733561 11123 net.cpp:84] Creating Layer layer_128_2_relu3
I0528 19:00:47.733568 11123 net.cpp:406] layer_128_2_relu3 <- layer_128_2_conv2
I0528 19:00:47.733579 11123 net.cpp:367] layer_128_2_relu3 -> layer_128_2_conv2 (in-place)
I0528 19:00:47.733759 11123 net.cpp:122] Setting up layer_128_2_relu3
I0528 19:00:47.733772 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.733777 11123 net.cpp:137] Memory required for data: 1310597240
I0528 19:00:47.733784 11123 layer_factory.hpp:77] Creating layer layer_128_2_conv3
I0528 19:00:47.733799 11123 net.cpp:84] Creating Layer layer_128_2_conv3
I0528 19:00:47.733806 11123 net.cpp:406] layer_128_2_conv3 <- layer_128_2_conv2
I0528 19:00:47.733819 11123 net.cpp:380] layer_128_2_conv3 -> layer_128_2_conv3
I0528 19:00:47.735772 11123 net.cpp:122] Setting up layer_128_2_conv3
I0528 19:00:47.735787 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.735793 11123 net.cpp:137] Memory required for data: 1326653560
I0528 19:00:47.735803 11123 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 19:00:47.735817 11123 net.cpp:84] Creating Layer layer_128_2_sum
I0528 19:00:47.735826 11123 net.cpp:406] layer_128_2_sum <- layer_128_2_conv3
I0528 19:00:47.735834 11123 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 19:00:47.735846 11123 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 19:00:47.735888 11123 net.cpp:122] Setting up layer_128_2_sum
I0528 19:00:47.735900 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.735906 11123 net.cpp:137] Memory required for data: 1342709880
I0528 19:00:47.735913 11123 layer_factory.hpp:77] Creating layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.735924 11123 net.cpp:84] Creating Layer layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.735934 11123 net.cpp:406] layer_128_2_sum_layer_128_2_sum_0_split <- layer_128_2_sum
I0528 19:00:47.735944 11123 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 19:00:47.735957 11123 net.cpp:380] layer_128_2_sum_layer_128_2_sum_0_split -> layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 19:00:47.736014 11123 net.cpp:122] Setting up layer_128_2_sum_layer_128_2_sum_0_split
I0528 19:00:47.736027 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.736034 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.736042 11123 net.cpp:137] Memory required for data: 1374822520
I0528 19:00:47.736047 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn1
I0528 19:00:47.736059 11123 net.cpp:84] Creating Layer layer_128_3_bn1
I0528 19:00:47.736066 11123 net.cpp:406] layer_128_3_bn1 <- layer_128_2_sum_layer_128_2_sum_0_split_0
I0528 19:00:47.736086 11123 net.cpp:380] layer_128_3_bn1 -> layer_128_3_bn1
I0528 19:00:47.736331 11123 net.cpp:122] Setting up layer_128_3_bn1
I0528 19:00:47.736344 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.736351 11123 net.cpp:137] Memory required for data: 1390878840
I0528 19:00:47.736363 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 19:00:47.736374 11123 net.cpp:84] Creating Layer layer_128_3_scale1
I0528 19:00:47.736382 11123 net.cpp:406] layer_128_3_scale1 <- layer_128_3_bn1
I0528 19:00:47.736392 11123 net.cpp:367] layer_128_3_scale1 -> layer_128_3_bn1 (in-place)
I0528 19:00:47.736454 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale1
I0528 19:00:47.736596 11123 net.cpp:122] Setting up layer_128_3_scale1
I0528 19:00:47.736608 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.736614 11123 net.cpp:137] Memory required for data: 1406935160
I0528 19:00:47.736625 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu1
I0528 19:00:47.736636 11123 net.cpp:84] Creating Layer layer_128_3_relu1
I0528 19:00:47.736644 11123 net.cpp:406] layer_128_3_relu1 <- layer_128_3_bn1
I0528 19:00:47.736655 11123 net.cpp:367] layer_128_3_relu1 -> layer_128_3_bn1 (in-place)
I0528 19:00:47.736829 11123 net.cpp:122] Setting up layer_128_3_relu1
I0528 19:00:47.736840 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.736846 11123 net.cpp:137] Memory required for data: 1422991480
I0528 19:00:47.736852 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv1
I0528 19:00:47.736868 11123 net.cpp:84] Creating Layer layer_128_3_conv1
I0528 19:00:47.736876 11123 net.cpp:406] layer_128_3_conv1 <- layer_128_3_bn1
I0528 19:00:47.736888 11123 net.cpp:380] layer_128_3_conv1 -> layer_128_3_conv1
I0528 19:00:47.739363 11123 net.cpp:122] Setting up layer_128_3_conv1
I0528 19:00:47.739377 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.739384 11123 net.cpp:137] Memory required for data: 1427005560
I0528 19:00:47.739393 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn2
I0528 19:00:47.739405 11123 net.cpp:84] Creating Layer layer_128_3_bn2
I0528 19:00:47.739413 11123 net.cpp:406] layer_128_3_bn2 <- layer_128_3_conv1
I0528 19:00:47.739425 11123 net.cpp:367] layer_128_3_bn2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.739665 11123 net.cpp:122] Setting up layer_128_3_bn2
I0528 19:00:47.739677 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.739683 11123 net.cpp:137] Memory required for data: 1431019640
I0528 19:00:47.739696 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 19:00:47.739707 11123 net.cpp:84] Creating Layer layer_128_3_scale2
I0528 19:00:47.739715 11123 net.cpp:406] layer_128_3_scale2 <- layer_128_3_conv1
I0528 19:00:47.739728 11123 net.cpp:367] layer_128_3_scale2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.739789 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale2
I0528 19:00:47.739934 11123 net.cpp:122] Setting up layer_128_3_scale2
I0528 19:00:47.739946 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.739953 11123 net.cpp:137] Memory required for data: 1435033720
I0528 19:00:47.739964 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu2
I0528 19:00:47.739974 11123 net.cpp:84] Creating Layer layer_128_3_relu2
I0528 19:00:47.739982 11123 net.cpp:406] layer_128_3_relu2 <- layer_128_3_conv1
I0528 19:00:47.739994 11123 net.cpp:367] layer_128_3_relu2 -> layer_128_3_conv1 (in-place)
I0528 19:00:47.740176 11123 net.cpp:122] Setting up layer_128_3_relu2
I0528 19:00:47.740188 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.740195 11123 net.cpp:137] Memory required for data: 1439047800
I0528 19:00:47.740201 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv2
I0528 19:00:47.740217 11123 net.cpp:84] Creating Layer layer_128_3_conv2
I0528 19:00:47.740223 11123 net.cpp:406] layer_128_3_conv2 <- layer_128_3_conv1
I0528 19:00:47.740236 11123 net.cpp:380] layer_128_3_conv2 -> layer_128_3_conv2
I0528 19:00:47.743505 11123 net.cpp:122] Setting up layer_128_3_conv2
I0528 19:00:47.743520 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.743526 11123 net.cpp:137] Memory required for data: 1443061880
I0528 19:00:47.743535 11123 layer_factory.hpp:77] Creating layer layer_128_3_bn3
I0528 19:00:47.743548 11123 net.cpp:84] Creating Layer layer_128_3_bn3
I0528 19:00:47.743557 11123 net.cpp:406] layer_128_3_bn3 <- layer_128_3_conv2
I0528 19:00:47.743566 11123 net.cpp:367] layer_128_3_bn3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.743809 11123 net.cpp:122] Setting up layer_128_3_bn3
I0528 19:00:47.743821 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.743827 11123 net.cpp:137] Memory required for data: 1447075960
I0528 19:00:47.743840 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0528 19:00:47.743852 11123 net.cpp:84] Creating Layer layer_128_3_scale3
I0528 19:00:47.743860 11123 net.cpp:406] layer_128_3_scale3 <- layer_128_3_conv2
I0528 19:00:47.743875 11123 net.cpp:367] layer_128_3_scale3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.743935 11123 layer_factory.hpp:77] Creating layer layer_128_3_scale3
I0528 19:00:47.744083 11123 net.cpp:122] Setting up layer_128_3_scale3
I0528 19:00:47.744094 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.744102 11123 net.cpp:137] Memory required for data: 1451090040
I0528 19:00:47.744112 11123 layer_factory.hpp:77] Creating layer layer_128_3_relu3
I0528 19:00:47.744123 11123 net.cpp:84] Creating Layer layer_128_3_relu3
I0528 19:00:47.744132 11123 net.cpp:406] layer_128_3_relu3 <- layer_128_3_conv2
I0528 19:00:47.744143 11123 net.cpp:367] layer_128_3_relu3 -> layer_128_3_conv2 (in-place)
I0528 19:00:47.744321 11123 net.cpp:122] Setting up layer_128_3_relu3
I0528 19:00:47.744333 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.744339 11123 net.cpp:137] Memory required for data: 1455104120
I0528 19:00:47.744345 11123 layer_factory.hpp:77] Creating layer layer_128_3_conv3
I0528 19:00:47.744361 11123 net.cpp:84] Creating Layer layer_128_3_conv3
I0528 19:00:47.744369 11123 net.cpp:406] layer_128_3_conv3 <- layer_128_3_conv2
I0528 19:00:47.744379 11123 net.cpp:380] layer_128_3_conv3 -> layer_128_3_conv3
I0528 19:00:47.746331 11123 net.cpp:122] Setting up layer_128_3_conv3
I0528 19:00:47.746347 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.746354 11123 net.cpp:137] Memory required for data: 1471160440
I0528 19:00:47.746363 11123 layer_factory.hpp:77] Creating layer layer_128_3_sum
I0528 19:00:47.746374 11123 net.cpp:84] Creating Layer layer_128_3_sum
I0528 19:00:47.746383 11123 net.cpp:406] layer_128_3_sum <- layer_128_3_conv3
I0528 19:00:47.746392 11123 net.cpp:406] layer_128_3_sum <- layer_128_2_sum_layer_128_2_sum_0_split_1
I0528 19:00:47.746402 11123 net.cpp:380] layer_128_3_sum -> layer_128_3_sum
I0528 19:00:47.746446 11123 net.cpp:122] Setting up layer_128_3_sum
I0528 19:00:47.746457 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.746464 11123 net.cpp:137] Memory required for data: 1487216760
I0528 19:00:47.746469 11123 layer_factory.hpp:77] Creating layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.746484 11123 net.cpp:84] Creating Layer layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.746490 11123 net.cpp:406] layer_128_3_sum_layer_128_3_sum_0_split <- layer_128_3_sum
I0528 19:00:47.746501 11123 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 19:00:47.746516 11123 net.cpp:380] layer_128_3_sum_layer_128_3_sum_0_split -> layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 19:00:47.746572 11123 net.cpp:122] Setting up layer_128_3_sum_layer_128_3_sum_0_split
I0528 19:00:47.746584 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.746592 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.746599 11123 net.cpp:137] Memory required for data: 1519329400
I0528 19:00:47.746605 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn1
I0528 19:00:47.746618 11123 net.cpp:84] Creating Layer layer_128_4_bn1
I0528 19:00:47.746634 11123 net.cpp:406] layer_128_4_bn1 <- layer_128_3_sum_layer_128_3_sum_0_split_0
I0528 19:00:47.746644 11123 net.cpp:380] layer_128_4_bn1 -> layer_128_4_bn1
I0528 19:00:47.746889 11123 net.cpp:122] Setting up layer_128_4_bn1
I0528 19:00:47.746901 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.746907 11123 net.cpp:137] Memory required for data: 1535385720
I0528 19:00:47.746922 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 19:00:47.746932 11123 net.cpp:84] Creating Layer layer_128_4_scale1
I0528 19:00:47.746940 11123 net.cpp:406] layer_128_4_scale1 <- layer_128_4_bn1
I0528 19:00:47.746953 11123 net.cpp:367] layer_128_4_scale1 -> layer_128_4_bn1 (in-place)
I0528 19:00:47.747014 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale1
I0528 19:00:47.747159 11123 net.cpp:122] Setting up layer_128_4_scale1
I0528 19:00:47.747171 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.747177 11123 net.cpp:137] Memory required for data: 1551442040
I0528 19:00:47.747189 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu1
I0528 19:00:47.747200 11123 net.cpp:84] Creating Layer layer_128_4_relu1
I0528 19:00:47.747207 11123 net.cpp:406] layer_128_4_relu1 <- layer_128_4_bn1
I0528 19:00:47.747218 11123 net.cpp:367] layer_128_4_relu1 -> layer_128_4_bn1 (in-place)
I0528 19:00:47.747925 11123 net.cpp:122] Setting up layer_128_4_relu1
I0528 19:00:47.747937 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.747944 11123 net.cpp:137] Memory required for data: 1567498360
I0528 19:00:47.747951 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv1
I0528 19:00:47.747966 11123 net.cpp:84] Creating Layer layer_128_4_conv1
I0528 19:00:47.747973 11123 net.cpp:406] layer_128_4_conv1 <- layer_128_4_bn1
I0528 19:00:47.747987 11123 net.cpp:380] layer_128_4_conv1 -> layer_128_4_conv1
I0528 19:00:47.749392 11123 net.cpp:122] Setting up layer_128_4_conv1
I0528 19:00:47.749406 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.749413 11123 net.cpp:137] Memory required for data: 1571512440
I0528 19:00:47.749423 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn2
I0528 19:00:47.749436 11123 net.cpp:84] Creating Layer layer_128_4_bn2
I0528 19:00:47.749444 11123 net.cpp:406] layer_128_4_bn2 <- layer_128_4_conv1
I0528 19:00:47.749454 11123 net.cpp:367] layer_128_4_bn2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.749694 11123 net.cpp:122] Setting up layer_128_4_bn2
I0528 19:00:47.749706 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.749712 11123 net.cpp:137] Memory required for data: 1575526520
I0528 19:00:47.749725 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 19:00:47.749737 11123 net.cpp:84] Creating Layer layer_128_4_scale2
I0528 19:00:47.749745 11123 net.cpp:406] layer_128_4_scale2 <- layer_128_4_conv1
I0528 19:00:47.749758 11123 net.cpp:367] layer_128_4_scale2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.749817 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale2
I0528 19:00:47.749967 11123 net.cpp:122] Setting up layer_128_4_scale2
I0528 19:00:47.749979 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.749985 11123 net.cpp:137] Memory required for data: 1579540600
I0528 19:00:47.749996 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu2
I0528 19:00:47.750007 11123 net.cpp:84] Creating Layer layer_128_4_relu2
I0528 19:00:47.750015 11123 net.cpp:406] layer_128_4_relu2 <- layer_128_4_conv1
I0528 19:00:47.750026 11123 net.cpp:367] layer_128_4_relu2 -> layer_128_4_conv1 (in-place)
I0528 19:00:47.750738 11123 net.cpp:122] Setting up layer_128_4_relu2
I0528 19:00:47.750753 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.750761 11123 net.cpp:137] Memory required for data: 1583554680
I0528 19:00:47.750766 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv2
I0528 19:00:47.750782 11123 net.cpp:84] Creating Layer layer_128_4_conv2
I0528 19:00:47.750789 11123 net.cpp:406] layer_128_4_conv2 <- layer_128_4_conv1
I0528 19:00:47.750811 11123 net.cpp:380] layer_128_4_conv2 -> layer_128_4_conv2
I0528 19:00:47.754076 11123 net.cpp:122] Setting up layer_128_4_conv2
I0528 19:00:47.754091 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.754096 11123 net.cpp:137] Memory required for data: 1587568760
I0528 19:00:47.754124 11123 layer_factory.hpp:77] Creating layer layer_128_4_bn3
I0528 19:00:47.754137 11123 net.cpp:84] Creating Layer layer_128_4_bn3
I0528 19:00:47.754148 11123 net.cpp:406] layer_128_4_bn3 <- layer_128_4_conv2
I0528 19:00:47.754158 11123 net.cpp:367] layer_128_4_bn3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.754401 11123 net.cpp:122] Setting up layer_128_4_bn3
I0528 19:00:47.754415 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.754423 11123 net.cpp:137] Memory required for data: 1591582840
I0528 19:00:47.754436 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0528 19:00:47.754447 11123 net.cpp:84] Creating Layer layer_128_4_scale3
I0528 19:00:47.754456 11123 net.cpp:406] layer_128_4_scale3 <- layer_128_4_conv2
I0528 19:00:47.754467 11123 net.cpp:367] layer_128_4_scale3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.754526 11123 layer_factory.hpp:77] Creating layer layer_128_4_scale3
I0528 19:00:47.754676 11123 net.cpp:122] Setting up layer_128_4_scale3
I0528 19:00:47.754688 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.754695 11123 net.cpp:137] Memory required for data: 1595596920
I0528 19:00:47.754706 11123 layer_factory.hpp:77] Creating layer layer_128_4_relu3
I0528 19:00:47.754716 11123 net.cpp:84] Creating Layer layer_128_4_relu3
I0528 19:00:47.754724 11123 net.cpp:406] layer_128_4_relu3 <- layer_128_4_conv2
I0528 19:00:47.754736 11123 net.cpp:367] layer_128_4_relu3 -> layer_128_4_conv2 (in-place)
I0528 19:00:47.754914 11123 net.cpp:122] Setting up layer_128_4_relu3
I0528 19:00:47.754926 11123 net.cpp:129] Top shape: 10 128 28 28 (1003520)
I0528 19:00:47.754932 11123 net.cpp:137] Memory required for data: 1599611000
I0528 19:00:47.754938 11123 layer_factory.hpp:77] Creating layer layer_128_4_conv3
I0528 19:00:47.754954 11123 net.cpp:84] Creating Layer layer_128_4_conv3
I0528 19:00:47.754962 11123 net.cpp:406] layer_128_4_conv3 <- layer_128_4_conv2
I0528 19:00:47.754972 11123 net.cpp:380] layer_128_4_conv3 -> layer_128_4_conv3
I0528 19:00:47.756952 11123 net.cpp:122] Setting up layer_128_4_conv3
I0528 19:00:47.756966 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.756973 11123 net.cpp:137] Memory required for data: 1615667320
I0528 19:00:47.756981 11123 layer_factory.hpp:77] Creating layer layer_128_4_sum
I0528 19:00:47.756994 11123 net.cpp:84] Creating Layer layer_128_4_sum
I0528 19:00:47.757002 11123 net.cpp:406] layer_128_4_sum <- layer_128_4_conv3
I0528 19:00:47.757010 11123 net.cpp:406] layer_128_4_sum <- layer_128_3_sum_layer_128_3_sum_0_split_1
I0528 19:00:47.757022 11123 net.cpp:380] layer_128_4_sum -> layer_128_4_sum
I0528 19:00:47.757066 11123 net.cpp:122] Setting up layer_128_4_sum
I0528 19:00:47.757077 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.757083 11123 net.cpp:137] Memory required for data: 1631723640
I0528 19:00:47.757091 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 19:00:47.757104 11123 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 19:00:47.757112 11123 net.cpp:406] layer_256_1_bn1 <- layer_128_4_sum
I0528 19:00:47.757122 11123 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 19:00:47.757381 11123 net.cpp:122] Setting up layer_256_1_bn1
I0528 19:00:47.757393 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.757400 11123 net.cpp:137] Memory required for data: 1647779960
I0528 19:00:47.757413 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 19:00:47.757424 11123 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 19:00:47.757432 11123 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 19:00:47.757441 11123 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 19:00:47.757506 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 19:00:47.757663 11123 net.cpp:122] Setting up layer_256_1_scale1
I0528 19:00:47.757674 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.757680 11123 net.cpp:137] Memory required for data: 1663836280
I0528 19:00:47.757692 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 19:00:47.757702 11123 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 19:00:47.757709 11123 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 19:00:47.757721 11123 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 19:00:47.757894 11123 net.cpp:122] Setting up layer_256_1_relu1
I0528 19:00:47.757906 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.757913 11123 net.cpp:137] Memory required for data: 1679892600
I0528 19:00:47.757920 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.757930 11123 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.757937 11123 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 19:00:47.757947 11123 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 19:00:47.757962 11123 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 19:00:47.758021 11123 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 19:00:47.758033 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.758040 11123 net.cpp:129] Top shape: 10 512 28 28 (4014080)
I0528 19:00:47.758047 11123 net.cpp:137] Memory required for data: 1712005240
I0528 19:00:47.758054 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 19:00:47.758071 11123 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 19:00:47.758080 11123 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 19:00:47.758090 11123 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 19:00:47.760733 11123 net.cpp:122] Setting up layer_256_1_conv1
I0528 19:00:47.760747 11123 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0528 19:00:47.760753 11123 net.cpp:137] Memory required for data: 1720033400
I0528 19:00:47.760762 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 19:00:47.760772 11123 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 19:00:47.760781 11123 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 19:00:47.760792 11123 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.761066 11123 net.cpp:122] Setting up layer_256_1_bn2
I0528 19:00:47.761078 11123 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0528 19:00:47.761085 11123 net.cpp:137] Memory required for data: 1728061560
I0528 19:00:47.761097 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 19:00:47.761109 11123 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 19:00:47.761117 11123 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 19:00:47.761128 11123 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.761186 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 19:00:47.761332 11123 net.cpp:122] Setting up layer_256_1_scale2
I0528 19:00:47.761344 11123 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0528 19:00:47.761350 11123 net.cpp:137] Memory required for data: 1736089720
I0528 19:00:47.761361 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 19:00:47.761371 11123 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 19:00:47.761379 11123 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 19:00:47.761389 11123 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 19:00:47.761581 11123 net.cpp:122] Setting up layer_256_1_relu2
I0528 19:00:47.761593 11123 net.cpp:129] Top shape: 10 256 28 28 (2007040)
I0528 19:00:47.761600 11123 net.cpp:137] Memory required for data: 1744117880
I0528 19:00:47.761605 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 19:00:47.761632 11123 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 19:00:47.761641 11123 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 19:00:47.761653 11123 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 19:00:47.769527 11123 net.cpp:122] Setting up layer_256_1_conv2
I0528 19:00:47.769544 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.769551 11123 net.cpp:137] Memory required for data: 1746124920
I0528 19:00:47.769560 11123 layer_factory.hpp:77] Creating layer layer_256_1_bn3
I0528 19:00:47.769572 11123 net.cpp:84] Creating Layer layer_256_1_bn3
I0528 19:00:47.769582 11123 net.cpp:406] layer_256_1_bn3 <- layer_256_1_conv2
I0528 19:00:47.769603 11123 net.cpp:367] layer_256_1_bn3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.769860 11123 net.cpp:122] Setting up layer_256_1_bn3
I0528 19:00:47.769871 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.769877 11123 net.cpp:137] Memory required for data: 1748131960
I0528 19:00:47.769904 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0528 19:00:47.769914 11123 net.cpp:84] Creating Layer layer_256_1_scale3
I0528 19:00:47.769922 11123 net.cpp:406] layer_256_1_scale3 <- layer_256_1_conv2
I0528 19:00:47.769937 11123 net.cpp:367] layer_256_1_scale3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.769996 11123 layer_factory.hpp:77] Creating layer layer_256_1_scale3
I0528 19:00:47.770144 11123 net.cpp:122] Setting up layer_256_1_scale3
I0528 19:00:47.770156 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.770162 11123 net.cpp:137] Memory required for data: 1750139000
I0528 19:00:47.770174 11123 layer_factory.hpp:77] Creating layer layer_256_1_relu3
I0528 19:00:47.770185 11123 net.cpp:84] Creating Layer layer_256_1_relu3
I0528 19:00:47.770193 11123 net.cpp:406] layer_256_1_relu3 <- layer_256_1_conv2
I0528 19:00:47.770203 11123 net.cpp:367] layer_256_1_relu3 -> layer_256_1_conv2 (in-place)
I0528 19:00:47.770380 11123 net.cpp:122] Setting up layer_256_1_relu3
I0528 19:00:47.770392 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.770398 11123 net.cpp:137] Memory required for data: 1752146040
I0528 19:00:47.770404 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv3
I0528 19:00:47.770422 11123 net.cpp:84] Creating Layer layer_256_1_conv3
I0528 19:00:47.770429 11123 net.cpp:406] layer_256_1_conv3 <- layer_256_1_conv2
I0528 19:00:47.770444 11123 net.cpp:380] layer_256_1_conv3 -> layer_256_1_conv3
I0528 19:00:47.775084 11123 net.cpp:122] Setting up layer_256_1_conv3
I0528 19:00:47.775099 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.775107 11123 net.cpp:137] Memory required for data: 1760174200
I0528 19:00:47.775117 11123 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 19:00:47.775135 11123 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 19:00:47.775143 11123 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 19:00:47.775156 11123 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 19:00:47.782258 11123 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 19:00:47.782274 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.782281 11123 net.cpp:137] Memory required for data: 1768202360
I0528 19:00:47.782290 11123 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 19:00:47.782302 11123 net.cpp:84] Creating Layer layer_256_1_sum
I0528 19:00:47.782310 11123 net.cpp:406] layer_256_1_sum <- layer_256_1_conv3
I0528 19:00:47.782320 11123 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 19:00:47.782332 11123 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 19:00:47.782385 11123 net.cpp:122] Setting up layer_256_1_sum
I0528 19:00:47.782398 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.782404 11123 net.cpp:137] Memory required for data: 1776230520
I0528 19:00:47.782413 11123 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.782423 11123 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.782441 11123 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 19:00:47.782454 11123 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 19:00:47.782466 11123 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 19:00:47.782526 11123 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 19:00:47.782537 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.782546 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.782552 11123 net.cpp:137] Memory required for data: 1792286840
I0528 19:00:47.782559 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 19:00:47.782572 11123 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 19:00:47.782579 11123 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 19:00:47.782589 11123 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 19:00:47.782852 11123 net.cpp:122] Setting up layer_256_2_bn1
I0528 19:00:47.782863 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.782869 11123 net.cpp:137] Memory required for data: 1800315000
I0528 19:00:47.782883 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 19:00:47.782896 11123 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 19:00:47.782903 11123 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 19:00:47.782913 11123 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 19:00:47.782973 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 19:00:47.783124 11123 net.cpp:122] Setting up layer_256_2_scale1
I0528 19:00:47.783135 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.783141 11123 net.cpp:137] Memory required for data: 1808343160
I0528 19:00:47.783154 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 19:00:47.783162 11123 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 19:00:47.783170 11123 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 19:00:47.783181 11123 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 19:00:47.783370 11123 net.cpp:122] Setting up layer_256_2_relu1
I0528 19:00:47.783381 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.783387 11123 net.cpp:137] Memory required for data: 1816371320
I0528 19:00:47.783393 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 19:00:47.783409 11123 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 19:00:47.783416 11123 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 19:00:47.783428 11123 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 19:00:47.787328 11123 net.cpp:122] Setting up layer_256_2_conv1
I0528 19:00:47.787343 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.787349 11123 net.cpp:137] Memory required for data: 1818378360
I0528 19:00:47.787358 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 19:00:47.787370 11123 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 19:00:47.787379 11123 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 19:00:47.787391 11123 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.787637 11123 net.cpp:122] Setting up layer_256_2_bn2
I0528 19:00:47.787649 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.787655 11123 net.cpp:137] Memory required for data: 1820385400
I0528 19:00:47.787668 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 19:00:47.787683 11123 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 19:00:47.787691 11123 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 19:00:47.787701 11123 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.787765 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 19:00:47.787915 11123 net.cpp:122] Setting up layer_256_2_scale2
I0528 19:00:47.787927 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.787943 11123 net.cpp:137] Memory required for data: 1822392440
I0528 19:00:47.787955 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 19:00:47.787987 11123 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 19:00:47.787994 11123 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 19:00:47.788003 11123 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 19:00:47.788720 11123 net.cpp:122] Setting up layer_256_2_relu2
I0528 19:00:47.788736 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.788743 11123 net.cpp:137] Memory required for data: 1824399480
I0528 19:00:47.788751 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 19:00:47.788769 11123 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 19:00:47.788776 11123 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 19:00:47.788790 11123 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 19:00:47.796804 11123 net.cpp:122] Setting up layer_256_2_conv2
I0528 19:00:47.796825 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.796831 11123 net.cpp:137] Memory required for data: 1826406520
I0528 19:00:47.796844 11123 layer_factory.hpp:77] Creating layer layer_256_2_bn3
I0528 19:00:47.796856 11123 net.cpp:84] Creating Layer layer_256_2_bn3
I0528 19:00:47.796867 11123 net.cpp:406] layer_256_2_bn3 <- layer_256_2_conv2
I0528 19:00:47.796883 11123 net.cpp:367] layer_256_2_bn3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.797147 11123 net.cpp:122] Setting up layer_256_2_bn3
I0528 19:00:47.797160 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.797166 11123 net.cpp:137] Memory required for data: 1828413560
I0528 19:00:47.797180 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0528 19:00:47.797193 11123 net.cpp:84] Creating Layer layer_256_2_scale3
I0528 19:00:47.797200 11123 net.cpp:406] layer_256_2_scale3 <- layer_256_2_conv2
I0528 19:00:47.797212 11123 net.cpp:367] layer_256_2_scale3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.797276 11123 layer_factory.hpp:77] Creating layer layer_256_2_scale3
I0528 19:00:47.797431 11123 net.cpp:122] Setting up layer_256_2_scale3
I0528 19:00:47.797443 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.797449 11123 net.cpp:137] Memory required for data: 1830420600
I0528 19:00:47.797461 11123 layer_factory.hpp:77] Creating layer layer_256_2_relu3
I0528 19:00:47.797471 11123 net.cpp:84] Creating Layer layer_256_2_relu3
I0528 19:00:47.797479 11123 net.cpp:406] layer_256_2_relu3 <- layer_256_2_conv2
I0528 19:00:47.797488 11123 net.cpp:367] layer_256_2_relu3 -> layer_256_2_conv2 (in-place)
I0528 19:00:47.798246 11123 net.cpp:122] Setting up layer_256_2_relu3
I0528 19:00:47.798260 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.798266 11123 net.cpp:137] Memory required for data: 1832427640
I0528 19:00:47.798272 11123 layer_factory.hpp:77] Creating layer layer_256_2_conv3
I0528 19:00:47.798288 11123 net.cpp:84] Creating Layer layer_256_2_conv3
I0528 19:00:47.798295 11123 net.cpp:406] layer_256_2_conv3 <- layer_256_2_conv2
I0528 19:00:47.798310 11123 net.cpp:380] layer_256_2_conv3 -> layer_256_2_conv3
I0528 19:00:47.802940 11123 net.cpp:122] Setting up layer_256_2_conv3
I0528 19:00:47.802955 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.802961 11123 net.cpp:137] Memory required for data: 1840455800
I0528 19:00:47.802970 11123 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 19:00:47.802983 11123 net.cpp:84] Creating Layer layer_256_2_sum
I0528 19:00:47.802991 11123 net.cpp:406] layer_256_2_sum <- layer_256_2_conv3
I0528 19:00:47.802999 11123 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 19:00:47.803011 11123 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 19:00:47.803053 11123 net.cpp:122] Setting up layer_256_2_sum
I0528 19:00:47.803066 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.803071 11123 net.cpp:137] Memory required for data: 1848483960
I0528 19:00:47.803077 11123 layer_factory.hpp:77] Creating layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.803098 11123 net.cpp:84] Creating Layer layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.803107 11123 net.cpp:406] layer_256_2_sum_layer_256_2_sum_0_split <- layer_256_2_sum
I0528 19:00:47.803122 11123 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 19:00:47.803134 11123 net.cpp:380] layer_256_2_sum_layer_256_2_sum_0_split -> layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 19:00:47.803194 11123 net.cpp:122] Setting up layer_256_2_sum_layer_256_2_sum_0_split
I0528 19:00:47.803205 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.803213 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.803220 11123 net.cpp:137] Memory required for data: 1864540280
I0528 19:00:47.803226 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn1
I0528 19:00:47.803238 11123 net.cpp:84] Creating Layer layer_256_3_bn1
I0528 19:00:47.803246 11123 net.cpp:406] layer_256_3_bn1 <- layer_256_2_sum_layer_256_2_sum_0_split_0
I0528 19:00:47.803256 11123 net.cpp:380] layer_256_3_bn1 -> layer_256_3_bn1
I0528 19:00:47.803508 11123 net.cpp:122] Setting up layer_256_3_bn1
I0528 19:00:47.803520 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.803525 11123 net.cpp:137] Memory required for data: 1872568440
I0528 19:00:47.803539 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 19:00:47.803550 11123 net.cpp:84] Creating Layer layer_256_3_scale1
I0528 19:00:47.803557 11123 net.cpp:406] layer_256_3_scale1 <- layer_256_3_bn1
I0528 19:00:47.803568 11123 net.cpp:367] layer_256_3_scale1 -> layer_256_3_bn1 (in-place)
I0528 19:00:47.803627 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale1
I0528 19:00:47.803778 11123 net.cpp:122] Setting up layer_256_3_scale1
I0528 19:00:47.803791 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.803797 11123 net.cpp:137] Memory required for data: 1880596600
I0528 19:00:47.803807 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu1
I0528 19:00:47.803817 11123 net.cpp:84] Creating Layer layer_256_3_relu1
I0528 19:00:47.803825 11123 net.cpp:406] layer_256_3_relu1 <- layer_256_3_bn1
I0528 19:00:47.803838 11123 net.cpp:367] layer_256_3_relu1 -> layer_256_3_bn1 (in-place)
I0528 19:00:47.804010 11123 net.cpp:122] Setting up layer_256_3_relu1
I0528 19:00:47.804023 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.804028 11123 net.cpp:137] Memory required for data: 1888624760
I0528 19:00:47.804033 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv1
I0528 19:00:47.804049 11123 net.cpp:84] Creating Layer layer_256_3_conv1
I0528 19:00:47.804056 11123 net.cpp:406] layer_256_3_conv1 <- layer_256_3_bn1
I0528 19:00:47.804066 11123 net.cpp:380] layer_256_3_conv1 -> layer_256_3_conv1
I0528 19:00:47.807898 11123 net.cpp:122] Setting up layer_256_3_conv1
I0528 19:00:47.807911 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.807919 11123 net.cpp:137] Memory required for data: 1890631800
I0528 19:00:47.807927 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn2
I0528 19:00:47.807953 11123 net.cpp:84] Creating Layer layer_256_3_bn2
I0528 19:00:47.807962 11123 net.cpp:406] layer_256_3_bn2 <- layer_256_3_conv1
I0528 19:00:47.807974 11123 net.cpp:367] layer_256_3_bn2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.808229 11123 net.cpp:122] Setting up layer_256_3_bn2
I0528 19:00:47.808241 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.808248 11123 net.cpp:137] Memory required for data: 1892638840
I0528 19:00:47.808274 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 19:00:47.808286 11123 net.cpp:84] Creating Layer layer_256_3_scale2
I0528 19:00:47.808295 11123 net.cpp:406] layer_256_3_scale2 <- layer_256_3_conv1
I0528 19:00:47.808305 11123 net.cpp:367] layer_256_3_scale2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.808377 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale2
I0528 19:00:47.808552 11123 net.cpp:122] Setting up layer_256_3_scale2
I0528 19:00:47.808570 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.808578 11123 net.cpp:137] Memory required for data: 1894645880
I0528 19:00:47.808600 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu2
I0528 19:00:47.808610 11123 net.cpp:84] Creating Layer layer_256_3_relu2
I0528 19:00:47.808619 11123 net.cpp:406] layer_256_3_relu2 <- layer_256_3_conv1
I0528 19:00:47.808630 11123 net.cpp:367] layer_256_3_relu2 -> layer_256_3_conv1 (in-place)
I0528 19:00:47.808807 11123 net.cpp:122] Setting up layer_256_3_relu2
I0528 19:00:47.808820 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.808826 11123 net.cpp:137] Memory required for data: 1896652920
I0528 19:00:47.808833 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv2
I0528 19:00:47.808850 11123 net.cpp:84] Creating Layer layer_256_3_conv2
I0528 19:00:47.808856 11123 net.cpp:406] layer_256_3_conv2 <- layer_256_3_conv1
I0528 19:00:47.808867 11123 net.cpp:380] layer_256_3_conv2 -> layer_256_3_conv2
I0528 19:00:47.817353 11123 net.cpp:122] Setting up layer_256_3_conv2
I0528 19:00:47.817370 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.817378 11123 net.cpp:137] Memory required for data: 1898659960
I0528 19:00:47.817387 11123 layer_factory.hpp:77] Creating layer layer_256_3_bn3
I0528 19:00:47.817400 11123 net.cpp:84] Creating Layer layer_256_3_bn3
I0528 19:00:47.817409 11123 net.cpp:406] layer_256_3_bn3 <- layer_256_3_conv2
I0528 19:00:47.817421 11123 net.cpp:367] layer_256_3_bn3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.817675 11123 net.cpp:122] Setting up layer_256_3_bn3
I0528 19:00:47.817687 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.817693 11123 net.cpp:137] Memory required for data: 1900667000
I0528 19:00:47.817708 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0528 19:00:47.817721 11123 net.cpp:84] Creating Layer layer_256_3_scale3
I0528 19:00:47.817730 11123 net.cpp:406] layer_256_3_scale3 <- layer_256_3_conv2
I0528 19:00:47.817740 11123 net.cpp:367] layer_256_3_scale3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.817803 11123 layer_factory.hpp:77] Creating layer layer_256_3_scale3
I0528 19:00:47.817955 11123 net.cpp:122] Setting up layer_256_3_scale3
I0528 19:00:47.817966 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.817972 11123 net.cpp:137] Memory required for data: 1902674040
I0528 19:00:47.817983 11123 layer_factory.hpp:77] Creating layer layer_256_3_relu3
I0528 19:00:47.817996 11123 net.cpp:84] Creating Layer layer_256_3_relu3
I0528 19:00:47.818004 11123 net.cpp:406] layer_256_3_relu3 <- layer_256_3_conv2
I0528 19:00:47.818014 11123 net.cpp:367] layer_256_3_relu3 -> layer_256_3_conv2 (in-place)
I0528 19:00:47.818195 11123 net.cpp:122] Setting up layer_256_3_relu3
I0528 19:00:47.818207 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.818213 11123 net.cpp:137] Memory required for data: 1904681080
I0528 19:00:47.818219 11123 layer_factory.hpp:77] Creating layer layer_256_3_conv3
I0528 19:00:47.818234 11123 net.cpp:84] Creating Layer layer_256_3_conv3
I0528 19:00:47.818241 11123 net.cpp:406] layer_256_3_conv3 <- layer_256_3_conv2
I0528 19:00:47.818255 11123 net.cpp:380] layer_256_3_conv3 -> layer_256_3_conv3
I0528 19:00:47.822876 11123 net.cpp:122] Setting up layer_256_3_conv3
I0528 19:00:47.822891 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.822898 11123 net.cpp:137] Memory required for data: 1912709240
I0528 19:00:47.822907 11123 layer_factory.hpp:77] Creating layer layer_256_3_sum
I0528 19:00:47.822919 11123 net.cpp:84] Creating Layer layer_256_3_sum
I0528 19:00:47.822927 11123 net.cpp:406] layer_256_3_sum <- layer_256_3_conv3
I0528 19:00:47.822935 11123 net.cpp:406] layer_256_3_sum <- layer_256_2_sum_layer_256_2_sum_0_split_1
I0528 19:00:47.822947 11123 net.cpp:380] layer_256_3_sum -> layer_256_3_sum
I0528 19:00:47.822990 11123 net.cpp:122] Setting up layer_256_3_sum
I0528 19:00:47.823001 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.823020 11123 net.cpp:137] Memory required for data: 1920737400
I0528 19:00:47.823027 11123 layer_factory.hpp:77] Creating layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.823037 11123 net.cpp:84] Creating Layer layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.823045 11123 net.cpp:406] layer_256_3_sum_layer_256_3_sum_0_split <- layer_256_3_sum
I0528 19:00:47.823068 11123 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 19:00:47.823081 11123 net.cpp:380] layer_256_3_sum_layer_256_3_sum_0_split -> layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 19:00:47.823151 11123 net.cpp:122] Setting up layer_256_3_sum_layer_256_3_sum_0_split
I0528 19:00:47.823163 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.823171 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.823179 11123 net.cpp:137] Memory required for data: 1936793720
I0528 19:00:47.823184 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn1
I0528 19:00:47.823207 11123 net.cpp:84] Creating Layer layer_256_4_bn1
I0528 19:00:47.823215 11123 net.cpp:406] layer_256_4_bn1 <- layer_256_3_sum_layer_256_3_sum_0_split_0
I0528 19:00:47.823225 11123 net.cpp:380] layer_256_4_bn1 -> layer_256_4_bn1
I0528 19:00:47.823495 11123 net.cpp:122] Setting up layer_256_4_bn1
I0528 19:00:47.823508 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.823524 11123 net.cpp:137] Memory required for data: 1944821880
I0528 19:00:47.823539 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 19:00:47.823550 11123 net.cpp:84] Creating Layer layer_256_4_scale1
I0528 19:00:47.823559 11123 net.cpp:406] layer_256_4_scale1 <- layer_256_4_bn1
I0528 19:00:47.823571 11123 net.cpp:367] layer_256_4_scale1 -> layer_256_4_bn1 (in-place)
I0528 19:00:47.823632 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale1
I0528 19:00:47.823794 11123 net.cpp:122] Setting up layer_256_4_scale1
I0528 19:00:47.823807 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.823812 11123 net.cpp:137] Memory required for data: 1952850040
I0528 19:00:47.823823 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu1
I0528 19:00:47.823833 11123 net.cpp:84] Creating Layer layer_256_4_relu1
I0528 19:00:47.823840 11123 net.cpp:406] layer_256_4_relu1 <- layer_256_4_bn1
I0528 19:00:47.823850 11123 net.cpp:367] layer_256_4_relu1 -> layer_256_4_bn1 (in-place)
I0528 19:00:47.824029 11123 net.cpp:122] Setting up layer_256_4_relu1
I0528 19:00:47.824043 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.824048 11123 net.cpp:137] Memory required for data: 1960878200
I0528 19:00:47.824054 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv1
I0528 19:00:47.824069 11123 net.cpp:84] Creating Layer layer_256_4_conv1
I0528 19:00:47.824075 11123 net.cpp:406] layer_256_4_conv1 <- layer_256_4_bn1
I0528 19:00:47.824090 11123 net.cpp:380] layer_256_4_conv1 -> layer_256_4_conv1
I0528 19:00:47.833195 11123 net.cpp:122] Setting up layer_256_4_conv1
I0528 19:00:47.833219 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.833225 11123 net.cpp:137] Memory required for data: 1962885240
I0528 19:00:47.833237 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn2
I0528 19:00:47.833254 11123 net.cpp:84] Creating Layer layer_256_4_bn2
I0528 19:00:47.833263 11123 net.cpp:406] layer_256_4_bn2 <- layer_256_4_conv1
I0528 19:00:47.833276 11123 net.cpp:367] layer_256_4_bn2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.833537 11123 net.cpp:122] Setting up layer_256_4_bn2
I0528 19:00:47.833549 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.833555 11123 net.cpp:137] Memory required for data: 1964892280
I0528 19:00:47.833570 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 19:00:47.833582 11123 net.cpp:84] Creating Layer layer_256_4_scale2
I0528 19:00:47.833590 11123 net.cpp:406] layer_256_4_scale2 <- layer_256_4_conv1
I0528 19:00:47.833600 11123 net.cpp:367] layer_256_4_scale2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.833688 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale2
I0528 19:00:47.833843 11123 net.cpp:122] Setting up layer_256_4_scale2
I0528 19:00:47.833855 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.833861 11123 net.cpp:137] Memory required for data: 1966899320
I0528 19:00:47.833873 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu2
I0528 19:00:47.833884 11123 net.cpp:84] Creating Layer layer_256_4_relu2
I0528 19:00:47.833892 11123 net.cpp:406] layer_256_4_relu2 <- layer_256_4_conv1
I0528 19:00:47.833904 11123 net.cpp:367] layer_256_4_relu2 -> layer_256_4_conv1 (in-place)
I0528 19:00:47.834647 11123 net.cpp:122] Setting up layer_256_4_relu2
I0528 19:00:47.834661 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.834667 11123 net.cpp:137] Memory required for data: 1968906360
I0528 19:00:47.834674 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv2
I0528 19:00:47.834692 11123 net.cpp:84] Creating Layer layer_256_4_conv2
I0528 19:00:47.834699 11123 net.cpp:406] layer_256_4_conv2 <- layer_256_4_conv1
I0528 19:00:47.834712 11123 net.cpp:380] layer_256_4_conv2 -> layer_256_4_conv2
I0528 19:00:47.842679 11123 net.cpp:122] Setting up layer_256_4_conv2
I0528 19:00:47.842694 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.842700 11123 net.cpp:137] Memory required for data: 1970913400
I0528 19:00:47.842710 11123 layer_factory.hpp:77] Creating layer layer_256_4_bn3
I0528 19:00:47.842722 11123 net.cpp:84] Creating Layer layer_256_4_bn3
I0528 19:00:47.842731 11123 net.cpp:406] layer_256_4_bn3 <- layer_256_4_conv2
I0528 19:00:47.842746 11123 net.cpp:367] layer_256_4_bn3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.843009 11123 net.cpp:122] Setting up layer_256_4_bn3
I0528 19:00:47.843021 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.843027 11123 net.cpp:137] Memory required for data: 1972920440
I0528 19:00:47.843040 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0528 19:00:47.843051 11123 net.cpp:84] Creating Layer layer_256_4_scale3
I0528 19:00:47.843060 11123 net.cpp:406] layer_256_4_scale3 <- layer_256_4_conv2
I0528 19:00:47.843073 11123 net.cpp:367] layer_256_4_scale3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.843133 11123 layer_factory.hpp:77] Creating layer layer_256_4_scale3
I0528 19:00:47.843286 11123 net.cpp:122] Setting up layer_256_4_scale3
I0528 19:00:47.843297 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.843302 11123 net.cpp:137] Memory required for data: 1974927480
I0528 19:00:47.843313 11123 layer_factory.hpp:77] Creating layer layer_256_4_relu3
I0528 19:00:47.843323 11123 net.cpp:84] Creating Layer layer_256_4_relu3
I0528 19:00:47.843331 11123 net.cpp:406] layer_256_4_relu3 <- layer_256_4_conv2
I0528 19:00:47.843340 11123 net.cpp:367] layer_256_4_relu3 -> layer_256_4_conv2 (in-place)
I0528 19:00:47.844040 11123 net.cpp:122] Setting up layer_256_4_relu3
I0528 19:00:47.844053 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.844059 11123 net.cpp:137] Memory required for data: 1976934520
I0528 19:00:47.844065 11123 layer_factory.hpp:77] Creating layer layer_256_4_conv3
I0528 19:00:47.844084 11123 net.cpp:84] Creating Layer layer_256_4_conv3
I0528 19:00:47.844090 11123 net.cpp:406] layer_256_4_conv3 <- layer_256_4_conv2
I0528 19:00:47.844105 11123 net.cpp:380] layer_256_4_conv3 -> layer_256_4_conv3
I0528 19:00:47.848700 11123 net.cpp:122] Setting up layer_256_4_conv3
I0528 19:00:47.848714 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.848721 11123 net.cpp:137] Memory required for data: 1984962680
I0528 19:00:47.848731 11123 layer_factory.hpp:77] Creating layer layer_256_4_sum
I0528 19:00:47.848742 11123 net.cpp:84] Creating Layer layer_256_4_sum
I0528 19:00:47.848752 11123 net.cpp:406] layer_256_4_sum <- layer_256_4_conv3
I0528 19:00:47.848759 11123 net.cpp:406] layer_256_4_sum <- layer_256_3_sum_layer_256_3_sum_0_split_1
I0528 19:00:47.848770 11123 net.cpp:380] layer_256_4_sum -> layer_256_4_sum
I0528 19:00:47.848819 11123 net.cpp:122] Setting up layer_256_4_sum
I0528 19:00:47.848837 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.848845 11123 net.cpp:137] Memory required for data: 1992990840
I0528 19:00:47.848850 11123 layer_factory.hpp:77] Creating layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.848861 11123 net.cpp:84] Creating Layer layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.848870 11123 net.cpp:406] layer_256_4_sum_layer_256_4_sum_0_split <- layer_256_4_sum
I0528 19:00:47.848881 11123 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 19:00:47.848893 11123 net.cpp:380] layer_256_4_sum_layer_256_4_sum_0_split -> layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 19:00:47.848985 11123 net.cpp:122] Setting up layer_256_4_sum_layer_256_4_sum_0_split
I0528 19:00:47.848996 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.849004 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.849010 11123 net.cpp:137] Memory required for data: 2009047160
I0528 19:00:47.849017 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn1
I0528 19:00:47.849030 11123 net.cpp:84] Creating Layer layer_256_5_bn1
I0528 19:00:47.849047 11123 net.cpp:406] layer_256_5_bn1 <- layer_256_4_sum_layer_256_4_sum_0_split_0
I0528 19:00:47.849056 11123 net.cpp:380] layer_256_5_bn1 -> layer_256_5_bn1
I0528 19:00:47.849333 11123 net.cpp:122] Setting up layer_256_5_bn1
I0528 19:00:47.849344 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.849361 11123 net.cpp:137] Memory required for data: 2017075320
I0528 19:00:47.849377 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 19:00:47.849388 11123 net.cpp:84] Creating Layer layer_256_5_scale1
I0528 19:00:47.849396 11123 net.cpp:406] layer_256_5_scale1 <- layer_256_5_bn1
I0528 19:00:47.849409 11123 net.cpp:367] layer_256_5_scale1 -> layer_256_5_bn1 (in-place)
I0528 19:00:47.849480 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale1
I0528 19:00:47.849663 11123 net.cpp:122] Setting up layer_256_5_scale1
I0528 19:00:47.849674 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.849680 11123 net.cpp:137] Memory required for data: 2025103480
I0528 19:00:47.849702 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu1
I0528 19:00:47.849711 11123 net.cpp:84] Creating Layer layer_256_5_relu1
I0528 19:00:47.849720 11123 net.cpp:406] layer_256_5_relu1 <- layer_256_5_bn1
I0528 19:00:47.849728 11123 net.cpp:367] layer_256_5_relu1 -> layer_256_5_bn1 (in-place)
I0528 19:00:47.849915 11123 net.cpp:122] Setting up layer_256_5_relu1
I0528 19:00:47.849926 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.849932 11123 net.cpp:137] Memory required for data: 2033131640
I0528 19:00:47.849949 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv1
I0528 19:00:47.849966 11123 net.cpp:84] Creating Layer layer_256_5_conv1
I0528 19:00:47.849973 11123 net.cpp:406] layer_256_5_conv1 <- layer_256_5_bn1
I0528 19:00:47.849985 11123 net.cpp:380] layer_256_5_conv1 -> layer_256_5_conv1
I0528 19:00:47.853984 11123 net.cpp:122] Setting up layer_256_5_conv1
I0528 19:00:47.853999 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.854007 11123 net.cpp:137] Memory required for data: 2035138680
I0528 19:00:47.854015 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn2
I0528 19:00:47.854029 11123 net.cpp:84] Creating Layer layer_256_5_bn2
I0528 19:00:47.854038 11123 net.cpp:406] layer_256_5_bn2 <- layer_256_5_conv1
I0528 19:00:47.854048 11123 net.cpp:367] layer_256_5_bn2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.854297 11123 net.cpp:122] Setting up layer_256_5_bn2
I0528 19:00:47.854310 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.854315 11123 net.cpp:137] Memory required for data: 2037145720
I0528 19:00:47.854327 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 19:00:47.854338 11123 net.cpp:84] Creating Layer layer_256_5_scale2
I0528 19:00:47.854346 11123 net.cpp:406] layer_256_5_scale2 <- layer_256_5_conv1
I0528 19:00:47.854368 11123 net.cpp:367] layer_256_5_scale2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.854431 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale2
I0528 19:00:47.854586 11123 net.cpp:122] Setting up layer_256_5_scale2
I0528 19:00:47.854598 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.854604 11123 net.cpp:137] Memory required for data: 2039152760
I0528 19:00:47.854614 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu2
I0528 19:00:47.854625 11123 net.cpp:84] Creating Layer layer_256_5_relu2
I0528 19:00:47.854634 11123 net.cpp:406] layer_256_5_relu2 <- layer_256_5_conv1
I0528 19:00:47.854645 11123 net.cpp:367] layer_256_5_relu2 -> layer_256_5_conv1 (in-place)
I0528 19:00:47.854817 11123 net.cpp:122] Setting up layer_256_5_relu2
I0528 19:00:47.854830 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.854835 11123 net.cpp:137] Memory required for data: 2041159800
I0528 19:00:47.854841 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv2
I0528 19:00:47.854857 11123 net.cpp:84] Creating Layer layer_256_5_conv2
I0528 19:00:47.854864 11123 net.cpp:406] layer_256_5_conv2 <- layer_256_5_conv1
I0528 19:00:47.854876 11123 net.cpp:380] layer_256_5_conv2 -> layer_256_5_conv2
I0528 19:00:47.863343 11123 net.cpp:122] Setting up layer_256_5_conv2
I0528 19:00:47.863364 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.863371 11123 net.cpp:137] Memory required for data: 2043166840
I0528 19:00:47.863382 11123 layer_factory.hpp:77] Creating layer layer_256_5_bn3
I0528 19:00:47.863395 11123 net.cpp:84] Creating Layer layer_256_5_bn3
I0528 19:00:47.863415 11123 net.cpp:406] layer_256_5_bn3 <- layer_256_5_conv2
I0528 19:00:47.863427 11123 net.cpp:367] layer_256_5_bn3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.863709 11123 net.cpp:122] Setting up layer_256_5_bn3
I0528 19:00:47.863721 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.863728 11123 net.cpp:137] Memory required for data: 2045173880
I0528 19:00:47.863754 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0528 19:00:47.863767 11123 net.cpp:84] Creating Layer layer_256_5_scale3
I0528 19:00:47.863777 11123 net.cpp:406] layer_256_5_scale3 <- layer_256_5_conv2
I0528 19:00:47.863787 11123 net.cpp:367] layer_256_5_scale3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.863864 11123 layer_factory.hpp:77] Creating layer layer_256_5_scale3
I0528 19:00:47.864054 11123 net.cpp:122] Setting up layer_256_5_scale3
I0528 19:00:47.864066 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.864073 11123 net.cpp:137] Memory required for data: 2047180920
I0528 19:00:47.864084 11123 layer_factory.hpp:77] Creating layer layer_256_5_relu3
I0528 19:00:47.864096 11123 net.cpp:84] Creating Layer layer_256_5_relu3
I0528 19:00:47.864105 11123 net.cpp:406] layer_256_5_relu3 <- layer_256_5_conv2
I0528 19:00:47.864114 11123 net.cpp:367] layer_256_5_relu3 -> layer_256_5_conv2 (in-place)
I0528 19:00:47.864323 11123 net.cpp:122] Setting up layer_256_5_relu3
I0528 19:00:47.864336 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.864341 11123 net.cpp:137] Memory required for data: 2049187960
I0528 19:00:47.864359 11123 layer_factory.hpp:77] Creating layer layer_256_5_conv3
I0528 19:00:47.864377 11123 net.cpp:84] Creating Layer layer_256_5_conv3
I0528 19:00:47.864384 11123 net.cpp:406] layer_256_5_conv3 <- layer_256_5_conv2
I0528 19:00:47.864398 11123 net.cpp:380] layer_256_5_conv3 -> layer_256_5_conv3
I0528 19:00:47.869112 11123 net.cpp:122] Setting up layer_256_5_conv3
I0528 19:00:47.869128 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.869135 11123 net.cpp:137] Memory required for data: 2057216120
I0528 19:00:47.869155 11123 layer_factory.hpp:77] Creating layer layer_256_5_sum
I0528 19:00:47.869170 11123 net.cpp:84] Creating Layer layer_256_5_sum
I0528 19:00:47.869179 11123 net.cpp:406] layer_256_5_sum <- layer_256_5_conv3
I0528 19:00:47.869187 11123 net.cpp:406] layer_256_5_sum <- layer_256_4_sum_layer_256_4_sum_0_split_1
I0528 19:00:47.869210 11123 net.cpp:380] layer_256_5_sum -> layer_256_5_sum
I0528 19:00:47.869256 11123 net.cpp:122] Setting up layer_256_5_sum
I0528 19:00:47.869266 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.869283 11123 net.cpp:137] Memory required for data: 2065244280
I0528 19:00:47.869292 11123 layer_factory.hpp:77] Creating layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.869302 11123 net.cpp:84] Creating Layer layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.869310 11123 net.cpp:406] layer_256_5_sum_layer_256_5_sum_0_split <- layer_256_5_sum
I0528 19:00:47.869323 11123 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 19:00:47.869345 11123 net.cpp:380] layer_256_5_sum_layer_256_5_sum_0_split -> layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 19:00:47.869405 11123 net.cpp:122] Setting up layer_256_5_sum_layer_256_5_sum_0_split
I0528 19:00:47.869428 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.869436 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.869443 11123 net.cpp:137] Memory required for data: 2081300600
I0528 19:00:47.869449 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn1
I0528 19:00:47.869463 11123 net.cpp:84] Creating Layer layer_256_6_bn1
I0528 19:00:47.869482 11123 net.cpp:406] layer_256_6_bn1 <- layer_256_5_sum_layer_256_5_sum_0_split_0
I0528 19:00:47.869491 11123 net.cpp:380] layer_256_6_bn1 -> layer_256_6_bn1
I0528 19:00:47.869791 11123 net.cpp:122] Setting up layer_256_6_bn1
I0528 19:00:47.869803 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.869809 11123 net.cpp:137] Memory required for data: 2089328760
I0528 19:00:47.869823 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 19:00:47.869834 11123 net.cpp:84] Creating Layer layer_256_6_scale1
I0528 19:00:47.869843 11123 net.cpp:406] layer_256_6_scale1 <- layer_256_6_bn1
I0528 19:00:47.869854 11123 net.cpp:367] layer_256_6_scale1 -> layer_256_6_bn1 (in-place)
I0528 19:00:47.869930 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale1
I0528 19:00:47.870105 11123 net.cpp:122] Setting up layer_256_6_scale1
I0528 19:00:47.870116 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.870122 11123 net.cpp:137] Memory required for data: 2097356920
I0528 19:00:47.870133 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu1
I0528 19:00:47.870144 11123 net.cpp:84] Creating Layer layer_256_6_relu1
I0528 19:00:47.870152 11123 net.cpp:406] layer_256_6_relu1 <- layer_256_6_bn1
I0528 19:00:47.870162 11123 net.cpp:367] layer_256_6_relu1 -> layer_256_6_bn1 (in-place)
I0528 19:00:47.870342 11123 net.cpp:122] Setting up layer_256_6_relu1
I0528 19:00:47.870354 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.870360 11123 net.cpp:137] Memory required for data: 2105385080
I0528 19:00:47.870367 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv1
I0528 19:00:47.870381 11123 net.cpp:84] Creating Layer layer_256_6_conv1
I0528 19:00:47.870388 11123 net.cpp:406] layer_256_6_conv1 <- layer_256_6_bn1
I0528 19:00:47.870403 11123 net.cpp:380] layer_256_6_conv1 -> layer_256_6_conv1
I0528 19:00:47.874289 11123 net.cpp:122] Setting up layer_256_6_conv1
I0528 19:00:47.874305 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.874311 11123 net.cpp:137] Memory required for data: 2107392120
I0528 19:00:47.874330 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn2
I0528 19:00:47.874343 11123 net.cpp:84] Creating Layer layer_256_6_bn2
I0528 19:00:47.874352 11123 net.cpp:406] layer_256_6_bn2 <- layer_256_6_conv1
I0528 19:00:47.874364 11123 net.cpp:367] layer_256_6_bn2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.874626 11123 net.cpp:122] Setting up layer_256_6_bn2
I0528 19:00:47.874639 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.874655 11123 net.cpp:137] Memory required for data: 2109399160
I0528 19:00:47.874671 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 19:00:47.874681 11123 net.cpp:84] Creating Layer layer_256_6_scale2
I0528 19:00:47.874698 11123 net.cpp:406] layer_256_6_scale2 <- layer_256_6_conv1
I0528 19:00:47.874711 11123 net.cpp:367] layer_256_6_scale2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.874773 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale2
I0528 19:00:47.874967 11123 net.cpp:122] Setting up layer_256_6_scale2
I0528 19:00:47.874979 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.874984 11123 net.cpp:137] Memory required for data: 2111406200
I0528 19:00:47.875006 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu2
I0528 19:00:47.875016 11123 net.cpp:84] Creating Layer layer_256_6_relu2
I0528 19:00:47.875025 11123 net.cpp:406] layer_256_6_relu2 <- layer_256_6_conv1
I0528 19:00:47.875035 11123 net.cpp:367] layer_256_6_relu2 -> layer_256_6_conv1 (in-place)
I0528 19:00:47.875777 11123 net.cpp:122] Setting up layer_256_6_relu2
I0528 19:00:47.875790 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.875797 11123 net.cpp:137] Memory required for data: 2113413240
I0528 19:00:47.875803 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv2
I0528 19:00:47.875818 11123 net.cpp:84] Creating Layer layer_256_6_conv2
I0528 19:00:47.875826 11123 net.cpp:406] layer_256_6_conv2 <- layer_256_6_conv1
I0528 19:00:47.875840 11123 net.cpp:380] layer_256_6_conv2 -> layer_256_6_conv2
I0528 19:00:47.883816 11123 net.cpp:122] Setting up layer_256_6_conv2
I0528 19:00:47.883836 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.883841 11123 net.cpp:137] Memory required for data: 2115420280
I0528 19:00:47.883852 11123 layer_factory.hpp:77] Creating layer layer_256_6_bn3
I0528 19:00:47.883863 11123 net.cpp:84] Creating Layer layer_256_6_bn3
I0528 19:00:47.883872 11123 net.cpp:406] layer_256_6_bn3 <- layer_256_6_conv2
I0528 19:00:47.883884 11123 net.cpp:367] layer_256_6_bn3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.884187 11123 net.cpp:122] Setting up layer_256_6_bn3
I0528 19:00:47.884199 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.884205 11123 net.cpp:137] Memory required for data: 2117427320
I0528 19:00:47.884232 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0528 19:00:47.884244 11123 net.cpp:84] Creating Layer layer_256_6_scale3
I0528 19:00:47.884253 11123 net.cpp:406] layer_256_6_scale3 <- layer_256_6_conv2
I0528 19:00:47.884263 11123 net.cpp:367] layer_256_6_scale3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.884338 11123 layer_factory.hpp:77] Creating layer layer_256_6_scale3
I0528 19:00:47.884518 11123 net.cpp:122] Setting up layer_256_6_scale3
I0528 19:00:47.884531 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.884536 11123 net.cpp:137] Memory required for data: 2119434360
I0528 19:00:47.884557 11123 layer_factory.hpp:77] Creating layer layer_256_6_relu3
I0528 19:00:47.884570 11123 net.cpp:84] Creating Layer layer_256_6_relu3
I0528 19:00:47.884578 11123 net.cpp:406] layer_256_6_relu3 <- layer_256_6_conv2
I0528 19:00:47.884588 11123 net.cpp:367] layer_256_6_relu3 -> layer_256_6_conv2 (in-place)
I0528 19:00:47.885365 11123 net.cpp:122] Setting up layer_256_6_relu3
I0528 19:00:47.885380 11123 net.cpp:129] Top shape: 10 256 14 14 (501760)
I0528 19:00:47.885397 11123 net.cpp:137] Memory required for data: 2121441400
I0528 19:00:47.885406 11123 layer_factory.hpp:77] Creating layer layer_256_6_conv3
I0528 19:00:47.885423 11123 net.cpp:84] Creating Layer layer_256_6_conv3
I0528 19:00:47.885431 11123 net.cpp:406] layer_256_6_conv3 <- layer_256_6_conv2
I0528 19:00:47.885444 11123 net.cpp:380] layer_256_6_conv3 -> layer_256_6_conv3
I0528 19:00:47.890199 11123 net.cpp:122] Setting up layer_256_6_conv3
I0528 19:00:47.890215 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.890223 11123 net.cpp:137] Memory required for data: 2129469560
I0528 19:00:47.890231 11123 layer_factory.hpp:77] Creating layer layer_256_6_sum
I0528 19:00:47.890244 11123 net.cpp:84] Creating Layer layer_256_6_sum
I0528 19:00:47.890251 11123 net.cpp:406] layer_256_6_sum <- layer_256_6_conv3
I0528 19:00:47.890281 11123 net.cpp:406] layer_256_6_sum <- layer_256_5_sum_layer_256_5_sum_0_split_1
I0528 19:00:47.890296 11123 net.cpp:380] layer_256_6_sum -> layer_256_6_sum
I0528 19:00:47.890341 11123 net.cpp:122] Setting up layer_256_6_sum
I0528 19:00:47.890352 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.890368 11123 net.cpp:137] Memory required for data: 2137497720
I0528 19:00:47.890374 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 19:00:47.890388 11123 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 19:00:47.890396 11123 net.cpp:406] layer_512_1_bn1 <- layer_256_6_sum
I0528 19:00:47.890408 11123 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 19:00:47.890707 11123 net.cpp:122] Setting up layer_512_1_bn1
I0528 19:00:47.890718 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.890724 11123 net.cpp:137] Memory required for data: 2145525880
I0528 19:00:47.890748 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 19:00:47.890759 11123 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 19:00:47.890769 11123 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 19:00:47.890777 11123 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 19:00:47.890851 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 19:00:47.891026 11123 net.cpp:122] Setting up layer_512_1_scale1
I0528 19:00:47.891038 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.891044 11123 net.cpp:137] Memory required for data: 2153554040
I0528 19:00:47.891055 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 19:00:47.891068 11123 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 19:00:47.891077 11123 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 19:00:47.891086 11123 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 19:00:47.891268 11123 net.cpp:122] Setting up layer_512_1_relu1
I0528 19:00:47.891279 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.891286 11123 net.cpp:137] Memory required for data: 2161582200
I0528 19:00:47.891293 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.891301 11123 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.891310 11123 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 19:00:47.891324 11123 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 19:00:47.891336 11123 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 19:00:47.891403 11123 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 19:00:47.891414 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.891422 11123 net.cpp:129] Top shape: 10 1024 14 14 (2007040)
I0528 19:00:47.891430 11123 net.cpp:137] Memory required for data: 2177638520
I0528 19:00:47.891436 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 19:00:47.891451 11123 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 19:00:47.891458 11123 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 19:00:47.891471 11123 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 19:00:47.898815 11123 net.cpp:122] Setting up layer_512_1_conv1
I0528 19:00:47.898834 11123 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0528 19:00:47.898841 11123 net.cpp:137] Memory required for data: 2181652600
I0528 19:00:47.898851 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 19:00:47.898865 11123 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 19:00:47.898874 11123 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 19:00:47.898885 11123 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.899154 11123 net.cpp:122] Setting up layer_512_1_bn2
I0528 19:00:47.899166 11123 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0528 19:00:47.899173 11123 net.cpp:137] Memory required for data: 2185666680
I0528 19:00:47.899199 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 19:00:47.899210 11123 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 19:00:47.899219 11123 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 19:00:47.899231 11123 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.899292 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 19:00:47.899459 11123 net.cpp:122] Setting up layer_512_1_scale2
I0528 19:00:47.899471 11123 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0528 19:00:47.899477 11123 net.cpp:137] Memory required for data: 2189680760
I0528 19:00:47.899488 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 19:00:47.899499 11123 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 19:00:47.899507 11123 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 19:00:47.899519 11123 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 19:00:47.899701 11123 net.cpp:122] Setting up layer_512_1_relu2
I0528 19:00:47.899713 11123 net.cpp:129] Top shape: 10 512 14 14 (1003520)
I0528 19:00:47.899719 11123 net.cpp:137] Memory required for data: 2193694840
I0528 19:00:47.899725 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 19:00:47.899741 11123 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 19:00:47.899749 11123 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 19:00:47.899760 11123 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 19:00:47.927194 11123 net.cpp:122] Setting up layer_512_1_conv2
I0528 19:00:47.927227 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.927232 11123 net.cpp:137] Memory required for data: 2194698360
I0528 19:00:47.927245 11123 layer_factory.hpp:77] Creating layer layer_512_1_bn3
I0528 19:00:47.927259 11123 net.cpp:84] Creating Layer layer_512_1_bn3
I0528 19:00:47.927269 11123 net.cpp:406] layer_512_1_bn3 <- layer_512_1_conv2
I0528 19:00:47.927284 11123 net.cpp:367] layer_512_1_bn3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.927563 11123 net.cpp:122] Setting up layer_512_1_bn3
I0528 19:00:47.927575 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.927582 11123 net.cpp:137] Memory required for data: 2195701880
I0528 19:00:47.927619 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0528 19:00:47.927633 11123 net.cpp:84] Creating Layer layer_512_1_scale3
I0528 19:00:47.927640 11123 net.cpp:406] layer_512_1_scale3 <- layer_512_1_conv2
I0528 19:00:47.927650 11123 net.cpp:367] layer_512_1_scale3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.927717 11123 layer_factory.hpp:77] Creating layer layer_512_1_scale3
I0528 19:00:47.927882 11123 net.cpp:122] Setting up layer_512_1_scale3
I0528 19:00:47.927893 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.927899 11123 net.cpp:137] Memory required for data: 2196705400
I0528 19:00:47.927911 11123 layer_factory.hpp:77] Creating layer layer_512_1_relu3
I0528 19:00:47.927922 11123 net.cpp:84] Creating Layer layer_512_1_relu3
I0528 19:00:47.927929 11123 net.cpp:406] layer_512_1_relu3 <- layer_512_1_conv2
I0528 19:00:47.927939 11123 net.cpp:367] layer_512_1_relu3 -> layer_512_1_conv2 (in-place)
I0528 19:00:47.928119 11123 net.cpp:122] Setting up layer_512_1_relu3
I0528 19:00:47.928131 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.928138 11123 net.cpp:137] Memory required for data: 2197708920
I0528 19:00:47.928144 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv3
I0528 19:00:47.928160 11123 net.cpp:84] Creating Layer layer_512_1_conv3
I0528 19:00:47.928167 11123 net.cpp:406] layer_512_1_conv3 <- layer_512_1_conv2
I0528 19:00:47.928179 11123 net.cpp:380] layer_512_1_conv3 -> layer_512_1_conv3
I0528 19:00:47.941507 11123 net.cpp:122] Setting up layer_512_1_conv3
I0528 19:00:47.941534 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.941540 11123 net.cpp:137] Memory required for data: 2201723000
I0528 19:00:47.941553 11123 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 19:00:47.941591 11123 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 19:00:47.941601 11123 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 19:00:47.941615 11123 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 19:00:47.966297 11123 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 19:00:47.966327 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.966333 11123 net.cpp:137] Memory required for data: 2205737080
I0528 19:00:47.966346 11123 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 19:00:47.966361 11123 net.cpp:84] Creating Layer layer_512_1_sum
I0528 19:00:47.966370 11123 net.cpp:406] layer_512_1_sum <- layer_512_1_conv3
I0528 19:00:47.966382 11123 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 19:00:47.966392 11123 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 19:00:47.966440 11123 net.cpp:122] Setting up layer_512_1_sum
I0528 19:00:47.966451 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.966457 11123 net.cpp:137] Memory required for data: 2209751160
I0528 19:00:47.966465 11123 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.966476 11123 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.966483 11123 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 19:00:47.966495 11123 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 19:00:47.966508 11123 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 19:00:47.966569 11123 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 19:00:47.966580 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.966588 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.966595 11123 net.cpp:137] Memory required for data: 2217779320
I0528 19:00:47.966601 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 19:00:47.966614 11123 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 19:00:47.966621 11123 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 19:00:47.966631 11123 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 19:00:47.966933 11123 net.cpp:122] Setting up layer_512_2_bn1
I0528 19:00:47.966945 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.966950 11123 net.cpp:137] Memory required for data: 2221793400
I0528 19:00:47.966965 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 19:00:47.966990 11123 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 19:00:47.966998 11123 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 19:00:47.967007 11123 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 19:00:47.967089 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 19:00:47.967259 11123 net.cpp:122] Setting up layer_512_2_scale1
I0528 19:00:47.967272 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.967278 11123 net.cpp:137] Memory required for data: 2225807480
I0528 19:00:47.967288 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 19:00:47.967300 11123 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 19:00:47.967309 11123 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 19:00:47.967320 11123 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 19:00:47.967522 11123 net.cpp:122] Setting up layer_512_2_relu1
I0528 19:00:47.967545 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:47.967551 11123 net.cpp:137] Memory required for data: 2229821560
I0528 19:00:47.967558 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 19:00:47.967576 11123 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 19:00:47.967584 11123 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 19:00:47.967595 11123 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 19:00:47.980680 11123 net.cpp:122] Setting up layer_512_2_conv1
I0528 19:00:47.980717 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.980723 11123 net.cpp:137] Memory required for data: 2230825080
I0528 19:00:47.980746 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 19:00:47.980762 11123 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 19:00:47.980772 11123 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 19:00:47.980787 11123 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.981097 11123 net.cpp:122] Setting up layer_512_2_bn2
I0528 19:00:47.981109 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.981115 11123 net.cpp:137] Memory required for data: 2231828600
I0528 19:00:47.981129 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 19:00:47.981151 11123 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 19:00:47.981160 11123 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 19:00:47.981174 11123 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.981250 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 19:00:47.981432 11123 net.cpp:122] Setting up layer_512_2_scale2
I0528 19:00:47.981444 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.981451 11123 net.cpp:137] Memory required for data: 2232832120
I0528 19:00:47.981462 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 19:00:47.981473 11123 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 19:00:47.981482 11123 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 19:00:47.981492 11123 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 19:00:47.981678 11123 net.cpp:122] Setting up layer_512_2_relu2
I0528 19:00:47.981689 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:47.981695 11123 net.cpp:137] Memory required for data: 2233835640
I0528 19:00:47.981703 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 19:00:47.981719 11123 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 19:00:47.981726 11123 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 19:00:47.981740 11123 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 19:00:48.009387 11123 net.cpp:122] Setting up layer_512_2_conv2
I0528 19:00:48.009420 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.009426 11123 net.cpp:137] Memory required for data: 2234839160
I0528 19:00:48.009449 11123 layer_factory.hpp:77] Creating layer layer_512_2_bn3
I0528 19:00:48.009467 11123 net.cpp:84] Creating Layer layer_512_2_bn3
I0528 19:00:48.009479 11123 net.cpp:406] layer_512_2_bn3 <- layer_512_2_conv2
I0528 19:00:48.009493 11123 net.cpp:367] layer_512_2_bn3 -> layer_512_2_conv2 (in-place)
I0528 19:00:48.009795 11123 net.cpp:122] Setting up layer_512_2_bn3
I0528 19:00:48.009807 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.009814 11123 net.cpp:137] Memory required for data: 2235842680
I0528 19:00:48.009837 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0528 19:00:48.009850 11123 net.cpp:84] Creating Layer layer_512_2_scale3
I0528 19:00:48.009858 11123 net.cpp:406] layer_512_2_scale3 <- layer_512_2_conv2
I0528 19:00:48.009868 11123 net.cpp:367] layer_512_2_scale3 -> layer_512_2_conv2 (in-place)
I0528 19:00:48.009948 11123 layer_factory.hpp:77] Creating layer layer_512_2_scale3
I0528 19:00:48.010140 11123 net.cpp:122] Setting up layer_512_2_scale3
I0528 19:00:48.010152 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.010169 11123 net.cpp:137] Memory required for data: 2236846200
I0528 19:00:48.010180 11123 layer_factory.hpp:77] Creating layer layer_512_2_relu3
I0528 19:00:48.010195 11123 net.cpp:84] Creating Layer layer_512_2_relu3
I0528 19:00:48.010202 11123 net.cpp:406] layer_512_2_relu3 <- layer_512_2_conv2
I0528 19:00:48.010212 11123 net.cpp:367] layer_512_2_relu3 -> layer_512_2_conv2 (in-place)
I0528 19:00:48.010988 11123 net.cpp:122] Setting up layer_512_2_relu3
I0528 19:00:48.011005 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.011025 11123 net.cpp:137] Memory required for data: 2237849720
I0528 19:00:48.011045 11123 layer_factory.hpp:77] Creating layer layer_512_2_conv3
I0528 19:00:48.011062 11123 net.cpp:84] Creating Layer layer_512_2_conv3
I0528 19:00:48.011070 11123 net.cpp:406] layer_512_2_conv3 <- layer_512_2_conv2
I0528 19:00:48.011082 11123 net.cpp:380] layer_512_2_conv3 -> layer_512_2_conv3
I0528 19:00:48.024267 11123 net.cpp:122] Setting up layer_512_2_conv3
I0528 19:00:48.024293 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.024300 11123 net.cpp:137] Memory required for data: 2241863800
I0528 19:00:48.024310 11123 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 19:00:48.024323 11123 net.cpp:84] Creating Layer layer_512_2_sum
I0528 19:00:48.024333 11123 net.cpp:406] layer_512_2_sum <- layer_512_2_conv3
I0528 19:00:48.024343 11123 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 19:00:48.024356 11123 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 19:00:48.024402 11123 net.cpp:122] Setting up layer_512_2_sum
I0528 19:00:48.024416 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.024425 11123 net.cpp:137] Memory required for data: 2245877880
I0528 19:00:48.024432 11123 layer_factory.hpp:77] Creating layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:48.024443 11123 net.cpp:84] Creating Layer layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:48.024451 11123 net.cpp:406] layer_512_2_sum_layer_512_2_sum_0_split <- layer_512_2_sum
I0528 19:00:48.024461 11123 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 19:00:48.024477 11123 net.cpp:380] layer_512_2_sum_layer_512_2_sum_0_split -> layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 19:00:48.024540 11123 net.cpp:122] Setting up layer_512_2_sum_layer_512_2_sum_0_split
I0528 19:00:48.024552 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.024560 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.024567 11123 net.cpp:137] Memory required for data: 2253906040
I0528 19:00:48.024574 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn1
I0528 19:00:48.024586 11123 net.cpp:84] Creating Layer layer_512_3_bn1
I0528 19:00:48.024595 11123 net.cpp:406] layer_512_3_bn1 <- layer_512_2_sum_layer_512_2_sum_0_split_0
I0528 19:00:48.024606 11123 net.cpp:380] layer_512_3_bn1 -> layer_512_3_bn1
I0528 19:00:48.024910 11123 net.cpp:122] Setting up layer_512_3_bn1
I0528 19:00:48.024922 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.024935 11123 net.cpp:137] Memory required for data: 2257920120
I0528 19:00:48.024948 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 19:00:48.024960 11123 net.cpp:84] Creating Layer layer_512_3_scale1
I0528 19:00:48.024967 11123 net.cpp:406] layer_512_3_scale1 <- layer_512_3_bn1
I0528 19:00:48.024977 11123 net.cpp:367] layer_512_3_scale1 -> layer_512_3_bn1 (in-place)
I0528 19:00:48.025046 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale1
I0528 19:00:48.025223 11123 net.cpp:122] Setting up layer_512_3_scale1
I0528 19:00:48.025235 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.025241 11123 net.cpp:137] Memory required for data: 2261934200
I0528 19:00:48.025254 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu1
I0528 19:00:48.025265 11123 net.cpp:84] Creating Layer layer_512_3_relu1
I0528 19:00:48.025274 11123 net.cpp:406] layer_512_3_relu1 <- layer_512_3_bn1
I0528 19:00:48.025283 11123 net.cpp:367] layer_512_3_relu1 -> layer_512_3_bn1 (in-place)
I0528 19:00:48.025470 11123 net.cpp:122] Setting up layer_512_3_relu1
I0528 19:00:48.025481 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.025487 11123 net.cpp:137] Memory required for data: 2265948280
I0528 19:00:48.025493 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv1
I0528 19:00:48.025509 11123 net.cpp:84] Creating Layer layer_512_3_conv1
I0528 19:00:48.025516 11123 net.cpp:406] layer_512_3_conv1 <- layer_512_3_bn1
I0528 19:00:48.025529 11123 net.cpp:380] layer_512_3_conv1 -> layer_512_3_conv1
I0528 19:00:48.038760 11123 net.cpp:122] Setting up layer_512_3_conv1
I0528 19:00:48.038787 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.038794 11123 net.cpp:137] Memory required for data: 2266951800
I0528 19:00:48.038806 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn2
I0528 19:00:48.038821 11123 net.cpp:84] Creating Layer layer_512_3_bn2
I0528 19:00:48.038831 11123 net.cpp:406] layer_512_3_bn2 <- layer_512_3_conv1
I0528 19:00:48.038846 11123 net.cpp:367] layer_512_3_bn2 -> layer_512_3_conv1 (in-place)
I0528 19:00:48.039140 11123 net.cpp:122] Setting up layer_512_3_bn2
I0528 19:00:48.039152 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.039158 11123 net.cpp:137] Memory required for data: 2267955320
I0528 19:00:48.039175 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 19:00:48.039188 11123 net.cpp:84] Creating Layer layer_512_3_scale2
I0528 19:00:48.039197 11123 net.cpp:406] layer_512_3_scale2 <- layer_512_3_conv1
I0528 19:00:48.039207 11123 net.cpp:367] layer_512_3_scale2 -> layer_512_3_conv1 (in-place)
I0528 19:00:48.039278 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale2
I0528 19:00:48.039455 11123 net.cpp:122] Setting up layer_512_3_scale2
I0528 19:00:48.039468 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.039474 11123 net.cpp:137] Memory required for data: 2268958840
I0528 19:00:48.039484 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu2
I0528 19:00:48.039496 11123 net.cpp:84] Creating Layer layer_512_3_relu2
I0528 19:00:48.039505 11123 net.cpp:406] layer_512_3_relu2 <- layer_512_3_conv1
I0528 19:00:48.039516 11123 net.cpp:367] layer_512_3_relu2 -> layer_512_3_conv1 (in-place)
I0528 19:00:48.040266 11123 net.cpp:122] Setting up layer_512_3_relu2
I0528 19:00:48.040279 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.040285 11123 net.cpp:137] Memory required for data: 2269962360
I0528 19:00:48.040292 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv2
I0528 19:00:48.040309 11123 net.cpp:84] Creating Layer layer_512_3_conv2
I0528 19:00:48.040316 11123 net.cpp:406] layer_512_3_conv2 <- layer_512_3_conv1
I0528 19:00:48.040330 11123 net.cpp:380] layer_512_3_conv2 -> layer_512_3_conv2
I0528 19:00:48.068109 11123 net.cpp:122] Setting up layer_512_3_conv2
I0528 19:00:48.068138 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.068145 11123 net.cpp:137] Memory required for data: 2270965880
I0528 19:00:48.068158 11123 layer_factory.hpp:77] Creating layer layer_512_3_bn3
I0528 19:00:48.068176 11123 net.cpp:84] Creating Layer layer_512_3_bn3
I0528 19:00:48.068186 11123 net.cpp:406] layer_512_3_bn3 <- layer_512_3_conv2
I0528 19:00:48.068199 11123 net.cpp:367] layer_512_3_bn3 -> layer_512_3_conv2 (in-place)
I0528 19:00:48.068511 11123 net.cpp:122] Setting up layer_512_3_bn3
I0528 19:00:48.068522 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.068528 11123 net.cpp:137] Memory required for data: 2271969400
I0528 19:00:48.068557 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0528 19:00:48.068567 11123 net.cpp:84] Creating Layer layer_512_3_scale3
I0528 19:00:48.068577 11123 net.cpp:406] layer_512_3_scale3 <- layer_512_3_conv2
I0528 19:00:48.068585 11123 net.cpp:367] layer_512_3_scale3 -> layer_512_3_conv2 (in-place)
I0528 19:00:48.068657 11123 layer_factory.hpp:77] Creating layer layer_512_3_scale3
I0528 19:00:48.068867 11123 net.cpp:122] Setting up layer_512_3_scale3
I0528 19:00:48.068879 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.068897 11123 net.cpp:137] Memory required for data: 2272972920
I0528 19:00:48.068907 11123 layer_factory.hpp:77] Creating layer layer_512_3_relu3
I0528 19:00:48.068922 11123 net.cpp:84] Creating Layer layer_512_3_relu3
I0528 19:00:48.068935 11123 net.cpp:406] layer_512_3_relu3 <- layer_512_3_conv2
I0528 19:00:48.068944 11123 net.cpp:367] layer_512_3_relu3 -> layer_512_3_conv2 (in-place)
I0528 19:00:48.069131 11123 net.cpp:122] Setting up layer_512_3_relu3
I0528 19:00:48.069144 11123 net.cpp:129] Top shape: 10 512 7 7 (250880)
I0528 19:00:48.069161 11123 net.cpp:137] Memory required for data: 2273976440
I0528 19:00:48.069169 11123 layer_factory.hpp:77] Creating layer layer_512_3_conv3
I0528 19:00:48.069186 11123 net.cpp:84] Creating Layer layer_512_3_conv3
I0528 19:00:48.069193 11123 net.cpp:406] layer_512_3_conv3 <- layer_512_3_conv2
I0528 19:00:48.069208 11123 net.cpp:380] layer_512_3_conv3 -> layer_512_3_conv3
I0528 19:00:48.082309 11123 net.cpp:122] Setting up layer_512_3_conv3
I0528 19:00:48.082329 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.082335 11123 net.cpp:137] Memory required for data: 2277990520
I0528 19:00:48.082355 11123 layer_factory.hpp:77] Creating layer layer_512_3_sum
I0528 19:00:48.082366 11123 net.cpp:84] Creating Layer layer_512_3_sum
I0528 19:00:48.082376 11123 net.cpp:406] layer_512_3_sum <- layer_512_3_conv3
I0528 19:00:48.082386 11123 net.cpp:406] layer_512_3_sum <- layer_512_2_sum_layer_512_2_sum_0_split_1
I0528 19:00:48.082399 11123 net.cpp:380] layer_512_3_sum -> layer_512_3_sum
I0528 19:00:48.082445 11123 net.cpp:122] Setting up layer_512_3_sum
I0528 19:00:48.082456 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.082463 11123 net.cpp:137] Memory required for data: 2282004600
I0528 19:00:48.082468 11123 layer_factory.hpp:77] Creating layer last_bn
I0528 19:00:48.082482 11123 net.cpp:84] Creating Layer last_bn
I0528 19:00:48.082490 11123 net.cpp:406] last_bn <- layer_512_3_sum
I0528 19:00:48.082502 11123 net.cpp:367] last_bn -> layer_512_3_sum (in-place)
I0528 19:00:48.082795 11123 net.cpp:122] Setting up last_bn
I0528 19:00:48.082808 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.082813 11123 net.cpp:137] Memory required for data: 2286018680
I0528 19:00:48.082826 11123 layer_factory.hpp:77] Creating layer last_scale
I0528 19:00:48.082839 11123 net.cpp:84] Creating Layer last_scale
I0528 19:00:48.082847 11123 net.cpp:406] last_scale <- layer_512_3_sum
I0528 19:00:48.082857 11123 net.cpp:367] last_scale -> layer_512_3_sum (in-place)
I0528 19:00:48.082926 11123 layer_factory.hpp:77] Creating layer last_scale
I0528 19:00:48.083104 11123 net.cpp:122] Setting up last_scale
I0528 19:00:48.083115 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.083122 11123 net.cpp:137] Memory required for data: 2290032760
I0528 19:00:48.083133 11123 layer_factory.hpp:77] Creating layer last_relu
I0528 19:00:48.083143 11123 net.cpp:84] Creating Layer last_relu
I0528 19:00:48.083151 11123 net.cpp:406] last_relu <- layer_512_3_sum
I0528 19:00:48.083163 11123 net.cpp:367] last_relu -> layer_512_3_sum (in-place)
I0528 19:00:48.083348 11123 net.cpp:122] Setting up last_relu
I0528 19:00:48.083359 11123 net.cpp:129] Top shape: 10 2048 7 7 (1003520)
I0528 19:00:48.083365 11123 net.cpp:137] Memory required for data: 2294046840
I0528 19:00:48.083371 11123 layer_factory.hpp:77] Creating layer global_pool
I0528 19:00:48.083384 11123 net.cpp:84] Creating Layer global_pool
I0528 19:00:48.083391 11123 net.cpp:406] global_pool <- layer_512_3_sum
I0528 19:00:48.083403 11123 net.cpp:380] global_pool -> global_pool
I0528 19:00:48.084197 11123 net.cpp:122] Setting up global_pool
I0528 19:00:48.084211 11123 net.cpp:129] Top shape: 10 2048 1 1 (20480)
I0528 19:00:48.084218 11123 net.cpp:137] Memory required for data: 2294128760
I0528 19:00:48.084224 11123 layer_factory.hpp:77] Creating layer score
I0528 19:00:48.084237 11123 net.cpp:84] Creating Layer score
I0528 19:00:48.084245 11123 net.cpp:406] score <- global_pool
I0528 19:00:48.084256 11123 net.cpp:380] score -> score
I0528 19:00:48.084424 11123 net.cpp:122] Setting up score
I0528 19:00:48.084434 11123 net.cpp:129] Top shape: 10 2 (20)
I0528 19:00:48.084440 11123 net.cpp:137] Memory required for data: 2294128840
I0528 19:00:48.084451 11123 layer_factory.hpp:77] Creating layer score_score_0_split
I0528 19:00:48.084462 11123 net.cpp:84] Creating Layer score_score_0_split
I0528 19:00:48.084471 11123 net.cpp:406] score_score_0_split <- score
I0528 19:00:48.084482 11123 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0528 19:00:48.084507 11123 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0528 19:00:48.084575 11123 net.cpp:122] Setting up score_score_0_split
I0528 19:00:48.084586 11123 net.cpp:129] Top shape: 10 2 (20)
I0528 19:00:48.084594 11123 net.cpp:129] Top shape: 10 2 (20)
I0528 19:00:48.084599 11123 net.cpp:137] Memory required for data: 2294129000
I0528 19:00:48.084607 11123 layer_factory.hpp:77] Creating layer loss
I0528 19:00:48.084619 11123 net.cpp:84] Creating Layer loss
I0528 19:00:48.084625 11123 net.cpp:406] loss <- score_score_0_split_0
I0528 19:00:48.084633 11123 net.cpp:406] loss <- label_data_1_split_0
I0528 19:00:48.084647 11123 net.cpp:380] loss -> loss
I0528 19:00:48.084661 11123 layer_factory.hpp:77] Creating layer loss
I0528 19:00:48.084980 11123 net.cpp:122] Setting up loss
I0528 19:00:48.084995 11123 net.cpp:129] Top shape: (1)
I0528 19:00:48.085000 11123 net.cpp:132]     with loss weight 1
I0528 19:00:48.085016 11123 net.cpp:137] Memory required for data: 2294129004
I0528 19:00:48.085023 11123 layer_factory.hpp:77] Creating layer accuracy
I0528 19:00:48.085036 11123 net.cpp:84] Creating Layer accuracy
I0528 19:00:48.085043 11123 net.cpp:406] accuracy <- score_score_0_split_1
I0528 19:00:48.085052 11123 net.cpp:406] accuracy <- label_data_1_split_1
I0528 19:00:48.085063 11123 net.cpp:380] accuracy -> accuracy
I0528 19:00:48.085079 11123 net.cpp:122] Setting up accuracy
I0528 19:00:48.085088 11123 net.cpp:129] Top shape: (1)
I0528 19:00:48.085093 11123 net.cpp:137] Memory required for data: 2294129008
I0528 19:00:48.085101 11123 net.cpp:200] accuracy does not need backward computation.
I0528 19:00:48.085109 11123 net.cpp:198] loss needs backward computation.
I0528 19:00:48.085119 11123 net.cpp:198] score_score_0_split needs backward computation.
I0528 19:00:48.085125 11123 net.cpp:198] score needs backward computation.
I0528 19:00:48.085132 11123 net.cpp:198] global_pool needs backward computation.
I0528 19:00:48.085139 11123 net.cpp:198] last_relu needs backward computation.
I0528 19:00:48.085145 11123 net.cpp:198] last_scale needs backward computation.
I0528 19:00:48.085152 11123 net.cpp:198] last_bn needs backward computation.
I0528 19:00:48.085158 11123 net.cpp:198] layer_512_3_sum needs backward computation.
I0528 19:00:48.085165 11123 net.cpp:198] layer_512_3_conv3 needs backward computation.
I0528 19:00:48.085175 11123 net.cpp:198] layer_512_3_relu3 needs backward computation.
I0528 19:00:48.085183 11123 net.cpp:198] layer_512_3_scale3 needs backward computation.
I0528 19:00:48.085189 11123 net.cpp:198] layer_512_3_bn3 needs backward computation.
I0528 19:00:48.085196 11123 net.cpp:198] layer_512_3_conv2 needs backward computation.
I0528 19:00:48.085203 11123 net.cpp:198] layer_512_3_relu2 needs backward computation.
I0528 19:00:48.085211 11123 net.cpp:198] layer_512_3_scale2 needs backward computation.
I0528 19:00:48.085217 11123 net.cpp:198] layer_512_3_bn2 needs backward computation.
I0528 19:00:48.085224 11123 net.cpp:198] layer_512_3_conv1 needs backward computation.
I0528 19:00:48.085232 11123 net.cpp:198] layer_512_3_relu1 needs backward computation.
I0528 19:00:48.085239 11123 net.cpp:198] layer_512_3_scale1 needs backward computation.
I0528 19:00:48.085245 11123 net.cpp:198] layer_512_3_bn1 needs backward computation.
I0528 19:00:48.085253 11123 net.cpp:198] layer_512_2_sum_layer_512_2_sum_0_split needs backward computation.
I0528 19:00:48.085261 11123 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 19:00:48.085269 11123 net.cpp:198] layer_512_2_conv3 needs backward computation.
I0528 19:00:48.085278 11123 net.cpp:198] layer_512_2_relu3 needs backward computation.
I0528 19:00:48.085284 11123 net.cpp:198] layer_512_2_scale3 needs backward computation.
I0528 19:00:48.085291 11123 net.cpp:198] layer_512_2_bn3 needs backward computation.
I0528 19:00:48.085297 11123 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 19:00:48.085305 11123 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 19:00:48.085312 11123 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 19:00:48.085328 11123 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 19:00:48.085335 11123 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 19:00:48.085343 11123 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 19:00:48.085351 11123 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 19:00:48.085357 11123 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 19:00:48.085366 11123 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 19:00:48.085374 11123 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 19:00:48.085382 11123 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 19:00:48.085391 11123 net.cpp:198] layer_512_1_conv3 needs backward computation.
I0528 19:00:48.085397 11123 net.cpp:198] layer_512_1_relu3 needs backward computation.
I0528 19:00:48.085407 11123 net.cpp:198] layer_512_1_scale3 needs backward computation.
I0528 19:00:48.085413 11123 net.cpp:198] layer_512_1_bn3 needs backward computation.
I0528 19:00:48.085420 11123 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 19:00:48.085427 11123 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 19:00:48.085435 11123 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 19:00:48.085441 11123 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 19:00:48.085448 11123 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 19:00:48.085455 11123 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 19:00:48.085464 11123 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 19:00:48.085470 11123 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 19:00:48.085479 11123 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 19:00:48.085484 11123 net.cpp:198] layer_256_6_sum needs backward computation.
I0528 19:00:48.085494 11123 net.cpp:198] layer_256_6_conv3 needs backward computation.
I0528 19:00:48.085501 11123 net.cpp:198] layer_256_6_relu3 needs backward computation.
I0528 19:00:48.085508 11123 net.cpp:198] layer_256_6_scale3 needs backward computation.
I0528 19:00:48.085515 11123 net.cpp:198] layer_256_6_bn3 needs backward computation.
I0528 19:00:48.085521 11123 net.cpp:198] layer_256_6_conv2 needs backward computation.
I0528 19:00:48.085530 11123 net.cpp:198] layer_256_6_relu2 needs backward computation.
I0528 19:00:48.085537 11123 net.cpp:198] layer_256_6_scale2 needs backward computation.
I0528 19:00:48.085543 11123 net.cpp:198] layer_256_6_bn2 needs backward computation.
I0528 19:00:48.085551 11123 net.cpp:198] layer_256_6_conv1 needs backward computation.
I0528 19:00:48.085557 11123 net.cpp:198] layer_256_6_relu1 needs backward computation.
I0528 19:00:48.085564 11123 net.cpp:198] layer_256_6_scale1 needs backward computation.
I0528 19:00:48.085572 11123 net.cpp:198] layer_256_6_bn1 needs backward computation.
I0528 19:00:48.085578 11123 net.cpp:198] layer_256_5_sum_layer_256_5_sum_0_split needs backward computation.
I0528 19:00:48.085587 11123 net.cpp:198] layer_256_5_sum needs backward computation.
I0528 19:00:48.085597 11123 net.cpp:198] layer_256_5_conv3 needs backward computation.
I0528 19:00:48.085604 11123 net.cpp:198] layer_256_5_relu3 needs backward computation.
I0528 19:00:48.085613 11123 net.cpp:198] layer_256_5_scale3 needs backward computation.
I0528 19:00:48.085619 11123 net.cpp:198] layer_256_5_bn3 needs backward computation.
I0528 19:00:48.085626 11123 net.cpp:198] layer_256_5_conv2 needs backward computation.
I0528 19:00:48.085633 11123 net.cpp:198] layer_256_5_relu2 needs backward computation.
I0528 19:00:48.085640 11123 net.cpp:198] layer_256_5_scale2 needs backward computation.
I0528 19:00:48.085646 11123 net.cpp:198] layer_256_5_bn2 needs backward computation.
I0528 19:00:48.085654 11123 net.cpp:198] layer_256_5_conv1 needs backward computation.
I0528 19:00:48.085660 11123 net.cpp:198] layer_256_5_relu1 needs backward computation.
I0528 19:00:48.085675 11123 net.cpp:198] layer_256_5_scale1 needs backward computation.
I0528 19:00:48.085683 11123 net.cpp:198] layer_256_5_bn1 needs backward computation.
I0528 19:00:48.085691 11123 net.cpp:198] layer_256_4_sum_layer_256_4_sum_0_split needs backward computation.
I0528 19:00:48.085698 11123 net.cpp:198] layer_256_4_sum needs backward computation.
I0528 19:00:48.085706 11123 net.cpp:198] layer_256_4_conv3 needs backward computation.
I0528 19:00:48.085717 11123 net.cpp:198] layer_256_4_relu3 needs backward computation.
I0528 19:00:48.085726 11123 net.cpp:198] layer_256_4_scale3 needs backward computation.
I0528 19:00:48.085731 11123 net.cpp:198] layer_256_4_bn3 needs backward computation.
I0528 19:00:48.085738 11123 net.cpp:198] layer_256_4_conv2 needs backward computation.
I0528 19:00:48.085746 11123 net.cpp:198] layer_256_4_relu2 needs backward computation.
I0528 19:00:48.085752 11123 net.cpp:198] layer_256_4_scale2 needs backward computation.
I0528 19:00:48.085759 11123 net.cpp:198] layer_256_4_bn2 needs backward computation.
I0528 19:00:48.085767 11123 net.cpp:198] layer_256_4_conv1 needs backward computation.
I0528 19:00:48.085773 11123 net.cpp:198] layer_256_4_relu1 needs backward computation.
I0528 19:00:48.085780 11123 net.cpp:198] layer_256_4_scale1 needs backward computation.
I0528 19:00:48.085788 11123 net.cpp:198] layer_256_4_bn1 needs backward computation.
I0528 19:00:48.085794 11123 net.cpp:198] layer_256_3_sum_layer_256_3_sum_0_split needs backward computation.
I0528 19:00:48.085803 11123 net.cpp:198] layer_256_3_sum needs backward computation.
I0528 19:00:48.085811 11123 net.cpp:198] layer_256_3_conv3 needs backward computation.
I0528 19:00:48.085819 11123 net.cpp:198] layer_256_3_relu3 needs backward computation.
I0528 19:00:48.085826 11123 net.cpp:198] layer_256_3_scale3 needs backward computation.
I0528 19:00:48.085834 11123 net.cpp:198] layer_256_3_bn3 needs backward computation.
I0528 19:00:48.085840 11123 net.cpp:198] layer_256_3_conv2 needs backward computation.
I0528 19:00:48.085846 11123 net.cpp:198] layer_256_3_relu2 needs backward computation.
I0528 19:00:48.085855 11123 net.cpp:198] layer_256_3_scale2 needs backward computation.
I0528 19:00:48.085860 11123 net.cpp:198] layer_256_3_bn2 needs backward computation.
I0528 19:00:48.085868 11123 net.cpp:198] layer_256_3_conv1 needs backward computation.
I0528 19:00:48.085876 11123 net.cpp:198] layer_256_3_relu1 needs backward computation.
I0528 19:00:48.085885 11123 net.cpp:198] layer_256_3_scale1 needs backward computation.
I0528 19:00:48.085891 11123 net.cpp:198] layer_256_3_bn1 needs backward computation.
I0528 19:00:48.085899 11123 net.cpp:198] layer_256_2_sum_layer_256_2_sum_0_split needs backward computation.
I0528 19:00:48.085906 11123 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 19:00:48.085914 11123 net.cpp:198] layer_256_2_conv3 needs backward computation.
I0528 19:00:48.085922 11123 net.cpp:198] layer_256_2_relu3 needs backward computation.
I0528 19:00:48.085932 11123 net.cpp:198] layer_256_2_scale3 needs backward computation.
I0528 19:00:48.085938 11123 net.cpp:198] layer_256_2_bn3 needs backward computation.
I0528 19:00:48.085945 11123 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 19:00:48.085952 11123 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 19:00:48.085960 11123 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 19:00:48.085966 11123 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 19:00:48.085973 11123 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 19:00:48.085979 11123 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 19:00:48.085989 11123 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 19:00:48.085996 11123 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 19:00:48.086004 11123 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 19:00:48.086012 11123 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 19:00:48.086030 11123 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 19:00:48.086038 11123 net.cpp:198] layer_256_1_conv3 needs backward computation.
I0528 19:00:48.086045 11123 net.cpp:198] layer_256_1_relu3 needs backward computation.
I0528 19:00:48.086052 11123 net.cpp:198] layer_256_1_scale3 needs backward computation.
I0528 19:00:48.086058 11123 net.cpp:198] layer_256_1_bn3 needs backward computation.
I0528 19:00:48.086066 11123 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 19:00:48.086073 11123 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 19:00:48.086081 11123 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 19:00:48.086087 11123 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 19:00:48.086094 11123 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 19:00:48.086102 11123 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 19:00:48.086110 11123 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 19:00:48.086118 11123 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 19:00:48.086124 11123 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 19:00:48.086133 11123 net.cpp:198] layer_128_4_sum needs backward computation.
I0528 19:00:48.086143 11123 net.cpp:198] layer_128_4_conv3 needs backward computation.
I0528 19:00:48.086150 11123 net.cpp:198] layer_128_4_relu3 needs backward computation.
I0528 19:00:48.086158 11123 net.cpp:198] layer_128_4_scale3 needs backward computation.
I0528 19:00:48.086164 11123 net.cpp:198] layer_128_4_bn3 needs backward computation.
I0528 19:00:48.086171 11123 net.cpp:198] layer_128_4_conv2 needs backward computation.
I0528 19:00:48.086179 11123 net.cpp:198] layer_128_4_relu2 needs backward computation.
I0528 19:00:48.086186 11123 net.cpp:198] layer_128_4_scale2 needs backward computation.
I0528 19:00:48.086192 11123 net.cpp:198] layer_128_4_bn2 needs backward computation.
I0528 19:00:48.086200 11123 net.cpp:198] layer_128_4_conv1 needs backward computation.
I0528 19:00:48.086206 11123 net.cpp:198] layer_128_4_relu1 needs backward computation.
I0528 19:00:48.086215 11123 net.cpp:198] layer_128_4_scale1 needs backward computation.
I0528 19:00:48.086220 11123 net.cpp:198] layer_128_4_bn1 needs backward computation.
I0528 19:00:48.086230 11123 net.cpp:198] layer_128_3_sum_layer_128_3_sum_0_split needs backward computation.
I0528 19:00:48.086237 11123 net.cpp:198] layer_128_3_sum needs backward computation.
I0528 19:00:48.086246 11123 net.cpp:198] layer_128_3_conv3 needs backward computation.
I0528 19:00:48.086254 11123 net.cpp:198] layer_128_3_relu3 needs backward computation.
I0528 19:00:48.086262 11123 net.cpp:198] layer_128_3_scale3 needs backward computation.
I0528 19:00:48.086269 11123 net.cpp:198] layer_128_3_bn3 needs backward computation.
I0528 19:00:48.086277 11123 net.cpp:198] layer_128_3_conv2 needs backward computation.
I0528 19:00:48.086285 11123 net.cpp:198] layer_128_3_relu2 needs backward computation.
I0528 19:00:48.086293 11123 net.cpp:198] layer_128_3_scale2 needs backward computation.
I0528 19:00:48.086299 11123 net.cpp:198] layer_128_3_bn2 needs backward computation.
I0528 19:00:48.086308 11123 net.cpp:198] layer_128_3_conv1 needs backward computation.
I0528 19:00:48.086314 11123 net.cpp:198] layer_128_3_relu1 needs backward computation.
I0528 19:00:48.086323 11123 net.cpp:198] layer_128_3_scale1 needs backward computation.
I0528 19:00:48.086328 11123 net.cpp:198] layer_128_3_bn1 needs backward computation.
I0528 19:00:48.086336 11123 net.cpp:198] layer_128_2_sum_layer_128_2_sum_0_split needs backward computation.
I0528 19:00:48.086344 11123 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 19:00:48.086352 11123 net.cpp:198] layer_128_2_conv3 needs backward computation.
I0528 19:00:48.086360 11123 net.cpp:198] layer_128_2_relu3 needs backward computation.
I0528 19:00:48.086369 11123 net.cpp:198] layer_128_2_scale3 needs backward computation.
I0528 19:00:48.086374 11123 net.cpp:198] layer_128_2_bn3 needs backward computation.
I0528 19:00:48.086390 11123 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 19:00:48.086397 11123 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 19:00:48.086405 11123 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 19:00:48.086411 11123 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 19:00:48.086418 11123 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 19:00:48.086426 11123 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 19:00:48.086434 11123 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 19:00:48.086441 11123 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 19:00:48.086449 11123 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 19:00:48.086457 11123 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 19:00:48.086464 11123 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 19:00:48.086472 11123 net.cpp:198] layer_128_1_conv3 needs backward computation.
I0528 19:00:48.086482 11123 net.cpp:198] layer_128_1_relu3 needs backward computation.
I0528 19:00:48.086489 11123 net.cpp:198] layer_128_1_scale3 needs backward computation.
I0528 19:00:48.086495 11123 net.cpp:198] layer_128_1_bn3 needs backward computation.
I0528 19:00:48.086503 11123 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 19:00:48.086509 11123 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 19:00:48.086519 11123 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 19:00:48.086525 11123 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 19:00:48.086534 11123 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 19:00:48.086540 11123 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 19:00:48.086549 11123 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 19:00:48.086555 11123 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 19:00:48.086562 11123 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 19:00:48.086570 11123 net.cpp:198] layer_64_3_sum needs backward computation.
I0528 19:00:48.086578 11123 net.cpp:198] layer_64_3_conv3 needs backward computation.
I0528 19:00:48.086586 11123 net.cpp:198] layer_64_3_relu3 needs backward computation.
I0528 19:00:48.086594 11123 net.cpp:198] layer_64_3_scale3 needs backward computation.
I0528 19:00:48.086601 11123 net.cpp:198] layer_64_3_bn3 needs backward computation.
I0528 19:00:48.086608 11123 net.cpp:198] layer_64_3_conv2 needs backward computation.
I0528 19:00:48.086616 11123 net.cpp:198] layer_64_3_relu2 needs backward computation.
I0528 19:00:48.086623 11123 net.cpp:198] layer_64_3_scale2 needs backward computation.
I0528 19:00:48.086630 11123 net.cpp:198] layer_64_3_bn2 needs backward computation.
I0528 19:00:48.086637 11123 net.cpp:198] layer_64_3_conv1 needs backward computation.
I0528 19:00:48.086644 11123 net.cpp:198] layer_64_3_relu1 needs backward computation.
I0528 19:00:48.086652 11123 net.cpp:198] layer_64_3_scale1 needs backward computation.
I0528 19:00:48.086658 11123 net.cpp:198] layer_64_3_bn1 needs backward computation.
I0528 19:00:48.086664 11123 net.cpp:198] layer_64_2_sum_layer_64_2_sum_0_split needs backward computation.
I0528 19:00:48.086673 11123 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 19:00:48.086681 11123 net.cpp:198] layer_64_2_conv3 needs backward computation.
I0528 19:00:48.086690 11123 net.cpp:198] layer_64_2_relu3 needs backward computation.
I0528 19:00:48.086696 11123 net.cpp:198] layer_64_2_scale3 needs backward computation.
I0528 19:00:48.086704 11123 net.cpp:198] layer_64_2_bn3 needs backward computation.
I0528 19:00:48.086710 11123 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 19:00:48.086717 11123 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 19:00:48.086725 11123 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 19:00:48.086740 11123 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 19:00:48.086746 11123 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 19:00:48.086755 11123 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 19:00:48.086760 11123 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 19:00:48.086767 11123 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 19:00:48.086774 11123 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 19:00:48.086782 11123 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 19:00:48.086791 11123 net.cpp:198] layer_64_1_conv_expand needs backward computation.
I0528 19:00:48.086798 11123 net.cpp:198] layer_64_1_conv3 needs backward computation.
I0528 19:00:48.086807 11123 net.cpp:198] layer_64_1_relu3 needs backward computation.
I0528 19:00:48.086815 11123 net.cpp:198] layer_64_1_scale3 needs backward computation.
I0528 19:00:48.086822 11123 net.cpp:198] layer_64_1_bn3 needs backward computation.
I0528 19:00:48.086829 11123 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 19:00:48.086838 11123 net.cpp:198] layer_64_1_conv1_layer_64_1_relu2_0_split needs backward computation.
I0528 19:00:48.086846 11123 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 19:00:48.086853 11123 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 19:00:48.086860 11123 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 19:00:48.086868 11123 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 19:00:48.086875 11123 net.cpp:198] conv1_pool needs backward computation.
I0528 19:00:48.086884 11123 net.cpp:198] conv1_relu needs backward computation.
I0528 19:00:48.086890 11123 net.cpp:198] conv1_scale needs backward computation.
I0528 19:00:48.086897 11123 net.cpp:198] conv1_bn needs backward computation.
I0528 19:00:48.086904 11123 net.cpp:198] conv1 needs backward computation.
I0528 19:00:48.086911 11123 net.cpp:198] data_scale needs backward computation.
I0528 19:00:48.086920 11123 net.cpp:200] data_bn does not need backward computation.
I0528 19:00:48.086928 11123 net.cpp:200] label_data_1_split does not need backward computation.
I0528 19:00:48.086937 11123 net.cpp:200] data does not need backward computation.
I0528 19:00:48.086944 11123 net.cpp:242] This network produces output accuracy
I0528 19:00:48.086951 11123 net.cpp:242] This network produces output loss
I0528 19:00:48.087077 11123 net.cpp:255] Network initialization done.
I0528 19:00:48.087620 11123 solver.cpp:56] Solver scaffolding done.
I0528 19:00:48.097106 11123 caffe.cpp:248] Starting Optimization
I0528 19:00:48.097121 11123 solver.cpp:272] Solving Pre-ResNet-50
I0528 19:00:48.097127 11123 solver.cpp:273] Learning Rate Policy: poly
I0528 19:00:48.114405 11123 solver.cpp:330] Iteration 0, Testing net (#0)
I0528 19:00:52.749507 11123 solver.cpp:397]     Test net output #0: accuracy = 0.561
I0528 19:00:52.749552 11123 solver.cpp:397]     Test net output #1: loss = 87.3365 (* 1 = 87.3365 loss)
I0528 19:00:53.100196 11123 solver.cpp:218] Iteration 0 (-1.94631e+36 iter/s, 5.00291s/100 iters), loss = 0.693147
I0528 19:00:53.100245 11123 solver.cpp:237]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0528 19:00:53.100265 11123 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0528 19:01:21.562981 11123 solver.cpp:218] Iteration 100 (3.51346 iter/s, 28.462s/100 iters), loss = 0.733494
I0528 19:01:21.563129 11123 solver.cpp:237]     Train net output #0: loss = 0.733494 (* 1 = 0.733494 loss)
I0528 19:01:21.563140 11123 sgd_solver.cpp:105] Iteration 100, lr = 0.009995
I0528 19:01:49.879003 11123 solver.cpp:218] Iteration 200 (3.53168 iter/s, 28.3152s/100 iters), loss = 0.58036
I0528 19:01:49.879060 11123 solver.cpp:237]     Train net output #0: loss = 0.58036 (* 1 = 0.58036 loss)
I0528 19:01:49.879068 11123 sgd_solver.cpp:105] Iteration 200, lr = 0.00999
I0528 19:02:18.494663 11123 solver.cpp:218] Iteration 300 (3.49471 iter/s, 28.6147s/100 iters), loss = 0.858097
I0528 19:02:18.494853 11123 solver.cpp:237]     Train net output #0: loss = 0.858097 (* 1 = 0.858097 loss)
I0528 19:02:18.494864 11123 sgd_solver.cpp:105] Iteration 300, lr = 0.009985
I0528 19:02:47.143185 11123 solver.cpp:218] Iteration 400 (3.49067 iter/s, 28.6478s/100 iters), loss = 0.669455
I0528 19:02:47.143259 11123 solver.cpp:237]     Train net output #0: loss = 0.669455 (* 1 = 0.669455 loss)
I0528 19:02:47.143275 11123 sgd_solver.cpp:105] Iteration 400, lr = 0.00998
I0528 19:03:15.213373 11123 solver.cpp:218] Iteration 500 (3.56257 iter/s, 28.0696s/100 iters), loss = 0.67564
I0528 19:03:15.213582 11123 solver.cpp:237]     Train net output #0: loss = 0.67564 (* 1 = 0.67564 loss)
I0528 19:03:15.213593 11123 sgd_solver.cpp:105] Iteration 500, lr = 0.009975
I0528 19:03:43.835661 11123 solver.cpp:218] Iteration 600 (3.49387 iter/s, 28.6216s/100 iters), loss = 0.746937
I0528 19:03:43.835721 11123 solver.cpp:237]     Train net output #0: loss = 0.746937 (* 1 = 0.746937 loss)
I0528 19:03:43.835731 11123 sgd_solver.cpp:105] Iteration 600, lr = 0.00997
I0528 19:03:46.133913 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:04:12.318722 11123 solver.cpp:218] Iteration 700 (3.51093 iter/s, 28.4825s/100 iters), loss = 0.71918
I0528 19:04:12.318779 11123 solver.cpp:237]     Train net output #0: loss = 0.71918 (* 1 = 0.71918 loss)
I0528 19:04:12.318789 11123 sgd_solver.cpp:105] Iteration 700, lr = 0.009965
I0528 19:04:41.005053 11123 solver.cpp:218] Iteration 800 (3.48612 iter/s, 28.6852s/100 iters), loss = 0.686023
I0528 19:04:41.005185 11123 solver.cpp:237]     Train net output #0: loss = 0.686023 (* 1 = 0.686023 loss)
I0528 19:04:41.005197 11123 sgd_solver.cpp:105] Iteration 800, lr = 0.00996
I0528 19:05:09.207633 11123 solver.cpp:218] Iteration 900 (3.54586 iter/s, 28.2019s/100 iters), loss = 0.678817
I0528 19:05:09.207677 11123 solver.cpp:237]     Train net output #0: loss = 0.678817 (* 1 = 0.678817 loss)
I0528 19:05:09.207686 11123 sgd_solver.cpp:105] Iteration 900, lr = 0.009955
I0528 19:05:37.026623 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_1000.caffemodel
I0528 19:05:37.378557 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_1000.solverstate
I0528 19:05:37.525115 11123 solver.cpp:330] Iteration 1000, Testing net (#0)
I0528 19:05:38.873345 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:05:41.984381 11123 solver.cpp:397]     Test net output #0: accuracy = 0.59
I0528 19:05:41.984428 11123 solver.cpp:397]     Test net output #1: loss = 1.08779 (* 1 = 1.08779 loss)
I0528 19:05:42.262693 11123 solver.cpp:218] Iteration 1000 (3.02532 iter/s, 33.0544s/100 iters), loss = 0.615023
I0528 19:05:42.262740 11123 solver.cpp:237]     Train net output #0: loss = 0.615023 (* 1 = 0.615023 loss)
I0528 19:05:42.262748 11123 sgd_solver.cpp:105] Iteration 1000, lr = 0.00995
I0528 19:06:10.600407 11123 solver.cpp:218] Iteration 1100 (3.52894 iter/s, 28.3371s/100 iters), loss = 0.573475
I0528 19:06:10.600580 11123 solver.cpp:237]     Train net output #0: loss = 0.573475 (* 1 = 0.573475 loss)
I0528 19:06:10.600597 11123 sgd_solver.cpp:105] Iteration 1100, lr = 0.009945
I0528 19:06:39.149601 11123 solver.cpp:218] Iteration 1200 (3.50281 iter/s, 28.5485s/100 iters), loss = 0.861003
I0528 19:06:39.149646 11123 solver.cpp:237]     Train net output #0: loss = 0.861003 (* 1 = 0.861003 loss)
I0528 19:06:39.149654 11123 sgd_solver.cpp:105] Iteration 1200, lr = 0.00994
I0528 19:06:45.122913 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:07:07.301864 11123 solver.cpp:218] Iteration 1300 (3.55219 iter/s, 28.1517s/100 iters), loss = 0.644118
I0528 19:07:07.301911 11123 solver.cpp:237]     Train net output #0: loss = 0.644118 (* 1 = 0.644118 loss)
I0528 19:07:07.301920 11123 sgd_solver.cpp:105] Iteration 1300, lr = 0.009935
I0528 19:07:35.537616 11123 solver.cpp:218] Iteration 1400 (3.54168 iter/s, 28.2352s/100 iters), loss = 0.885988
I0528 19:07:35.537924 11123 solver.cpp:237]     Train net output #0: loss = 0.885988 (* 1 = 0.885988 loss)
I0528 19:07:35.537938 11123 sgd_solver.cpp:105] Iteration 1400, lr = 0.00993
I0528 19:08:03.614289 11123 solver.cpp:218] Iteration 1500 (3.56178 iter/s, 28.0758s/100 iters), loss = 0.656635
I0528 19:08:03.614338 11123 solver.cpp:237]     Train net output #0: loss = 0.656635 (* 1 = 0.656635 loss)
I0528 19:08:03.614347 11123 sgd_solver.cpp:105] Iteration 1500, lr = 0.009925
I0528 19:08:31.687289 11123 solver.cpp:218] Iteration 1600 (3.56222 iter/s, 28.0724s/100 iters), loss = 0.514463
I0528 19:08:31.687497 11123 solver.cpp:237]     Train net output #0: loss = 0.514463 (* 1 = 0.514463 loss)
I0528 19:08:31.687510 11123 sgd_solver.cpp:105] Iteration 1600, lr = 0.00992
I0528 19:08:59.754472 11123 solver.cpp:218] Iteration 1700 (3.56297 iter/s, 28.0665s/100 iters), loss = 0.740765
I0528 19:08:59.754516 11123 solver.cpp:237]     Train net output #0: loss = 0.740765 (* 1 = 0.740765 loss)
I0528 19:08:59.754525 11123 sgd_solver.cpp:105] Iteration 1700, lr = 0.009915
I0528 19:09:27.809651 11123 solver.cpp:218] Iteration 1800 (3.56448 iter/s, 28.0546s/100 iters), loss = 0.552097
I0528 19:09:27.809811 11123 solver.cpp:237]     Train net output #0: loss = 0.552097 (* 1 = 0.552097 loss)
I0528 19:09:27.809824 11123 sgd_solver.cpp:105] Iteration 1800, lr = 0.00991
I0528 19:09:37.366051 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:09:55.872344 11123 solver.cpp:218] Iteration 1900 (3.56354 iter/s, 28.062s/100 iters), loss = 0.510824
I0528 19:09:55.872387 11123 solver.cpp:237]     Train net output #0: loss = 0.510824 (* 1 = 0.510824 loss)
I0528 19:09:55.872396 11123 sgd_solver.cpp:105] Iteration 1900, lr = 0.009905
I0528 19:10:23.624358 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_2000.caffemodel
I0528 19:10:23.935047 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_2000.solverstate
I0528 19:10:24.081535 11123 solver.cpp:330] Iteration 2000, Testing net (#0)
I0528 19:10:26.926893 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:10:28.517333 11123 solver.cpp:397]     Test net output #0: accuracy = 0.636
I0528 19:10:28.517367 11123 solver.cpp:397]     Test net output #1: loss = 0.634017 (* 1 = 0.634017 loss)
I0528 19:10:28.794487 11123 solver.cpp:218] Iteration 2000 (3.03753 iter/s, 32.9215s/100 iters), loss = 0.673876
I0528 19:10:28.794548 11123 solver.cpp:237]     Train net output #0: loss = 0.673876 (* 1 = 0.673876 loss)
I0528 19:10:28.794556 11123 sgd_solver.cpp:105] Iteration 2000, lr = 0.0099
I0528 19:10:56.808888 11123 solver.cpp:218] Iteration 2100 (3.56967 iter/s, 28.0138s/100 iters), loss = 0.49914
I0528 19:10:56.809075 11123 solver.cpp:237]     Train net output #0: loss = 0.49914 (* 1 = 0.49914 loss)
I0528 19:10:56.809098 11123 sgd_solver.cpp:105] Iteration 2100, lr = 0.009895
I0528 19:11:24.851481 11123 solver.cpp:218] Iteration 2200 (3.5661 iter/s, 28.0419s/100 iters), loss = 0.595186
I0528 19:11:24.851527 11123 solver.cpp:237]     Train net output #0: loss = 0.595186 (* 1 = 0.595186 loss)
I0528 19:11:24.851536 11123 sgd_solver.cpp:105] Iteration 2200, lr = 0.00989
I0528 19:11:52.896776 11123 solver.cpp:218] Iteration 2300 (3.56574 iter/s, 28.0447s/100 iters), loss = 0.450327
I0528 19:11:52.896951 11123 solver.cpp:237]     Train net output #0: loss = 0.450327 (* 1 = 0.450327 loss)
I0528 19:11:52.896967 11123 sgd_solver.cpp:105] Iteration 2300, lr = 0.009885
I0528 19:12:20.951453 11123 solver.cpp:218] Iteration 2400 (3.56456 iter/s, 28.054s/100 iters), loss = 0.484252
I0528 19:12:20.951498 11123 solver.cpp:237]     Train net output #0: loss = 0.484252 (* 1 = 0.484252 loss)
I0528 19:12:20.951506 11123 sgd_solver.cpp:105] Iteration 2400, lr = 0.00988
I0528 19:12:34.144032 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:12:48.981761 11123 solver.cpp:218] Iteration 2500 (3.56764 iter/s, 28.0297s/100 iters), loss = 0.393848
I0528 19:12:48.981806 11123 solver.cpp:237]     Train net output #0: loss = 0.393848 (* 1 = 0.393848 loss)
I0528 19:12:48.981815 11123 sgd_solver.cpp:105] Iteration 2500, lr = 0.009875
I0528 19:13:17.029597 11123 solver.cpp:218] Iteration 2600 (3.56541 iter/s, 28.0472s/100 iters), loss = 0.664366
I0528 19:13:17.029793 11123 solver.cpp:237]     Train net output #0: loss = 0.664366 (* 1 = 0.664366 loss)
I0528 19:13:17.029803 11123 sgd_solver.cpp:105] Iteration 2600, lr = 0.00987
I0528 19:13:45.097713 11123 solver.cpp:218] Iteration 2700 (3.56286 iter/s, 28.0674s/100 iters), loss = 0.444691
I0528 19:13:45.097759 11123 solver.cpp:237]     Train net output #0: loss = 0.444691 (* 1 = 0.444691 loss)
I0528 19:13:45.097769 11123 sgd_solver.cpp:105] Iteration 2700, lr = 0.009865
I0528 19:14:13.150094 11123 solver.cpp:218] Iteration 2800 (3.56484 iter/s, 28.0518s/100 iters), loss = 0.545473
I0528 19:14:13.150261 11123 solver.cpp:237]     Train net output #0: loss = 0.545473 (* 1 = 0.545473 loss)
I0528 19:14:13.150272 11123 sgd_solver.cpp:105] Iteration 2800, lr = 0.00986
I0528 19:14:41.188174 11123 solver.cpp:218] Iteration 2900 (3.56667 iter/s, 28.0374s/100 iters), loss = 0.682576
I0528 19:14:41.188221 11123 solver.cpp:237]     Train net output #0: loss = 0.682576 (* 1 = 0.682576 loss)
I0528 19:14:41.188230 11123 sgd_solver.cpp:105] Iteration 2900, lr = 0.009855
I0528 19:15:08.951197 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_3000.caffemodel
I0528 19:15:09.258541 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_3000.solverstate
I0528 19:15:09.405622 11123 solver.cpp:330] Iteration 3000, Testing net (#0)
I0528 19:15:13.781239 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:15:13.867947 11123 solver.cpp:397]     Test net output #0: accuracy = 0.691
I0528 19:15:13.867995 11123 solver.cpp:397]     Test net output #1: loss = 0.573005 (* 1 = 0.573005 loss)
I0528 19:15:14.147660 11123 solver.cpp:218] Iteration 3000 (3.03409 iter/s, 32.9588s/100 iters), loss = 0.718457
I0528 19:15:14.147702 11123 solver.cpp:237]     Train net output #0: loss = 0.718457 (* 1 = 0.718457 loss)
I0528 19:15:14.147711 11123 sgd_solver.cpp:105] Iteration 3000, lr = 0.00985
I0528 19:15:30.717104 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:15:42.202850 11123 solver.cpp:218] Iteration 3100 (3.56448 iter/s, 28.0546s/100 iters), loss = 0.432201
I0528 19:15:42.203001 11123 solver.cpp:237]     Train net output #0: loss = 0.432201 (* 1 = 0.432201 loss)
I0528 19:15:42.203016 11123 sgd_solver.cpp:105] Iteration 3100, lr = 0.009845
I0528 19:16:10.256531 11123 solver.cpp:218] Iteration 3200 (3.56469 iter/s, 28.053s/100 iters), loss = 0.539466
I0528 19:16:10.256577 11123 solver.cpp:237]     Train net output #0: loss = 0.539466 (* 1 = 0.539466 loss)
I0528 19:16:10.256585 11123 sgd_solver.cpp:105] Iteration 3200, lr = 0.00984
I0528 19:16:38.428998 11123 solver.cpp:218] Iteration 3300 (3.54964 iter/s, 28.1719s/100 iters), loss = 0.562491
I0528 19:16:38.429265 11123 solver.cpp:237]     Train net output #0: loss = 0.562491 (* 1 = 0.562491 loss)
I0528 19:16:38.429276 11123 sgd_solver.cpp:105] Iteration 3300, lr = 0.009835
I0528 19:17:07.288206 11123 solver.cpp:218] Iteration 3400 (3.4652 iter/s, 28.8584s/100 iters), loss = 0.532958
I0528 19:17:07.288252 11123 solver.cpp:237]     Train net output #0: loss = 0.532958 (* 1 = 0.532958 loss)
I0528 19:17:07.288261 11123 sgd_solver.cpp:105] Iteration 3400, lr = 0.00983
I0528 19:17:36.393200 11123 solver.cpp:218] Iteration 3500 (3.43591 iter/s, 29.1044s/100 iters), loss = 0.442559
I0528 19:17:36.393407 11123 solver.cpp:237]     Train net output #0: loss = 0.442559 (* 1 = 0.442559 loss)
I0528 19:17:36.393419 11123 sgd_solver.cpp:105] Iteration 3500, lr = 0.009825
I0528 19:18:04.930055 11123 solver.cpp:218] Iteration 3600 (3.50434 iter/s, 28.5361s/100 iters), loss = 0.756105
I0528 19:18:04.930104 11123 solver.cpp:237]     Train net output #0: loss = 0.756105 (* 1 = 0.756105 loss)
I0528 19:18:04.930112 11123 sgd_solver.cpp:105] Iteration 3600, lr = 0.00982
I0528 19:18:25.790618 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:18:33.850628 11123 solver.cpp:218] Iteration 3700 (3.45782 iter/s, 28.9199s/100 iters), loss = 0.627986
I0528 19:18:33.850693 11123 solver.cpp:237]     Train net output #0: loss = 0.627986 (* 1 = 0.627986 loss)
I0528 19:18:33.850703 11123 sgd_solver.cpp:105] Iteration 3700, lr = 0.009815
I0528 19:19:02.913307 11123 solver.cpp:218] Iteration 3800 (3.44096 iter/s, 29.0616s/100 iters), loss = 0.607164
I0528 19:19:02.913405 11123 solver.cpp:237]     Train net output #0: loss = 0.607164 (* 1 = 0.607164 loss)
I0528 19:19:02.913416 11123 sgd_solver.cpp:105] Iteration 3800, lr = 0.00981
I0528 19:19:33.007757 11123 solver.cpp:218] Iteration 3900 (3.32295 iter/s, 30.0937s/100 iters), loss = 0.500251
I0528 19:19:33.007867 11123 solver.cpp:237]     Train net output #0: loss = 0.500251 (* 1 = 0.500251 loss)
I0528 19:19:33.007880 11123 sgd_solver.cpp:105] Iteration 3900, lr = 0.009805
I0528 19:20:01.492797 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_4000.caffemodel
I0528 19:20:01.801599 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_4000.solverstate
I0528 19:20:01.948506 11123 solver.cpp:330] Iteration 4000, Testing net (#0)
I0528 19:20:06.462397 11123 solver.cpp:397]     Test net output #0: accuracy = 0.646
I0528 19:20:06.462597 11123 solver.cpp:397]     Test net output #1: loss = 0.64888 (* 1 = 0.64888 loss)
I0528 19:20:06.742425 11123 solver.cpp:218] Iteration 4000 (2.96438 iter/s, 33.7339s/100 iters), loss = 0.727806
I0528 19:20:06.742482 11123 solver.cpp:237]     Train net output #0: loss = 0.727806 (* 1 = 0.727806 loss)
I0528 19:20:06.742491 11123 sgd_solver.cpp:105] Iteration 4000, lr = 0.0098
I0528 19:20:35.525629 11123 solver.cpp:218] Iteration 4100 (3.47433 iter/s, 28.7826s/100 iters), loss = 0.633299
I0528 19:20:35.525681 11123 solver.cpp:237]     Train net output #0: loss = 0.633298 (* 1 = 0.633298 loss)
I0528 19:20:35.525689 11123 sgd_solver.cpp:105] Iteration 4100, lr = 0.009795
I0528 19:21:03.884028 11123 solver.cpp:218] Iteration 4200 (3.52637 iter/s, 28.3578s/100 iters), loss = 0.438332
I0528 19:21:03.884230 11123 solver.cpp:237]     Train net output #0: loss = 0.438331 (* 1 = 0.438331 loss)
I0528 19:21:03.884243 11123 sgd_solver.cpp:105] Iteration 4200, lr = 0.00979
I0528 19:21:27.752147 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:21:31.943076 11123 solver.cpp:218] Iteration 4300 (3.56401 iter/s, 28.0583s/100 iters), loss = 0.591271
I0528 19:21:31.943121 11123 solver.cpp:237]     Train net output #0: loss = 0.591271 (* 1 = 0.591271 loss)
I0528 19:21:31.943130 11123 sgd_solver.cpp:105] Iteration 4300, lr = 0.009785
I0528 19:22:00.063390 11123 solver.cpp:218] Iteration 4400 (3.55623 iter/s, 28.1197s/100 iters), loss = 0.737905
I0528 19:22:00.063594 11123 solver.cpp:237]     Train net output #0: loss = 0.737905 (* 1 = 0.737905 loss)
I0528 19:22:00.063606 11123 sgd_solver.cpp:105] Iteration 4400, lr = 0.00978
I0528 19:22:28.215131 11123 solver.cpp:218] Iteration 4500 (3.55228 iter/s, 28.151s/100 iters), loss = 0.453298
I0528 19:22:28.215175 11123 solver.cpp:237]     Train net output #0: loss = 0.453298 (* 1 = 0.453298 loss)
I0528 19:22:28.215184 11123 sgd_solver.cpp:105] Iteration 4500, lr = 0.009775
I0528 19:22:56.616649 11123 solver.cpp:218] Iteration 4600 (3.52102 iter/s, 28.4009s/100 iters), loss = 0.348688
I0528 19:22:56.616813 11123 solver.cpp:237]     Train net output #0: loss = 0.348688 (* 1 = 0.348688 loss)
I0528 19:22:56.616827 11123 sgd_solver.cpp:105] Iteration 4600, lr = 0.00977
I0528 19:23:25.052131 11123 solver.cpp:218] Iteration 4700 (3.51683 iter/s, 28.4347s/100 iters), loss = 0.573005
I0528 19:23:25.052191 11123 solver.cpp:237]     Train net output #0: loss = 0.573004 (* 1 = 0.573004 loss)
I0528 19:23:25.052211 11123 sgd_solver.cpp:105] Iteration 4700, lr = 0.009765
I0528 19:23:53.508699 11123 solver.cpp:218] Iteration 4800 (3.51421 iter/s, 28.4559s/100 iters), loss = 0.473535
I0528 19:23:53.508976 11123 solver.cpp:237]     Train net output #0: loss = 0.473534 (* 1 = 0.473534 loss)
I0528 19:23:53.508990 11123 sgd_solver.cpp:105] Iteration 4800, lr = 0.00976
I0528 19:24:21.266923 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:24:21.813459 11123 solver.cpp:218] Iteration 4900 (3.53308 iter/s, 28.3039s/100 iters), loss = 0.383488
I0528 19:24:21.813503 11123 solver.cpp:237]     Train net output #0: loss = 0.383488 (* 1 = 0.383488 loss)
I0528 19:24:21.813511 11123 sgd_solver.cpp:105] Iteration 4900, lr = 0.009755
I0528 19:24:49.606073 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_5000.caffemodel
I0528 19:24:49.914510 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_5000.solverstate
I0528 19:24:50.060784 11123 solver.cpp:330] Iteration 5000, Testing net (#0)
I0528 19:24:51.496289 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:24:54.524639 11123 solver.cpp:397]     Test net output #0: accuracy = 0.674
I0528 19:24:54.524686 11123 solver.cpp:397]     Test net output #1: loss = 1.01454 (* 1 = 1.01454 loss)
I0528 19:24:54.803483 11123 solver.cpp:218] Iteration 5000 (3.03129 iter/s, 32.9893s/100 iters), loss = 0.437199
I0528 19:24:54.803529 11123 solver.cpp:237]     Train net output #0: loss = 0.437199 (* 1 = 0.437199 loss)
I0528 19:24:54.803539 11123 sgd_solver.cpp:105] Iteration 5000, lr = 0.00975
I0528 19:25:22.899147 11123 solver.cpp:218] Iteration 5100 (3.55935 iter/s, 28.095s/100 iters), loss = 0.401514
I0528 19:25:22.899310 11123 solver.cpp:237]     Train net output #0: loss = 0.401514 (* 1 = 0.401514 loss)
I0528 19:25:22.899322 11123 sgd_solver.cpp:105] Iteration 5100, lr = 0.009745
I0528 19:25:51.096128 11123 solver.cpp:218] Iteration 5200 (3.54657 iter/s, 28.1962s/100 iters), loss = 0.482126
I0528 19:25:51.096184 11123 solver.cpp:237]     Train net output #0: loss = 0.482126 (* 1 = 0.482126 loss)
I0528 19:25:51.096192 11123 sgd_solver.cpp:105] Iteration 5200, lr = 0.00974
I0528 19:26:20.296876 11123 solver.cpp:218] Iteration 5300 (3.42465 iter/s, 29.2001s/100 iters), loss = 0.602065
I0528 19:26:20.297006 11123 solver.cpp:237]     Train net output #0: loss = 0.602065 (* 1 = 0.602065 loss)
I0528 19:26:20.297020 11123 sgd_solver.cpp:105] Iteration 5300, lr = 0.009735
I0528 19:26:48.458923 11123 solver.cpp:218] Iteration 5400 (3.55097 iter/s, 28.1613s/100 iters), loss = 0.428714
I0528 19:26:48.458973 11123 solver.cpp:237]     Train net output #0: loss = 0.428714 (* 1 = 0.428714 loss)
I0528 19:26:48.458982 11123 sgd_solver.cpp:105] Iteration 5400, lr = 0.00973
I0528 19:27:16.492795 11123 solver.cpp:218] Iteration 5500 (3.56719 iter/s, 28.0332s/100 iters), loss = 0.418366
I0528 19:27:16.492981 11123 solver.cpp:237]     Train net output #0: loss = 0.418366 (* 1 = 0.418366 loss)
I0528 19:27:16.492992 11123 sgd_solver.cpp:105] Iteration 5500, lr = 0.009725
I0528 19:27:19.596994 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:27:44.565429 11123 solver.cpp:218] Iteration 5600 (3.56229 iter/s, 28.0719s/100 iters), loss = 0.347908
I0528 19:27:44.565488 11123 solver.cpp:237]     Train net output #0: loss = 0.347907 (* 1 = 0.347907 loss)
I0528 19:27:44.565497 11123 sgd_solver.cpp:105] Iteration 5600, lr = 0.00972
I0528 19:28:12.587463 11123 solver.cpp:218] Iteration 5700 (3.5687 iter/s, 28.0214s/100 iters), loss = 0.407529
I0528 19:28:12.587748 11123 solver.cpp:237]     Train net output #0: loss = 0.407529 (* 1 = 0.407529 loss)
I0528 19:28:12.587759 11123 sgd_solver.cpp:105] Iteration 5700, lr = 0.009715
I0528 19:28:40.580423 11123 solver.cpp:218] Iteration 5800 (3.57244 iter/s, 27.9921s/100 iters), loss = 0.523599
I0528 19:28:40.580467 11123 solver.cpp:237]     Train net output #0: loss = 0.523598 (* 1 = 0.523598 loss)
I0528 19:28:40.580476 11123 sgd_solver.cpp:105] Iteration 5800, lr = 0.00971
I0528 19:29:08.625521 11123 solver.cpp:218] Iteration 5900 (3.56577 iter/s, 28.0445s/100 iters), loss = 0.659485
I0528 19:29:08.625761 11123 solver.cpp:237]     Train net output #0: loss = 0.659484 (* 1 = 0.659484 loss)
I0528 19:29:08.625772 11123 sgd_solver.cpp:105] Iteration 5900, lr = 0.009705
I0528 19:29:36.372110 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_6000.caffemodel
I0528 19:29:36.679953 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_6000.solverstate
I0528 19:29:36.827045 11123 solver.cpp:330] Iteration 6000, Testing net (#0)
I0528 19:29:39.770242 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:29:41.278450 11123 solver.cpp:397]     Test net output #0: accuracy = 0.741
I0528 19:29:41.278496 11123 solver.cpp:397]     Test net output #1: loss = 0.518182 (* 1 = 0.518182 loss)
I0528 19:29:41.556264 11123 solver.cpp:218] Iteration 6000 (3.03676 iter/s, 32.9298s/100 iters), loss = 0.552817
I0528 19:29:41.556308 11123 solver.cpp:237]     Train net output #0: loss = 0.552817 (* 1 = 0.552817 loss)
I0528 19:29:41.556316 11123 sgd_solver.cpp:105] Iteration 6000, lr = 0.0097
I0528 19:30:09.623934 11123 solver.cpp:218] Iteration 6100 (3.5629 iter/s, 28.067s/100 iters), loss = 0.45594
I0528 19:30:09.623984 11123 solver.cpp:237]     Train net output #0: loss = 0.45594 (* 1 = 0.45594 loss)
I0528 19:30:09.623993 11123 sgd_solver.cpp:105] Iteration 6100, lr = 0.009695
I0528 19:30:16.100778 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:30:37.719971 11123 solver.cpp:218] Iteration 6200 (3.5593 iter/s, 28.0954s/100 iters), loss = 0.727645
I0528 19:30:37.720023 11123 solver.cpp:237]     Train net output #0: loss = 0.727644 (* 1 = 0.727644 loss)
I0528 19:30:37.720032 11123 sgd_solver.cpp:105] Iteration 6200, lr = 0.00969
I0528 19:31:06.000955 11123 solver.cpp:218] Iteration 6300 (3.53603 iter/s, 28.2803s/100 iters), loss = 0.378553
I0528 19:31:06.001144 11123 solver.cpp:237]     Train net output #0: loss = 0.378553 (* 1 = 0.378553 loss)
I0528 19:31:06.001157 11123 sgd_solver.cpp:105] Iteration 6300, lr = 0.009685
I0528 19:31:34.765552 11123 solver.cpp:218] Iteration 6400 (3.47659 iter/s, 28.7638s/100 iters), loss = 0.302907
I0528 19:31:34.765627 11123 solver.cpp:237]     Train net output #0: loss = 0.302907 (* 1 = 0.302907 loss)
I0528 19:31:34.765641 11123 sgd_solver.cpp:105] Iteration 6400, lr = 0.00968
I0528 19:32:03.335297 11123 solver.cpp:218] Iteration 6500 (3.50029 iter/s, 28.5691s/100 iters), loss = 0.370399
I0528 19:32:03.335525 11123 solver.cpp:237]     Train net output #0: loss = 0.370399 (* 1 = 0.370399 loss)
I0528 19:32:03.335547 11123 sgd_solver.cpp:105] Iteration 6500, lr = 0.009675
I0528 19:32:32.218152 11123 solver.cpp:218] Iteration 6600 (3.46236 iter/s, 28.882s/100 iters), loss = 0.583135
I0528 19:32:32.218200 11123 solver.cpp:237]     Train net output #0: loss = 0.583135 (* 1 = 0.583135 loss)
I0528 19:32:32.218220 11123 sgd_solver.cpp:105] Iteration 6600, lr = 0.00967
I0528 19:33:01.127708 11123 solver.cpp:218] Iteration 6700 (3.45914 iter/s, 28.9089s/100 iters), loss = 0.684721
I0528 19:33:01.127769 11123 solver.cpp:237]     Train net output #0: loss = 0.684721 (* 1 = 0.684721 loss)
I0528 19:33:01.127779 11123 sgd_solver.cpp:105] Iteration 6700, lr = 0.009665
I0528 19:33:11.421983 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:33:30.090942 11123 solver.cpp:218] Iteration 6800 (3.45273 iter/s, 28.9626s/100 iters), loss = 0.49712
I0528 19:33:30.091019 11123 solver.cpp:237]     Train net output #0: loss = 0.49712 (* 1 = 0.49712 loss)
I0528 19:33:30.091029 11123 sgd_solver.cpp:105] Iteration 6800, lr = 0.00966
I0528 19:33:58.880676 11123 solver.cpp:218] Iteration 6900 (3.47354 iter/s, 28.789s/100 iters), loss = 0.647833
I0528 19:33:58.880918 11123 solver.cpp:237]     Train net output #0: loss = 0.647833 (* 1 = 0.647833 loss)
I0528 19:33:58.880939 11123 sgd_solver.cpp:105] Iteration 6900, lr = 0.009655
I0528 19:34:27.528839 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_7000.caffemodel
I0528 19:34:27.837636 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_7000.solverstate
I0528 19:34:27.983501 11123 solver.cpp:330] Iteration 7000, Testing net (#0)
I0528 19:34:32.503880 11123 solver.cpp:397]     Test net output #0: accuracy = 0.692
I0528 19:34:32.504065 11123 solver.cpp:397]     Test net output #1: loss = 0.745835 (* 1 = 0.745835 loss)
I0528 19:34:32.784529 11123 solver.cpp:218] Iteration 7000 (2.9496 iter/s, 33.9029s/100 iters), loss = 0.449672
I0528 19:34:32.784600 11123 solver.cpp:237]     Train net output #0: loss = 0.449672 (* 1 = 0.449672 loss)
I0528 19:34:32.784610 11123 sgd_solver.cpp:105] Iteration 7000, lr = 0.00965
I0528 19:35:01.210991 11123 solver.cpp:218] Iteration 7100 (3.51793 iter/s, 28.4258s/100 iters), loss = 0.571512
I0528 19:35:01.211040 11123 solver.cpp:237]     Train net output #0: loss = 0.571512 (* 1 = 0.571512 loss)
I0528 19:35:01.211051 11123 sgd_solver.cpp:105] Iteration 7100, lr = 0.009645
I0528 19:35:29.772814 11123 solver.cpp:218] Iteration 7200 (3.50126 iter/s, 28.5612s/100 iters), loss = 0.314638
I0528 19:35:29.772971 11123 solver.cpp:237]     Train net output #0: loss = 0.314638 (* 1 = 0.314638 loss)
I0528 19:35:29.772984 11123 sgd_solver.cpp:105] Iteration 7200, lr = 0.00964
I0528 19:35:58.530138 11123 solver.cpp:218] Iteration 7300 (3.47747 iter/s, 28.7566s/100 iters), loss = 0.337156
I0528 19:35:58.530187 11123 solver.cpp:237]     Train net output #0: loss = 0.337156 (* 1 = 0.337156 loss)
I0528 19:35:58.530196 11123 sgd_solver.cpp:105] Iteration 7300, lr = 0.009635
I0528 19:36:12.723309 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:36:27.410265 11123 solver.cpp:218] Iteration 7400 (3.46267 iter/s, 28.8795s/100 iters), loss = 0.636918
I0528 19:36:27.410316 11123 solver.cpp:237]     Train net output #0: loss = 0.636918 (* 1 = 0.636918 loss)
I0528 19:36:27.410326 11123 sgd_solver.cpp:105] Iteration 7400, lr = 0.00963
I0528 19:36:57.101392 11123 solver.cpp:218] Iteration 7500 (3.36809 iter/s, 29.6904s/100 iters), loss = 0.493012
I0528 19:36:57.101557 11123 solver.cpp:237]     Train net output #0: loss = 0.493012 (* 1 = 0.493012 loss)
I0528 19:36:57.101572 11123 sgd_solver.cpp:105] Iteration 7500, lr = 0.009625
I0528 19:37:26.467496 11123 solver.cpp:218] Iteration 7600 (3.40538 iter/s, 29.3653s/100 iters), loss = 0.609995
I0528 19:37:26.467542 11123 solver.cpp:237]     Train net output #0: loss = 0.609995 (* 1 = 0.609995 loss)
I0528 19:37:26.467551 11123 sgd_solver.cpp:105] Iteration 7600, lr = 0.00962
I0528 19:37:55.630177 11123 solver.cpp:218] Iteration 7700 (3.42912 iter/s, 29.162s/100 iters), loss = 0.378764
I0528 19:37:55.630359 11123 solver.cpp:237]     Train net output #0: loss = 0.378764 (* 1 = 0.378764 loss)
I0528 19:37:55.630403 11123 sgd_solver.cpp:105] Iteration 7700, lr = 0.009615
I0528 19:38:25.038489 11123 solver.cpp:218] Iteration 7800 (3.40051 iter/s, 29.4074s/100 iters), loss = 0.332978
I0528 19:38:25.038552 11123 solver.cpp:237]     Train net output #0: loss = 0.332978 (* 1 = 0.332978 loss)
I0528 19:38:25.038564 11123 sgd_solver.cpp:105] Iteration 7800, lr = 0.00961
I0528 19:38:53.889642 11123 solver.cpp:218] Iteration 7900 (3.46617 iter/s, 28.8503s/100 iters), loss = 0.357646
I0528 19:38:53.889866 11123 solver.cpp:237]     Train net output #0: loss = 0.357646 (* 1 = 0.357646 loss)
I0528 19:38:53.889879 11123 sgd_solver.cpp:105] Iteration 7900, lr = 0.009605
I0528 19:39:12.146397 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:39:22.606312 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_8000.caffemodel
I0528 19:39:22.927848 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_8000.solverstate
I0528 19:39:23.080042 11123 solver.cpp:330] Iteration 8000, Testing net (#0)
I0528 19:39:23.084494 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:39:27.794164 11123 solver.cpp:397]     Test net output #0: accuracy = 0.685
I0528 19:39:27.794260 11123 solver.cpp:397]     Test net output #1: loss = 1.33041 (* 1 = 1.33041 loss)
I0528 19:39:28.111917 11123 solver.cpp:218] Iteration 8000 (2.92217 iter/s, 34.2212s/100 iters), loss = 0.53207
I0528 19:39:28.111999 11123 solver.cpp:237]     Train net output #0: loss = 0.532069 (* 1 = 0.532069 loss)
I0528 19:39:28.112010 11123 sgd_solver.cpp:105] Iteration 8000, lr = 0.0096
I0528 19:39:57.244029 11123 solver.cpp:218] Iteration 8100 (3.43282 iter/s, 29.1306s/100 iters), loss = 0.14173
I0528 19:39:57.244096 11123 solver.cpp:237]     Train net output #0: loss = 0.14173 (* 1 = 0.14173 loss)
I0528 19:39:57.244108 11123 sgd_solver.cpp:105] Iteration 8100, lr = 0.009595
I0528 19:40:26.001814 11123 solver.cpp:218] Iteration 8200 (3.47742 iter/s, 28.757s/100 iters), loss = 0.480693
I0528 19:40:26.003260 11123 solver.cpp:237]     Train net output #0: loss = 0.480693 (* 1 = 0.480693 loss)
I0528 19:40:26.003279 11123 sgd_solver.cpp:105] Iteration 8200, lr = 0.00959
I0528 19:40:54.779306 11123 solver.cpp:218] Iteration 8300 (3.4752 iter/s, 28.7753s/100 iters), loss = 0.406145
I0528 19:40:54.779409 11123 solver.cpp:237]     Train net output #0: loss = 0.406145 (* 1 = 0.406145 loss)
I0528 19:40:54.779418 11123 sgd_solver.cpp:105] Iteration 8300, lr = 0.009585
I0528 19:41:23.255303 11123 solver.cpp:218] Iteration 8400 (3.51183 iter/s, 28.4751s/100 iters), loss = 0.230387
I0528 19:41:23.255468 11123 solver.cpp:237]     Train net output #0: loss = 0.230387 (* 1 = 0.230387 loss)
I0528 19:41:23.255481 11123 sgd_solver.cpp:105] Iteration 8400, lr = 0.00958
I0528 19:41:51.876231 11123 solver.cpp:218] Iteration 8500 (3.49405 iter/s, 28.62s/100 iters), loss = 0.530728
I0528 19:41:51.876314 11123 solver.cpp:237]     Train net output #0: loss = 0.530728 (* 1 = 0.530728 loss)
I0528 19:41:51.876325 11123 sgd_solver.cpp:105] Iteration 8500, lr = 0.009575
I0528 19:42:13.294826 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:42:20.373533 11123 solver.cpp:218] Iteration 8600 (3.50923 iter/s, 28.4963s/100 iters), loss = 0.356363
I0528 19:42:20.373600 11123 solver.cpp:237]     Train net output #0: loss = 0.356363 (* 1 = 0.356363 loss)
I0528 19:42:20.373610 11123 sgd_solver.cpp:105] Iteration 8600, lr = 0.00957
I0528 19:42:49.218612 11123 solver.cpp:218] Iteration 8700 (3.46691 iter/s, 28.8441s/100 iters), loss = 0.344468
I0528 19:42:49.218768 11123 solver.cpp:237]     Train net output #0: loss = 0.344468 (* 1 = 0.344468 loss)
I0528 19:42:49.218781 11123 sgd_solver.cpp:105] Iteration 8700, lr = 0.009565
I0528 19:43:17.962893 11123 solver.cpp:218] Iteration 8800 (3.47906 iter/s, 28.7434s/100 iters), loss = 0.283754
I0528 19:43:17.962961 11123 solver.cpp:237]     Train net output #0: loss = 0.283754 (* 1 = 0.283754 loss)
I0528 19:43:17.962970 11123 sgd_solver.cpp:105] Iteration 8800, lr = 0.00956
I0528 19:43:46.789062 11123 solver.cpp:218] Iteration 8900 (3.46916 iter/s, 28.8254s/100 iters), loss = 0.335893
I0528 19:43:46.789305 11123 solver.cpp:237]     Train net output #0: loss = 0.335893 (* 1 = 0.335893 loss)
I0528 19:43:46.789330 11123 sgd_solver.cpp:105] Iteration 8900, lr = 0.009555
I0528 19:44:15.079639 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_9000.caffemodel
I0528 19:44:15.389621 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_9000.solverstate
I0528 19:44:15.539222 11123 solver.cpp:330] Iteration 9000, Testing net (#0)
I0528 19:44:17.068624 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:44:20.027261 11123 solver.cpp:397]     Test net output #0: accuracy = 0.787
I0528 19:44:20.027294 11123 solver.cpp:397]     Test net output #1: loss = 0.42887 (* 1 = 0.42887 loss)
I0528 19:44:20.314179 11123 solver.cpp:218] Iteration 9000 (2.98293 iter/s, 33.5241s/100 iters), loss = 0.418923
I0528 19:44:20.314246 11123 solver.cpp:237]     Train net output #0: loss = 0.418923 (* 1 = 0.418923 loss)
I0528 19:44:20.314255 11123 sgd_solver.cpp:105] Iteration 9000, lr = 0.00955
I0528 19:44:48.891800 11123 solver.cpp:218] Iteration 9100 (3.49934 iter/s, 28.5769s/100 iters), loss = 0.502891
I0528 19:44:48.891974 11123 solver.cpp:237]     Train net output #0: loss = 0.502891 (* 1 = 0.502891 loss)
I0528 19:44:48.891989 11123 sgd_solver.cpp:105] Iteration 9100, lr = 0.009545
I0528 19:45:13.804683 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:45:17.780953 11123 solver.cpp:218] Iteration 9200 (3.46161 iter/s, 28.8883s/100 iters), loss = 0.556243
I0528 19:45:17.781023 11123 solver.cpp:237]     Train net output #0: loss = 0.556243 (* 1 = 0.556243 loss)
I0528 19:45:17.781038 11123 sgd_solver.cpp:105] Iteration 9200, lr = 0.00954
I0528 19:45:46.621170 11123 solver.cpp:218] Iteration 9300 (3.46753 iter/s, 28.839s/100 iters), loss = 0.467464
I0528 19:45:46.621301 11123 solver.cpp:237]     Train net output #0: loss = 0.467464 (* 1 = 0.467464 loss)
I0528 19:45:46.621311 11123 sgd_solver.cpp:105] Iteration 9300, lr = 0.009535
I0528 19:46:15.551779 11123 solver.cpp:218] Iteration 9400 (3.45665 iter/s, 28.9298s/100 iters), loss = 0.247121
I0528 19:46:15.551837 11123 solver.cpp:237]     Train net output #0: loss = 0.247121 (* 1 = 0.247121 loss)
I0528 19:46:15.551847 11123 sgd_solver.cpp:105] Iteration 9400, lr = 0.00953
I0528 19:46:44.220079 11123 solver.cpp:218] Iteration 9500 (3.48826 iter/s, 28.6676s/100 iters), loss = 0.475668
I0528 19:46:44.220223 11123 solver.cpp:237]     Train net output #0: loss = 0.475668 (* 1 = 0.475668 loss)
I0528 19:46:44.220235 11123 sgd_solver.cpp:105] Iteration 9500, lr = 0.009525
I0528 19:47:12.815935 11123 solver.cpp:218] Iteration 9600 (3.49711 iter/s, 28.595s/100 iters), loss = 0.300835
I0528 19:47:12.815991 11123 solver.cpp:237]     Train net output #0: loss = 0.300835 (* 1 = 0.300835 loss)
I0528 19:47:12.816004 11123 sgd_solver.cpp:105] Iteration 9600, lr = 0.00952
I0528 19:47:41.086920 11123 solver.cpp:218] Iteration 9700 (3.53729 iter/s, 28.2703s/100 iters), loss = 0.33113
I0528 19:47:41.087077 11123 solver.cpp:237]     Train net output #0: loss = 0.33113 (* 1 = 0.33113 loss)
I0528 19:47:41.087088 11123 sgd_solver.cpp:105] Iteration 9700, lr = 0.009515
I0528 19:48:09.496945 11123 solver.cpp:218] Iteration 9800 (3.51999 iter/s, 28.4092s/100 iters), loss = 0.511505
I0528 19:48:09.497009 11123 solver.cpp:237]     Train net output #0: loss = 0.511505 (* 1 = 0.511505 loss)
I0528 19:48:09.497017 11123 sgd_solver.cpp:105] Iteration 9800, lr = 0.00951
I0528 19:48:09.520191 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:48:37.975968 11123 solver.cpp:218] Iteration 9900 (3.51145 iter/s, 28.4783s/100 iters), loss = 0.597541
I0528 19:48:37.976140 11123 solver.cpp:237]     Train net output #0: loss = 0.597541 (* 1 = 0.597541 loss)
I0528 19:48:37.976155 11123 sgd_solver.cpp:105] Iteration 9900, lr = 0.009505
I0528 19:49:06.222810 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_10000.caffemodel
I0528 19:49:06.535944 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_10000.solverstate
I0528 19:49:06.682925 11123 solver.cpp:330] Iteration 10000, Testing net (#0)
I0528 19:49:09.770372 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:49:11.223497 11123 solver.cpp:397]     Test net output #0: accuracy = 0.808
I0528 19:49:11.223541 11123 solver.cpp:397]     Test net output #1: loss = 0.399061 (* 1 = 0.399061 loss)
I0528 19:49:11.502575 11123 solver.cpp:218] Iteration 10000 (2.9828 iter/s, 33.5256s/100 iters), loss = 0.336001
I0528 19:49:11.502625 11123 solver.cpp:237]     Train net output #0: loss = 0.336001 (* 1 = 0.336001 loss)
I0528 19:49:11.502638 11123 sgd_solver.cpp:105] Iteration 10000, lr = 0.0095
I0528 19:49:39.896010 11123 solver.cpp:218] Iteration 10100 (3.52203 iter/s, 28.3927s/100 iters), loss = 0.150723
I0528 19:49:40.457962 11123 solver.cpp:237]     Train net output #0: loss = 0.150724 (* 1 = 0.150724 loss)
I0528 19:49:40.458030 11123 sgd_solver.cpp:105] Iteration 10100, lr = 0.009495
I0528 19:50:08.783182 11123 solver.cpp:218] Iteration 10200 (3.5305 iter/s, 28.3246s/100 iters), loss = 0.302591
I0528 19:50:08.783229 11123 solver.cpp:237]     Train net output #0: loss = 0.302591 (* 1 = 0.302591 loss)
I0528 19:50:08.783237 11123 sgd_solver.cpp:105] Iteration 10200, lr = 0.00949
I0528 19:50:37.642581 11123 solver.cpp:218] Iteration 10300 (3.46516 iter/s, 28.8587s/100 iters), loss = 0.192367
I0528 19:50:37.642827 11123 solver.cpp:237]     Train net output #0: loss = 0.192368 (* 1 = 0.192368 loss)
I0528 19:50:37.642849 11123 sgd_solver.cpp:105] Iteration 10300, lr = 0.009485
I0528 19:51:05.782311 11123 solver.cpp:218] Iteration 10400 (3.55381 iter/s, 28.1388s/100 iters), loss = 0.858679
I0528 19:51:05.782356 11123 solver.cpp:237]     Train net output #0: loss = 0.85868 (* 1 = 0.85868 loss)
I0528 19:51:05.782366 11123 sgd_solver.cpp:105] Iteration 10400, lr = 0.00948
I0528 19:51:09.445076 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:51:34.242660 11123 solver.cpp:218] Iteration 10500 (3.51375 iter/s, 28.4596s/100 iters), loss = 0.414135
I0528 19:51:34.242733 11123 solver.cpp:237]     Train net output #0: loss = 0.414136 (* 1 = 0.414136 loss)
I0528 19:51:34.242755 11123 sgd_solver.cpp:105] Iteration 10500, lr = 0.009475
I0528 19:52:02.740598 11123 solver.cpp:218] Iteration 10600 (3.50912 iter/s, 28.4972s/100 iters), loss = 0.178113
I0528 19:52:02.740766 11123 solver.cpp:237]     Train net output #0: loss = 0.178113 (* 1 = 0.178113 loss)
I0528 19:52:02.740777 11123 sgd_solver.cpp:105] Iteration 10600, lr = 0.00947
I0528 19:52:31.398166 11123 solver.cpp:218] Iteration 10700 (3.48958 iter/s, 28.6568s/100 iters), loss = 0.249033
I0528 19:52:31.398214 11123 solver.cpp:237]     Train net output #0: loss = 0.249033 (* 1 = 0.249033 loss)
I0528 19:52:31.398222 11123 sgd_solver.cpp:105] Iteration 10700, lr = 0.009465
I0528 19:52:59.854203 11123 solver.cpp:218] Iteration 10800 (3.51428 iter/s, 28.4553s/100 iters), loss = 0.32931
I0528 19:52:59.854442 11123 solver.cpp:237]     Train net output #0: loss = 0.329311 (* 1 = 0.329311 loss)
I0528 19:52:59.854455 11123 sgd_solver.cpp:105] Iteration 10800, lr = 0.00946
I0528 19:53:28.408440 11123 solver.cpp:218] Iteration 10900 (3.50222 iter/s, 28.5533s/100 iters), loss = 0.210435
I0528 19:53:28.408495 11123 solver.cpp:237]     Train net output #0: loss = 0.210435 (* 1 = 0.210435 loss)
I0528 19:53:28.408504 11123 sgd_solver.cpp:105] Iteration 10900, lr = 0.009455
I0528 19:53:56.667073 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_11000.caffemodel
I0528 19:53:56.979746 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_11000.solverstate
I0528 19:53:57.129743 11123 solver.cpp:330] Iteration 11000, Testing net (#0)
I0528 19:54:01.799656 11123 solver.cpp:397]     Test net output #0: accuracy = 0.819
I0528 19:54:01.799695 11123 solver.cpp:397]     Test net output #1: loss = 0.383115 (* 1 = 0.383115 loss)
I0528 19:54:02.078353 11123 solver.cpp:218] Iteration 11000 (2.97008 iter/s, 33.6691s/100 iters), loss = 0.313019
I0528 19:54:02.078431 11123 solver.cpp:237]     Train net output #0: loss = 0.313019 (* 1 = 0.313019 loss)
I0528 19:54:02.078441 11123 sgd_solver.cpp:105] Iteration 11000, lr = 0.00945
I0528 19:54:09.583384 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:54:30.750401 11123 solver.cpp:218] Iteration 11100 (3.48781 iter/s, 28.6713s/100 iters), loss = 0.246305
I0528 19:54:30.750574 11123 solver.cpp:237]     Train net output #0: loss = 0.246305 (* 1 = 0.246305 loss)
I0528 19:54:30.750586 11123 sgd_solver.cpp:105] Iteration 11100, lr = 0.009445
I0528 19:54:59.913187 11123 solver.cpp:218] Iteration 11200 (3.42913 iter/s, 29.162s/100 iters), loss = 0.260959
I0528 19:54:59.913234 11123 solver.cpp:237]     Train net output #0: loss = 0.260959 (* 1 = 0.260959 loss)
I0528 19:54:59.913244 11123 sgd_solver.cpp:105] Iteration 11200, lr = 0.00944
I0528 19:55:28.738657 11123 solver.cpp:218] Iteration 11300 (3.46924 iter/s, 28.8248s/100 iters), loss = 0.373968
I0528 19:55:28.738823 11123 solver.cpp:237]     Train net output #0: loss = 0.373968 (* 1 = 0.373968 loss)
I0528 19:55:28.738834 11123 sgd_solver.cpp:105] Iteration 11300, lr = 0.009435
I0528 19:55:56.941064 11123 solver.cpp:218] Iteration 11400 (3.5459 iter/s, 28.2016s/100 iters), loss = 0.658673
I0528 19:55:56.941126 11123 solver.cpp:237]     Train net output #0: loss = 0.658673 (* 1 = 0.658673 loss)
I0528 19:55:56.941135 11123 sgd_solver.cpp:105] Iteration 11400, lr = 0.00943
I0528 19:56:25.750195 11123 solver.cpp:218] Iteration 11500 (3.47121 iter/s, 28.8084s/100 iters), loss = 0.185191
I0528 19:56:25.750398 11123 solver.cpp:237]     Train net output #0: loss = 0.185191 (* 1 = 0.185191 loss)
I0528 19:56:25.750411 11123 sgd_solver.cpp:105] Iteration 11500, lr = 0.009425
I0528 19:56:54.287542 11123 solver.cpp:218] Iteration 11600 (3.50428 iter/s, 28.5365s/100 iters), loss = 0.286751
I0528 19:56:54.287587 11123 solver.cpp:237]     Train net output #0: loss = 0.286751 (* 1 = 0.286751 loss)
I0528 19:56:54.287596 11123 sgd_solver.cpp:105] Iteration 11600, lr = 0.00942
I0528 19:57:05.404189 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:57:23.224400 11123 solver.cpp:218] Iteration 11700 (3.45588 iter/s, 28.9362s/100 iters), loss = 0.236276
I0528 19:57:23.224445 11123 solver.cpp:237]     Train net output #0: loss = 0.236276 (* 1 = 0.236276 loss)
I0528 19:57:23.224454 11123 sgd_solver.cpp:105] Iteration 11700, lr = 0.009415
I0528 19:57:51.992811 11123 solver.cpp:218] Iteration 11800 (3.47612 iter/s, 28.7677s/100 iters), loss = 0.326001
I0528 19:57:51.992980 11123 solver.cpp:237]     Train net output #0: loss = 0.326001 (* 1 = 0.326001 loss)
I0528 19:57:51.992996 11123 sgd_solver.cpp:105] Iteration 11800, lr = 0.00941
I0528 19:58:20.667592 11123 solver.cpp:218] Iteration 11900 (3.48748 iter/s, 28.674s/100 iters), loss = 0.291933
I0528 19:58:20.667662 11123 solver.cpp:237]     Train net output #0: loss = 0.291933 (* 1 = 0.291933 loss)
I0528 19:58:20.667671 11123 sgd_solver.cpp:105] Iteration 11900, lr = 0.009405
I0528 19:58:48.999275 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_12000.caffemodel
I0528 19:58:49.308769 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_12000.solverstate
I0528 19:58:49.456801 11123 solver.cpp:330] Iteration 12000, Testing net (#0)
I0528 19:58:49.555999 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 19:58:53.996994 11123 solver.cpp:397]     Test net output #0: accuracy = 0.851
I0528 19:58:53.997032 11123 solver.cpp:397]     Test net output #1: loss = 0.326214 (* 1 = 0.326214 loss)
I0528 19:58:54.276198 11123 solver.cpp:218] Iteration 12000 (2.9755 iter/s, 33.6078s/100 iters), loss = 0.422958
I0528 19:58:54.276244 11123 solver.cpp:237]     Train net output #0: loss = 0.422958 (* 1 = 0.422958 loss)
I0528 19:58:54.276252 11123 sgd_solver.cpp:105] Iteration 12000, lr = 0.0094
I0528 19:59:22.886683 11123 solver.cpp:218] Iteration 12100 (3.49531 iter/s, 28.6098s/100 iters), loss = 0.260268
I0528 19:59:22.886852 11123 solver.cpp:237]     Train net output #0: loss = 0.260269 (* 1 = 0.260269 loss)
I0528 19:59:22.886863 11123 sgd_solver.cpp:105] Iteration 12100, lr = 0.009395
I0528 19:59:51.513427 11123 solver.cpp:218] Iteration 12200 (3.49334 iter/s, 28.6259s/100 iters), loss = 0.111274
I0528 19:59:51.513485 11123 solver.cpp:237]     Train net output #0: loss = 0.111275 (* 1 = 0.111275 loss)
I0528 19:59:51.513495 11123 sgd_solver.cpp:105] Iteration 12200, lr = 0.00939
I0528 20:00:06.140856 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:00:20.057518 11123 solver.cpp:218] Iteration 12300 (3.50344 iter/s, 28.5434s/100 iters), loss = 0.179779
I0528 20:00:20.057562 11123 solver.cpp:237]     Train net output #0: loss = 0.179779 (* 1 = 0.179779 loss)
I0528 20:00:20.057570 11123 sgd_solver.cpp:105] Iteration 12300, lr = 0.009385
I0528 20:00:48.178468 11123 solver.cpp:218] Iteration 12400 (3.55616 iter/s, 28.1202s/100 iters), loss = 0.297407
I0528 20:00:48.178635 11123 solver.cpp:237]     Train net output #0: loss = 0.297407 (* 1 = 0.297407 loss)
I0528 20:00:48.178647 11123 sgd_solver.cpp:105] Iteration 12400, lr = 0.00938
I0528 20:01:16.670258 11123 solver.cpp:218] Iteration 12500 (3.50988 iter/s, 28.491s/100 iters), loss = 0.230409
I0528 20:01:16.670311 11123 solver.cpp:237]     Train net output #0: loss = 0.230409 (* 1 = 0.230409 loss)
I0528 20:01:16.670321 11123 sgd_solver.cpp:105] Iteration 12500, lr = 0.009375
I0528 20:01:44.910480 11123 solver.cpp:218] Iteration 12600 (3.54113 iter/s, 28.2395s/100 iters), loss = 0.11091
I0528 20:01:44.910681 11123 solver.cpp:237]     Train net output #0: loss = 0.11091 (* 1 = 0.11091 loss)
I0528 20:01:44.910693 11123 sgd_solver.cpp:105] Iteration 12600, lr = 0.00937
I0528 20:02:13.230139 11123 solver.cpp:218] Iteration 12700 (3.53122 iter/s, 28.3188s/100 iters), loss = 0.314843
I0528 20:02:13.230206 11123 solver.cpp:237]     Train net output #0: loss = 0.314843 (* 1 = 0.314843 loss)
I0528 20:02:13.230217 11123 sgd_solver.cpp:105] Iteration 12700, lr = 0.009365
I0528 20:02:41.666370 11123 solver.cpp:218] Iteration 12800 (3.51673 iter/s, 28.4355s/100 iters), loss = 0.243835
I0528 20:02:41.670958 11123 solver.cpp:237]     Train net output #0: loss = 0.243835 (* 1 = 0.243835 loss)
I0528 20:02:41.670974 11123 sgd_solver.cpp:105] Iteration 12800, lr = 0.00936
I0528 20:03:00.026320 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:03:10.273010 11123 solver.cpp:218] Iteration 12900 (3.49633 iter/s, 28.6014s/100 iters), loss = 0.19241
I0528 20:03:10.273056 11123 solver.cpp:237]     Train net output #0: loss = 0.19241 (* 1 = 0.19241 loss)
I0528 20:03:10.273066 11123 sgd_solver.cpp:105] Iteration 12900, lr = 0.009355
I0528 20:03:38.425412 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_13000.caffemodel
I0528 20:03:38.737287 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_13000.solverstate
I0528 20:03:38.909860 11123 solver.cpp:330] Iteration 13000, Testing net (#0)
I0528 20:03:40.497881 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:03:43.454092 11123 solver.cpp:397]     Test net output #0: accuracy = 0.77
I0528 20:03:43.454131 11123 solver.cpp:397]     Test net output #1: loss = 0.539432 (* 1 = 0.539432 loss)
I0528 20:03:43.739058 11123 solver.cpp:218] Iteration 13000 (2.98817 iter/s, 33.4653s/100 iters), loss = 0.308985
I0528 20:03:43.739116 11123 solver.cpp:237]     Train net output #0: loss = 0.308985 (* 1 = 0.308985 loss)
I0528 20:03:43.739125 11123 sgd_solver.cpp:105] Iteration 13000, lr = 0.00935
I0528 20:04:12.347266 11123 solver.cpp:218] Iteration 13100 (3.49559 iter/s, 28.6075s/100 iters), loss = 0.325465
I0528 20:04:12.347419 11123 solver.cpp:237]     Train net output #0: loss = 0.325465 (* 1 = 0.325465 loss)
I0528 20:04:12.347430 11123 sgd_solver.cpp:105] Iteration 13100, lr = 0.009345
I0528 20:04:41.291920 11123 solver.cpp:218] Iteration 13200 (3.45496 iter/s, 28.9439s/100 iters), loss = 0.145575
I0528 20:04:41.291980 11123 solver.cpp:237]     Train net output #0: loss = 0.145575 (* 1 = 0.145575 loss)
I0528 20:04:41.291990 11123 sgd_solver.cpp:105] Iteration 13200, lr = 0.00934
I0528 20:05:10.488528 11123 solver.cpp:218] Iteration 13300 (3.42514 iter/s, 29.1959s/100 iters), loss = 0.334689
I0528 20:05:10.488692 11123 solver.cpp:237]     Train net output #0: loss = 0.334689 (* 1 = 0.334689 loss)
I0528 20:05:10.488703 11123 sgd_solver.cpp:105] Iteration 13300, lr = 0.009335
I0528 20:05:38.971987 11123 solver.cpp:218] Iteration 13400 (3.51091 iter/s, 28.4827s/100 iters), loss = 0.682379
I0528 20:05:38.972050 11123 solver.cpp:237]     Train net output #0: loss = 0.682379 (* 1 = 0.682379 loss)
I0528 20:05:38.972062 11123 sgd_solver.cpp:105] Iteration 13400, lr = 0.00933
I0528 20:06:01.571609 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:06:08.097280 11123 solver.cpp:218] Iteration 13500 (3.43353 iter/s, 29.1246s/100 iters), loss = 0.443758
I0528 20:06:08.097334 11123 solver.cpp:237]     Train net output #0: loss = 0.443758 (* 1 = 0.443758 loss)
I0528 20:06:08.097342 11123 sgd_solver.cpp:105] Iteration 13500, lr = 0.009325
I0528 20:06:37.110549 11123 solver.cpp:218] Iteration 13600 (3.44678 iter/s, 29.0126s/100 iters), loss = 0.334696
I0528 20:06:37.110692 11123 solver.cpp:237]     Train net output #0: loss = 0.334696 (* 1 = 0.334696 loss)
I0528 20:06:37.110703 11123 sgd_solver.cpp:105] Iteration 13600, lr = 0.00932
I0528 20:07:05.568913 11123 solver.cpp:218] Iteration 13700 (3.514 iter/s, 28.4576s/100 iters), loss = 0.153345
I0528 20:07:05.568991 11123 solver.cpp:237]     Train net output #0: loss = 0.153345 (* 1 = 0.153345 loss)
I0528 20:07:05.569007 11123 sgd_solver.cpp:105] Iteration 13700, lr = 0.009315
I0528 20:07:34.093646 11123 solver.cpp:218] Iteration 13800 (3.50582 iter/s, 28.524s/100 iters), loss = 0.236233
I0528 20:07:34.093798 11123 solver.cpp:237]     Train net output #0: loss = 0.236233 (* 1 = 0.236233 loss)
I0528 20:07:34.093809 11123 sgd_solver.cpp:105] Iteration 13800, lr = 0.00931
I0528 20:08:02.394297 11123 solver.cpp:218] Iteration 13900 (3.53358 iter/s, 28.2999s/100 iters), loss = 0.34287
I0528 20:08:02.394342 11123 solver.cpp:237]     Train net output #0: loss = 0.342869 (* 1 = 0.342869 loss)
I0528 20:08:02.394351 11123 sgd_solver.cpp:105] Iteration 13900, lr = 0.009305
I0528 20:08:30.958523 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_14000.caffemodel
I0528 20:08:31.265709 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_14000.solverstate
I0528 20:08:31.411571 11123 solver.cpp:330] Iteration 14000, Testing net (#0)
I0528 20:08:34.677610 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:08:36.135047 11123 solver.cpp:397]     Test net output #0: accuracy = 0.854
I0528 20:08:36.135089 11123 solver.cpp:397]     Test net output #1: loss = 0.323634 (* 1 = 0.323634 loss)
I0528 20:08:36.431293 11123 solver.cpp:218] Iteration 14000 (2.93805 iter/s, 34.0362s/100 iters), loss = 0.381045
I0528 20:08:36.431352 11123 solver.cpp:237]     Train net output #0: loss = 0.381045 (* 1 = 0.381045 loss)
I0528 20:08:36.431363 11123 sgd_solver.cpp:105] Iteration 14000, lr = 0.0093
I0528 20:09:01.772846 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:09:04.556507 11123 solver.cpp:218] Iteration 14100 (3.55561 iter/s, 28.1245s/100 iters), loss = 0.214379
I0528 20:09:04.556552 11123 solver.cpp:237]     Train net output #0: loss = 0.214379 (* 1 = 0.214379 loss)
I0528 20:09:04.556560 11123 sgd_solver.cpp:105] Iteration 14100, lr = 0.009295
I0528 20:09:32.530027 11123 solver.cpp:218] Iteration 14200 (3.57489 iter/s, 27.9729s/100 iters), loss = 0.257412
I0528 20:09:32.530230 11123 solver.cpp:237]     Train net output #0: loss = 0.257412 (* 1 = 0.257412 loss)
I0528 20:09:32.530257 11123 sgd_solver.cpp:105] Iteration 14200, lr = 0.00929
I0528 20:10:00.518604 11123 solver.cpp:218] Iteration 14300 (3.57299 iter/s, 27.9878s/100 iters), loss = 0.581065
I0528 20:10:00.518646 11123 solver.cpp:237]     Train net output #0: loss = 0.581065 (* 1 = 0.581065 loss)
I0528 20:10:00.518656 11123 sgd_solver.cpp:105] Iteration 14300, lr = 0.009285
I0528 20:10:28.482615 11123 solver.cpp:218] Iteration 14400 (3.57611 iter/s, 27.9634s/100 iters), loss = 0.248053
I0528 20:10:28.482797 11123 solver.cpp:237]     Train net output #0: loss = 0.248053 (* 1 = 0.248053 loss)
I0528 20:10:28.482808 11123 sgd_solver.cpp:105] Iteration 14400, lr = 0.00928
I0528 20:10:56.458465 11123 solver.cpp:218] Iteration 14500 (3.57461 iter/s, 27.9751s/100 iters), loss = 0.464187
I0528 20:10:56.458520 11123 solver.cpp:237]     Train net output #0: loss = 0.464187 (* 1 = 0.464187 loss)
I0528 20:10:56.458529 11123 sgd_solver.cpp:105] Iteration 14500, lr = 0.009275
I0528 20:11:24.477015 11123 solver.cpp:218] Iteration 14600 (3.56915 iter/s, 28.0179s/100 iters), loss = 0.138484
I0528 20:11:24.477171 11123 solver.cpp:237]     Train net output #0: loss = 0.138484 (* 1 = 0.138484 loss)
I0528 20:11:24.477183 11123 sgd_solver.cpp:105] Iteration 14600, lr = 0.00927
I0528 20:11:52.478129 11123 solver.cpp:218] Iteration 14700 (3.57138 iter/s, 28.0004s/100 iters), loss = 0.275201
I0528 20:11:52.478174 11123 solver.cpp:237]     Train net output #0: loss = 0.275201 (* 1 = 0.275201 loss)
I0528 20:11:52.478183 11123 sgd_solver.cpp:105] Iteration 14700, lr = 0.009265
I0528 20:11:53.334684 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:12:20.465522 11123 solver.cpp:218] Iteration 14800 (3.57319 iter/s, 27.9862s/100 iters), loss = 0.328182
I0528 20:12:20.465767 11123 solver.cpp:237]     Train net output #0: loss = 0.328182 (* 1 = 0.328182 loss)
I0528 20:12:20.465780 11123 sgd_solver.cpp:105] Iteration 14800, lr = 0.00926
I0528 20:12:48.447556 11123 solver.cpp:218] Iteration 14900 (3.57392 iter/s, 27.9805s/100 iters), loss = 0.111756
I0528 20:12:48.447602 11123 solver.cpp:237]     Train net output #0: loss = 0.111756 (* 1 = 0.111756 loss)
I0528 20:12:48.447609 11123 sgd_solver.cpp:105] Iteration 14900, lr = 0.009255
I0528 20:13:16.167296 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_15000.caffemodel
I0528 20:13:16.475545 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_15000.solverstate
I0528 20:13:16.622189 11123 solver.cpp:330] Iteration 15000, Testing net (#0)
I0528 20:13:21.071382 11123 solver.cpp:397]     Test net output #0: accuracy = 0.827
I0528 20:13:21.071420 11123 solver.cpp:397]     Test net output #1: loss = 0.371256 (* 1 = 0.371256 loss)
I0528 20:13:21.347190 11123 solver.cpp:218] Iteration 15000 (3.03969 iter/s, 32.8981s/100 iters), loss = 0.105142
I0528 20:13:21.347237 11123 solver.cpp:237]     Train net output #0: loss = 0.105142 (* 1 = 0.105142 loss)
I0528 20:13:21.347246 11123 sgd_solver.cpp:105] Iteration 15000, lr = 0.00925
I0528 20:13:49.377813 11123 solver.cpp:218] Iteration 15100 (3.56769 iter/s, 28.0293s/100 iters), loss = 0.289181
I0528 20:13:49.377976 11123 solver.cpp:237]     Train net output #0: loss = 0.289181 (* 1 = 0.289181 loss)
I0528 20:13:49.377987 11123 sgd_solver.cpp:105] Iteration 15100, lr = 0.009245
I0528 20:14:17.393402 11123 solver.cpp:218] Iteration 15200 (3.56962 iter/s, 28.0142s/100 iters), loss = 0.131042
I0528 20:14:17.393446 11123 solver.cpp:237]     Train net output #0: loss = 0.131041 (* 1 = 0.131041 loss)
I0528 20:14:17.393455 11123 sgd_solver.cpp:105] Iteration 15200, lr = 0.00924
I0528 20:14:45.366253 11123 solver.cpp:218] Iteration 15300 (3.57505 iter/s, 27.9716s/100 iters), loss = 0.195122
I0528 20:14:45.366415 11123 solver.cpp:237]     Train net output #0: loss = 0.195122 (* 1 = 0.195122 loss)
I0528 20:14:45.366426 11123 sgd_solver.cpp:105] Iteration 15300, lr = 0.009235
I0528 20:14:49.582866 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:15:13.365021 11123 solver.cpp:218] Iteration 15400 (3.57175 iter/s, 27.9975s/100 iters), loss = 0.110679
I0528 20:15:13.365067 11123 solver.cpp:237]     Train net output #0: loss = 0.110678 (* 1 = 0.110678 loss)
I0528 20:15:13.365089 11123 sgd_solver.cpp:105] Iteration 15400, lr = 0.00923
I0528 20:15:41.378151 11123 solver.cpp:218] Iteration 15500 (3.5699 iter/s, 28.012s/100 iters), loss = 0.164846
I0528 20:15:41.378291 11123 solver.cpp:237]     Train net output #0: loss = 0.164846 (* 1 = 0.164846 loss)
I0528 20:15:41.378304 11123 sgd_solver.cpp:105] Iteration 15500, lr = 0.009225
I0528 20:16:09.384450 11123 solver.cpp:218] Iteration 15600 (3.57078 iter/s, 28.0051s/100 iters), loss = 0.345814
I0528 20:16:09.384497 11123 solver.cpp:237]     Train net output #0: loss = 0.345813 (* 1 = 0.345813 loss)
I0528 20:16:09.384506 11123 sgd_solver.cpp:105] Iteration 15600, lr = 0.00922
I0528 20:16:37.387094 11123 solver.cpp:218] Iteration 15700 (3.57124 iter/s, 28.0015s/100 iters), loss = 0.125313
I0528 20:16:37.387298 11123 solver.cpp:237]     Train net output #0: loss = 0.125313 (* 1 = 0.125313 loss)
I0528 20:16:37.387310 11123 sgd_solver.cpp:105] Iteration 15700, lr = 0.009215
I0528 20:17:05.400223 11123 solver.cpp:218] Iteration 15800 (3.56992 iter/s, 28.0119s/100 iters), loss = 0.0752225
I0528 20:17:05.400265 11123 solver.cpp:237]     Train net output #0: loss = 0.0752221 (* 1 = 0.0752221 loss)
I0528 20:17:05.400274 11123 sgd_solver.cpp:105] Iteration 15800, lr = 0.00921
I0528 20:17:33.401217 11123 solver.cpp:218] Iteration 15900 (3.57144 iter/s, 27.9999s/100 iters), loss = 0.290795
I0528 20:17:33.401397 11123 solver.cpp:237]     Train net output #0: loss = 0.290795 (* 1 = 0.290795 loss)
I0528 20:17:33.401427 11123 sgd_solver.cpp:105] Iteration 15900, lr = 0.009205
I0528 20:17:41.254575 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:18:01.132050 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_16000.caffemodel
I0528 20:18:01.438801 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_16000.solverstate
I0528 20:18:01.584146 11123 solver.cpp:330] Iteration 16000, Testing net (#0)
I0528 20:18:01.725114 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:18:06.030084 11123 solver.cpp:397]     Test net output #0: accuracy = 0.843
I0528 20:18:06.030241 11123 solver.cpp:397]     Test net output #1: loss = 0.351488 (* 1 = 0.351488 loss)
I0528 20:18:06.306787 11123 solver.cpp:218] Iteration 16000 (3.03912 iter/s, 32.9042s/100 iters), loss = 0.483254
I0528 20:18:06.306844 11123 solver.cpp:237]     Train net output #0: loss = 0.483254 (* 1 = 0.483254 loss)
I0528 20:18:06.306854 11123 sgd_solver.cpp:105] Iteration 16000, lr = 0.0092
I0528 20:18:34.324282 11123 solver.cpp:218] Iteration 16100 (3.56933 iter/s, 28.0164s/100 iters), loss = 0.0995081
I0528 20:18:34.324326 11123 solver.cpp:237]     Train net output #0: loss = 0.0995076 (* 1 = 0.0995076 loss)
I0528 20:18:34.324335 11123 sgd_solver.cpp:105] Iteration 16100, lr = 0.009195
I0528 20:19:02.356675 11123 solver.cpp:218] Iteration 16200 (3.56743 iter/s, 28.0314s/100 iters), loss = 0.116737
I0528 20:19:02.356859 11123 solver.cpp:237]     Train net output #0: loss = 0.116737 (* 1 = 0.116737 loss)
I0528 20:19:02.356883 11123 sgd_solver.cpp:105] Iteration 16200, lr = 0.00919
I0528 20:19:30.386782 11123 solver.cpp:218] Iteration 16300 (3.56774 iter/s, 28.029s/100 iters), loss = 0.131892
I0528 20:19:30.386826 11123 solver.cpp:237]     Train net output #0: loss = 0.131891 (* 1 = 0.131891 loss)
I0528 20:19:30.386834 11123 sgd_solver.cpp:105] Iteration 16300, lr = 0.009185
I0528 20:19:58.404886 11123 solver.cpp:218] Iteration 16400 (3.56925 iter/s, 28.0171s/100 iters), loss = 0.156036
I0528 20:19:58.405050 11123 solver.cpp:237]     Train net output #0: loss = 0.156036 (* 1 = 0.156036 loss)
I0528 20:19:58.405061 11123 sgd_solver.cpp:105] Iteration 16400, lr = 0.00918
I0528 20:20:26.418185 11123 solver.cpp:218] Iteration 16500 (3.56987 iter/s, 28.0122s/100 iters), loss = 0.174432
I0528 20:20:26.418231 11123 solver.cpp:237]     Train net output #0: loss = 0.174431 (* 1 = 0.174431 loss)
I0528 20:20:26.418239 11123 sgd_solver.cpp:105] Iteration 16500, lr = 0.009175
I0528 20:20:37.920497 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:20:54.418730 11123 solver.cpp:218] Iteration 16600 (3.57148 iter/s, 27.9996s/100 iters), loss = 0.152415
I0528 20:20:54.418777 11123 solver.cpp:237]     Train net output #0: loss = 0.152414 (* 1 = 0.152414 loss)
I0528 20:20:54.418787 11123 sgd_solver.cpp:105] Iteration 16600, lr = 0.00917
I0528 20:21:22.439957 11123 solver.cpp:218] Iteration 16700 (3.56885 iter/s, 28.0203s/100 iters), loss = 0.18287
I0528 20:21:22.440124 11123 solver.cpp:237]     Train net output #0: loss = 0.18287 (* 1 = 0.18287 loss)
I0528 20:21:22.440135 11123 sgd_solver.cpp:105] Iteration 16700, lr = 0.009165
I0528 20:21:50.436218 11123 solver.cpp:218] Iteration 16800 (3.57204 iter/s, 27.9952s/100 iters), loss = 0.24264
I0528 20:21:50.436260 11123 solver.cpp:237]     Train net output #0: loss = 0.242639 (* 1 = 0.242639 loss)
I0528 20:21:50.436269 11123 sgd_solver.cpp:105] Iteration 16800, lr = 0.00916
I0528 20:22:18.419143 11123 solver.cpp:218] Iteration 16900 (3.57373 iter/s, 27.982s/100 iters), loss = 0.057694
I0528 20:22:18.419347 11123 solver.cpp:237]     Train net output #0: loss = 0.0576936 (* 1 = 0.0576936 loss)
I0528 20:22:18.419358 11123 sgd_solver.cpp:105] Iteration 16900, lr = 0.009155
I0528 20:22:46.112903 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_17000.caffemodel
I0528 20:22:46.419051 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_17000.solverstate
I0528 20:22:46.564992 11123 solver.cpp:330] Iteration 17000, Testing net (#0)
I0528 20:22:48.217952 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:22:51.015015 11123 solver.cpp:397]     Test net output #0: accuracy = 0.853
I0528 20:22:51.015208 11123 solver.cpp:397]     Test net output #1: loss = 0.328481 (* 1 = 0.328481 loss)
I0528 20:22:51.291939 11123 solver.cpp:218] Iteration 17000 (3.04214 iter/s, 32.8716s/100 iters), loss = 0.254407
I0528 20:22:51.291980 11123 solver.cpp:237]     Train net output #0: loss = 0.254407 (* 1 = 0.254407 loss)
I0528 20:22:51.291990 11123 sgd_solver.cpp:105] Iteration 17000, lr = 0.00915
I0528 20:23:19.295362 11123 solver.cpp:218] Iteration 17100 (3.57111 iter/s, 28.0025s/100 iters), loss = 0.0617646
I0528 20:23:19.295404 11123 solver.cpp:237]     Train net output #0: loss = 0.0617642 (* 1 = 0.0617642 loss)
I0528 20:23:19.295413 11123 sgd_solver.cpp:105] Iteration 17100, lr = 0.009145
I0528 20:23:34.428483 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:23:47.289297 11123 solver.cpp:218] Iteration 17200 (3.57232 iter/s, 27.993s/100 iters), loss = 0.164142
I0528 20:23:47.289342 11123 solver.cpp:237]     Train net output #0: loss = 0.164142 (* 1 = 0.164142 loss)
I0528 20:23:47.289350 11123 sgd_solver.cpp:105] Iteration 17200, lr = 0.00914
I0528 20:24:15.297345 11123 solver.cpp:218] Iteration 17300 (3.57052 iter/s, 28.0072s/100 iters), loss = 0.321595
I0528 20:24:15.297518 11123 solver.cpp:237]     Train net output #0: loss = 0.321595 (* 1 = 0.321595 loss)
I0528 20:24:15.297529 11123 sgd_solver.cpp:105] Iteration 17300, lr = 0.009135
I0528 20:24:43.292033 11123 solver.cpp:218] Iteration 17400 (3.57224 iter/s, 27.9937s/100 iters), loss = 0.406095
I0528 20:24:43.292078 11123 solver.cpp:237]     Train net output #0: loss = 0.406095 (* 1 = 0.406095 loss)
I0528 20:24:43.292088 11123 sgd_solver.cpp:105] Iteration 17400, lr = 0.00913
I0528 20:25:11.298753 11123 solver.cpp:218] Iteration 17500 (3.57068 iter/s, 28.0058s/100 iters), loss = 0.171661
I0528 20:25:11.298918 11123 solver.cpp:237]     Train net output #0: loss = 0.171661 (* 1 = 0.171661 loss)
I0528 20:25:11.298929 11123 sgd_solver.cpp:105] Iteration 17500, lr = 0.009125
I0528 20:25:39.321993 11123 solver.cpp:218] Iteration 17600 (3.56859 iter/s, 28.0223s/100 iters), loss = 0.0764696
I0528 20:25:39.322036 11123 solver.cpp:237]     Train net output #0: loss = 0.0764691 (* 1 = 0.0764691 loss)
I0528 20:25:39.322046 11123 sgd_solver.cpp:105] Iteration 17600, lr = 0.00912
I0528 20:26:07.337254 11123 solver.cpp:218] Iteration 17700 (3.56959 iter/s, 28.0144s/100 iters), loss = 0.12211
I0528 20:26:07.337407 11123 solver.cpp:237]     Train net output #0: loss = 0.122109 (* 1 = 0.122109 loss)
I0528 20:26:07.337419 11123 sgd_solver.cpp:105] Iteration 17700, lr = 0.009115
I0528 20:26:26.106247 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:26:35.335391 11123 solver.cpp:218] Iteration 17800 (3.57179 iter/s, 27.9972s/100 iters), loss = 0.42461
I0528 20:26:35.335448 11123 solver.cpp:237]     Train net output #0: loss = 0.424609 (* 1 = 0.424609 loss)
I0528 20:26:35.335456 11123 sgd_solver.cpp:105] Iteration 17800, lr = 0.00911
I0528 20:27:03.333775 11123 solver.cpp:218] Iteration 17900 (3.57174 iter/s, 27.9975s/100 iters), loss = 0.148848
I0528 20:27:03.333940 11123 solver.cpp:237]     Train net output #0: loss = 0.148847 (* 1 = 0.148847 loss)
I0528 20:27:03.333951 11123 sgd_solver.cpp:105] Iteration 17900, lr = 0.009105
I0528 20:27:31.083627 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_18000.caffemodel
I0528 20:27:31.393591 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_18000.solverstate
I0528 20:27:31.539549 11123 solver.cpp:330] Iteration 18000, Testing net (#0)
I0528 20:27:34.703233 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:27:35.987720 11123 solver.cpp:397]     Test net output #0: accuracy = 0.852
I0528 20:27:35.987762 11123 solver.cpp:397]     Test net output #1: loss = 0.382642 (* 1 = 0.382642 loss)
I0528 20:27:36.265440 11123 solver.cpp:218] Iteration 18000 (3.03669 iter/s, 32.9306s/100 iters), loss = 0.195128
I0528 20:27:36.265483 11123 solver.cpp:237]     Train net output #0: loss = 0.195127 (* 1 = 0.195127 loss)
I0528 20:27:36.265492 11123 sgd_solver.cpp:105] Iteration 18000, lr = 0.0091
I0528 20:28:04.280426 11123 solver.cpp:218] Iteration 18100 (3.56963 iter/s, 28.0141s/100 iters), loss = 0.100686
I0528 20:28:04.280472 11123 solver.cpp:237]     Train net output #0: loss = 0.100686 (* 1 = 0.100686 loss)
I0528 20:28:04.280480 11123 sgd_solver.cpp:105] Iteration 18100, lr = 0.009095
I0528 20:28:32.286732 11123 solver.cpp:218] Iteration 18200 (3.57073 iter/s, 28.0055s/100 iters), loss = 0.170415
I0528 20:28:32.286906 11123 solver.cpp:237]     Train net output #0: loss = 0.170414 (* 1 = 0.170414 loss)
I0528 20:28:32.286917 11123 sgd_solver.cpp:105] Iteration 18200, lr = 0.00909
I0528 20:29:00.319954 11123 solver.cpp:218] Iteration 18300 (3.56732 iter/s, 28.0323s/100 iters), loss = 0.10877
I0528 20:29:00.320000 11123 solver.cpp:237]     Train net output #0: loss = 0.10877 (* 1 = 0.10877 loss)
I0528 20:29:00.320008 11123 sgd_solver.cpp:105] Iteration 18300, lr = 0.009085
I0528 20:29:22.473934 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:29:28.337947 11123 solver.cpp:218] Iteration 18400 (3.56924 iter/s, 28.0172s/100 iters), loss = 0.120292
I0528 20:29:28.337992 11123 solver.cpp:237]     Train net output #0: loss = 0.120291 (* 1 = 0.120291 loss)
I0528 20:29:28.338001 11123 sgd_solver.cpp:105] Iteration 18400, lr = 0.00908
I0528 20:29:56.344358 11123 solver.cpp:218] Iteration 18500 (3.57072 iter/s, 28.0056s/100 iters), loss = 0.0333759
I0528 20:29:56.344561 11123 solver.cpp:237]     Train net output #0: loss = 0.0333751 (* 1 = 0.0333751 loss)
I0528 20:29:56.344573 11123 sgd_solver.cpp:105] Iteration 18500, lr = 0.009075
I0528 20:30:24.279592 11123 solver.cpp:218] Iteration 18600 (3.57983 iter/s, 27.9343s/100 iters), loss = 0.260665
I0528 20:30:24.279642 11123 solver.cpp:237]     Train net output #0: loss = 0.260665 (* 1 = 0.260665 loss)
I0528 20:30:24.279655 11123 sgd_solver.cpp:105] Iteration 18600, lr = 0.00907
I0528 20:30:52.216693 11123 solver.cpp:218] Iteration 18700 (3.57957 iter/s, 27.9363s/100 iters), loss = 0.105438
I0528 20:30:52.216830 11123 solver.cpp:237]     Train net output #0: loss = 0.105437 (* 1 = 0.105437 loss)
I0528 20:30:52.216851 11123 sgd_solver.cpp:105] Iteration 18700, lr = 0.009065
I0528 20:31:20.173220 11123 solver.cpp:218] Iteration 18800 (3.5771 iter/s, 27.9556s/100 iters), loss = 0.448429
I0528 20:31:20.173261 11123 solver.cpp:237]     Train net output #0: loss = 0.448428 (* 1 = 0.448428 loss)
I0528 20:31:20.173270 11123 sgd_solver.cpp:105] Iteration 18800, lr = 0.00906
I0528 20:31:48.106108 11123 solver.cpp:218] Iteration 18900 (3.58011 iter/s, 27.9321s/100 iters), loss = 0.350239
I0528 20:31:48.106266 11123 solver.cpp:237]     Train net output #0: loss = 0.350238 (* 1 = 0.350238 loss)
I0528 20:31:48.106276 11123 sgd_solver.cpp:105] Iteration 18900, lr = 0.009055
I0528 20:32:13.831854 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:32:15.773098 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_19000.caffemodel
I0528 20:32:16.078269 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_19000.solverstate
I0528 20:32:16.266978 11123 solver.cpp:330] Iteration 19000, Testing net (#0)
I0528 20:32:20.707116 11123 solver.cpp:397]     Test net output #0: accuracy = 0.833
I0528 20:32:20.707259 11123 solver.cpp:397]     Test net output #1: loss = 0.395435 (* 1 = 0.395435 loss)
I0528 20:32:20.984069 11123 solver.cpp:218] Iteration 19000 (3.04165 iter/s, 32.8769s/100 iters), loss = 0.3024
I0528 20:32:20.984132 11123 solver.cpp:237]     Train net output #0: loss = 0.302399 (* 1 = 0.302399 loss)
I0528 20:32:20.984140 11123 sgd_solver.cpp:105] Iteration 19000, lr = 0.00905
I0528 20:32:48.981158 11123 solver.cpp:218] Iteration 19100 (3.5719 iter/s, 27.9963s/100 iters), loss = 0.157549
I0528 20:32:48.981202 11123 solver.cpp:237]     Train net output #0: loss = 0.157548 (* 1 = 0.157548 loss)
I0528 20:32:48.981210 11123 sgd_solver.cpp:105] Iteration 19100, lr = 0.009045
I0528 20:33:16.988648 11123 solver.cpp:218] Iteration 19200 (3.57057 iter/s, 28.0067s/100 iters), loss = 0.422902
I0528 20:33:16.988876 11123 solver.cpp:237]     Train net output #0: loss = 0.422901 (* 1 = 0.422901 loss)
I0528 20:33:16.988889 11123 sgd_solver.cpp:105] Iteration 19200, lr = 0.00904
I0528 20:33:44.998158 11123 solver.cpp:218] Iteration 19300 (3.57034 iter/s, 28.0086s/100 iters), loss = 0.133539
I0528 20:33:44.998203 11123 solver.cpp:237]     Train net output #0: loss = 0.133538 (* 1 = 0.133538 loss)
I0528 20:33:44.998211 11123 sgd_solver.cpp:105] Iteration 19300, lr = 0.009035
I0528 20:34:12.994462 11123 solver.cpp:218] Iteration 19400 (3.572 iter/s, 27.9955s/100 iters), loss = 0.0711289
I0528 20:34:12.994669 11123 solver.cpp:237]     Train net output #0: loss = 0.0711277 (* 1 = 0.0711277 loss)
I0528 20:34:12.994681 11123 sgd_solver.cpp:105] Iteration 19400, lr = 0.00903
I0528 20:34:40.990022 11123 solver.cpp:218] Iteration 19500 (3.57212 iter/s, 27.9946s/100 iters), loss = 0.214386
I0528 20:34:40.990068 11123 solver.cpp:237]     Train net output #0: loss = 0.214385 (* 1 = 0.214385 loss)
I0528 20:34:40.990077 11123 sgd_solver.cpp:105] Iteration 19500, lr = 0.009025
I0528 20:35:08.998361 11123 solver.cpp:218] Iteration 19600 (3.57047 iter/s, 28.0076s/100 iters), loss = 0.0235691
I0528 20:35:08.998522 11123 solver.cpp:237]     Train net output #0: loss = 0.0235679 (* 1 = 0.0235679 loss)
I0528 20:35:08.998534 11123 sgd_solver.cpp:105] Iteration 19600, lr = 0.00902
I0528 20:35:10.416867 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:35:37.025513 11123 solver.cpp:218] Iteration 19700 (3.56808 iter/s, 28.0263s/100 iters), loss = 0.0817382
I0528 20:35:37.025560 11123 solver.cpp:237]     Train net output #0: loss = 0.0817371 (* 1 = 0.0817371 loss)
I0528 20:35:37.025569 11123 sgd_solver.cpp:105] Iteration 19700, lr = 0.009015
I0528 20:36:05.030668 11123 solver.cpp:218] Iteration 19800 (3.57087 iter/s, 28.0044s/100 iters), loss = 0.130559
I0528 20:36:05.030827 11123 solver.cpp:237]     Train net output #0: loss = 0.130558 (* 1 = 0.130558 loss)
I0528 20:36:05.030839 11123 sgd_solver.cpp:105] Iteration 19800, lr = 0.00901
I0528 20:36:33.046211 11123 solver.cpp:218] Iteration 19900 (3.56956 iter/s, 28.0147s/100 iters), loss = 0.20644
I0528 20:36:33.046258 11123 solver.cpp:237]     Train net output #0: loss = 0.206438 (* 1 = 0.206438 loss)
I0528 20:36:33.046267 11123 sgd_solver.cpp:105] Iteration 19900, lr = 0.009005
I0528 20:37:00.781373 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_20000.caffemodel
I0528 20:37:01.090311 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_20000.solverstate
I0528 20:37:01.236348 11123 solver.cpp:330] Iteration 20000, Testing net (#0)
I0528 20:37:01.466172 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:37:05.689316 11123 solver.cpp:397]     Test net output #0: accuracy = 0.824
I0528 20:37:05.689357 11123 solver.cpp:397]     Test net output #1: loss = 0.443426 (* 1 = 0.443426 loss)
I0528 20:37:05.966727 11123 solver.cpp:218] Iteration 20000 (3.0377 iter/s, 32.9196s/100 iters), loss = 0.0662766
I0528 20:37:05.966774 11123 solver.cpp:237]     Train net output #0: loss = 0.0662756 (* 1 = 0.0662756 loss)
I0528 20:37:05.966784 11123 sgd_solver.cpp:105] Iteration 20000, lr = 0.009
I0528 20:37:34.010720 11123 solver.cpp:218] Iteration 20100 (3.56592 iter/s, 28.0432s/100 iters), loss = 0.218026
I0528 20:37:34.010887 11123 solver.cpp:237]     Train net output #0: loss = 0.218025 (* 1 = 0.218025 loss)
I0528 20:37:34.010900 11123 sgd_solver.cpp:105] Iteration 20100, lr = 0.008995
I0528 20:38:02.046896 11123 solver.cpp:218] Iteration 20200 (3.56693 iter/s, 28.0353s/100 iters), loss = 0.24166
I0528 20:38:02.046942 11123 solver.cpp:237]     Train net output #0: loss = 0.241659 (* 1 = 0.241659 loss)
I0528 20:38:02.046952 11123 sgd_solver.cpp:105] Iteration 20200, lr = 0.00899
I0528 20:38:07.101012 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:38:30.046864 11123 solver.cpp:218] Iteration 20300 (3.57153 iter/s, 27.9992s/100 iters), loss = 0.0580097
I0528 20:38:30.046911 11123 solver.cpp:237]     Train net output #0: loss = 0.0580089 (* 1 = 0.0580089 loss)
I0528 20:38:30.046923 11123 sgd_solver.cpp:105] Iteration 20300, lr = 0.008985
I0528 20:38:58.039583 11123 solver.cpp:218] Iteration 20400 (3.57246 iter/s, 27.992s/100 iters), loss = 0.094612
I0528 20:38:58.039753 11123 solver.cpp:237]     Train net output #0: loss = 0.0946112 (* 1 = 0.0946112 loss)
I0528 20:38:58.039764 11123 sgd_solver.cpp:105] Iteration 20400, lr = 0.00898
I0528 20:39:26.055562 11123 solver.cpp:218] Iteration 20500 (3.5695 iter/s, 28.0151s/100 iters), loss = 0.0534999
I0528 20:39:26.055609 11123 solver.cpp:237]     Train net output #0: loss = 0.053499 (* 1 = 0.053499 loss)
I0528 20:39:26.055619 11123 sgd_solver.cpp:105] Iteration 20500, lr = 0.008975
I0528 20:39:54.061904 11123 solver.cpp:218] Iteration 20600 (3.57072 iter/s, 28.0056s/100 iters), loss = 0.334477
I0528 20:39:54.062067 11123 solver.cpp:237]     Train net output #0: loss = 0.334476 (* 1 = 0.334476 loss)
I0528 20:39:54.062078 11123 sgd_solver.cpp:105] Iteration 20600, lr = 0.00897
I0528 20:40:22.077719 11123 solver.cpp:218] Iteration 20700 (3.56952 iter/s, 28.0149s/100 iters), loss = 0.113501
I0528 20:40:22.077764 11123 solver.cpp:237]     Train net output #0: loss = 0.1135 (* 1 = 0.1135 loss)
I0528 20:40:22.077774 11123 sgd_solver.cpp:105] Iteration 20700, lr = 0.008965
I0528 20:40:50.091177 11123 solver.cpp:218] Iteration 20800 (3.56981 iter/s, 28.0127s/100 iters), loss = 0.100679
I0528 20:40:50.091462 11123 solver.cpp:237]     Train net output #0: loss = 0.100678 (* 1 = 0.100678 loss)
I0528 20:40:50.091473 11123 sgd_solver.cpp:105] Iteration 20800, lr = 0.00896
I0528 20:40:58.786813 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:41:18.105651 11123 solver.cpp:218] Iteration 20900 (3.56971 iter/s, 28.0135s/100 iters), loss = 0.259384
I0528 20:41:18.105698 11123 solver.cpp:237]     Train net output #0: loss = 0.259382 (* 1 = 0.259382 loss)
I0528 20:41:18.105707 11123 sgd_solver.cpp:105] Iteration 20900, lr = 0.008955
I0528 20:41:45.838253 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_21000.caffemodel
I0528 20:41:46.144359 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_21000.solverstate
I0528 20:41:46.290261 11123 solver.cpp:330] Iteration 21000, Testing net (#0)
I0528 20:41:48.029690 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:41:50.740020 11123 solver.cpp:397]     Test net output #0: accuracy = 0.854
I0528 20:41:50.740073 11123 solver.cpp:397]     Test net output #1: loss = 0.319587 (* 1 = 0.319587 loss)
I0528 20:41:51.017508 11123 solver.cpp:218] Iteration 21000 (3.0385 iter/s, 32.911s/100 iters), loss = 0.0334179
I0528 20:41:51.017560 11123 solver.cpp:237]     Train net output #0: loss = 0.0334168 (* 1 = 0.0334168 loss)
I0528 20:41:51.017571 11123 sgd_solver.cpp:105] Iteration 21000, lr = 0.00895
I0528 20:42:19.002532 11123 solver.cpp:218] Iteration 21100 (3.57344 iter/s, 27.9843s/100 iters), loss = 0.0658464
I0528 20:42:19.002723 11123 solver.cpp:237]     Train net output #0: loss = 0.0658453 (* 1 = 0.0658453 loss)
I0528 20:42:19.002735 11123 sgd_solver.cpp:105] Iteration 21100, lr = 0.008945
I0528 20:42:46.982878 11123 solver.cpp:218] Iteration 21200 (3.57405 iter/s, 27.9794s/100 iters), loss = 0.0718812
I0528 20:42:46.982928 11123 solver.cpp:237]     Train net output #0: loss = 0.0718801 (* 1 = 0.0718801 loss)
I0528 20:42:46.982936 11123 sgd_solver.cpp:105] Iteration 21200, lr = 0.00894
I0528 20:43:14.953814 11123 solver.cpp:218] Iteration 21300 (3.57524 iter/s, 27.9702s/100 iters), loss = 0.141915
I0528 20:43:14.954015 11123 solver.cpp:237]     Train net output #0: loss = 0.141914 (* 1 = 0.141914 loss)
I0528 20:43:14.954026 11123 sgd_solver.cpp:105] Iteration 21300, lr = 0.008935
I0528 20:43:42.923823 11123 solver.cpp:218] Iteration 21400 (3.57537 iter/s, 27.9691s/100 iters), loss = 0.118143
I0528 20:43:42.923866 11123 solver.cpp:237]     Train net output #0: loss = 0.118142 (* 1 = 0.118142 loss)
I0528 20:43:42.923876 11123 sgd_solver.cpp:105] Iteration 21400, lr = 0.00893
I0528 20:43:54.963840 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:44:10.898630 11123 solver.cpp:218] Iteration 21500 (3.57474 iter/s, 27.9741s/100 iters), loss = 0.30914
I0528 20:44:10.898680 11123 solver.cpp:237]     Train net output #0: loss = 0.309139 (* 1 = 0.309139 loss)
I0528 20:44:10.898689 11123 sgd_solver.cpp:105] Iteration 21500, lr = 0.008925
I0528 20:44:38.904196 11123 solver.cpp:218] Iteration 21600 (3.57082 iter/s, 28.0048s/100 iters), loss = 0.087448
I0528 20:44:38.904346 11123 solver.cpp:237]     Train net output #0: loss = 0.0874468 (* 1 = 0.0874468 loss)
I0528 20:44:38.904358 11123 sgd_solver.cpp:105] Iteration 21600, lr = 0.00892
I0528 20:45:06.918712 11123 solver.cpp:218] Iteration 21700 (3.56969 iter/s, 28.0137s/100 iters), loss = 0.394434
I0528 20:45:06.918768 11123 solver.cpp:237]     Train net output #0: loss = 0.394433 (* 1 = 0.394433 loss)
I0528 20:45:06.918777 11123 sgd_solver.cpp:105] Iteration 21700, lr = 0.008915
I0528 20:45:34.923554 11123 solver.cpp:218] Iteration 21800 (3.57091 iter/s, 28.0041s/100 iters), loss = 0.207439
I0528 20:45:34.923765 11123 solver.cpp:237]     Train net output #0: loss = 0.207438 (* 1 = 0.207438 loss)
I0528 20:45:34.923777 11123 sgd_solver.cpp:105] Iteration 21800, lr = 0.00891
I0528 20:46:02.926100 11123 solver.cpp:218] Iteration 21900 (3.57122 iter/s, 28.0017s/100 iters), loss = 0.0191862
I0528 20:46:02.926159 11123 solver.cpp:237]     Train net output #0: loss = 0.019185 (* 1 = 0.019185 loss)
I0528 20:46:02.926167 11123 sgd_solver.cpp:105] Iteration 21900, lr = 0.008905
I0528 20:46:30.654335 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_22000.caffemodel
I0528 20:46:31.098335 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_22000.solverstate
I0528 20:46:31.244956 11123 solver.cpp:330] Iteration 22000, Testing net (#0)
I0528 20:46:34.494729 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:46:35.691447 11123 solver.cpp:397]     Test net output #0: accuracy = 0.872001
I0528 20:46:35.691490 11123 solver.cpp:397]     Test net output #1: loss = 0.308712 (* 1 = 0.308712 loss)
I0528 20:46:35.967232 11123 solver.cpp:218] Iteration 22000 (3.02661 iter/s, 33.0402s/100 iters), loss = 0.242323
I0528 20:46:35.967285 11123 solver.cpp:237]     Train net output #0: loss = 0.242321 (* 1 = 0.242321 loss)
I0528 20:46:35.967309 11123 sgd_solver.cpp:105] Iteration 22000, lr = 0.0089
I0528 20:46:51.648378 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:47:03.948484 11123 solver.cpp:218] Iteration 22100 (3.57392 iter/s, 27.9805s/100 iters), loss = 0.253847
I0528 20:47:03.948655 11123 solver.cpp:237]     Train net output #0: loss = 0.253845 (* 1 = 0.253845 loss)
I0528 20:47:03.948673 11123 sgd_solver.cpp:105] Iteration 22100, lr = 0.008895
I0528 20:47:31.922472 11123 solver.cpp:218] Iteration 22200 (3.57486 iter/s, 27.9731s/100 iters), loss = 0.0460061
I0528 20:47:31.922523 11123 solver.cpp:237]     Train net output #0: loss = 0.0460047 (* 1 = 0.0460047 loss)
I0528 20:47:31.922535 11123 sgd_solver.cpp:105] Iteration 22200, lr = 0.00889
I0528 20:47:59.885689 11123 solver.cpp:218] Iteration 22300 (3.57622 iter/s, 27.9625s/100 iters), loss = 0.215386
I0528 20:47:59.885891 11123 solver.cpp:237]     Train net output #0: loss = 0.215385 (* 1 = 0.215385 loss)
I0528 20:47:59.885918 11123 sgd_solver.cpp:105] Iteration 22300, lr = 0.008885
I0528 20:48:27.871433 11123 solver.cpp:218] Iteration 22400 (3.57336 iter/s, 27.9848s/100 iters), loss = 0.0658493
I0528 20:48:27.871481 11123 solver.cpp:237]     Train net output #0: loss = 0.0658478 (* 1 = 0.0658478 loss)
I0528 20:48:27.871495 11123 sgd_solver.cpp:105] Iteration 22400, lr = 0.00888
I0528 20:48:55.830499 11123 solver.cpp:218] Iteration 22500 (3.57675 iter/s, 27.9583s/100 iters), loss = 0.0474441
I0528 20:48:55.830691 11123 solver.cpp:237]     Train net output #0: loss = 0.0474427 (* 1 = 0.0474427 loss)
I0528 20:48:55.830709 11123 sgd_solver.cpp:105] Iteration 22500, lr = 0.008875
I0528 20:49:23.819870 11123 solver.cpp:218] Iteration 22600 (3.5729 iter/s, 27.9885s/100 iters), loss = 0.0586774
I0528 20:49:23.819916 11123 solver.cpp:237]     Train net output #0: loss = 0.058676 (* 1 = 0.058676 loss)
I0528 20:49:23.819926 11123 sgd_solver.cpp:105] Iteration 22600, lr = 0.00887
I0528 20:49:43.136940 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:49:51.783414 11123 solver.cpp:218] Iteration 22700 (3.57618 iter/s, 27.9628s/100 iters), loss = 0.192264
I0528 20:49:51.783462 11123 solver.cpp:237]     Train net output #0: loss = 0.192262 (* 1 = 0.192262 loss)
I0528 20:49:51.783481 11123 sgd_solver.cpp:105] Iteration 22700, lr = 0.008865
I0528 20:50:19.742061 11123 solver.cpp:218] Iteration 22800 (3.57681 iter/s, 27.9579s/100 iters), loss = 0.115733
I0528 20:50:19.742260 11123 solver.cpp:237]     Train net output #0: loss = 0.115732 (* 1 = 0.115732 loss)
I0528 20:50:19.742271 11123 sgd_solver.cpp:105] Iteration 22800, lr = 0.00886
I0528 20:50:47.683418 11123 solver.cpp:218] Iteration 22900 (3.57903 iter/s, 27.9405s/100 iters), loss = 0.375589
I0528 20:50:47.683466 11123 solver.cpp:237]     Train net output #0: loss = 0.375588 (* 1 = 0.375588 loss)
I0528 20:50:47.683475 11123 sgd_solver.cpp:105] Iteration 22900, lr = 0.008855
I0528 20:51:15.366683 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_23000.caffemodel
I0528 20:51:15.866199 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_23000.solverstate
I0528 20:51:16.014468 11123 solver.cpp:330] Iteration 23000, Testing net (#0)
I0528 20:51:20.465865 11123 solver.cpp:397]     Test net output #0: accuracy = 0.843
I0528 20:51:20.465911 11123 solver.cpp:397]     Test net output #1: loss = 0.399403 (* 1 = 0.399403 loss)
I0528 20:51:20.741595 11123 solver.cpp:218] Iteration 23000 (3.02505 iter/s, 33.0573s/100 iters), loss = 0.0781433
I0528 20:51:20.741641 11123 solver.cpp:237]     Train net output #0: loss = 0.0781419 (* 1 = 0.0781419 loss)
I0528 20:51:20.741649 11123 sgd_solver.cpp:105] Iteration 23000, lr = 0.00885
I0528 20:51:48.705343 11123 solver.cpp:218] Iteration 23100 (3.57615 iter/s, 27.963s/100 iters), loss = 0.0528489
I0528 20:51:48.705548 11123 solver.cpp:237]     Train net output #0: loss = 0.0528475 (* 1 = 0.0528475 loss)
I0528 20:51:48.705559 11123 sgd_solver.cpp:105] Iteration 23100, lr = 0.008845
I0528 20:52:16.669114 11123 solver.cpp:218] Iteration 23200 (3.57617 iter/s, 27.9629s/100 iters), loss = 0.127184
I0528 20:52:16.669162 11123 solver.cpp:237]     Train net output #0: loss = 0.127183 (* 1 = 0.127183 loss)
I0528 20:52:16.669172 11123 sgd_solver.cpp:105] Iteration 23200, lr = 0.00884
I0528 20:52:39.610813 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:52:44.624184 11123 solver.cpp:218] Iteration 23300 (3.57726 iter/s, 27.9543s/100 iters), loss = 0.0679004
I0528 20:52:44.624234 11123 solver.cpp:237]     Train net output #0: loss = 0.067899 (* 1 = 0.067899 loss)
I0528 20:52:44.624243 11123 sgd_solver.cpp:105] Iteration 23300, lr = 0.008835
I0528 20:53:12.590191 11123 solver.cpp:218] Iteration 23400 (3.57586 iter/s, 27.9653s/100 iters), loss = 0.0537835
I0528 20:53:12.590342 11123 solver.cpp:237]     Train net output #0: loss = 0.0537821 (* 1 = 0.0537821 loss)
I0528 20:53:12.590354 11123 sgd_solver.cpp:105] Iteration 23400, lr = 0.00883
I0528 20:53:40.558069 11123 solver.cpp:218] Iteration 23500 (3.57564 iter/s, 27.967s/100 iters), loss = 0.393231
I0528 20:53:40.558112 11123 solver.cpp:237]     Train net output #0: loss = 0.39323 (* 1 = 0.39323 loss)
I0528 20:53:40.558120 11123 sgd_solver.cpp:105] Iteration 23500, lr = 0.008825
I0528 20:54:08.519541 11123 solver.cpp:218] Iteration 23600 (3.57644 iter/s, 27.9607s/100 iters), loss = 0.183917
I0528 20:54:08.519768 11123 solver.cpp:237]     Train net output #0: loss = 0.183916 (* 1 = 0.183916 loss)
I0528 20:54:08.519780 11123 sgd_solver.cpp:105] Iteration 23600, lr = 0.00882
I0528 20:54:36.506237 11123 solver.cpp:218] Iteration 23700 (3.57324 iter/s, 27.9858s/100 iters), loss = 0.174233
I0528 20:54:36.506280 11123 solver.cpp:237]     Train net output #0: loss = 0.174231 (* 1 = 0.174231 loss)
I0528 20:54:36.506289 11123 sgd_solver.cpp:105] Iteration 23700, lr = 0.008815
I0528 20:55:04.466912 11123 solver.cpp:218] Iteration 23800 (3.57655 iter/s, 27.9599s/100 iters), loss = 0.079776
I0528 20:55:04.467115 11123 solver.cpp:237]     Train net output #0: loss = 0.0797748 (* 1 = 0.0797748 loss)
I0528 20:55:04.467126 11123 sgd_solver.cpp:105] Iteration 23800, lr = 0.00881
I0528 20:55:31.054541 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:55:32.441097 11123 solver.cpp:218] Iteration 23900 (3.57484 iter/s, 27.9733s/100 iters), loss = 0.0243285
I0528 20:55:32.441139 11123 solver.cpp:237]     Train net output #0: loss = 0.0243272 (* 1 = 0.0243272 loss)
I0528 20:55:32.441148 11123 sgd_solver.cpp:105] Iteration 23900, lr = 0.008805
I0528 20:56:00.148810 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_24000.caffemodel
I0528 20:56:00.633594 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_24000.solverstate
I0528 20:56:00.780810 11123 solver.cpp:330] Iteration 24000, Testing net (#0)
I0528 20:56:01.098400 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:56:05.226866 11123 solver.cpp:397]     Test net output #0: accuracy = 0.781
I0528 20:56:05.226919 11123 solver.cpp:397]     Test net output #1: loss = 0.608524 (* 1 = 0.608524 loss)
I0528 20:56:05.503180 11123 solver.cpp:218] Iteration 24000 (3.02469 iter/s, 33.0612s/100 iters), loss = 0.111546
I0528 20:56:05.503221 11123 solver.cpp:237]     Train net output #0: loss = 0.111545 (* 1 = 0.111545 loss)
I0528 20:56:05.503231 11123 sgd_solver.cpp:105] Iteration 24000, lr = 0.0088
I0528 20:56:33.470571 11123 solver.cpp:218] Iteration 24100 (3.57569 iter/s, 27.9667s/100 iters), loss = 0.146662
I0528 20:56:33.470731 11123 solver.cpp:237]     Train net output #0: loss = 0.146661 (* 1 = 0.146661 loss)
I0528 20:56:33.470743 11123 sgd_solver.cpp:105] Iteration 24100, lr = 0.008795
I0528 20:57:01.451356 11123 solver.cpp:218] Iteration 24200 (3.57399 iter/s, 27.9799s/100 iters), loss = 0.145525
I0528 20:57:01.451400 11123 solver.cpp:237]     Train net output #0: loss = 0.145523 (* 1 = 0.145523 loss)
I0528 20:57:01.451408 11123 sgd_solver.cpp:105] Iteration 24200, lr = 0.00879
I0528 20:57:29.454851 11123 solver.cpp:218] Iteration 24300 (3.57108 iter/s, 28.0028s/100 iters), loss = 0.080174
I0528 20:57:29.455008 11123 solver.cpp:237]     Train net output #0: loss = 0.0801726 (* 1 = 0.0801726 loss)
I0528 20:57:29.455019 11123 sgd_solver.cpp:105] Iteration 24300, lr = 0.008785
I0528 20:57:57.430733 11123 solver.cpp:218] Iteration 24400 (3.57462 iter/s, 27.975s/100 iters), loss = 0.0525272
I0528 20:57:57.430776 11123 solver.cpp:237]     Train net output #0: loss = 0.0525259 (* 1 = 0.0525259 loss)
I0528 20:57:57.430785 11123 sgd_solver.cpp:105] Iteration 24400, lr = 0.00878
I0528 20:58:25.405653 11123 solver.cpp:218] Iteration 24500 (3.57472 iter/s, 27.9742s/100 iters), loss = 0.181594
I0528 20:58:25.405866 11123 solver.cpp:237]     Train net output #0: loss = 0.181593 (* 1 = 0.181593 loss)
I0528 20:58:25.405879 11123 sgd_solver.cpp:105] Iteration 24500, lr = 0.008775
I0528 20:58:27.387650 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 20:58:53.387729 11123 solver.cpp:218] Iteration 24600 (3.57383 iter/s, 27.9812s/100 iters), loss = 0.275194
I0528 20:58:53.387786 11123 solver.cpp:237]     Train net output #0: loss = 0.275192 (* 1 = 0.275192 loss)
I0528 20:58:53.387795 11123 sgd_solver.cpp:105] Iteration 24600, lr = 0.00877
I0528 20:59:21.414579 11123 solver.cpp:218] Iteration 24700 (3.5681 iter/s, 28.0261s/100 iters), loss = 0.0501335
I0528 20:59:21.414791 11123 solver.cpp:237]     Train net output #0: loss = 0.0501321 (* 1 = 0.0501321 loss)
I0528 20:59:21.414803 11123 sgd_solver.cpp:105] Iteration 24700, lr = 0.008765
I0528 20:59:49.420631 11123 solver.cpp:218] Iteration 24800 (3.57077 iter/s, 28.0051s/100 iters), loss = 0.127641
I0528 20:59:49.420675 11123 solver.cpp:237]     Train net output #0: loss = 0.12764 (* 1 = 0.12764 loss)
I0528 20:59:49.420682 11123 sgd_solver.cpp:105] Iteration 24800, lr = 0.00876
I0528 21:00:17.408079 11123 solver.cpp:218] Iteration 24900 (3.57312 iter/s, 27.9867s/100 iters), loss = 0.00584564
I0528 21:00:17.408242 11123 solver.cpp:237]     Train net output #0: loss = 0.00584424 (* 1 = 0.00584424 loss)
I0528 21:00:17.408253 11123 sgd_solver.cpp:105] Iteration 24900, lr = 0.008755
I0528 21:00:45.140780 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_25000.caffemodel
I0528 21:00:45.562964 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_25000.solverstate
I0528 21:00:45.710291 11123 solver.cpp:330] Iteration 25000, Testing net (#0)
I0528 21:00:47.537457 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:00:50.157811 11123 solver.cpp:397]     Test net output #0: accuracy = 0.898
I0528 21:00:50.157851 11123 solver.cpp:397]     Test net output #1: loss = 0.267901 (* 1 = 0.267901 loss)
I0528 21:00:50.433411 11123 solver.cpp:218] Iteration 25000 (3.02807 iter/s, 33.0244s/100 iters), loss = 0.0400591
I0528 21:00:50.433457 11123 solver.cpp:237]     Train net output #0: loss = 0.0400578 (* 1 = 0.0400578 loss)
I0528 21:00:50.433466 11123 sgd_solver.cpp:105] Iteration 25000, lr = 0.00875
I0528 21:01:18.428414 11123 solver.cpp:218] Iteration 25100 (3.57216 iter/s, 27.9943s/100 iters), loss = 0.0413922
I0528 21:01:18.428623 11123 solver.cpp:237]     Train net output #0: loss = 0.0413909 (* 1 = 0.0413909 loss)
I0528 21:01:18.428634 11123 sgd_solver.cpp:105] Iteration 25100, lr = 0.008745
I0528 21:01:24.042203 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:01:46.408629 11123 solver.cpp:218] Iteration 25200 (3.57407 iter/s, 27.9793s/100 iters), loss = 0.0796144
I0528 21:01:46.408671 11123 solver.cpp:237]     Train net output #0: loss = 0.0796131 (* 1 = 0.0796131 loss)
I0528 21:01:46.408680 11123 sgd_solver.cpp:105] Iteration 25200, lr = 0.00874
I0528 21:02:14.409485 11123 solver.cpp:218] Iteration 25300 (3.57141 iter/s, 28.0001s/100 iters), loss = 0.045213
I0528 21:02:14.409694 11123 solver.cpp:237]     Train net output #0: loss = 0.0452117 (* 1 = 0.0452117 loss)
I0528 21:02:14.409705 11123 sgd_solver.cpp:105] Iteration 25300, lr = 0.008735
I0528 21:02:42.401793 11123 solver.cpp:218] Iteration 25400 (3.57252 iter/s, 27.9914s/100 iters), loss = 0.0802753
I0528 21:02:42.401842 11123 solver.cpp:237]     Train net output #0: loss = 0.080274 (* 1 = 0.080274 loss)
I0528 21:02:42.401850 11123 sgd_solver.cpp:105] Iteration 25400, lr = 0.00873
I0528 21:03:10.412266 11123 solver.cpp:218] Iteration 25500 (3.57019 iter/s, 28.0097s/100 iters), loss = 0.104811
I0528 21:03:10.412562 11123 solver.cpp:237]     Train net output #0: loss = 0.104809 (* 1 = 0.104809 loss)
I0528 21:03:10.412575 11123 sgd_solver.cpp:105] Iteration 25500, lr = 0.008725
I0528 21:03:38.429203 11123 solver.cpp:218] Iteration 25600 (3.5694 iter/s, 28.016s/100 iters), loss = 0.12666
I0528 21:03:38.429245 11123 solver.cpp:237]     Train net output #0: loss = 0.126659 (* 1 = 0.126659 loss)
I0528 21:03:38.429253 11123 sgd_solver.cpp:105] Iteration 25600, lr = 0.00872
I0528 21:04:06.403059 11123 solver.cpp:218] Iteration 25700 (3.57486 iter/s, 27.9731s/100 iters), loss = 0.0949174
I0528 21:04:06.403240 11123 solver.cpp:237]     Train net output #0: loss = 0.0949162 (* 1 = 0.0949162 loss)
I0528 21:04:06.403271 11123 sgd_solver.cpp:105] Iteration 25700, lr = 0.008715
I0528 21:04:15.656064 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:04:34.384155 11123 solver.cpp:218] Iteration 25800 (3.57395 iter/s, 27.9802s/100 iters), loss = 0.111658
I0528 21:04:34.384202 11123 solver.cpp:237]     Train net output #0: loss = 0.111657 (* 1 = 0.111657 loss)
I0528 21:04:34.384210 11123 sgd_solver.cpp:105] Iteration 25800, lr = 0.00871
I0528 21:05:02.373657 11123 solver.cpp:218] Iteration 25900 (3.57286 iter/s, 27.9888s/100 iters), loss = 0.0156374
I0528 21:05:02.373848 11123 solver.cpp:237]     Train net output #0: loss = 0.0156363 (* 1 = 0.0156363 loss)
I0528 21:05:02.373863 11123 sgd_solver.cpp:105] Iteration 25900, lr = 0.008705
I0528 21:05:30.098453 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_26000.caffemodel
I0528 21:05:30.440876 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_26000.solverstate
I0528 21:05:30.589035 11123 solver.cpp:330] Iteration 26000, Testing net (#0)
I0528 21:05:33.897006 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:05:35.044864 11123 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0528 21:05:35.044919 11123 solver.cpp:397]     Test net output #1: loss = 0.325878 (* 1 = 0.325878 loss)
I0528 21:05:35.322358 11123 solver.cpp:218] Iteration 26000 (3.03511 iter/s, 32.9477s/100 iters), loss = 0.138792
I0528 21:05:35.322415 11123 solver.cpp:237]     Train net output #0: loss = 0.138791 (* 1 = 0.138791 loss)
I0528 21:05:35.322424 11123 sgd_solver.cpp:105] Iteration 26000, lr = 0.0087
I0528 21:06:03.298027 11123 solver.cpp:218] Iteration 26100 (3.57463 iter/s, 27.9749s/100 iters), loss = 0.121707
I0528 21:06:03.298071 11123 solver.cpp:237]     Train net output #0: loss = 0.121706 (* 1 = 0.121706 loss)
I0528 21:06:03.298080 11123 sgd_solver.cpp:105] Iteration 26100, lr = 0.008695
I0528 21:06:31.271677 11123 solver.cpp:218] Iteration 26200 (3.57489 iter/s, 27.9729s/100 iters), loss = 0.0890978
I0528 21:06:31.271854 11123 solver.cpp:237]     Train net output #0: loss = 0.0890967 (* 1 = 0.0890967 loss)
I0528 21:06:31.271867 11123 sgd_solver.cpp:105] Iteration 26200, lr = 0.00869
I0528 21:06:59.264129 11123 solver.cpp:218] Iteration 26300 (3.5725 iter/s, 27.9916s/100 iters), loss = 0.238188
I0528 21:06:59.264178 11123 solver.cpp:237]     Train net output #0: loss = 0.238187 (* 1 = 0.238187 loss)
I0528 21:06:59.264188 11123 sgd_solver.cpp:105] Iteration 26300, lr = 0.008685
I0528 21:07:12.169558 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:07:27.274080 11123 solver.cpp:218] Iteration 26400 (3.57025 iter/s, 28.0092s/100 iters), loss = 0.174627
I0528 21:07:27.274127 11123 solver.cpp:237]     Train net output #0: loss = 0.174626 (* 1 = 0.174626 loss)
I0528 21:07:27.274137 11123 sgd_solver.cpp:105] Iteration 26400, lr = 0.00868
I0528 21:07:55.276602 11123 solver.cpp:218] Iteration 26500 (3.5712 iter/s, 28.0018s/100 iters), loss = 0.245796
I0528 21:07:55.276773 11123 solver.cpp:237]     Train net output #0: loss = 0.245795 (* 1 = 0.245795 loss)
I0528 21:07:55.276784 11123 sgd_solver.cpp:105] Iteration 26500, lr = 0.008675
I0528 21:08:23.266338 11123 solver.cpp:218] Iteration 26600 (3.57285 iter/s, 27.9889s/100 iters), loss = 0.0265819
I0528 21:08:23.266387 11123 solver.cpp:237]     Train net output #0: loss = 0.0265809 (* 1 = 0.0265809 loss)
I0528 21:08:23.266396 11123 sgd_solver.cpp:105] Iteration 26600, lr = 0.00867
I0528 21:08:51.235682 11123 solver.cpp:218] Iteration 26700 (3.57544 iter/s, 27.9686s/100 iters), loss = 0.0528177
I0528 21:08:51.235846 11123 solver.cpp:237]     Train net output #0: loss = 0.0528166 (* 1 = 0.0528166 loss)
I0528 21:08:51.235857 11123 sgd_solver.cpp:105] Iteration 26700, lr = 0.008665
I0528 21:09:19.232254 11123 solver.cpp:218] Iteration 26800 (3.57198 iter/s, 27.9957s/100 iters), loss = 0.132365
I0528 21:09:19.232305 11123 solver.cpp:237]     Train net output #0: loss = 0.132364 (* 1 = 0.132364 loss)
I0528 21:09:19.232324 11123 sgd_solver.cpp:105] Iteration 26800, lr = 0.00866
I0528 21:09:47.216513 11123 solver.cpp:218] Iteration 26900 (3.57353 iter/s, 27.9835s/100 iters), loss = 0.0196197
I0528 21:09:47.216709 11123 solver.cpp:237]     Train net output #0: loss = 0.0196187 (* 1 = 0.0196187 loss)
I0528 21:09:47.216722 11123 sgd_solver.cpp:105] Iteration 26900, lr = 0.008655
I0528 21:10:03.779445 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:10:14.967587 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_27000.caffemodel
I0528 21:10:15.274893 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_27000.solverstate
I0528 21:10:15.420207 11123 solver.cpp:330] Iteration 27000, Testing net (#0)
I0528 21:10:19.855147 11123 solver.cpp:397]     Test net output #0: accuracy = 0.879
I0528 21:10:19.855305 11123 solver.cpp:397]     Test net output #1: loss = 0.305033 (* 1 = 0.305033 loss)
I0528 21:10:20.131919 11123 solver.cpp:218] Iteration 27000 (3.03818 iter/s, 32.9144s/100 iters), loss = 0.262595
I0528 21:10:20.131966 11123 solver.cpp:237]     Train net output #0: loss = 0.262594 (* 1 = 0.262594 loss)
I0528 21:10:20.131975 11123 sgd_solver.cpp:105] Iteration 27000, lr = 0.00865
I0528 21:10:48.130965 11123 solver.cpp:218] Iteration 27100 (3.57165 iter/s, 27.9983s/100 iters), loss = 0.0413403
I0528 21:10:48.131024 11123 solver.cpp:237]     Train net output #0: loss = 0.0413391 (* 1 = 0.0413391 loss)
I0528 21:10:48.131032 11123 sgd_solver.cpp:105] Iteration 27100, lr = 0.008645
I0528 21:11:16.162571 11123 solver.cpp:218] Iteration 27200 (3.5675 iter/s, 28.0309s/100 iters), loss = 0.00553461
I0528 21:11:16.162726 11123 solver.cpp:237]     Train net output #0: loss = 0.00553341 (* 1 = 0.00553341 loss)
I0528 21:11:16.162737 11123 sgd_solver.cpp:105] Iteration 27200, lr = 0.00864
I0528 21:11:44.189126 11123 solver.cpp:218] Iteration 27300 (3.56815 iter/s, 28.0257s/100 iters), loss = 0.016571
I0528 21:11:44.189172 11123 solver.cpp:237]     Train net output #0: loss = 0.0165698 (* 1 = 0.0165698 loss)
I0528 21:11:44.189180 11123 sgd_solver.cpp:105] Iteration 27300, lr = 0.008635
I0528 21:12:12.170683 11123 solver.cpp:218] Iteration 27400 (3.57388 iter/s, 27.9808s/100 iters), loss = 0.020184
I0528 21:12:12.170883 11123 solver.cpp:237]     Train net output #0: loss = 0.0201828 (* 1 = 0.0201828 loss)
I0528 21:12:12.170895 11123 sgd_solver.cpp:105] Iteration 27400, lr = 0.00863
I0528 21:12:40.164718 11123 solver.cpp:218] Iteration 27500 (3.5723 iter/s, 27.9932s/100 iters), loss = 0.0437977
I0528 21:12:40.164775 11123 solver.cpp:237]     Train net output #0: loss = 0.0437966 (* 1 = 0.0437966 loss)
I0528 21:12:40.164784 11123 sgd_solver.cpp:105] Iteration 27500, lr = 0.008625
I0528 21:13:00.072613 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:13:08.199419 11123 solver.cpp:218] Iteration 27600 (3.5671 iter/s, 28.034s/100 iters), loss = 0.113929
I0528 21:13:08.199479 11123 solver.cpp:237]     Train net output #0: loss = 0.113928 (* 1 = 0.113928 loss)
I0528 21:13:08.199488 11123 sgd_solver.cpp:105] Iteration 27600, lr = 0.00862
I0528 21:13:36.220856 11123 solver.cpp:218] Iteration 27700 (3.56879 iter/s, 28.0207s/100 iters), loss = 0.0123623
I0528 21:13:36.221112 11123 solver.cpp:237]     Train net output #0: loss = 0.0123612 (* 1 = 0.0123612 loss)
I0528 21:13:36.221122 11123 sgd_solver.cpp:105] Iteration 27700, lr = 0.008615
I0528 21:14:04.235056 11123 solver.cpp:218] Iteration 27800 (3.56974 iter/s, 28.0133s/100 iters), loss = 0.116076
I0528 21:14:04.235121 11123 solver.cpp:237]     Train net output #0: loss = 0.116075 (* 1 = 0.116075 loss)
I0528 21:14:04.235129 11123 sgd_solver.cpp:105] Iteration 27800, lr = 0.00861
I0528 21:14:32.246224 11123 solver.cpp:218] Iteration 27900 (3.5701 iter/s, 28.0104s/100 iters), loss = 0.0277395
I0528 21:14:32.246413 11123 solver.cpp:237]     Train net output #0: loss = 0.0277383 (* 1 = 0.0277383 loss)
I0528 21:14:32.246438 11123 sgd_solver.cpp:105] Iteration 27900, lr = 0.008605
I0528 21:14:59.971485 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_28000.caffemodel
I0528 21:15:00.283172 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_28000.solverstate
I0528 21:15:00.427423 11123 solver.cpp:330] Iteration 28000, Testing net (#0)
I0528 21:15:00.791200 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:15:04.882380 11123 solver.cpp:397]     Test net output #0: accuracy = 0.873001
I0528 21:15:04.882628 11123 solver.cpp:397]     Test net output #1: loss = 0.346262 (* 1 = 0.346262 loss)
I0528 21:15:05.160208 11123 solver.cpp:218] Iteration 28000 (3.03831 iter/s, 32.913s/100 iters), loss = 0.0200133
I0528 21:15:05.160254 11123 solver.cpp:237]     Train net output #0: loss = 0.0200122 (* 1 = 0.0200122 loss)
I0528 21:15:05.160261 11123 sgd_solver.cpp:105] Iteration 28000, lr = 0.0086
I0528 21:15:33.194794 11123 solver.cpp:218] Iteration 28100 (3.56712 iter/s, 28.0338s/100 iters), loss = 0.157446
I0528 21:15:33.194850 11123 solver.cpp:237]     Train net output #0: loss = 0.157445 (* 1 = 0.157445 loss)
I0528 21:15:33.194859 11123 sgd_solver.cpp:105] Iteration 28100, lr = 0.008595
I0528 21:15:56.747743 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:16:01.211704 11123 solver.cpp:218] Iteration 28200 (3.56937 iter/s, 28.0162s/100 iters), loss = 0.0239186
I0528 21:16:01.211746 11123 solver.cpp:237]     Train net output #0: loss = 0.0239176 (* 1 = 0.0239176 loss)
I0528 21:16:01.211755 11123 sgd_solver.cpp:105] Iteration 28200, lr = 0.00859
I0528 21:16:29.219856 11123 solver.cpp:218] Iteration 28300 (3.57048 iter/s, 28.0074s/100 iters), loss = 0.0524536
I0528 21:16:29.220018 11123 solver.cpp:237]     Train net output #0: loss = 0.0524526 (* 1 = 0.0524526 loss)
I0528 21:16:29.220031 11123 sgd_solver.cpp:105] Iteration 28300, lr = 0.008585
I0528 21:16:57.238622 11123 solver.cpp:218] Iteration 28400 (3.56915 iter/s, 28.0179s/100 iters), loss = 0.0901603
I0528 21:16:57.238684 11123 solver.cpp:237]     Train net output #0: loss = 0.0901594 (* 1 = 0.0901594 loss)
I0528 21:16:57.238693 11123 sgd_solver.cpp:105] Iteration 28400, lr = 0.00858
I0528 21:17:25.242656 11123 solver.cpp:218] Iteration 28500 (3.57101 iter/s, 28.0033s/100 iters), loss = 0.1071
I0528 21:17:25.243474 11123 solver.cpp:237]     Train net output #0: loss = 0.107099 (* 1 = 0.107099 loss)
I0528 21:17:25.243497 11123 sgd_solver.cpp:105] Iteration 28500, lr = 0.008575
I0528 21:17:53.219784 11123 solver.cpp:218] Iteration 28600 (3.57454 iter/s, 27.9756s/100 iters), loss = 0.0315667
I0528 21:17:53.219830 11123 solver.cpp:237]     Train net output #0: loss = 0.0315658 (* 1 = 0.0315658 loss)
I0528 21:17:53.219841 11123 sgd_solver.cpp:105] Iteration 28600, lr = 0.00857
I0528 21:18:21.194854 11123 solver.cpp:218] Iteration 28700 (3.57471 iter/s, 27.9743s/100 iters), loss = 0.0438273
I0528 21:18:21.195019 11123 solver.cpp:237]     Train net output #0: loss = 0.0438264 (* 1 = 0.0438264 loss)
I0528 21:18:21.195030 11123 sgd_solver.cpp:105] Iteration 28700, lr = 0.008565
I0528 21:18:48.364130 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:18:49.189291 11123 solver.cpp:218] Iteration 28800 (3.57225 iter/s, 27.9936s/100 iters), loss = 0.0907218
I0528 21:18:49.189333 11123 solver.cpp:237]     Train net output #0: loss = 0.090721 (* 1 = 0.090721 loss)
I0528 21:18:49.189342 11123 sgd_solver.cpp:105] Iteration 28800, lr = 0.00856
I0528 21:19:17.199970 11123 solver.cpp:218] Iteration 28900 (3.57016 iter/s, 28.0099s/100 iters), loss = 0.0241257
I0528 21:19:17.200177 11123 solver.cpp:237]     Train net output #0: loss = 0.0241249 (* 1 = 0.0241249 loss)
I0528 21:19:17.200189 11123 sgd_solver.cpp:105] Iteration 28900, lr = 0.008555
I0528 21:19:44.931370 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_29000.caffemodel
I0528 21:19:45.246655 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_29000.solverstate
I0528 21:19:45.391403 11123 solver.cpp:330] Iteration 29000, Testing net (#0)
I0528 21:19:47.266829 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:19:49.842051 11123 solver.cpp:397]     Test net output #0: accuracy = 0.829
I0528 21:19:49.842089 11123 solver.cpp:397]     Test net output #1: loss = 0.475581 (* 1 = 0.475581 loss)
I0528 21:19:50.118206 11123 solver.cpp:218] Iteration 29000 (3.03792 iter/s, 32.9173s/100 iters), loss = 0.0861468
I0528 21:19:50.118250 11123 solver.cpp:237]     Train net output #0: loss = 0.0861461 (* 1 = 0.0861461 loss)
I0528 21:19:50.118258 11123 sgd_solver.cpp:105] Iteration 29000, lr = 0.00855
I0528 21:20:18.115844 11123 solver.cpp:218] Iteration 29100 (3.57181 iter/s, 27.997s/100 iters), loss = 0.00992283
I0528 21:20:18.116006 11123 solver.cpp:237]     Train net output #0: loss = 0.00992211 (* 1 = 0.00992211 loss)
I0528 21:20:18.116019 11123 sgd_solver.cpp:105] Iteration 29100, lr = 0.008545
I0528 21:20:46.112593 11123 solver.cpp:218] Iteration 29200 (3.57171 iter/s, 27.9978s/100 iters), loss = 0.0452094
I0528 21:20:46.112635 11123 solver.cpp:237]     Train net output #0: loss = 0.0452086 (* 1 = 0.0452086 loss)
I0528 21:20:46.112644 11123 sgd_solver.cpp:105] Iteration 29200, lr = 0.00854
I0528 21:21:14.096634 11123 solver.cpp:218] Iteration 29300 (3.57333 iter/s, 27.9851s/100 iters), loss = 0.0192483
I0528 21:21:14.096752 11123 solver.cpp:237]     Train net output #0: loss = 0.0192475 (* 1 = 0.0192475 loss)
I0528 21:21:14.096763 11123 sgd_solver.cpp:105] Iteration 29300, lr = 0.008535
I0528 21:21:42.068637 11123 solver.cpp:218] Iteration 29400 (3.57489 iter/s, 27.9729s/100 iters), loss = 0.0629339
I0528 21:21:42.068682 11123 solver.cpp:237]     Train net output #0: loss = 0.0629332 (* 1 = 0.0629332 loss)
I0528 21:21:42.068691 11123 sgd_solver.cpp:105] Iteration 29400, lr = 0.00853
I0528 21:21:44.886616 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:22:10.096565 11123 solver.cpp:218] Iteration 29500 (3.56776 iter/s, 28.0288s/100 iters), loss = 0.0818486
I0528 21:22:10.096621 11123 solver.cpp:237]     Train net output #0: loss = 0.0818479 (* 1 = 0.0818479 loss)
I0528 21:22:10.096629 11123 sgd_solver.cpp:105] Iteration 29500, lr = 0.008525
I0528 21:22:38.122503 11123 solver.cpp:218] Iteration 29600 (3.56802 iter/s, 28.0267s/100 iters), loss = 0.18434
I0528 21:22:38.122676 11123 solver.cpp:237]     Train net output #0: loss = 0.18434 (* 1 = 0.18434 loss)
I0528 21:22:38.122689 11123 sgd_solver.cpp:105] Iteration 29600, lr = 0.00852
I0528 21:23:06.121408 11123 solver.cpp:218] Iteration 29700 (3.57149 iter/s, 27.9995s/100 iters), loss = 0.149505
I0528 21:23:06.121450 11123 solver.cpp:237]     Train net output #0: loss = 0.149504 (* 1 = 0.149504 loss)
I0528 21:23:06.121459 11123 sgd_solver.cpp:105] Iteration 29700, lr = 0.008515
I0528 21:23:34.099311 11123 solver.cpp:218] Iteration 29800 (3.57416 iter/s, 27.9786s/100 iters), loss = 0.0350362
I0528 21:23:34.099622 11123 solver.cpp:237]     Train net output #0: loss = 0.0350354 (* 1 = 0.0350354 loss)
I0528 21:23:34.099632 11123 sgd_solver.cpp:105] Iteration 29800, lr = 0.00851
I0528 21:24:02.107903 11123 solver.cpp:218] Iteration 29900 (3.57029 iter/s, 28.0089s/100 iters), loss = 0.215972
I0528 21:24:02.107947 11123 solver.cpp:237]     Train net output #0: loss = 0.215971 (* 1 = 0.215971 loss)
I0528 21:24:02.107955 11123 sgd_solver.cpp:105] Iteration 29900, lr = 0.008505
I0528 21:24:29.831646 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_30000.caffemodel
I0528 21:24:30.145135 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_30000.solverstate
I0528 21:24:30.290560 11123 solver.cpp:330] Iteration 30000, Testing net (#0)
I0528 21:24:33.673494 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:24:34.734983 11123 solver.cpp:397]     Test net output #0: accuracy = 0.841
I0528 21:24:34.735024 11123 solver.cpp:397]     Test net output #1: loss = 0.54875 (* 1 = 0.54875 loss)
I0528 21:24:35.012678 11123 solver.cpp:218] Iteration 30000 (3.03901 iter/s, 32.9054s/100 iters), loss = 0.227517
I0528 21:24:35.012722 11123 solver.cpp:237]     Train net output #0: loss = 0.227516 (* 1 = 0.227516 loss)
I0528 21:24:35.012742 11123 sgd_solver.cpp:105] Iteration 30000, lr = 0.0085
I0528 21:24:41.469846 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:25:03.040119 11123 solver.cpp:218] Iteration 30100 (3.56787 iter/s, 28.0279s/100 iters), loss = 0.149736
I0528 21:25:03.040360 11123 solver.cpp:237]     Train net output #0: loss = 0.149735 (* 1 = 0.149735 loss)
I0528 21:25:03.040387 11123 sgd_solver.cpp:105] Iteration 30100, lr = 0.008495
I0528 21:25:31.071202 11123 solver.cpp:218] Iteration 30200 (3.56744 iter/s, 28.0313s/100 iters), loss = 0.161734
I0528 21:25:31.071245 11123 solver.cpp:237]     Train net output #0: loss = 0.161733 (* 1 = 0.161733 loss)
I0528 21:25:31.071254 11123 sgd_solver.cpp:105] Iteration 30200, lr = 0.00849
I0528 21:25:59.060545 11123 solver.cpp:218] Iteration 30300 (3.57274 iter/s, 27.9897s/100 iters), loss = 0.13252
I0528 21:25:59.060715 11123 solver.cpp:237]     Train net output #0: loss = 0.132519 (* 1 = 0.132519 loss)
I0528 21:25:59.060726 11123 sgd_solver.cpp:105] Iteration 30300, lr = 0.008485
I0528 21:26:27.049305 11123 solver.cpp:218] Iteration 30400 (3.57283 iter/s, 27.989s/100 iters), loss = 0.00568474
I0528 21:26:27.049362 11123 solver.cpp:237]     Train net output #0: loss = 0.00568382 (* 1 = 0.00568382 loss)
I0528 21:26:27.049371 11123 sgd_solver.cpp:105] Iteration 30400, lr = 0.00848
I0528 21:26:55.023133 11123 solver.cpp:218] Iteration 30500 (3.57473 iter/s, 27.9741s/100 iters), loss = 0.0495575
I0528 21:26:55.023288 11123 solver.cpp:237]     Train net output #0: loss = 0.0495566 (* 1 = 0.0495566 loss)
I0528 21:26:55.023303 11123 sgd_solver.cpp:105] Iteration 30500, lr = 0.008475
I0528 21:27:23.021704 11123 solver.cpp:218] Iteration 30600 (3.57159 iter/s, 27.9987s/100 iters), loss = 0.0170389
I0528 21:27:23.021749 11123 solver.cpp:237]     Train net output #0: loss = 0.017038 (* 1 = 0.017038 loss)
I0528 21:27:23.021757 11123 sgd_solver.cpp:105] Iteration 30600, lr = 0.00847
I0528 21:27:32.851408 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:27:51.030321 11123 solver.cpp:218] Iteration 30700 (3.5703 iter/s, 28.0088s/100 iters), loss = 0.0466294
I0528 21:27:51.030364 11123 solver.cpp:237]     Train net output #0: loss = 0.0466286 (* 1 = 0.0466286 loss)
I0528 21:27:51.030372 11123 sgd_solver.cpp:105] Iteration 30700, lr = 0.008465
I0528 21:28:19.028360 11123 solver.cpp:218] Iteration 30800 (3.57166 iter/s, 27.9982s/100 iters), loss = 0.143231
I0528 21:28:19.028594 11123 solver.cpp:237]     Train net output #0: loss = 0.14323 (* 1 = 0.14323 loss)
I0528 21:28:19.028604 11123 sgd_solver.cpp:105] Iteration 30800, lr = 0.00846
I0528 21:28:47.024981 11123 solver.cpp:218] Iteration 30900 (3.57186 iter/s, 27.9966s/100 iters), loss = 0.0959143
I0528 21:28:47.025041 11123 solver.cpp:237]     Train net output #0: loss = 0.0959135 (* 1 = 0.0959135 loss)
I0528 21:28:47.025050 11123 sgd_solver.cpp:105] Iteration 30900, lr = 0.008455
I0528 21:29:14.739006 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_31000.caffemodel
I0528 21:29:15.064663 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_31000.solverstate
I0528 21:29:15.209020 11123 solver.cpp:330] Iteration 31000, Testing net (#0)
I0528 21:29:19.663703 11123 solver.cpp:397]     Test net output #0: accuracy = 0.902
I0528 21:29:19.663743 11123 solver.cpp:397]     Test net output #1: loss = 0.288174 (* 1 = 0.288174 loss)
I0528 21:29:19.940274 11123 solver.cpp:218] Iteration 31000 (3.03809 iter/s, 32.9154s/100 iters), loss = 0.0253539
I0528 21:29:19.940327 11123 solver.cpp:237]     Train net output #0: loss = 0.0253531 (* 1 = 0.0253531 loss)
I0528 21:29:19.940336 11123 sgd_solver.cpp:105] Iteration 31000, lr = 0.00845
I0528 21:29:47.955723 11123 solver.cpp:218] Iteration 31100 (3.56945 iter/s, 28.0155s/100 iters), loss = 0.0820647
I0528 21:29:47.955888 11123 solver.cpp:237]     Train net output #0: loss = 0.0820639 (* 1 = 0.0820639 loss)
I0528 21:29:47.955904 11123 sgd_solver.cpp:105] Iteration 31100, lr = 0.008445
I0528 21:30:15.976799 11123 solver.cpp:218] Iteration 31200 (3.56875 iter/s, 28.021s/100 iters), loss = 0.028836
I0528 21:30:15.976841 11123 solver.cpp:237]     Train net output #0: loss = 0.0288352 (* 1 = 0.0288352 loss)
I0528 21:30:15.976850 11123 sgd_solver.cpp:105] Iteration 31200, lr = 0.00844
I0528 21:30:29.413419 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:30:43.936415 11123 solver.cpp:218] Iteration 31300 (3.57658 iter/s, 27.9596s/100 iters), loss = 0.0971479
I0528 21:30:43.936458 11123 solver.cpp:237]     Train net output #0: loss = 0.0971472 (* 1 = 0.0971472 loss)
I0528 21:30:43.936466 11123 sgd_solver.cpp:105] Iteration 31300, lr = 0.008435
I0528 21:31:11.942124 11123 solver.cpp:218] Iteration 31400 (3.5707 iter/s, 28.0057s/100 iters), loss = 0.0423765
I0528 21:31:11.942289 11123 solver.cpp:237]     Train net output #0: loss = 0.0423759 (* 1 = 0.0423759 loss)
I0528 21:31:11.942301 11123 sgd_solver.cpp:105] Iteration 31400, lr = 0.00843
I0528 21:31:39.912941 11123 solver.cpp:218] Iteration 31500 (3.57517 iter/s, 27.9707s/100 iters), loss = 0.0107629
I0528 21:31:39.912986 11123 solver.cpp:237]     Train net output #0: loss = 0.0107623 (* 1 = 0.0107623 loss)
I0528 21:31:39.912994 11123 sgd_solver.cpp:105] Iteration 31500, lr = 0.008425
I0528 21:32:07.910521 11123 solver.cpp:218] Iteration 31600 (3.57174 iter/s, 27.9975s/100 iters), loss = 0.227942
I0528 21:32:07.910691 11123 solver.cpp:237]     Train net output #0: loss = 0.227942 (* 1 = 0.227942 loss)
I0528 21:32:07.910706 11123 sgd_solver.cpp:105] Iteration 31600, lr = 0.00842
I0528 21:32:35.878350 11123 solver.cpp:218] Iteration 31700 (3.57556 iter/s, 27.9676s/100 iters), loss = 0.175972
I0528 21:32:35.878420 11123 solver.cpp:237]     Train net output #0: loss = 0.175971 (* 1 = 0.175971 loss)
I0528 21:32:35.878430 11123 sgd_solver.cpp:105] Iteration 31700, lr = 0.008415
I0528 21:33:03.850611 11123 solver.cpp:218] Iteration 31800 (3.57499 iter/s, 27.9721s/100 iters), loss = 0.0992017
I0528 21:33:03.850769 11123 solver.cpp:237]     Train net output #0: loss = 0.0992011 (* 1 = 0.0992011 loss)
I0528 21:33:03.850780 11123 sgd_solver.cpp:105] Iteration 31800, lr = 0.00841
I0528 21:33:20.930500 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:33:31.833884 11123 solver.cpp:218] Iteration 31900 (3.57359 iter/s, 27.983s/100 iters), loss = 0.0373643
I0528 21:33:31.833927 11123 solver.cpp:237]     Train net output #0: loss = 0.0373637 (* 1 = 0.0373637 loss)
I0528 21:33:31.833936 11123 sgd_solver.cpp:105] Iteration 31900, lr = 0.008405
I0528 21:33:59.524359 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_32000.caffemodel
I0528 21:33:59.830883 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_32000.solverstate
I0528 21:33:59.976016 11123 solver.cpp:330] Iteration 32000, Testing net (#0)
I0528 21:34:00.434799 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:34:04.416666 11123 solver.cpp:397]     Test net output #0: accuracy = 0.897
I0528 21:34:04.416705 11123 solver.cpp:397]     Test net output #1: loss = 0.304915 (* 1 = 0.304915 loss)
I0528 21:34:04.694057 11123 solver.cpp:218] Iteration 32000 (3.04322 iter/s, 32.86s/100 iters), loss = 0.281157
I0528 21:34:04.694114 11123 solver.cpp:237]     Train net output #0: loss = 0.281156 (* 1 = 0.281156 loss)
I0528 21:34:04.694123 11123 sgd_solver.cpp:105] Iteration 32000, lr = 0.0084
I0528 21:34:32.691860 11123 solver.cpp:218] Iteration 32100 (3.57173 iter/s, 27.9976s/100 iters), loss = 0.109509
I0528 21:34:32.692028 11123 solver.cpp:237]     Train net output #0: loss = 0.109509 (* 1 = 0.109509 loss)
I0528 21:34:32.692040 11123 sgd_solver.cpp:105] Iteration 32100, lr = 0.008395
I0528 21:35:00.707412 11123 solver.cpp:218] Iteration 32200 (3.56948 iter/s, 28.0152s/100 iters), loss = 0.169327
I0528 21:35:00.707474 11123 solver.cpp:237]     Train net output #0: loss = 0.169327 (* 1 = 0.169327 loss)
I0528 21:35:00.707484 11123 sgd_solver.cpp:105] Iteration 32200, lr = 0.00839
I0528 21:35:28.706858 11123 solver.cpp:218] Iteration 32300 (3.57153 iter/s, 27.9992s/100 iters), loss = 0.0267668
I0528 21:35:28.707063 11123 solver.cpp:237]     Train net output #0: loss = 0.0267663 (* 1 = 0.0267663 loss)
I0528 21:35:28.707075 11123 sgd_solver.cpp:105] Iteration 32300, lr = 0.008385
I0528 21:35:56.722848 11123 solver.cpp:218] Iteration 32400 (3.56944 iter/s, 28.0156s/100 iters), loss = 0.0520937
I0528 21:35:56.722904 11123 solver.cpp:237]     Train net output #0: loss = 0.0520932 (* 1 = 0.0520932 loss)
I0528 21:35:56.722913 11123 sgd_solver.cpp:105] Iteration 32400, lr = 0.00838
I0528 21:36:17.475603 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:36:24.742509 11123 solver.cpp:218] Iteration 32500 (3.56895 iter/s, 28.0194s/100 iters), loss = 0.0277445
I0528 21:36:24.742558 11123 solver.cpp:237]     Train net output #0: loss = 0.027744 (* 1 = 0.027744 loss)
I0528 21:36:24.742565 11123 sgd_solver.cpp:105] Iteration 32500, lr = 0.008375
I0528 21:36:52.754225 11123 solver.cpp:218] Iteration 32600 (3.56997 iter/s, 28.0115s/100 iters), loss = 0.0844577
I0528 21:36:52.754382 11123 solver.cpp:237]     Train net output #0: loss = 0.0844571 (* 1 = 0.0844571 loss)
I0528 21:36:52.754395 11123 sgd_solver.cpp:105] Iteration 32600, lr = 0.00837
I0528 21:37:20.764534 11123 solver.cpp:218] Iteration 32700 (3.57016 iter/s, 28.0099s/100 iters), loss = 0.0429309
I0528 21:37:20.764580 11123 solver.cpp:237]     Train net output #0: loss = 0.0429304 (* 1 = 0.0429304 loss)
I0528 21:37:20.764588 11123 sgd_solver.cpp:105] Iteration 32700, lr = 0.008365
I0528 21:37:48.752276 11123 solver.cpp:218] Iteration 32800 (3.57303 iter/s, 27.9875s/100 iters), loss = 0.147191
I0528 21:37:48.752432 11123 solver.cpp:237]     Train net output #0: loss = 0.14719 (* 1 = 0.14719 loss)
I0528 21:37:48.752444 11123 sgd_solver.cpp:105] Iteration 32800, lr = 0.00836
I0528 21:38:16.737639 11123 solver.cpp:218] Iteration 32900 (3.57334 iter/s, 27.985s/100 iters), loss = 0.0308036
I0528 21:38:16.737689 11123 solver.cpp:237]     Train net output #0: loss = 0.030803 (* 1 = 0.030803 loss)
I0528 21:38:16.737696 11123 sgd_solver.cpp:105] Iteration 32900, lr = 0.008355
I0528 21:38:44.442986 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_33000.caffemodel
I0528 21:38:44.752444 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_33000.solverstate
I0528 21:38:44.897545 11123 solver.cpp:330] Iteration 33000, Testing net (#0)
I0528 21:38:46.858299 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:38:49.343751 11123 solver.cpp:397]     Test net output #0: accuracy = 0.867001
I0528 21:38:49.343803 11123 solver.cpp:397]     Test net output #1: loss = 0.411358 (* 1 = 0.411358 loss)
I0528 21:38:49.621275 11123 solver.cpp:218] Iteration 33000 (3.04106 iter/s, 32.8833s/100 iters), loss = 0.00402635
I0528 21:38:49.621325 11123 solver.cpp:237]     Train net output #0: loss = 0.0040258 (* 1 = 0.0040258 loss)
I0528 21:38:49.621335 11123 sgd_solver.cpp:105] Iteration 33000, lr = 0.00835
I0528 21:39:14.005745 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:39:17.636781 11123 solver.cpp:218] Iteration 33100 (3.56949 iter/s, 28.0152s/100 iters), loss = 0.0761957
I0528 21:39:17.636911 11123 solver.cpp:237]     Train net output #0: loss = 0.0761951 (* 1 = 0.0761951 loss)
I0528 21:39:17.636921 11123 sgd_solver.cpp:105] Iteration 33100, lr = 0.008345
I0528 21:39:45.638751 11123 solver.cpp:218] Iteration 33200 (3.57123 iter/s, 28.0016s/100 iters), loss = 0.181546
I0528 21:39:45.638799 11123 solver.cpp:237]     Train net output #0: loss = 0.181545 (* 1 = 0.181545 loss)
I0528 21:39:45.638808 11123 sgd_solver.cpp:105] Iteration 33200, lr = 0.00834
I0528 21:40:13.650507 11123 solver.cpp:218] Iteration 33300 (3.56997 iter/s, 28.0114s/100 iters), loss = 0.00561015
I0528 21:40:13.650678 11123 solver.cpp:237]     Train net output #0: loss = 0.00560955 (* 1 = 0.00560955 loss)
I0528 21:40:13.650692 11123 sgd_solver.cpp:105] Iteration 33300, lr = 0.008335
I0528 21:40:41.652245 11123 solver.cpp:218] Iteration 33400 (3.57126 iter/s, 28.0013s/100 iters), loss = 0.0422492
I0528 21:40:41.652288 11123 solver.cpp:237]     Train net output #0: loss = 0.0422486 (* 1 = 0.0422486 loss)
I0528 21:40:41.652297 11123 sgd_solver.cpp:105] Iteration 33400, lr = 0.00833
I0528 21:41:09.669384 11123 solver.cpp:218] Iteration 33500 (3.56929 iter/s, 28.0168s/100 iters), loss = 0.0417036
I0528 21:41:09.669580 11123 solver.cpp:237]     Train net output #0: loss = 0.041703 (* 1 = 0.041703 loss)
I0528 21:41:09.669592 11123 sgd_solver.cpp:105] Iteration 33500, lr = 0.008325
I0528 21:41:37.683917 11123 solver.cpp:218] Iteration 33600 (3.56964 iter/s, 28.014s/100 iters), loss = 0.0164613
I0528 21:41:37.683976 11123 solver.cpp:237]     Train net output #0: loss = 0.0164607 (* 1 = 0.0164607 loss)
I0528 21:41:37.683985 11123 sgd_solver.cpp:105] Iteration 33600, lr = 0.00832
I0528 21:42:05.447791 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:42:05.710140 11123 solver.cpp:218] Iteration 33700 (3.56813 iter/s, 28.0259s/100 iters), loss = 0.15969
I0528 21:42:05.710181 11123 solver.cpp:237]     Train net output #0: loss = 0.15969 (* 1 = 0.15969 loss)
I0528 21:42:05.710191 11123 sgd_solver.cpp:105] Iteration 33700, lr = 0.008315
I0528 21:42:33.718996 11123 solver.cpp:218] Iteration 33800 (3.57034 iter/s, 28.0085s/100 iters), loss = 0.0795328
I0528 21:42:33.719053 11123 solver.cpp:237]     Train net output #0: loss = 0.0795322 (* 1 = 0.0795322 loss)
I0528 21:42:33.719061 11123 sgd_solver.cpp:105] Iteration 33800, lr = 0.00831
I0528 21:43:01.720599 11123 solver.cpp:218] Iteration 33900 (3.57127 iter/s, 28.0012s/100 iters), loss = 0.148587
I0528 21:43:01.720753 11123 solver.cpp:237]     Train net output #0: loss = 0.148587 (* 1 = 0.148587 loss)
I0528 21:43:01.720768 11123 sgd_solver.cpp:105] Iteration 33900, lr = 0.008305
I0528 21:43:29.439887 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_34000.caffemodel
I0528 21:43:29.748561 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_34000.solverstate
I0528 21:43:29.894913 11123 solver.cpp:330] Iteration 34000, Testing net (#0)
I0528 21:43:33.367822 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:43:34.343374 11123 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0528 21:43:34.343426 11123 solver.cpp:397]     Test net output #1: loss = 0.31752 (* 1 = 0.31752 loss)
I0528 21:43:34.619504 11123 solver.cpp:218] Iteration 34000 (3.03966 iter/s, 32.8984s/100 iters), loss = 0.0440374
I0528 21:43:34.619567 11123 solver.cpp:237]     Train net output #0: loss = 0.0440368 (* 1 = 0.0440368 loss)
I0528 21:43:34.619576 11123 sgd_solver.cpp:105] Iteration 34000, lr = 0.0083
I0528 21:44:02.603472 11123 solver.cpp:218] Iteration 34100 (3.57353 iter/s, 27.9836s/100 iters), loss = 0.0766223
I0528 21:44:02.603525 11123 solver.cpp:237]     Train net output #0: loss = 0.0766217 (* 1 = 0.0766217 loss)
I0528 21:44:02.603534 11123 sgd_solver.cpp:105] Iteration 34100, lr = 0.008295
I0528 21:44:30.588707 11123 solver.cpp:218] Iteration 34200 (3.57336 iter/s, 27.9848s/100 iters), loss = 0.284153
I0528 21:44:30.588838 11123 solver.cpp:237]     Train net output #0: loss = 0.284153 (* 1 = 0.284153 loss)
I0528 21:44:30.588860 11123 sgd_solver.cpp:105] Iteration 34200, lr = 0.00829
I0528 21:44:58.592237 11123 solver.cpp:218] Iteration 34300 (3.57104 iter/s, 28.0031s/100 iters), loss = 0.180206
I0528 21:44:58.592285 11123 solver.cpp:237]     Train net output #0: loss = 0.180205 (* 1 = 0.180205 loss)
I0528 21:44:58.592294 11123 sgd_solver.cpp:105] Iteration 34300, lr = 0.008285
I0528 21:45:01.984519 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:45:26.613358 11123 solver.cpp:218] Iteration 34400 (3.56879 iter/s, 28.0207s/100 iters), loss = 0.160269
I0528 21:45:26.613438 11123 solver.cpp:237]     Train net output #0: loss = 0.160268 (* 1 = 0.160268 loss)
I0528 21:45:26.613466 11123 sgd_solver.cpp:105] Iteration 34400, lr = 0.00828
I0528 21:45:54.574548 11123 solver.cpp:218] Iteration 34500 (3.57644 iter/s, 27.9608s/100 iters), loss = 0.0850682
I0528 21:45:54.574746 11123 solver.cpp:237]     Train net output #0: loss = 0.0850676 (* 1 = 0.0850676 loss)
I0528 21:45:54.574759 11123 sgd_solver.cpp:105] Iteration 34500, lr = 0.008275
I0528 21:46:22.560632 11123 solver.cpp:218] Iteration 34600 (3.57327 iter/s, 27.9855s/100 iters), loss = 0.0141735
I0528 21:46:22.560680 11123 solver.cpp:237]     Train net output #0: loss = 0.0141729 (* 1 = 0.0141729 loss)
I0528 21:46:22.560703 11123 sgd_solver.cpp:105] Iteration 34600, lr = 0.00827
I0528 21:46:50.535233 11123 solver.cpp:218] Iteration 34700 (3.57472 iter/s, 27.9742s/100 iters), loss = 0.150976
I0528 21:46:50.535461 11123 solver.cpp:237]     Train net output #0: loss = 0.150975 (* 1 = 0.150975 loss)
I0528 21:46:50.535472 11123 sgd_solver.cpp:105] Iteration 34700, lr = 0.008265
I0528 21:47:18.521551 11123 solver.cpp:218] Iteration 34800 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.0932155
I0528 21:47:18.521610 11123 solver.cpp:237]     Train net output #0: loss = 0.0932148 (* 1 = 0.0932148 loss)
I0528 21:47:18.521618 11123 sgd_solver.cpp:105] Iteration 34800, lr = 0.00826
I0528 21:47:46.495625 11123 solver.cpp:218] Iteration 34900 (3.57479 iter/s, 27.9736s/100 iters), loss = 0.166189
I0528 21:47:46.495852 11123 solver.cpp:237]     Train net output #0: loss = 0.166188 (* 1 = 0.166188 loss)
I0528 21:47:46.495865 11123 sgd_solver.cpp:105] Iteration 34900, lr = 0.008255
I0528 21:47:53.503401 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:48:14.199874 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_35000.caffemodel
I0528 21:48:14.617177 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_35000.solverstate
I0528 21:48:14.762841 11123 solver.cpp:330] Iteration 35000, Testing net (#0)
I0528 21:48:19.190981 11123 solver.cpp:397]     Test net output #0: accuracy = 0.875
I0528 21:48:19.191145 11123 solver.cpp:397]     Test net output #1: loss = 0.322751 (* 1 = 0.322751 loss)
I0528 21:48:19.467254 11123 solver.cpp:218] Iteration 35000 (3.03297 iter/s, 32.971s/100 iters), loss = 0.0162546
I0528 21:48:19.467301 11123 solver.cpp:237]     Train net output #0: loss = 0.0162541 (* 1 = 0.0162541 loss)
I0528 21:48:19.467309 11123 sgd_solver.cpp:105] Iteration 35000, lr = 0.00825
I0528 21:48:47.470818 11123 solver.cpp:218] Iteration 35100 (3.57103 iter/s, 28.0031s/100 iters), loss = 0.0351385
I0528 21:48:47.470865 11123 solver.cpp:237]     Train net output #0: loss = 0.0351378 (* 1 = 0.0351378 loss)
I0528 21:48:47.470873 11123 sgd_solver.cpp:105] Iteration 35100, lr = 0.008245
I0528 21:49:15.477290 11123 solver.cpp:218] Iteration 35200 (3.57066 iter/s, 28.006s/100 iters), loss = 0.0794723
I0528 21:49:15.477454 11123 solver.cpp:237]     Train net output #0: loss = 0.0794716 (* 1 = 0.0794716 loss)
I0528 21:49:15.477466 11123 sgd_solver.cpp:105] Iteration 35200, lr = 0.00824
I0528 21:49:43.484815 11123 solver.cpp:218] Iteration 35300 (3.57054 iter/s, 28.007s/100 iters), loss = 0.309086
I0528 21:49:43.484863 11123 solver.cpp:237]     Train net output #0: loss = 0.309085 (* 1 = 0.309085 loss)
I0528 21:49:43.484881 11123 sgd_solver.cpp:105] Iteration 35300, lr = 0.008235
I0528 21:50:11.470340 11123 solver.cpp:218] Iteration 35400 (3.57333 iter/s, 27.9851s/100 iters), loss = 0.330315
I0528 21:50:11.470562 11123 solver.cpp:237]     Train net output #0: loss = 0.330314 (* 1 = 0.330314 loss)
I0528 21:50:11.470573 11123 sgd_solver.cpp:105] Iteration 35400, lr = 0.00823
I0528 21:50:39.433368 11123 solver.cpp:218] Iteration 35500 (3.57623 iter/s, 27.9624s/100 iters), loss = 0.0820347
I0528 21:50:39.433410 11123 solver.cpp:237]     Train net output #0: loss = 0.0820341 (* 1 = 0.0820341 loss)
I0528 21:50:39.433419 11123 sgd_solver.cpp:105] Iteration 35500, lr = 0.008225
I0528 21:50:50.075719 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:51:07.406599 11123 solver.cpp:218] Iteration 35600 (3.5749 iter/s, 27.9728s/100 iters), loss = 0.036221
I0528 21:51:07.406641 11123 solver.cpp:237]     Train net output #0: loss = 0.0362204 (* 1 = 0.0362204 loss)
I0528 21:51:07.406651 11123 sgd_solver.cpp:105] Iteration 35600, lr = 0.00822
I0528 21:51:35.375195 11123 solver.cpp:218] Iteration 35700 (3.57549 iter/s, 27.9682s/100 iters), loss = 0.0307942
I0528 21:51:35.375399 11123 solver.cpp:237]     Train net output #0: loss = 0.0307935 (* 1 = 0.0307935 loss)
I0528 21:51:35.375411 11123 sgd_solver.cpp:105] Iteration 35700, lr = 0.008215
I0528 21:52:03.348239 11123 solver.cpp:218] Iteration 35800 (3.57495 iter/s, 27.9725s/100 iters), loss = 0.195981
I0528 21:52:03.348297 11123 solver.cpp:237]     Train net output #0: loss = 0.19598 (* 1 = 0.19598 loss)
I0528 21:52:03.348306 11123 sgd_solver.cpp:105] Iteration 35800, lr = 0.00821
I0528 21:52:31.307766 11123 solver.cpp:218] Iteration 35900 (3.57666 iter/s, 27.9591s/100 iters), loss = 0.0410105
I0528 21:52:31.307921 11123 solver.cpp:237]     Train net output #0: loss = 0.0410099 (* 1 = 0.0410099 loss)
I0528 21:52:31.307934 11123 sgd_solver.cpp:105] Iteration 35900, lr = 0.008205
I0528 21:52:58.994897 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_36000.caffemodel
I0528 21:52:59.300921 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_36000.solverstate
I0528 21:52:59.446070 11123 solver.cpp:330] Iteration 36000, Testing net (#0)
I0528 21:52:59.984256 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:53:03.906747 11123 solver.cpp:397]     Test net output #0: accuracy = 0.89
I0528 21:53:03.906895 11123 solver.cpp:397]     Test net output #1: loss = 0.280563 (* 1 = 0.280563 loss)
I0528 21:53:04.184325 11123 solver.cpp:218] Iteration 36000 (3.04174 iter/s, 32.8759s/100 iters), loss = 0.0353123
I0528 21:53:04.184372 11123 solver.cpp:237]     Train net output #0: loss = 0.0353117 (* 1 = 0.0353117 loss)
I0528 21:53:04.184384 11123 sgd_solver.cpp:105] Iteration 36000, lr = 0.0082
I0528 21:53:32.185310 11123 solver.cpp:218] Iteration 36100 (3.57136 iter/s, 28.0005s/100 iters), loss = 0.0337562
I0528 21:53:32.185359 11123 solver.cpp:237]     Train net output #0: loss = 0.0337556 (* 1 = 0.0337556 loss)
I0528 21:53:32.185384 11123 sgd_solver.cpp:105] Iteration 36100, lr = 0.008195
I0528 21:53:46.476743 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:54:00.190656 11123 solver.cpp:218] Iteration 36200 (3.5708 iter/s, 28.0049s/100 iters), loss = 0.0288904
I0528 21:54:00.190711 11123 solver.cpp:237]     Train net output #0: loss = 0.0288898 (* 1 = 0.0288898 loss)
I0528 21:54:00.190734 11123 sgd_solver.cpp:105] Iteration 36200, lr = 0.00819
I0528 21:54:28.186473 11123 solver.cpp:218] Iteration 36300 (3.57203 iter/s, 27.9953s/100 iters), loss = 0.0711683
I0528 21:54:28.186635 11123 solver.cpp:237]     Train net output #0: loss = 0.0711677 (* 1 = 0.0711677 loss)
I0528 21:54:28.186647 11123 sgd_solver.cpp:105] Iteration 36300, lr = 0.008185
I0528 21:54:56.189786 11123 solver.cpp:218] Iteration 36400 (3.57118 iter/s, 28.002s/100 iters), loss = 0.00699508
I0528 21:54:56.189842 11123 solver.cpp:237]     Train net output #0: loss = 0.00699451 (* 1 = 0.00699451 loss)
I0528 21:54:56.189851 11123 sgd_solver.cpp:105] Iteration 36400, lr = 0.00818
I0528 21:55:24.218029 11123 solver.cpp:218] Iteration 36500 (3.56799 iter/s, 28.027s/100 iters), loss = 0.157941
I0528 21:55:24.218257 11123 solver.cpp:237]     Train net output #0: loss = 0.157941 (* 1 = 0.157941 loss)
I0528 21:55:24.218286 11123 sgd_solver.cpp:105] Iteration 36500, lr = 0.008175
I0528 21:55:52.243927 11123 solver.cpp:218] Iteration 36600 (3.5683 iter/s, 28.0245s/100 iters), loss = 0.0174765
I0528 21:55:52.243978 11123 solver.cpp:237]     Train net output #0: loss = 0.017476 (* 1 = 0.017476 loss)
I0528 21:55:52.243990 11123 sgd_solver.cpp:105] Iteration 36600, lr = 0.00817
I0528 21:56:20.235522 11123 solver.cpp:218] Iteration 36700 (3.57265 iter/s, 27.9904s/100 iters), loss = 0.0346225
I0528 21:56:20.235677 11123 solver.cpp:237]     Train net output #0: loss = 0.034622 (* 1 = 0.034622 loss)
I0528 21:56:20.235697 11123 sgd_solver.cpp:105] Iteration 36700, lr = 0.008165
I0528 21:56:37.889606 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:56:48.322929 11123 solver.cpp:218] Iteration 36800 (3.56047 iter/s, 28.0862s/100 iters), loss = 0.00190864
I0528 21:56:48.322985 11123 solver.cpp:237]     Train net output #0: loss = 0.00190808 (* 1 = 0.00190808 loss)
I0528 21:56:48.322994 11123 sgd_solver.cpp:105] Iteration 36800, lr = 0.00816
I0528 21:57:16.357113 11123 solver.cpp:218] Iteration 36900 (3.56721 iter/s, 28.0331s/100 iters), loss = 0.0438777
I0528 21:57:16.357306 11123 solver.cpp:237]     Train net output #0: loss = 0.0438771 (* 1 = 0.0438771 loss)
I0528 21:57:16.357317 11123 sgd_solver.cpp:105] Iteration 36900, lr = 0.008155
I0528 21:57:44.049520 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_37000.caffemodel
I0528 21:57:44.354718 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_37000.solverstate
I0528 21:57:44.499197 11123 solver.cpp:330] Iteration 37000, Testing net (#0)
I0528 21:57:46.551182 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:57:48.950376 11123 solver.cpp:397]     Test net output #0: accuracy = 0.887
I0528 21:57:48.950412 11123 solver.cpp:397]     Test net output #1: loss = 0.318571 (* 1 = 0.318571 loss)
I0528 21:57:49.225037 11123 solver.cpp:218] Iteration 37000 (3.04261 iter/s, 32.8665s/100 iters), loss = 0.225249
I0528 21:57:49.225078 11123 solver.cpp:237]     Train net output #0: loss = 0.225248 (* 1 = 0.225248 loss)
I0528 21:57:49.225087 11123 sgd_solver.cpp:105] Iteration 37000, lr = 0.00815
I0528 21:58:17.209498 11123 solver.cpp:218] Iteration 37100 (3.57354 iter/s, 27.9834s/100 iters), loss = 0.00341745
I0528 21:58:17.209663 11123 solver.cpp:237]     Train net output #0: loss = 0.00341686 (* 1 = 0.00341686 loss)
I0528 21:58:17.209679 11123 sgd_solver.cpp:105] Iteration 37100, lr = 0.008145
I0528 21:58:45.195657 11123 solver.cpp:218] Iteration 37200 (3.57334 iter/s, 27.985s/100 iters), loss = 0.00307484
I0528 21:58:45.195708 11123 solver.cpp:237]     Train net output #0: loss = 0.00307424 (* 1 = 0.00307424 loss)
I0528 21:58:45.195719 11123 sgd_solver.cpp:105] Iteration 37200, lr = 0.00814
I0528 21:59:13.219560 11123 solver.cpp:218] Iteration 37300 (3.56851 iter/s, 28.0229s/100 iters), loss = 0.00544115
I0528 21:59:13.219722 11123 solver.cpp:237]     Train net output #0: loss = 0.00544052 (* 1 = 0.00544052 loss)
I0528 21:59:13.219738 11123 sgd_solver.cpp:105] Iteration 37300, lr = 0.008135
I0528 21:59:34.527568 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:59:41.230207 11123 solver.cpp:218] Iteration 37400 (3.57021 iter/s, 28.0096s/100 iters), loss = 0.00271609
I0528 21:59:41.230250 11123 solver.cpp:237]     Train net output #0: loss = 0.00271542 (* 1 = 0.00271542 loss)
I0528 21:59:41.230260 11123 sgd_solver.cpp:105] Iteration 37400, lr = 0.00813
I0528 22:00:09.236460 11123 solver.cpp:218] Iteration 37500 (3.57075 iter/s, 28.0053s/100 iters), loss = 0.0083071
I0528 22:00:09.236631 11123 solver.cpp:237]     Train net output #0: loss = 0.00830644 (* 1 = 0.00830644 loss)
I0528 22:00:09.236644 11123 sgd_solver.cpp:105] Iteration 37500, lr = 0.008125
I0528 22:00:37.222929 11123 solver.cpp:218] Iteration 37600 (3.57329 iter/s, 27.9854s/100 iters), loss = 0.186279
I0528 22:00:37.222987 11123 solver.cpp:237]     Train net output #0: loss = 0.186279 (* 1 = 0.186279 loss)
I0528 22:00:37.222996 11123 sgd_solver.cpp:105] Iteration 37600, lr = 0.00812
I0528 22:01:05.241188 11123 solver.cpp:218] Iteration 37700 (3.56922 iter/s, 28.0173s/100 iters), loss = 0.0287882
I0528 22:01:05.241353 11123 solver.cpp:237]     Train net output #0: loss = 0.0287875 (* 1 = 0.0287875 loss)
I0528 22:01:05.241364 11123 sgd_solver.cpp:105] Iteration 37700, lr = 0.008115
I0528 22:01:33.250174 11123 solver.cpp:218] Iteration 37800 (3.57041 iter/s, 28.008s/100 iters), loss = 0.205124
I0528 22:01:33.250216 11123 solver.cpp:237]     Train net output #0: loss = 0.205123 (* 1 = 0.205123 loss)
I0528 22:01:33.250226 11123 sgd_solver.cpp:105] Iteration 37800, lr = 0.00811
I0528 22:02:01.248324 11123 solver.cpp:218] Iteration 37900 (3.57178 iter/s, 27.9973s/100 iters), loss = 0.0399794
I0528 22:02:01.248564 11123 solver.cpp:237]     Train net output #0: loss = 0.0399787 (* 1 = 0.0399787 loss)
I0528 22:02:01.248579 11123 sgd_solver.cpp:105] Iteration 37900, lr = 0.008105
I0528 22:02:26.176811 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:02:28.960057 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_38000.caffemodel
I0528 22:02:29.263586 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_38000.solverstate
I0528 22:02:29.408694 11123 solver.cpp:330] Iteration 38000, Testing net (#0)
I0528 22:02:32.973624 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:02:33.861336 11123 solver.cpp:397]     Test net output #0: accuracy = 0.88
I0528 22:02:33.861392 11123 solver.cpp:397]     Test net output #1: loss = 0.459352 (* 1 = 0.459352 loss)
I0528 22:02:34.138044 11123 solver.cpp:218] Iteration 38000 (3.04057 iter/s, 32.8885s/100 iters), loss = 0.0870623
I0528 22:02:34.138087 11123 solver.cpp:237]     Train net output #0: loss = 0.0870617 (* 1 = 0.0870617 loss)
I0528 22:02:34.138097 11123 sgd_solver.cpp:105] Iteration 38000, lr = 0.0081
I0528 22:03:02.152390 11123 solver.cpp:218] Iteration 38100 (3.56971 iter/s, 28.0135s/100 iters), loss = 0.0471251
I0528 22:03:02.152433 11123 solver.cpp:237]     Train net output #0: loss = 0.0471245 (* 1 = 0.0471245 loss)
I0528 22:03:02.152441 11123 sgd_solver.cpp:105] Iteration 38100, lr = 0.008095
I0528 22:03:30.177094 11123 solver.cpp:218] Iteration 38200 (3.56839 iter/s, 28.0239s/100 iters), loss = 0.0654219
I0528 22:03:30.177248 11123 solver.cpp:237]     Train net output #0: loss = 0.0654213 (* 1 = 0.0654213 loss)
I0528 22:03:30.177261 11123 sgd_solver.cpp:105] Iteration 38200, lr = 0.00809
I0528 22:03:58.178220 11123 solver.cpp:218] Iteration 38300 (3.5714 iter/s, 28.0002s/100 iters), loss = 0.28943
I0528 22:03:58.178264 11123 solver.cpp:237]     Train net output #0: loss = 0.28943 (* 1 = 0.28943 loss)
I0528 22:03:58.178273 11123 sgd_solver.cpp:105] Iteration 38300, lr = 0.008085
I0528 22:04:26.192054 11123 solver.cpp:218] Iteration 38400 (3.56977 iter/s, 28.013s/100 iters), loss = 0.00648919
I0528 22:04:26.192199 11123 solver.cpp:237]     Train net output #0: loss = 0.00648864 (* 1 = 0.00648864 loss)
I0528 22:04:26.192222 11123 sgd_solver.cpp:105] Iteration 38400, lr = 0.00808
I0528 22:04:54.166048 11123 solver.cpp:218] Iteration 38500 (3.57486 iter/s, 27.9731s/100 iters), loss = 0.00746743
I0528 22:04:54.166100 11123 solver.cpp:237]     Train net output #0: loss = 0.00746689 (* 1 = 0.00746689 loss)
I0528 22:04:54.166110 11123 sgd_solver.cpp:105] Iteration 38500, lr = 0.008075
I0528 22:05:22.145472 11123 solver.cpp:218] Iteration 38600 (3.57416 iter/s, 27.9786s/100 iters), loss = 0.0175983
I0528 22:05:22.145759 11123 solver.cpp:237]     Train net output #0: loss = 0.0175978 (* 1 = 0.0175978 loss)
I0528 22:05:22.145771 11123 sgd_solver.cpp:105] Iteration 38600, lr = 0.00807
I0528 22:05:22.724591 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:05:50.113692 11123 solver.cpp:218] Iteration 38700 (3.57562 iter/s, 27.9672s/100 iters), loss = 0.0160998
I0528 22:05:50.113739 11123 solver.cpp:237]     Train net output #0: loss = 0.0160992 (* 1 = 0.0160992 loss)
I0528 22:05:50.113749 11123 sgd_solver.cpp:105] Iteration 38700, lr = 0.008065
I0528 22:06:18.103304 11123 solver.cpp:218] Iteration 38800 (3.57285 iter/s, 27.9888s/100 iters), loss = 0.0444803
I0528 22:06:18.103483 11123 solver.cpp:237]     Train net output #0: loss = 0.0444797 (* 1 = 0.0444797 loss)
I0528 22:06:18.103513 11123 sgd_solver.cpp:105] Iteration 38800, lr = 0.00806
I0528 22:06:46.111634 11123 solver.cpp:218] Iteration 38900 (3.57048 iter/s, 28.0074s/100 iters), loss = 0.0276032
I0528 22:06:46.111678 11123 solver.cpp:237]     Train net output #0: loss = 0.0276026 (* 1 = 0.0276026 loss)
I0528 22:06:46.111690 11123 sgd_solver.cpp:105] Iteration 38900, lr = 0.008055
I0528 22:07:13.879916 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_39000.caffemodel
I0528 22:07:14.188019 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_39000.solverstate
I0528 22:07:14.333462 11123 solver.cpp:330] Iteration 39000, Testing net (#0)
I0528 22:07:18.781738 11123 solver.cpp:397]     Test net output #0: accuracy = 0.839001
I0528 22:07:18.781780 11123 solver.cpp:397]     Test net output #1: loss = 0.521319 (* 1 = 0.521319 loss)
I0528 22:07:19.058537 11123 solver.cpp:218] Iteration 39000 (3.03527 iter/s, 32.946s/100 iters), loss = 0.0591524
I0528 22:07:19.058586 11123 solver.cpp:237]     Train net output #0: loss = 0.0591518 (* 1 = 0.0591518 loss)
I0528 22:07:19.058599 11123 sgd_solver.cpp:105] Iteration 39000, lr = 0.00805
I0528 22:07:47.029508 11123 solver.cpp:218] Iteration 39100 (3.57523 iter/s, 27.9702s/100 iters), loss = 0.205971
I0528 22:07:47.029724 11123 solver.cpp:237]     Train net output #0: loss = 0.20597 (* 1 = 0.20597 loss)
I0528 22:07:47.029742 11123 sgd_solver.cpp:105] Iteration 39100, lr = 0.008045
I0528 22:08:15.028122 11123 solver.cpp:218] Iteration 39200 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.0423242
I0528 22:08:15.028178 11123 solver.cpp:237]     Train net output #0: loss = 0.0423234 (* 1 = 0.0423234 loss)
I0528 22:08:15.028187 11123 sgd_solver.cpp:105] Iteration 39200, lr = 0.00804
I0528 22:08:19.245554 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:08:43.018755 11123 solver.cpp:218] Iteration 39300 (3.57272 iter/s, 27.9899s/100 iters), loss = 0.0140757
I0528 22:08:43.018798 11123 solver.cpp:237]     Train net output #0: loss = 0.0140749 (* 1 = 0.0140749 loss)
I0528 22:08:43.018806 11123 sgd_solver.cpp:105] Iteration 39300, lr = 0.008035
I0528 22:09:11.031195 11123 solver.cpp:218] Iteration 39400 (3.56993 iter/s, 28.0117s/100 iters), loss = 0.0184888
I0528 22:09:11.031401 11123 solver.cpp:237]     Train net output #0: loss = 0.018488 (* 1 = 0.018488 loss)
I0528 22:09:11.031417 11123 sgd_solver.cpp:105] Iteration 39400, lr = 0.00803
I0528 22:09:39.058115 11123 solver.cpp:218] Iteration 39500 (3.56811 iter/s, 28.0261s/100 iters), loss = 0.0281902
I0528 22:09:39.058164 11123 solver.cpp:237]     Train net output #0: loss = 0.0281894 (* 1 = 0.0281894 loss)
I0528 22:09:39.058177 11123 sgd_solver.cpp:105] Iteration 39500, lr = 0.008025
I0528 22:10:07.078727 11123 solver.cpp:218] Iteration 39600 (3.56889 iter/s, 28.0199s/100 iters), loss = 0.173667
I0528 22:10:07.078891 11123 solver.cpp:237]     Train net output #0: loss = 0.173667 (* 1 = 0.173667 loss)
I0528 22:10:07.078903 11123 sgd_solver.cpp:105] Iteration 39600, lr = 0.00802
I0528 22:10:35.095945 11123 solver.cpp:218] Iteration 39700 (3.56934 iter/s, 28.0164s/100 iters), loss = 0.105118
I0528 22:10:35.095986 11123 solver.cpp:237]     Train net output #0: loss = 0.105117 (* 1 = 0.105117 loss)
I0528 22:10:35.095994 11123 sgd_solver.cpp:105] Iteration 39700, lr = 0.008015
I0528 22:11:03.128504 11123 solver.cpp:218] Iteration 39800 (3.56737 iter/s, 28.0319s/100 iters), loss = 0.0182795
I0528 22:11:03.128690 11123 solver.cpp:237]     Train net output #0: loss = 0.0182788 (* 1 = 0.0182788 loss)
I0528 22:11:03.128702 11123 sgd_solver.cpp:105] Iteration 39800, lr = 0.00801
I0528 22:11:10.716429 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:11:31.147048 11123 solver.cpp:218] Iteration 39900 (3.56917 iter/s, 28.0177s/100 iters), loss = 0.245378
I0528 22:11:31.147091 11123 solver.cpp:237]     Train net output #0: loss = 0.245378 (* 1 = 0.245378 loss)
I0528 22:11:31.147100 11123 sgd_solver.cpp:105] Iteration 39900, lr = 0.008005
I0528 22:11:58.850240 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_40000.caffemodel
I0528 22:11:59.155854 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_40000.solverstate
I0528 22:11:59.300742 11123 solver.cpp:330] Iteration 40000, Testing net (#0)
I0528 22:11:59.887650 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:12:03.761353 11123 solver.cpp:397]     Test net output #0: accuracy = 0.914
I0528 22:12:03.761390 11123 solver.cpp:397]     Test net output #1: loss = 0.2461 (* 1 = 0.2461 loss)
I0528 22:12:04.039038 11123 solver.cpp:218] Iteration 40000 (3.04033 iter/s, 32.8912s/100 iters), loss = 0.0450268
I0528 22:12:04.039088 11123 solver.cpp:237]     Train net output #0: loss = 0.0450262 (* 1 = 0.0450262 loss)
I0528 22:12:04.039110 11123 sgd_solver.cpp:105] Iteration 40000, lr = 0.008
I0528 22:12:32.067994 11123 solver.cpp:218] Iteration 40100 (3.56783 iter/s, 28.0283s/100 iters), loss = 0.107993
I0528 22:12:32.068198 11123 solver.cpp:237]     Train net output #0: loss = 0.107992 (* 1 = 0.107992 loss)
I0528 22:12:32.068217 11123 sgd_solver.cpp:105] Iteration 40100, lr = 0.007995
I0528 22:13:00.065158 11123 solver.cpp:218] Iteration 40200 (3.5719 iter/s, 27.9963s/100 iters), loss = 0.0138554
I0528 22:13:00.065212 11123 solver.cpp:237]     Train net output #0: loss = 0.0138548 (* 1 = 0.0138548 loss)
I0528 22:13:00.065224 11123 sgd_solver.cpp:105] Iteration 40200, lr = 0.00799
I0528 22:13:28.096130 11123 solver.cpp:218] Iteration 40300 (3.56757 iter/s, 28.0303s/100 iters), loss = 0.168616
I0528 22:13:28.096294 11123 solver.cpp:237]     Train net output #0: loss = 0.168616 (* 1 = 0.168616 loss)
I0528 22:13:28.096312 11123 sgd_solver.cpp:105] Iteration 40300, lr = 0.007985
I0528 22:13:56.098645 11123 solver.cpp:218] Iteration 40400 (3.57121 iter/s, 28.0017s/100 iters), loss = 0.0305739
I0528 22:13:56.098695 11123 solver.cpp:237]     Train net output #0: loss = 0.0305733 (* 1 = 0.0305733 loss)
I0528 22:13:56.098707 11123 sgd_solver.cpp:105] Iteration 40400, lr = 0.00798
I0528 22:14:07.320559 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:14:24.096771 11123 solver.cpp:218] Iteration 40500 (3.57175 iter/s, 27.9975s/100 iters), loss = 0.00123855
I0528 22:14:24.096822 11123 solver.cpp:237]     Train net output #0: loss = 0.00123788 (* 1 = 0.00123788 loss)
I0528 22:14:24.096837 11123 sgd_solver.cpp:105] Iteration 40500, lr = 0.007975
I0528 22:14:52.075623 11123 solver.cpp:218] Iteration 40600 (3.57421 iter/s, 27.9782s/100 iters), loss = 0.0324501
I0528 22:14:52.075790 11123 solver.cpp:237]     Train net output #0: loss = 0.0324495 (* 1 = 0.0324495 loss)
I0528 22:14:52.075819 11123 sgd_solver.cpp:105] Iteration 40600, lr = 0.00797
I0528 22:15:20.192297 11123 solver.cpp:218] Iteration 40700 (3.55671 iter/s, 28.1159s/100 iters), loss = 0.0055437
I0528 22:15:20.192345 11123 solver.cpp:237]     Train net output #0: loss = 0.00554302 (* 1 = 0.00554302 loss)
I0528 22:15:20.192354 11123 sgd_solver.cpp:105] Iteration 40700, lr = 0.007965
I0528 22:15:48.180270 11123 solver.cpp:218] Iteration 40800 (3.57305 iter/s, 27.9873s/100 iters), loss = 0.0817831
I0528 22:15:48.180444 11123 solver.cpp:237]     Train net output #0: loss = 0.0817824 (* 1 = 0.0817824 loss)
I0528 22:15:48.180460 11123 sgd_solver.cpp:105] Iteration 40800, lr = 0.00796
I0528 22:16:16.179960 11123 solver.cpp:218] Iteration 40900 (3.57157 iter/s, 27.9989s/100 iters), loss = 0.00740271
I0528 22:16:16.180009 11123 solver.cpp:237]     Train net output #0: loss = 0.00740205 (* 1 = 0.00740205 loss)
I0528 22:16:16.180022 11123 sgd_solver.cpp:105] Iteration 40900, lr = 0.007955
I0528 22:16:43.920719 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_41000.caffemodel
I0528 22:16:44.250057 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_41000.solverstate
I0528 22:16:44.395602 11123 solver.cpp:330] Iteration 41000, Testing net (#0)
I0528 22:16:46.493958 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:16:48.843320 11123 solver.cpp:397]     Test net output #0: accuracy = 0.885
I0528 22:16:48.843359 11123 solver.cpp:397]     Test net output #1: loss = 0.352753 (* 1 = 0.352753 loss)
I0528 22:16:49.119612 11123 solver.cpp:218] Iteration 41000 (3.03592 iter/s, 32.9389s/100 iters), loss = 0.0222604
I0528 22:16:49.119658 11123 solver.cpp:237]     Train net output #0: loss = 0.0222598 (* 1 = 0.0222598 loss)
I0528 22:16:49.119683 11123 sgd_solver.cpp:105] Iteration 41000, lr = 0.00795
I0528 22:17:04.007643 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:17:17.146780 11123 solver.cpp:218] Iteration 41100 (3.56805 iter/s, 28.0265s/100 iters), loss = 0.025602
I0528 22:17:17.146981 11123 solver.cpp:237]     Train net output #0: loss = 0.0256014 (* 1 = 0.0256014 loss)
I0528 22:17:17.146992 11123 sgd_solver.cpp:105] Iteration 41100, lr = 0.007945
I0528 22:17:45.132410 11123 solver.cpp:218] Iteration 41200 (3.57336 iter/s, 27.9848s/100 iters), loss = 0.0455112
I0528 22:17:45.132465 11123 solver.cpp:237]     Train net output #0: loss = 0.0455106 (* 1 = 0.0455106 loss)
I0528 22:17:45.132474 11123 sgd_solver.cpp:105] Iteration 41200, lr = 0.00794
I0528 22:18:13.124343 11123 solver.cpp:218] Iteration 41300 (3.57254 iter/s, 27.9913s/100 iters), loss = 0.00137403
I0528 22:18:13.124514 11123 solver.cpp:237]     Train net output #0: loss = 0.00137342 (* 1 = 0.00137342 loss)
I0528 22:18:13.124547 11123 sgd_solver.cpp:105] Iteration 41300, lr = 0.007935
I0528 22:18:41.113603 11123 solver.cpp:218] Iteration 41400 (3.5729 iter/s, 27.9885s/100 iters), loss = 0.112381
I0528 22:18:41.113656 11123 solver.cpp:237]     Train net output #0: loss = 0.11238 (* 1 = 0.11238 loss)
I0528 22:18:41.113669 11123 sgd_solver.cpp:105] Iteration 41400, lr = 0.00793
I0528 22:19:09.147120 11123 solver.cpp:218] Iteration 41500 (3.56724 iter/s, 28.0329s/100 iters), loss = 0.0389267
I0528 22:19:09.147281 11123 solver.cpp:237]     Train net output #0: loss = 0.0389261 (* 1 = 0.0389261 loss)
I0528 22:19:09.147296 11123 sgd_solver.cpp:105] Iteration 41500, lr = 0.007925
I0528 22:19:37.145756 11123 solver.cpp:218] Iteration 41600 (3.5717 iter/s, 27.9979s/100 iters), loss = 0.0153924
I0528 22:19:37.145814 11123 solver.cpp:237]     Train net output #0: loss = 0.0153917 (* 1 = 0.0153917 loss)
I0528 22:19:37.145823 11123 sgd_solver.cpp:105] Iteration 41600, lr = 0.00792
I0528 22:19:55.637543 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:20:05.146347 11123 solver.cpp:218] Iteration 41700 (3.57144 iter/s, 27.9999s/100 iters), loss = 0.0204374
I0528 22:20:05.146391 11123 solver.cpp:237]     Train net output #0: loss = 0.0204368 (* 1 = 0.0204368 loss)
I0528 22:20:05.146400 11123 sgd_solver.cpp:105] Iteration 41700, lr = 0.007915
I0528 22:20:33.136396 11123 solver.cpp:218] Iteration 41800 (3.57278 iter/s, 27.9894s/100 iters), loss = 0.00205517
I0528 22:20:33.136556 11123 solver.cpp:237]     Train net output #0: loss = 0.00205455 (* 1 = 0.00205455 loss)
I0528 22:20:33.136571 11123 sgd_solver.cpp:105] Iteration 41800, lr = 0.00791
I0528 22:21:01.134400 11123 solver.cpp:218] Iteration 41900 (3.57178 iter/s, 27.9973s/100 iters), loss = 0.0929281
I0528 22:21:01.134443 11123 solver.cpp:237]     Train net output #0: loss = 0.0929275 (* 1 = 0.0929275 loss)
I0528 22:21:01.134450 11123 sgd_solver.cpp:105] Iteration 41900, lr = 0.007905
I0528 22:21:28.859742 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_42000.caffemodel
I0528 22:21:29.170605 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_42000.solverstate
I0528 22:21:29.322485 11123 solver.cpp:330] Iteration 42000, Testing net (#0)
I0528 22:21:32.930191 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:21:33.771414 11123 solver.cpp:397]     Test net output #0: accuracy = 0.901
I0528 22:21:33.771464 11123 solver.cpp:397]     Test net output #1: loss = 0.35237 (* 1 = 0.35237 loss)
I0528 22:21:34.047627 11123 solver.cpp:218] Iteration 42000 (3.03836 iter/s, 32.9125s/100 iters), loss = 0.0184059
I0528 22:21:34.047672 11123 solver.cpp:237]     Train net output #0: loss = 0.0184053 (* 1 = 0.0184053 loss)
I0528 22:21:34.047680 11123 sgd_solver.cpp:105] Iteration 42000, lr = 0.0079
I0528 22:22:02.002499 11123 solver.cpp:218] Iteration 42100 (3.57727 iter/s, 27.9542s/100 iters), loss = 0.0117404
I0528 22:22:02.002733 11123 solver.cpp:237]     Train net output #0: loss = 0.0117398 (* 1 = 0.0117398 loss)
I0528 22:22:02.002745 11123 sgd_solver.cpp:105] Iteration 42100, lr = 0.007895
I0528 22:22:30.008591 11123 solver.cpp:218] Iteration 42200 (3.57076 iter/s, 28.0053s/100 iters), loss = 0.00770283
I0528 22:22:30.008638 11123 solver.cpp:237]     Train net output #0: loss = 0.00770219 (* 1 = 0.00770219 loss)
I0528 22:22:30.008661 11123 sgd_solver.cpp:105] Iteration 42200, lr = 0.00789
I0528 22:22:52.152498 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:22:58.018630 11123 solver.cpp:218] Iteration 42300 (3.57023 iter/s, 28.0094s/100 iters), loss = 0.0451121
I0528 22:22:58.018679 11123 solver.cpp:237]     Train net output #0: loss = 0.0451115 (* 1 = 0.0451115 loss)
I0528 22:22:58.018692 11123 sgd_solver.cpp:105] Iteration 42300, lr = 0.007885
I0528 22:23:26.036087 11123 solver.cpp:218] Iteration 42400 (3.56928 iter/s, 28.0168s/100 iters), loss = 0.0218915
I0528 22:23:26.036231 11123 solver.cpp:237]     Train net output #0: loss = 0.0218909 (* 1 = 0.0218909 loss)
I0528 22:23:26.036250 11123 sgd_solver.cpp:105] Iteration 42400, lr = 0.00788
I0528 22:23:54.049319 11123 solver.cpp:218] Iteration 42500 (3.56983 iter/s, 28.0125s/100 iters), loss = 0.0281349
I0528 22:23:54.049371 11123 solver.cpp:237]     Train net output #0: loss = 0.0281343 (* 1 = 0.0281343 loss)
I0528 22:23:54.049383 11123 sgd_solver.cpp:105] Iteration 42500, lr = 0.007875
I0528 22:24:22.061686 11123 solver.cpp:218] Iteration 42600 (3.56993 iter/s, 28.0117s/100 iters), loss = 0.00285129
I0528 22:24:22.061897 11123 solver.cpp:237]     Train net output #0: loss = 0.00285065 (* 1 = 0.00285065 loss)
I0528 22:24:22.061910 11123 sgd_solver.cpp:105] Iteration 42600, lr = 0.00787
I0528 22:24:50.076845 11123 solver.cpp:218] Iteration 42700 (3.56959 iter/s, 28.0144s/100 iters), loss = 0.00713469
I0528 22:24:50.076889 11123 solver.cpp:237]     Train net output #0: loss = 0.00713402 (* 1 = 0.00713402 loss)
I0528 22:24:50.076897 11123 sgd_solver.cpp:105] Iteration 42700, lr = 0.007865
I0528 22:25:18.095957 11123 solver.cpp:218] Iteration 42800 (3.56907 iter/s, 28.0185s/100 iters), loss = 0.0121185
I0528 22:25:18.096159 11123 solver.cpp:237]     Train net output #0: loss = 0.0121178 (* 1 = 0.0121178 loss)
I0528 22:25:18.096171 11123 sgd_solver.cpp:105] Iteration 42800, lr = 0.00786
I0528 22:25:43.585678 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:25:46.086004 11123 solver.cpp:218] Iteration 42900 (3.57279 iter/s, 27.9893s/100 iters), loss = 0.0544645
I0528 22:25:46.086047 11123 solver.cpp:237]     Train net output #0: loss = 0.0544639 (* 1 = 0.0544639 loss)
I0528 22:25:46.086056 11123 sgd_solver.cpp:105] Iteration 42900, lr = 0.007855
I0528 22:26:13.808616 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_43000.caffemodel
I0528 22:26:14.113597 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_43000.solverstate
I0528 22:26:14.259119 11123 solver.cpp:330] Iteration 43000, Testing net (#0)
I0528 22:26:18.681888 11123 solver.cpp:397]     Test net output #0: accuracy = 0.878
I0528 22:26:18.681927 11123 solver.cpp:397]     Test net output #1: loss = 0.42867 (* 1 = 0.42867 loss)
I0528 22:26:18.958873 11123 solver.cpp:218] Iteration 43000 (3.04209 iter/s, 32.8722s/100 iters), loss = 0.00579888
I0528 22:26:18.958920 11123 solver.cpp:237]     Train net output #0: loss = 0.00579814 (* 1 = 0.00579814 loss)
I0528 22:26:18.958927 11123 sgd_solver.cpp:105] Iteration 43000, lr = 0.00785
I0528 22:26:46.957232 11123 solver.cpp:218] Iteration 43100 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.03018
I0528 22:26:46.957401 11123 solver.cpp:237]     Train net output #0: loss = 0.0301793 (* 1 = 0.0301793 loss)
I0528 22:26:46.957412 11123 sgd_solver.cpp:105] Iteration 43100, lr = 0.007845
I0528 22:27:14.964929 11123 solver.cpp:218] Iteration 43200 (3.57054 iter/s, 28.007s/100 iters), loss = 0.0462718
I0528 22:27:14.964977 11123 solver.cpp:237]     Train net output #0: loss = 0.0462711 (* 1 = 0.0462711 loss)
I0528 22:27:14.964987 11123 sgd_solver.cpp:105] Iteration 43200, lr = 0.00784
I0528 22:27:42.959564 11123 solver.cpp:218] Iteration 43300 (3.57219 iter/s, 27.994s/100 iters), loss = 0.00422304
I0528 22:27:42.959810 11123 solver.cpp:237]     Train net output #0: loss = 0.00422238 (* 1 = 0.00422238 loss)
I0528 22:27:42.959822 11123 sgd_solver.cpp:105] Iteration 43300, lr = 0.007835
I0528 22:28:10.950655 11123 solver.cpp:218] Iteration 43400 (3.57267 iter/s, 27.9903s/100 iters), loss = 0.0707539
I0528 22:28:10.950706 11123 solver.cpp:237]     Train net output #0: loss = 0.0707533 (* 1 = 0.0707533 loss)
I0528 22:28:10.950714 11123 sgd_solver.cpp:105] Iteration 43400, lr = 0.00783
I0528 22:28:38.918488 11123 solver.cpp:218] Iteration 43500 (3.57561 iter/s, 27.9672s/100 iters), loss = 0.0173361
I0528 22:28:38.918670 11123 solver.cpp:237]     Train net output #0: loss = 0.0173354 (* 1 = 0.0173354 loss)
I0528 22:28:38.918681 11123 sgd_solver.cpp:105] Iteration 43500, lr = 0.007825
I0528 22:28:40.058650 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:29:06.894731 11123 solver.cpp:218] Iteration 43600 (3.57454 iter/s, 27.9757s/100 iters), loss = 0.00288053
I0528 22:29:06.894783 11123 solver.cpp:237]     Train net output #0: loss = 0.00287983 (* 1 = 0.00287983 loss)
I0528 22:29:06.894791 11123 sgd_solver.cpp:105] Iteration 43600, lr = 0.00782
I0528 22:29:34.911125 11123 solver.cpp:218] Iteration 43700 (3.5694 iter/s, 28.0159s/100 iters), loss = 0.00885606
I0528 22:29:34.911303 11123 solver.cpp:237]     Train net output #0: loss = 0.00885536 (* 1 = 0.00885536 loss)
I0528 22:29:34.911314 11123 sgd_solver.cpp:105] Iteration 43700, lr = 0.007815
I0528 22:30:02.932780 11123 solver.cpp:218] Iteration 43800 (3.56874 iter/s, 28.0211s/100 iters), loss = 0.0640248
I0528 22:30:02.932829 11123 solver.cpp:237]     Train net output #0: loss = 0.064024 (* 1 = 0.064024 loss)
I0528 22:30:02.932838 11123 sgd_solver.cpp:105] Iteration 43800, lr = 0.00781
I0528 22:30:30.944627 11123 solver.cpp:218] Iteration 43900 (3.56998 iter/s, 28.0114s/100 iters), loss = 0.00156059
I0528 22:30:30.944754 11123 solver.cpp:237]     Train net output #0: loss = 0.00155977 (* 1 = 0.00155977 loss)
I0528 22:30:30.944766 11123 sgd_solver.cpp:105] Iteration 43900, lr = 0.007805
I0528 22:30:58.690634 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_44000.caffemodel
I0528 22:30:58.998970 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_44000.solverstate
I0528 22:30:59.144740 11123 solver.cpp:330] Iteration 44000, Testing net (#0)
I0528 22:30:59.822180 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:31:03.608582 11123 solver.cpp:397]     Test net output #0: accuracy = 0.902
I0528 22:31:03.608741 11123 solver.cpp:397]     Test net output #1: loss = 0.303934 (* 1 = 0.303934 loss)
I0528 22:31:03.885673 11123 solver.cpp:218] Iteration 44000 (3.03578 iter/s, 32.9404s/100 iters), loss = 0.0127995
I0528 22:31:03.885722 11123 solver.cpp:237]     Train net output #0: loss = 0.0127987 (* 1 = 0.0127987 loss)
I0528 22:31:03.885731 11123 sgd_solver.cpp:105] Iteration 44000, lr = 0.0078
I0528 22:31:31.885799 11123 solver.cpp:218] Iteration 44100 (3.57147 iter/s, 27.9996s/100 iters), loss = 0.00928374
I0528 22:31:31.885870 11123 solver.cpp:237]     Train net output #0: loss = 0.00928287 (* 1 = 0.00928287 loss)
I0528 22:31:31.885895 11123 sgd_solver.cpp:105] Iteration 44100, lr = 0.007795
I0528 22:31:36.671109 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:31:59.917230 11123 solver.cpp:218] Iteration 44200 (3.56749 iter/s, 28.0309s/100 iters), loss = 0.0184719
I0528 22:31:59.917290 11123 solver.cpp:237]     Train net output #0: loss = 0.018471 (* 1 = 0.018471 loss)
I0528 22:31:59.917304 11123 sgd_solver.cpp:105] Iteration 44200, lr = 0.00779
I0528 22:32:27.923292 11123 solver.cpp:218] Iteration 44300 (3.57072 iter/s, 28.0056s/100 iters), loss = 0.00448659
I0528 22:32:27.923470 11123 solver.cpp:237]     Train net output #0: loss = 0.00448574 (* 1 = 0.00448574 loss)
I0528 22:32:27.923481 11123 sgd_solver.cpp:105] Iteration 44300, lr = 0.007785
I0528 22:32:55.915098 11123 solver.cpp:218] Iteration 44400 (3.57255 iter/s, 27.9912s/100 iters), loss = 0.0181378
I0528 22:32:55.915148 11123 solver.cpp:237]     Train net output #0: loss = 0.018137 (* 1 = 0.018137 loss)
I0528 22:32:55.915156 11123 sgd_solver.cpp:105] Iteration 44400, lr = 0.00778
I0528 22:33:23.960414 11123 solver.cpp:218] Iteration 44500 (3.56572 iter/s, 28.0448s/100 iters), loss = 0.0154543
I0528 22:33:23.960593 11123 solver.cpp:237]     Train net output #0: loss = 0.0154535 (* 1 = 0.0154535 loss)
I0528 22:33:23.960604 11123 sgd_solver.cpp:105] Iteration 44500, lr = 0.007775
I0528 22:33:51.973896 11123 solver.cpp:218] Iteration 44600 (3.56979 iter/s, 28.0128s/100 iters), loss = 0.0386776
I0528 22:33:51.973947 11123 solver.cpp:237]     Train net output #0: loss = 0.0386768 (* 1 = 0.0386768 loss)
I0528 22:33:51.973955 11123 sgd_solver.cpp:105] Iteration 44600, lr = 0.00777
I0528 22:34:19.986730 11123 solver.cpp:218] Iteration 44700 (3.56986 iter/s, 28.0123s/100 iters), loss = 0.100537
I0528 22:34:19.986899 11123 solver.cpp:237]     Train net output #0: loss = 0.100536 (* 1 = 0.100536 loss)
I0528 22:34:19.986910 11123 sgd_solver.cpp:105] Iteration 44700, lr = 0.007765
I0528 22:34:28.402534 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:34:47.989955 11123 solver.cpp:218] Iteration 44800 (3.5711 iter/s, 28.0026s/100 iters), loss = 0.0178127
I0528 22:34:47.990003 11123 solver.cpp:237]     Train net output #0: loss = 0.017812 (* 1 = 0.017812 loss)
I0528 22:34:47.990011 11123 sgd_solver.cpp:105] Iteration 44800, lr = 0.00776
I0528 22:35:16.023809 11123 solver.cpp:218] Iteration 44900 (3.56718 iter/s, 28.0333s/100 iters), loss = 0.0333229
I0528 22:35:16.023977 11123 solver.cpp:237]     Train net output #0: loss = 0.0333222 (* 1 = 0.0333222 loss)
I0528 22:35:16.023989 11123 sgd_solver.cpp:105] Iteration 44900, lr = 0.007755
I0528 22:35:43.773747 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_45000.caffemodel
I0528 22:35:44.085853 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_45000.solverstate
I0528 22:35:44.230912 11123 solver.cpp:330] Iteration 45000, Testing net (#0)
I0528 22:35:46.414865 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:35:48.679744 11123 solver.cpp:397]     Test net output #0: accuracy = 0.894
I0528 22:35:48.679795 11123 solver.cpp:397]     Test net output #1: loss = 0.341514 (* 1 = 0.341514 loss)
I0528 22:35:48.956743 11123 solver.cpp:218] Iteration 45000 (3.03654 iter/s, 32.9322s/100 iters), loss = 0.0240224
I0528 22:35:48.956789 11123 solver.cpp:237]     Train net output #0: loss = 0.0240216 (* 1 = 0.0240216 loss)
I0528 22:35:48.956797 11123 sgd_solver.cpp:105] Iteration 45000, lr = 0.00775
I0528 22:36:16.930752 11123 solver.cpp:218] Iteration 45100 (3.57481 iter/s, 27.9735s/100 iters), loss = 0.0670683
I0528 22:36:16.930960 11123 solver.cpp:237]     Train net output #0: loss = 0.0670675 (* 1 = 0.0670675 loss)
I0528 22:36:16.930974 11123 sgd_solver.cpp:105] Iteration 45100, lr = 0.007745
I0528 22:36:44.916532 11123 solver.cpp:218] Iteration 45200 (3.57333 iter/s, 27.9851s/100 iters), loss = 0.0213958
I0528 22:36:44.916584 11123 solver.cpp:237]     Train net output #0: loss = 0.021395 (* 1 = 0.021395 loss)
I0528 22:36:44.916592 11123 sgd_solver.cpp:105] Iteration 45200, lr = 0.00774
I0528 22:37:12.899394 11123 solver.cpp:218] Iteration 45300 (3.57368 iter/s, 27.9823s/100 iters), loss = 0.00559138
I0528 22:37:12.899606 11123 solver.cpp:237]     Train net output #0: loss = 0.00559059 (* 1 = 0.00559059 loss)
I0528 22:37:12.899619 11123 sgd_solver.cpp:105] Iteration 45300, lr = 0.007735
I0528 22:37:24.940822 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:37:40.868736 11123 solver.cpp:218] Iteration 45400 (3.57543 iter/s, 27.9686s/100 iters), loss = 0.0189438
I0528 22:37:40.868782 11123 solver.cpp:237]     Train net output #0: loss = 0.018943 (* 1 = 0.018943 loss)
I0528 22:37:40.868793 11123 sgd_solver.cpp:105] Iteration 45400, lr = 0.00773
I0528 22:38:08.848691 11123 solver.cpp:218] Iteration 45500 (3.57406 iter/s, 27.9794s/100 iters), loss = 0.00687036
I0528 22:38:08.848902 11123 solver.cpp:237]     Train net output #0: loss = 0.00686958 (* 1 = 0.00686958 loss)
I0528 22:38:08.848913 11123 sgd_solver.cpp:105] Iteration 45500, lr = 0.007725
I0528 22:38:36.820051 11123 solver.cpp:218] Iteration 45600 (3.57517 iter/s, 27.9707s/100 iters), loss = 0.0385146
I0528 22:38:36.820096 11123 solver.cpp:237]     Train net output #0: loss = 0.0385138 (* 1 = 0.0385138 loss)
I0528 22:38:36.820106 11123 sgd_solver.cpp:105] Iteration 45600, lr = 0.00772
I0528 22:39:04.793371 11123 solver.cpp:218] Iteration 45700 (3.5749 iter/s, 27.9728s/100 iters), loss = 0.000587571
I0528 22:39:04.793529 11123 solver.cpp:237]     Train net output #0: loss = 0.00058676 (* 1 = 0.00058676 loss)
I0528 22:39:04.793541 11123 sgd_solver.cpp:105] Iteration 45700, lr = 0.007715
I0528 22:39:32.764330 11123 solver.cpp:218] Iteration 45800 (3.57522 iter/s, 27.9703s/100 iters), loss = 0.0519795
I0528 22:39:32.764374 11123 solver.cpp:237]     Train net output #0: loss = 0.0519787 (* 1 = 0.0519787 loss)
I0528 22:39:32.764384 11123 sgd_solver.cpp:105] Iteration 45800, lr = 0.00771
I0528 22:40:00.740164 11123 solver.cpp:218] Iteration 45900 (3.57458 iter/s, 27.9753s/100 iters), loss = 0.0122727
I0528 22:40:00.740330 11123 solver.cpp:237]     Train net output #0: loss = 0.0122719 (* 1 = 0.0122719 loss)
I0528 22:40:00.740342 11123 sgd_solver.cpp:105] Iteration 45900, lr = 0.007705
I0528 22:40:16.156103 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:40:28.451431 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_46000.caffemodel
I0528 22:40:28.756218 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_46000.solverstate
I0528 22:40:28.900936 11123 solver.cpp:330] Iteration 46000, Testing net (#0)
I0528 22:40:32.598518 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:40:33.351665 11123 solver.cpp:397]     Test net output #0: accuracy = 0.837
I0528 22:40:33.351717 11123 solver.cpp:397]     Test net output #1: loss = 0.557787 (* 1 = 0.557787 loss)
I0528 22:40:33.627768 11123 solver.cpp:218] Iteration 46000 (3.04073 iter/s, 32.8868s/100 iters), loss = 0.00406502
I0528 22:40:33.627826 11123 solver.cpp:237]     Train net output #0: loss = 0.00406433 (* 1 = 0.00406433 loss)
I0528 22:40:33.627835 11123 sgd_solver.cpp:105] Iteration 46000, lr = 0.0077
I0528 22:41:01.614666 11123 solver.cpp:218] Iteration 46100 (3.57317 iter/s, 27.9863s/100 iters), loss = 0.00210184
I0528 22:41:01.614729 11123 solver.cpp:237]     Train net output #0: loss = 0.00210118 (* 1 = 0.00210118 loss)
I0528 22:41:01.614738 11123 sgd_solver.cpp:105] Iteration 46100, lr = 0.007695
I0528 22:41:29.646742 11123 solver.cpp:218] Iteration 46200 (3.56742 iter/s, 28.0315s/100 iters), loss = 0.248722
I0528 22:41:29.646908 11123 solver.cpp:237]     Train net output #0: loss = 0.248721 (* 1 = 0.248721 loss)
I0528 22:41:29.646919 11123 sgd_solver.cpp:105] Iteration 46200, lr = 0.00769
I0528 22:41:57.650998 11123 solver.cpp:218] Iteration 46300 (3.57097 iter/s, 28.0036s/100 iters), loss = 0.00224249
I0528 22:41:57.651053 11123 solver.cpp:237]     Train net output #0: loss = 0.0022418 (* 1 = 0.0022418 loss)
I0528 22:41:57.651063 11123 sgd_solver.cpp:105] Iteration 46300, lr = 0.007685
I0528 22:42:25.667209 11123 solver.cpp:218] Iteration 46400 (3.56944 iter/s, 28.0156s/100 iters), loss = 0.0236531
I0528 22:42:25.667378 11123 solver.cpp:237]     Train net output #0: loss = 0.0236525 (* 1 = 0.0236525 loss)
I0528 22:42:25.667389 11123 sgd_solver.cpp:105] Iteration 46400, lr = 0.00768
I0528 22:42:53.675674 11123 solver.cpp:218] Iteration 46500 (3.57044 iter/s, 28.0078s/100 iters), loss = 0.0185864
I0528 22:42:53.675729 11123 solver.cpp:237]     Train net output #0: loss = 0.0185858 (* 1 = 0.0185858 loss)
I0528 22:42:53.675739 11123 sgd_solver.cpp:105] Iteration 46500, lr = 0.007675
I0528 22:43:12.766621 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:43:21.714722 11123 solver.cpp:218] Iteration 46600 (3.56653 iter/s, 28.0385s/100 iters), loss = 0.220057
I0528 22:43:21.714771 11123 solver.cpp:237]     Train net output #0: loss = 0.220056 (* 1 = 0.220056 loss)
I0528 22:43:21.714779 11123 sgd_solver.cpp:105] Iteration 46600, lr = 0.00767
I0528 22:43:49.740659 11123 solver.cpp:218] Iteration 46700 (3.5682 iter/s, 28.0254s/100 iters), loss = 0.244903
I0528 22:43:49.740782 11123 solver.cpp:237]     Train net output #0: loss = 0.244902 (* 1 = 0.244902 loss)
I0528 22:43:49.740793 11123 sgd_solver.cpp:105] Iteration 46700, lr = 0.007665
I0528 22:44:17.757410 11123 solver.cpp:218] Iteration 46800 (3.56937 iter/s, 28.0161s/100 iters), loss = 0.0147034
I0528 22:44:17.757459 11123 solver.cpp:237]     Train net output #0: loss = 0.0147026 (* 1 = 0.0147026 loss)
I0528 22:44:17.757468 11123 sgd_solver.cpp:105] Iteration 46800, lr = 0.00766
I0528 22:44:45.765089 11123 solver.cpp:218] Iteration 46900 (3.57052 iter/s, 28.0071s/100 iters), loss = 0.00656763
I0528 22:44:45.765257 11123 solver.cpp:237]     Train net output #0: loss = 0.00656684 (* 1 = 0.00656684 loss)
I0528 22:44:45.765269 11123 sgd_solver.cpp:105] Iteration 46900, lr = 0.007655
I0528 22:45:13.483997 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_47000.caffemodel
I0528 22:45:13.796274 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_47000.solverstate
I0528 22:45:13.941786 11123 solver.cpp:330] Iteration 47000, Testing net (#0)
I0528 22:45:18.390344 11123 solver.cpp:397]     Test net output #0: accuracy = 0.901
I0528 22:45:18.390496 11123 solver.cpp:397]     Test net output #1: loss = 0.314033 (* 1 = 0.314033 loss)
I0528 22:45:18.666144 11123 solver.cpp:218] Iteration 47000 (3.03949 iter/s, 32.9003s/100 iters), loss = 0.0749222
I0528 22:45:18.666193 11123 solver.cpp:237]     Train net output #0: loss = 0.0749214 (* 1 = 0.0749214 loss)
I0528 22:45:18.666201 11123 sgd_solver.cpp:105] Iteration 47000, lr = 0.00765
I0528 22:45:46.631214 11123 solver.cpp:218] Iteration 47100 (3.57596 iter/s, 27.9645s/100 iters), loss = 0.0144012
I0528 22:45:46.631263 11123 solver.cpp:237]     Train net output #0: loss = 0.0144004 (* 1 = 0.0144004 loss)
I0528 22:45:46.631271 11123 sgd_solver.cpp:105] Iteration 47100, lr = 0.007645
I0528 22:46:09.309412 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:46:14.608028 11123 solver.cpp:218] Iteration 47200 (3.57446 iter/s, 27.9762s/100 iters), loss = 0.00393806
I0528 22:46:14.608070 11123 solver.cpp:237]     Train net output #0: loss = 0.00393735 (* 1 = 0.00393735 loss)
I0528 22:46:14.608078 11123 sgd_solver.cpp:105] Iteration 47200, lr = 0.00764
I0528 22:46:42.576125 11123 solver.cpp:218] Iteration 47300 (3.57557 iter/s, 27.9675s/100 iters), loss = 0.00080409
I0528 22:46:42.576334 11123 solver.cpp:237]     Train net output #0: loss = 0.000803335 (* 1 = 0.000803335 loss)
I0528 22:46:42.576345 11123 sgd_solver.cpp:105] Iteration 47300, lr = 0.007635
I0528 22:47:10.576131 11123 solver.cpp:218] Iteration 47400 (3.57152 iter/s, 27.9993s/100 iters), loss = 0.00359182
I0528 22:47:10.576179 11123 solver.cpp:237]     Train net output #0: loss = 0.00359105 (* 1 = 0.00359105 loss)
I0528 22:47:10.576189 11123 sgd_solver.cpp:105] Iteration 47400, lr = 0.00763
I0528 22:47:38.573976 11123 solver.cpp:218] Iteration 47500 (3.57178 iter/s, 27.9973s/100 iters), loss = 0.0490947
I0528 22:47:38.574143 11123 solver.cpp:237]     Train net output #0: loss = 0.0490939 (* 1 = 0.0490939 loss)
I0528 22:47:38.574156 11123 sgd_solver.cpp:105] Iteration 47500, lr = 0.007625
I0528 22:48:06.553092 11123 solver.cpp:218] Iteration 47600 (3.57418 iter/s, 27.9784s/100 iters), loss = 0.00566462
I0528 22:48:06.553138 11123 solver.cpp:237]     Train net output #0: loss = 0.00566383 (* 1 = 0.00566383 loss)
I0528 22:48:06.553148 11123 sgd_solver.cpp:105] Iteration 47600, lr = 0.00762
I0528 22:48:34.518950 11123 solver.cpp:218] Iteration 47700 (3.57586 iter/s, 27.9653s/100 iters), loss = 0.00719862
I0528 22:48:34.519182 11123 solver.cpp:237]     Train net output #0: loss = 0.00719789 (* 1 = 0.00719789 loss)
I0528 22:48:34.519194 11123 sgd_solver.cpp:105] Iteration 47700, lr = 0.007615
I0528 22:49:00.851874 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:49:02.519459 11123 solver.cpp:218] Iteration 47800 (3.57146 iter/s, 27.9998s/100 iters), loss = 0.138319
I0528 22:49:02.519500 11123 solver.cpp:237]     Train net output #0: loss = 0.138318 (* 1 = 0.138318 loss)
I0528 22:49:02.519508 11123 sgd_solver.cpp:105] Iteration 47800, lr = 0.00761
I0528 22:49:30.530864 11123 solver.cpp:218] Iteration 47900 (3.57005 iter/s, 28.0108s/100 iters), loss = 0.00412298
I0528 22:49:30.531069 11123 solver.cpp:237]     Train net output #0: loss = 0.0041223 (* 1 = 0.0041223 loss)
I0528 22:49:30.531085 11123 sgd_solver.cpp:105] Iteration 47900, lr = 0.007605
I0528 22:49:58.256178 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_48000.caffemodel
I0528 22:49:58.563282 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_48000.solverstate
I0528 22:49:58.708519 11123 solver.cpp:330] Iteration 48000, Testing net (#0)
I0528 22:49:59.470221 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:50:03.161759 11123 solver.cpp:397]     Test net output #0: accuracy = 0.887
I0528 22:50:03.161919 11123 solver.cpp:397]     Test net output #1: loss = 0.360159 (* 1 = 0.360159 loss)
I0528 22:50:03.438645 11123 solver.cpp:218] Iteration 48000 (3.03887 iter/s, 32.907s/100 iters), loss = 0.0148481
I0528 22:50:03.438688 11123 solver.cpp:237]     Train net output #0: loss = 0.0148474 (* 1 = 0.0148474 loss)
I0528 22:50:03.438697 11123 sgd_solver.cpp:105] Iteration 48000, lr = 0.0076
I0528 22:50:31.417430 11123 solver.cpp:218] Iteration 48100 (3.57421 iter/s, 27.9782s/100 iters), loss = 0.0182469
I0528 22:50:31.417479 11123 solver.cpp:237]     Train net output #0: loss = 0.0182462 (* 1 = 0.0182462 loss)
I0528 22:50:31.417490 11123 sgd_solver.cpp:105] Iteration 48100, lr = 0.007595
I0528 22:50:59.393820 11123 solver.cpp:218] Iteration 48200 (3.57452 iter/s, 27.9758s/100 iters), loss = 0.00384717
I0528 22:50:59.394001 11123 solver.cpp:237]     Train net output #0: loss = 0.00384653 (* 1 = 0.00384653 loss)
I0528 22:50:59.394024 11123 sgd_solver.cpp:105] Iteration 48200, lr = 0.00759
I0528 22:51:27.394902 11123 solver.cpp:218] Iteration 48300 (3.57138 iter/s, 28.0004s/100 iters), loss = 0.00426858
I0528 22:51:27.394961 11123 solver.cpp:237]     Train net output #0: loss = 0.00426793 (* 1 = 0.00426793 loss)
I0528 22:51:27.394971 11123 sgd_solver.cpp:105] Iteration 48300, lr = 0.007585
I0528 22:51:55.401373 11123 solver.cpp:218] Iteration 48400 (3.57068 iter/s, 28.0059s/100 iters), loss = 0.0451211
I0528 22:51:55.401525 11123 solver.cpp:237]     Train net output #0: loss = 0.0451205 (* 1 = 0.0451205 loss)
I0528 22:51:55.401535 11123 sgd_solver.cpp:105] Iteration 48400, lr = 0.00758
I0528 22:51:57.379994 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:52:23.433951 11123 solver.cpp:218] Iteration 48500 (3.56736 iter/s, 28.0319s/100 iters), loss = 0.142622
I0528 22:52:23.433996 11123 solver.cpp:237]     Train net output #0: loss = 0.142622 (* 1 = 0.142622 loss)
I0528 22:52:23.434016 11123 sgd_solver.cpp:105] Iteration 48500, lr = 0.007575
I0528 22:52:51.426877 11123 solver.cpp:218] Iteration 48600 (3.5724 iter/s, 27.9923s/100 iters), loss = 0.0500049
I0528 22:52:51.427086 11123 solver.cpp:237]     Train net output #0: loss = 0.0500042 (* 1 = 0.0500042 loss)
I0528 22:52:51.427098 11123 sgd_solver.cpp:105] Iteration 48600, lr = 0.00757
I0528 22:53:19.426494 11123 solver.cpp:218] Iteration 48700 (3.57157 iter/s, 27.9989s/100 iters), loss = 0.312067
I0528 22:53:19.426538 11123 solver.cpp:237]     Train net output #0: loss = 0.312066 (* 1 = 0.312066 loss)
I0528 22:53:19.426548 11123 sgd_solver.cpp:105] Iteration 48700, lr = 0.007565
I0528 22:53:47.391959 11123 solver.cpp:218] Iteration 48800 (3.57591 iter/s, 27.9649s/100 iters), loss = 0.030026
I0528 22:53:47.392164 11123 solver.cpp:237]     Train net output #0: loss = 0.0300253 (* 1 = 0.0300253 loss)
I0528 22:53:47.392175 11123 sgd_solver.cpp:105] Iteration 48800, lr = 0.00756
I0528 22:54:15.373358 11123 solver.cpp:218] Iteration 48900 (3.5739 iter/s, 27.9807s/100 iters), loss = 0.0272421
I0528 22:54:15.373414 11123 solver.cpp:237]     Train net output #0: loss = 0.0272415 (* 1 = 0.0272415 loss)
I0528 22:54:15.373423 11123 sgd_solver.cpp:105] Iteration 48900, lr = 0.007555
I0528 22:54:43.065852 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_49000.caffemodel
I0528 22:54:43.373790 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_49000.solverstate
I0528 22:54:43.519078 11123 solver.cpp:330] Iteration 49000, Testing net (#0)
I0528 22:54:45.794778 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:54:47.968997 11123 solver.cpp:397]     Test net output #0: accuracy = 0.915001
I0528 22:54:47.969049 11123 solver.cpp:397]     Test net output #1: loss = 0.262351 (* 1 = 0.262351 loss)
I0528 22:54:48.245338 11123 solver.cpp:218] Iteration 49000 (3.04217 iter/s, 32.8713s/100 iters), loss = 0.00109519
I0528 22:54:48.245400 11123 solver.cpp:237]     Train net output #0: loss = 0.00109456 (* 1 = 0.00109456 loss)
I0528 22:54:48.245409 11123 sgd_solver.cpp:105] Iteration 49000, lr = 0.00755
I0528 22:54:53.583864 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:55:16.247862 11123 solver.cpp:218] Iteration 49100 (3.57118 iter/s, 28.0019s/100 iters), loss = 0.0119406
I0528 22:55:16.248035 11123 solver.cpp:237]     Train net output #0: loss = 0.01194 (* 1 = 0.01194 loss)
I0528 22:55:16.248047 11123 sgd_solver.cpp:105] Iteration 49100, lr = 0.007545
I0528 22:55:44.225878 11123 solver.cpp:218] Iteration 49200 (3.57433 iter/s, 27.9773s/100 iters), loss = 0.0127096
I0528 22:55:44.225925 11123 solver.cpp:237]     Train net output #0: loss = 0.012709 (* 1 = 0.012709 loss)
I0528 22:55:44.225934 11123 sgd_solver.cpp:105] Iteration 49200, lr = 0.00754
I0528 22:56:12.193934 11123 solver.cpp:218] Iteration 49300 (3.57558 iter/s, 27.9675s/100 iters), loss = 0.0500572
I0528 22:56:12.194144 11123 solver.cpp:237]     Train net output #0: loss = 0.0500566 (* 1 = 0.0500566 loss)
I0528 22:56:12.194155 11123 sgd_solver.cpp:105] Iteration 49300, lr = 0.007535
I0528 22:56:40.178970 11123 solver.cpp:218] Iteration 49400 (3.57343 iter/s, 27.9843s/100 iters), loss = 0.0017092
I0528 22:56:40.179016 11123 solver.cpp:237]     Train net output #0: loss = 0.00170855 (* 1 = 0.00170855 loss)
I0528 22:56:40.179024 11123 sgd_solver.cpp:105] Iteration 49400, lr = 0.00753
I0528 22:57:08.176525 11123 solver.cpp:218] Iteration 49500 (3.57181 iter/s, 27.997s/100 iters), loss = 0.0436356
I0528 22:57:08.176700 11123 solver.cpp:237]     Train net output #0: loss = 0.0436349 (* 1 = 0.0436349 loss)
I0528 22:57:08.176738 11123 sgd_solver.cpp:105] Iteration 49500, lr = 0.007525
I0528 22:57:36.162935 11123 solver.cpp:218] Iteration 49600 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.0269732
I0528 22:57:36.162983 11123 solver.cpp:237]     Train net output #0: loss = 0.0269725 (* 1 = 0.0269725 loss)
I0528 22:57:36.162992 11123 sgd_solver.cpp:105] Iteration 49600, lr = 0.00752
I0528 22:57:45.141865 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:58:04.175011 11123 solver.cpp:218] Iteration 49700 (3.56996 iter/s, 28.0115s/100 iters), loss = 0.00506455
I0528 22:58:04.175060 11123 solver.cpp:237]     Train net output #0: loss = 0.00506387 (* 1 = 0.00506387 loss)
I0528 22:58:04.175070 11123 sgd_solver.cpp:105] Iteration 49700, lr = 0.007515
I0528 22:58:32.131778 11123 solver.cpp:218] Iteration 49800 (3.57703 iter/s, 27.9562s/100 iters), loss = 0.0160344
I0528 22:58:32.131942 11123 solver.cpp:237]     Train net output #0: loss = 0.0160336 (* 1 = 0.0160336 loss)
I0528 22:58:32.131953 11123 sgd_solver.cpp:105] Iteration 49800, lr = 0.00751
I0528 22:59:00.140877 11123 solver.cpp:218] Iteration 49900 (3.57036 iter/s, 28.0084s/100 iters), loss = 0.266613
I0528 22:59:00.140933 11123 solver.cpp:237]     Train net output #0: loss = 0.266613 (* 1 = 0.266613 loss)
I0528 22:59:00.140941 11123 sgd_solver.cpp:105] Iteration 49900, lr = 0.007505
I0528 22:59:27.867548 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_50000.caffemodel
I0528 22:59:28.175863 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_50000.solverstate
I0528 22:59:28.322188 11123 solver.cpp:330] Iteration 50000, Testing net (#0)
I0528 22:59:32.110772 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:59:32.776463 11123 solver.cpp:397]     Test net output #0: accuracy = 0.901
I0528 22:59:32.776511 11123 solver.cpp:397]     Test net output #1: loss = 0.289396 (* 1 = 0.289396 loss)
I0528 22:59:33.053076 11123 solver.cpp:218] Iteration 50000 (3.03845 iter/s, 32.9115s/100 iters), loss = 0.02738
I0528 22:59:33.053117 11123 solver.cpp:237]     Train net output #0: loss = 0.0273793 (* 1 = 0.0273793 loss)
I0528 22:59:33.053127 11123 sgd_solver.cpp:105] Iteration 50000, lr = 0.0075
I0528 23:00:01.023386 11123 solver.cpp:218] Iteration 50100 (3.57529 iter/s, 27.9697s/100 iters), loss = 0.030259
I0528 23:00:01.023602 11123 solver.cpp:237]     Train net output #0: loss = 0.0302583 (* 1 = 0.0302583 loss)
I0528 23:00:01.023628 11123 sgd_solver.cpp:105] Iteration 50100, lr = 0.007495
I0528 23:00:29.009847 11123 solver.cpp:218] Iteration 50200 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.14194
I0528 23:00:29.009905 11123 solver.cpp:237]     Train net output #0: loss = 0.141939 (* 1 = 0.141939 loss)
I0528 23:00:29.009913 11123 sgd_solver.cpp:105] Iteration 50200, lr = 0.00749
I0528 23:00:41.624758 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:00:57.000531 11123 solver.cpp:218] Iteration 50300 (3.57269 iter/s, 27.9901s/100 iters), loss = 0.0399841
I0528 23:00:57.000576 11123 solver.cpp:237]     Train net output #0: loss = 0.0399833 (* 1 = 0.0399833 loss)
I0528 23:00:57.000586 11123 sgd_solver.cpp:105] Iteration 50300, lr = 0.007485
I0528 23:01:25.031705 11123 solver.cpp:218] Iteration 50400 (3.56753 iter/s, 28.0306s/100 iters), loss = 0.00312544
I0528 23:01:25.031801 11123 solver.cpp:237]     Train net output #0: loss = 0.00312467 (* 1 = 0.00312467 loss)
I0528 23:01:25.031811 11123 sgd_solver.cpp:105] Iteration 50400, lr = 0.00748
I0528 23:01:53.056711 11123 solver.cpp:218] Iteration 50500 (3.56832 iter/s, 28.0244s/100 iters), loss = 0.0142355
I0528 23:01:53.056758 11123 solver.cpp:237]     Train net output #0: loss = 0.0142347 (* 1 = 0.0142347 loss)
I0528 23:01:53.056771 11123 sgd_solver.cpp:105] Iteration 50500, lr = 0.007475
I0528 23:02:21.087047 11123 solver.cpp:218] Iteration 50600 (3.56764 iter/s, 28.0297s/100 iters), loss = 0.00573721
I0528 23:02:21.087222 11123 solver.cpp:237]     Train net output #0: loss = 0.0057364 (* 1 = 0.0057364 loss)
I0528 23:02:21.087234 11123 sgd_solver.cpp:105] Iteration 50600, lr = 0.00747
I0528 23:02:49.087978 11123 solver.cpp:218] Iteration 50700 (3.5714 iter/s, 28.0002s/100 iters), loss = 0.15782
I0528 23:02:49.088026 11123 solver.cpp:237]     Train net output #0: loss = 0.157819 (* 1 = 0.157819 loss)
I0528 23:02:49.088034 11123 sgd_solver.cpp:105] Iteration 50700, lr = 0.007465
I0528 23:03:17.100119 11123 solver.cpp:218] Iteration 50800 (3.56995 iter/s, 28.0116s/100 iters), loss = 0.000214234
I0528 23:03:17.100267 11123 solver.cpp:237]     Train net output #0: loss = 0.000213381 (* 1 = 0.000213381 loss)
I0528 23:03:17.100280 11123 sgd_solver.cpp:105] Iteration 50800, lr = 0.00746
I0528 23:03:33.349354 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:03:45.091341 11123 solver.cpp:218] Iteration 50900 (3.57263 iter/s, 27.9906s/100 iters), loss = 0.192266
I0528 23:03:45.091385 11123 solver.cpp:237]     Train net output #0: loss = 0.192265 (* 1 = 0.192265 loss)
I0528 23:03:45.091393 11123 sgd_solver.cpp:105] Iteration 50900, lr = 0.007455
I0528 23:04:12.814210 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_51000.caffemodel
I0528 23:04:13.121640 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_51000.solverstate
I0528 23:04:13.266865 11123 solver.cpp:330] Iteration 51000, Testing net (#0)
I0528 23:04:17.712446 11123 solver.cpp:397]     Test net output #0: accuracy = 0.875
I0528 23:04:17.712486 11123 solver.cpp:397]     Test net output #1: loss = 0.449491 (* 1 = 0.449491 loss)
I0528 23:04:17.989276 11123 solver.cpp:218] Iteration 51000 (3.03976 iter/s, 32.8973s/100 iters), loss = 0.271691
I0528 23:04:17.989322 11123 solver.cpp:237]     Train net output #0: loss = 0.27169 (* 1 = 0.27169 loss)
I0528 23:04:17.989331 11123 sgd_solver.cpp:105] Iteration 51000, lr = 0.00745
I0528 23:04:45.960296 11123 solver.cpp:218] Iteration 51100 (3.5752 iter/s, 27.9705s/100 iters), loss = 0.00267907
I0528 23:04:45.960469 11123 solver.cpp:237]     Train net output #0: loss = 0.00267818 (* 1 = 0.00267818 loss)
I0528 23:04:45.960480 11123 sgd_solver.cpp:105] Iteration 51100, lr = 0.007445
I0528 23:05:13.974370 11123 solver.cpp:218] Iteration 51200 (3.56972 iter/s, 28.0134s/100 iters), loss = 0.000579722
I0528 23:05:13.974428 11123 solver.cpp:237]     Train net output #0: loss = 0.000578814 (* 1 = 0.000578814 loss)
I0528 23:05:13.974437 11123 sgd_solver.cpp:105] Iteration 51200, lr = 0.00744
I0528 23:05:41.973670 11123 solver.cpp:218] Iteration 51300 (3.57159 iter/s, 27.9988s/100 iters), loss = 0.00110268
I0528 23:05:41.973837 11123 solver.cpp:237]     Train net output #0: loss = 0.00110178 (* 1 = 0.00110178 loss)
I0528 23:05:41.973850 11123 sgd_solver.cpp:105] Iteration 51300, lr = 0.007435
I0528 23:06:09.971190 11123 solver.cpp:218] Iteration 51400 (3.57183 iter/s, 27.9969s/100 iters), loss = 0.262031
I0528 23:06:09.971236 11123 solver.cpp:237]     Train net output #0: loss = 0.26203 (* 1 = 0.26203 loss)
I0528 23:06:09.971245 11123 sgd_solver.cpp:105] Iteration 51400, lr = 0.00743
I0528 23:06:29.852023 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:06:37.960167 11123 solver.cpp:218] Iteration 51500 (3.5729 iter/s, 27.9884s/100 iters), loss = 0.0173676
I0528 23:06:37.960227 11123 solver.cpp:237]     Train net output #0: loss = 0.0173666 (* 1 = 0.0173666 loss)
I0528 23:06:37.960237 11123 sgd_solver.cpp:105] Iteration 51500, lr = 0.007425
I0528 23:07:05.990876 11123 solver.cpp:218] Iteration 51600 (3.56759 iter/s, 28.0302s/100 iters), loss = 0.00156218
I0528 23:07:05.991071 11123 solver.cpp:237]     Train net output #0: loss = 0.00156117 (* 1 = 0.00156117 loss)
I0528 23:07:05.991106 11123 sgd_solver.cpp:105] Iteration 51600, lr = 0.00742
I0528 23:07:34.026634 11123 solver.cpp:218] Iteration 51700 (3.56696 iter/s, 28.0351s/100 iters), loss = 0.0108352
I0528 23:07:34.026679 11123 solver.cpp:237]     Train net output #0: loss = 0.0108342 (* 1 = 0.0108342 loss)
I0528 23:07:34.026687 11123 sgd_solver.cpp:105] Iteration 51700, lr = 0.007415
I0528 23:08:02.053514 11123 solver.cpp:218] Iteration 51800 (3.56807 iter/s, 28.0263s/100 iters), loss = 0.0286435
I0528 23:08:02.053730 11123 solver.cpp:237]     Train net output #0: loss = 0.0286424 (* 1 = 0.0286424 loss)
I0528 23:08:02.053742 11123 sgd_solver.cpp:105] Iteration 51800, lr = 0.00741
I0528 23:08:30.063711 11123 solver.cpp:218] Iteration 51900 (3.57022 iter/s, 28.0095s/100 iters), loss = 0.00192985
I0528 23:08:30.063755 11123 solver.cpp:237]     Train net output #0: loss = 0.00192881 (* 1 = 0.00192881 loss)
I0528 23:08:30.063762 11123 sgd_solver.cpp:105] Iteration 51900, lr = 0.007405
I0528 23:08:57.787608 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_52000.caffemodel
I0528 23:08:58.094058 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_52000.solverstate
I0528 23:08:58.239323 11123 solver.cpp:330] Iteration 52000, Testing net (#0)
I0528 23:08:59.089730 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:09:02.700222 11123 solver.cpp:397]     Test net output #0: accuracy = 0.917
I0528 23:09:02.700275 11123 solver.cpp:397]     Test net output #1: loss = 0.233112 (* 1 = 0.233112 loss)
I0528 23:09:02.978469 11123 solver.cpp:218] Iteration 52000 (3.03821 iter/s, 32.9141s/100 iters), loss = 0.017458
I0528 23:09:02.978518 11123 solver.cpp:237]     Train net output #0: loss = 0.0174568 (* 1 = 0.0174568 loss)
I0528 23:09:02.978526 11123 sgd_solver.cpp:105] Iteration 52000, lr = 0.0074
I0528 23:09:26.252954 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:09:30.997894 11123 solver.cpp:218] Iteration 52100 (3.56902 iter/s, 28.0189s/100 iters), loss = 0.0179411
I0528 23:09:30.998086 11123 solver.cpp:237]     Train net output #0: loss = 0.01794 (* 1 = 0.01794 loss)
I0528 23:09:30.998098 11123 sgd_solver.cpp:105] Iteration 52100, lr = 0.007395
I0528 23:09:58.999845 11123 solver.cpp:218] Iteration 52200 (3.57127 iter/s, 28.0013s/100 iters), loss = 0.0202662
I0528 23:09:58.999887 11123 solver.cpp:237]     Train net output #0: loss = 0.020265 (* 1 = 0.020265 loss)
I0528 23:09:58.999897 11123 sgd_solver.cpp:105] Iteration 52200, lr = 0.00739
I0528 23:10:27.007236 11123 solver.cpp:218] Iteration 52300 (3.57056 iter/s, 28.0068s/100 iters), loss = 0.0009943
I0528 23:10:27.007375 11123 solver.cpp:237]     Train net output #0: loss = 0.000993226 (* 1 = 0.000993226 loss)
I0528 23:10:27.007386 11123 sgd_solver.cpp:105] Iteration 52300, lr = 0.007385
I0528 23:10:55.002694 11123 solver.cpp:218] Iteration 52400 (3.57209 iter/s, 27.9948s/100 iters), loss = 0.000167225
I0528 23:10:55.002735 11123 solver.cpp:237]     Train net output #0: loss = 0.000166177 (* 1 = 0.000166177 loss)
I0528 23:10:55.002744 11123 sgd_solver.cpp:105] Iteration 52400, lr = 0.00738
I0528 23:11:22.999461 11123 solver.cpp:218] Iteration 52500 (3.57191 iter/s, 27.9962s/100 iters), loss = 0.00309251
I0528 23:11:22.999626 11123 solver.cpp:237]     Train net output #0: loss = 0.00309148 (* 1 = 0.00309148 loss)
I0528 23:11:22.999639 11123 sgd_solver.cpp:105] Iteration 52500, lr = 0.007375
I0528 23:11:50.966040 11123 solver.cpp:218] Iteration 52600 (3.57578 iter/s, 27.9659s/100 iters), loss = 0.0488918
I0528 23:11:50.966084 11123 solver.cpp:237]     Train net output #0: loss = 0.0488907 (* 1 = 0.0488907 loss)
I0528 23:11:50.966104 11123 sgd_solver.cpp:105] Iteration 52600, lr = 0.00737
I0528 23:12:17.854416 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:12:18.956714 11123 solver.cpp:218] Iteration 52700 (3.57269 iter/s, 27.9901s/100 iters), loss = 0.0696156
I0528 23:12:18.956769 11123 solver.cpp:237]     Train net output #0: loss = 0.0696145 (* 1 = 0.0696145 loss)
I0528 23:12:18.956779 11123 sgd_solver.cpp:105] Iteration 52700, lr = 0.007365
I0528 23:12:46.909859 11123 solver.cpp:218] Iteration 52800 (3.57749 iter/s, 27.9526s/100 iters), loss = 0.0139885
I0528 23:12:46.909904 11123 solver.cpp:237]     Train net output #0: loss = 0.0139874 (* 1 = 0.0139874 loss)
I0528 23:12:46.909914 11123 sgd_solver.cpp:105] Iteration 52800, lr = 0.00736
I0528 23:13:14.888043 11123 solver.cpp:218] Iteration 52900 (3.57428 iter/s, 27.9776s/100 iters), loss = 0.00130505
I0528 23:13:14.888202 11123 solver.cpp:237]     Train net output #0: loss = 0.001304 (* 1 = 0.001304 loss)
I0528 23:13:14.888213 11123 sgd_solver.cpp:105] Iteration 52900, lr = 0.007355
I0528 23:13:42.607084 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_53000.caffemodel
I0528 23:13:42.911576 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_53000.solverstate
I0528 23:13:43.056722 11123 solver.cpp:330] Iteration 53000, Testing net (#0)
I0528 23:13:45.375470 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:13:47.507397 11123 solver.cpp:397]     Test net output #0: accuracy = 0.856
I0528 23:13:47.507444 11123 solver.cpp:397]     Test net output #1: loss = 0.595057 (* 1 = 0.595057 loss)
I0528 23:13:47.784901 11123 solver.cpp:218] Iteration 53000 (3.03987 iter/s, 32.8961s/100 iters), loss = 0.00241079
I0528 23:13:47.784966 11123 solver.cpp:237]     Train net output #0: loss = 0.00240974 (* 1 = 0.00240974 loss)
I0528 23:13:47.784976 11123 sgd_solver.cpp:105] Iteration 53000, lr = 0.00735
I0528 23:14:15.759845 11123 solver.cpp:218] Iteration 53100 (3.5747 iter/s, 27.9744s/100 iters), loss = 0.0293553
I0528 23:14:15.760027 11123 solver.cpp:237]     Train net output #0: loss = 0.0293543 (* 1 = 0.0293543 loss)
I0528 23:14:15.760040 11123 sgd_solver.cpp:105] Iteration 53100, lr = 0.007345
I0528 23:14:43.730967 11123 solver.cpp:218] Iteration 53200 (3.5752 iter/s, 27.9704s/100 iters), loss = 0.000761718
I0528 23:14:43.731014 11123 solver.cpp:237]     Train net output #0: loss = 0.000760678 (* 1 = 0.000760678 loss)
I0528 23:14:43.731022 11123 sgd_solver.cpp:105] Iteration 53200, lr = 0.00734
I0528 23:15:11.727891 11123 solver.cpp:218] Iteration 53300 (3.57189 iter/s, 27.9964s/100 iters), loss = 0.00433544
I0528 23:15:11.728060 11123 solver.cpp:237]     Train net output #0: loss = 0.00433442 (* 1 = 0.00433442 loss)
I0528 23:15:11.728072 11123 sgd_solver.cpp:105] Iteration 53300, lr = 0.007335
I0528 23:15:14.265727 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:15:39.712723 11123 solver.cpp:218] Iteration 53400 (3.57345 iter/s, 27.9842s/100 iters), loss = 0.0241143
I0528 23:15:39.712772 11123 solver.cpp:237]     Train net output #0: loss = 0.0241133 (* 1 = 0.0241133 loss)
I0528 23:15:39.712781 11123 sgd_solver.cpp:105] Iteration 53400, lr = 0.00733
I0528 23:16:07.688974 11123 solver.cpp:218] Iteration 53500 (3.57453 iter/s, 27.9757s/100 iters), loss = 0.000975126
I0528 23:16:07.689141 11123 solver.cpp:237]     Train net output #0: loss = 0.000974109 (* 1 = 0.000974109 loss)
I0528 23:16:07.689153 11123 sgd_solver.cpp:105] Iteration 53500, lr = 0.007325
I0528 23:16:35.641721 11123 solver.cpp:218] Iteration 53600 (3.57755 iter/s, 27.9521s/100 iters), loss = 0.00486146
I0528 23:16:35.641765 11123 solver.cpp:237]     Train net output #0: loss = 0.00486046 (* 1 = 0.00486046 loss)
I0528 23:16:35.641774 11123 sgd_solver.cpp:105] Iteration 53600, lr = 0.00732
I0528 23:17:03.627009 11123 solver.cpp:218] Iteration 53700 (3.57338 iter/s, 27.9847s/100 iters), loss = 0.0864115
I0528 23:17:03.627279 11123 solver.cpp:237]     Train net output #0: loss = 0.0864105 (* 1 = 0.0864105 loss)
I0528 23:17:03.627291 11123 sgd_solver.cpp:105] Iteration 53700, lr = 0.007315
I0528 23:17:31.658634 11123 solver.cpp:218] Iteration 53800 (3.5675 iter/s, 28.0308s/100 iters), loss = 0.00524156
I0528 23:17:31.658682 11123 solver.cpp:237]     Train net output #0: loss = 0.00524056 (* 1 = 0.00524056 loss)
I0528 23:17:31.658691 11123 sgd_solver.cpp:105] Iteration 53800, lr = 0.00731
I0528 23:17:59.674626 11123 solver.cpp:218] Iteration 53900 (3.56946 iter/s, 28.0154s/100 iters), loss = 0.0128457
I0528 23:17:59.674798 11123 solver.cpp:237]     Train net output #0: loss = 0.0128447 (* 1 = 0.0128447 loss)
I0528 23:17:59.674809 11123 sgd_solver.cpp:105] Iteration 53900, lr = 0.007305
I0528 23:18:05.858037 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:18:27.409587 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_54000.caffemodel
I0528 23:18:27.772214 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_54000.solverstate
I0528 23:18:27.917223 11123 solver.cpp:330] Iteration 54000, Testing net (#0)
I0528 23:18:31.746894 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:18:32.365447 11123 solver.cpp:397]     Test net output #0: accuracy = 0.911
I0528 23:18:32.365496 11123 solver.cpp:397]     Test net output #1: loss = 0.378803 (* 1 = 0.378803 loss)
I0528 23:18:32.641258 11123 solver.cpp:218] Iteration 54000 (3.03344 iter/s, 32.9658s/100 iters), loss = 0.000250052
I0528 23:18:32.641314 11123 solver.cpp:237]     Train net output #0: loss = 0.000249069 (* 1 = 0.000249069 loss)
I0528 23:18:32.641322 11123 sgd_solver.cpp:105] Iteration 54000, lr = 0.0073
I0528 23:19:00.660338 11123 solver.cpp:218] Iteration 54100 (3.56907 iter/s, 28.0185s/100 iters), loss = 0.430705
I0528 23:19:00.660394 11123 solver.cpp:237]     Train net output #0: loss = 0.430704 (* 1 = 0.430704 loss)
I0528 23:19:00.660403 11123 sgd_solver.cpp:105] Iteration 54100, lr = 0.007295
I0528 23:19:28.650480 11123 solver.cpp:218] Iteration 54200 (3.57276 iter/s, 27.9896s/100 iters), loss = 0.00927108
I0528 23:19:28.650686 11123 solver.cpp:237]     Train net output #0: loss = 0.00927013 (* 1 = 0.00927013 loss)
I0528 23:19:28.650698 11123 sgd_solver.cpp:105] Iteration 54200, lr = 0.00729
I0528 23:19:56.665027 11123 solver.cpp:218] Iteration 54300 (3.56967 iter/s, 28.0138s/100 iters), loss = 0.00765381
I0528 23:19:56.665083 11123 solver.cpp:237]     Train net output #0: loss = 0.00765286 (* 1 = 0.00765286 loss)
I0528 23:19:56.665092 11123 sgd_solver.cpp:105] Iteration 54300, lr = 0.007285
I0528 23:20:24.672410 11123 solver.cpp:218] Iteration 54400 (3.57056 iter/s, 28.0068s/100 iters), loss = 0.184156
I0528 23:20:24.672577 11123 solver.cpp:237]     Train net output #0: loss = 0.184155 (* 1 = 0.184155 loss)
I0528 23:20:24.672590 11123 sgd_solver.cpp:105] Iteration 54400, lr = 0.00728
I0528 23:20:52.634114 11123 solver.cpp:218] Iteration 54500 (3.57641 iter/s, 27.961s/100 iters), loss = 0.200224
I0528 23:20:52.634171 11123 solver.cpp:237]     Train net output #0: loss = 0.200223 (* 1 = 0.200223 loss)
I0528 23:20:52.634181 11123 sgd_solver.cpp:105] Iteration 54500, lr = 0.007275
I0528 23:21:02.458385 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:21:20.609547 11123 solver.cpp:218] Iteration 54600 (3.57464 iter/s, 27.9748s/100 iters), loss = 0.00251991
I0528 23:21:20.609611 11123 solver.cpp:237]     Train net output #0: loss = 0.00251899 (* 1 = 0.00251899 loss)
I0528 23:21:20.609622 11123 sgd_solver.cpp:105] Iteration 54600, lr = 0.00727
I0528 23:21:48.591334 11123 solver.cpp:218] Iteration 54700 (3.57383 iter/s, 27.9812s/100 iters), loss = 0.00140067
I0528 23:21:48.591493 11123 solver.cpp:237]     Train net output #0: loss = 0.00139975 (* 1 = 0.00139975 loss)
I0528 23:21:48.591505 11123 sgd_solver.cpp:105] Iteration 54700, lr = 0.007265
I0528 23:22:16.580704 11123 solver.cpp:218] Iteration 54800 (3.57287 iter/s, 27.9887s/100 iters), loss = 0.108316
I0528 23:22:16.580747 11123 solver.cpp:237]     Train net output #0: loss = 0.108315 (* 1 = 0.108315 loss)
I0528 23:22:16.580756 11123 sgd_solver.cpp:105] Iteration 54800, lr = 0.00726
I0528 23:22:44.541054 11123 solver.cpp:218] Iteration 54900 (3.57657 iter/s, 27.9598s/100 iters), loss = 0.00113756
I0528 23:22:44.541282 11123 solver.cpp:237]     Train net output #0: loss = 0.00113667 (* 1 = 0.00113667 loss)
I0528 23:22:44.541294 11123 sgd_solver.cpp:105] Iteration 54900, lr = 0.007255
I0528 23:23:12.259652 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_55000.caffemodel
I0528 23:23:12.802098 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_55000.solverstate
I0528 23:23:12.949255 11123 solver.cpp:330] Iteration 55000, Testing net (#0)
I0528 23:23:17.402943 11123 solver.cpp:397]     Test net output #0: accuracy = 0.916001
I0528 23:23:17.403106 11123 solver.cpp:397]     Test net output #1: loss = 0.290553 (* 1 = 0.290553 loss)
I0528 23:23:17.680788 11123 solver.cpp:218] Iteration 55000 (3.0176 iter/s, 33.1389s/100 iters), loss = 0.199654
I0528 23:23:17.680835 11123 solver.cpp:237]     Train net output #0: loss = 0.199653 (* 1 = 0.199653 loss)
I0528 23:23:17.680842 11123 sgd_solver.cpp:105] Iteration 55000, lr = 0.00725
I0528 23:23:45.705925 11123 solver.cpp:218] Iteration 55100 (3.5683 iter/s, 28.0246s/100 iters), loss = 0.000917092
I0528 23:23:45.705971 11123 solver.cpp:237]     Train net output #0: loss = 0.000916165 (* 1 = 0.000916165 loss)
I0528 23:23:45.705981 11123 sgd_solver.cpp:105] Iteration 55100, lr = 0.007245
I0528 23:23:58.891546 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:24:13.712944 11123 solver.cpp:218] Iteration 55200 (3.57061 iter/s, 28.0064s/100 iters), loss = 0.00361713
I0528 23:24:13.712991 11123 solver.cpp:237]     Train net output #0: loss = 0.0036162 (* 1 = 0.0036162 loss)
I0528 23:24:13.713001 11123 sgd_solver.cpp:105] Iteration 55200, lr = 0.00724
I0528 23:24:41.698842 11123 solver.cpp:218] Iteration 55300 (3.5733 iter/s, 27.9853s/100 iters), loss = 0.000373971
I0528 23:24:41.699038 11123 solver.cpp:237]     Train net output #0: loss = 0.000373055 (* 1 = 0.000373055 loss)
I0528 23:24:41.699049 11123 sgd_solver.cpp:105] Iteration 55300, lr = 0.007235
I0528 23:25:09.725440 11123 solver.cpp:218] Iteration 55400 (3.56813 iter/s, 28.0259s/100 iters), loss = 0.0024297
I0528 23:25:09.725486 11123 solver.cpp:237]     Train net output #0: loss = 0.00242878 (* 1 = 0.00242878 loss)
I0528 23:25:09.725494 11123 sgd_solver.cpp:105] Iteration 55400, lr = 0.00723
I0528 23:25:37.728940 11123 solver.cpp:218] Iteration 55500 (3.57105 iter/s, 28.0029s/100 iters), loss = 0.00437558
I0528 23:25:37.729156 11123 solver.cpp:237]     Train net output #0: loss = 0.00437464 (* 1 = 0.00437464 loss)
I0528 23:25:37.729167 11123 sgd_solver.cpp:105] Iteration 55500, lr = 0.007225
I0528 23:26:05.715268 11123 solver.cpp:218] Iteration 55600 (3.57326 iter/s, 27.9856s/100 iters), loss = 0.0118773
I0528 23:26:05.715312 11123 solver.cpp:237]     Train net output #0: loss = 0.0118764 (* 1 = 0.0118764 loss)
I0528 23:26:05.715320 11123 sgd_solver.cpp:105] Iteration 55600, lr = 0.00722
I0528 23:26:33.714609 11123 solver.cpp:218] Iteration 55700 (3.57159 iter/s, 27.9988s/100 iters), loss = 0.00113508
I0528 23:26:33.714758 11123 solver.cpp:237]     Train net output #0: loss = 0.00113414 (* 1 = 0.00113414 loss)
I0528 23:26:33.714769 11123 sgd_solver.cpp:105] Iteration 55700, lr = 0.007215
I0528 23:26:50.545084 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:27:01.734031 11123 solver.cpp:218] Iteration 55800 (3.56904 iter/s, 28.0188s/100 iters), loss = 0.000866063
I0528 23:27:01.734077 11123 solver.cpp:237]     Train net output #0: loss = 0.000865127 (* 1 = 0.000865127 loss)
I0528 23:27:01.734086 11123 sgd_solver.cpp:105] Iteration 55800, lr = 0.00721
I0528 23:27:29.735570 11123 solver.cpp:218] Iteration 55900 (3.5713 iter/s, 28.001s/100 iters), loss = 0.0029797
I0528 23:27:29.735741 11123 solver.cpp:237]     Train net output #0: loss = 0.00297877 (* 1 = 0.00297877 loss)
I0528 23:27:29.735756 11123 sgd_solver.cpp:105] Iteration 55900, lr = 0.007205
I0528 23:27:57.477341 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_56000.caffemodel
I0528 23:27:58.038280 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_56000.solverstate
I0528 23:27:58.185842 11123 solver.cpp:330] Iteration 56000, Testing net (#0)
I0528 23:27:59.082947 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:28:02.645622 11123 solver.cpp:397]     Test net output #0: accuracy = 0.885
I0528 23:28:02.645781 11123 solver.cpp:397]     Test net output #1: loss = 0.385362 (* 1 = 0.385362 loss)
I0528 23:28:02.922339 11123 solver.cpp:218] Iteration 56000 (3.01332 iter/s, 33.186s/100 iters), loss = 0.0284564
I0528 23:28:02.922385 11123 solver.cpp:237]     Train net output #0: loss = 0.0284554 (* 1 = 0.0284554 loss)
I0528 23:28:02.922394 11123 sgd_solver.cpp:105] Iteration 56000, lr = 0.0072
I0528 23:28:30.898519 11123 solver.cpp:218] Iteration 56100 (3.57454 iter/s, 27.9756s/100 iters), loss = 0.000481112
I0528 23:28:30.898576 11123 solver.cpp:237]     Train net output #0: loss = 0.000480147 (* 1 = 0.000480147 loss)
I0528 23:28:30.898584 11123 sgd_solver.cpp:105] Iteration 56100, lr = 0.007195
I0528 23:28:58.877456 11123 solver.cpp:218] Iteration 56200 (3.57419 iter/s, 27.9784s/100 iters), loss = 0.00139298
I0528 23:28:58.877621 11123 solver.cpp:237]     Train net output #0: loss = 0.00139201 (* 1 = 0.00139201 loss)
I0528 23:28:58.877632 11123 sgd_solver.cpp:105] Iteration 56200, lr = 0.00719
I0528 23:29:26.899696 11123 solver.cpp:218] Iteration 56300 (3.56868 iter/s, 28.0216s/100 iters), loss = 0.0129514
I0528 23:29:26.899739 11123 solver.cpp:237]     Train net output #0: loss = 0.0129505 (* 1 = 0.0129505 loss)
I0528 23:29:26.899749 11123 sgd_solver.cpp:105] Iteration 56300, lr = 0.007185
I0528 23:29:47.357734 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:29:54.902585 11123 solver.cpp:218] Iteration 56400 (3.57113 iter/s, 28.0023s/100 iters), loss = 0.00176258
I0528 23:29:54.902643 11123 solver.cpp:237]     Train net output #0: loss = 0.00176159 (* 1 = 0.00176159 loss)
I0528 23:29:54.902654 11123 sgd_solver.cpp:105] Iteration 56400, lr = 0.00718
I0528 23:30:22.903017 11123 solver.cpp:218] Iteration 56500 (3.57145 iter/s, 27.9998s/100 iters), loss = 0.0498786
I0528 23:30:22.903179 11123 solver.cpp:237]     Train net output #0: loss = 0.0498776 (* 1 = 0.0498776 loss)
I0528 23:30:22.903198 11123 sgd_solver.cpp:105] Iteration 56500, lr = 0.007175
I0528 23:30:50.884397 11123 solver.cpp:218] Iteration 56600 (3.57389 iter/s, 27.9807s/100 iters), loss = 0.00154615
I0528 23:30:50.884454 11123 solver.cpp:237]     Train net output #0: loss = 0.00154516 (* 1 = 0.00154516 loss)
I0528 23:30:50.884461 11123 sgd_solver.cpp:105] Iteration 56600, lr = 0.00717
I0528 23:31:18.902415 11123 solver.cpp:218] Iteration 56700 (3.56921 iter/s, 28.0174s/100 iters), loss = 0.065924
I0528 23:31:18.902572 11123 solver.cpp:237]     Train net output #0: loss = 0.065923 (* 1 = 0.065923 loss)
I0528 23:31:18.902583 11123 sgd_solver.cpp:105] Iteration 56700, lr = 0.007165
I0528 23:31:46.883816 11123 solver.cpp:218] Iteration 56800 (3.57389 iter/s, 27.9807s/100 iters), loss = 0.0152122
I0528 23:31:46.883857 11123 solver.cpp:237]     Train net output #0: loss = 0.0152112 (* 1 = 0.0152112 loss)
I0528 23:31:46.883867 11123 sgd_solver.cpp:105] Iteration 56800, lr = 0.00716
I0528 23:32:14.875202 11123 solver.cpp:218] Iteration 56900 (3.5726 iter/s, 27.9908s/100 iters), loss = 0.0940798
I0528 23:32:14.875396 11123 solver.cpp:237]     Train net output #0: loss = 0.0940788 (* 1 = 0.0940788 loss)
I0528 23:32:14.875407 11123 sgd_solver.cpp:105] Iteration 56900, lr = 0.007155
I0528 23:32:38.964776 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:32:42.588258 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_57000.caffemodel
I0528 23:32:43.264101 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_57000.solverstate
I0528 23:32:43.411178 11123 solver.cpp:330] Iteration 57000, Testing net (#0)
I0528 23:32:45.817116 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:32:47.856231 11123 solver.cpp:397]     Test net output #0: accuracy = 0.874
I0528 23:32:47.856271 11123 solver.cpp:397]     Test net output #1: loss = 0.525028 (* 1 = 0.525028 loss)
I0528 23:32:48.135011 11123 solver.cpp:218] Iteration 57000 (3.0067 iter/s, 33.259s/100 iters), loss = 0.00294483
I0528 23:32:48.135053 11123 solver.cpp:237]     Train net output #0: loss = 0.00294378 (* 1 = 0.00294378 loss)
I0528 23:32:48.135061 11123 sgd_solver.cpp:105] Iteration 57000, lr = 0.00715
I0528 23:33:16.146440 11123 solver.cpp:218] Iteration 57100 (3.57004 iter/s, 28.0109s/100 iters), loss = 0.0551404
I0528 23:33:16.146610 11123 solver.cpp:237]     Train net output #0: loss = 0.0551394 (* 1 = 0.0551394 loss)
I0528 23:33:16.146642 11123 sgd_solver.cpp:105] Iteration 57100, lr = 0.007145
I0528 23:33:44.150705 11123 solver.cpp:218] Iteration 57200 (3.57097 iter/s, 28.0036s/100 iters), loss = 0.000889931
I0528 23:33:44.150750 11123 solver.cpp:237]     Train net output #0: loss = 0.00088891 (* 1 = 0.00088891 loss)
I0528 23:33:44.150758 11123 sgd_solver.cpp:105] Iteration 57200, lr = 0.00714
I0528 23:34:12.151969 11123 solver.cpp:218] Iteration 57300 (3.57134 iter/s, 28.0007s/100 iters), loss = 0.0028805
I0528 23:34:12.152127 11123 solver.cpp:237]     Train net output #0: loss = 0.00287948 (* 1 = 0.00287948 loss)
I0528 23:34:12.152139 11123 sgd_solver.cpp:105] Iteration 57300, lr = 0.007135
I0528 23:34:40.117346 11123 solver.cpp:218] Iteration 57400 (3.57594 iter/s, 27.9647s/100 iters), loss = 0.0858539
I0528 23:34:40.117399 11123 solver.cpp:237]     Train net output #0: loss = 0.0858528 (* 1 = 0.0858528 loss)
I0528 23:34:40.117408 11123 sgd_solver.cpp:105] Iteration 57400, lr = 0.00713
I0528 23:35:08.105164 11123 solver.cpp:218] Iteration 57500 (3.57306 iter/s, 27.9872s/100 iters), loss = 0.0211586
I0528 23:35:08.105355 11123 solver.cpp:237]     Train net output #0: loss = 0.0211575 (* 1 = 0.0211575 loss)
I0528 23:35:08.105366 11123 sgd_solver.cpp:105] Iteration 57500, lr = 0.007125
I0528 23:35:35.844629 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:35:36.112084 11123 solver.cpp:218] Iteration 57600 (3.57064 iter/s, 28.0062s/100 iters), loss = 0.000509311
I0528 23:35:36.112139 11123 solver.cpp:237]     Train net output #0: loss = 0.000508277 (* 1 = 0.000508277 loss)
I0528 23:35:36.112149 11123 sgd_solver.cpp:105] Iteration 57600, lr = 0.00712
I0528 23:36:04.130476 11123 solver.cpp:218] Iteration 57700 (3.56916 iter/s, 28.0178s/100 iters), loss = 0.0270307
I0528 23:36:04.130640 11123 solver.cpp:237]     Train net output #0: loss = 0.0270296 (* 1 = 0.0270296 loss)
I0528 23:36:04.130652 11123 sgd_solver.cpp:105] Iteration 57700, lr = 0.007115
I0528 23:36:32.124059 11123 solver.cpp:218] Iteration 57800 (3.57234 iter/s, 27.9929s/100 iters), loss = 0.00103713
I0528 23:36:32.124104 11123 solver.cpp:237]     Train net output #0: loss = 0.00103613 (* 1 = 0.00103613 loss)
I0528 23:36:32.124114 11123 sgd_solver.cpp:105] Iteration 57800, lr = 0.00711
I0528 23:37:00.123654 11123 solver.cpp:218] Iteration 57900 (3.57159 iter/s, 27.9987s/100 iters), loss = 0.0638246
I0528 23:37:00.123802 11123 solver.cpp:237]     Train net output #0: loss = 0.0638236 (* 1 = 0.0638236 loss)
I0528 23:37:00.123816 11123 sgd_solver.cpp:105] Iteration 57900, lr = 0.007105
I0528 23:37:27.852888 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_58000.caffemodel
I0528 23:37:28.356634 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_58000.solverstate
I0528 23:37:28.505357 11123 solver.cpp:330] Iteration 58000, Testing net (#0)
I0528 23:37:32.426498 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:37:32.957299 11123 solver.cpp:397]     Test net output #0: accuracy = 0.875
I0528 23:37:32.957352 11123 solver.cpp:397]     Test net output #1: loss = 0.596877 (* 1 = 0.596877 loss)
I0528 23:37:33.235572 11123 solver.cpp:218] Iteration 58000 (3.02022 iter/s, 33.1102s/100 iters), loss = 0.000316991
I0528 23:37:33.235616 11123 solver.cpp:237]     Train net output #0: loss = 0.000315964 (* 1 = 0.000315964 loss)
I0528 23:37:33.235625 11123 sgd_solver.cpp:105] Iteration 58000, lr = 0.0071
I0528 23:38:01.252800 11123 solver.cpp:218] Iteration 58100 (3.5694 iter/s, 28.0159s/100 iters), loss = 0.0192108
I0528 23:38:01.252842 11123 solver.cpp:237]     Train net output #0: loss = 0.0192098 (* 1 = 0.0192098 loss)
I0528 23:38:01.252851 11123 sgd_solver.cpp:105] Iteration 58100, lr = 0.007095
I0528 23:38:29.256367 11123 solver.cpp:218] Iteration 58200 (3.57114 iter/s, 28.0023s/100 iters), loss = 0.0255212
I0528 23:38:29.256486 11123 solver.cpp:237]     Train net output #0: loss = 0.0255202 (* 1 = 0.0255202 loss)
I0528 23:38:29.256510 11123 sgd_solver.cpp:105] Iteration 58200, lr = 0.00709
I0528 23:38:32.358423 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:38:57.253218 11123 solver.cpp:218] Iteration 58300 (3.572 iter/s, 27.9955s/100 iters), loss = 0.185526
I0528 23:38:57.253275 11123 solver.cpp:237]     Train net output #0: loss = 0.185525 (* 1 = 0.185525 loss)
I0528 23:38:57.253284 11123 sgd_solver.cpp:105] Iteration 58300, lr = 0.007085
I0528 23:39:25.279114 11123 solver.cpp:218] Iteration 58400 (3.56829 iter/s, 28.0246s/100 iters), loss = 0.00117959
I0528 23:39:25.279273 11123 solver.cpp:237]     Train net output #0: loss = 0.00117858 (* 1 = 0.00117858 loss)
I0528 23:39:25.279289 11123 sgd_solver.cpp:105] Iteration 58400, lr = 0.00708
I0528 23:39:53.275523 11123 solver.cpp:218] Iteration 58500 (3.57206 iter/s, 27.9951s/100 iters), loss = 0.0630311
I0528 23:39:53.275568 11123 solver.cpp:237]     Train net output #0: loss = 0.06303 (* 1 = 0.06303 loss)
I0528 23:39:53.275576 11123 sgd_solver.cpp:105] Iteration 58500, lr = 0.007075
I0528 23:40:21.248387 11123 solver.cpp:218] Iteration 58600 (3.57504 iter/s, 27.9717s/100 iters), loss = 0.00141923
I0528 23:40:21.248589 11123 solver.cpp:237]     Train net output #0: loss = 0.00141821 (* 1 = 0.00141821 loss)
I0528 23:40:21.248601 11123 sgd_solver.cpp:105] Iteration 58600, lr = 0.00707
I0528 23:40:49.236960 11123 solver.cpp:218] Iteration 58700 (3.57305 iter/s, 27.9873s/100 iters), loss = 0.0052204
I0528 23:40:49.237002 11123 solver.cpp:237]     Train net output #0: loss = 0.00521938 (* 1 = 0.00521938 loss)
I0528 23:40:49.237022 11123 sgd_solver.cpp:105] Iteration 58700, lr = 0.007065
I0528 23:41:17.268352 11123 solver.cpp:218] Iteration 58800 (3.56757 iter/s, 28.0303s/100 iters), loss = 0.000736319
I0528 23:41:17.268589 11123 solver.cpp:237]     Train net output #0: loss = 0.000735254 (* 1 = 0.000735254 loss)
I0528 23:41:17.268599 11123 sgd_solver.cpp:105] Iteration 58800, lr = 0.00706
I0528 23:41:24.009045 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:41:45.251175 11123 solver.cpp:218] Iteration 58900 (3.57379 iter/s, 27.9815s/100 iters), loss = 0.0289796
I0528 23:41:45.251231 11123 solver.cpp:237]     Train net output #0: loss = 0.0289786 (* 1 = 0.0289786 loss)
I0528 23:41:45.251240 11123 sgd_solver.cpp:105] Iteration 58900, lr = 0.007055
I0528 23:42:12.968957 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_59000.caffemodel
I0528 23:42:13.540604 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_59000.solverstate
I0528 23:42:13.687980 11123 solver.cpp:330] Iteration 59000, Testing net (#0)
I0528 23:42:18.134608 11123 solver.cpp:397]     Test net output #0: accuracy = 0.938
I0528 23:42:18.134646 11123 solver.cpp:397]     Test net output #1: loss = 0.202662 (* 1 = 0.202662 loss)
I0528 23:42:18.412466 11123 solver.cpp:218] Iteration 59000 (3.01568 iter/s, 33.16s/100 iters), loss = 0.0615044
I0528 23:42:18.412508 11123 solver.cpp:237]     Train net output #0: loss = 0.0615033 (* 1 = 0.0615033 loss)
I0528 23:42:18.412515 11123 sgd_solver.cpp:105] Iteration 59000, lr = 0.00705
I0528 23:42:46.401501 11123 solver.cpp:218] Iteration 59100 (3.57296 iter/s, 27.988s/100 iters), loss = 0.000404611
I0528 23:42:46.401656 11123 solver.cpp:237]     Train net output #0: loss = 0.000403575 (* 1 = 0.000403575 loss)
I0528 23:42:46.401671 11123 sgd_solver.cpp:105] Iteration 59100, lr = 0.007045
I0528 23:43:14.392441 11123 solver.cpp:218] Iteration 59200 (3.57273 iter/s, 27.9898s/100 iters), loss = 0.0785847
I0528 23:43:14.392485 11123 solver.cpp:237]     Train net output #0: loss = 0.0785837 (* 1 = 0.0785837 loss)
I0528 23:43:14.392494 11123 sgd_solver.cpp:105] Iteration 59200, lr = 0.00704
I0528 23:43:42.424113 11123 solver.cpp:218] Iteration 59300 (3.56752 iter/s, 28.0307s/100 iters), loss = 0.0138382
I0528 23:43:42.424280 11123 solver.cpp:237]     Train net output #0: loss = 0.0138372 (* 1 = 0.0138372 loss)
I0528 23:43:42.424293 11123 sgd_solver.cpp:105] Iteration 59300, lr = 0.007035
I0528 23:44:10.448047 11123 solver.cpp:218] Iteration 59400 (3.56852 iter/s, 28.0228s/100 iters), loss = 0.00941836
I0528 23:44:10.448104 11123 solver.cpp:237]     Train net output #0: loss = 0.00941732 (* 1 = 0.00941732 loss)
I0528 23:44:10.448113 11123 sgd_solver.cpp:105] Iteration 59400, lr = 0.00703
I0528 23:44:20.831662 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:44:38.458308 11123 solver.cpp:218] Iteration 59500 (3.57025 iter/s, 28.0093s/100 iters), loss = 0.0321762
I0528 23:44:38.458375 11123 solver.cpp:237]     Train net output #0: loss = 0.0321752 (* 1 = 0.0321752 loss)
I0528 23:44:38.458384 11123 sgd_solver.cpp:105] Iteration 59500, lr = 0.007025
I0528 23:45:06.486600 11123 solver.cpp:218] Iteration 59600 (3.56795 iter/s, 28.0273s/100 iters), loss = 0.0664539
I0528 23:45:06.486778 11123 solver.cpp:237]     Train net output #0: loss = 0.0664528 (* 1 = 0.0664528 loss)
I0528 23:45:06.486789 11123 sgd_solver.cpp:105] Iteration 59600, lr = 0.00702
I0528 23:45:34.482172 11123 solver.cpp:218] Iteration 59700 (3.57213 iter/s, 27.9945s/100 iters), loss = 0.091683
I0528 23:45:34.482231 11123 solver.cpp:237]     Train net output #0: loss = 0.0916819 (* 1 = 0.0916819 loss)
I0528 23:45:34.482240 11123 sgd_solver.cpp:105] Iteration 59700, lr = 0.007015
I0528 23:46:02.465734 11123 solver.cpp:218] Iteration 59800 (3.57365 iter/s, 27.9826s/100 iters), loss = 0.0171019
I0528 23:46:02.466794 11123 solver.cpp:237]     Train net output #0: loss = 0.0171008 (* 1 = 0.0171008 loss)
I0528 23:46:02.466809 11123 sgd_solver.cpp:105] Iteration 59800, lr = 0.00701
I0528 23:46:30.442721 11123 solver.cpp:218] Iteration 59900 (3.57461 iter/s, 27.9751s/100 iters), loss = 0.0202392
I0528 23:46:30.442766 11123 solver.cpp:237]     Train net output #0: loss = 0.0202381 (* 1 = 0.0202381 loss)
I0528 23:46:30.442775 11123 sgd_solver.cpp:105] Iteration 59900, lr = 0.007005
I0528 23:46:58.175526 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_60000.caffemodel
I0528 23:46:58.829207 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_60000.solverstate
I0528 23:46:58.975800 11123 solver.cpp:330] Iteration 60000, Testing net (#0)
I0528 23:46:59.962776 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:47:03.434586 11123 solver.cpp:397]     Test net output #0: accuracy = 0.862
I0528 23:47:03.434636 11123 solver.cpp:397]     Test net output #1: loss = 0.592502 (* 1 = 0.592502 loss)
I0528 23:47:03.711843 11123 solver.cpp:218] Iteration 60000 (3.00589 iter/s, 33.2681s/100 iters), loss = 0.127722
I0528 23:47:03.711897 11123 solver.cpp:237]     Train net output #0: loss = 0.127721 (* 1 = 0.127721 loss)
I0528 23:47:03.711906 11123 sgd_solver.cpp:105] Iteration 60000, lr = 0.007
I0528 23:47:17.718300 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:47:31.690834 11123 solver.cpp:218] Iteration 60100 (3.57423 iter/s, 27.9781s/100 iters), loss = 0.0324335
I0528 23:47:31.691014 11123 solver.cpp:237]     Train net output #0: loss = 0.0324324 (* 1 = 0.0324324 loss)
I0528 23:47:31.691025 11123 sgd_solver.cpp:105] Iteration 60100, lr = 0.006995
I0528 23:47:59.661216 11123 solver.cpp:218] Iteration 60200 (3.57534 iter/s, 27.9694s/100 iters), loss = 0.0121066
I0528 23:47:59.661278 11123 solver.cpp:237]     Train net output #0: loss = 0.0121056 (* 1 = 0.0121056 loss)
I0528 23:47:59.661288 11123 sgd_solver.cpp:105] Iteration 60200, lr = 0.00699
I0528 23:48:27.632930 11123 solver.cpp:218] Iteration 60300 (3.57515 iter/s, 27.9708s/100 iters), loss = 0.0269034
I0528 23:48:27.633110 11123 solver.cpp:237]     Train net output #0: loss = 0.0269024 (* 1 = 0.0269024 loss)
I0528 23:48:27.633121 11123 sgd_solver.cpp:105] Iteration 60300, lr = 0.006985
I0528 23:48:55.596115 11123 solver.cpp:218] Iteration 60400 (3.57626 iter/s, 27.9622s/100 iters), loss = 0.00142991
I0528 23:48:55.596168 11123 solver.cpp:237]     Train net output #0: loss = 0.00142884 (* 1 = 0.00142884 loss)
I0528 23:48:55.596176 11123 sgd_solver.cpp:105] Iteration 60400, lr = 0.00698
I0528 23:49:23.586271 11123 solver.cpp:218] Iteration 60500 (3.57279 iter/s, 27.9893s/100 iters), loss = 0.00247041
I0528 23:49:23.586438 11123 solver.cpp:237]     Train net output #0: loss = 0.00246935 (* 1 = 0.00246935 loss)
I0528 23:49:23.586450 11123 sgd_solver.cpp:105] Iteration 60500, lr = 0.006975
I0528 23:49:51.555121 11123 solver.cpp:218] Iteration 60600 (3.57553 iter/s, 27.9679s/100 iters), loss = 0.000850628
I0528 23:49:51.555173 11123 solver.cpp:237]     Train net output #0: loss = 0.000849566 (* 1 = 0.000849566 loss)
I0528 23:49:51.555182 11123 sgd_solver.cpp:105] Iteration 60600, lr = 0.00697
I0528 23:50:09.196775 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:50:19.527654 11123 solver.cpp:218] Iteration 60700 (3.57504 iter/s, 27.9717s/100 iters), loss = 0.026824
I0528 23:50:19.527704 11123 solver.cpp:237]     Train net output #0: loss = 0.0268229 (* 1 = 0.0268229 loss)
I0528 23:50:19.527712 11123 sgd_solver.cpp:105] Iteration 60700, lr = 0.006965
I0528 23:50:47.493723 11123 solver.cpp:218] Iteration 60800 (3.57587 iter/s, 27.9652s/100 iters), loss = 0.00719892
I0528 23:50:47.493911 11123 solver.cpp:237]     Train net output #0: loss = 0.00719786 (* 1 = 0.00719786 loss)
I0528 23:50:47.493921 11123 sgd_solver.cpp:105] Iteration 60800, lr = 0.00696
I0528 23:51:15.483858 11123 solver.cpp:218] Iteration 60900 (3.57281 iter/s, 27.9892s/100 iters), loss = 0.00016544
I0528 23:51:15.483901 11123 solver.cpp:237]     Train net output #0: loss = 0.000164373 (* 1 = 0.000164373 loss)
I0528 23:51:15.483909 11123 sgd_solver.cpp:105] Iteration 60900, lr = 0.006955
I0528 23:51:43.229821 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_61000.caffemodel
I0528 23:51:43.759449 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_61000.solverstate
I0528 23:51:43.966903 11123 solver.cpp:330] Iteration 61000, Testing net (#0)
I0528 23:51:46.449575 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:51:48.396950 11123 solver.cpp:397]     Test net output #0: accuracy = 0.906001
I0528 23:51:48.397002 11123 solver.cpp:397]     Test net output #1: loss = 0.370868 (* 1 = 0.370868 loss)
I0528 23:51:48.674018 11123 solver.cpp:218] Iteration 61000 (3.01303 iter/s, 33.1892s/100 iters), loss = 0.00259985
I0528 23:51:48.674067 11123 solver.cpp:237]     Train net output #0: loss = 0.0025988 (* 1 = 0.0025988 loss)
I0528 23:51:48.674075 11123 sgd_solver.cpp:105] Iteration 61000, lr = 0.00695
I0528 23:52:16.673830 11123 solver.cpp:218] Iteration 61100 (3.57156 iter/s, 27.999s/100 iters), loss = 0.0178127
I0528 23:52:16.674006 11123 solver.cpp:237]     Train net output #0: loss = 0.0178116 (* 1 = 0.0178116 loss)
I0528 23:52:16.674018 11123 sgd_solver.cpp:105] Iteration 61100, lr = 0.006945
I0528 23:52:44.672052 11123 solver.cpp:218] Iteration 61200 (3.57177 iter/s, 27.9973s/100 iters), loss = 0.0152263
I0528 23:52:44.672104 11123 solver.cpp:237]     Train net output #0: loss = 0.0152253 (* 1 = 0.0152253 loss)
I0528 23:52:44.672113 11123 sgd_solver.cpp:105] Iteration 61200, lr = 0.00694
I0528 23:53:05.696259 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:53:12.672633 11123 solver.cpp:218] Iteration 61300 (3.57146 iter/s, 27.9998s/100 iters), loss = 0.00429307
I0528 23:53:12.672684 11123 solver.cpp:237]     Train net output #0: loss = 0.00429208 (* 1 = 0.00429208 loss)
I0528 23:53:12.672693 11123 sgd_solver.cpp:105] Iteration 61300, lr = 0.006935
I0528 23:53:40.677453 11123 solver.cpp:218] Iteration 61400 (3.57091 iter/s, 28.004s/100 iters), loss = 0.00292636
I0528 23:53:40.677628 11123 solver.cpp:237]     Train net output #0: loss = 0.0029254 (* 1 = 0.0029254 loss)
I0528 23:53:40.677640 11123 sgd_solver.cpp:105] Iteration 61400, lr = 0.00693
I0528 23:54:08.691428 11123 solver.cpp:218] Iteration 61500 (3.56976 iter/s, 28.0131s/100 iters), loss = 0.290713
I0528 23:54:08.691485 11123 solver.cpp:237]     Train net output #0: loss = 0.290712 (* 1 = 0.290712 loss)
I0528 23:54:08.691496 11123 sgd_solver.cpp:105] Iteration 61500, lr = 0.006925
I0528 23:54:36.675113 11123 solver.cpp:218] Iteration 61600 (3.57361 iter/s, 27.9829s/100 iters), loss = 0.00210231
I0528 23:54:36.675334 11123 solver.cpp:237]     Train net output #0: loss = 0.00210138 (* 1 = 0.00210138 loss)
I0528 23:54:36.675359 11123 sgd_solver.cpp:105] Iteration 61600, lr = 0.00692
I0528 23:55:04.669137 11123 solver.cpp:218] Iteration 61700 (3.57231 iter/s, 27.9931s/100 iters), loss = 0.0142977
I0528 23:55:04.669196 11123 solver.cpp:237]     Train net output #0: loss = 0.0142968 (* 1 = 0.0142968 loss)
I0528 23:55:04.669222 11123 sgd_solver.cpp:105] Iteration 61700, lr = 0.006915
I0528 23:55:32.667507 11123 solver.cpp:218] Iteration 61800 (3.57173 iter/s, 27.9976s/100 iters), loss = 0.00163786
I0528 23:55:32.667677 11123 solver.cpp:237]     Train net output #0: loss = 0.00163697 (* 1 = 0.00163697 loss)
I0528 23:55:32.667693 11123 sgd_solver.cpp:105] Iteration 61800, lr = 0.00691
I0528 23:55:57.316359 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:56:00.662472 11123 solver.cpp:218] Iteration 61900 (3.57218 iter/s, 27.9941s/100 iters), loss = 0.0125731
I0528 23:56:00.662544 11123 solver.cpp:237]     Train net output #0: loss = 0.0125722 (* 1 = 0.0125722 loss)
I0528 23:56:00.662560 11123 sgd_solver.cpp:105] Iteration 61900, lr = 0.006905
I0528 23:56:28.356148 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_62000.caffemodel
I0528 23:56:28.857164 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_62000.solverstate
I0528 23:56:29.005070 11123 solver.cpp:330] Iteration 62000, Testing net (#0)
I0528 23:56:33.007711 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:56:33.450083 11123 solver.cpp:397]     Test net output #0: accuracy = 0.929
I0528 23:56:33.450124 11123 solver.cpp:397]     Test net output #1: loss = 0.274828 (* 1 = 0.274828 loss)
I0528 23:56:33.726719 11123 solver.cpp:218] Iteration 62000 (3.0245 iter/s, 33.0634s/100 iters), loss = 0.0001349
I0528 23:56:33.726763 11123 solver.cpp:237]     Train net output #0: loss = 0.000134027 (* 1 = 0.000134027 loss)
I0528 23:56:33.726771 11123 sgd_solver.cpp:105] Iteration 62000, lr = 0.0069
I0528 23:57:01.751662 11123 solver.cpp:218] Iteration 62100 (3.56834 iter/s, 28.0242s/100 iters), loss = 0.000676984
I0528 23:57:01.751821 11123 solver.cpp:237]     Train net output #0: loss = 0.000676107 (* 1 = 0.000676107 loss)
I0528 23:57:01.751837 11123 sgd_solver.cpp:105] Iteration 62100, lr = 0.006895
I0528 23:57:29.769081 11123 solver.cpp:218] Iteration 62200 (3.56932 iter/s, 28.0166s/100 iters), loss = 0.00778967
I0528 23:57:29.769129 11123 solver.cpp:237]     Train net output #0: loss = 0.0077888 (* 1 = 0.0077888 loss)
I0528 23:57:29.769148 11123 sgd_solver.cpp:105] Iteration 62200, lr = 0.00689
I0528 23:57:57.758546 11123 solver.cpp:218] Iteration 62300 (3.57287 iter/s, 27.9887s/100 iters), loss = 0.040556
I0528 23:57:57.758716 11123 solver.cpp:237]     Train net output #0: loss = 0.0405552 (* 1 = 0.0405552 loss)
I0528 23:57:57.758728 11123 sgd_solver.cpp:105] Iteration 62300, lr = 0.006885
I0528 23:58:25.719564 11123 solver.cpp:218] Iteration 62400 (3.57652 iter/s, 27.9602s/100 iters), loss = 0.000182134
I0528 23:58:25.719619 11123 solver.cpp:237]     Train net output #0: loss = 0.000181269 (* 1 = 0.000181269 loss)
I0528 23:58:25.719627 11123 sgd_solver.cpp:105] Iteration 62400, lr = 0.00688
I0528 23:58:53.691500 11123 solver.cpp:218] Iteration 62500 (3.57511 iter/s, 27.9712s/100 iters), loss = 0.00143547
I0528 23:58:53.691669 11123 solver.cpp:237]     Train net output #0: loss = 0.00143461 (* 1 = 0.00143461 loss)
I0528 23:58:53.691681 11123 sgd_solver.cpp:105] Iteration 62500, lr = 0.006875
I0528 23:58:53.992013 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:59:21.696059 11123 solver.cpp:218] Iteration 62600 (3.57096 iter/s, 28.0037s/100 iters), loss = 0.0067984
I0528 23:59:21.696113 11123 solver.cpp:237]     Train net output #0: loss = 0.00679757 (* 1 = 0.00679757 loss)
I0528 23:59:21.696122 11123 sgd_solver.cpp:105] Iteration 62600, lr = 0.00687
I0528 23:59:49.687117 11123 solver.cpp:218] Iteration 62700 (3.57266 iter/s, 27.9903s/100 iters), loss = 0.0407551
I0528 23:59:49.687283 11123 solver.cpp:237]     Train net output #0: loss = 0.0407543 (* 1 = 0.0407543 loss)
I0528 23:59:49.687295 11123 sgd_solver.cpp:105] Iteration 62700, lr = 0.006865
I0529 00:00:17.681008 11123 solver.cpp:218] Iteration 62800 (3.57232 iter/s, 27.993s/100 iters), loss = 0.00345356
I0529 00:00:17.681066 11123 solver.cpp:237]     Train net output #0: loss = 0.00345274 (* 1 = 0.00345274 loss)
I0529 00:00:17.681073 11123 sgd_solver.cpp:105] Iteration 62800, lr = 0.00686
I0529 00:00:45.659503 11123 solver.cpp:218] Iteration 62900 (3.57427 iter/s, 27.9778s/100 iters), loss = 0.00051317
I0529 00:00:45.659687 11123 solver.cpp:237]     Train net output #0: loss = 0.000512345 (* 1 = 0.000512345 loss)
I0529 00:00:45.659699 11123 sgd_solver.cpp:105] Iteration 62900, lr = 0.006855
I0529 00:01:13.387455 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_63000.caffemodel
I0529 00:01:13.844250 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_63000.solverstate
I0529 00:01:13.992094 11123 solver.cpp:330] Iteration 63000, Testing net (#0)
I0529 00:01:18.441493 11123 solver.cpp:397]     Test net output #0: accuracy = 0.9
I0529 00:01:18.441742 11123 solver.cpp:397]     Test net output #1: loss = 0.379213 (* 1 = 0.379213 loss)
I0529 00:01:18.719966 11123 solver.cpp:218] Iteration 63000 (3.02485 iter/s, 33.0595s/100 iters), loss = 0.0155814
I0529 00:01:18.720016 11123 solver.cpp:237]     Train net output #0: loss = 0.0155806 (* 1 = 0.0155806 loss)
I0529 00:01:18.720026 11123 sgd_solver.cpp:105] Iteration 63000, lr = 0.00685
I0529 00:01:46.733454 11123 solver.cpp:218] Iteration 63100 (3.5698 iter/s, 28.0128s/100 iters), loss = 0.00388275
I0529 00:01:46.733517 11123 solver.cpp:237]     Train net output #0: loss = 0.00388192 (* 1 = 0.00388192 loss)
I0529 00:01:46.733527 11123 sgd_solver.cpp:105] Iteration 63100, lr = 0.006845
I0529 00:01:50.680567 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:02:14.760964 11123 solver.cpp:218] Iteration 63200 (3.56801 iter/s, 28.0268s/100 iters), loss = 0.0124266
I0529 00:02:14.761013 11123 solver.cpp:237]     Train net output #0: loss = 0.0124257 (* 1 = 0.0124257 loss)
I0529 00:02:14.761020 11123 sgd_solver.cpp:105] Iteration 63200, lr = 0.00684
I0529 00:02:42.766917 11123 solver.cpp:218] Iteration 63300 (3.57076 iter/s, 28.0052s/100 iters), loss = 0.000382278
I0529 00:02:42.767091 11123 solver.cpp:237]     Train net output #0: loss = 0.00038143 (* 1 = 0.00038143 loss)
I0529 00:02:42.767102 11123 sgd_solver.cpp:105] Iteration 63300, lr = 0.006835
I0529 00:03:10.783136 11123 solver.cpp:218] Iteration 63400 (3.56947 iter/s, 28.0154s/100 iters), loss = 0.00568827
I0529 00:03:10.783186 11123 solver.cpp:237]     Train net output #0: loss = 0.00568738 (* 1 = 0.00568738 loss)
I0529 00:03:10.783195 11123 sgd_solver.cpp:105] Iteration 63400, lr = 0.00683
I0529 00:03:38.791375 11123 solver.cpp:218] Iteration 63500 (3.57047 iter/s, 28.0075s/100 iters), loss = 0.00591243
I0529 00:03:38.791579 11123 solver.cpp:237]     Train net output #0: loss = 0.00591155 (* 1 = 0.00591155 loss)
I0529 00:03:38.791591 11123 sgd_solver.cpp:105] Iteration 63500, lr = 0.006825
I0529 00:04:06.814071 11123 solver.cpp:218] Iteration 63600 (3.56864 iter/s, 28.0219s/100 iters), loss = 0.00728731
I0529 00:04:06.814119 11123 solver.cpp:237]     Train net output #0: loss = 0.00728641 (* 1 = 0.00728641 loss)
I0529 00:04:06.814143 11123 sgd_solver.cpp:105] Iteration 63600, lr = 0.00682
I0529 00:04:34.817009 11123 solver.cpp:218] Iteration 63700 (3.57114 iter/s, 28.0022s/100 iters), loss = 0.00948809
I0529 00:04:34.817167 11123 solver.cpp:237]     Train net output #0: loss = 0.00948717 (* 1 = 0.00948717 loss)
I0529 00:04:34.817185 11123 sgd_solver.cpp:105] Iteration 63700, lr = 0.006815
I0529 00:04:42.385471 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:05:02.817299 11123 solver.cpp:218] Iteration 63800 (3.57149 iter/s, 27.9995s/100 iters), loss = 0.0433479
I0529 00:05:02.817353 11123 solver.cpp:237]     Train net output #0: loss = 0.043347 (* 1 = 0.043347 loss)
I0529 00:05:02.817365 11123 sgd_solver.cpp:105] Iteration 63800, lr = 0.00681
I0529 00:05:30.830299 11123 solver.cpp:218] Iteration 63900 (3.56986 iter/s, 28.0123s/100 iters), loss = 0.0203564
I0529 00:05:30.830519 11123 solver.cpp:237]     Train net output #0: loss = 0.0203555 (* 1 = 0.0203555 loss)
I0529 00:05:30.830548 11123 sgd_solver.cpp:105] Iteration 63900, lr = 0.006805
I0529 00:05:58.551590 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_64000.caffemodel
I0529 00:05:59.113322 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_64000.solverstate
I0529 00:05:59.259656 11123 solver.cpp:330] Iteration 64000, Testing net (#0)
I0529 00:06:00.342485 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:06:03.717725 11123 solver.cpp:397]     Test net output #0: accuracy = 0.926001
I0529 00:06:03.717936 11123 solver.cpp:397]     Test net output #1: loss = 0.231108 (* 1 = 0.231108 loss)
I0529 00:06:03.994676 11123 solver.cpp:218] Iteration 64000 (3.01537 iter/s, 33.1634s/100 iters), loss = 0.262053
I0529 00:06:03.994731 11123 solver.cpp:237]     Train net output #0: loss = 0.262052 (* 1 = 0.262052 loss)
I0529 00:06:03.994740 11123 sgd_solver.cpp:105] Iteration 64000, lr = 0.0068
I0529 00:06:31.954458 11123 solver.cpp:218] Iteration 64100 (3.57666 iter/s, 27.9591s/100 iters), loss = 0.0441312
I0529 00:06:31.954504 11123 solver.cpp:237]     Train net output #0: loss = 0.0441302 (* 1 = 0.0441302 loss)
I0529 00:06:31.954511 11123 sgd_solver.cpp:105] Iteration 64100, lr = 0.006795
I0529 00:06:59.933130 11123 solver.cpp:218] Iteration 64200 (3.57424 iter/s, 27.978s/100 iters), loss = 0.000819067
I0529 00:06:59.933298 11123 solver.cpp:237]     Train net output #0: loss = 0.000818075 (* 1 = 0.000818075 loss)
I0529 00:06:59.933310 11123 sgd_solver.cpp:105] Iteration 64200, lr = 0.00679
I0529 00:07:27.952520 11123 solver.cpp:218] Iteration 64300 (3.56906 iter/s, 28.0186s/100 iters), loss = 0.0202699
I0529 00:07:27.952565 11123 solver.cpp:237]     Train net output #0: loss = 0.0202689 (* 1 = 0.0202689 loss)
I0529 00:07:27.952574 11123 sgd_solver.cpp:105] Iteration 64300, lr = 0.006785
I0529 00:07:38.877176 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:07:55.909340 11123 solver.cpp:218] Iteration 64400 (3.57703 iter/s, 27.9561s/100 iters), loss = 0.00989971
I0529 00:07:55.909384 11123 solver.cpp:237]     Train net output #0: loss = 0.00989876 (* 1 = 0.00989876 loss)
I0529 00:07:55.909392 11123 sgd_solver.cpp:105] Iteration 64400, lr = 0.00678
I0529 00:08:23.902344 11123 solver.cpp:218] Iteration 64500 (3.57241 iter/s, 27.9923s/100 iters), loss = 0.00284708
I0529 00:08:23.902510 11123 solver.cpp:237]     Train net output #0: loss = 0.00284616 (* 1 = 0.00284616 loss)
I0529 00:08:23.902521 11123 sgd_solver.cpp:105] Iteration 64500, lr = 0.006775
I0529 00:08:51.870139 11123 solver.cpp:218] Iteration 64600 (3.57564 iter/s, 27.967s/100 iters), loss = 0.00249597
I0529 00:08:51.870190 11123 solver.cpp:237]     Train net output #0: loss = 0.00249504 (* 1 = 0.00249504 loss)
I0529 00:08:51.870203 11123 sgd_solver.cpp:105] Iteration 64600, lr = 0.00677
I0529 00:09:19.864785 11123 solver.cpp:218] Iteration 64700 (3.5722 iter/s, 27.994s/100 iters), loss = 0.0194271
I0529 00:09:19.864956 11123 solver.cpp:237]     Train net output #0: loss = 0.0194262 (* 1 = 0.0194262 loss)
I0529 00:09:19.864969 11123 sgd_solver.cpp:105] Iteration 64700, lr = 0.006765
I0529 00:09:47.886734 11123 solver.cpp:218] Iteration 64800 (3.56873 iter/s, 28.0211s/100 iters), loss = 0.00336422
I0529 00:09:47.886781 11123 solver.cpp:237]     Train net output #0: loss = 0.00336327 (* 1 = 0.00336327 loss)
I0529 00:09:47.886790 11123 sgd_solver.cpp:105] Iteration 64800, lr = 0.00676
I0529 00:10:15.873181 11123 solver.cpp:218] Iteration 64900 (3.57325 iter/s, 27.9858s/100 iters), loss = 0.000129249
I0529 00:10:15.873384 11123 solver.cpp:237]     Train net output #0: loss = 0.000128298 (* 1 = 0.000128298 loss)
I0529 00:10:15.873396 11123 sgd_solver.cpp:105] Iteration 64900, lr = 0.006755
I0529 00:10:30.441164 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:10:43.577747 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_65000.caffemodel
I0529 00:10:44.019645 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_65000.solverstate
I0529 00:10:44.166636 11123 solver.cpp:330] Iteration 65000, Testing net (#0)
I0529 00:10:46.751647 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:10:48.614596 11123 solver.cpp:397]     Test net output #0: accuracy = 0.918
I0529 00:10:48.614639 11123 solver.cpp:397]     Test net output #1: loss = 0.304763 (* 1 = 0.304763 loss)
I0529 00:10:48.890771 11123 solver.cpp:218] Iteration 65000 (3.02877 iter/s, 33.0167s/100 iters), loss = 0.0327311
I0529 00:10:48.890817 11123 solver.cpp:237]     Train net output #0: loss = 0.0327302 (* 1 = 0.0327302 loss)
I0529 00:10:48.890826 11123 sgd_solver.cpp:105] Iteration 65000, lr = 0.00675
I0529 00:11:16.878443 11123 solver.cpp:218] Iteration 65100 (3.57308 iter/s, 27.987s/100 iters), loss = 0.00275551
I0529 00:11:16.878680 11123 solver.cpp:237]     Train net output #0: loss = 0.00275459 (* 1 = 0.00275459 loss)
I0529 00:11:16.878692 11123 sgd_solver.cpp:105] Iteration 65100, lr = 0.006745
I0529 00:11:44.889292 11123 solver.cpp:218] Iteration 65200 (3.57014 iter/s, 28.0101s/100 iters), loss = 0.0154576
I0529 00:11:44.889338 11123 solver.cpp:237]     Train net output #0: loss = 0.0154567 (* 1 = 0.0154567 loss)
I0529 00:11:44.889348 11123 sgd_solver.cpp:105] Iteration 65200, lr = 0.00674
I0529 00:12:12.901932 11123 solver.cpp:218] Iteration 65300 (3.56989 iter/s, 28.012s/100 iters), loss = 0.00421184
I0529 00:12:12.902139 11123 solver.cpp:237]     Train net output #0: loss = 0.0042109 (* 1 = 0.0042109 loss)
I0529 00:12:12.902151 11123 sgd_solver.cpp:105] Iteration 65300, lr = 0.006735
I0529 00:12:40.902381 11123 solver.cpp:218] Iteration 65400 (3.57147 iter/s, 27.9997s/100 iters), loss = 0.00712342
I0529 00:12:40.902429 11123 solver.cpp:237]     Train net output #0: loss = 0.00712247 (* 1 = 0.00712247 loss)
I0529 00:12:40.902437 11123 sgd_solver.cpp:105] Iteration 65400, lr = 0.00673
I0529 00:13:08.902860 11123 solver.cpp:218] Iteration 65500 (3.57145 iter/s, 27.9999s/100 iters), loss = 3.42857e-05
I0529 00:13:08.903025 11123 solver.cpp:237]     Train net output #0: loss = 3.33409e-05 (* 1 = 3.33409e-05 loss)
I0529 00:13:08.903038 11123 sgd_solver.cpp:105] Iteration 65500, lr = 0.006725
I0529 00:13:27.125409 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:13:36.908129 11123 solver.cpp:218] Iteration 65600 (3.57085 iter/s, 28.0045s/100 iters), loss = 0.00638537
I0529 00:13:36.908176 11123 solver.cpp:237]     Train net output #0: loss = 0.00638439 (* 1 = 0.00638439 loss)
I0529 00:13:36.908185 11123 sgd_solver.cpp:105] Iteration 65600, lr = 0.00672
I0529 00:14:04.918900 11123 solver.cpp:218] Iteration 65700 (3.57013 iter/s, 28.0102s/100 iters), loss = 0.0109621
I0529 00:14:04.919055 11123 solver.cpp:237]     Train net output #0: loss = 0.0109611 (* 1 = 0.0109611 loss)
I0529 00:14:04.919067 11123 sgd_solver.cpp:105] Iteration 65700, lr = 0.006715
I0529 00:14:32.909720 11123 solver.cpp:218] Iteration 65800 (3.57269 iter/s, 27.9901s/100 iters), loss = 9.7923e-05
I0529 00:14:32.909767 11123 solver.cpp:237]     Train net output #0: loss = 9.69525e-05 (* 1 = 9.69525e-05 loss)
I0529 00:14:32.909777 11123 sgd_solver.cpp:105] Iteration 65800, lr = 0.00671
I0529 00:15:00.907747 11123 solver.cpp:218] Iteration 65900 (3.57176 iter/s, 27.9974s/100 iters), loss = 0.01123
I0529 00:15:00.907912 11123 solver.cpp:237]     Train net output #0: loss = 0.011229 (* 1 = 0.011229 loss)
I0529 00:15:00.907922 11123 sgd_solver.cpp:105] Iteration 65900, lr = 0.006705
I0529 00:15:28.635064 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_66000.caffemodel
I0529 00:15:29.000421 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_66000.solverstate
I0529 00:15:29.148720 11123 solver.cpp:330] Iteration 66000, Testing net (#0)
I0529 00:15:33.203687 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:15:33.600157 11123 solver.cpp:397]     Test net output #0: accuracy = 0.923
I0529 00:15:33.600208 11123 solver.cpp:397]     Test net output #1: loss = 0.261395 (* 1 = 0.261395 loss)
I0529 00:15:33.878345 11123 solver.cpp:218] Iteration 66000 (3.03308 iter/s, 32.9698s/100 iters), loss = 0.000747969
I0529 00:15:33.878392 11123 solver.cpp:237]     Train net output #0: loss = 0.000746998 (* 1 = 0.000746998 loss)
I0529 00:15:33.878401 11123 sgd_solver.cpp:105] Iteration 66000, lr = 0.0067
I0529 00:16:01.889854 11123 solver.cpp:218] Iteration 66100 (3.57004 iter/s, 28.0109s/100 iters), loss = 0.0808876
I0529 00:16:01.889909 11123 solver.cpp:237]     Train net output #0: loss = 0.0808866 (* 1 = 0.0808866 loss)
I0529 00:16:01.889931 11123 sgd_solver.cpp:105] Iteration 66100, lr = 0.006695
I0529 00:16:23.749445 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:16:29.898195 11123 solver.cpp:218] Iteration 66200 (3.57045 iter/s, 28.0077s/100 iters), loss = 0.0211862
I0529 00:16:29.898250 11123 solver.cpp:237]     Train net output #0: loss = 0.0211853 (* 1 = 0.0211853 loss)
I0529 00:16:29.898263 11123 sgd_solver.cpp:105] Iteration 66200, lr = 0.00669
I0529 00:16:57.904338 11123 solver.cpp:218] Iteration 66300 (3.57073 iter/s, 28.0055s/100 iters), loss = 0.000746127
I0529 00:16:57.904552 11123 solver.cpp:237]     Train net output #0: loss = 0.000745175 (* 1 = 0.000745175 loss)
I0529 00:16:57.904569 11123 sgd_solver.cpp:105] Iteration 66300, lr = 0.006685
I0529 00:17:25.941277 11123 solver.cpp:218] Iteration 66400 (3.56682 iter/s, 28.0362s/100 iters), loss = 0.000814626
I0529 00:17:25.941332 11123 solver.cpp:237]     Train net output #0: loss = 0.000813674 (* 1 = 0.000813674 loss)
I0529 00:17:25.941345 11123 sgd_solver.cpp:105] Iteration 66400, lr = 0.00668
I0529 00:17:53.954057 11123 solver.cpp:218] Iteration 66500 (3.56988 iter/s, 28.0121s/100 iters), loss = 0.00292178
I0529 00:17:53.954234 11123 solver.cpp:237]     Train net output #0: loss = 0.00292084 (* 1 = 0.00292084 loss)
I0529 00:17:53.954246 11123 sgd_solver.cpp:105] Iteration 66500, lr = 0.006675
I0529 00:18:21.948922 11123 solver.cpp:218] Iteration 66600 (3.57218 iter/s, 27.9941s/100 iters), loss = 0.126241
I0529 00:18:21.948976 11123 solver.cpp:237]     Train net output #0: loss = 0.12624 (* 1 = 0.12624 loss)
I0529 00:18:21.948984 11123 sgd_solver.cpp:105] Iteration 66600, lr = 0.00667
I0529 00:18:49.907940 11123 solver.cpp:218] Iteration 66700 (3.57675 iter/s, 27.9584s/100 iters), loss = 0.0148654
I0529 00:18:49.908164 11123 solver.cpp:237]     Train net output #0: loss = 0.0148644 (* 1 = 0.0148644 loss)
I0529 00:18:49.908175 11123 sgd_solver.cpp:105] Iteration 66700, lr = 0.006665
I0529 00:19:15.383365 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:19:17.884732 11123 solver.cpp:218] Iteration 66800 (3.57449 iter/s, 27.976s/100 iters), loss = 0.000122666
I0529 00:19:17.884779 11123 solver.cpp:237]     Train net output #0: loss = 0.000121679 (* 1 = 0.000121679 loss)
I0529 00:19:17.884788 11123 sgd_solver.cpp:105] Iteration 66800, lr = 0.00666
I0529 00:19:45.847307 11123 solver.cpp:218] Iteration 66900 (3.57629 iter/s, 27.9619s/100 iters), loss = 0.00446917
I0529 00:19:45.847473 11123 solver.cpp:237]     Train net output #0: loss = 0.00446818 (* 1 = 0.00446818 loss)
I0529 00:19:45.847484 11123 sgd_solver.cpp:105] Iteration 66900, lr = 0.006655
I0529 00:20:13.562922 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_67000.caffemodel
I0529 00:20:13.869096 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_67000.solverstate
I0529 00:20:14.014997 11123 solver.cpp:330] Iteration 67000, Testing net (#0)
I0529 00:20:18.462443 11123 solver.cpp:397]     Test net output #0: accuracy = 0.910001
I0529 00:20:18.462621 11123 solver.cpp:397]     Test net output #1: loss = 0.302918 (* 1 = 0.302918 loss)
I0529 00:20:18.740820 11123 solver.cpp:218] Iteration 67000 (3.04019 iter/s, 32.8927s/100 iters), loss = 0.00322031
I0529 00:20:18.740865 11123 solver.cpp:237]     Train net output #0: loss = 0.00321931 (* 1 = 0.00321931 loss)
I0529 00:20:18.740875 11123 sgd_solver.cpp:105] Iteration 67000, lr = 0.00665
I0529 00:20:46.753305 11123 solver.cpp:218] Iteration 67100 (3.56992 iter/s, 28.0118s/100 iters), loss = 0.00200025
I0529 00:20:46.753366 11123 solver.cpp:237]     Train net output #0: loss = 0.00199924 (* 1 = 0.00199924 loss)
I0529 00:20:46.753376 11123 sgd_solver.cpp:105] Iteration 67100, lr = 0.006645
I0529 00:21:14.774324 11123 solver.cpp:218] Iteration 67200 (3.56884 iter/s, 28.0203s/100 iters), loss = 0.00150773
I0529 00:21:14.774538 11123 solver.cpp:237]     Train net output #0: loss = 0.00150672 (* 1 = 0.00150672 loss)
I0529 00:21:14.774567 11123 sgd_solver.cpp:105] Iteration 67200, lr = 0.00664
I0529 00:21:42.771394 11123 solver.cpp:218] Iteration 67300 (3.5719 iter/s, 27.9963s/100 iters), loss = 0.0553663
I0529 00:21:42.771455 11123 solver.cpp:237]     Train net output #0: loss = 0.0553653 (* 1 = 0.0553653 loss)
I0529 00:21:42.771467 11123 sgd_solver.cpp:105] Iteration 67300, lr = 0.006635
I0529 00:22:10.766345 11123 solver.cpp:218] Iteration 67400 (3.57216 iter/s, 27.9943s/100 iters), loss = 0.00408195
I0529 00:22:10.766528 11123 solver.cpp:237]     Train net output #0: loss = 0.00408096 (* 1 = 0.00408096 loss)
I0529 00:22:10.766541 11123 sgd_solver.cpp:105] Iteration 67400, lr = 0.00663
I0529 00:22:11.626991 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:22:38.746724 11123 solver.cpp:218] Iteration 67500 (3.57403 iter/s, 27.9796s/100 iters), loss = 0.0105691
I0529 00:22:38.746781 11123 solver.cpp:237]     Train net output #0: loss = 0.0105681 (* 1 = 0.0105681 loss)
I0529 00:22:38.746790 11123 sgd_solver.cpp:105] Iteration 67500, lr = 0.006625
I0529 00:23:06.737614 11123 solver.cpp:218] Iteration 67600 (3.57267 iter/s, 27.9902s/100 iters), loss = 0.132349
I0529 00:23:06.738469 11123 solver.cpp:237]     Train net output #0: loss = 0.132348 (* 1 = 0.132348 loss)
I0529 00:23:06.738481 11123 sgd_solver.cpp:105] Iteration 67600, lr = 0.00662
I0529 00:23:34.732753 11123 solver.cpp:218] Iteration 67700 (3.57223 iter/s, 27.9937s/100 iters), loss = 0.0103091
I0529 00:23:34.732800 11123 solver.cpp:237]     Train net output #0: loss = 0.0103081 (* 1 = 0.0103081 loss)
I0529 00:23:34.732808 11123 sgd_solver.cpp:105] Iteration 67700, lr = 0.006615
I0529 00:24:02.720782 11123 solver.cpp:218] Iteration 67800 (3.57304 iter/s, 27.9874s/100 iters), loss = 0.0416048
I0529 00:24:02.720963 11123 solver.cpp:237]     Train net output #0: loss = 0.0416038 (* 1 = 0.0416038 loss)
I0529 00:24:02.720974 11123 sgd_solver.cpp:105] Iteration 67800, lr = 0.00661
I0529 00:24:30.696838 11123 solver.cpp:218] Iteration 67900 (3.57458 iter/s, 27.9753s/100 iters), loss = 0.00114152
I0529 00:24:30.696892 11123 solver.cpp:237]     Train net output #0: loss = 0.00114055 (* 1 = 0.00114055 loss)
I0529 00:24:30.696900 11123 sgd_solver.cpp:105] Iteration 67900, lr = 0.006605
I0529 00:24:58.372952 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_68000.caffemodel
I0529 00:24:58.679330 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_68000.solverstate
I0529 00:24:58.824666 11123 solver.cpp:330] Iteration 68000, Testing net (#0)
I0529 00:24:59.944852 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:25:03.290812 11123 solver.cpp:397]     Test net output #0: accuracy = 0.908001
I0529 00:25:03.290850 11123 solver.cpp:397]     Test net output #1: loss = 0.433843 (* 1 = 0.433843 loss)
I0529 00:25:03.567143 11123 solver.cpp:218] Iteration 68000 (3.04233 iter/s, 32.8696s/100 iters), loss = 0.0104668
I0529 00:25:03.567186 11123 solver.cpp:237]     Train net output #0: loss = 0.0104658 (* 1 = 0.0104658 loss)
I0529 00:25:03.567194 11123 sgd_solver.cpp:105] Iteration 68000, lr = 0.0066
I0529 00:25:08.077458 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:25:31.598573 11123 solver.cpp:218] Iteration 68100 (3.56751 iter/s, 28.0308s/100 iters), loss = 0.069291
I0529 00:25:31.598783 11123 solver.cpp:237]     Train net output #0: loss = 0.06929 (* 1 = 0.06929 loss)
I0529 00:25:31.598793 11123 sgd_solver.cpp:105] Iteration 68100, lr = 0.006595
I0529 00:25:59.620034 11123 solver.cpp:218] Iteration 68200 (3.56879 iter/s, 28.0207s/100 iters), loss = 0.0252699
I0529 00:25:59.620090 11123 solver.cpp:237]     Train net output #0: loss = 0.0252689 (* 1 = 0.0252689 loss)
I0529 00:25:59.620100 11123 sgd_solver.cpp:105] Iteration 68200, lr = 0.00659
I0529 00:26:27.660169 11123 solver.cpp:218] Iteration 68300 (3.5664 iter/s, 28.0395s/100 iters), loss = 0.0167959
I0529 00:26:27.660390 11123 solver.cpp:237]     Train net output #0: loss = 0.016795 (* 1 = 0.016795 loss)
I0529 00:26:27.660408 11123 sgd_solver.cpp:105] Iteration 68300, lr = 0.006585
I0529 00:26:55.685070 11123 solver.cpp:218] Iteration 68400 (3.56836 iter/s, 28.0241s/100 iters), loss = 6.77351e-05
I0529 00:26:55.685123 11123 solver.cpp:237]     Train net output #0: loss = 6.68191e-05 (* 1 = 6.68191e-05 loss)
I0529 00:26:55.685133 11123 sgd_solver.cpp:105] Iteration 68400, lr = 0.00658
I0529 00:27:23.678267 11123 solver.cpp:218] Iteration 68500 (3.57238 iter/s, 27.9925s/100 iters), loss = 0.0021501
I0529 00:27:23.678442 11123 solver.cpp:237]     Train net output #0: loss = 0.00214919 (* 1 = 0.00214919 loss)
I0529 00:27:23.678458 11123 sgd_solver.cpp:105] Iteration 68500, lr = 0.006575
I0529 00:27:51.676414 11123 solver.cpp:218] Iteration 68600 (3.57176 iter/s, 27.9974s/100 iters), loss = 0.0020136
I0529 00:27:51.676476 11123 solver.cpp:237]     Train net output #0: loss = 0.00201269 (* 1 = 0.00201269 loss)
I0529 00:27:51.676499 11123 sgd_solver.cpp:105] Iteration 68600, lr = 0.00657
I0529 00:27:59.815456 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:28:19.684849 11123 solver.cpp:218] Iteration 68700 (3.57044 iter/s, 28.0078s/100 iters), loss = 0.000872472
I0529 00:28:19.684904 11123 solver.cpp:237]     Train net output #0: loss = 0.000871549 (* 1 = 0.000871549 loss)
I0529 00:28:19.684931 11123 sgd_solver.cpp:105] Iteration 68700, lr = 0.006565
I0529 00:28:47.675850 11123 solver.cpp:218] Iteration 68800 (3.57266 iter/s, 27.9903s/100 iters), loss = 0.000225394
I0529 00:28:47.676075 11123 solver.cpp:237]     Train net output #0: loss = 0.000224475 (* 1 = 0.000224475 loss)
I0529 00:28:47.676086 11123 sgd_solver.cpp:105] Iteration 68800, lr = 0.00656
I0529 00:29:15.696290 11123 solver.cpp:218] Iteration 68900 (3.56893 iter/s, 28.0196s/100 iters), loss = 0.00260634
I0529 00:29:15.696346 11123 solver.cpp:237]     Train net output #0: loss = 0.00260542 (* 1 = 0.00260542 loss)
I0529 00:29:15.696354 11123 sgd_solver.cpp:105] Iteration 68900, lr = 0.006555
I0529 00:29:43.411727 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_69000.caffemodel
I0529 00:29:43.717416 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_69000.solverstate
I0529 00:29:43.863049 11123 solver.cpp:330] Iteration 69000, Testing net (#0)
I0529 00:29:46.489485 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:29:48.306228 11123 solver.cpp:397]     Test net output #0: accuracy = 0.924
I0529 00:29:48.306262 11123 solver.cpp:397]     Test net output #1: loss = 0.283034 (* 1 = 0.283034 loss)
I0529 00:29:48.582923 11123 solver.cpp:218] Iteration 69000 (3.04082 iter/s, 32.8859s/100 iters), loss = 0.000467568
I0529 00:29:48.582967 11123 solver.cpp:237]     Train net output #0: loss = 0.000466647 (* 1 = 0.000466647 loss)
I0529 00:29:48.582975 11123 sgd_solver.cpp:105] Iteration 69000, lr = 0.00655
I0529 00:30:16.590579 11123 solver.cpp:218] Iteration 69100 (3.57054 iter/s, 28.007s/100 iters), loss = 0.000103846
I0529 00:30:16.590662 11123 solver.cpp:237]     Train net output #0: loss = 0.000102922 (* 1 = 0.000102922 loss)
I0529 00:30:16.590672 11123 sgd_solver.cpp:105] Iteration 69100, lr = 0.006545
I0529 00:30:44.591617 11123 solver.cpp:218] Iteration 69200 (3.57138 iter/s, 28.0003s/100 iters), loss = 0.00527702
I0529 00:30:44.591661 11123 solver.cpp:237]     Train net output #0: loss = 0.0052761 (* 1 = 0.0052761 loss)
I0529 00:30:44.591670 11123 sgd_solver.cpp:105] Iteration 69200, lr = 0.00654
I0529 00:30:56.372967 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:31:12.613926 11123 solver.cpp:218] Iteration 69300 (3.56867 iter/s, 28.0217s/100 iters), loss = 0.00129162
I0529 00:31:12.613978 11123 solver.cpp:237]     Train net output #0: loss = 0.00129072 (* 1 = 0.00129072 loss)
I0529 00:31:12.613988 11123 sgd_solver.cpp:105] Iteration 69300, lr = 0.006535
I0529 00:31:40.638746 11123 solver.cpp:218] Iteration 69400 (3.56835 iter/s, 28.0242s/100 iters), loss = 0.000222998
I0529 00:31:40.639015 11123 solver.cpp:237]     Train net output #0: loss = 0.000222095 (* 1 = 0.000222095 loss)
I0529 00:31:40.639027 11123 sgd_solver.cpp:105] Iteration 69400, lr = 0.00653
I0529 00:32:08.646518 11123 solver.cpp:218] Iteration 69500 (3.57055 iter/s, 28.0069s/100 iters), loss = 0.154413
I0529 00:32:08.646564 11123 solver.cpp:237]     Train net output #0: loss = 0.154412 (* 1 = 0.154412 loss)
I0529 00:32:08.646572 11123 sgd_solver.cpp:105] Iteration 69500, lr = 0.006525
I0529 00:32:36.650267 11123 solver.cpp:218] Iteration 69600 (3.57103 iter/s, 28.0031s/100 iters), loss = 0.000368262
I0529 00:32:36.650420 11123 solver.cpp:237]     Train net output #0: loss = 0.000367385 (* 1 = 0.000367385 loss)
I0529 00:32:36.650431 11123 sgd_solver.cpp:105] Iteration 69600, lr = 0.00652
I0529 00:33:04.651649 11123 solver.cpp:218] Iteration 69700 (3.57135 iter/s, 28.0006s/100 iters), loss = 0.000259443
I0529 00:33:04.651700 11123 solver.cpp:237]     Train net output #0: loss = 0.000258558 (* 1 = 0.000258558 loss)
I0529 00:33:04.651710 11123 sgd_solver.cpp:105] Iteration 69700, lr = 0.006515
I0529 00:33:32.673787 11123 solver.cpp:218] Iteration 69800 (3.56869 iter/s, 28.0215s/100 iters), loss = 0.0172741
I0529 00:33:32.673966 11123 solver.cpp:237]     Train net output #0: loss = 0.0172732 (* 1 = 0.0172732 loss)
I0529 00:33:32.673979 11123 sgd_solver.cpp:105] Iteration 69800, lr = 0.00651
I0529 00:33:48.090445 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:34:00.672075 11123 solver.cpp:218] Iteration 69900 (3.57175 iter/s, 27.9975s/100 iters), loss = 0.000578642
I0529 00:34:00.672127 11123 solver.cpp:237]     Train net output #0: loss = 0.000577738 (* 1 = 0.000577738 loss)
I0529 00:34:00.672135 11123 sgd_solver.cpp:105] Iteration 69900, lr = 0.006505
I0529 00:34:28.388417 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_70000.caffemodel
I0529 00:34:28.960774 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_70000.solverstate
I0529 00:34:29.106484 11123 solver.cpp:330] Iteration 70000, Testing net (#0)
I0529 00:34:33.249843 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:34:33.556610 11123 solver.cpp:397]     Test net output #0: accuracy = 0.929
I0529 00:34:33.556653 11123 solver.cpp:397]     Test net output #1: loss = 0.276507 (* 1 = 0.276507 loss)
I0529 00:34:33.832895 11123 solver.cpp:218] Iteration 70000 (3.01568 iter/s, 33.16s/100 iters), loss = 0.00291248
I0529 00:34:33.832944 11123 solver.cpp:237]     Train net output #0: loss = 0.0029116 (* 1 = 0.0029116 loss)
I0529 00:34:33.832953 11123 sgd_solver.cpp:105] Iteration 70000, lr = 0.0065
I0529 00:35:01.815601 11123 solver.cpp:218] Iteration 70100 (3.57372 iter/s, 27.982s/100 iters), loss = 0.177272
I0529 00:35:01.815765 11123 solver.cpp:237]     Train net output #0: loss = 0.177272 (* 1 = 0.177272 loss)
I0529 00:35:01.815778 11123 sgd_solver.cpp:105] Iteration 70100, lr = 0.006495
I0529 00:35:29.819509 11123 solver.cpp:218] Iteration 70200 (3.57103 iter/s, 28.0031s/100 iters), loss = 0.000215721
I0529 00:35:29.819562 11123 solver.cpp:237]     Train net output #0: loss = 0.000214878 (* 1 = 0.000214878 loss)
I0529 00:35:29.819572 11123 sgd_solver.cpp:105] Iteration 70200, lr = 0.00649
I0529 00:35:57.833891 11123 solver.cpp:218] Iteration 70300 (3.56968 iter/s, 28.0137s/100 iters), loss = 0.0634692
I0529 00:35:57.834048 11123 solver.cpp:237]     Train net output #0: loss = 0.0634684 (* 1 = 0.0634684 loss)
I0529 00:35:57.834067 11123 sgd_solver.cpp:105] Iteration 70300, lr = 0.006485
I0529 00:36:25.851269 11123 solver.cpp:218] Iteration 70400 (3.56931 iter/s, 28.0166s/100 iters), loss = 0.00948812
I0529 00:36:25.851332 11123 solver.cpp:237]     Train net output #0: loss = 0.00948727 (* 1 = 0.00948727 loss)
I0529 00:36:25.851346 11123 sgd_solver.cpp:105] Iteration 70400, lr = 0.00648
I0529 00:36:44.633555 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:36:53.850612 11123 solver.cpp:218] Iteration 70500 (3.5716 iter/s, 27.9987s/100 iters), loss = 0.0011316
I0529 00:36:53.850659 11123 solver.cpp:237]     Train net output #0: loss = 0.00113074 (* 1 = 0.00113074 loss)
I0529 00:36:53.850667 11123 sgd_solver.cpp:105] Iteration 70500, lr = 0.006475
I0529 00:37:21.868855 11123 solver.cpp:218] Iteration 70600 (3.56919 iter/s, 28.0176s/100 iters), loss = 0.000591869
I0529 00:37:21.869048 11123 solver.cpp:237]     Train net output #0: loss = 0.000591013 (* 1 = 0.000591013 loss)
I0529 00:37:21.869060 11123 sgd_solver.cpp:105] Iteration 70600, lr = 0.00647
I0529 00:37:49.876119 11123 solver.cpp:218] Iteration 70700 (3.57061 iter/s, 28.0064s/100 iters), loss = 0.000166903
I0529 00:37:49.876175 11123 solver.cpp:237]     Train net output #0: loss = 0.000166048 (* 1 = 0.000166048 loss)
I0529 00:37:49.876184 11123 sgd_solver.cpp:105] Iteration 70700, lr = 0.006465
I0529 00:38:17.882743 11123 solver.cpp:218] Iteration 70800 (3.57067 iter/s, 28.006s/100 iters), loss = 0.000595503
I0529 00:38:17.882956 11123 solver.cpp:237]     Train net output #0: loss = 0.000594646 (* 1 = 0.000594646 loss)
I0529 00:38:17.882967 11123 sgd_solver.cpp:105] Iteration 70800, lr = 0.00646
I0529 00:38:45.877625 11123 solver.cpp:218] Iteration 70900 (3.57219 iter/s, 27.9941s/100 iters), loss = 0.00248485
I0529 00:38:45.877670 11123 solver.cpp:237]     Train net output #0: loss = 0.002484 (* 1 = 0.002484 loss)
I0529 00:38:45.877678 11123 sgd_solver.cpp:105] Iteration 70900, lr = 0.006455
I0529 00:39:13.623497 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_71000.caffemodel
I0529 00:39:14.093219 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_71000.solverstate
I0529 00:39:14.240141 11123 solver.cpp:330] Iteration 71000, Testing net (#0)
I0529 00:39:18.694079 11123 solver.cpp:397]     Test net output #0: accuracy = 0.919001
I0529 00:39:18.694120 11123 solver.cpp:397]     Test net output #1: loss = 0.3133 (* 1 = 0.3133 loss)
I0529 00:39:18.971020 11123 solver.cpp:218] Iteration 71000 (3.02182 iter/s, 33.0926s/100 iters), loss = 0.00169413
I0529 00:39:18.971073 11123 solver.cpp:237]     Train net output #0: loss = 0.00169326 (* 1 = 0.00169326 loss)
I0529 00:39:18.971082 11123 sgd_solver.cpp:105] Iteration 71000, lr = 0.00645
I0529 00:39:41.371212 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:39:46.951398 11123 solver.cpp:218] Iteration 71100 (3.57402 iter/s, 27.9797s/100 iters), loss = 0.00608723
I0529 00:39:46.951576 11123 solver.cpp:237]     Train net output #0: loss = 0.00608634 (* 1 = 0.00608634 loss)
I0529 00:39:46.951589 11123 sgd_solver.cpp:105] Iteration 71100, lr = 0.006445
I0529 00:40:14.948432 11123 solver.cpp:218] Iteration 71200 (3.57191 iter/s, 27.9962s/100 iters), loss = 0.000156663
I0529 00:40:14.948488 11123 solver.cpp:237]     Train net output #0: loss = 0.00015578 (* 1 = 0.00015578 loss)
I0529 00:40:14.948498 11123 sgd_solver.cpp:105] Iteration 71200, lr = 0.00644
I0529 00:40:42.922180 11123 solver.cpp:218] Iteration 71300 (3.57487 iter/s, 27.9731s/100 iters), loss = 0.0026187
I0529 00:40:42.922360 11123 solver.cpp:237]     Train net output #0: loss = 0.00261785 (* 1 = 0.00261785 loss)
I0529 00:40:42.922372 11123 sgd_solver.cpp:105] Iteration 71300, lr = 0.006435
I0529 00:41:10.916750 11123 solver.cpp:218] Iteration 71400 (3.57222 iter/s, 27.9938s/100 iters), loss = 0.0877014
I0529 00:41:10.916795 11123 solver.cpp:237]     Train net output #0: loss = 0.0877005 (* 1 = 0.0877005 loss)
I0529 00:41:10.916805 11123 sgd_solver.cpp:105] Iteration 71400, lr = 0.00643
I0529 00:41:38.894800 11123 solver.cpp:218] Iteration 71500 (3.57431 iter/s, 27.9774s/100 iters), loss = 0.00377449
I0529 00:41:38.894958 11123 solver.cpp:237]     Train net output #0: loss = 0.00377365 (* 1 = 0.00377365 loss)
I0529 00:41:38.894969 11123 sgd_solver.cpp:105] Iteration 71500, lr = 0.006425
I0529 00:42:06.878820 11123 solver.cpp:218] Iteration 71600 (3.57357 iter/s, 27.9833s/100 iters), loss = 0.00273583
I0529 00:42:06.878865 11123 solver.cpp:237]     Train net output #0: loss = 0.00273502 (* 1 = 0.00273502 loss)
I0529 00:42:06.878873 11123 sgd_solver.cpp:105] Iteration 71600, lr = 0.00642
I0529 00:42:32.951650 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:42:34.897225 11123 solver.cpp:218] Iteration 71700 (3.56917 iter/s, 28.0177s/100 iters), loss = 0.0174547
I0529 00:42:34.897269 11123 solver.cpp:237]     Train net output #0: loss = 0.0174539 (* 1 = 0.0174539 loss)
I0529 00:42:34.897277 11123 sgd_solver.cpp:105] Iteration 71700, lr = 0.006415
I0529 00:43:02.913564 11123 solver.cpp:218] Iteration 71800 (3.56943 iter/s, 28.0157s/100 iters), loss = 8.16295e-05
I0529 00:43:02.913609 11123 solver.cpp:237]     Train net output #0: loss = 8.08448e-05 (* 1 = 8.08448e-05 loss)
I0529 00:43:02.913617 11123 sgd_solver.cpp:105] Iteration 71800, lr = 0.00641
I0529 00:43:30.919203 11123 solver.cpp:218] Iteration 71900 (3.57079 iter/s, 28.005s/100 iters), loss = 0.0117882
I0529 00:43:30.919409 11123 solver.cpp:237]     Train net output #0: loss = 0.0117875 (* 1 = 0.0117875 loss)
I0529 00:43:30.919421 11123 sgd_solver.cpp:105] Iteration 71900, lr = 0.006405
I0529 00:43:58.648596 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_72000.caffemodel
I0529 00:43:59.088398 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_72000.solverstate
I0529 00:43:59.233597 11123 solver.cpp:330] Iteration 72000, Testing net (#0)
I0529 00:44:00.453269 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:44:03.693840 11123 solver.cpp:397]     Test net output #0: accuracy = 0.892
I0529 00:44:03.693985 11123 solver.cpp:397]     Test net output #1: loss = 0.381844 (* 1 = 0.381844 loss)
I0529 00:44:03.970219 11123 solver.cpp:218] Iteration 72000 (3.02571 iter/s, 33.0501s/100 iters), loss = 0.151153
I0529 00:44:03.970270 11123 solver.cpp:237]     Train net output #0: loss = 0.151152 (* 1 = 0.151152 loss)
I0529 00:44:03.970279 11123 sgd_solver.cpp:105] Iteration 72000, lr = 0.0064
I0529 00:44:31.922544 11123 solver.cpp:218] Iteration 72100 (3.57761 iter/s, 27.9517s/100 iters), loss = 0.000916358
I0529 00:44:31.922598 11123 solver.cpp:237]     Train net output #0: loss = 0.000915609 (* 1 = 0.000915609 loss)
I0529 00:44:31.922607 11123 sgd_solver.cpp:105] Iteration 72100, lr = 0.006395
I0529 00:44:59.878132 11123 solver.cpp:218] Iteration 72200 (3.57719 iter/s, 27.9549s/100 iters), loss = 5.60659e-05
I0529 00:44:59.878288 11123 solver.cpp:237]     Train net output #0: loss = 5.53128e-05 (* 1 = 5.53128e-05 loss)
I0529 00:44:59.878300 11123 sgd_solver.cpp:105] Iteration 72200, lr = 0.00639
I0529 00:45:27.842927 11123 solver.cpp:218] Iteration 72300 (3.57601 iter/s, 27.9641s/100 iters), loss = 0.0121006
I0529 00:45:27.842974 11123 solver.cpp:237]     Train net output #0: loss = 0.0120999 (* 1 = 0.0120999 loss)
I0529 00:45:27.842983 11123 sgd_solver.cpp:105] Iteration 72300, lr = 0.006385
I0529 00:45:29.541714 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:45:55.857220 11123 solver.cpp:218] Iteration 72400 (3.56968 iter/s, 28.0137s/100 iters), loss = 0.000150741
I0529 00:45:55.857389 11123 solver.cpp:237]     Train net output #0: loss = 0.00014999 (* 1 = 0.00014999 loss)
I0529 00:45:55.857401 11123 sgd_solver.cpp:105] Iteration 72400, lr = 0.00638
I0529 00:46:23.883455 11123 solver.cpp:218] Iteration 72500 (3.56817 iter/s, 28.0255s/100 iters), loss = 0.0163701
I0529 00:46:23.883512 11123 solver.cpp:237]     Train net output #0: loss = 0.0163693 (* 1 = 0.0163693 loss)
I0529 00:46:23.883519 11123 sgd_solver.cpp:105] Iteration 72500, lr = 0.006375
I0529 00:46:51.880300 11123 solver.cpp:218] Iteration 72600 (3.57191 iter/s, 27.9963s/100 iters), loss = 0.0132528
I0529 00:46:51.880491 11123 solver.cpp:237]     Train net output #0: loss = 0.013252 (* 1 = 0.013252 loss)
I0529 00:46:51.880502 11123 sgd_solver.cpp:105] Iteration 72600, lr = 0.00637
I0529 00:47:19.872597 11123 solver.cpp:218] Iteration 72700 (3.5725 iter/s, 27.9916s/100 iters), loss = 0.000247207
I0529 00:47:19.872642 11123 solver.cpp:237]     Train net output #0: loss = 0.000246383 (* 1 = 0.000246383 loss)
I0529 00:47:19.872651 11123 sgd_solver.cpp:105] Iteration 72700, lr = 0.006365
I0529 00:47:47.878060 11123 solver.cpp:218] Iteration 72800 (3.57081 iter/s, 28.0049s/100 iters), loss = 0.00125648
I0529 00:47:47.878232 11123 solver.cpp:237]     Train net output #0: loss = 0.00125565 (* 1 = 0.00125565 loss)
I0529 00:47:47.878244 11123 sgd_solver.cpp:105] Iteration 72800, lr = 0.00636
I0529 00:48:15.883644 11123 solver.cpp:218] Iteration 72900 (3.57081 iter/s, 28.0049s/100 iters), loss = 0.0135478
I0529 00:48:15.883700 11123 solver.cpp:237]     Train net output #0: loss = 0.0135469 (* 1 = 0.0135469 loss)
I0529 00:48:15.883710 11123 sgd_solver.cpp:105] Iteration 72900, lr = 0.006355
I0529 00:48:21.221215 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:48:43.597457 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_73000.caffemodel
I0529 00:48:44.060731 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_73000.solverstate
I0529 00:48:44.206243 11123 solver.cpp:330] Iteration 73000, Testing net (#0)
I0529 00:48:46.923557 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:48:48.653107 11123 solver.cpp:397]     Test net output #0: accuracy = 0.917
I0529 00:48:48.653156 11123 solver.cpp:397]     Test net output #1: loss = 0.309872 (* 1 = 0.309872 loss)
I0529 00:48:48.930171 11123 solver.cpp:218] Iteration 73000 (3.0261 iter/s, 33.0458s/100 iters), loss = 0.0239396
I0529 00:48:48.930214 11123 solver.cpp:237]     Train net output #0: loss = 0.0239388 (* 1 = 0.0239388 loss)
I0529 00:48:48.930222 11123 sgd_solver.cpp:105] Iteration 73000, lr = 0.00635
I0529 00:49:16.933190 11123 solver.cpp:218] Iteration 73100 (3.57112 iter/s, 28.0024s/100 iters), loss = 0.000895619
I0529 00:49:16.933388 11123 solver.cpp:237]     Train net output #0: loss = 0.000894723 (* 1 = 0.000894723 loss)
I0529 00:49:16.933400 11123 sgd_solver.cpp:105] Iteration 73100, lr = 0.006345
I0529 00:49:44.931861 11123 solver.cpp:218] Iteration 73200 (3.57169 iter/s, 27.998s/100 iters), loss = 0.000464156
I0529 00:49:44.931905 11123 solver.cpp:237]     Train net output #0: loss = 0.000463259 (* 1 = 0.000463259 loss)
I0529 00:49:44.931915 11123 sgd_solver.cpp:105] Iteration 73200, lr = 0.00634
I0529 00:50:12.927834 11123 solver.cpp:218] Iteration 73300 (3.57202 iter/s, 27.9954s/100 iters), loss = 0.0406532
I0529 00:50:12.928004 11123 solver.cpp:237]     Train net output #0: loss = 0.0406523 (* 1 = 0.0406523 loss)
I0529 00:50:12.928014 11123 sgd_solver.cpp:105] Iteration 73300, lr = 0.006335
I0529 00:50:40.904913 11123 solver.cpp:218] Iteration 73400 (3.57445 iter/s, 27.9764s/100 iters), loss = 0.000401845
I0529 00:50:40.904960 11123 solver.cpp:237]     Train net output #0: loss = 0.000400926 (* 1 = 0.000400926 loss)
I0529 00:50:40.904969 11123 sgd_solver.cpp:105] Iteration 73400, lr = 0.00633
I0529 00:51:08.922390 11123 solver.cpp:218] Iteration 73500 (3.56928 iter/s, 28.0169s/100 iters), loss = 0.000297452
I0529 00:51:08.922544 11123 solver.cpp:237]     Train net output #0: loss = 0.000296551 (* 1 = 0.000296551 loss)
I0529 00:51:08.922554 11123 sgd_solver.cpp:105] Iteration 73500, lr = 0.006325
I0529 00:51:17.623323 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:51:36.920956 11123 solver.cpp:218] Iteration 73600 (3.5717 iter/s, 27.9979s/100 iters), loss = 0.00389274
I0529 00:51:36.921002 11123 solver.cpp:237]     Train net output #0: loss = 0.00389185 (* 1 = 0.00389185 loss)
I0529 00:51:36.921011 11123 sgd_solver.cpp:105] Iteration 73600, lr = 0.00632
I0529 00:52:04.900568 11123 solver.cpp:218] Iteration 73700 (3.57411 iter/s, 27.979s/100 iters), loss = 0.00479155
I0529 00:52:04.900733 11123 solver.cpp:237]     Train net output #0: loss = 0.00479068 (* 1 = 0.00479068 loss)
I0529 00:52:04.900746 11123 sgd_solver.cpp:105] Iteration 73700, lr = 0.006315
I0529 00:52:32.889459 11123 solver.cpp:218] Iteration 73800 (3.57294 iter/s, 27.9882s/100 iters), loss = 0.00114889
I0529 00:52:32.889504 11123 solver.cpp:237]     Train net output #0: loss = 0.00114801 (* 1 = 0.00114801 loss)
I0529 00:52:32.889513 11123 sgd_solver.cpp:105] Iteration 73800, lr = 0.00631
I0529 00:53:00.865206 11123 solver.cpp:218] Iteration 73900 (3.5746 iter/s, 27.9751s/100 iters), loss = 0.00188607
I0529 00:53:00.865424 11123 solver.cpp:237]     Train net output #0: loss = 0.00188519 (* 1 = 0.00188519 loss)
I0529 00:53:00.865435 11123 sgd_solver.cpp:105] Iteration 73900, lr = 0.006305
I0529 00:53:28.585662 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_74000.caffemodel
I0529 00:53:28.940448 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_74000.solverstate
I0529 00:53:29.086174 11123 solver.cpp:330] Iteration 74000, Testing net (#0)
I0529 00:53:33.318877 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:53:33.539296 11123 solver.cpp:397]     Test net output #0: accuracy = 0.921
I0529 00:53:33.539346 11123 solver.cpp:397]     Test net output #1: loss = 0.26858 (* 1 = 0.26858 loss)
I0529 00:53:33.816802 11123 solver.cpp:218] Iteration 74000 (3.03484 iter/s, 32.9507s/100 iters), loss = 0.000387858
I0529 00:53:33.816848 11123 solver.cpp:237]     Train net output #0: loss = 0.000386978 (* 1 = 0.000386978 loss)
I0529 00:53:33.816857 11123 sgd_solver.cpp:105] Iteration 74000, lr = 0.0063
I0529 00:54:01.823652 11123 solver.cpp:218] Iteration 74100 (3.57063 iter/s, 28.0062s/100 iters), loss = 0.000616275
I0529 00:54:01.823696 11123 solver.cpp:237]     Train net output #0: loss = 0.000615388 (* 1 = 0.000615388 loss)
I0529 00:54:01.823705 11123 sgd_solver.cpp:105] Iteration 74100, lr = 0.006295
I0529 00:54:14.167120 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:54:29.817723 11123 solver.cpp:218] Iteration 74200 (3.57226 iter/s, 27.9935s/100 iters), loss = 0.261766
I0529 00:54:29.817765 11123 solver.cpp:237]     Train net output #0: loss = 0.261765 (* 1 = 0.261765 loss)
I0529 00:54:29.817773 11123 sgd_solver.cpp:105] Iteration 74200, lr = 0.00629
I0529 00:54:57.790772 11123 solver.cpp:218] Iteration 74300 (3.57495 iter/s, 27.9724s/100 iters), loss = 0.000403576
I0529 00:54:57.790925 11123 solver.cpp:237]     Train net output #0: loss = 0.000402744 (* 1 = 0.000402744 loss)
I0529 00:54:57.790936 11123 sgd_solver.cpp:105] Iteration 74300, lr = 0.006285
I0529 00:55:25.775282 11123 solver.cpp:218] Iteration 74400 (3.5735 iter/s, 27.9838s/100 iters), loss = 0.00094172
I0529 00:55:25.775326 11123 solver.cpp:237]     Train net output #0: loss = 0.000940894 (* 1 = 0.000940894 loss)
I0529 00:55:25.775336 11123 sgd_solver.cpp:105] Iteration 74400, lr = 0.00628
I0529 00:55:53.761664 11123 solver.cpp:218] Iteration 74500 (3.57325 iter/s, 27.9858s/100 iters), loss = 0.000223076
I0529 00:55:53.761945 11123 solver.cpp:237]     Train net output #0: loss = 0.000222241 (* 1 = 0.000222241 loss)
I0529 00:55:53.761957 11123 sgd_solver.cpp:105] Iteration 74500, lr = 0.006275
I0529 00:56:21.747828 11123 solver.cpp:218] Iteration 74600 (3.5733 iter/s, 27.9853s/100 iters), loss = 0.0272852
I0529 00:56:21.747871 11123 solver.cpp:237]     Train net output #0: loss = 0.0272844 (* 1 = 0.0272844 loss)
I0529 00:56:21.747879 11123 sgd_solver.cpp:105] Iteration 74600, lr = 0.00627
I0529 00:56:49.726058 11123 solver.cpp:218] Iteration 74700 (3.57429 iter/s, 27.9776s/100 iters), loss = 4.03806e-05
I0529 00:56:49.726220 11123 solver.cpp:237]     Train net output #0: loss = 3.95369e-05 (* 1 = 3.95369e-05 loss)
I0529 00:56:49.726231 11123 sgd_solver.cpp:105] Iteration 74700, lr = 0.006265
I0529 00:57:05.707661 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:57:17.712780 11123 solver.cpp:218] Iteration 74800 (3.57322 iter/s, 27.986s/100 iters), loss = 0.00719218
I0529 00:57:17.712827 11123 solver.cpp:237]     Train net output #0: loss = 0.0071913 (* 1 = 0.0071913 loss)
I0529 00:57:17.712837 11123 sgd_solver.cpp:105] Iteration 74800, lr = 0.00626
I0529 00:57:45.688076 11123 solver.cpp:218] Iteration 74900 (3.57466 iter/s, 27.9747s/100 iters), loss = 0.00970753
I0529 00:57:45.688261 11123 solver.cpp:237]     Train net output #0: loss = 0.00970667 (* 1 = 0.00970667 loss)
I0529 00:57:45.688272 11123 sgd_solver.cpp:105] Iteration 74900, lr = 0.006255
I0529 00:58:13.355413 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_75000.caffemodel
I0529 00:58:13.718514 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_75000.solverstate
I0529 00:58:13.864606 11123 solver.cpp:330] Iteration 75000, Testing net (#0)
I0529 00:58:18.308135 11123 solver.cpp:397]     Test net output #0: accuracy = 0.923001
I0529 00:58:18.308289 11123 solver.cpp:397]     Test net output #1: loss = 0.22279 (* 1 = 0.22279 loss)
I0529 00:58:18.584833 11123 solver.cpp:218] Iteration 75000 (3.03989 iter/s, 32.8959s/100 iters), loss = 0.000792294
I0529 00:58:18.584887 11123 solver.cpp:237]     Train net output #0: loss = 0.000791439 (* 1 = 0.000791439 loss)
I0529 00:58:18.584897 11123 sgd_solver.cpp:105] Iteration 75000, lr = 0.00625
I0529 00:58:46.575340 11123 solver.cpp:218] Iteration 75100 (3.57272 iter/s, 27.9899s/100 iters), loss = 0.112319
I0529 00:58:46.575390 11123 solver.cpp:237]     Train net output #0: loss = 0.112318 (* 1 = 0.112318 loss)
I0529 00:58:46.575399 11123 sgd_solver.cpp:105] Iteration 75100, lr = 0.006245
I0529 00:59:14.586205 11123 solver.cpp:218] Iteration 75200 (3.57012 iter/s, 28.0102s/100 iters), loss = 0.000464919
I0529 00:59:14.586369 11123 solver.cpp:237]     Train net output #0: loss = 0.000464059 (* 1 = 0.000464059 loss)
I0529 00:59:14.586381 11123 sgd_solver.cpp:105] Iteration 75200, lr = 0.00624
I0529 00:59:42.576918 11123 solver.cpp:218] Iteration 75300 (3.57271 iter/s, 27.99s/100 iters), loss = 0.00627497
I0529 00:59:42.576966 11123 solver.cpp:237]     Train net output #0: loss = 0.00627411 (* 1 = 0.00627411 loss)
I0529 00:59:42.576974 11123 sgd_solver.cpp:105] Iteration 75300, lr = 0.006235
I0529 01:00:02.195016 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:00:10.574511 11123 solver.cpp:218] Iteration 75400 (3.57182 iter/s, 27.997s/100 iters), loss = 0.00013257
I0529 01:00:10.574553 11123 solver.cpp:237]     Train net output #0: loss = 0.000131656 (* 1 = 0.000131656 loss)
I0529 01:00:10.574561 11123 sgd_solver.cpp:105] Iteration 75400, lr = 0.00623
I0529 01:00:38.563175 11123 solver.cpp:218] Iteration 75500 (3.57296 iter/s, 27.988s/100 iters), loss = 0.000140493
I0529 01:00:38.563297 11123 solver.cpp:237]     Train net output #0: loss = 0.000139595 (* 1 = 0.000139595 loss)
I0529 01:00:38.563307 11123 sgd_solver.cpp:105] Iteration 75500, lr = 0.006225
I0529 01:01:06.560791 11123 solver.cpp:218] Iteration 75600 (3.57182 iter/s, 27.9969s/100 iters), loss = 0.00291245
I0529 01:01:06.560835 11123 solver.cpp:237]     Train net output #0: loss = 0.00291152 (* 1 = 0.00291152 loss)
I0529 01:01:06.560844 11123 sgd_solver.cpp:105] Iteration 75600, lr = 0.00622
I0529 01:01:34.541641 11123 solver.cpp:218] Iteration 75700 (3.57395 iter/s, 27.9802s/100 iters), loss = 0.00722148
I0529 01:01:34.541795 11123 solver.cpp:237]     Train net output #0: loss = 0.00722057 (* 1 = 0.00722057 loss)
I0529 01:01:34.541806 11123 sgd_solver.cpp:105] Iteration 75700, lr = 0.006215
I0529 01:02:02.508379 11123 solver.cpp:218] Iteration 75800 (3.57577 iter/s, 27.966s/100 iters), loss = 0.000129061
I0529 01:02:02.508422 11123 solver.cpp:237]     Train net output #0: loss = 0.000128133 (* 1 = 0.000128133 loss)
I0529 01:02:02.508430 11123 sgd_solver.cpp:105] Iteration 75800, lr = 0.00621
I0529 01:02:30.494848 11123 solver.cpp:218] Iteration 75900 (3.57324 iter/s, 27.9858s/100 iters), loss = 0.00185731
I0529 01:02:30.494966 11123 solver.cpp:237]     Train net output #0: loss = 0.0018564 (* 1 = 0.0018564 loss)
I0529 01:02:30.494978 11123 sgd_solver.cpp:105] Iteration 75900, lr = 0.006205
I0529 01:02:53.714088 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:02:58.181990 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_76000.caffemodel
I0529 01:02:58.488201 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_76000.solverstate
I0529 01:02:58.633909 11123 solver.cpp:330] Iteration 76000, Testing net (#0)
I0529 01:02:59.928526 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:03:03.091934 11123 solver.cpp:397]     Test net output #0: accuracy = 0.923
I0529 01:03:03.092077 11123 solver.cpp:397]     Test net output #1: loss = 0.2715 (* 1 = 0.2715 loss)
I0529 01:03:03.369377 11123 solver.cpp:218] Iteration 76000 (3.04194 iter/s, 32.8737s/100 iters), loss = 0.0102579
I0529 01:03:03.369421 11123 solver.cpp:237]     Train net output #0: loss = 0.010257 (* 1 = 0.010257 loss)
I0529 01:03:03.369429 11123 sgd_solver.cpp:105] Iteration 76000, lr = 0.0062
I0529 01:03:31.352495 11123 solver.cpp:218] Iteration 76100 (3.57366 iter/s, 27.9825s/100 iters), loss = 0.000752466
I0529 01:03:31.352537 11123 solver.cpp:237]     Train net output #0: loss = 0.000751524 (* 1 = 0.000751524 loss)
I0529 01:03:31.352546 11123 sgd_solver.cpp:105] Iteration 76100, lr = 0.006195
I0529 01:03:59.326452 11123 solver.cpp:218] Iteration 76200 (3.57484 iter/s, 27.9733s/100 iters), loss = 0.000481661
I0529 01:03:59.326609 11123 solver.cpp:237]     Train net output #0: loss = 0.000480715 (* 1 = 0.000480715 loss)
I0529 01:03:59.326620 11123 sgd_solver.cpp:105] Iteration 76200, lr = 0.00619
I0529 01:04:27.296114 11123 solver.cpp:218] Iteration 76300 (3.5754 iter/s, 27.9689s/100 iters), loss = 0.00319372
I0529 01:04:27.296165 11123 solver.cpp:237]     Train net output #0: loss = 0.00319277 (* 1 = 0.00319277 loss)
I0529 01:04:27.296175 11123 sgd_solver.cpp:105] Iteration 76300, lr = 0.006185
I0529 01:04:55.275769 11123 solver.cpp:218] Iteration 76400 (3.57411 iter/s, 27.979s/100 iters), loss = 0.00610397
I0529 01:04:55.275948 11123 solver.cpp:237]     Train net output #0: loss = 0.00610303 (* 1 = 0.00610303 loss)
I0529 01:04:55.275959 11123 sgd_solver.cpp:105] Iteration 76400, lr = 0.00618
I0529 01:05:23.310436 11123 solver.cpp:218] Iteration 76500 (3.56711 iter/s, 28.0339s/100 iters), loss = 0.00702567
I0529 01:05:23.310497 11123 solver.cpp:237]     Train net output #0: loss = 0.00702473 (* 1 = 0.00702473 loss)
I0529 01:05:23.310506 11123 sgd_solver.cpp:105] Iteration 76500, lr = 0.006175
I0529 01:05:49.954401 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:05:51.335894 11123 solver.cpp:218] Iteration 76600 (3.56827 iter/s, 28.0248s/100 iters), loss = 0.00120544
I0529 01:05:51.335937 11123 solver.cpp:237]     Train net output #0: loss = 0.0012045 (* 1 = 0.0012045 loss)
I0529 01:05:51.335945 11123 sgd_solver.cpp:105] Iteration 76600, lr = 0.00617
I0529 01:06:19.356586 11123 solver.cpp:218] Iteration 76700 (3.56887 iter/s, 28.0201s/100 iters), loss = 0.000382332
I0529 01:06:19.356649 11123 solver.cpp:237]     Train net output #0: loss = 0.000381394 (* 1 = 0.000381394 loss)
I0529 01:06:19.356662 11123 sgd_solver.cpp:105] Iteration 76700, lr = 0.006165
I0529 01:06:47.380678 11123 solver.cpp:218] Iteration 76800 (3.56844 iter/s, 28.0234s/100 iters), loss = 1.83144e-05
I0529 01:06:47.380828 11123 solver.cpp:237]     Train net output #0: loss = 1.73857e-05 (* 1 = 1.73857e-05 loss)
I0529 01:06:47.380839 11123 sgd_solver.cpp:105] Iteration 76800, lr = 0.00616
I0529 01:07:15.418314 11123 solver.cpp:218] Iteration 76900 (3.56673 iter/s, 28.0369s/100 iters), loss = 0.00215254
I0529 01:07:15.418360 11123 solver.cpp:237]     Train net output #0: loss = 0.00215161 (* 1 = 0.00215161 loss)
I0529 01:07:15.418381 11123 sgd_solver.cpp:105] Iteration 76900, lr = 0.006155
I0529 01:07:43.143673 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_77000.caffemodel
I0529 01:07:43.475442 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_77000.solverstate
I0529 01:07:43.621779 11123 solver.cpp:330] Iteration 77000, Testing net (#0)
I0529 01:07:46.429522 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:07:48.072131 11123 solver.cpp:397]     Test net output #0: accuracy = 0.921001
I0529 01:07:48.072183 11123 solver.cpp:397]     Test net output #1: loss = 0.251629 (* 1 = 0.251629 loss)
I0529 01:07:48.350617 11123 solver.cpp:218] Iteration 77000 (3.0366 iter/s, 32.9316s/100 iters), loss = 0.0921147
I0529 01:07:48.350661 11123 solver.cpp:237]     Train net output #0: loss = 0.0921138 (* 1 = 0.0921138 loss)
I0529 01:07:48.350669 11123 sgd_solver.cpp:105] Iteration 77000, lr = 0.00615
I0529 01:08:16.330920 11123 solver.cpp:218] Iteration 77100 (3.57403 iter/s, 27.9797s/100 iters), loss = 0.00510088
I0529 01:08:16.331125 11123 solver.cpp:237]     Train net output #0: loss = 0.00509995 (* 1 = 0.00509995 loss)
I0529 01:08:16.331137 11123 sgd_solver.cpp:105] Iteration 77100, lr = 0.006145
I0529 01:08:44.298910 11123 solver.cpp:218] Iteration 77200 (3.57562 iter/s, 27.9672s/100 iters), loss = 0.00677544
I0529 01:08:44.298975 11123 solver.cpp:237]     Train net output #0: loss = 0.00677453 (* 1 = 0.00677453 loss)
I0529 01:08:44.298985 11123 sgd_solver.cpp:105] Iteration 77200, lr = 0.00614
I0529 01:08:46.558889 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:09:12.279119 11123 solver.cpp:218] Iteration 77300 (3.57404 iter/s, 27.9795s/100 iters), loss = 0.0638417
I0529 01:09:12.279170 11123 solver.cpp:237]     Train net output #0: loss = 0.0638408 (* 1 = 0.0638408 loss)
I0529 01:09:12.279180 11123 sgd_solver.cpp:105] Iteration 77300, lr = 0.006135
I0529 01:09:40.286579 11123 solver.cpp:218] Iteration 77400 (3.57056 iter/s, 28.0068s/100 iters), loss = 0.000284202
I0529 01:09:40.286748 11123 solver.cpp:237]     Train net output #0: loss = 0.000283291 (* 1 = 0.000283291 loss)
I0529 01:09:40.286759 11123 sgd_solver.cpp:105] Iteration 77400, lr = 0.00613
I0529 01:10:08.282837 11123 solver.cpp:218] Iteration 77500 (3.572 iter/s, 27.9955s/100 iters), loss = 0.0240672
I0529 01:10:08.282889 11123 solver.cpp:237]     Train net output #0: loss = 0.0240663 (* 1 = 0.0240663 loss)
I0529 01:10:08.282898 11123 sgd_solver.cpp:105] Iteration 77500, lr = 0.006125
I0529 01:10:36.240479 11123 solver.cpp:218] Iteration 77600 (3.57692 iter/s, 27.957s/100 iters), loss = 0.00312733
I0529 01:10:36.240643 11123 solver.cpp:237]     Train net output #0: loss = 0.00312643 (* 1 = 0.00312643 loss)
I0529 01:10:36.240658 11123 sgd_solver.cpp:105] Iteration 77600, lr = 0.00612
I0529 01:11:04.242216 11123 solver.cpp:218] Iteration 77700 (3.5713 iter/s, 28.001s/100 iters), loss = 0.0247213
I0529 01:11:04.242271 11123 solver.cpp:237]     Train net output #0: loss = 0.0247204 (* 1 = 0.0247204 loss)
I0529 01:11:04.242292 11123 sgd_solver.cpp:105] Iteration 77700, lr = 0.006115
I0529 01:11:32.246950 11123 solver.cpp:218] Iteration 77800 (3.57091 iter/s, 28.0041s/100 iters), loss = 0.000124516
I0529 01:11:32.247123 11123 solver.cpp:237]     Train net output #0: loss = 0.000123622 (* 1 = 0.000123622 loss)
I0529 01:11:32.247134 11123 sgd_solver.cpp:105] Iteration 77800, lr = 0.00611
I0529 01:11:38.146910 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:12:00.267156 11123 solver.cpp:218] Iteration 77900 (3.56895 iter/s, 28.0194s/100 iters), loss = 0.000678493
I0529 01:12:00.267210 11123 solver.cpp:237]     Train net output #0: loss = 0.000677607 (* 1 = 0.000677607 loss)
I0529 01:12:00.267220 11123 sgd_solver.cpp:105] Iteration 77900, lr = 0.006105
I0529 01:12:27.975467 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_78000.caffemodel
I0529 01:12:28.280431 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_78000.solverstate
I0529 01:12:28.425540 11123 solver.cpp:330] Iteration 78000, Testing net (#0)
I0529 01:12:32.740296 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:12:32.873025 11123 solver.cpp:397]     Test net output #0: accuracy = 0.904
I0529 01:12:32.873067 11123 solver.cpp:397]     Test net output #1: loss = 0.394432 (* 1 = 0.394432 loss)
I0529 01:12:33.148180 11123 solver.cpp:218] Iteration 78000 (3.04134 iter/s, 32.8803s/100 iters), loss = 0.000732054
I0529 01:12:33.148224 11123 solver.cpp:237]     Train net output #0: loss = 0.000731173 (* 1 = 0.000731173 loss)
I0529 01:12:33.148233 11123 sgd_solver.cpp:105] Iteration 78000, lr = 0.0061
I0529 01:13:01.128640 11123 solver.cpp:218] Iteration 78100 (3.57401 iter/s, 27.9798s/100 iters), loss = 0.161364
I0529 01:13:01.128870 11123 solver.cpp:237]     Train net output #0: loss = 0.161364 (* 1 = 0.161364 loss)
I0529 01:13:01.128880 11123 sgd_solver.cpp:105] Iteration 78100, lr = 0.006095
I0529 01:13:29.086851 11123 solver.cpp:218] Iteration 78200 (3.57687 iter/s, 27.9574s/100 iters), loss = 0.000610947
I0529 01:13:29.086894 11123 solver.cpp:237]     Train net output #0: loss = 0.000610089 (* 1 = 0.000610089 loss)
I0529 01:13:29.086904 11123 sgd_solver.cpp:105] Iteration 78200, lr = 0.00609
I0529 01:13:57.077622 11123 solver.cpp:218] Iteration 78300 (3.57269 iter/s, 27.9901s/100 iters), loss = 0.00164304
I0529 01:13:57.077786 11123 solver.cpp:237]     Train net output #0: loss = 0.00164217 (* 1 = 0.00164217 loss)
I0529 01:13:57.077798 11123 sgd_solver.cpp:105] Iteration 78300, lr = 0.006085
I0529 01:14:25.093252 11123 solver.cpp:218] Iteration 78400 (3.56953 iter/s, 28.0149s/100 iters), loss = 0.000102958
I0529 01:14:25.093297 11123 solver.cpp:237]     Train net output #0: loss = 0.000102086 (* 1 = 0.000102086 loss)
I0529 01:14:25.093317 11123 sgd_solver.cpp:105] Iteration 78400, lr = 0.00608
I0529 01:14:34.631109 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:14:53.107755 11123 solver.cpp:218] Iteration 78500 (3.56966 iter/s, 28.0139s/100 iters), loss = 2.60174e-05
I0529 01:14:53.107800 11123 solver.cpp:237]     Train net output #0: loss = 2.51456e-05 (* 1 = 2.51456e-05 loss)
I0529 01:14:53.107808 11123 sgd_solver.cpp:105] Iteration 78500, lr = 0.006075
I0529 01:15:21.140957 11123 solver.cpp:218] Iteration 78600 (3.56728 iter/s, 28.0326s/100 iters), loss = 0.0131809
I0529 01:15:21.141125 11123 solver.cpp:237]     Train net output #0: loss = 0.01318 (* 1 = 0.01318 loss)
I0529 01:15:21.141136 11123 sgd_solver.cpp:105] Iteration 78600, lr = 0.00607
I0529 01:15:49.145059 11123 solver.cpp:218] Iteration 78700 (3.571 iter/s, 28.0033s/100 iters), loss = 0.00188736
I0529 01:15:49.145103 11123 solver.cpp:237]     Train net output #0: loss = 0.00188648 (* 1 = 0.00188648 loss)
I0529 01:15:49.145112 11123 sgd_solver.cpp:105] Iteration 78700, lr = 0.006065
I0529 01:16:17.154628 11123 solver.cpp:218] Iteration 78800 (3.57029 iter/s, 28.0089s/100 iters), loss = 0.00305378
I0529 01:16:17.154784 11123 solver.cpp:237]     Train net output #0: loss = 0.0030529 (* 1 = 0.0030529 loss)
I0529 01:16:17.154798 11123 sgd_solver.cpp:105] Iteration 78800, lr = 0.00606
I0529 01:16:45.143549 11123 solver.cpp:218] Iteration 78900 (3.57294 iter/s, 27.9882s/100 iters), loss = 0.00441889
I0529 01:16:45.143594 11123 solver.cpp:237]     Train net output #0: loss = 0.00441801 (* 1 = 0.00441801 loss)
I0529 01:16:45.143602 11123 sgd_solver.cpp:105] Iteration 78900, lr = 0.006055
I0529 01:17:12.857791 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_79000.caffemodel
I0529 01:17:13.164008 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_79000.solverstate
I0529 01:17:13.310128 11123 solver.cpp:330] Iteration 79000, Testing net (#0)
I0529 01:17:17.760505 11123 solver.cpp:397]     Test net output #0: accuracy = 0.903
I0529 01:17:17.760547 11123 solver.cpp:397]     Test net output #1: loss = 0.361277 (* 1 = 0.361277 loss)
I0529 01:17:18.036746 11123 solver.cpp:218] Iteration 79000 (3.04021 iter/s, 32.8924s/100 iters), loss = 0.00183447
I0529 01:17:18.036789 11123 solver.cpp:237]     Train net output #0: loss = 0.00183361 (* 1 = 0.00183361 loss)
I0529 01:17:18.036798 11123 sgd_solver.cpp:105] Iteration 79000, lr = 0.00605
I0529 01:17:31.219564 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:17:46.054024 11123 solver.cpp:218] Iteration 79100 (3.56931 iter/s, 28.0166s/100 iters), loss = 0.000361699
I0529 01:17:46.054219 11123 solver.cpp:237]     Train net output #0: loss = 0.000360815 (* 1 = 0.000360815 loss)
I0529 01:17:46.054229 11123 sgd_solver.cpp:105] Iteration 79100, lr = 0.006045
I0529 01:18:14.079852 11123 solver.cpp:218] Iteration 79200 (3.56824 iter/s, 28.025s/100 iters), loss = 0.0027317
I0529 01:18:14.079900 11123 solver.cpp:237]     Train net output #0: loss = 0.00273082 (* 1 = 0.00273082 loss)
I0529 01:18:14.079910 11123 sgd_solver.cpp:105] Iteration 79200, lr = 0.00604
I0529 01:18:42.075995 11123 solver.cpp:218] Iteration 79300 (3.572 iter/s, 27.9955s/100 iters), loss = 0.0021187
I0529 01:18:42.076287 11123 solver.cpp:237]     Train net output #0: loss = 0.0021178 (* 1 = 0.0021178 loss)
I0529 01:18:42.076298 11123 sgd_solver.cpp:105] Iteration 79300, lr = 0.006035
I0529 01:19:10.051292 11123 solver.cpp:218] Iteration 79400 (3.5747 iter/s, 27.9744s/100 iters), loss = 0.0204072
I0529 01:19:10.051337 11123 solver.cpp:237]     Train net output #0: loss = 0.0204063 (* 1 = 0.0204063 loss)
I0529 01:19:10.051345 11123 sgd_solver.cpp:105] Iteration 79400, lr = 0.00603
I0529 01:19:38.021765 11123 solver.cpp:218] Iteration 79500 (3.57528 iter/s, 27.9698s/100 iters), loss = 0.00224625
I0529 01:19:38.021975 11123 solver.cpp:237]     Train net output #0: loss = 0.00224535 (* 1 = 0.00224535 loss)
I0529 01:19:38.021986 11123 sgd_solver.cpp:105] Iteration 79500, lr = 0.006025
I0529 01:20:06.014884 11123 solver.cpp:218] Iteration 79600 (3.57241 iter/s, 27.9923s/100 iters), loss = 0.000119642
I0529 01:20:06.014941 11123 solver.cpp:237]     Train net output #0: loss = 0.000118749 (* 1 = 0.000118749 loss)
I0529 01:20:06.014951 11123 sgd_solver.cpp:105] Iteration 79600, lr = 0.00602
I0529 01:20:22.541388 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:20:34.003752 11123 solver.cpp:218] Iteration 79700 (3.57293 iter/s, 27.9882s/100 iters), loss = 0.000818761
I0529 01:20:34.003813 11123 solver.cpp:237]     Train net output #0: loss = 0.000817878 (* 1 = 0.000817878 loss)
I0529 01:20:34.003824 11123 sgd_solver.cpp:105] Iteration 79700, lr = 0.006015
I0529 01:21:02.011358 11123 solver.cpp:218] Iteration 79800 (3.57054 iter/s, 28.0069s/100 iters), loss = 1.70865e-05
I0529 01:21:02.011539 11123 solver.cpp:237]     Train net output #0: loss = 1.6211e-05 (* 1 = 1.6211e-05 loss)
I0529 01:21:02.011564 11123 sgd_solver.cpp:105] Iteration 79800, lr = 0.00601
I0529 01:21:30.033063 11123 solver.cpp:218] Iteration 79900 (3.56876 iter/s, 28.0209s/100 iters), loss = 0.000966761
I0529 01:21:30.033113 11123 solver.cpp:237]     Train net output #0: loss = 0.000965902 (* 1 = 0.000965902 loss)
I0529 01:21:30.033123 11123 sgd_solver.cpp:105] Iteration 79900, lr = 0.006005
I0529 01:21:57.762648 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_80000.caffemodel
I0529 01:21:58.068615 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_80000.solverstate
I0529 01:21:58.214395 11123 solver.cpp:330] Iteration 80000, Testing net (#0)
I0529 01:21:59.556777 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:22:02.669831 11123 solver.cpp:397]     Test net output #0: accuracy = 0.928
I0529 01:22:02.669872 11123 solver.cpp:397]     Test net output #1: loss = 0.261461 (* 1 = 0.261461 loss)
I0529 01:22:02.946617 11123 solver.cpp:218] Iteration 80000 (3.03833 iter/s, 32.9128s/100 iters), loss = 0.131875
I0529 01:22:02.946663 11123 solver.cpp:237]     Train net output #0: loss = 0.131874 (* 1 = 0.131874 loss)
I0529 01:22:02.946673 11123 sgd_solver.cpp:105] Iteration 80000, lr = 0.006
I0529 01:22:30.910244 11123 solver.cpp:218] Iteration 80100 (3.57616 iter/s, 27.963s/100 iters), loss = 0.00571774
I0529 01:22:30.910403 11123 solver.cpp:237]     Train net output #0: loss = 0.00571686 (* 1 = 0.00571686 loss)
I0529 01:22:30.910420 11123 sgd_solver.cpp:105] Iteration 80100, lr = 0.005995
I0529 01:22:58.855463 11123 solver.cpp:218] Iteration 80200 (3.57853 iter/s, 27.9445s/100 iters), loss = 0.00857876
I0529 01:22:58.855506 11123 solver.cpp:237]     Train net output #0: loss = 0.00857782 (* 1 = 0.00857782 loss)
I0529 01:22:58.855515 11123 sgd_solver.cpp:105] Iteration 80200, lr = 0.00599
I0529 01:23:19.040623 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:23:26.872938 11123 solver.cpp:218] Iteration 80300 (3.56929 iter/s, 28.0168s/100 iters), loss = 0.00661465
I0529 01:23:26.872983 11123 solver.cpp:237]     Train net output #0: loss = 0.00661366 (* 1 = 0.00661366 loss)
I0529 01:23:26.872992 11123 sgd_solver.cpp:105] Iteration 80300, lr = 0.005985
I0529 01:23:54.878319 11123 solver.cpp:218] Iteration 80400 (3.57083 iter/s, 28.0047s/100 iters), loss = 0.00103281
I0529 01:23:54.879412 11123 solver.cpp:237]     Train net output #0: loss = 0.00103184 (* 1 = 0.00103184 loss)
I0529 01:23:54.879425 11123 sgd_solver.cpp:105] Iteration 80400, lr = 0.00598
I0529 01:24:22.897507 11123 solver.cpp:218] Iteration 80500 (3.5692 iter/s, 28.0175s/100 iters), loss = 0.000770275
I0529 01:24:22.897554 11123 solver.cpp:237]     Train net output #0: loss = 0.000769307 (* 1 = 0.000769307 loss)
I0529 01:24:22.897562 11123 sgd_solver.cpp:105] Iteration 80500, lr = 0.005975
I0529 01:24:50.878238 11123 solver.cpp:218] Iteration 80600 (3.57397 iter/s, 27.9801s/100 iters), loss = 0.022244
I0529 01:24:50.878443 11123 solver.cpp:237]     Train net output #0: loss = 0.022243 (* 1 = 0.022243 loss)
I0529 01:24:50.878471 11123 sgd_solver.cpp:105] Iteration 80600, lr = 0.00597
I0529 01:25:18.880280 11123 solver.cpp:218] Iteration 80700 (3.57127 iter/s, 28.0012s/100 iters), loss = 0.00242098
I0529 01:25:18.880333 11123 solver.cpp:237]     Train net output #0: loss = 0.00242002 (* 1 = 0.00242002 loss)
I0529 01:25:18.880343 11123 sgd_solver.cpp:105] Iteration 80700, lr = 0.005965
I0529 01:25:46.874724 11123 solver.cpp:218] Iteration 80800 (3.57222 iter/s, 27.9938s/100 iters), loss = 0.0001314
I0529 01:25:46.874886 11123 solver.cpp:237]     Train net output #0: loss = 0.000130449 (* 1 = 0.000130449 loss)
I0529 01:25:46.874897 11123 sgd_solver.cpp:105] Iteration 80800, lr = 0.00596
I0529 01:26:10.689301 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:26:14.878844 11123 solver.cpp:218] Iteration 80900 (3.571 iter/s, 28.0034s/100 iters), loss = 0.00253926
I0529 01:26:14.878885 11123 solver.cpp:237]     Train net output #0: loss = 0.0025383 (* 1 = 0.0025383 loss)
I0529 01:26:14.878895 11123 sgd_solver.cpp:105] Iteration 80900, lr = 0.005955
I0529 01:26:42.611461 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_81000.caffemodel
I0529 01:26:42.918318 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_81000.solverstate
I0529 01:26:43.067170 11123 solver.cpp:330] Iteration 81000, Testing net (#0)
I0529 01:26:45.916625 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:26:47.510627 11123 solver.cpp:397]     Test net output #0: accuracy = 0.918
I0529 01:26:47.510664 11123 solver.cpp:397]     Test net output #1: loss = 0.286883 (* 1 = 0.286883 loss)
I0529 01:26:47.786679 11123 solver.cpp:218] Iteration 81000 (3.03886 iter/s, 32.9071s/100 iters), loss = 0.000299774
I0529 01:26:47.786728 11123 solver.cpp:237]     Train net output #0: loss = 0.000298804 (* 1 = 0.000298804 loss)
I0529 01:26:47.786736 11123 sgd_solver.cpp:105] Iteration 81000, lr = 0.00595
I0529 01:27:15.818646 11123 solver.cpp:218] Iteration 81100 (3.56744 iter/s, 28.0313s/100 iters), loss = 0.0020022
I0529 01:27:15.818802 11123 solver.cpp:237]     Train net output #0: loss = 0.00200125 (* 1 = 0.00200125 loss)
I0529 01:27:15.818814 11123 sgd_solver.cpp:105] Iteration 81100, lr = 0.005945
I0529 01:27:43.835397 11123 solver.cpp:218] Iteration 81200 (3.56939 iter/s, 28.016s/100 iters), loss = 0.000149209
I0529 01:27:43.835441 11123 solver.cpp:237]     Train net output #0: loss = 0.000148277 (* 1 = 0.000148277 loss)
I0529 01:27:43.835449 11123 sgd_solver.cpp:105] Iteration 81200, lr = 0.00594
I0529 01:28:11.817724 11123 solver.cpp:218] Iteration 81300 (3.57377 iter/s, 27.9817s/100 iters), loss = 0.0286779
I0529 01:28:11.817881 11123 solver.cpp:237]     Train net output #0: loss = 0.0286769 (* 1 = 0.0286769 loss)
I0529 01:28:11.817893 11123 sgd_solver.cpp:105] Iteration 81300, lr = 0.005935
I0529 01:28:39.822279 11123 solver.cpp:218] Iteration 81400 (3.57094 iter/s, 28.0038s/100 iters), loss = 4.18353e-05
I0529 01:28:39.822327 11123 solver.cpp:237]     Train net output #0: loss = 4.08737e-05 (* 1 = 4.08737e-05 loss)
I0529 01:28:39.822335 11123 sgd_solver.cpp:105] Iteration 81400, lr = 0.00593
I0529 01:29:07.294929 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:29:07.841017 11123 solver.cpp:218] Iteration 81500 (3.56912 iter/s, 28.0181s/100 iters), loss = 7.68562e-06
I0529 01:29:07.841068 11123 solver.cpp:237]     Train net output #0: loss = 6.72355e-06 (* 1 = 6.72355e-06 loss)
I0529 01:29:07.841076 11123 sgd_solver.cpp:105] Iteration 81500, lr = 0.005925
I0529 01:29:35.851516 11123 solver.cpp:218] Iteration 81600 (3.57017 iter/s, 28.0098s/100 iters), loss = 7.6175e-05
I0529 01:29:35.851559 11123 solver.cpp:237]     Train net output #0: loss = 7.52096e-05 (* 1 = 7.52096e-05 loss)
I0529 01:29:35.851568 11123 sgd_solver.cpp:105] Iteration 81600, lr = 0.00592
I0529 01:30:03.888990 11123 solver.cpp:218] Iteration 81700 (3.56674 iter/s, 28.0368s/100 iters), loss = 0.000201026
I0529 01:30:03.889163 11123 solver.cpp:237]     Train net output #0: loss = 0.000200066 (* 1 = 0.000200066 loss)
I0529 01:30:03.889174 11123 sgd_solver.cpp:105] Iteration 81700, lr = 0.005915
I0529 01:30:31.886633 11123 solver.cpp:218] Iteration 81800 (3.57183 iter/s, 27.9969s/100 iters), loss = 0.00588542
I0529 01:30:31.886687 11123 solver.cpp:237]     Train net output #0: loss = 0.00588445 (* 1 = 0.00588445 loss)
I0529 01:30:31.886698 11123 sgd_solver.cpp:105] Iteration 81800, lr = 0.00591
I0529 01:30:59.830343 11123 solver.cpp:218] Iteration 81900 (3.57871 iter/s, 27.9431s/100 iters), loss = 0.00429593
I0529 01:30:59.830515 11123 solver.cpp:237]     Train net output #0: loss = 0.00429496 (* 1 = 0.00429496 loss)
I0529 01:30:59.830533 11123 sgd_solver.cpp:105] Iteration 81900, lr = 0.005905
I0529 01:31:27.533987 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_82000.caffemodel
I0529 01:31:27.840878 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_82000.solverstate
I0529 01:31:27.987195 11123 solver.cpp:330] Iteration 82000, Testing net (#0)
I0529 01:31:32.352934 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:31:32.438623 11123 solver.cpp:397]     Test net output #0: accuracy = 0.924
I0529 01:31:32.438664 11123 solver.cpp:397]     Test net output #1: loss = 0.286989 (* 1 = 0.286989 loss)
I0529 01:31:32.715585 11123 solver.cpp:218] Iteration 82000 (3.04096 iter/s, 32.8844s/100 iters), loss = 0.000923211
I0529 01:31:32.715634 11123 solver.cpp:237]     Train net output #0: loss = 0.000922238 (* 1 = 0.000922238 loss)
I0529 01:31:32.715643 11123 sgd_solver.cpp:105] Iteration 82000, lr = 0.0059
I0529 01:32:00.717730 11123 solver.cpp:218] Iteration 82100 (3.57124 iter/s, 28.0015s/100 iters), loss = 0.0108682
I0529 01:32:00.717794 11123 solver.cpp:237]     Train net output #0: loss = 0.0108672 (* 1 = 0.0108672 loss)
I0529 01:32:00.717804 11123 sgd_solver.cpp:105] Iteration 82100, lr = 0.005895
I0529 01:32:03.815985 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:32:28.726491 11123 solver.cpp:218] Iteration 82200 (3.5704 iter/s, 28.0081s/100 iters), loss = 0.000364526
I0529 01:32:28.726539 11123 solver.cpp:237]     Train net output #0: loss = 0.000363526 (* 1 = 0.000363526 loss)
I0529 01:32:28.726548 11123 sgd_solver.cpp:105] Iteration 82200, lr = 0.00589
I0529 01:32:56.706501 11123 solver.cpp:218] Iteration 82300 (3.57407 iter/s, 27.9793s/100 iters), loss = 0.00215386
I0529 01:32:56.706715 11123 solver.cpp:237]     Train net output #0: loss = 0.00215286 (* 1 = 0.00215286 loss)
I0529 01:32:56.706728 11123 sgd_solver.cpp:105] Iteration 82300, lr = 0.005885
I0529 01:33:24.737459 11123 solver.cpp:218] Iteration 82400 (3.56759 iter/s, 28.0302s/100 iters), loss = 0.00373734
I0529 01:33:24.737509 11123 solver.cpp:237]     Train net output #0: loss = 0.00373636 (* 1 = 0.00373636 loss)
I0529 01:33:24.737517 11123 sgd_solver.cpp:105] Iteration 82400, lr = 0.00588
I0529 01:33:52.725888 11123 solver.cpp:218] Iteration 82500 (3.57299 iter/s, 27.9878s/100 iters), loss = 0.00141368
I0529 01:33:52.726084 11123 solver.cpp:237]     Train net output #0: loss = 0.0014127 (* 1 = 0.0014127 loss)
I0529 01:33:52.726100 11123 sgd_solver.cpp:105] Iteration 82500, lr = 0.005875
I0529 01:34:20.738842 11123 solver.cpp:218] Iteration 82600 (3.56988 iter/s, 28.0122s/100 iters), loss = 0.000522329
I0529 01:34:20.738888 11123 solver.cpp:237]     Train net output #0: loss = 0.000521344 (* 1 = 0.000521344 loss)
I0529 01:34:20.738896 11123 sgd_solver.cpp:105] Iteration 82600, lr = 0.00587
I0529 01:34:48.737174 11123 solver.cpp:218] Iteration 82700 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.00149023
I0529 01:34:48.737325 11123 solver.cpp:237]     Train net output #0: loss = 0.00148924 (* 1 = 0.00148924 loss)
I0529 01:34:48.737337 11123 sgd_solver.cpp:105] Iteration 82700, lr = 0.005865
I0529 01:34:55.205205 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:35:16.764014 11123 solver.cpp:218] Iteration 82800 (3.5681 iter/s, 28.0261s/100 iters), loss = 0.00940149
I0529 01:35:16.764060 11123 solver.cpp:237]     Train net output #0: loss = 0.00940052 (* 1 = 0.00940052 loss)
I0529 01:35:16.764070 11123 sgd_solver.cpp:105] Iteration 82800, lr = 0.00586
I0529 01:35:44.780858 11123 solver.cpp:218] Iteration 82900 (3.56936 iter/s, 28.0162s/100 iters), loss = 0.000750534
I0529 01:35:44.780987 11123 solver.cpp:237]     Train net output #0: loss = 0.000749547 (* 1 = 0.000749547 loss)
I0529 01:35:44.781008 11123 sgd_solver.cpp:105] Iteration 82900, lr = 0.005855
I0529 01:36:12.517398 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_83000.caffemodel
I0529 01:36:12.825613 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_83000.solverstate
I0529 01:36:12.971257 11123 solver.cpp:330] Iteration 83000, Testing net (#0)
I0529 01:36:17.419419 11123 solver.cpp:397]     Test net output #0: accuracy = 0.932
I0529 01:36:17.419579 11123 solver.cpp:397]     Test net output #1: loss = 0.268301 (* 1 = 0.268301 loss)
I0529 01:36:17.697185 11123 solver.cpp:218] Iteration 83000 (3.03808 iter/s, 32.9155s/100 iters), loss = 6.77808e-05
I0529 01:36:17.697230 11123 solver.cpp:237]     Train net output #0: loss = 6.68458e-05 (* 1 = 6.68458e-05 loss)
I0529 01:36:17.697239 11123 sgd_solver.cpp:105] Iteration 83000, lr = 0.00585
I0529 01:36:45.702262 11123 solver.cpp:218] Iteration 83100 (3.57086 iter/s, 28.0044s/100 iters), loss = 1.68038e-05
I0529 01:36:45.702311 11123 solver.cpp:237]     Train net output #0: loss = 1.58674e-05 (* 1 = 1.58674e-05 loss)
I0529 01:36:45.702318 11123 sgd_solver.cpp:105] Iteration 83100, lr = 0.005845
I0529 01:37:13.691787 11123 solver.cpp:218] Iteration 83200 (3.57285 iter/s, 27.9889s/100 iters), loss = 2.03987e-05
I0529 01:37:13.691941 11123 solver.cpp:237]     Train net output #0: loss = 1.94559e-05 (* 1 = 1.94559e-05 loss)
I0529 01:37:13.691952 11123 sgd_solver.cpp:105] Iteration 83200, lr = 0.00584
I0529 01:37:41.678277 11123 solver.cpp:218] Iteration 83300 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.00109649
I0529 01:37:41.678328 11123 solver.cpp:237]     Train net output #0: loss = 0.00109553 (* 1 = 0.00109553 loss)
I0529 01:37:41.678338 11123 sgd_solver.cpp:105] Iteration 83300, lr = 0.005835
I0529 01:37:51.768307 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:38:09.673991 11123 solver.cpp:218] Iteration 83400 (3.57206 iter/s, 27.9951s/100 iters), loss = 0.000132781
I0529 01:38:09.674047 11123 solver.cpp:237]     Train net output #0: loss = 0.000131794 (* 1 = 0.000131794 loss)
I0529 01:38:09.674057 11123 sgd_solver.cpp:105] Iteration 83400, lr = 0.00583
I0529 01:38:37.677453 11123 solver.cpp:218] Iteration 83500 (3.57107 iter/s, 28.0028s/100 iters), loss = 0.000579118
I0529 01:38:37.677647 11123 solver.cpp:237]     Train net output #0: loss = 0.000578135 (* 1 = 0.000578135 loss)
I0529 01:38:37.677659 11123 sgd_solver.cpp:105] Iteration 83500, lr = 0.005825
I0529 01:39:05.681510 11123 solver.cpp:218] Iteration 83600 (3.57101 iter/s, 28.0033s/100 iters), loss = 0.0173326
I0529 01:39:05.681555 11123 solver.cpp:237]     Train net output #0: loss = 0.0173316 (* 1 = 0.0173316 loss)
I0529 01:39:05.681565 11123 sgd_solver.cpp:105] Iteration 83600, lr = 0.00582
I0529 01:39:33.672468 11123 solver.cpp:218] Iteration 83700 (3.57267 iter/s, 27.9903s/100 iters), loss = 0.115828
I0529 01:39:33.672624 11123 solver.cpp:237]     Train net output #0: loss = 0.115827 (* 1 = 0.115827 loss)
I0529 01:39:33.672634 11123 sgd_solver.cpp:105] Iteration 83700, lr = 0.005815
I0529 01:40:01.650827 11123 solver.cpp:218] Iteration 83800 (3.57429 iter/s, 27.9776s/100 iters), loss = 0.00369122
I0529 01:40:01.650889 11123 solver.cpp:237]     Train net output #0: loss = 0.00369019 (* 1 = 0.00369019 loss)
I0529 01:40:01.650898 11123 sgd_solver.cpp:105] Iteration 83800, lr = 0.00581
I0529 01:40:29.661906 11123 solver.cpp:218] Iteration 83900 (3.5701 iter/s, 28.0104s/100 iters), loss = 0.000988306
I0529 01:40:29.662353 11123 solver.cpp:237]     Train net output #0: loss = 0.000987273 (* 1 = 0.000987273 loss)
I0529 01:40:29.662369 11123 sgd_solver.cpp:105] Iteration 83900, lr = 0.005805
I0529 01:40:43.406766 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:40:57.409044 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_84000.caffemodel
I0529 01:40:57.714906 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_84000.solverstate
I0529 01:40:57.861150 11123 solver.cpp:330] Iteration 84000, Testing net (#0)
I0529 01:40:59.291980 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:41:02.318514 11123 solver.cpp:397]     Test net output #0: accuracy = 0.926
I0529 01:41:02.318672 11123 solver.cpp:397]     Test net output #1: loss = 0.303877 (* 1 = 0.303877 loss)
I0529 01:41:02.596343 11123 solver.cpp:218] Iteration 84000 (3.03644 iter/s, 32.9333s/100 iters), loss = 0.0134123
I0529 01:41:02.596391 11123 solver.cpp:237]     Train net output #0: loss = 0.0134113 (* 1 = 0.0134113 loss)
I0529 01:41:02.596400 11123 sgd_solver.cpp:105] Iteration 84000, lr = 0.0058
I0529 01:41:30.590986 11123 solver.cpp:218] Iteration 84100 (3.5722 iter/s, 27.994s/100 iters), loss = 0.0703255
I0529 01:41:30.591030 11123 solver.cpp:237]     Train net output #0: loss = 0.0703245 (* 1 = 0.0703245 loss)
I0529 01:41:30.591039 11123 sgd_solver.cpp:105] Iteration 84100, lr = 0.005795
I0529 01:41:58.547777 11123 solver.cpp:218] Iteration 84200 (3.57703 iter/s, 27.9561s/100 iters), loss = 0.00101384
I0529 01:41:58.547948 11123 solver.cpp:237]     Train net output #0: loss = 0.00101282 (* 1 = 0.00101282 loss)
I0529 01:41:58.547960 11123 sgd_solver.cpp:105] Iteration 84200, lr = 0.00579
I0529 01:42:26.514169 11123 solver.cpp:218] Iteration 84300 (3.57582 iter/s, 27.9656s/100 iters), loss = 0.037018
I0529 01:42:26.514223 11123 solver.cpp:237]     Train net output #0: loss = 0.037017 (* 1 = 0.037017 loss)
I0529 01:42:26.514232 11123 sgd_solver.cpp:105] Iteration 84300, lr = 0.005785
I0529 01:42:54.472929 11123 solver.cpp:218] Iteration 84400 (3.57678 iter/s, 27.9581s/100 iters), loss = 0.00111447
I0529 01:42:54.473157 11123 solver.cpp:237]     Train net output #0: loss = 0.00111345 (* 1 = 0.00111345 loss)
I0529 01:42:54.473168 11123 sgd_solver.cpp:105] Iteration 84400, lr = 0.00578
I0529 01:43:22.470289 11123 solver.cpp:218] Iteration 84500 (3.57187 iter/s, 27.9965s/100 iters), loss = 0.0015517
I0529 01:43:22.470335 11123 solver.cpp:237]     Train net output #0: loss = 0.00155069 (* 1 = 0.00155069 loss)
I0529 01:43:22.470342 11123 sgd_solver.cpp:105] Iteration 84500, lr = 0.005775
I0529 01:43:39.850039 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:43:50.467212 11123 solver.cpp:218] Iteration 84600 (3.5719 iter/s, 27.9963s/100 iters), loss = 0.107611
I0529 01:43:50.467264 11123 solver.cpp:237]     Train net output #0: loss = 0.10761 (* 1 = 0.10761 loss)
I0529 01:43:50.467273 11123 sgd_solver.cpp:105] Iteration 84600, lr = 0.00577
I0529 01:44:18.476622 11123 solver.cpp:218] Iteration 84700 (3.57031 iter/s, 28.0088s/100 iters), loss = 0.000710372
I0529 01:44:18.476840 11123 solver.cpp:237]     Train net output #0: loss = 0.000709358 (* 1 = 0.000709358 loss)
I0529 01:44:18.476862 11123 sgd_solver.cpp:105] Iteration 84700, lr = 0.005765
I0529 01:44:46.477082 11123 solver.cpp:218] Iteration 84800 (3.57147 iter/s, 27.9996s/100 iters), loss = 0.00148091
I0529 01:44:46.477125 11123 solver.cpp:237]     Train net output #0: loss = 0.00147988 (* 1 = 0.00147988 loss)
I0529 01:44:46.477134 11123 sgd_solver.cpp:105] Iteration 84800, lr = 0.00576
I0529 01:45:14.456221 11123 solver.cpp:218] Iteration 84900 (3.57417 iter/s, 27.9785s/100 iters), loss = 2.49632e-05
I0529 01:45:14.456384 11123 solver.cpp:237]     Train net output #0: loss = 2.39149e-05 (* 1 = 2.39149e-05 loss)
I0529 01:45:14.456395 11123 sgd_solver.cpp:105] Iteration 84900, lr = 0.005755
I0529 01:45:42.192023 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_85000.caffemodel
I0529 01:45:42.665643 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_85000.solverstate
I0529 01:45:42.812016 11123 solver.cpp:330] Iteration 85000, Testing net (#0)
I0529 01:45:45.749095 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:45:47.258427 11123 solver.cpp:397]     Test net output #0: accuracy = 0.926
I0529 01:45:47.258476 11123 solver.cpp:397]     Test net output #1: loss = 0.279606 (* 1 = 0.279606 loss)
I0529 01:45:47.535624 11123 solver.cpp:218] Iteration 85000 (3.02311 iter/s, 33.0785s/100 iters), loss = 0.000476119
I0529 01:45:47.535681 11123 solver.cpp:237]     Train net output #0: loss = 0.000475074 (* 1 = 0.000475074 loss)
I0529 01:45:47.535689 11123 sgd_solver.cpp:105] Iteration 85000, lr = 0.00575
I0529 01:46:15.544620 11123 solver.cpp:218] Iteration 85100 (3.57037 iter/s, 28.0083s/100 iters), loss = 0.000284857
I0529 01:46:15.544672 11123 solver.cpp:237]     Train net output #0: loss = 0.000283793 (* 1 = 0.000283793 loss)
I0529 01:46:15.544682 11123 sgd_solver.cpp:105] Iteration 85100, lr = 0.005745
I0529 01:46:36.552397 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:46:43.530988 11123 solver.cpp:218] Iteration 85200 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.00107929
I0529 01:46:43.531056 11123 solver.cpp:237]     Train net output #0: loss = 0.00107825 (* 1 = 0.00107825 loss)
I0529 01:46:43.531065 11123 sgd_solver.cpp:105] Iteration 85200, lr = 0.00574
I0529 01:47:11.530843 11123 solver.cpp:218] Iteration 85300 (3.57153 iter/s, 27.9992s/100 iters), loss = 0.00389143
I0529 01:47:11.531016 11123 solver.cpp:237]     Train net output #0: loss = 0.0038904 (* 1 = 0.0038904 loss)
I0529 01:47:11.531028 11123 sgd_solver.cpp:105] Iteration 85300, lr = 0.005735
I0529 01:47:39.548144 11123 solver.cpp:218] Iteration 85400 (3.56932 iter/s, 28.0165s/100 iters), loss = 0.0224702
I0529 01:47:39.548197 11123 solver.cpp:237]     Train net output #0: loss = 0.0224692 (* 1 = 0.0224692 loss)
I0529 01:47:39.548207 11123 sgd_solver.cpp:105] Iteration 85400, lr = 0.00573
I0529 01:48:07.532990 11123 solver.cpp:218] Iteration 85500 (3.57345 iter/s, 27.9842s/100 iters), loss = 0.00278938
I0529 01:48:07.533238 11123 solver.cpp:237]     Train net output #0: loss = 0.00278836 (* 1 = 0.00278836 loss)
I0529 01:48:07.533251 11123 sgd_solver.cpp:105] Iteration 85500, lr = 0.005725
I0529 01:48:35.496356 11123 solver.cpp:218] Iteration 85600 (3.57622 iter/s, 27.9625s/100 iters), loss = 0.00143755
I0529 01:48:35.496402 11123 solver.cpp:237]     Train net output #0: loss = 0.00143652 (* 1 = 0.00143652 loss)
I0529 01:48:35.496409 11123 sgd_solver.cpp:105] Iteration 85600, lr = 0.00572
I0529 01:49:03.451025 11123 solver.cpp:218] Iteration 85700 (3.5773 iter/s, 27.954s/100 iters), loss = 0.00255803
I0529 01:49:03.451186 11123 solver.cpp:237]     Train net output #0: loss = 0.00255699 (* 1 = 0.00255699 loss)
I0529 01:49:03.451197 11123 sgd_solver.cpp:105] Iteration 85700, lr = 0.005715
I0529 01:49:27.811043 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:49:31.434445 11123 solver.cpp:218] Iteration 85800 (3.57364 iter/s, 27.9827s/100 iters), loss = 0.0304512
I0529 01:49:31.434489 11123 solver.cpp:237]     Train net output #0: loss = 0.0304502 (* 1 = 0.0304502 loss)
I0529 01:49:31.434497 11123 sgd_solver.cpp:105] Iteration 85800, lr = 0.00571
I0529 01:49:59.416924 11123 solver.cpp:218] Iteration 85900 (3.57375 iter/s, 27.9818s/100 iters), loss = 0.000177512
I0529 01:49:59.417171 11123 solver.cpp:237]     Train net output #0: loss = 0.000176478 (* 1 = 0.000176478 loss)
I0529 01:49:59.417183 11123 sgd_solver.cpp:105] Iteration 85900, lr = 0.005705
I0529 01:50:27.170557 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_86000.caffemodel
I0529 01:50:27.791311 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_86000.solverstate
I0529 01:50:27.937408 11123 solver.cpp:330] Iteration 86000, Testing net (#0)
I0529 01:50:32.387231 11123 solver.cpp:397]     Test net output #0: accuracy = 0.913
I0529 01:50:32.387339 11123 solver.cpp:397]     Test net output #1: loss = 0.383817 (* 1 = 0.383817 loss)
I0529 01:50:32.665304 11123 solver.cpp:218] Iteration 86000 (3.00775 iter/s, 33.2474s/100 iters), loss = 2.07247e-05
I0529 01:50:32.665361 11123 solver.cpp:237]     Train net output #0: loss = 1.96747e-05 (* 1 = 1.96747e-05 loss)
I0529 01:50:32.665370 11123 sgd_solver.cpp:105] Iteration 86000, lr = 0.0057
I0529 01:51:00.675262 11123 solver.cpp:218] Iteration 86100 (3.57024 iter/s, 28.0093s/100 iters), loss = 0.0003291
I0529 01:51:00.675313 11123 solver.cpp:237]     Train net output #0: loss = 0.000328047 (* 1 = 0.000328047 loss)
I0529 01:51:00.675323 11123 sgd_solver.cpp:105] Iteration 86100, lr = 0.005695
I0529 01:51:28.708858 11123 solver.cpp:218] Iteration 86200 (3.56723 iter/s, 28.0329s/100 iters), loss = 0.00723258
I0529 01:51:28.708995 11123 solver.cpp:237]     Train net output #0: loss = 0.00723153 (* 1 = 0.00723153 loss)
I0529 01:51:28.709007 11123 sgd_solver.cpp:105] Iteration 86200, lr = 0.00569
I0529 01:51:56.716717 11123 solver.cpp:218] Iteration 86300 (3.57052 iter/s, 28.0071s/100 iters), loss = 0.0296847
I0529 01:51:56.716773 11123 solver.cpp:237]     Train net output #0: loss = 0.0296837 (* 1 = 0.0296837 loss)
I0529 01:51:56.716783 11123 sgd_solver.cpp:105] Iteration 86300, lr = 0.005685
I0529 01:52:24.721485 11123 solver.cpp:218] Iteration 86400 (3.57091 iter/s, 28.0041s/100 iters), loss = 0.000536691
I0529 01:52:24.721667 11123 solver.cpp:237]     Train net output #0: loss = 0.000535661 (* 1 = 0.000535661 loss)
I0529 01:52:24.721678 11123 sgd_solver.cpp:105] Iteration 86400, lr = 0.00568
I0529 01:52:24.740952 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:52:52.714267 11123 solver.cpp:218] Iteration 86500 (3.57245 iter/s, 27.992s/100 iters), loss = 0.000207671
I0529 01:52:52.714325 11123 solver.cpp:237]     Train net output #0: loss = 0.000206638 (* 1 = 0.000206638 loss)
I0529 01:52:52.714334 11123 sgd_solver.cpp:105] Iteration 86500, lr = 0.005675
I0529 01:53:20.727123 11123 solver.cpp:218] Iteration 86600 (3.56987 iter/s, 28.0122s/100 iters), loss = 0.000143693
I0529 01:53:20.727288 11123 solver.cpp:237]     Train net output #0: loss = 0.000142658 (* 1 = 0.000142658 loss)
I0529 01:53:20.727300 11123 sgd_solver.cpp:105] Iteration 86600, lr = 0.00567
I0529 01:53:48.731812 11123 solver.cpp:218] Iteration 86700 (3.57092 iter/s, 28.004s/100 iters), loss = 5.65947e-06
I0529 01:53:48.731859 11123 solver.cpp:237]     Train net output #0: loss = 4.62549e-06 (* 1 = 4.62549e-06 loss)
I0529 01:53:48.731868 11123 sgd_solver.cpp:105] Iteration 86700, lr = 0.005665
I0529 01:54:16.759099 11123 solver.cpp:218] Iteration 86800 (3.56802 iter/s, 28.0267s/100 iters), loss = 5.42286e-05
I0529 01:54:16.759331 11123 solver.cpp:237]     Train net output #0: loss = 5.32047e-05 (* 1 = 5.32047e-05 loss)
I0529 01:54:16.759342 11123 sgd_solver.cpp:105] Iteration 86800, lr = 0.00566
I0529 01:54:44.783891 11123 solver.cpp:218] Iteration 86900 (3.56837 iter/s, 28.024s/100 iters), loss = 1.56613e-05
I0529 01:54:44.783946 11123 solver.cpp:237]     Train net output #0: loss = 1.46254e-05 (* 1 = 1.46254e-05 loss)
I0529 01:54:44.783954 11123 sgd_solver.cpp:105] Iteration 86900, lr = 0.005655
I0529 01:55:12.518451 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_87000.caffemodel
I0529 01:55:13.058430 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_87000.solverstate
I0529 01:55:13.205090 11123 solver.cpp:330] Iteration 87000, Testing net (#0)
I0529 01:55:13.210007 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:55:17.652242 11123 solver.cpp:397]     Test net output #0: accuracy = 0.932
I0529 01:55:17.652276 11123 solver.cpp:397]     Test net output #1: loss = 0.315737 (* 1 = 0.315737 loss)
I0529 01:55:17.928942 11123 solver.cpp:218] Iteration 87000 (3.0171 iter/s, 33.1444s/100 iters), loss = 0.0148091
I0529 01:55:17.928997 11123 solver.cpp:237]     Train net output #0: loss = 0.0148081 (* 1 = 0.0148081 loss)
I0529 01:55:17.929006 11123 sgd_solver.cpp:105] Iteration 87000, lr = 0.00565
I0529 01:55:21.593109 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:55:45.967376 11123 solver.cpp:218] Iteration 87100 (3.56661 iter/s, 28.0378s/100 iters), loss = 0.000284542
I0529 01:55:45.967540 11123 solver.cpp:237]     Train net output #0: loss = 0.00028352 (* 1 = 0.00028352 loss)
I0529 01:55:45.967552 11123 sgd_solver.cpp:105] Iteration 87100, lr = 0.005645
I0529 01:56:13.994015 11123 solver.cpp:218] Iteration 87200 (3.56812 iter/s, 28.0259s/100 iters), loss = 0.00336782
I0529 01:56:13.994057 11123 solver.cpp:237]     Train net output #0: loss = 0.00336679 (* 1 = 0.00336679 loss)
I0529 01:56:13.994066 11123 sgd_solver.cpp:105] Iteration 87200, lr = 0.00564
I0529 01:56:42.012339 11123 solver.cpp:218] Iteration 87300 (3.56917 iter/s, 28.0177s/100 iters), loss = 0.000952143
I0529 01:56:42.012501 11123 solver.cpp:237]     Train net output #0: loss = 0.000951139 (* 1 = 0.000951139 loss)
I0529 01:56:42.012513 11123 sgd_solver.cpp:105] Iteration 87300, lr = 0.005635
I0529 01:57:10.023402 11123 solver.cpp:218] Iteration 87400 (3.57011 iter/s, 28.0104s/100 iters), loss = 0.000345456
I0529 01:57:10.023458 11123 solver.cpp:237]     Train net output #0: loss = 0.000344464 (* 1 = 0.000344464 loss)
I0529 01:57:10.023468 11123 sgd_solver.cpp:105] Iteration 87400, lr = 0.00563
I0529 01:57:38.025583 11123 solver.cpp:218] Iteration 87500 (3.57123 iter/s, 28.0016s/100 iters), loss = 0.00277853
I0529 01:57:38.025754 11123 solver.cpp:237]     Train net output #0: loss = 0.00277755 (* 1 = 0.00277755 loss)
I0529 01:57:38.025765 11123 sgd_solver.cpp:105] Iteration 87500, lr = 0.005625
I0529 01:58:06.001152 11123 solver.cpp:218] Iteration 87600 (3.57464 iter/s, 27.9749s/100 iters), loss = 7.689e-06
I0529 01:58:06.001196 11123 solver.cpp:237]     Train net output #0: loss = 6.71166e-06 (* 1 = 6.71166e-06 loss)
I0529 01:58:06.001205 11123 sgd_solver.cpp:105] Iteration 87600, lr = 0.00562
I0529 01:58:13.290323 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:58:33.999126 11123 solver.cpp:218] Iteration 87700 (3.57176 iter/s, 27.9974s/100 iters), loss = 0.000385661
I0529 01:58:33.999168 11123 solver.cpp:237]     Train net output #0: loss = 0.000384685 (* 1 = 0.000384685 loss)
I0529 01:58:33.999177 11123 sgd_solver.cpp:105] Iteration 87700, lr = 0.005615
I0529 01:59:02.022078 11123 solver.cpp:218] Iteration 87800 (3.56858 iter/s, 28.0224s/100 iters), loss = 0.00037338
I0529 01:59:02.022235 11123 solver.cpp:237]     Train net output #0: loss = 0.000372401 (* 1 = 0.000372401 loss)
I0529 01:59:02.022246 11123 sgd_solver.cpp:105] Iteration 87800, lr = 0.00561
I0529 01:59:30.057471 11123 solver.cpp:218] Iteration 87900 (3.56701 iter/s, 28.0347s/100 iters), loss = 0.00567917
I0529 01:59:30.057516 11123 solver.cpp:237]     Train net output #0: loss = 0.00567818 (* 1 = 0.00567818 loss)
I0529 01:59:30.057525 11123 sgd_solver.cpp:105] Iteration 87900, lr = 0.005605
I0529 01:59:57.784648 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_88000.caffemodel
I0529 01:59:58.287883 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_88000.solverstate
I0529 01:59:58.434645 11123 solver.cpp:330] Iteration 88000, Testing net (#0)
I0529 01:59:59.953578 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:00:02.894136 11123 solver.cpp:397]     Test net output #0: accuracy = 0.932
I0529 02:00:02.894184 11123 solver.cpp:397]     Test net output #1: loss = 0.24608 (* 1 = 0.24608 loss)
I0529 02:00:03.171723 11123 solver.cpp:218] Iteration 88000 (3.01991 iter/s, 33.1135s/100 iters), loss = 0.00626675
I0529 02:00:03.171768 11123 solver.cpp:237]     Train net output #0: loss = 0.00626577 (* 1 = 0.00626577 loss)
I0529 02:00:03.171777 11123 sgd_solver.cpp:105] Iteration 88000, lr = 0.0056
I0529 02:00:31.177659 11123 solver.cpp:218] Iteration 88100 (3.57075 iter/s, 28.0053s/100 iters), loss = 9.96467e-05
I0529 02:00:31.177816 11123 solver.cpp:237]     Train net output #0: loss = 9.86621e-05 (* 1 = 9.86621e-05 loss)
I0529 02:00:31.177829 11123 sgd_solver.cpp:105] Iteration 88100, lr = 0.005595
I0529 02:00:59.157006 11123 solver.cpp:218] Iteration 88200 (3.57416 iter/s, 27.9786s/100 iters), loss = 7.92672e-05
I0529 02:00:59.157061 11123 solver.cpp:237]     Train net output #0: loss = 7.82805e-05 (* 1 = 7.82805e-05 loss)
I0529 02:00:59.157071 11123 sgd_solver.cpp:105] Iteration 88200, lr = 0.00559
I0529 02:01:10.098659 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:01:27.172284 11123 solver.cpp:218] Iteration 88300 (3.56956 iter/s, 28.0147s/100 iters), loss = 0.0105073
I0529 02:01:27.172327 11123 solver.cpp:237]     Train net output #0: loss = 0.0105063 (* 1 = 0.0105063 loss)
I0529 02:01:27.172336 11123 sgd_solver.cpp:105] Iteration 88300, lr = 0.005585
I0529 02:01:55.185643 11123 solver.cpp:218] Iteration 88400 (3.5698 iter/s, 28.0127s/100 iters), loss = 0.00128014
I0529 02:01:55.185794 11123 solver.cpp:237]     Train net output #0: loss = 0.00127913 (* 1 = 0.00127913 loss)
I0529 02:01:55.185806 11123 sgd_solver.cpp:105] Iteration 88400, lr = 0.00558
I0529 02:02:23.202884 11123 solver.cpp:218] Iteration 88500 (3.56932 iter/s, 28.0165s/100 iters), loss = 0.0348481
I0529 02:02:23.202929 11123 solver.cpp:237]     Train net output #0: loss = 0.0348471 (* 1 = 0.0348471 loss)
I0529 02:02:23.202937 11123 sgd_solver.cpp:105] Iteration 88500, lr = 0.005575
I0529 02:02:51.196573 11123 solver.cpp:218] Iteration 88600 (3.57231 iter/s, 27.9931s/100 iters), loss = 5.62742e-05
I0529 02:02:51.196781 11123 solver.cpp:237]     Train net output #0: loss = 5.52835e-05 (* 1 = 5.52835e-05 loss)
I0529 02:02:51.196792 11123 sgd_solver.cpp:105] Iteration 88600, lr = 0.00557
I0529 02:03:19.177963 11123 solver.cpp:218] Iteration 88700 (3.5739 iter/s, 27.9806s/100 iters), loss = 8.67084e-05
I0529 02:03:19.178005 11123 solver.cpp:237]     Train net output #0: loss = 8.57218e-05 (* 1 = 8.57218e-05 loss)
I0529 02:03:19.178014 11123 sgd_solver.cpp:105] Iteration 88700, lr = 0.005565
I0529 02:03:47.142276 11123 solver.cpp:218] Iteration 88800 (3.57607 iter/s, 27.9637s/100 iters), loss = 6.73636e-05
I0529 02:03:47.142429 11123 solver.cpp:237]     Train net output #0: loss = 6.63839e-05 (* 1 = 6.63839e-05 loss)
I0529 02:03:47.142441 11123 sgd_solver.cpp:105] Iteration 88800, lr = 0.00556
I0529 02:04:01.438906 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:04:15.117105 11123 solver.cpp:218] Iteration 88900 (3.57473 iter/s, 27.9741s/100 iters), loss = 7.0699e-05
I0529 02:04:15.117148 11123 solver.cpp:237]     Train net output #0: loss = 6.97349e-05 (* 1 = 6.97349e-05 loss)
I0529 02:04:15.117157 11123 sgd_solver.cpp:105] Iteration 88900, lr = 0.005555
I0529 02:04:42.826555 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_89000.caffemodel
I0529 02:04:43.427355 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_89000.solverstate
I0529 02:04:43.573596 11123 solver.cpp:330] Iteration 89000, Testing net (#0)
I0529 02:04:46.601816 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:04:48.015208 11123 solver.cpp:397]     Test net output #0: accuracy = 0.926001
I0529 02:04:48.015262 11123 solver.cpp:397]     Test net output #1: loss = 0.290053 (* 1 = 0.290053 loss)
I0529 02:04:48.292183 11123 solver.cpp:218] Iteration 89000 (3.01438 iter/s, 33.1744s/100 iters), loss = 0.00341911
I0529 02:04:48.292232 11123 solver.cpp:237]     Train net output #0: loss = 0.00341815 (* 1 = 0.00341815 loss)
I0529 02:04:48.292243 11123 sgd_solver.cpp:105] Iteration 89000, lr = 0.00555
I0529 02:05:16.282196 11123 solver.cpp:218] Iteration 89100 (3.57278 iter/s, 27.9894s/100 iters), loss = 0.00698396
I0529 02:05:16.282361 11123 solver.cpp:237]     Train net output #0: loss = 0.00698299 (* 1 = 0.00698299 loss)
I0529 02:05:16.282373 11123 sgd_solver.cpp:105] Iteration 89100, lr = 0.005545
I0529 02:05:44.270941 11123 solver.cpp:218] Iteration 89200 (3.57296 iter/s, 27.988s/100 iters), loss = 4.7693e-05
I0529 02:05:44.270984 11123 solver.cpp:237]     Train net output #0: loss = 4.67409e-05 (* 1 = 4.67409e-05 loss)
I0529 02:05:44.270993 11123 sgd_solver.cpp:105] Iteration 89200, lr = 0.00554
I0529 02:06:12.261497 11123 solver.cpp:218] Iteration 89300 (3.57271 iter/s, 27.9899s/100 iters), loss = 2.90605e-05
I0529 02:06:12.261654 11123 solver.cpp:237]     Train net output #0: loss = 2.81119e-05 (* 1 = 2.81119e-05 loss)
I0529 02:06:12.261667 11123 sgd_solver.cpp:105] Iteration 89300, lr = 0.005535
I0529 02:06:40.234845 11123 solver.cpp:218] Iteration 89400 (3.57492 iter/s, 27.9726s/100 iters), loss = 0.00141782
I0529 02:06:40.234889 11123 solver.cpp:237]     Train net output #0: loss = 0.00141687 (* 1 = 0.00141687 loss)
I0529 02:06:40.234896 11123 sgd_solver.cpp:105] Iteration 89400, lr = 0.00553
I0529 02:06:58.149555 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:07:08.207797 11123 solver.cpp:218] Iteration 89500 (3.57496 iter/s, 27.9723s/100 iters), loss = 0.00385616
I0529 02:07:08.207839 11123 solver.cpp:237]     Train net output #0: loss = 0.0038552 (* 1 = 0.0038552 loss)
I0529 02:07:08.207847 11123 sgd_solver.cpp:105] Iteration 89500, lr = 0.005525
I0529 02:07:36.196585 11123 solver.cpp:218] Iteration 89600 (3.57294 iter/s, 27.9882s/100 iters), loss = 0.019324
I0529 02:07:36.196739 11123 solver.cpp:237]     Train net output #0: loss = 0.019323 (* 1 = 0.019323 loss)
I0529 02:07:36.196753 11123 sgd_solver.cpp:105] Iteration 89600, lr = 0.00552
I0529 02:08:04.162950 11123 solver.cpp:218] Iteration 89700 (3.57582 iter/s, 27.9656s/100 iters), loss = 0.0117677
I0529 02:08:04.162999 11123 solver.cpp:237]     Train net output #0: loss = 0.0117667 (* 1 = 0.0117667 loss)
I0529 02:08:04.163010 11123 sgd_solver.cpp:105] Iteration 89700, lr = 0.005515
I0529 02:08:32.132350 11123 solver.cpp:218] Iteration 89800 (3.57542 iter/s, 27.9688s/100 iters), loss = 9.08249e-06
I0529 02:08:32.132513 11123 solver.cpp:237]     Train net output #0: loss = 8.14226e-06 (* 1 = 8.14226e-06 loss)
I0529 02:08:32.132525 11123 sgd_solver.cpp:105] Iteration 89800, lr = 0.00551
I0529 02:09:00.091042 11123 solver.cpp:218] Iteration 89900 (3.5768 iter/s, 27.9579s/100 iters), loss = 0.000257158
I0529 02:09:00.091090 11123 solver.cpp:237]     Train net output #0: loss = 0.000256208 (* 1 = 0.000256208 loss)
I0529 02:09:00.091110 11123 sgd_solver.cpp:105] Iteration 89900, lr = 0.005505
I0529 02:09:27.795339 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_90000.caffemodel
I0529 02:09:28.324522 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_90000.solverstate
I0529 02:09:28.470890 11123 solver.cpp:330] Iteration 90000, Testing net (#0)
I0529 02:09:32.920408 11123 solver.cpp:397]     Test net output #0: accuracy = 0.95
I0529 02:09:32.920461 11123 solver.cpp:397]     Test net output #1: loss = 0.242274 (* 1 = 0.242274 loss)
I0529 02:09:33.197055 11123 solver.cpp:218] Iteration 90000 (3.02084 iter/s, 33.1034s/100 iters), loss = 1.05004e-05
I0529 02:09:33.197096 11123 solver.cpp:237]     Train net output #0: loss = 9.57322e-06 (* 1 = 9.57322e-06 loss)
I0529 02:09:33.197105 11123 sgd_solver.cpp:105] Iteration 90000, lr = 0.0055
I0529 02:09:54.755579 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:10:01.180701 11123 solver.cpp:218] Iteration 90100 (3.5736 iter/s, 27.983s/100 iters), loss = 0.000173376
I0529 02:10:01.180881 11123 solver.cpp:237]     Train net output #0: loss = 0.000172445 (* 1 = 0.000172445 loss)
I0529 02:10:01.180892 11123 sgd_solver.cpp:105] Iteration 90100, lr = 0.005495
I0529 02:10:29.163264 11123 solver.cpp:218] Iteration 90200 (3.57375 iter/s, 27.9818s/100 iters), loss = 0.00224727
I0529 02:10:29.163306 11123 solver.cpp:237]     Train net output #0: loss = 0.00224633 (* 1 = 0.00224633 loss)
I0529 02:10:29.163316 11123 sgd_solver.cpp:105] Iteration 90200, lr = 0.00549
I0529 02:10:57.125000 11123 solver.cpp:218] Iteration 90300 (3.5764 iter/s, 27.9611s/100 iters), loss = 0.00632747
I0529 02:10:57.125130 11123 solver.cpp:237]     Train net output #0: loss = 0.00632653 (* 1 = 0.00632653 loss)
I0529 02:10:57.125151 11123 sgd_solver.cpp:105] Iteration 90300, lr = 0.005485
I0529 02:11:25.110591 11123 solver.cpp:218] Iteration 90400 (3.57336 iter/s, 27.9849s/100 iters), loss = 0.00231964
I0529 02:11:25.110633 11123 solver.cpp:237]     Train net output #0: loss = 0.00231871 (* 1 = 0.00231871 loss)
I0529 02:11:25.110642 11123 sgd_solver.cpp:105] Iteration 90400, lr = 0.00548
I0529 02:11:53.082459 11123 solver.cpp:218] Iteration 90500 (3.5751 iter/s, 27.9712s/100 iters), loss = 0.00815859
I0529 02:11:53.082618 11123 solver.cpp:237]     Train net output #0: loss = 0.00815765 (* 1 = 0.00815765 loss)
I0529 02:11:53.082630 11123 sgd_solver.cpp:105] Iteration 90500, lr = 0.005475
I0529 02:12:21.064988 11123 solver.cpp:218] Iteration 90600 (3.57375 iter/s, 27.9818s/100 iters), loss = 0.000109521
I0529 02:12:21.065043 11123 solver.cpp:237]     Train net output #0: loss = 0.000108559 (* 1 = 0.000108559 loss)
I0529 02:12:21.065053 11123 sgd_solver.cpp:105] Iteration 90600, lr = 0.00547
I0529 02:12:46.265801 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:12:49.048810 11123 solver.cpp:218] Iteration 90700 (3.57357 iter/s, 27.9832s/100 iters), loss = 0.00895466
I0529 02:12:49.048851 11123 solver.cpp:237]     Train net output #0: loss = 0.0089537 (* 1 = 0.0089537 loss)
I0529 02:12:49.048859 11123 sgd_solver.cpp:105] Iteration 90700, lr = 0.005465
I0529 02:13:17.032848 11123 solver.cpp:218] Iteration 90800 (3.57355 iter/s, 27.9834s/100 iters), loss = 0.00135238
I0529 02:13:17.033004 11123 solver.cpp:237]     Train net output #0: loss = 0.00135141 (* 1 = 0.00135141 loss)
I0529 02:13:17.033015 11123 sgd_solver.cpp:105] Iteration 90800, lr = 0.00546
I0529 02:13:45.044764 11123 solver.cpp:218] Iteration 90900 (3.57 iter/s, 28.0112s/100 iters), loss = 0.00178833
I0529 02:13:45.044819 11123 solver.cpp:237]     Train net output #0: loss = 0.00178736 (* 1 = 0.00178736 loss)
I0529 02:13:45.044828 11123 sgd_solver.cpp:105] Iteration 90900, lr = 0.005455
I0529 02:14:12.776062 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_91000.caffemodel
I0529 02:14:13.241541 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_91000.solverstate
I0529 02:14:13.390638 11123 solver.cpp:330] Iteration 91000, Testing net (#0)
I0529 02:14:13.486227 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:14:17.847153 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 02:14:17.847198 11123 solver.cpp:397]     Test net output #1: loss = 0.242137 (* 1 = 0.242137 loss)
I0529 02:14:18.124627 11123 solver.cpp:218] Iteration 91000 (3.02306 iter/s, 33.0791s/100 iters), loss = 0.000215532
I0529 02:14:18.124677 11123 solver.cpp:237]     Train net output #0: loss = 0.000214562 (* 1 = 0.000214562 loss)
I0529 02:14:18.124691 11123 sgd_solver.cpp:105] Iteration 91000, lr = 0.00545
I0529 02:14:46.100230 11123 solver.cpp:218] Iteration 91100 (3.57462 iter/s, 27.975s/100 iters), loss = 0.000406209
I0529 02:14:46.100435 11123 solver.cpp:237]     Train net output #0: loss = 0.000405239 (* 1 = 0.000405239 loss)
I0529 02:14:46.100452 11123 sgd_solver.cpp:105] Iteration 91100, lr = 0.005445
I0529 02:15:14.119158 11123 solver.cpp:218] Iteration 91200 (3.56912 iter/s, 28.0181s/100 iters), loss = 1.28702e-05
I0529 02:15:14.119206 11123 solver.cpp:237]     Train net output #0: loss = 1.19037e-05 (* 1 = 1.19037e-05 loss)
I0529 02:15:14.119220 11123 sgd_solver.cpp:105] Iteration 91200, lr = 0.00544
I0529 02:15:42.137162 11123 solver.cpp:218] Iteration 91300 (3.56921 iter/s, 28.0174s/100 iters), loss = 0.000113489
I0529 02:15:42.137336 11123 solver.cpp:237]     Train net output #0: loss = 0.000112521 (* 1 = 0.000112521 loss)
I0529 02:15:42.137356 11123 sgd_solver.cpp:105] Iteration 91300, lr = 0.005435
I0529 02:15:42.993113 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:16:10.159675 11123 solver.cpp:218] Iteration 91400 (3.56866 iter/s, 28.0218s/100 iters), loss = 0.000126204
I0529 02:16:10.159735 11123 solver.cpp:237]     Train net output #0: loss = 0.000125235 (* 1 = 0.000125235 loss)
I0529 02:16:10.159749 11123 sgd_solver.cpp:105] Iteration 91400, lr = 0.00543
I0529 02:16:38.167111 11123 solver.cpp:218] Iteration 91500 (3.57056 iter/s, 28.0068s/100 iters), loss = 0.000484882
I0529 02:16:38.167263 11123 solver.cpp:237]     Train net output #0: loss = 0.000483919 (* 1 = 0.000483919 loss)
I0529 02:16:38.167278 11123 sgd_solver.cpp:105] Iteration 91500, lr = 0.005425
I0529 02:17:06.165537 11123 solver.cpp:218] Iteration 91600 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.000294819
I0529 02:17:06.165586 11123 solver.cpp:237]     Train net output #0: loss = 0.000293858 (* 1 = 0.000293858 loss)
I0529 02:17:06.165611 11123 sgd_solver.cpp:105] Iteration 91600, lr = 0.00542
I0529 02:17:34.157316 11123 solver.cpp:218] Iteration 91700 (3.57256 iter/s, 27.9911s/100 iters), loss = 1.14033e-05
I0529 02:17:34.157521 11123 solver.cpp:237]     Train net output #0: loss = 1.0443e-05 (* 1 = 1.0443e-05 loss)
I0529 02:17:34.157541 11123 sgd_solver.cpp:105] Iteration 91700, lr = 0.005415
I0529 02:18:02.145213 11123 solver.cpp:218] Iteration 91800 (3.57307 iter/s, 27.9871s/100 iters), loss = 0.00132875
I0529 02:18:02.145262 11123 solver.cpp:237]     Train net output #0: loss = 0.00132779 (* 1 = 0.00132779 loss)
I0529 02:18:02.145274 11123 sgd_solver.cpp:105] Iteration 91800, lr = 0.00541
I0529 02:18:30.140077 11123 solver.cpp:218] Iteration 91900 (3.57217 iter/s, 27.9942s/100 iters), loss = 0.000635745
I0529 02:18:30.140360 11123 solver.cpp:237]     Train net output #0: loss = 0.000634792 (* 1 = 0.000634792 loss)
I0529 02:18:30.140377 11123 sgd_solver.cpp:105] Iteration 91900, lr = 0.005405
I0529 02:18:34.365136 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:18:57.858499 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_92000.caffemodel
I0529 02:18:58.336853 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_92000.solverstate
I0529 02:18:58.484349 11123 solver.cpp:330] Iteration 92000, Testing net (#0)
I0529 02:19:00.088919 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:19:02.941615 11123 solver.cpp:397]     Test net output #0: accuracy = 0.925
I0529 02:19:02.941777 11123 solver.cpp:397]     Test net output #1: loss = 0.333307 (* 1 = 0.333307 loss)
I0529 02:19:03.218430 11123 solver.cpp:218] Iteration 92000 (3.02321 iter/s, 33.0774s/100 iters), loss = 0.00116313
I0529 02:19:03.218477 11123 solver.cpp:237]     Train net output #0: loss = 0.00116217 (* 1 = 0.00116217 loss)
I0529 02:19:03.218500 11123 sgd_solver.cpp:105] Iteration 92000, lr = 0.0054
I0529 02:19:31.210280 11123 solver.cpp:218] Iteration 92100 (3.57255 iter/s, 27.9912s/100 iters), loss = 0.000223737
I0529 02:19:31.210330 11123 solver.cpp:237]     Train net output #0: loss = 0.000222774 (* 1 = 0.000222774 loss)
I0529 02:19:31.210352 11123 sgd_solver.cpp:105] Iteration 92100, lr = 0.005395
I0529 02:19:59.220917 11123 solver.cpp:218] Iteration 92200 (3.57015 iter/s, 28.01s/100 iters), loss = 0.00121475
I0529 02:19:59.221154 11123 solver.cpp:237]     Train net output #0: loss = 0.0012138 (* 1 = 0.0012138 loss)
I0529 02:19:59.221174 11123 sgd_solver.cpp:105] Iteration 92200, lr = 0.00539
I0529 02:20:27.224838 11123 solver.cpp:218] Iteration 92300 (3.57103 iter/s, 28.0031s/100 iters), loss = 0.00172312
I0529 02:20:27.224892 11123 solver.cpp:237]     Train net output #0: loss = 0.00172219 (* 1 = 0.00172219 loss)
I0529 02:20:27.224902 11123 sgd_solver.cpp:105] Iteration 92300, lr = 0.005385
I0529 02:20:55.213806 11123 solver.cpp:218] Iteration 92400 (3.57292 iter/s, 27.9883s/100 iters), loss = 0.0668317
I0529 02:20:55.214030 11123 solver.cpp:237]     Train net output #0: loss = 0.0668308 (* 1 = 0.0668308 loss)
I0529 02:20:55.214041 11123 sgd_solver.cpp:105] Iteration 92400, lr = 0.00538
I0529 02:21:23.230362 11123 solver.cpp:218] Iteration 92500 (3.56942 iter/s, 28.0157s/100 iters), loss = 0.0129773
I0529 02:21:23.230407 11123 solver.cpp:237]     Train net output #0: loss = 0.0129764 (* 1 = 0.0129764 loss)
I0529 02:21:23.230417 11123 sgd_solver.cpp:105] Iteration 92500, lr = 0.005375
I0529 02:21:31.087488 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:21:51.223047 11123 solver.cpp:218] Iteration 92600 (3.57244 iter/s, 27.992s/100 iters), loss = 0.00335966
I0529 02:21:51.223090 11123 solver.cpp:237]     Train net output #0: loss = 0.00335876 (* 1 = 0.00335876 loss)
I0529 02:21:51.223098 11123 sgd_solver.cpp:105] Iteration 92600, lr = 0.00537
I0529 02:22:19.216372 11123 solver.cpp:218] Iteration 92700 (3.57236 iter/s, 27.9927s/100 iters), loss = 0.000569395
I0529 02:22:19.216536 11123 solver.cpp:237]     Train net output #0: loss = 0.000568482 (* 1 = 0.000568482 loss)
I0529 02:22:19.216548 11123 sgd_solver.cpp:105] Iteration 92700, lr = 0.005365
I0529 02:22:47.194584 11123 solver.cpp:218] Iteration 92800 (3.57431 iter/s, 27.9775s/100 iters), loss = 0.0215388
I0529 02:22:47.194628 11123 solver.cpp:237]     Train net output #0: loss = 0.0215378 (* 1 = 0.0215378 loss)
I0529 02:22:47.194638 11123 sgd_solver.cpp:105] Iteration 92800, lr = 0.00536
I0529 02:23:15.214179 11123 solver.cpp:218] Iteration 92900 (3.56901 iter/s, 28.019s/100 iters), loss = 0.00266332
I0529 02:23:15.214347 11123 solver.cpp:237]     Train net output #0: loss = 0.00266238 (* 1 = 0.00266238 loss)
I0529 02:23:15.214359 11123 sgd_solver.cpp:105] Iteration 92900, lr = 0.005355
I0529 02:23:42.956327 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_93000.caffemodel
I0529 02:23:43.390769 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_93000.solverstate
I0529 02:23:43.536514 11123 solver.cpp:330] Iteration 93000, Testing net (#0)
I0529 02:23:46.618288 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:23:47.986811 11123 solver.cpp:397]     Test net output #0: accuracy = 0.918
I0529 02:23:47.986853 11123 solver.cpp:397]     Test net output #1: loss = 0.288555 (* 1 = 0.288555 loss)
I0529 02:23:48.264114 11123 solver.cpp:218] Iteration 93000 (3.0258 iter/s, 33.0491s/100 iters), loss = 0.000157481
I0529 02:23:48.264171 11123 solver.cpp:237]     Train net output #0: loss = 0.00015654 (* 1 = 0.00015654 loss)
I0529 02:23:48.264180 11123 sgd_solver.cpp:105] Iteration 93000, lr = 0.00535
I0529 02:24:16.245347 11123 solver.cpp:218] Iteration 93100 (3.57391 iter/s, 27.9806s/100 iters), loss = 1.80084e-05
I0529 02:24:16.245404 11123 solver.cpp:237]     Train net output #0: loss = 1.7081e-05 (* 1 = 1.7081e-05 loss)
I0529 02:24:16.245414 11123 sgd_solver.cpp:105] Iteration 93100, lr = 0.005345
I0529 02:24:27.737309 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:24:44.223734 11123 solver.cpp:218] Iteration 93200 (3.57427 iter/s, 27.9777s/100 iters), loss = 0.000181182
I0529 02:24:44.223778 11123 solver.cpp:237]     Train net output #0: loss = 0.000180253 (* 1 = 0.000180253 loss)
I0529 02:24:44.223786 11123 sgd_solver.cpp:105] Iteration 93200, lr = 0.00534
I0529 02:25:12.206568 11123 solver.cpp:218] Iteration 93300 (3.5737 iter/s, 27.9822s/100 iters), loss = 0.00674113
I0529 02:25:12.206755 11123 solver.cpp:237]     Train net output #0: loss = 0.0067402 (* 1 = 0.0067402 loss)
I0529 02:25:12.206766 11123 sgd_solver.cpp:105] Iteration 93300, lr = 0.005335
I0529 02:25:40.203449 11123 solver.cpp:218] Iteration 93400 (3.57193 iter/s, 27.9961s/100 iters), loss = 0.000491005
I0529 02:25:40.203495 11123 solver.cpp:237]     Train net output #0: loss = 0.000490067 (* 1 = 0.000490067 loss)
I0529 02:25:40.203516 11123 sgd_solver.cpp:105] Iteration 93400, lr = 0.00533
I0529 02:26:08.217715 11123 solver.cpp:218] Iteration 93500 (3.56969 iter/s, 28.0136s/100 iters), loss = 0.000661376
I0529 02:26:08.217876 11123 solver.cpp:237]     Train net output #0: loss = 0.000660454 (* 1 = 0.000660454 loss)
I0529 02:26:08.217888 11123 sgd_solver.cpp:105] Iteration 93500, lr = 0.005325
I0529 02:26:36.229058 11123 solver.cpp:218] Iteration 93600 (3.57008 iter/s, 28.0106s/100 iters), loss = 3.5529e-05
I0529 02:26:36.229102 11123 solver.cpp:237]     Train net output #0: loss = 3.45687e-05 (* 1 = 3.45687e-05 loss)
I0529 02:26:36.229111 11123 sgd_solver.cpp:105] Iteration 93600, lr = 0.00532
I0529 02:27:04.253159 11123 solver.cpp:218] Iteration 93700 (3.56844 iter/s, 28.0235s/100 iters), loss = 5.88801e-05
I0529 02:27:04.253345 11123 solver.cpp:237]     Train net output #0: loss = 5.79403e-05 (* 1 = 5.79403e-05 loss)
I0529 02:27:04.253371 11123 sgd_solver.cpp:105] Iteration 93700, lr = 0.005315
I0529 02:27:19.387560 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:27:32.234303 11123 solver.cpp:218] Iteration 93800 (3.57393 iter/s, 27.9804s/100 iters), loss = 2.49427e-05
I0529 02:27:32.234352 11123 solver.cpp:237]     Train net output #0: loss = 2.3982e-05 (* 1 = 2.3982e-05 loss)
I0529 02:27:32.234364 11123 sgd_solver.cpp:105] Iteration 93800, lr = 0.00531
I0529 02:28:00.212852 11123 solver.cpp:218] Iteration 93900 (3.57425 iter/s, 27.9779s/100 iters), loss = 9.25046e-05
I0529 02:28:00.213021 11123 solver.cpp:237]     Train net output #0: loss = 9.1533e-05 (* 1 = 9.1533e-05 loss)
I0529 02:28:00.213033 11123 sgd_solver.cpp:105] Iteration 93900, lr = 0.005305
I0529 02:28:27.940659 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_94000.caffemodel
I0529 02:28:28.359459 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_94000.solverstate
I0529 02:28:28.505967 11123 solver.cpp:330] Iteration 94000, Testing net (#0)
I0529 02:28:32.951608 11123 solver.cpp:397]     Test net output #0: accuracy = 0.927
I0529 02:28:32.951751 11123 solver.cpp:397]     Test net output #1: loss = 0.303331 (* 1 = 0.303331 loss)
I0529 02:28:33.228471 11123 solver.cpp:218] Iteration 94000 (3.02895 iter/s, 33.0147s/100 iters), loss = 0.010787
I0529 02:28:33.228526 11123 solver.cpp:237]     Train net output #0: loss = 0.010786 (* 1 = 0.010786 loss)
I0529 02:28:33.228535 11123 sgd_solver.cpp:105] Iteration 94000, lr = 0.0053
I0529 02:29:01.216552 11123 solver.cpp:218] Iteration 94100 (3.57304 iter/s, 27.9874s/100 iters), loss = 0.00238786
I0529 02:29:01.216594 11123 solver.cpp:237]     Train net output #0: loss = 0.00238687 (* 1 = 0.00238687 loss)
I0529 02:29:01.216603 11123 sgd_solver.cpp:105] Iteration 94100, lr = 0.005295
I0529 02:29:29.183142 11123 solver.cpp:218] Iteration 94200 (3.57578 iter/s, 27.9659s/100 iters), loss = 3.59912e-05
I0529 02:29:29.183297 11123 solver.cpp:237]     Train net output #0: loss = 3.50157e-05 (* 1 = 3.50157e-05 loss)
I0529 02:29:29.183308 11123 sgd_solver.cpp:105] Iteration 94200, lr = 0.00529
I0529 02:29:57.166438 11123 solver.cpp:218] Iteration 94300 (3.57366 iter/s, 27.9825s/100 iters), loss = 0.000521831
I0529 02:29:57.166494 11123 solver.cpp:237]     Train net output #0: loss = 0.000520856 (* 1 = 0.000520856 loss)
I0529 02:29:57.166503 11123 sgd_solver.cpp:105] Iteration 94300, lr = 0.005285
I0529 02:30:15.948648 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:30:25.180404 11123 solver.cpp:218] Iteration 94400 (3.56974 iter/s, 28.0133s/100 iters), loss = 0.0203748
I0529 02:30:25.180449 11123 solver.cpp:237]     Train net output #0: loss = 0.0203738 (* 1 = 0.0203738 loss)
I0529 02:30:25.180457 11123 sgd_solver.cpp:105] Iteration 94400, lr = 0.00528
I0529 02:30:53.180479 11123 solver.cpp:218] Iteration 94500 (3.57151 iter/s, 27.9994s/100 iters), loss = 0.00045896
I0529 02:30:53.180692 11123 solver.cpp:237]     Train net output #0: loss = 0.000457915 (* 1 = 0.000457915 loss)
I0529 02:30:53.180704 11123 sgd_solver.cpp:105] Iteration 94500, lr = 0.005275
I0529 02:31:21.189070 11123 solver.cpp:218] Iteration 94600 (3.57044 iter/s, 28.0077s/100 iters), loss = 0.0919742
I0529 02:31:21.189115 11123 solver.cpp:237]     Train net output #0: loss = 0.0919732 (* 1 = 0.0919732 loss)
I0529 02:31:21.189123 11123 sgd_solver.cpp:105] Iteration 94600, lr = 0.00527
I0529 02:31:49.223496 11123 solver.cpp:218] Iteration 94700 (3.56713 iter/s, 28.0337s/100 iters), loss = 0.0950949
I0529 02:31:49.223708 11123 solver.cpp:237]     Train net output #0: loss = 0.0950938 (* 1 = 0.0950938 loss)
I0529 02:31:49.223731 11123 sgd_solver.cpp:105] Iteration 94700, lr = 0.005265
I0529 02:32:17.221477 11123 solver.cpp:218] Iteration 94800 (3.57179 iter/s, 27.9971s/100 iters), loss = 0.000238025
I0529 02:32:17.221523 11123 solver.cpp:237]     Train net output #0: loss = 0.000236952 (* 1 = 0.000236952 loss)
I0529 02:32:17.221531 11123 sgd_solver.cpp:105] Iteration 94800, lr = 0.00526
I0529 02:32:45.193025 11123 solver.cpp:218] Iteration 94900 (3.57515 iter/s, 27.9709s/100 iters), loss = 0.00364852
I0529 02:32:45.193195 11123 solver.cpp:237]     Train net output #0: loss = 0.00364746 (* 1 = 0.00364746 loss)
I0529 02:32:45.193207 11123 sgd_solver.cpp:105] Iteration 94900, lr = 0.005255
I0529 02:33:07.327241 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:33:12.915071 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_95000.caffemodel
I0529 02:33:13.327356 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_95000.solverstate
I0529 02:33:13.474210 11123 solver.cpp:330] Iteration 95000, Testing net (#0)
I0529 02:33:13.615361 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:33:17.925834 11123 solver.cpp:397]     Test net output #0: accuracy = 0.927
I0529 02:33:17.926057 11123 solver.cpp:397]     Test net output #1: loss = 0.357806 (* 1 = 0.357806 loss)
I0529 02:33:18.203665 11123 solver.cpp:218] Iteration 95000 (3.02941 iter/s, 33.0097s/100 iters), loss = 0.00158824
I0529 02:33:18.203711 11123 solver.cpp:237]     Train net output #0: loss = 0.00158717 (* 1 = 0.00158717 loss)
I0529 02:33:18.203732 11123 sgd_solver.cpp:105] Iteration 95000, lr = 0.00525
I0529 02:33:46.203114 11123 solver.cpp:218] Iteration 95100 (3.57159 iter/s, 27.9988s/100 iters), loss = 0.0157285
I0529 02:33:46.203160 11123 solver.cpp:237]     Train net output #0: loss = 0.0157274 (* 1 = 0.0157274 loss)
I0529 02:33:46.203168 11123 sgd_solver.cpp:105] Iteration 95100, lr = 0.005245
I0529 02:34:14.209358 11123 solver.cpp:218] Iteration 95200 (3.57072 iter/s, 28.0056s/100 iters), loss = 0.0633606
I0529 02:34:14.209513 11123 solver.cpp:237]     Train net output #0: loss = 0.0633595 (* 1 = 0.0633595 loss)
I0529 02:34:14.209524 11123 sgd_solver.cpp:105] Iteration 95200, lr = 0.00524
I0529 02:34:42.221716 11123 solver.cpp:218] Iteration 95300 (3.56995 iter/s, 28.0116s/100 iters), loss = 0.0507083
I0529 02:34:42.221760 11123 solver.cpp:237]     Train net output #0: loss = 0.0507072 (* 1 = 0.0507072 loss)
I0529 02:34:42.221767 11123 sgd_solver.cpp:105] Iteration 95300, lr = 0.005235
I0529 02:35:10.229264 11123 solver.cpp:218] Iteration 95400 (3.57055 iter/s, 28.0069s/100 iters), loss = 0.0300038
I0529 02:35:10.229430 11123 solver.cpp:237]     Train net output #0: loss = 0.0300028 (* 1 = 0.0300028 loss)
I0529 02:35:10.229445 11123 sgd_solver.cpp:105] Iteration 95400, lr = 0.00523
I0529 02:35:38.222360 11123 solver.cpp:218] Iteration 95500 (3.57241 iter/s, 27.9923s/100 iters), loss = 0.160405
I0529 02:35:38.222404 11123 solver.cpp:237]     Train net output #0: loss = 0.160404 (* 1 = 0.160404 loss)
I0529 02:35:38.222412 11123 sgd_solver.cpp:105] Iteration 95500, lr = 0.005225
I0529 02:36:04.000910 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:36:06.222148 11123 solver.cpp:218] Iteration 95600 (3.57154 iter/s, 27.9991s/100 iters), loss = 0.000703909
I0529 02:36:06.222199 11123 solver.cpp:237]     Train net output #0: loss = 0.000702856 (* 1 = 0.000702856 loss)
I0529 02:36:06.222223 11123 sgd_solver.cpp:105] Iteration 95600, lr = 0.00522
I0529 02:36:34.214202 11123 solver.cpp:218] Iteration 95700 (3.57253 iter/s, 27.9914s/100 iters), loss = 0.000684263
I0529 02:36:34.214381 11123 solver.cpp:237]     Train net output #0: loss = 0.000683228 (* 1 = 0.000683228 loss)
I0529 02:36:34.214399 11123 sgd_solver.cpp:105] Iteration 95700, lr = 0.005215
I0529 02:37:02.224921 11123 solver.cpp:218] Iteration 95800 (3.57016 iter/s, 28.0099s/100 iters), loss = 2.79222e-05
I0529 02:37:02.224982 11123 solver.cpp:237]     Train net output #0: loss = 2.69019e-05 (* 1 = 2.69019e-05 loss)
I0529 02:37:02.224992 11123 sgd_solver.cpp:105] Iteration 95800, lr = 0.00521
I0529 02:37:30.229948 11123 solver.cpp:218] Iteration 95900 (3.57087 iter/s, 28.0044s/100 iters), loss = 0.00119669
I0529 02:37:30.230166 11123 solver.cpp:237]     Train net output #0: loss = 0.0011957 (* 1 = 0.0011957 loss)
I0529 02:37:30.230178 11123 sgd_solver.cpp:105] Iteration 95900, lr = 0.005205
I0529 02:37:57.955230 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_96000.caffemodel
I0529 02:37:58.273943 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_96000.solverstate
I0529 02:37:58.418802 11123 solver.cpp:330] Iteration 96000, Testing net (#0)
I0529 02:38:00.069298 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:38:02.879590 11123 solver.cpp:397]     Test net output #0: accuracy = 0.918
I0529 02:38:02.879742 11123 solver.cpp:397]     Test net output #1: loss = 0.285222 (* 1 = 0.285222 loss)
I0529 02:38:03.155725 11123 solver.cpp:218] Iteration 96000 (3.03722 iter/s, 32.9249s/100 iters), loss = 0.0122644
I0529 02:38:03.155768 11123 solver.cpp:237]     Train net output #0: loss = 0.0122634 (* 1 = 0.0122634 loss)
I0529 02:38:03.155788 11123 sgd_solver.cpp:105] Iteration 96000, lr = 0.0052
I0529 02:38:31.166893 11123 solver.cpp:218] Iteration 96100 (3.57009 iter/s, 28.0105s/100 iters), loss = 0.0122537
I0529 02:38:31.166944 11123 solver.cpp:237]     Train net output #0: loss = 0.0122528 (* 1 = 0.0122528 loss)
I0529 02:38:31.166956 11123 sgd_solver.cpp:105] Iteration 96100, lr = 0.005195
I0529 02:38:59.161341 11123 solver.cpp:218] Iteration 96200 (3.57222 iter/s, 27.9938s/100 iters), loss = 0.0989138
I0529 02:38:59.161512 11123 solver.cpp:237]     Train net output #0: loss = 0.0989129 (* 1 = 0.0989129 loss)
I0529 02:38:59.161530 11123 sgd_solver.cpp:105] Iteration 96200, lr = 0.00519
I0529 02:39:00.588791 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:39:27.168619 11123 solver.cpp:218] Iteration 96300 (3.5706 iter/s, 28.0065s/100 iters), loss = 0.000184074
I0529 02:39:27.168680 11123 solver.cpp:237]     Train net output #0: loss = 0.000183079 (* 1 = 0.000183079 loss)
I0529 02:39:27.168689 11123 sgd_solver.cpp:105] Iteration 96300, lr = 0.005185
I0529 02:39:55.134090 11123 solver.cpp:218] Iteration 96400 (3.57593 iter/s, 27.9648s/100 iters), loss = 0.0549761
I0529 02:39:55.134249 11123 solver.cpp:237]     Train net output #0: loss = 0.0549751 (* 1 = 0.0549751 loss)
I0529 02:39:55.134260 11123 sgd_solver.cpp:105] Iteration 96400, lr = 0.00518
I0529 02:40:23.109889 11123 solver.cpp:218] Iteration 96500 (3.57462 iter/s, 27.975s/100 iters), loss = 0.00122856
I0529 02:40:23.109936 11123 solver.cpp:237]     Train net output #0: loss = 0.00122756 (* 1 = 0.00122756 loss)
I0529 02:40:23.109946 11123 sgd_solver.cpp:105] Iteration 96500, lr = 0.005175
I0529 02:40:51.091986 11123 solver.cpp:218] Iteration 96600 (3.5738 iter/s, 27.9814s/100 iters), loss = 0.0111653
I0529 02:40:51.092211 11123 solver.cpp:237]     Train net output #0: loss = 0.0111643 (* 1 = 0.0111643 loss)
I0529 02:40:51.092222 11123 sgd_solver.cpp:105] Iteration 96600, lr = 0.00517
I0529 02:41:19.081049 11123 solver.cpp:218] Iteration 96700 (3.57293 iter/s, 27.9882s/100 iters), loss = 0.00151915
I0529 02:41:19.081113 11123 solver.cpp:237]     Train net output #0: loss = 0.00151816 (* 1 = 0.00151816 loss)
I0529 02:41:19.081123 11123 sgd_solver.cpp:105] Iteration 96700, lr = 0.005165
I0529 02:41:47.072639 11123 solver.cpp:218] Iteration 96800 (3.57259 iter/s, 27.9909s/100 iters), loss = 0.000462988
I0529 02:41:47.072824 11123 solver.cpp:237]     Train net output #0: loss = 0.000461998 (* 1 = 0.000461998 loss)
I0529 02:41:47.072850 11123 sgd_solver.cpp:105] Iteration 96800, lr = 0.00516
I0529 02:41:52.127538 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:42:15.052429 11123 solver.cpp:218] Iteration 96900 (3.57411 iter/s, 27.979s/100 iters), loss = 1.86369e-05
I0529 02:42:15.052489 11123 solver.cpp:237]     Train net output #0: loss = 1.76416e-05 (* 1 = 1.76416e-05 loss)
I0529 02:42:15.052515 11123 sgd_solver.cpp:105] Iteration 96900, lr = 0.005155
I0529 02:42:42.756484 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_97000.caffemodel
I0529 02:42:43.061468 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_97000.solverstate
I0529 02:42:43.209712 11123 solver.cpp:330] Iteration 97000, Testing net (#0)
I0529 02:42:46.355942 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:42:47.643705 11123 solver.cpp:397]     Test net output #0: accuracy = 0.933
I0529 02:42:47.643746 11123 solver.cpp:397]     Test net output #1: loss = 0.284267 (* 1 = 0.284267 loss)
I0529 02:42:47.921546 11123 solver.cpp:218] Iteration 97000 (3.04244 iter/s, 32.8683s/100 iters), loss = 7.46639e-05
I0529 02:42:47.921589 11123 solver.cpp:237]     Train net output #0: loss = 7.3667e-05 (* 1 = 7.3667e-05 loss)
I0529 02:42:47.921598 11123 sgd_solver.cpp:105] Iteration 97000, lr = 0.00515
I0529 02:43:15.917773 11123 solver.cpp:218] Iteration 97100 (3.57199 iter/s, 27.9956s/100 iters), loss = 0.00372982
I0529 02:43:15.917989 11123 solver.cpp:237]     Train net output #0: loss = 0.00372883 (* 1 = 0.00372883 loss)
I0529 02:43:15.918012 11123 sgd_solver.cpp:105] Iteration 97100, lr = 0.005145
I0529 02:43:43.906965 11123 solver.cpp:218] Iteration 97200 (3.57291 iter/s, 27.9884s/100 iters), loss = 2.85953e-05
I0529 02:43:43.907011 11123 solver.cpp:237]     Train net output #0: loss = 2.76059e-05 (* 1 = 2.76059e-05 loss)
I0529 02:43:43.907019 11123 sgd_solver.cpp:105] Iteration 97200, lr = 0.00514
I0529 02:44:11.906251 11123 solver.cpp:218] Iteration 97300 (3.5716 iter/s, 27.9986s/100 iters), loss = 0.000135035
I0529 02:44:11.906486 11123 solver.cpp:237]     Train net output #0: loss = 0.000134047 (* 1 = 0.000134047 loss)
I0529 02:44:11.906497 11123 sgd_solver.cpp:105] Iteration 97300, lr = 0.005135
I0529 02:44:39.905680 11123 solver.cpp:218] Iteration 97400 (3.57161 iter/s, 27.9986s/100 iters), loss = 0.000847464
I0529 02:44:39.905725 11123 solver.cpp:237]     Train net output #0: loss = 0.000846482 (* 1 = 0.000846482 loss)
I0529 02:44:39.905735 11123 sgd_solver.cpp:105] Iteration 97400, lr = 0.00513
I0529 02:44:48.602385 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:45:07.919941 11123 solver.cpp:218] Iteration 97500 (3.56969 iter/s, 28.0136s/100 iters), loss = 0.000216202
I0529 02:45:07.919984 11123 solver.cpp:237]     Train net output #0: loss = 0.000215218 (* 1 = 0.000215218 loss)
I0529 02:45:07.919993 11123 sgd_solver.cpp:105] Iteration 97500, lr = 0.005125
I0529 02:45:35.926131 11123 solver.cpp:218] Iteration 97600 (3.57072 iter/s, 28.0055s/100 iters), loss = 1.64006e-06
I0529 02:45:35.926342 11123 solver.cpp:237]     Train net output #0: loss = 6.55652e-07 (* 1 = 6.55652e-07 loss)
I0529 02:45:35.926352 11123 sgd_solver.cpp:105] Iteration 97600, lr = 0.00512
I0529 02:46:03.910322 11123 solver.cpp:218] Iteration 97700 (3.57355 iter/s, 27.9834s/100 iters), loss = 0.00279077
I0529 02:46:03.910367 11123 solver.cpp:237]     Train net output #0: loss = 0.00278979 (* 1 = 0.00278979 loss)
I0529 02:46:03.910375 11123 sgd_solver.cpp:105] Iteration 97700, lr = 0.005115
I0529 02:46:31.880800 11123 solver.cpp:218] Iteration 97800 (3.57528 iter/s, 27.9698s/100 iters), loss = 8.66043e-06
I0529 02:46:31.880985 11123 solver.cpp:237]     Train net output #0: loss = 7.67736e-06 (* 1 = 7.67736e-06 loss)
I0529 02:46:31.880996 11123 sgd_solver.cpp:105] Iteration 97800, lr = 0.00511
I0529 02:46:59.886852 11123 solver.cpp:218] Iteration 97900 (3.57076 iter/s, 28.0053s/100 iters), loss = 0.00158156
I0529 02:46:59.886898 11123 solver.cpp:237]     Train net output #0: loss = 0.00158057 (* 1 = 0.00158057 loss)
I0529 02:46:59.886905 11123 sgd_solver.cpp:105] Iteration 97900, lr = 0.005105
I0529 02:47:27.621078 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_98000.caffemodel
I0529 02:47:27.938133 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_98000.solverstate
I0529 02:47:28.084368 11123 solver.cpp:330] Iteration 98000, Testing net (#0)
I0529 02:47:32.533610 11123 solver.cpp:397]     Test net output #0: accuracy = 0.926
I0529 02:47:32.533663 11123 solver.cpp:397]     Test net output #1: loss = 0.287162 (* 1 = 0.287162 loss)
I0529 02:47:32.810564 11123 solver.cpp:218] Iteration 98000 (3.03739 iter/s, 32.923s/100 iters), loss = 0.000518646
I0529 02:47:32.810616 11123 solver.cpp:237]     Train net output #0: loss = 0.000517657 (* 1 = 0.000517657 loss)
I0529 02:47:32.810626 11123 sgd_solver.cpp:105] Iteration 98000, lr = 0.0051
I0529 02:47:44.878919 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:48:00.841517 11123 solver.cpp:218] Iteration 98100 (3.56757 iter/s, 28.0303s/100 iters), loss = 0.00305194
I0529 02:48:00.841681 11123 solver.cpp:237]     Train net output #0: loss = 0.00305095 (* 1 = 0.00305095 loss)
I0529 02:48:00.841692 11123 sgd_solver.cpp:105] Iteration 98100, lr = 0.005095
I0529 02:48:28.867636 11123 solver.cpp:218] Iteration 98200 (3.5682 iter/s, 28.0253s/100 iters), loss = 0.168218
I0529 02:48:28.867683 11123 solver.cpp:237]     Train net output #0: loss = 0.168217 (* 1 = 0.168217 loss)
I0529 02:48:28.867691 11123 sgd_solver.cpp:105] Iteration 98200, lr = 0.00509
I0529 02:48:56.860736 11123 solver.cpp:218] Iteration 98300 (3.57239 iter/s, 27.9924s/100 iters), loss = 0.000758125
I0529 02:48:56.860968 11123 solver.cpp:237]     Train net output #0: loss = 0.000757138 (* 1 = 0.000757138 loss)
I0529 02:48:56.860981 11123 sgd_solver.cpp:105] Iteration 98300, lr = 0.005085
I0529 02:49:24.919631 11123 solver.cpp:218] Iteration 98400 (3.56404 iter/s, 28.0581s/100 iters), loss = 0.000410453
I0529 02:49:24.919685 11123 solver.cpp:237]     Train net output #0: loss = 0.00040946 (* 1 = 0.00040946 loss)
I0529 02:49:24.919695 11123 sgd_solver.cpp:105] Iteration 98400, lr = 0.00508
I0529 02:49:52.956151 11123 solver.cpp:218] Iteration 98500 (3.56686 iter/s, 28.0358s/100 iters), loss = 3.5171e-05
I0529 02:49:52.956279 11123 solver.cpp:237]     Train net output #0: loss = 3.41899e-05 (* 1 = 3.41899e-05 loss)
I0529 02:49:52.956291 11123 sgd_solver.cpp:105] Iteration 98500, lr = 0.005075
I0529 02:50:20.965428 11123 solver.cpp:218] Iteration 98600 (3.57034 iter/s, 28.0085s/100 iters), loss = 0.00221003
I0529 02:50:20.965472 11123 solver.cpp:237]     Train net output #0: loss = 0.00220904 (* 1 = 0.00220904 loss)
I0529 02:50:20.965482 11123 sgd_solver.cpp:105] Iteration 98600, lr = 0.00507
I0529 02:50:36.663754 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:50:48.972636 11123 solver.cpp:218] Iteration 98700 (3.57059 iter/s, 28.0066s/100 iters), loss = 0.000133693
I0529 02:50:48.972681 11123 solver.cpp:237]     Train net output #0: loss = 0.000132719 (* 1 = 0.000132719 loss)
I0529 02:50:48.972689 11123 sgd_solver.cpp:105] Iteration 98700, lr = 0.005065
I0529 02:51:16.973601 11123 solver.cpp:218] Iteration 98800 (3.57139 iter/s, 28.0003s/100 iters), loss = 0.00988571
I0529 02:51:16.973775 11123 solver.cpp:237]     Train net output #0: loss = 0.00988474 (* 1 = 0.00988474 loss)
I0529 02:51:16.973788 11123 sgd_solver.cpp:105] Iteration 98800, lr = 0.00506
I0529 02:51:44.964525 11123 solver.cpp:218] Iteration 98900 (3.57269 iter/s, 27.9901s/100 iters), loss = 0.000889843
I0529 02:51:44.964570 11123 solver.cpp:237]     Train net output #0: loss = 0.000888874 (* 1 = 0.000888874 loss)
I0529 02:51:44.964579 11123 sgd_solver.cpp:105] Iteration 98900, lr = 0.005055
I0529 02:52:12.677306 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_99000.caffemodel
I0529 02:52:13.132311 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_99000.solverstate
I0529 02:52:13.278770 11123 solver.cpp:330] Iteration 99000, Testing net (#0)
I0529 02:52:13.509073 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:52:17.727461 11123 solver.cpp:397]     Test net output #0: accuracy = 0.917001
I0529 02:52:17.727514 11123 solver.cpp:397]     Test net output #1: loss = 0.317908 (* 1 = 0.317908 loss)
I0529 02:52:18.004144 11123 solver.cpp:218] Iteration 99000 (3.02674 iter/s, 33.0389s/100 iters), loss = 0.0273676
I0529 02:52:18.004201 11123 solver.cpp:237]     Train net output #0: loss = 0.0273667 (* 1 = 0.0273667 loss)
I0529 02:52:18.004210 11123 sgd_solver.cpp:105] Iteration 99000, lr = 0.00505
I0529 02:52:45.999889 11123 solver.cpp:218] Iteration 99100 (3.57206 iter/s, 27.9951s/100 iters), loss = 0.000177609
I0529 02:52:46.000056 11123 solver.cpp:237]     Train net output #0: loss = 0.000176658 (* 1 = 0.000176658 loss)
I0529 02:52:46.000068 11123 sgd_solver.cpp:105] Iteration 99100, lr = 0.005045
I0529 02:53:13.996289 11123 solver.cpp:218] Iteration 99200 (3.57199 iter/s, 27.9956s/100 iters), loss = 0.00221069
I0529 02:53:13.996331 11123 solver.cpp:237]     Train net output #0: loss = 0.00220973 (* 1 = 0.00220973 loss)
I0529 02:53:13.996340 11123 sgd_solver.cpp:105] Iteration 99200, lr = 0.00504
I0529 02:53:33.334482 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:53:41.990392 11123 solver.cpp:218] Iteration 99300 (3.57226 iter/s, 27.9935s/100 iters), loss = 0.00397929
I0529 02:53:41.990435 11123 solver.cpp:237]     Train net output #0: loss = 0.00397833 (* 1 = 0.00397833 loss)
I0529 02:53:41.990443 11123 sgd_solver.cpp:105] Iteration 99300, lr = 0.005035
I0529 02:54:09.956743 11123 solver.cpp:218] Iteration 99400 (3.57581 iter/s, 27.9657s/100 iters), loss = 0.00243241
I0529 02:54:09.956897 11123 solver.cpp:237]     Train net output #0: loss = 0.00243146 (* 1 = 0.00243146 loss)
I0529 02:54:09.956910 11123 sgd_solver.cpp:105] Iteration 99400, lr = 0.00503
I0529 02:54:37.941957 11123 solver.cpp:218] Iteration 99500 (3.57341 iter/s, 27.9845s/100 iters), loss = 0.000232479
I0529 02:54:37.942010 11123 solver.cpp:237]     Train net output #0: loss = 0.000231525 (* 1 = 0.000231525 loss)
I0529 02:54:37.942019 11123 sgd_solver.cpp:105] Iteration 99500, lr = 0.005025
I0529 02:55:05.928355 11123 solver.cpp:218] Iteration 99600 (3.57325 iter/s, 27.9857s/100 iters), loss = 0.000250601
I0529 02:55:05.928499 11123 solver.cpp:237]     Train net output #0: loss = 0.000249646 (* 1 = 0.000249646 loss)
I0529 02:55:05.928508 11123 sgd_solver.cpp:105] Iteration 99600, lr = 0.00502
I0529 02:55:33.907227 11123 solver.cpp:218] Iteration 99700 (3.57422 iter/s, 27.9781s/100 iters), loss = 0.000956985
I0529 02:55:33.907285 11123 solver.cpp:237]     Train net output #0: loss = 0.000956028 (* 1 = 0.000956028 loss)
I0529 02:55:33.907295 11123 sgd_solver.cpp:105] Iteration 99700, lr = 0.005015
I0529 02:56:01.889729 11123 solver.cpp:218] Iteration 99800 (3.57375 iter/s, 27.9818s/100 iters), loss = 0.00649523
I0529 02:56:01.889881 11123 solver.cpp:237]     Train net output #0: loss = 0.00649428 (* 1 = 0.00649428 loss)
I0529 02:56:01.889894 11123 sgd_solver.cpp:105] Iteration 99800, lr = 0.00501
I0529 02:56:24.842248 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:56:29.859190 11123 solver.cpp:218] Iteration 99900 (3.57542 iter/s, 27.9687s/100 iters), loss = 0.000106326
I0529 02:56:29.859231 11123 solver.cpp:237]     Train net output #0: loss = 0.000105373 (* 1 = 0.000105373 loss)
I0529 02:56:29.859241 11123 sgd_solver.cpp:105] Iteration 99900, lr = 0.005005
I0529 02:56:57.565070 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_100000.caffemodel
I0529 02:56:58.177768 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_100000.solverstate
I0529 02:56:58.326236 11123 solver.cpp:330] Iteration 100000, Testing net (#0)
I0529 02:57:00.069907 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:57:02.790635 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 02:57:02.790676 11123 solver.cpp:397]     Test net output #1: loss = 0.240417 (* 1 = 0.240417 loss)
I0529 02:57:03.067422 11123 solver.cpp:218] Iteration 100000 (3.01137 iter/s, 33.2075s/100 iters), loss = 3.76751e-05
I0529 02:57:03.067478 11123 solver.cpp:237]     Train net output #0: loss = 3.67216e-05 (* 1 = 3.67216e-05 loss)
I0529 02:57:03.067487 11123 sgd_solver.cpp:105] Iteration 100000, lr = 0.005
I0529 02:57:31.096684 11123 solver.cpp:218] Iteration 100100 (3.56778 iter/s, 28.0286s/100 iters), loss = 0.00125601
I0529 02:57:31.096840 11123 solver.cpp:237]     Train net output #0: loss = 0.00125505 (* 1 = 0.00125505 loss)
I0529 02:57:31.096853 11123 sgd_solver.cpp:105] Iteration 100100, lr = 0.004995
I0529 02:57:59.104617 11123 solver.cpp:218] Iteration 100200 (3.57051 iter/s, 28.0072s/100 iters), loss = 3.76715e-05
I0529 02:57:59.104662 11123 solver.cpp:237]     Train net output #0: loss = 3.67185e-05 (* 1 = 3.67185e-05 loss)
I0529 02:57:59.104671 11123 sgd_solver.cpp:105] Iteration 100200, lr = 0.00499
I0529 02:58:27.127643 11123 solver.cpp:218] Iteration 100300 (3.56858 iter/s, 28.0224s/100 iters), loss = 0.0058257
I0529 02:58:27.127821 11123 solver.cpp:237]     Train net output #0: loss = 0.00582474 (* 1 = 0.00582474 loss)
I0529 02:58:27.127838 11123 sgd_solver.cpp:105] Iteration 100300, lr = 0.004985
I0529 02:58:55.126555 11123 solver.cpp:218] Iteration 100400 (3.57167 iter/s, 27.9981s/100 iters), loss = 6.05406e-06
I0529 02:58:55.126612 11123 solver.cpp:237]     Train net output #0: loss = 5.09632e-06 (* 1 = 5.09632e-06 loss)
I0529 02:58:55.126622 11123 sgd_solver.cpp:105] Iteration 100400, lr = 0.00498
I0529 02:59:21.731209 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:59:23.118959 11123 solver.cpp:218] Iteration 100500 (3.57248 iter/s, 27.9917s/100 iters), loss = 0.000235596
I0529 02:59:23.119006 11123 solver.cpp:237]     Train net output #0: loss = 0.000234641 (* 1 = 0.000234641 loss)
I0529 02:59:23.119015 11123 sgd_solver.cpp:105] Iteration 100500, lr = 0.004975
I0529 02:59:51.124933 11123 solver.cpp:218] Iteration 100600 (3.57075 iter/s, 28.0053s/100 iters), loss = 0.000161939
I0529 02:59:51.125000 11123 solver.cpp:237]     Train net output #0: loss = 0.000160984 (* 1 = 0.000160984 loss)
I0529 02:59:51.125010 11123 sgd_solver.cpp:105] Iteration 100600, lr = 0.00497
I0529 03:00:19.130149 11123 solver.cpp:218] Iteration 100700 (3.57085 iter/s, 28.0045s/100 iters), loss = 9.05472e-06
I0529 03:00:19.130331 11123 solver.cpp:237]     Train net output #0: loss = 8.10057e-06 (* 1 = 8.10057e-06 loss)
I0529 03:00:19.130342 11123 sgd_solver.cpp:105] Iteration 100700, lr = 0.004965
I0529 03:00:47.132035 11123 solver.cpp:218] Iteration 100800 (3.57129 iter/s, 28.0011s/100 iters), loss = 3.67118e-05
I0529 03:00:47.132082 11123 solver.cpp:237]     Train net output #0: loss = 3.57586e-05 (* 1 = 3.57586e-05 loss)
I0529 03:00:47.132091 11123 sgd_solver.cpp:105] Iteration 100800, lr = 0.00496
I0529 03:01:15.136433 11123 solver.cpp:218] Iteration 100900 (3.57095 iter/s, 28.0037s/100 iters), loss = 6.51707e-05
I0529 03:01:15.136623 11123 solver.cpp:237]     Train net output #0: loss = 6.42189e-05 (* 1 = 6.42189e-05 loss)
I0529 03:01:15.136638 11123 sgd_solver.cpp:105] Iteration 100900, lr = 0.004955
I0529 03:01:42.829169 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_101000.caffemodel
I0529 03:01:43.426940 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_101000.solverstate
I0529 03:01:43.573819 11123 solver.cpp:330] Iteration 101000, Testing net (#0)
I0529 03:01:46.820922 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:01:48.018779 11123 solver.cpp:397]     Test net output #0: accuracy = 0.936001
I0529 03:01:48.018831 11123 solver.cpp:397]     Test net output #1: loss = 0.289243 (* 1 = 0.289243 loss)
I0529 03:01:48.295473 11123 solver.cpp:218] Iteration 101000 (3.01585 iter/s, 33.1582s/100 iters), loss = 1.6188e-05
I0529 03:01:48.295529 11123 solver.cpp:237]     Train net output #0: loss = 1.52359e-05 (* 1 = 1.52359e-05 loss)
I0529 03:01:48.295538 11123 sgd_solver.cpp:105] Iteration 101000, lr = 0.00495
I0529 03:02:16.313925 11123 solver.cpp:218] Iteration 101100 (3.56915 iter/s, 28.0179s/100 iters), loss = 0.000515723
I0529 03:02:16.313982 11123 solver.cpp:237]     Train net output #0: loss = 0.000514771 (* 1 = 0.000514771 loss)
I0529 03:02:16.313992 11123 sgd_solver.cpp:105] Iteration 101100, lr = 0.004945
I0529 03:02:18.296324 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:02:44.310080 11123 solver.cpp:218] Iteration 101200 (3.57199 iter/s, 27.9956s/100 iters), loss = 9.79928e-05
I0529 03:02:44.310132 11123 solver.cpp:237]     Train net output #0: loss = 9.70443e-05 (* 1 = 9.70443e-05 loss)
I0529 03:02:44.310140 11123 sgd_solver.cpp:105] Iteration 101200, lr = 0.00494
I0529 03:03:12.296845 11123 solver.cpp:218] Iteration 101300 (3.57319 iter/s, 27.9862s/100 iters), loss = 3.5725e-05
I0529 03:03:12.297118 11123 solver.cpp:237]     Train net output #0: loss = 3.4772e-05 (* 1 = 3.4772e-05 loss)
I0529 03:03:12.297130 11123 sgd_solver.cpp:105] Iteration 101300, lr = 0.004935
I0529 03:03:40.252231 11123 solver.cpp:218] Iteration 101400 (3.57723 iter/s, 27.9546s/100 iters), loss = 0.00016983
I0529 03:03:40.252284 11123 solver.cpp:237]     Train net output #0: loss = 0.00016887 (* 1 = 0.00016887 loss)
I0529 03:03:40.252292 11123 sgd_solver.cpp:105] Iteration 101400, lr = 0.00493
I0529 03:04:08.256397 11123 solver.cpp:218] Iteration 101500 (3.57097 iter/s, 28.0036s/100 iters), loss = 1.99795e-05
I0529 03:04:08.256561 11123 solver.cpp:237]     Train net output #0: loss = 1.90191e-05 (* 1 = 1.90191e-05 loss)
I0529 03:04:08.256572 11123 sgd_solver.cpp:105] Iteration 101500, lr = 0.004925
I0529 03:04:36.270931 11123 solver.cpp:218] Iteration 101600 (3.56966 iter/s, 28.0138s/100 iters), loss = 1.29488e-05
I0529 03:04:36.270980 11123 solver.cpp:237]     Train net output #0: loss = 1.1987e-05 (* 1 = 1.1987e-05 loss)
I0529 03:04:36.270989 11123 sgd_solver.cpp:105] Iteration 101600, lr = 0.00492
I0529 03:05:04.293485 11123 solver.cpp:218] Iteration 101700 (3.56863 iter/s, 28.022s/100 iters), loss = 0.00296485
I0529 03:05:04.293638 11123 solver.cpp:237]     Train net output #0: loss = 0.00296389 (* 1 = 0.00296389 loss)
I0529 03:05:04.293648 11123 sgd_solver.cpp:105] Iteration 101700, lr = 0.004915
I0529 03:05:09.917428 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:05:32.324792 11123 solver.cpp:218] Iteration 101800 (3.56753 iter/s, 28.0306s/100 iters), loss = 8.95362e-05
I0529 03:05:32.324854 11123 solver.cpp:237]     Train net output #0: loss = 8.85643e-05 (* 1 = 8.85643e-05 loss)
I0529 03:05:32.324864 11123 sgd_solver.cpp:105] Iteration 101800, lr = 0.00491
I0529 03:06:00.338193 11123 solver.cpp:218] Iteration 101900 (3.5698 iter/s, 28.0128s/100 iters), loss = 4.34652e-05
I0529 03:06:00.338361 11123 solver.cpp:237]     Train net output #0: loss = 4.24925e-05 (* 1 = 4.24925e-05 loss)
I0529 03:06:00.338373 11123 sgd_solver.cpp:105] Iteration 101900, lr = 0.004905
I0529 03:06:28.063058 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_102000.caffemodel
I0529 03:06:28.608655 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_102000.solverstate
I0529 03:06:28.755681 11123 solver.cpp:330] Iteration 102000, Testing net (#0)
I0529 03:06:33.195289 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 03:06:33.195473 11123 solver.cpp:397]     Test net output #1: loss = 0.260184 (* 1 = 0.260184 loss)
I0529 03:06:33.471792 11123 solver.cpp:218] Iteration 102000 (3.01816 iter/s, 33.1328s/100 iters), loss = 7.67979e-06
I0529 03:06:33.471835 11123 solver.cpp:237]     Train net output #0: loss = 6.71764e-06 (* 1 = 6.71764e-06 loss)
I0529 03:06:33.471844 11123 sgd_solver.cpp:105] Iteration 102000, lr = 0.0049
I0529 03:07:01.479418 11123 solver.cpp:218] Iteration 102100 (3.57053 iter/s, 28.007s/100 iters), loss = 0.000522106
I0529 03:07:01.479463 11123 solver.cpp:237]     Train net output #0: loss = 0.000521143 (* 1 = 0.000521143 loss)
I0529 03:07:01.479472 11123 sgd_solver.cpp:105] Iteration 102100, lr = 0.004895
I0529 03:07:29.473718 11123 solver.cpp:218] Iteration 102200 (3.57223 iter/s, 27.9937s/100 iters), loss = 3.2954e-05
I0529 03:07:29.473920 11123 solver.cpp:237]     Train net output #0: loss = 3.19867e-05 (* 1 = 3.19867e-05 loss)
I0529 03:07:29.473948 11123 sgd_solver.cpp:105] Iteration 102200, lr = 0.00489
I0529 03:07:57.479372 11123 solver.cpp:218] Iteration 102300 (3.5708 iter/s, 28.0049s/100 iters), loss = 8.48569e-05
I0529 03:07:57.479427 11123 solver.cpp:237]     Train net output #0: loss = 8.38734e-05 (* 1 = 8.38734e-05 loss)
I0529 03:07:57.479436 11123 sgd_solver.cpp:105] Iteration 102300, lr = 0.004885
I0529 03:08:06.748692 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:08:25.501005 11123 solver.cpp:218] Iteration 102400 (3.56875 iter/s, 28.021s/100 iters), loss = 3.80403e-05
I0529 03:08:25.501049 11123 solver.cpp:237]     Train net output #0: loss = 3.70564e-05 (* 1 = 3.70564e-05 loss)
I0529 03:08:25.501058 11123 sgd_solver.cpp:105] Iteration 102400, lr = 0.00488
I0529 03:08:53.518038 11123 solver.cpp:218] Iteration 102500 (3.56933 iter/s, 28.0164s/100 iters), loss = 0.000590934
I0529 03:08:53.518265 11123 solver.cpp:237]     Train net output #0: loss = 0.000589953 (* 1 = 0.000589953 loss)
I0529 03:08:53.518276 11123 sgd_solver.cpp:105] Iteration 102500, lr = 0.004875
I0529 03:09:21.554415 11123 solver.cpp:218] Iteration 102600 (3.56689 iter/s, 28.0356s/100 iters), loss = 0.000131994
I0529 03:09:21.554458 11123 solver.cpp:237]     Train net output #0: loss = 0.000131029 (* 1 = 0.000131029 loss)
I0529 03:09:21.554466 11123 sgd_solver.cpp:105] Iteration 102600, lr = 0.00487
I0529 03:09:49.572132 11123 solver.cpp:218] Iteration 102700 (3.56925 iter/s, 28.0171s/100 iters), loss = 0.00010395
I0529 03:09:49.572340 11123 solver.cpp:237]     Train net output #0: loss = 0.000102987 (* 1 = 0.000102987 loss)
I0529 03:09:49.572353 11123 sgd_solver.cpp:105] Iteration 102700, lr = 0.004865
I0529 03:10:17.595803 11123 solver.cpp:218] Iteration 102800 (3.56851 iter/s, 28.0229s/100 iters), loss = 8.03442e-05
I0529 03:10:17.595849 11123 solver.cpp:237]     Train net output #0: loss = 7.93818e-05 (* 1 = 7.93818e-05 loss)
I0529 03:10:17.595857 11123 sgd_solver.cpp:105] Iteration 102800, lr = 0.00486
I0529 03:10:45.614482 11123 solver.cpp:218] Iteration 102900 (3.56912 iter/s, 28.0181s/100 iters), loss = 0.00179723
I0529 03:10:45.614770 11123 solver.cpp:237]     Train net output #0: loss = 0.00179624 (* 1 = 0.00179624 loss)
I0529 03:10:45.614781 11123 sgd_solver.cpp:105] Iteration 102900, lr = 0.004855
I0529 03:10:58.516621 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:11:13.361258 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_103000.caffemodel
I0529 03:11:13.897634 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_103000.solverstate
I0529 03:11:14.044616 11123 solver.cpp:330] Iteration 103000, Testing net (#0)
I0529 03:11:14.362351 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:11:18.502063 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 03:11:18.502285 11123 solver.cpp:397]     Test net output #1: loss = 0.245311 (* 1 = 0.245311 loss)
I0529 03:11:18.779737 11123 solver.cpp:218] Iteration 103000 (3.01529 iter/s, 33.1643s/100 iters), loss = 2.65813e-05
I0529 03:11:18.779784 11123 solver.cpp:237]     Train net output #0: loss = 2.55903e-05 (* 1 = 2.55903e-05 loss)
I0529 03:11:18.779793 11123 sgd_solver.cpp:105] Iteration 103000, lr = 0.00485
I0529 03:11:46.789636 11123 solver.cpp:218] Iteration 103100 (3.57024 iter/s, 28.0093s/100 iters), loss = 0.000633527
I0529 03:11:46.789680 11123 solver.cpp:237]     Train net output #0: loss = 0.000632537 (* 1 = 0.000632537 loss)
I0529 03:11:46.789700 11123 sgd_solver.cpp:105] Iteration 103100, lr = 0.004845
I0529 03:12:14.791249 11123 solver.cpp:218] Iteration 103200 (3.5713 iter/s, 28.001s/100 iters), loss = 1.02667e-05
I0529 03:12:14.791422 11123 solver.cpp:237]     Train net output #0: loss = 9.27478e-06 (* 1 = 9.27478e-06 loss)
I0529 03:12:14.791434 11123 sgd_solver.cpp:105] Iteration 103200, lr = 0.00484
I0529 03:12:42.768457 11123 solver.cpp:218] Iteration 103300 (3.57443 iter/s, 27.9765s/100 iters), loss = 1.96717e-05
I0529 03:12:42.768502 11123 solver.cpp:237]     Train net output #0: loss = 1.86693e-05 (* 1 = 1.86693e-05 loss)
I0529 03:12:42.768512 11123 sgd_solver.cpp:105] Iteration 103300, lr = 0.004835
I0529 03:13:10.767660 11123 solver.cpp:218] Iteration 103400 (3.57161 iter/s, 27.9986s/100 iters), loss = 6.89706e-05
I0529 03:13:10.768084 11123 solver.cpp:237]     Train net output #0: loss = 6.7968e-05 (* 1 = 6.7968e-05 loss)
I0529 03:13:10.768095 11123 sgd_solver.cpp:105] Iteration 103400, lr = 0.00483
I0529 03:13:38.747512 11123 solver.cpp:218] Iteration 103500 (3.57413 iter/s, 27.9789s/100 iters), loss = 5.16429e-05
I0529 03:13:38.747560 11123 solver.cpp:237]     Train net output #0: loss = 5.06644e-05 (* 1 = 5.06644e-05 loss)
I0529 03:13:38.747570 11123 sgd_solver.cpp:105] Iteration 103500, lr = 0.004825
I0529 03:13:55.254950 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:14:06.720382 11123 solver.cpp:218] Iteration 103600 (3.57497 iter/s, 27.9722s/100 iters), loss = 2.46942e-05
I0529 03:14:06.720438 11123 solver.cpp:237]     Train net output #0: loss = 2.37221e-05 (* 1 = 2.37221e-05 loss)
I0529 03:14:06.720448 11123 sgd_solver.cpp:105] Iteration 103600, lr = 0.00482
I0529 03:14:34.694399 11123 solver.cpp:218] Iteration 103700 (3.57483 iter/s, 27.9734s/100 iters), loss = 0.00012114
I0529 03:14:34.694582 11123 solver.cpp:237]     Train net output #0: loss = 0.000120178 (* 1 = 0.000120178 loss)
I0529 03:14:34.694605 11123 sgd_solver.cpp:105] Iteration 103700, lr = 0.004815
I0529 03:15:02.708787 11123 solver.cpp:218] Iteration 103800 (3.56969 iter/s, 28.0136s/100 iters), loss = 0.00220259
I0529 03:15:02.708839 11123 solver.cpp:237]     Train net output #0: loss = 0.00220163 (* 1 = 0.00220163 loss)
I0529 03:15:02.708849 11123 sgd_solver.cpp:105] Iteration 103800, lr = 0.00481
I0529 03:15:30.719804 11123 solver.cpp:218] Iteration 103900 (3.5701 iter/s, 28.0104s/100 iters), loss = 0.00477348
I0529 03:15:30.719987 11123 solver.cpp:237]     Train net output #0: loss = 0.00477252 (* 1 = 0.00477252 loss)
I0529 03:15:30.720000 11123 sgd_solver.cpp:105] Iteration 103900, lr = 0.004805
I0529 03:15:58.460398 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_104000.caffemodel
I0529 03:15:58.992952 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_104000.solverstate
I0529 03:15:59.138944 11123 solver.cpp:330] Iteration 104000, Testing net (#0)
I0529 03:16:00.977062 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:16:03.600258 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 03:16:03.600306 11123 solver.cpp:397]     Test net output #1: loss = 0.251443 (* 1 = 0.251443 loss)
I0529 03:16:03.877550 11123 solver.cpp:218] Iteration 104000 (3.01596 iter/s, 33.1569s/100 iters), loss = 0.000722011
I0529 03:16:03.877605 11123 solver.cpp:237]     Train net output #0: loss = 0.000721051 (* 1 = 0.000721051 loss)
I0529 03:16:03.877615 11123 sgd_solver.cpp:105] Iteration 104000, lr = 0.0048
I0529 03:16:31.832691 11123 solver.cpp:218] Iteration 104100 (3.57724 iter/s, 27.9545s/100 iters), loss = 0.00543845
I0529 03:16:31.832885 11123 solver.cpp:237]     Train net output #0: loss = 0.00543749 (* 1 = 0.00543749 loss)
I0529 03:16:31.832897 11123 sgd_solver.cpp:105] Iteration 104100, lr = 0.004795
I0529 03:16:51.702911 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:16:59.812427 11123 solver.cpp:218] Iteration 104200 (3.57411 iter/s, 27.979s/100 iters), loss = 0.00011162
I0529 03:16:59.812467 11123 solver.cpp:237]     Train net output #0: loss = 0.000110663 (* 1 = 0.000110663 loss)
I0529 03:16:59.812476 11123 sgd_solver.cpp:105] Iteration 104200, lr = 0.00479
I0529 03:17:27.856575 11123 solver.cpp:218] Iteration 104300 (3.56589 iter/s, 28.0435s/100 iters), loss = 3.23204e-06
I0529 03:17:27.856745 11123 solver.cpp:237]     Train net output #0: loss = 2.27691e-06 (* 1 = 2.27691e-06 loss)
I0529 03:17:27.856756 11123 sgd_solver.cpp:105] Iteration 104300, lr = 0.004785
I0529 03:17:55.877966 11123 solver.cpp:218] Iteration 104400 (3.5688 iter/s, 28.0206s/100 iters), loss = 0.00408169
I0529 03:17:55.878010 11123 solver.cpp:237]     Train net output #0: loss = 0.00408074 (* 1 = 0.00408074 loss)
I0529 03:17:55.878020 11123 sgd_solver.cpp:105] Iteration 104400, lr = 0.00478
I0529 03:18:23.885867 11123 solver.cpp:218] Iteration 104500 (3.5705 iter/s, 28.0073s/100 iters), loss = 7.71875e-05
I0529 03:18:23.886040 11123 solver.cpp:237]     Train net output #0: loss = 7.625e-05 (* 1 = 7.625e-05 loss)
I0529 03:18:23.886055 11123 sgd_solver.cpp:105] Iteration 104500, lr = 0.004775
I0529 03:18:51.857344 11123 solver.cpp:218] Iteration 104600 (3.57517 iter/s, 27.9707s/100 iters), loss = 8.00067e-05
I0529 03:18:51.857391 11123 solver.cpp:237]     Train net output #0: loss = 7.90666e-05 (* 1 = 7.90666e-05 loss)
I0529 03:18:51.857399 11123 sgd_solver.cpp:105] Iteration 104600, lr = 0.00477
I0529 03:19:19.870733 11123 solver.cpp:218] Iteration 104700 (3.5698 iter/s, 28.0128s/100 iters), loss = 0.0911135
I0529 03:19:19.870939 11123 solver.cpp:237]     Train net output #0: loss = 0.0911126 (* 1 = 0.0911126 loss)
I0529 03:19:19.870950 11123 sgd_solver.cpp:105] Iteration 104700, lr = 0.004765
I0529 03:19:43.411563 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:19:47.873422 11123 solver.cpp:218] Iteration 104800 (3.57119 iter/s, 28.0019s/100 iters), loss = 0.000323302
I0529 03:19:47.873467 11123 solver.cpp:237]     Train net output #0: loss = 0.000322378 (* 1 = 0.000322378 loss)
I0529 03:19:47.873476 11123 sgd_solver.cpp:105] Iteration 104800, lr = 0.00476
I0529 03:20:15.890379 11123 solver.cpp:218] Iteration 104900 (3.56935 iter/s, 28.0163s/100 iters), loss = 9.55459e-05
I0529 03:20:15.890586 11123 solver.cpp:237]     Train net output #0: loss = 9.46222e-05 (* 1 = 9.46222e-05 loss)
I0529 03:20:15.890599 11123 sgd_solver.cpp:105] Iteration 104900, lr = 0.004755
I0529 03:20:43.619946 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_105000.caffemodel
I0529 03:20:44.391861 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_105000.solverstate
I0529 03:20:44.539155 11123 solver.cpp:330] Iteration 105000, Testing net (#0)
I0529 03:20:47.873550 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:20:48.981853 11123 solver.cpp:397]     Test net output #0: accuracy = 0.922
I0529 03:20:48.981889 11123 solver.cpp:397]     Test net output #1: loss = 0.310133 (* 1 = 0.310133 loss)
I0529 03:20:49.259083 11123 solver.cpp:218] Iteration 105000 (2.9969 iter/s, 33.3678s/100 iters), loss = 0.000119698
I0529 03:20:49.259124 11123 solver.cpp:237]     Train net output #0: loss = 0.000118772 (* 1 = 0.000118772 loss)
I0529 03:20:49.259133 11123 sgd_solver.cpp:105] Iteration 105000, lr = 0.00475
I0529 03:21:17.243401 11123 solver.cpp:218] Iteration 105100 (3.57351 iter/s, 27.9837s/100 iters), loss = 0.00348818
I0529 03:21:17.243443 11123 solver.cpp:237]     Train net output #0: loss = 0.00348727 (* 1 = 0.00348727 loss)
I0529 03:21:17.243451 11123 sgd_solver.cpp:105] Iteration 105100, lr = 0.004745
I0529 03:21:45.221644 11123 solver.cpp:218] Iteration 105200 (3.57429 iter/s, 27.9776s/100 iters), loss = 0.000563046
I0529 03:21:45.221842 11123 solver.cpp:237]     Train net output #0: loss = 0.000562136 (* 1 = 0.000562136 loss)
I0529 03:21:45.221853 11123 sgd_solver.cpp:105] Iteration 105200, lr = 0.00474
I0529 03:22:13.229936 11123 solver.cpp:218] Iteration 105300 (3.57047 iter/s, 28.0075s/100 iters), loss = 0.000618233
I0529 03:22:13.229980 11123 solver.cpp:237]     Train net output #0: loss = 0.000617322 (* 1 = 0.000617322 loss)
I0529 03:22:13.229988 11123 sgd_solver.cpp:105] Iteration 105300, lr = 0.004735
I0529 03:22:40.402127 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:22:41.229238 11123 solver.cpp:218] Iteration 105400 (3.5716 iter/s, 27.9987s/100 iters), loss = 2.85256e-06
I0529 03:22:41.229281 11123 solver.cpp:237]     Train net output #0: loss = 1.94312e-06 (* 1 = 1.94312e-06 loss)
I0529 03:22:41.229290 11123 sgd_solver.cpp:105] Iteration 105400, lr = 0.00473
I0529 03:23:09.212035 11123 solver.cpp:218] Iteration 105500 (3.57371 iter/s, 27.9822s/100 iters), loss = 2.43221e-05
I0529 03:23:09.212081 11123 solver.cpp:237]     Train net output #0: loss = 2.3414e-05 (* 1 = 2.3414e-05 loss)
I0529 03:23:09.212090 11123 sgd_solver.cpp:105] Iteration 105500, lr = 0.004725
I0529 03:23:37.207021 11123 solver.cpp:218] Iteration 105600 (3.57215 iter/s, 27.9944s/100 iters), loss = 0.000641614
I0529 03:23:37.207183 11123 solver.cpp:237]     Train net output #0: loss = 0.0006407 (* 1 = 0.0006407 loss)
I0529 03:23:37.207195 11123 sgd_solver.cpp:105] Iteration 105600, lr = 0.00472
I0529 03:24:05.212710 11123 solver.cpp:218] Iteration 105700 (3.5708 iter/s, 28.0049s/100 iters), loss = 0.000146618
I0529 03:24:05.212767 11123 solver.cpp:237]     Train net output #0: loss = 0.000145734 (* 1 = 0.000145734 loss)
I0529 03:24:05.212776 11123 sgd_solver.cpp:105] Iteration 105700, lr = 0.004715
I0529 03:24:33.206357 11123 solver.cpp:218] Iteration 105800 (3.57232 iter/s, 27.993s/100 iters), loss = 0.000987882
I0529 03:24:33.206516 11123 solver.cpp:237]     Train net output #0: loss = 0.000986998 (* 1 = 0.000986998 loss)
I0529 03:24:33.206527 11123 sgd_solver.cpp:105] Iteration 105800, lr = 0.00471
I0529 03:25:01.225013 11123 solver.cpp:218] Iteration 105900 (3.56915 iter/s, 28.0179s/100 iters), loss = 0.00019077
I0529 03:25:01.225055 11123 solver.cpp:237]     Train net output #0: loss = 0.000189892 (* 1 = 0.000189892 loss)
I0529 03:25:01.225064 11123 sgd_solver.cpp:105] Iteration 105900, lr = 0.004705
I0529 03:25:28.960199 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_106000.caffemodel
I0529 03:25:29.563138 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_106000.solverstate
I0529 03:25:29.711325 11123 solver.cpp:330] Iteration 106000, Testing net (#0)
I0529 03:25:34.161531 11123 solver.cpp:397]     Test net output #0: accuracy = 0.950001
I0529 03:25:34.161573 11123 solver.cpp:397]     Test net output #1: loss = 0.202012 (* 1 = 0.202012 loss)
I0529 03:25:34.439651 11123 solver.cpp:218] Iteration 106000 (3.01079 iter/s, 33.2139s/100 iters), loss = 0.000787049
I0529 03:25:34.439710 11123 solver.cpp:237]     Train net output #0: loss = 0.000786169 (* 1 = 0.000786169 loss)
I0529 03:25:34.439734 11123 sgd_solver.cpp:105] Iteration 106000, lr = 0.0047
I0529 03:25:37.255465 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:26:02.436132 11123 solver.cpp:218] Iteration 106100 (3.57196 iter/s, 27.9958s/100 iters), loss = 1.67731e-05
I0529 03:26:02.436336 11123 solver.cpp:237]     Train net output #0: loss = 1.58891e-05 (* 1 = 1.58891e-05 loss)
I0529 03:26:02.436349 11123 sgd_solver.cpp:105] Iteration 106100, lr = 0.004695
I0529 03:26:30.429903 11123 solver.cpp:218] Iteration 106200 (3.57232 iter/s, 27.993s/100 iters), loss = 0.0136647
I0529 03:26:30.429955 11123 solver.cpp:237]     Train net output #0: loss = 0.0136639 (* 1 = 0.0136639 loss)
I0529 03:26:30.429963 11123 sgd_solver.cpp:105] Iteration 106200, lr = 0.00469
I0529 03:26:58.446838 11123 solver.cpp:218] Iteration 106300 (3.56935 iter/s, 28.0163s/100 iters), loss = 0.000210939
I0529 03:26:58.447062 11123 solver.cpp:237]     Train net output #0: loss = 0.000210067 (* 1 = 0.000210067 loss)
I0529 03:26:58.447078 11123 sgd_solver.cpp:105] Iteration 106300, lr = 0.004685
I0529 03:27:26.434876 11123 solver.cpp:218] Iteration 106400 (3.57306 iter/s, 27.9872s/100 iters), loss = 0.00288788
I0529 03:27:26.434936 11123 solver.cpp:237]     Train net output #0: loss = 0.002887 (* 1 = 0.002887 loss)
I0529 03:27:26.434948 11123 sgd_solver.cpp:105] Iteration 106400, lr = 0.00468
I0529 03:27:54.418524 11123 solver.cpp:218] Iteration 106500 (3.5736 iter/s, 27.983s/100 iters), loss = 0.000485922
I0529 03:27:54.418742 11123 solver.cpp:237]     Train net output #0: loss = 0.000485038 (* 1 = 0.000485038 loss)
I0529 03:27:54.418758 11123 sgd_solver.cpp:105] Iteration 106500, lr = 0.004675
I0529 03:28:22.434334 11123 solver.cpp:218] Iteration 106600 (3.56951 iter/s, 28.015s/100 iters), loss = 0.00338287
I0529 03:28:22.434407 11123 solver.cpp:237]     Train net output #0: loss = 0.003382 (* 1 = 0.003382 loss)
I0529 03:28:22.434422 11123 sgd_solver.cpp:105] Iteration 106600, lr = 0.00467
I0529 03:28:28.886873 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:28:50.418445 11123 solver.cpp:218] Iteration 106700 (3.57354 iter/s, 27.9835s/100 iters), loss = 7.16586e-05
I0529 03:28:50.418510 11123 solver.cpp:237]     Train net output #0: loss = 7.0791e-05 (* 1 = 7.0791e-05 loss)
I0529 03:28:50.418520 11123 sgd_solver.cpp:105] Iteration 106700, lr = 0.004665
I0529 03:29:18.427691 11123 solver.cpp:218] Iteration 106800 (3.57033 iter/s, 28.0086s/100 iters), loss = 0.00030862
I0529 03:29:18.427934 11123 solver.cpp:237]     Train net output #0: loss = 0.000307752 (* 1 = 0.000307752 loss)
I0529 03:29:18.427947 11123 sgd_solver.cpp:105] Iteration 106800, lr = 0.00466
I0529 03:29:46.416818 11123 solver.cpp:218] Iteration 106900 (3.57292 iter/s, 27.9883s/100 iters), loss = 0.000341897
I0529 03:29:46.416870 11123 solver.cpp:237]     Train net output #0: loss = 0.000341046 (* 1 = 0.000341046 loss)
I0529 03:29:46.416879 11123 sgd_solver.cpp:105] Iteration 106900, lr = 0.004655
I0529 03:30:14.158607 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_107000.caffemodel
I0529 03:30:14.664116 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_107000.solverstate
I0529 03:30:14.812883 11123 solver.cpp:330] Iteration 107000, Testing net (#0)
I0529 03:30:15.175953 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:30:19.262718 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 03:30:19.262766 11123 solver.cpp:397]     Test net output #1: loss = 0.247883 (* 1 = 0.247883 loss)
I0529 03:30:19.540395 11123 solver.cpp:218] Iteration 107000 (3.01907 iter/s, 33.1228s/100 iters), loss = 0.00024187
I0529 03:30:19.540444 11123 solver.cpp:237]     Train net output #0: loss = 0.000241018 (* 1 = 0.000241018 loss)
I0529 03:30:19.540453 11123 sgd_solver.cpp:105] Iteration 107000, lr = 0.00465
I0529 03:30:47.537989 11123 solver.cpp:218] Iteration 107100 (3.57182 iter/s, 27.9969s/100 iters), loss = 0.00190965
I0529 03:30:47.538156 11123 solver.cpp:237]     Train net output #0: loss = 0.0019088 (* 1 = 0.0019088 loss)
I0529 03:30:47.538166 11123 sgd_solver.cpp:105] Iteration 107100, lr = 0.004645
I0529 03:31:15.553778 11123 solver.cpp:218] Iteration 107200 (3.56951 iter/s, 28.015s/100 iters), loss = 1.48902e-05
I0529 03:31:15.553830 11123 solver.cpp:237]     Train net output #0: loss = 1.40409e-05 (* 1 = 1.40409e-05 loss)
I0529 03:31:15.553839 11123 sgd_solver.cpp:105] Iteration 107200, lr = 0.00464
I0529 03:31:25.377651 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:31:43.573949 11123 solver.cpp:218] Iteration 107300 (3.56894 iter/s, 28.0195s/100 iters), loss = 7.98755e-05
I0529 03:31:43.574012 11123 solver.cpp:237]     Train net output #0: loss = 7.90257e-05 (* 1 = 7.90257e-05 loss)
I0529 03:31:43.574021 11123 sgd_solver.cpp:105] Iteration 107300, lr = 0.004635
I0529 03:32:11.587265 11123 solver.cpp:218] Iteration 107400 (3.56981 iter/s, 28.0127s/100 iters), loss = 2.80439e-06
I0529 03:32:11.587452 11123 solver.cpp:237]     Train net output #0: loss = 1.95506e-06 (* 1 = 1.95506e-06 loss)
I0529 03:32:11.587477 11123 sgd_solver.cpp:105] Iteration 107400, lr = 0.00463
I0529 03:32:39.606003 11123 solver.cpp:218] Iteration 107500 (3.56914 iter/s, 28.018s/100 iters), loss = 0.000669188
I0529 03:32:39.606061 11123 solver.cpp:237]     Train net output #0: loss = 0.000668338 (* 1 = 0.000668338 loss)
I0529 03:32:39.606070 11123 sgd_solver.cpp:105] Iteration 107500, lr = 0.004625
I0529 03:33:07.589715 11123 solver.cpp:218] Iteration 107600 (3.57359 iter/s, 27.9831s/100 iters), loss = 0.000629919
I0529 03:33:07.589882 11123 solver.cpp:237]     Train net output #0: loss = 0.000629071 (* 1 = 0.000629071 loss)
I0529 03:33:07.589895 11123 sgd_solver.cpp:105] Iteration 107600, lr = 0.00462
I0529 03:33:35.590940 11123 solver.cpp:218] Iteration 107700 (3.57137 iter/s, 28.0005s/100 iters), loss = 0.000123548
I0529 03:33:35.590988 11123 solver.cpp:237]     Train net output #0: loss = 0.000122702 (* 1 = 0.000122702 loss)
I0529 03:33:35.590996 11123 sgd_solver.cpp:105] Iteration 107700, lr = 0.004615
I0529 03:34:03.561851 11123 solver.cpp:218] Iteration 107800 (3.57522 iter/s, 27.9703s/100 iters), loss = 6.92925e-06
I0529 03:34:03.561978 11123 solver.cpp:237]     Train net output #0: loss = 6.07978e-06 (* 1 = 6.07978e-06 loss)
I0529 03:34:03.562000 11123 sgd_solver.cpp:105] Iteration 107800, lr = 0.00461
I0529 03:34:17.018806 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:34:31.556704 11123 solver.cpp:218] Iteration 107900 (3.57218 iter/s, 27.9941s/100 iters), loss = 0.000316771
I0529 03:34:31.556749 11123 solver.cpp:237]     Train net output #0: loss = 0.000315921 (* 1 = 0.000315921 loss)
I0529 03:34:31.556757 11123 sgd_solver.cpp:105] Iteration 107900, lr = 0.004605
I0529 03:34:59.276772 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_108000.caffemodel
I0529 03:34:59.739852 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_108000.solverstate
I0529 03:34:59.889477 11123 solver.cpp:330] Iteration 108000, Testing net (#0)
I0529 03:35:01.775030 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:35:04.351435 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 03:35:04.351483 11123 solver.cpp:397]     Test net output #1: loss = 0.225912 (* 1 = 0.225912 loss)
I0529 03:35:04.628921 11123 solver.cpp:218] Iteration 108000 (3.02376 iter/s, 33.0715s/100 iters), loss = 0.000120034
I0529 03:35:04.628998 11123 solver.cpp:237]     Train net output #0: loss = 0.00011919 (* 1 = 0.00011919 loss)
I0529 03:35:04.629011 11123 sgd_solver.cpp:105] Iteration 108000, lr = 0.0046
I0529 03:35:32.638401 11123 solver.cpp:218] Iteration 108100 (3.57031 iter/s, 28.0088s/100 iters), loss = 7.95087e-05
I0529 03:35:32.638558 11123 solver.cpp:237]     Train net output #0: loss = 7.86659e-05 (* 1 = 7.86659e-05 loss)
I0529 03:35:32.638571 11123 sgd_solver.cpp:105] Iteration 108100, lr = 0.004595
I0529 03:36:00.637778 11123 solver.cpp:218] Iteration 108200 (3.57165 iter/s, 27.9982s/100 iters), loss = 9.82796e-05
I0529 03:36:00.637833 11123 solver.cpp:237]     Train net output #0: loss = 9.74363e-05 (* 1 = 9.74363e-05 loss)
I0529 03:36:00.637842 11123 sgd_solver.cpp:105] Iteration 108200, lr = 0.00459
I0529 03:36:28.622153 11123 solver.cpp:218] Iteration 108300 (3.57363 iter/s, 27.9827s/100 iters), loss = 0.00036942
I0529 03:36:28.622352 11123 solver.cpp:237]     Train net output #0: loss = 0.000368577 (* 1 = 0.000368577 loss)
I0529 03:36:28.622388 11123 sgd_solver.cpp:105] Iteration 108300, lr = 0.004585
I0529 03:36:56.598894 11123 solver.cpp:218] Iteration 108400 (3.57462 iter/s, 27.975s/100 iters), loss = 5.49997e-05
I0529 03:36:56.598944 11123 solver.cpp:237]     Train net output #0: loss = 5.4158e-05 (* 1 = 5.4158e-05 loss)
I0529 03:36:56.598953 11123 sgd_solver.cpp:105] Iteration 108400, lr = 0.00458
I0529 03:37:13.693845 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:37:24.604950 11123 solver.cpp:218] Iteration 108500 (3.57085 iter/s, 28.0045s/100 iters), loss = 8.21599e-06
I0529 03:37:24.605010 11123 solver.cpp:237]     Train net output #0: loss = 7.37327e-06 (* 1 = 7.37327e-06 loss)
I0529 03:37:24.605018 11123 sgd_solver.cpp:105] Iteration 108500, lr = 0.004575
I0529 03:37:52.624016 11123 solver.cpp:218] Iteration 108600 (3.56919 iter/s, 28.0175s/100 iters), loss = 0.000316112
I0529 03:37:52.624176 11123 solver.cpp:237]     Train net output #0: loss = 0.00031527 (* 1 = 0.00031527 loss)
I0529 03:37:52.624187 11123 sgd_solver.cpp:105] Iteration 108600, lr = 0.00457
I0529 03:38:20.638268 11123 solver.cpp:218] Iteration 108700 (3.56981 iter/s, 28.0127s/100 iters), loss = 0.00260201
I0529 03:38:20.638325 11123 solver.cpp:237]     Train net output #0: loss = 0.00260117 (* 1 = 0.00260117 loss)
I0529 03:38:20.638335 11123 sgd_solver.cpp:105] Iteration 108700, lr = 0.004565
I0529 03:38:48.642462 11123 solver.cpp:218] Iteration 108800 (3.57108 iter/s, 28.0027s/100 iters), loss = 0.000119165
I0529 03:38:48.642639 11123 solver.cpp:237]     Train net output #0: loss = 0.000118329 (* 1 = 0.000118329 loss)
I0529 03:38:48.642652 11123 sgd_solver.cpp:105] Iteration 108800, lr = 0.00456
I0529 03:39:16.664209 11123 solver.cpp:218] Iteration 108900 (3.56885 iter/s, 28.0202s/100 iters), loss = 0.000118859
I0529 03:39:16.664268 11123 solver.cpp:237]     Train net output #0: loss = 0.000118022 (* 1 = 0.000118022 loss)
I0529 03:39:16.664276 11123 sgd_solver.cpp:105] Iteration 108900, lr = 0.004555
I0529 03:39:44.397907 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_109000.caffemodel
I0529 03:39:44.897125 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_109000.solverstate
I0529 03:39:45.044013 11123 solver.cpp:330] Iteration 109000, Testing net (#0)
I0529 03:39:48.429838 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:39:49.493685 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 03:39:49.493742 11123 solver.cpp:397]     Test net output #1: loss = 0.275849 (* 1 = 0.275849 loss)
I0529 03:39:49.770779 11123 solver.cpp:218] Iteration 109000 (3.0207 iter/s, 33.105s/100 iters), loss = 9.60463e-06
I0529 03:39:49.770824 11123 solver.cpp:237]     Train net output #0: loss = 8.76845e-06 (* 1 = 8.76845e-06 loss)
I0529 03:39:49.770833 11123 sgd_solver.cpp:105] Iteration 109000, lr = 0.00455
I0529 03:40:10.521203 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:40:17.791774 11123 solver.cpp:218] Iteration 109100 (3.56892 iter/s, 28.0197s/100 iters), loss = 0.00109646
I0529 03:40:17.791908 11123 solver.cpp:237]     Train net output #0: loss = 0.00109562 (* 1 = 0.00109562 loss)
I0529 03:40:17.791934 11123 sgd_solver.cpp:105] Iteration 109100, lr = 0.004545
I0529 03:40:45.806910 11123 solver.cpp:218] Iteration 109200 (3.56968 iter/s, 28.0138s/100 iters), loss = 1.62675e-05
I0529 03:40:45.806962 11123 solver.cpp:237]     Train net output #0: loss = 1.54325e-05 (* 1 = 1.54325e-05 loss)
I0529 03:40:45.806975 11123 sgd_solver.cpp:105] Iteration 109200, lr = 0.00454
I0529 03:41:13.848031 11123 solver.cpp:218] Iteration 109300 (3.56635 iter/s, 28.0398s/100 iters), loss = 0.000357253
I0529 03:41:13.848182 11123 solver.cpp:237]     Train net output #0: loss = 0.000356422 (* 1 = 0.000356422 loss)
I0529 03:41:13.848194 11123 sgd_solver.cpp:105] Iteration 109300, lr = 0.004535
I0529 03:41:41.870599 11123 solver.cpp:218] Iteration 109400 (3.56872 iter/s, 28.0212s/100 iters), loss = 3.03484e-05
I0529 03:41:41.870643 11123 solver.cpp:237]     Train net output #0: loss = 2.95182e-05 (* 1 = 2.95182e-05 loss)
I0529 03:41:41.870651 11123 sgd_solver.cpp:105] Iteration 109400, lr = 0.00453
I0529 03:42:09.866694 11123 solver.cpp:218] Iteration 109500 (3.57208 iter/s, 27.9949s/100 iters), loss = 5.3002e-06
I0529 03:42:09.866876 11123 solver.cpp:237]     Train net output #0: loss = 4.47042e-06 (* 1 = 4.47042e-06 loss)
I0529 03:42:09.866888 11123 sgd_solver.cpp:105] Iteration 109500, lr = 0.004525
I0529 03:42:37.861618 11123 solver.cpp:218] Iteration 109600 (3.57225 iter/s, 27.9936s/100 iters), loss = 3.3575e-05
I0529 03:42:37.861680 11123 solver.cpp:237]     Train net output #0: loss = 3.2745e-05 (* 1 = 3.2745e-05 loss)
I0529 03:42:37.861692 11123 sgd_solver.cpp:105] Iteration 109600, lr = 0.00452
I0529 03:43:02.260354 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:43:05.888037 11123 solver.cpp:218] Iteration 109700 (3.56821 iter/s, 28.0252s/100 iters), loss = 1.48544e-05
I0529 03:43:05.888082 11123 solver.cpp:237]     Train net output #0: loss = 1.40258e-05 (* 1 = 1.40258e-05 loss)
I0529 03:43:05.888090 11123 sgd_solver.cpp:105] Iteration 109700, lr = 0.004515
I0529 03:43:33.916224 11123 solver.cpp:218] Iteration 109800 (3.56798 iter/s, 28.027s/100 iters), loss = 2.05767e-05
I0529 03:43:33.916337 11123 solver.cpp:237]     Train net output #0: loss = 1.97481e-05 (* 1 = 1.97481e-05 loss)
I0529 03:43:33.916358 11123 sgd_solver.cpp:105] Iteration 109800, lr = 0.00451
I0529 03:44:01.915191 11123 solver.cpp:218] Iteration 109900 (3.57171 iter/s, 27.9978s/100 iters), loss = 2.08371e-05
I0529 03:44:01.915237 11123 solver.cpp:237]     Train net output #0: loss = 2.00083e-05 (* 1 = 2.00083e-05 loss)
I0529 03:44:01.915246 11123 sgd_solver.cpp:105] Iteration 109900, lr = 0.004505
I0529 03:44:29.641862 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_110000.caffemodel
I0529 03:44:30.010952 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_110000.solverstate
I0529 03:44:30.156779 11123 solver.cpp:330] Iteration 110000, Testing net (#0)
I0529 03:44:34.602612 11123 solver.cpp:397]     Test net output #0: accuracy = 0.958
I0529 03:44:34.602665 11123 solver.cpp:397]     Test net output #1: loss = 0.212584 (* 1 = 0.212584 loss)
I0529 03:44:34.879837 11123 solver.cpp:218] Iteration 110000 (3.03367 iter/s, 32.9633s/100 iters), loss = 7.27608e-05
I0529 03:44:34.879883 11123 solver.cpp:237]     Train net output #0: loss = 7.19328e-05 (* 1 = 7.19328e-05 loss)
I0529 03:44:34.879891 11123 sgd_solver.cpp:105] Iteration 110000, lr = 0.0045
I0529 03:45:02.859139 11123 solver.cpp:218] Iteration 110100 (3.57421 iter/s, 27.9782s/100 iters), loss = 5.08999e-06
I0529 03:45:02.859285 11123 solver.cpp:237]     Train net output #0: loss = 4.26187e-06 (* 1 = 4.26187e-06 loss)
I0529 03:45:02.859297 11123 sgd_solver.cpp:105] Iteration 110100, lr = 0.004495
I0529 03:45:30.852533 11123 solver.cpp:218] Iteration 110200 (3.57242 iter/s, 27.9922s/100 iters), loss = 9.64618e-05
I0529 03:45:30.852581 11123 solver.cpp:237]     Train net output #0: loss = 9.56244e-05 (* 1 = 9.56244e-05 loss)
I0529 03:45:30.852589 11123 sgd_solver.cpp:105] Iteration 110200, lr = 0.00449
I0529 03:45:58.568176 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:45:58.831054 11123 solver.cpp:218] Iteration 110300 (3.57431 iter/s, 27.9774s/100 iters), loss = 1.37709e-05
I0529 03:45:58.831099 11123 solver.cpp:237]     Train net output #0: loss = 1.29347e-05 (* 1 = 1.29347e-05 loss)
I0529 03:45:58.831106 11123 sgd_solver.cpp:105] Iteration 110300, lr = 0.004485
I0529 03:46:26.814157 11123 solver.cpp:218] Iteration 110400 (3.57372 iter/s, 27.982s/100 iters), loss = 0.000169639
I0529 03:46:26.814203 11123 solver.cpp:237]     Train net output #0: loss = 0.000168802 (* 1 = 0.000168802 loss)
I0529 03:46:26.814213 11123 sgd_solver.cpp:105] Iteration 110400, lr = 0.00448
I0529 03:46:54.792556 11123 solver.cpp:218] Iteration 110500 (3.57432 iter/s, 27.9774s/100 iters), loss = 6.89959e-05
I0529 03:46:54.792713 11123 solver.cpp:237]     Train net output #0: loss = 6.81656e-05 (* 1 = 6.81656e-05 loss)
I0529 03:46:54.792724 11123 sgd_solver.cpp:105] Iteration 110500, lr = 0.004475
I0529 03:47:22.798715 11123 solver.cpp:218] Iteration 110600 (3.57079 iter/s, 28.005s/100 iters), loss = 0.000902687
I0529 03:47:22.798761 11123 solver.cpp:237]     Train net output #0: loss = 0.000901852 (* 1 = 0.000901852 loss)
I0529 03:47:22.798770 11123 sgd_solver.cpp:105] Iteration 110600, lr = 0.00447
I0529 03:47:50.774720 11123 solver.cpp:218] Iteration 110700 (3.57462 iter/s, 27.975s/100 iters), loss = 3.09015e-05
I0529 03:47:50.774895 11123 solver.cpp:237]     Train net output #0: loss = 3.00669e-05 (* 1 = 3.00669e-05 loss)
I0529 03:47:50.774906 11123 sgd_solver.cpp:105] Iteration 110700, lr = 0.004465
I0529 03:48:18.776824 11123 solver.cpp:218] Iteration 110800 (3.5713 iter/s, 28.001s/100 iters), loss = 8.74107e-06
I0529 03:48:18.776868 11123 solver.cpp:237]     Train net output #0: loss = 7.90377e-06 (* 1 = 7.90377e-06 loss)
I0529 03:48:18.776877 11123 sgd_solver.cpp:105] Iteration 110800, lr = 0.00446
I0529 03:48:46.769733 11123 solver.cpp:218] Iteration 110900 (3.57246 iter/s, 27.9919s/100 iters), loss = 1.52923e-05
I0529 03:48:46.769857 11123 solver.cpp:237]     Train net output #0: loss = 1.44548e-05 (* 1 = 1.44548e-05 loss)
I0529 03:48:46.769875 11123 sgd_solver.cpp:105] Iteration 110900, lr = 0.004455
I0529 03:48:50.152724 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:49:14.510965 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_111000.caffemodel
I0529 03:49:14.909521 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_111000.solverstate
I0529 03:49:15.056429 11123 solver.cpp:330] Iteration 111000, Testing net (#0)
I0529 03:49:15.508949 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:49:19.509165 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 03:49:19.509356 11123 solver.cpp:397]     Test net output #1: loss = 0.292762 (* 1 = 0.292762 loss)
I0529 03:49:19.785590 11123 solver.cpp:218] Iteration 111000 (3.02896 iter/s, 33.0146s/100 iters), loss = 0.00792249
I0529 03:49:19.785639 11123 solver.cpp:237]     Train net output #0: loss = 0.00792166 (* 1 = 0.00792166 loss)
I0529 03:49:19.785647 11123 sgd_solver.cpp:105] Iteration 111000, lr = 0.00445
I0529 03:49:47.761713 11123 solver.cpp:218] Iteration 111100 (3.5746 iter/s, 27.9751s/100 iters), loss = 0.000237695
I0529 03:49:47.761760 11123 solver.cpp:237]     Train net output #0: loss = 0.000236861 (* 1 = 0.000236861 loss)
I0529 03:49:47.761770 11123 sgd_solver.cpp:105] Iteration 111100, lr = 0.004445
I0529 03:50:15.763099 11123 solver.cpp:218] Iteration 111200 (3.57138 iter/s, 28.0004s/100 iters), loss = 4.1653e-05
I0529 03:50:15.763272 11123 solver.cpp:237]     Train net output #0: loss = 4.08239e-05 (* 1 = 4.08239e-05 loss)
I0529 03:50:15.763286 11123 sgd_solver.cpp:105] Iteration 111200, lr = 0.00444
I0529 03:50:43.754740 11123 solver.cpp:218] Iteration 111300 (3.57263 iter/s, 27.9906s/100 iters), loss = 4.94973e-05
I0529 03:50:43.754796 11123 solver.cpp:237]     Train net output #0: loss = 4.86688e-05 (* 1 = 4.86688e-05 loss)
I0529 03:50:43.754808 11123 sgd_solver.cpp:105] Iteration 111300, lr = 0.004435
I0529 03:51:11.766878 11123 solver.cpp:218] Iteration 111400 (3.57 iter/s, 28.0112s/100 iters), loss = 9.18297e-05
I0529 03:51:11.767050 11123 solver.cpp:237]     Train net output #0: loss = 9.1001e-05 (* 1 = 9.1001e-05 loss)
I0529 03:51:11.767066 11123 sgd_solver.cpp:105] Iteration 111400, lr = 0.00443
I0529 03:51:39.769214 11123 solver.cpp:218] Iteration 111500 (3.57126 iter/s, 28.0013s/100 iters), loss = 8.18106e-05
I0529 03:51:39.769260 11123 solver.cpp:237]     Train net output #0: loss = 8.0985e-05 (* 1 = 8.0985e-05 loss)
I0529 03:51:39.769269 11123 sgd_solver.cpp:105] Iteration 111500, lr = 0.004425
I0529 03:51:46.788202 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:52:07.770992 11123 solver.cpp:218] Iteration 111600 (3.57132 iter/s, 28.0008s/100 iters), loss = 0.000203701
I0529 03:52:07.771039 11123 solver.cpp:237]     Train net output #0: loss = 0.00020288 (* 1 = 0.00020288 loss)
I0529 03:52:07.771047 11123 sgd_solver.cpp:105] Iteration 111600, lr = 0.00442
I0529 03:52:35.760571 11123 solver.cpp:218] Iteration 111700 (3.57288 iter/s, 27.9887s/100 iters), loss = 0.00016035
I0529 03:52:35.760790 11123 solver.cpp:237]     Train net output #0: loss = 0.000159529 (* 1 = 0.000159529 loss)
I0529 03:52:35.760805 11123 sgd_solver.cpp:105] Iteration 111700, lr = 0.004415
I0529 03:53:03.768389 11123 solver.cpp:218] Iteration 111800 (3.57057 iter/s, 28.0067s/100 iters), loss = 6.33525e-05
I0529 03:53:03.768441 11123 solver.cpp:237]     Train net output #0: loss = 6.25329e-05 (* 1 = 6.25329e-05 loss)
I0529 03:53:03.768465 11123 sgd_solver.cpp:105] Iteration 111800, lr = 0.00441
I0529 03:53:31.776613 11123 solver.cpp:218] Iteration 111900 (3.5705 iter/s, 28.0073s/100 iters), loss = 0.00222911
I0529 03:53:31.776845 11123 solver.cpp:237]     Train net output #0: loss = 0.00222829 (* 1 = 0.00222829 loss)
I0529 03:53:31.776875 11123 sgd_solver.cpp:105] Iteration 111900, lr = 0.004405
I0529 03:53:59.497838 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_112000.caffemodel
I0529 03:53:59.818527 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_112000.solverstate
I0529 03:53:59.964390 11123 solver.cpp:330] Iteration 112000, Testing net (#0)
I0529 03:54:01.935806 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:54:04.422446 11123 solver.cpp:397]     Test net output #0: accuracy = 0.934
I0529 03:54:04.422492 11123 solver.cpp:397]     Test net output #1: loss = 0.283462 (* 1 = 0.283462 loss)
I0529 03:54:04.700040 11123 solver.cpp:218] Iteration 112000 (3.03747 iter/s, 32.9222s/100 iters), loss = 0.000585092
I0529 03:54:04.700103 11123 solver.cpp:237]     Train net output #0: loss = 0.000584266 (* 1 = 0.000584266 loss)
I0529 03:54:04.700130 11123 sgd_solver.cpp:105] Iteration 112000, lr = 0.0044
I0529 03:54:32.707499 11123 solver.cpp:218] Iteration 112100 (3.5706 iter/s, 28.0065s/100 iters), loss = 2.10619e-05
I0529 03:54:32.707659 11123 solver.cpp:237]     Train net output #0: loss = 2.02339e-05 (* 1 = 2.02339e-05 loss)
I0529 03:54:32.707674 11123 sgd_solver.cpp:105] Iteration 112100, lr = 0.004395
I0529 03:54:43.361372 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:55:00.698889 11123 solver.cpp:218] Iteration 112200 (3.57266 iter/s, 27.9904s/100 iters), loss = 0.000134263
I0529 03:55:00.698945 11123 solver.cpp:237]     Train net output #0: loss = 0.000133435 (* 1 = 0.000133435 loss)
I0529 03:55:00.698954 11123 sgd_solver.cpp:105] Iteration 112200, lr = 0.00439
I0529 03:55:28.701473 11123 solver.cpp:218] Iteration 112300 (3.57121 iter/s, 28.0017s/100 iters), loss = 1.52505e-06
I0529 03:55:28.701656 11123 solver.cpp:237]     Train net output #0: loss = 6.97377e-07 (* 1 = 6.97377e-07 loss)
I0529 03:55:28.701673 11123 sgd_solver.cpp:105] Iteration 112300, lr = 0.004385
I0529 03:55:56.679173 11123 solver.cpp:218] Iteration 112400 (3.57441 iter/s, 27.9767s/100 iters), loss = 0.00418179
I0529 03:55:56.679230 11123 solver.cpp:237]     Train net output #0: loss = 0.00418097 (* 1 = 0.00418097 loss)
I0529 03:55:56.679239 11123 sgd_solver.cpp:105] Iteration 112400, lr = 0.00438
I0529 03:56:24.660650 11123 solver.cpp:218] Iteration 112500 (3.57391 iter/s, 27.9806s/100 iters), loss = 0.000103974
I0529 03:56:24.660812 11123 solver.cpp:237]     Train net output #0: loss = 0.000103146 (* 1 = 0.000103146 loss)
I0529 03:56:24.660825 11123 sgd_solver.cpp:105] Iteration 112500, lr = 0.004375
I0529 03:56:52.629446 11123 solver.cpp:218] Iteration 112600 (3.57554 iter/s, 27.9678s/100 iters), loss = 0.00377176
I0529 03:56:52.629504 11123 solver.cpp:237]     Train net output #0: loss = 0.00377093 (* 1 = 0.00377093 loss)
I0529 03:56:52.629514 11123 sgd_solver.cpp:105] Iteration 112600, lr = 0.00437
I0529 03:57:20.625134 11123 solver.cpp:218] Iteration 112700 (3.57209 iter/s, 27.9948s/100 iters), loss = 0.00180703
I0529 03:57:20.625329 11123 solver.cpp:237]     Train net output #0: loss = 0.0018062 (* 1 = 0.0018062 loss)
I0529 03:57:20.625341 11123 sgd_solver.cpp:105] Iteration 112700, lr = 0.004365
I0529 03:57:34.902001 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:57:48.599800 11123 solver.cpp:218] Iteration 112800 (3.57479 iter/s, 27.9737s/100 iters), loss = 0.000199317
I0529 03:57:48.599844 11123 solver.cpp:237]     Train net output #0: loss = 0.000198482 (* 1 = 0.000198482 loss)
I0529 03:57:48.599853 11123 sgd_solver.cpp:105] Iteration 112800, lr = 0.00436
I0529 03:58:16.576155 11123 solver.cpp:218] Iteration 112900 (3.57456 iter/s, 27.9755s/100 iters), loss = 0.000295853
I0529 03:58:16.576362 11123 solver.cpp:237]     Train net output #0: loss = 0.000295017 (* 1 = 0.000295017 loss)
I0529 03:58:16.576375 11123 sgd_solver.cpp:105] Iteration 112900, lr = 0.004355
I0529 03:58:44.275265 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_113000.caffemodel
I0529 03:58:44.583753 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_113000.solverstate
I0529 03:58:44.733217 11123 solver.cpp:330] Iteration 113000, Testing net (#0)
I0529 03:58:48.205325 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:58:49.176892 11123 solver.cpp:397]     Test net output #0: accuracy = 0.931
I0529 03:58:49.176934 11123 solver.cpp:397]     Test net output #1: loss = 0.308462 (* 1 = 0.308462 loss)
I0529 03:58:49.452965 11123 solver.cpp:218] Iteration 113000 (3.04176 iter/s, 32.8757s/100 iters), loss = 1.70942e-05
I0529 03:58:49.453006 11123 solver.cpp:237]     Train net output #0: loss = 1.62551e-05 (* 1 = 1.62551e-05 loss)
I0529 03:58:49.453014 11123 sgd_solver.cpp:105] Iteration 113000, lr = 0.00435
I0529 03:59:17.487777 11123 solver.cpp:218] Iteration 113100 (3.5671 iter/s, 28.034s/100 iters), loss = 4.79005e-05
I0529 03:59:17.487819 11123 solver.cpp:237]     Train net output #0: loss = 4.7061e-05 (* 1 = 4.7061e-05 loss)
I0529 03:59:17.487828 11123 sgd_solver.cpp:105] Iteration 113100, lr = 0.004345
I0529 03:59:45.510736 11123 solver.cpp:218] Iteration 113200 (3.56861 iter/s, 28.0221s/100 iters), loss = 0.000208368
I0529 03:59:45.510901 11123 solver.cpp:237]     Train net output #0: loss = 0.00020753 (* 1 = 0.00020753 loss)
I0529 03:59:45.510912 11123 sgd_solver.cpp:105] Iteration 113200, lr = 0.00434
I0529 04:00:13.535049 11123 solver.cpp:218] Iteration 113300 (3.56845 iter/s, 28.0233s/100 iters), loss = 0.0156823
I0529 04:00:13.535109 11123 solver.cpp:237]     Train net output #0: loss = 0.0156815 (* 1 = 0.0156815 loss)
I0529 04:00:13.535118 11123 sgd_solver.cpp:105] Iteration 113300, lr = 0.004335
I0529 04:00:31.210887 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:00:41.560601 11123 solver.cpp:218] Iteration 113400 (3.56829 iter/s, 28.0247s/100 iters), loss = 0.00134981
I0529 04:00:41.560739 11123 solver.cpp:237]     Train net output #0: loss = 0.00134897 (* 1 = 0.00134897 loss)
I0529 04:00:41.560761 11123 sgd_solver.cpp:105] Iteration 113400, lr = 0.00433
I0529 04:01:09.565052 11123 solver.cpp:218] Iteration 113500 (3.57098 iter/s, 28.0035s/100 iters), loss = 0.0781585
I0529 04:01:09.565263 11123 solver.cpp:237]     Train net output #0: loss = 0.0781577 (* 1 = 0.0781577 loss)
I0529 04:01:09.565274 11123 sgd_solver.cpp:105] Iteration 113500, lr = 0.004325
I0529 04:01:37.587210 11123 solver.cpp:218] Iteration 113600 (3.56873 iter/s, 28.0212s/100 iters), loss = 0.000598184
I0529 04:01:37.587255 11123 solver.cpp:237]     Train net output #0: loss = 0.000597337 (* 1 = 0.000597337 loss)
I0529 04:01:37.587263 11123 sgd_solver.cpp:105] Iteration 113600, lr = 0.00432
I0529 04:02:05.592815 11123 solver.cpp:218] Iteration 113700 (3.57082 iter/s, 28.0048s/100 iters), loss = 0.000142048
I0529 04:02:05.593021 11123 solver.cpp:237]     Train net output #0: loss = 0.000141194 (* 1 = 0.000141194 loss)
I0529 04:02:05.593032 11123 sgd_solver.cpp:105] Iteration 113700, lr = 0.004315
I0529 04:02:33.583665 11123 solver.cpp:218] Iteration 113800 (3.57272 iter/s, 27.9899s/100 iters), loss = 0.000474731
I0529 04:02:33.583709 11123 solver.cpp:237]     Train net output #0: loss = 0.000473887 (* 1 = 0.000473887 loss)
I0529 04:02:33.583729 11123 sgd_solver.cpp:105] Iteration 113800, lr = 0.00431
I0529 04:03:01.597738 11123 solver.cpp:218] Iteration 113900 (3.56974 iter/s, 28.0132s/100 iters), loss = 0.00020243
I0529 04:03:01.597988 11123 solver.cpp:237]     Train net output #0: loss = 0.000201582 (* 1 = 0.000201582 loss)
I0529 04:03:01.598000 11123 sgd_solver.cpp:105] Iteration 113900, lr = 0.004305
I0529 04:03:22.908849 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:03:29.340705 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_114000.caffemodel
I0529 04:03:29.691764 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_114000.solverstate
I0529 04:03:29.837426 11123 solver.cpp:330] Iteration 114000, Testing net (#0)
I0529 04:03:34.282376 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 04:03:34.282541 11123 solver.cpp:397]     Test net output #1: loss = 0.231477 (* 1 = 0.231477 loss)
I0529 04:03:34.559314 11123 solver.cpp:218] Iteration 114000 (3.03394 iter/s, 32.9604s/100 iters), loss = 7.08935e-05
I0529 04:03:34.559357 11123 solver.cpp:237]     Train net output #0: loss = 7.00484e-05 (* 1 = 7.00484e-05 loss)
I0529 04:03:34.559366 11123 sgd_solver.cpp:105] Iteration 114000, lr = 0.0043
I0529 04:04:02.562191 11123 solver.cpp:218] Iteration 114100 (3.57117 iter/s, 28.002s/100 iters), loss = 5.09268e-06
I0529 04:04:02.562234 11123 solver.cpp:237]     Train net output #0: loss = 4.24987e-06 (* 1 = 4.24987e-06 loss)
I0529 04:04:02.562243 11123 sgd_solver.cpp:105] Iteration 114100, lr = 0.004295
I0529 04:04:30.542786 11123 solver.cpp:218] Iteration 114200 (3.57401 iter/s, 27.9798s/100 iters), loss = 0.00129522
I0529 04:04:30.543058 11123 solver.cpp:237]     Train net output #0: loss = 0.00129439 (* 1 = 0.00129439 loss)
I0529 04:04:30.543076 11123 sgd_solver.cpp:105] Iteration 114200, lr = 0.00429
I0529 04:04:58.538182 11123 solver.cpp:218] Iteration 114300 (3.57215 iter/s, 27.9943s/100 iters), loss = 0.000785088
I0529 04:04:58.538225 11123 solver.cpp:237]     Train net output #0: loss = 0.000784252 (* 1 = 0.000784252 loss)
I0529 04:04:58.538233 11123 sgd_solver.cpp:105] Iteration 114300, lr = 0.004285
I0529 04:05:26.559988 11123 solver.cpp:218] Iteration 114400 (3.56875 iter/s, 28.021s/100 iters), loss = 6.97652e-05
I0529 04:05:26.560142 11123 solver.cpp:237]     Train net output #0: loss = 6.89305e-05 (* 1 = 6.89305e-05 loss)
I0529 04:05:26.560154 11123 sgd_solver.cpp:105] Iteration 114400, lr = 0.00428
I0529 04:05:54.598119 11123 solver.cpp:218] Iteration 114500 (3.56669 iter/s, 28.0372s/100 iters), loss = 8.12463e-05
I0529 04:05:54.598162 11123 solver.cpp:237]     Train net output #0: loss = 8.04139e-05 (* 1 = 8.04139e-05 loss)
I0529 04:05:54.598171 11123 sgd_solver.cpp:105] Iteration 114500, lr = 0.004275
I0529 04:06:19.569533 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:06:22.635349 11123 solver.cpp:218] Iteration 114600 (3.56679 iter/s, 28.0364s/100 iters), loss = 4.59892e-05
I0529 04:06:22.635406 11123 solver.cpp:237]     Train net output #0: loss = 4.51566e-05 (* 1 = 4.51566e-05 loss)
I0529 04:06:22.635414 11123 sgd_solver.cpp:105] Iteration 114600, lr = 0.00427
I0529 04:06:50.658526 11123 solver.cpp:218] Iteration 114700 (3.56858 iter/s, 28.0223s/100 iters), loss = 0.000231659
I0529 04:06:50.658699 11123 solver.cpp:237]     Train net output #0: loss = 0.000230831 (* 1 = 0.000230831 loss)
I0529 04:06:50.658710 11123 sgd_solver.cpp:105] Iteration 114700, lr = 0.004265
I0529 04:07:18.684830 11123 solver.cpp:218] Iteration 114800 (3.5682 iter/s, 28.0253s/100 iters), loss = 0.00284743
I0529 04:07:18.684885 11123 solver.cpp:237]     Train net output #0: loss = 0.0028466 (* 1 = 0.0028466 loss)
I0529 04:07:18.684895 11123 sgd_solver.cpp:105] Iteration 114800, lr = 0.00426
I0529 04:07:46.683123 11123 solver.cpp:218] Iteration 114900 (3.57175 iter/s, 27.9975s/100 iters), loss = 1.01742e-05
I0529 04:07:46.683320 11123 solver.cpp:237]     Train net output #0: loss = 9.34623e-06 (* 1 = 9.34623e-06 loss)
I0529 04:07:46.683336 11123 sgd_solver.cpp:105] Iteration 114900, lr = 0.004255
I0529 04:08:14.394570 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_115000.caffemodel
I0529 04:08:14.945539 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_115000.solverstate
I0529 04:08:15.092249 11123 solver.cpp:330] Iteration 115000, Testing net (#0)
I0529 04:08:15.632125 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:08:19.539579 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939
I0529 04:08:19.539724 11123 solver.cpp:397]     Test net output #1: loss = 0.255351 (* 1 = 0.255351 loss)
I0529 04:08:19.815973 11123 solver.cpp:218] Iteration 115000 (3.01825 iter/s, 33.1317s/100 iters), loss = 7.81094e-06
I0529 04:08:19.816035 11123 solver.cpp:237]     Train net output #0: loss = 6.98588e-06 (* 1 = 6.98588e-06 loss)
I0529 04:08:19.816045 11123 sgd_solver.cpp:105] Iteration 115000, lr = 0.00425
I0529 04:08:47.790644 11123 solver.cpp:218] Iteration 115100 (3.57477 iter/s, 27.9738s/100 iters), loss = 0.00107881
I0529 04:08:47.790699 11123 solver.cpp:237]     Train net output #0: loss = 0.00107798 (* 1 = 0.00107798 loss)
I0529 04:08:47.790709 11123 sgd_solver.cpp:105] Iteration 115100, lr = 0.004245
I0529 04:09:15.757613 11123 solver.cpp:218] Iteration 115200 (3.57575 iter/s, 27.9661s/100 iters), loss = 0.000281736
I0529 04:09:15.757833 11123 solver.cpp:237]     Train net output #0: loss = 0.000280909 (* 1 = 0.000280909 loss)
I0529 04:09:15.757843 11123 sgd_solver.cpp:105] Iteration 115200, lr = 0.00424
I0529 04:09:16.334139 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:09:43.772454 11123 solver.cpp:218] Iteration 115300 (3.56966 iter/s, 28.0139s/100 iters), loss = 3.56509e-05
I0529 04:09:43.772507 11123 solver.cpp:237]     Train net output #0: loss = 3.48132e-05 (* 1 = 3.48132e-05 loss)
I0529 04:09:43.772516 11123 sgd_solver.cpp:105] Iteration 115300, lr = 0.004235
I0529 04:10:11.787871 11123 solver.cpp:218] Iteration 115400 (3.56953 iter/s, 28.0149s/100 iters), loss = 8.70941e-05
I0529 04:10:11.788045 11123 solver.cpp:237]     Train net output #0: loss = 8.62518e-05 (* 1 = 8.62518e-05 loss)
I0529 04:10:11.788058 11123 sgd_solver.cpp:105] Iteration 115400, lr = 0.00423
I0529 04:10:39.776659 11123 solver.cpp:218] Iteration 115500 (3.5729 iter/s, 27.9885s/100 iters), loss = 0.000109239
I0529 04:10:39.776708 11123 solver.cpp:237]     Train net output #0: loss = 0.000108398 (* 1 = 0.000108398 loss)
I0529 04:10:39.776717 11123 sgd_solver.cpp:105] Iteration 115500, lr = 0.004225
I0529 04:11:07.773926 11123 solver.cpp:218] Iteration 115600 (3.5718 iter/s, 27.9971s/100 iters), loss = 9.03198e-05
I0529 04:11:07.774106 11123 solver.cpp:237]     Train net output #0: loss = 8.94796e-05 (* 1 = 8.94796e-05 loss)
I0529 04:11:07.774122 11123 sgd_solver.cpp:105] Iteration 115600, lr = 0.00422
I0529 04:11:35.776113 11123 solver.cpp:218] Iteration 115700 (3.57119 iter/s, 28.0018s/100 iters), loss = 0.000920128
I0529 04:11:35.776177 11123 solver.cpp:237]     Train net output #0: loss = 0.000919288 (* 1 = 0.000919288 loss)
I0529 04:11:35.776188 11123 sgd_solver.cpp:105] Iteration 115700, lr = 0.004215
I0529 04:12:03.761771 11123 solver.cpp:218] Iteration 115800 (3.57329 iter/s, 27.9854s/100 iters), loss = 0.000662354
I0529 04:12:03.761991 11123 solver.cpp:237]     Train net output #0: loss = 0.000661517 (* 1 = 0.000661517 loss)
I0529 04:12:03.762002 11123 sgd_solver.cpp:105] Iteration 115800, lr = 0.00421
I0529 04:12:07.979871 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:12:31.747959 11123 solver.cpp:218] Iteration 115900 (3.57324 iter/s, 27.9858s/100 iters), loss = 2.48733e-05
I0529 04:12:31.748008 11123 solver.cpp:237]     Train net output #0: loss = 2.40281e-05 (* 1 = 2.40281e-05 loss)
I0529 04:12:31.748018 11123 sgd_solver.cpp:105] Iteration 115900, lr = 0.004205
I0529 04:12:59.452651 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_116000.caffemodel
I0529 04:12:59.831610 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_116000.solverstate
I0529 04:12:59.983075 11123 solver.cpp:330] Iteration 116000, Testing net (#0)
I0529 04:13:02.040695 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:13:04.438387 11123 solver.cpp:397]     Test net output #0: accuracy = 0.928001
I0529 04:13:04.438429 11123 solver.cpp:397]     Test net output #1: loss = 0.291627 (* 1 = 0.291627 loss)
I0529 04:13:04.715042 11123 solver.cpp:218] Iteration 116000 (3.03336 iter/s, 32.9667s/100 iters), loss = 7.89211e-05
I0529 04:13:04.715090 11123 solver.cpp:237]     Train net output #0: loss = 7.80734e-05 (* 1 = 7.80734e-05 loss)
I0529 04:13:04.715098 11123 sgd_solver.cpp:105] Iteration 116000, lr = 0.0042
I0529 04:13:32.717259 11123 solver.cpp:218] Iteration 116100 (3.57119 iter/s, 28.0019s/100 iters), loss = 0.000326842
I0529 04:13:32.717380 11123 solver.cpp:237]     Train net output #0: loss = 0.000325992 (* 1 = 0.000325992 loss)
I0529 04:13:32.717389 11123 sgd_solver.cpp:105] Iteration 116100, lr = 0.004195
I0529 04:14:00.733755 11123 solver.cpp:218] Iteration 116200 (3.56938 iter/s, 28.0161s/100 iters), loss = 0.000308614
I0529 04:14:00.733805 11123 solver.cpp:237]     Train net output #0: loss = 0.000307764 (* 1 = 0.000307764 loss)
I0529 04:14:00.733814 11123 sgd_solver.cpp:105] Iteration 116200, lr = 0.00419
I0529 04:14:28.717598 11123 solver.cpp:218] Iteration 116300 (3.57354 iter/s, 27.9835s/100 iters), loss = 0.000569903
I0529 04:14:28.717772 11123 solver.cpp:237]     Train net output #0: loss = 0.000569048 (* 1 = 0.000569048 loss)
I0529 04:14:28.717782 11123 sgd_solver.cpp:105] Iteration 116300, lr = 0.004185
I0529 04:14:56.677647 11123 solver.cpp:218] Iteration 116400 (3.5766 iter/s, 27.9595s/100 iters), loss = 0.00137131
I0529 04:14:56.677713 11123 solver.cpp:237]     Train net output #0: loss = 0.00137046 (* 1 = 0.00137046 loss)
I0529 04:14:56.677724 11123 sgd_solver.cpp:105] Iteration 116400, lr = 0.00418
I0529 04:15:04.261509 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:15:24.688678 11123 solver.cpp:218] Iteration 116500 (3.57008 iter/s, 28.0106s/100 iters), loss = 9.58469e-05
I0529 04:15:24.688745 11123 solver.cpp:237]     Train net output #0: loss = 9.49869e-05 (* 1 = 9.49869e-05 loss)
I0529 04:15:24.688757 11123 sgd_solver.cpp:105] Iteration 116500, lr = 0.004175
I0529 04:15:52.693058 11123 solver.cpp:218] Iteration 116600 (3.57093 iter/s, 28.0039s/100 iters), loss = 0.00118634
I0529 04:15:52.693228 11123 solver.cpp:237]     Train net output #0: loss = 0.00118548 (* 1 = 0.00118548 loss)
I0529 04:15:52.693238 11123 sgd_solver.cpp:105] Iteration 116600, lr = 0.00417
I0529 04:16:20.713735 11123 solver.cpp:218] Iteration 116700 (3.56886 iter/s, 28.0201s/100 iters), loss = 0.00894919
I0529 04:16:20.713789 11123 solver.cpp:237]     Train net output #0: loss = 0.00894833 (* 1 = 0.00894833 loss)
I0529 04:16:20.713798 11123 sgd_solver.cpp:105] Iteration 116700, lr = 0.004165
I0529 04:16:48.708003 11123 solver.cpp:218] Iteration 116800 (3.57222 iter/s, 27.9938s/100 iters), loss = 8.24613e-06
I0529 04:16:48.708219 11123 solver.cpp:237]     Train net output #0: loss = 7.39121e-06 (* 1 = 7.39121e-06 loss)
I0529 04:16:48.708230 11123 sgd_solver.cpp:105] Iteration 116800, lr = 0.00416
I0529 04:17:16.727244 11123 solver.cpp:218] Iteration 116900 (3.56905 iter/s, 28.0186s/100 iters), loss = 1.91678e-05
I0529 04:17:16.727298 11123 solver.cpp:237]     Train net output #0: loss = 1.83148e-05 (* 1 = 1.83148e-05 loss)
I0529 04:17:16.727308 11123 sgd_solver.cpp:105] Iteration 116900, lr = 0.004155
I0529 04:17:44.465703 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_117000.caffemodel
I0529 04:17:44.832962 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_117000.solverstate
I0529 04:17:44.978668 11123 solver.cpp:330] Iteration 117000, Testing net (#0)
I0529 04:17:48.535332 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:17:49.422991 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939
I0529 04:17:49.423040 11123 solver.cpp:397]     Test net output #1: loss = 0.275115 (* 1 = 0.275115 loss)
I0529 04:17:49.700215 11123 solver.cpp:218] Iteration 117000 (3.03284 iter/s, 32.9724s/100 iters), loss = 4.80633e-05
I0529 04:17:49.700263 11123 solver.cpp:237]     Train net output #0: loss = 4.72107e-05 (* 1 = 4.72107e-05 loss)
I0529 04:17:49.700271 11123 sgd_solver.cpp:105] Iteration 117000, lr = 0.00415
I0529 04:18:00.934649 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:18:17.718374 11123 solver.cpp:218] Iteration 117100 (3.56918 iter/s, 28.0177s/100 iters), loss = 1.6129e-06
I0529 04:18:17.718608 11123 solver.cpp:237]     Train net output #0: loss = 7.56982e-07 (* 1 = 7.56982e-07 loss)
I0529 04:18:17.718621 11123 sgd_solver.cpp:105] Iteration 117100, lr = 0.004145
I0529 04:18:45.701786 11123 solver.cpp:218] Iteration 117200 (3.57363 iter/s, 27.9827s/100 iters), loss = 5.27354e-05
I0529 04:18:45.701836 11123 solver.cpp:237]     Train net output #0: loss = 5.18793e-05 (* 1 = 5.18793e-05 loss)
I0529 04:18:45.701846 11123 sgd_solver.cpp:105] Iteration 117200, lr = 0.00414
I0529 04:19:13.687188 11123 solver.cpp:218] Iteration 117300 (3.57336 iter/s, 27.9849s/100 iters), loss = 4.86746e-05
I0529 04:19:13.687356 11123 solver.cpp:237]     Train net output #0: loss = 4.78175e-05 (* 1 = 4.78175e-05 loss)
I0529 04:19:13.687368 11123 sgd_solver.cpp:105] Iteration 117300, lr = 0.004135
I0529 04:19:41.673091 11123 solver.cpp:218] Iteration 117400 (3.57331 iter/s, 27.9853s/100 iters), loss = 0.000641784
I0529 04:19:41.673156 11123 solver.cpp:237]     Train net output #0: loss = 0.000640926 (* 1 = 0.000640926 loss)
I0529 04:19:41.673164 11123 sgd_solver.cpp:105] Iteration 117400, lr = 0.00413
I0529 04:20:09.664878 11123 solver.cpp:218] Iteration 117500 (3.57255 iter/s, 27.9912s/100 iters), loss = 0.000561528
I0529 04:20:09.665065 11123 solver.cpp:237]     Train net output #0: loss = 0.00056067 (* 1 = 0.00056067 loss)
I0529 04:20:09.665076 11123 sgd_solver.cpp:105] Iteration 117500, lr = 0.004125
I0529 04:20:37.629019 11123 solver.cpp:218] Iteration 117600 (3.5761 iter/s, 27.9634s/100 iters), loss = 0.000134103
I0529 04:20:37.629071 11123 solver.cpp:237]     Train net output #0: loss = 0.000133245 (* 1 = 0.000133245 loss)
I0529 04:20:37.629081 11123 sgd_solver.cpp:105] Iteration 117600, lr = 0.00412
I0529 04:20:52.477308 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:21:05.613440 11123 solver.cpp:218] Iteration 117700 (3.57349 iter/s, 27.9838s/100 iters), loss = 0.0112037
I0529 04:21:05.613497 11123 solver.cpp:237]     Train net output #0: loss = 0.0112028 (* 1 = 0.0112028 loss)
I0529 04:21:05.613505 11123 sgd_solver.cpp:105] Iteration 117700, lr = 0.004115
I0529 04:21:33.605540 11123 solver.cpp:218] Iteration 117800 (3.57251 iter/s, 27.9915s/100 iters), loss = 0.00181374
I0529 04:21:33.605738 11123 solver.cpp:237]     Train net output #0: loss = 0.00181289 (* 1 = 0.00181289 loss)
I0529 04:21:33.605751 11123 sgd_solver.cpp:105] Iteration 117800, lr = 0.00411
I0529 04:22:01.595669 11123 solver.cpp:218] Iteration 117900 (3.57278 iter/s, 27.9894s/100 iters), loss = 4.0499e-06
I0529 04:22:01.595713 11123 solver.cpp:237]     Train net output #0: loss = 3.20082e-06 (* 1 = 3.20082e-06 loss)
I0529 04:22:01.595722 11123 sgd_solver.cpp:105] Iteration 117900, lr = 0.004105
I0529 04:22:29.278949 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_118000.caffemodel
I0529 04:22:29.696550 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_118000.solverstate
I0529 04:22:29.843058 11123 solver.cpp:330] Iteration 118000, Testing net (#0)
I0529 04:22:34.288197 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 04:22:34.288250 11123 solver.cpp:397]     Test net output #1: loss = 0.220989 (* 1 = 0.220989 loss)
I0529 04:22:34.565912 11123 solver.cpp:218] Iteration 118000 (3.0331 iter/s, 32.9696s/100 iters), loss = 4.65143e-05
I0529 04:22:34.565956 11123 solver.cpp:237]     Train net output #0: loss = 4.56671e-05 (* 1 = 4.56671e-05 loss)
I0529 04:22:34.565965 11123 sgd_solver.cpp:105] Iteration 118000, lr = 0.0041
I0529 04:23:02.598383 11123 solver.cpp:218] Iteration 118100 (3.56737 iter/s, 28.0319s/100 iters), loss = 0.00995929
I0529 04:23:02.598573 11123 solver.cpp:237]     Train net output #0: loss = 0.00995844 (* 1 = 0.00995844 loss)
I0529 04:23:02.598584 11123 sgd_solver.cpp:105] Iteration 118100, lr = 0.004095
I0529 04:23:30.615180 11123 solver.cpp:218] Iteration 118200 (3.56938 iter/s, 28.016s/100 iters), loss = 3.75264e-06
I0529 04:23:30.615245 11123 solver.cpp:237]     Train net output #0: loss = 2.90874e-06 (* 1 = 2.90874e-06 loss)
I0529 04:23:30.615255 11123 sgd_solver.cpp:105] Iteration 118200, lr = 0.00409
I0529 04:23:49.125435 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:23:58.636871 11123 solver.cpp:218] Iteration 118300 (3.56874 iter/s, 28.0211s/100 iters), loss = 0.000249004
I0529 04:23:58.636929 11123 solver.cpp:237]     Train net output #0: loss = 0.00024814 (* 1 = 0.00024814 loss)
I0529 04:23:58.636937 11123 sgd_solver.cpp:105] Iteration 118300, lr = 0.004085
I0529 04:24:26.620242 11123 solver.cpp:218] Iteration 118400 (3.57363 iter/s, 27.9827s/100 iters), loss = 1.29171e-05
I0529 04:24:26.620410 11123 solver.cpp:237]     Train net output #0: loss = 1.20526e-05 (* 1 = 1.20526e-05 loss)
I0529 04:24:26.620422 11123 sgd_solver.cpp:105] Iteration 118400, lr = 0.00408
I0529 04:24:54.594898 11123 solver.cpp:218] Iteration 118500 (3.57476 iter/s, 27.9739s/100 iters), loss = 0.00664771
I0529 04:24:54.594943 11123 solver.cpp:237]     Train net output #0: loss = 0.00664685 (* 1 = 0.00664685 loss)
I0529 04:24:54.594951 11123 sgd_solver.cpp:105] Iteration 118500, lr = 0.004075
I0529 04:25:22.579692 11123 solver.cpp:218] Iteration 118600 (3.57345 iter/s, 27.9842s/100 iters), loss = 8.15239e-05
I0529 04:25:22.579846 11123 solver.cpp:237]     Train net output #0: loss = 8.06583e-05 (* 1 = 8.06583e-05 loss)
I0529 04:25:22.579859 11123 sgd_solver.cpp:105] Iteration 118600, lr = 0.00407
I0529 04:25:50.574600 11123 solver.cpp:218] Iteration 118700 (3.57217 iter/s, 27.9942s/100 iters), loss = 0.000313384
I0529 04:25:50.574645 11123 solver.cpp:237]     Train net output #0: loss = 0.000312518 (* 1 = 0.000312518 loss)
I0529 04:25:50.574653 11123 sgd_solver.cpp:105] Iteration 118700, lr = 0.004065
I0529 04:26:18.576992 11123 solver.cpp:218] Iteration 118800 (3.5712 iter/s, 28.0018s/100 iters), loss = 3.85052e-05
I0529 04:26:18.577198 11123 solver.cpp:237]     Train net output #0: loss = 3.76381e-05 (* 1 = 3.76381e-05 loss)
I0529 04:26:18.577208 11123 sgd_solver.cpp:105] Iteration 118800, lr = 0.00406
I0529 04:26:40.715724 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:26:46.584513 11123 solver.cpp:218] Iteration 118900 (3.57057 iter/s, 28.0067s/100 iters), loss = 0.00017317
I0529 04:26:46.584560 11123 solver.cpp:237]     Train net output #0: loss = 0.000172303 (* 1 = 0.000172303 loss)
I0529 04:26:46.584571 11123 sgd_solver.cpp:105] Iteration 118900, lr = 0.004055
I0529 04:27:14.324398 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_119000.caffemodel
I0529 04:27:14.918583 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_119000.solverstate
I0529 04:27:15.067415 11123 solver.cpp:330] Iteration 119000, Testing net (#0)
I0529 04:27:15.696869 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:27:19.520663 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 04:27:19.520714 11123 solver.cpp:397]     Test net output #1: loss = 0.239457 (* 1 = 0.239457 loss)
I0529 04:27:19.797629 11123 solver.cpp:218] Iteration 119000 (3.01093 iter/s, 33.2124s/100 iters), loss = 1.20851e-05
I0529 04:27:19.797678 11123 solver.cpp:237]     Train net output #0: loss = 1.1218e-05 (* 1 = 1.1218e-05 loss)
I0529 04:27:19.797688 11123 sgd_solver.cpp:105] Iteration 119000, lr = 0.00405
I0529 04:27:47.752254 11123 solver.cpp:218] Iteration 119100 (3.57731 iter/s, 27.954s/100 iters), loss = 4.81694e-05
I0529 04:27:47.752485 11123 solver.cpp:237]     Train net output #0: loss = 4.73024e-05 (* 1 = 4.73024e-05 loss)
I0529 04:27:47.752496 11123 sgd_solver.cpp:105] Iteration 119100, lr = 0.004045
I0529 04:28:15.752739 11123 solver.cpp:218] Iteration 119200 (3.57147 iter/s, 27.9997s/100 iters), loss = 9.75434e-06
I0529 04:28:15.752787 11123 solver.cpp:237]     Train net output #0: loss = 8.8873e-06 (* 1 = 8.8873e-06 loss)
I0529 04:28:15.752796 11123 sgd_solver.cpp:105] Iteration 119200, lr = 0.00404
I0529 04:28:43.767863 11123 solver.cpp:218] Iteration 119300 (3.56958 iter/s, 28.0145s/100 iters), loss = 1.21951e-05
I0529 04:28:43.768030 11123 solver.cpp:237]     Train net output #0: loss = 1.13313e-05 (* 1 = 1.13313e-05 loss)
I0529 04:28:43.768043 11123 sgd_solver.cpp:105] Iteration 119300, lr = 0.004035
I0529 04:29:11.795227 11123 solver.cpp:218] Iteration 119400 (3.56804 iter/s, 28.0266s/100 iters), loss = 3.19005e-05
I0529 04:29:11.795274 11123 solver.cpp:237]     Train net output #0: loss = 3.10369e-05 (* 1 = 3.10369e-05 loss)
I0529 04:29:11.795284 11123 sgd_solver.cpp:105] Iteration 119400, lr = 0.00403
I0529 04:29:37.322399 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:29:39.822980 11123 solver.cpp:218] Iteration 119500 (3.56798 iter/s, 28.0271s/100 iters), loss = 3.04963e-06
I0529 04:29:39.823029 11123 solver.cpp:237]     Train net output #0: loss = 2.18751e-06 (* 1 = 2.18751e-06 loss)
I0529 04:29:39.823037 11123 sgd_solver.cpp:105] Iteration 119500, lr = 0.004025
I0529 04:30:07.870800 11123 solver.cpp:218] Iteration 119600 (3.56542 iter/s, 28.0471s/100 iters), loss = 4.17965e-06
I0529 04:30:07.870964 11123 solver.cpp:237]     Train net output #0: loss = 3.32002e-06 (* 1 = 3.32002e-06 loss)
I0529 04:30:07.870975 11123 sgd_solver.cpp:105] Iteration 119600, lr = 0.00402
I0529 04:30:35.867784 11123 solver.cpp:218] Iteration 119700 (3.57191 iter/s, 27.9962s/100 iters), loss = 0.000130833
I0529 04:30:35.867833 11123 solver.cpp:237]     Train net output #0: loss = 0.000129973 (* 1 = 0.000129973 loss)
I0529 04:30:35.867844 11123 sgd_solver.cpp:105] Iteration 119700, lr = 0.004015
I0529 04:31:03.878440 11123 solver.cpp:218] Iteration 119800 (3.57016 iter/s, 28.01s/100 iters), loss = 2.02465e-05
I0529 04:31:03.878593 11123 solver.cpp:237]     Train net output #0: loss = 1.93878e-05 (* 1 = 1.93878e-05 loss)
I0529 04:31:03.878605 11123 sgd_solver.cpp:105] Iteration 119800, lr = 0.00401
I0529 04:31:31.897889 11123 solver.cpp:218] Iteration 119900 (3.56905 iter/s, 28.0187s/100 iters), loss = 8.3991e-06
I0529 04:31:31.897936 11123 solver.cpp:237]     Train net output #0: loss = 7.5402e-06 (* 1 = 7.5402e-06 loss)
I0529 04:31:31.897945 11123 sgd_solver.cpp:105] Iteration 119900, lr = 0.004005
I0529 04:31:59.633949 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_120000.caffemodel
I0529 04:31:59.999642 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_120000.solverstate
I0529 04:32:00.147974 11123 solver.cpp:330] Iteration 120000, Testing net (#0)
I0529 04:32:02.243729 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:32:04.591915 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 04:32:04.591955 11123 solver.cpp:397]     Test net output #1: loss = 0.249818 (* 1 = 0.249818 loss)
I0529 04:32:04.868655 11123 solver.cpp:218] Iteration 120000 (3.03306 iter/s, 32.97s/100 iters), loss = 7.10414e-06
I0529 04:32:04.868700 11123 solver.cpp:237]     Train net output #0: loss = 6.24686e-06 (* 1 = 6.24686e-06 loss)
I0529 04:32:04.868708 11123 sgd_solver.cpp:105] Iteration 120000, lr = 0.004
I0529 04:32:32.887804 11123 solver.cpp:218] Iteration 120100 (3.56908 iter/s, 28.0185s/100 iters), loss = 3.45594e-05
I0529 04:32:32.888041 11123 solver.cpp:237]     Train net output #0: loss = 3.3702e-05 (* 1 = 3.3702e-05 loss)
I0529 04:32:32.888051 11123 sgd_solver.cpp:105] Iteration 120100, lr = 0.003995
I0529 04:32:34.027959 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:33:00.914191 11123 solver.cpp:218] Iteration 120200 (3.56818 iter/s, 28.0255s/100 iters), loss = 4.25521e-06
I0529 04:33:00.914240 11123 solver.cpp:237]     Train net output #0: loss = 3.39753e-06 (* 1 = 3.39753e-06 loss)
I0529 04:33:00.914250 11123 sgd_solver.cpp:105] Iteration 120200, lr = 0.00399
I0529 04:33:28.921272 11123 solver.cpp:218] Iteration 120300 (3.57061 iter/s, 28.0064s/100 iters), loss = 0.0101257
I0529 04:33:28.921442 11123 solver.cpp:237]     Train net output #0: loss = 0.0101248 (* 1 = 0.0101248 loss)
I0529 04:33:28.921454 11123 sgd_solver.cpp:105] Iteration 120300, lr = 0.003985
I0529 04:33:56.926146 11123 solver.cpp:218] Iteration 120400 (3.57091 iter/s, 28.0041s/100 iters), loss = 0.000139784
I0529 04:33:56.926192 11123 solver.cpp:237]     Train net output #0: loss = 0.000138934 (* 1 = 0.000138934 loss)
I0529 04:33:56.926200 11123 sgd_solver.cpp:105] Iteration 120400, lr = 0.00398
I0529 04:34:24.943377 11123 solver.cpp:218] Iteration 120500 (3.56932 iter/s, 28.0165s/100 iters), loss = 2.73496e-05
I0529 04:34:24.943589 11123 solver.cpp:237]     Train net output #0: loss = 2.64999e-05 (* 1 = 2.64999e-05 loss)
I0529 04:34:24.943601 11123 sgd_solver.cpp:105] Iteration 120500, lr = 0.003975
I0529 04:34:52.952548 11123 solver.cpp:218] Iteration 120600 (3.57037 iter/s, 28.0083s/100 iters), loss = 2.39993e-05
I0529 04:34:52.952616 11123 solver.cpp:237]     Train net output #0: loss = 2.31495e-05 (* 1 = 2.31495e-05 loss)
I0529 04:34:52.952625 11123 sgd_solver.cpp:105] Iteration 120600, lr = 0.00397
I0529 04:35:20.964434 11123 solver.cpp:218] Iteration 120700 (3.57 iter/s, 28.0112s/100 iters), loss = 0.00202282
I0529 04:35:20.964598 11123 solver.cpp:237]     Train net output #0: loss = 0.00202197 (* 1 = 0.00202197 loss)
I0529 04:35:20.964609 11123 sgd_solver.cpp:105] Iteration 120700, lr = 0.003965
I0529 04:35:25.745514 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:35:48.989058 11123 solver.cpp:218] Iteration 120800 (3.56839 iter/s, 28.0238s/100 iters), loss = 0.000360649
I0529 04:35:48.989110 11123 solver.cpp:237]     Train net output #0: loss = 0.000359799 (* 1 = 0.000359799 loss)
I0529 04:35:48.989120 11123 sgd_solver.cpp:105] Iteration 120800, lr = 0.00396
I0529 04:36:17.004559 11123 solver.cpp:218] Iteration 120900 (3.56954 iter/s, 28.0148s/100 iters), loss = 0.000148264
I0529 04:36:17.004732 11123 solver.cpp:237]     Train net output #0: loss = 0.000147414 (* 1 = 0.000147414 loss)
I0529 04:36:17.004745 11123 sgd_solver.cpp:105] Iteration 120900, lr = 0.003955
I0529 04:36:44.740551 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_121000.caffemodel
I0529 04:36:45.247879 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_121000.solverstate
I0529 04:36:45.395318 11123 solver.cpp:330] Iteration 121000, Testing net (#0)
I0529 04:36:48.999738 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:36:49.841119 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 04:36:49.841153 11123 solver.cpp:397]     Test net output #1: loss = 0.267315 (* 1 = 0.267315 loss)
I0529 04:36:50.116575 11123 solver.cpp:218] Iteration 121000 (3.02014 iter/s, 33.1111s/100 iters), loss = 9.63172e-06
I0529 04:36:50.116621 11123 solver.cpp:237]     Train net output #0: loss = 8.77399e-06 (* 1 = 8.77399e-06 loss)
I0529 04:36:50.116631 11123 sgd_solver.cpp:105] Iteration 121000, lr = 0.00395
I0529 04:37:18.137590 11123 solver.cpp:218] Iteration 121100 (3.56884 iter/s, 28.0203s/100 iters), loss = 3.81107e-05
I0529 04:37:18.137639 11123 solver.cpp:237]     Train net output #0: loss = 3.72552e-05 (* 1 = 3.72552e-05 loss)
I0529 04:37:18.137646 11123 sgd_solver.cpp:105] Iteration 121100, lr = 0.003945
I0529 04:37:46.141263 11123 solver.cpp:218] Iteration 121200 (3.57105 iter/s, 28.003s/100 iters), loss = 0.00348845
I0529 04:37:46.141518 11123 solver.cpp:237]     Train net output #0: loss = 0.00348759 (* 1 = 0.00348759 loss)
I0529 04:37:46.141530 11123 sgd_solver.cpp:105] Iteration 121200, lr = 0.00394
I0529 04:38:14.139209 11123 solver.cpp:218] Iteration 121300 (3.57181 iter/s, 27.997s/100 iters), loss = 0.000128847
I0529 04:38:14.139262 11123 solver.cpp:237]     Train net output #0: loss = 0.000127983 (* 1 = 0.000127983 loss)
I0529 04:38:14.139271 11123 sgd_solver.cpp:105] Iteration 121300, lr = 0.003935
I0529 04:38:22.550606 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:38:42.129833 11123 solver.cpp:218] Iteration 121400 (3.57272 iter/s, 27.9899s/100 iters), loss = 2.29417e-05
I0529 04:38:42.129881 11123 solver.cpp:237]     Train net output #0: loss = 2.20791e-05 (* 1 = 2.20791e-05 loss)
I0529 04:38:42.129890 11123 sgd_solver.cpp:105] Iteration 121400, lr = 0.00393
I0529 04:39:10.133152 11123 solver.cpp:218] Iteration 121500 (3.5711 iter/s, 28.0026s/100 iters), loss = 2.18515e-05
I0529 04:39:10.133327 11123 solver.cpp:237]     Train net output #0: loss = 2.09955e-05 (* 1 = 2.09955e-05 loss)
I0529 04:39:10.133338 11123 sgd_solver.cpp:105] Iteration 121500, lr = 0.003925
I0529 04:39:38.152170 11123 solver.cpp:218] Iteration 121600 (3.56911 iter/s, 28.0182s/100 iters), loss = 0.0253131
I0529 04:39:38.152220 11123 solver.cpp:237]     Train net output #0: loss = 0.0253122 (* 1 = 0.0253122 loss)
I0529 04:39:38.152240 11123 sgd_solver.cpp:105] Iteration 121600, lr = 0.00392
I0529 04:40:06.154362 11123 solver.cpp:218] Iteration 121700 (3.57124 iter/s, 28.0015s/100 iters), loss = 6.41616e-06
I0529 04:40:06.154515 11123 solver.cpp:237]     Train net output #0: loss = 5.56123e-06 (* 1 = 5.56123e-06 loss)
I0529 04:40:06.154527 11123 sgd_solver.cpp:105] Iteration 121700, lr = 0.003915
I0529 04:40:34.157829 11123 solver.cpp:218] Iteration 121800 (3.57109 iter/s, 28.0027s/100 iters), loss = 1.89379e-05
I0529 04:40:34.157886 11123 solver.cpp:237]     Train net output #0: loss = 1.80831e-05 (* 1 = 1.80831e-05 loss)
I0529 04:40:34.157896 11123 sgd_solver.cpp:105] Iteration 121800, lr = 0.00391
I0529 04:41:02.165709 11123 solver.cpp:218] Iteration 121900 (3.57051 iter/s, 28.0072s/100 iters), loss = 8.02591e-06
I0529 04:41:02.165875 11123 solver.cpp:237]     Train net output #0: loss = 7.17069e-06 (* 1 = 7.17069e-06 loss)
I0529 04:41:02.165887 11123 sgd_solver.cpp:105] Iteration 121900, lr = 0.003905
I0529 04:41:14.231164 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:41:29.901667 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_122000.caffemodel
I0529 04:41:30.322175 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_122000.solverstate
I0529 04:41:30.470758 11123 solver.cpp:330] Iteration 122000, Testing net (#0)
I0529 04:41:34.918264 11123 solver.cpp:397]     Test net output #0: accuracy = 0.941
I0529 04:41:34.918413 11123 solver.cpp:397]     Test net output #1: loss = 0.228195 (* 1 = 0.228195 loss)
I0529 04:41:35.194802 11123 solver.cpp:218] Iteration 122000 (3.02772 iter/s, 33.0281s/100 iters), loss = 0.000424389
I0529 04:41:35.194852 11123 solver.cpp:237]     Train net output #0: loss = 0.000423534 (* 1 = 0.000423534 loss)
I0529 04:41:35.194861 11123 sgd_solver.cpp:105] Iteration 122000, lr = 0.0039
I0529 04:42:03.177171 11123 solver.cpp:218] Iteration 122100 (3.57377 iter/s, 27.9816s/100 iters), loss = 6.87582e-06
I0529 04:42:03.177217 11123 solver.cpp:237]     Train net output #0: loss = 6.02021e-06 (* 1 = 6.02021e-06 loss)
I0529 04:42:03.177242 11123 sgd_solver.cpp:105] Iteration 122100, lr = 0.003895
I0529 04:42:31.139380 11123 solver.cpp:218] Iteration 122200 (3.57635 iter/s, 27.9615s/100 iters), loss = 4.49845e-05
I0529 04:42:31.139551 11123 solver.cpp:237]     Train net output #0: loss = 4.41283e-05 (* 1 = 4.41283e-05 loss)
I0529 04:42:31.139564 11123 sgd_solver.cpp:105] Iteration 122200, lr = 0.00389
I0529 04:42:59.136318 11123 solver.cpp:218] Iteration 122300 (3.57193 iter/s, 27.9961s/100 iters), loss = 0.000447396
I0529 04:42:59.136366 11123 solver.cpp:237]     Train net output #0: loss = 0.00044654 (* 1 = 0.00044654 loss)
I0529 04:42:59.136375 11123 sgd_solver.cpp:105] Iteration 122300, lr = 0.003885
I0529 04:43:27.172330 11123 solver.cpp:218] Iteration 122400 (3.56693 iter/s, 28.0353s/100 iters), loss = 5.86942e-05
I0529 04:43:27.172531 11123 solver.cpp:237]     Train net output #0: loss = 5.78384e-05 (* 1 = 5.78384e-05 loss)
I0529 04:43:27.172544 11123 sgd_solver.cpp:105] Iteration 122400, lr = 0.00388
I0529 04:43:55.174553 11123 solver.cpp:218] Iteration 122500 (3.57126 iter/s, 28.0014s/100 iters), loss = 5.51725e-06
I0529 04:43:55.174602 11123 solver.cpp:237]     Train net output #0: loss = 4.66122e-06 (* 1 = 4.66122e-06 loss)
I0529 04:43:55.174612 11123 sgd_solver.cpp:105] Iteration 122500, lr = 0.003875
I0529 04:44:10.600332 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:44:23.179571 11123 solver.cpp:218] Iteration 122600 (3.57076 iter/s, 28.0052s/100 iters), loss = 8.89028e-05
I0529 04:44:23.179617 11123 solver.cpp:237]     Train net output #0: loss = 8.80471e-05 (* 1 = 8.80471e-05 loss)
I0529 04:44:23.179626 11123 sgd_solver.cpp:105] Iteration 122600, lr = 0.00387
I0529 04:44:51.163192 11123 solver.cpp:218] Iteration 122700 (3.57342 iter/s, 27.9844s/100 iters), loss = 2.34834e-05
I0529 04:44:51.163389 11123 solver.cpp:237]     Train net output #0: loss = 2.26275e-05 (* 1 = 2.26275e-05 loss)
I0529 04:44:51.163401 11123 sgd_solver.cpp:105] Iteration 122700, lr = 0.003865
I0529 04:45:19.168499 11123 solver.cpp:218] Iteration 122800 (3.57068 iter/s, 28.0059s/100 iters), loss = 0.000128127
I0529 04:45:19.168558 11123 solver.cpp:237]     Train net output #0: loss = 0.000127271 (* 1 = 0.000127271 loss)
I0529 04:45:19.168567 11123 sgd_solver.cpp:105] Iteration 122800, lr = 0.00386
I0529 04:45:47.176558 11123 solver.cpp:218] Iteration 122900 (3.57032 iter/s, 28.0087s/100 iters), loss = 4.16262e-05
I0529 04:45:47.176787 11123 solver.cpp:237]     Train net output #0: loss = 4.07704e-05 (* 1 = 4.07704e-05 loss)
I0529 04:45:47.176800 11123 sgd_solver.cpp:105] Iteration 122900, lr = 0.003855
I0529 04:46:14.908535 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_123000.caffemodel
I0529 04:46:15.337584 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_123000.solverstate
I0529 04:46:15.484771 11123 solver.cpp:330] Iteration 123000, Testing net (#0)
I0529 04:46:16.159535 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:46:19.930836 11123 solver.cpp:397]     Test net output #0: accuracy = 0.938
I0529 04:46:19.930984 11123 solver.cpp:397]     Test net output #1: loss = 0.256212 (* 1 = 0.256212 loss)
I0529 04:46:20.208045 11123 solver.cpp:218] Iteration 123000 (3.02737 iter/s, 33.032s/100 iters), loss = 1.58292e-05
I0529 04:46:20.208089 11123 solver.cpp:237]     Train net output #0: loss = 1.49732e-05 (* 1 = 1.49732e-05 loss)
I0529 04:46:20.208098 11123 sgd_solver.cpp:105] Iteration 123000, lr = 0.00385
I0529 04:46:48.190567 11123 solver.cpp:218] Iteration 123100 (3.57359 iter/s, 27.9831s/100 iters), loss = 2.11956e-06
I0529 04:46:48.190618 11123 solver.cpp:237]     Train net output #0: loss = 1.26362e-06 (* 1 = 1.26362e-06 loss)
I0529 04:46:48.190631 11123 sgd_solver.cpp:105] Iteration 123100, lr = 0.003845
I0529 04:47:07.267529 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:47:16.204391 11123 solver.cpp:218] Iteration 123200 (3.5696 iter/s, 28.0143s/100 iters), loss = 1.74843e-05
I0529 04:47:16.204454 11123 solver.cpp:237]     Train net output #0: loss = 1.66285e-05 (* 1 = 1.66285e-05 loss)
I0529 04:47:16.204463 11123 sgd_solver.cpp:105] Iteration 123200, lr = 0.00384
I0529 04:47:44.189651 11123 solver.cpp:218] Iteration 123300 (3.57326 iter/s, 27.9857s/100 iters), loss = 1.45159e-05
I0529 04:47:44.189826 11123 solver.cpp:237]     Train net output #0: loss = 1.36601e-05 (* 1 = 1.36601e-05 loss)
I0529 04:47:44.189837 11123 sgd_solver.cpp:105] Iteration 123300, lr = 0.003835
I0529 04:48:12.215667 11123 solver.cpp:218] Iteration 123400 (3.56808 iter/s, 28.0263s/100 iters), loss = 4.91372e-05
I0529 04:48:12.215718 11123 solver.cpp:237]     Train net output #0: loss = 4.82817e-05 (* 1 = 4.82817e-05 loss)
I0529 04:48:12.215726 11123 sgd_solver.cpp:105] Iteration 123400, lr = 0.00383
I0529 04:48:40.215389 11123 solver.cpp:218] Iteration 123500 (3.57142 iter/s, 28.0001s/100 iters), loss = 6.95504e-05
I0529 04:48:40.215626 11123 solver.cpp:237]     Train net output #0: loss = 6.86951e-05 (* 1 = 6.86951e-05 loss)
I0529 04:48:40.215636 11123 sgd_solver.cpp:105] Iteration 123500, lr = 0.003825
I0529 04:49:08.218137 11123 solver.cpp:218] Iteration 123600 (3.57106 iter/s, 28.0029s/100 iters), loss = 0.00393193
I0529 04:49:08.218183 11123 solver.cpp:237]     Train net output #0: loss = 0.00393108 (* 1 = 0.00393108 loss)
I0529 04:49:08.218192 11123 sgd_solver.cpp:105] Iteration 123600, lr = 0.00382
I0529 04:49:36.231403 11123 solver.cpp:218] Iteration 123700 (3.56971 iter/s, 28.0135s/100 iters), loss = 2.22757e-06
I0529 04:49:36.231590 11123 solver.cpp:237]     Train net output #0: loss = 1.37091e-06 (* 1 = 1.37091e-06 loss)
I0529 04:49:36.231618 11123 sgd_solver.cpp:105] Iteration 123700, lr = 0.003815
I0529 04:49:58.910202 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:50:04.219763 11123 solver.cpp:218] Iteration 123800 (3.5729 iter/s, 27.9885s/100 iters), loss = 0.000547828
I0529 04:50:04.219810 11123 solver.cpp:237]     Train net output #0: loss = 0.000546971 (* 1 = 0.000546971 loss)
I0529 04:50:04.219817 11123 sgd_solver.cpp:105] Iteration 123800, lr = 0.00381
I0529 04:50:32.195680 11123 solver.cpp:218] Iteration 123900 (3.57448 iter/s, 27.9761s/100 iters), loss = 1.80014e-06
I0529 04:50:32.195840 11123 solver.cpp:237]     Train net output #0: loss = 9.41757e-07 (* 1 = 9.41757e-07 loss)
I0529 04:50:32.195854 11123 sgd_solver.cpp:105] Iteration 123900, lr = 0.003805
I0529 04:50:59.912072 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_124000.caffemodel
I0529 04:51:00.369982 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_124000.solverstate
I0529 04:51:00.516902 11123 solver.cpp:330] Iteration 124000, Testing net (#0)
I0529 04:51:02.704053 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:51:04.968719 11123 solver.cpp:397]     Test net output #0: accuracy = 0.93
I0529 04:51:04.968770 11123 solver.cpp:397]     Test net output #1: loss = 0.291359 (* 1 = 0.291359 loss)
I0529 04:51:05.246220 11123 solver.cpp:218] Iteration 124000 (3.02566 iter/s, 33.0506s/100 iters), loss = 0.00038295
I0529 04:51:05.246266 11123 solver.cpp:237]     Train net output #0: loss = 0.000382092 (* 1 = 0.000382092 loss)
I0529 04:51:05.246274 11123 sgd_solver.cpp:105] Iteration 124000, lr = 0.0038
I0529 04:51:33.251673 11123 solver.cpp:218] Iteration 124100 (3.57072 iter/s, 28.0056s/100 iters), loss = 0.00043624
I0529 04:51:33.251833 11123 solver.cpp:237]     Train net output #0: loss = 0.00043538 (* 1 = 0.00043538 loss)
I0529 04:51:33.251844 11123 sgd_solver.cpp:105] Iteration 124100, lr = 0.003795
I0529 04:52:01.275979 11123 solver.cpp:218] Iteration 124200 (3.56834 iter/s, 28.0243s/100 iters), loss = 4.54289e-05
I0529 04:52:01.276026 11123 solver.cpp:237]     Train net output #0: loss = 4.45649e-05 (* 1 = 4.45649e-05 loss)
I0529 04:52:01.276046 11123 sgd_solver.cpp:105] Iteration 124200, lr = 0.00379
I0529 04:52:29.276628 11123 solver.cpp:218] Iteration 124300 (3.57134 iter/s, 28.0007s/100 iters), loss = 2.47146e-05
I0529 04:52:29.276841 11123 solver.cpp:237]     Train net output #0: loss = 2.38514e-05 (* 1 = 2.38514e-05 loss)
I0529 04:52:29.276852 11123 sgd_solver.cpp:105] Iteration 124300, lr = 0.003785
I0529 04:52:55.611843 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:52:57.277655 11123 solver.cpp:218] Iteration 124400 (3.57131 iter/s, 28.0009s/100 iters), loss = 6.57894e-06
I0529 04:52:57.277704 11123 solver.cpp:237]     Train net output #0: loss = 5.71635e-06 (* 1 = 5.71635e-06 loss)
I0529 04:52:57.277714 11123 sgd_solver.cpp:105] Iteration 124400, lr = 0.00378
I0529 04:53:25.296715 11123 solver.cpp:218] Iteration 124500 (3.569 iter/s, 28.019s/100 iters), loss = 8.0321e-05
I0529 04:53:25.296962 11123 solver.cpp:237]     Train net output #0: loss = 7.94579e-05 (* 1 = 7.94579e-05 loss)
I0529 04:53:25.296973 11123 sgd_solver.cpp:105] Iteration 124500, lr = 0.003775
I0529 04:53:53.294818 11123 solver.cpp:218] Iteration 124600 (3.5717 iter/s, 27.9979s/100 iters), loss = 2.13894e-05
I0529 04:53:53.294862 11123 solver.cpp:237]     Train net output #0: loss = 2.05261e-05 (* 1 = 2.05261e-05 loss)
I0529 04:53:53.294872 11123 sgd_solver.cpp:105] Iteration 124600, lr = 0.00377
I0529 04:54:21.301304 11123 solver.cpp:218] Iteration 124700 (3.57061 iter/s, 28.0064s/100 iters), loss = 1.8822e-05
I0529 04:54:21.301470 11123 solver.cpp:237]     Train net output #0: loss = 1.79597e-05 (* 1 = 1.79597e-05 loss)
I0529 04:54:21.301481 11123 sgd_solver.cpp:105] Iteration 124700, lr = 0.003765
I0529 04:54:49.287678 11123 solver.cpp:218] Iteration 124800 (3.57319 iter/s, 27.9862s/100 iters), loss = 2.11443e-05
I0529 04:54:49.287722 11123 solver.cpp:237]     Train net output #0: loss = 2.02812e-05 (* 1 = 2.02812e-05 loss)
I0529 04:54:49.287731 11123 sgd_solver.cpp:105] Iteration 124800, lr = 0.00376
I0529 04:55:17.301851 11123 solver.cpp:218] Iteration 124900 (3.56963 iter/s, 28.0141s/100 iters), loss = 5.27129e-05
I0529 04:55:17.302007 11123 solver.cpp:237]     Train net output #0: loss = 5.18499e-05 (* 1 = 5.18499e-05 loss)
I0529 04:55:17.302019 11123 sgd_solver.cpp:105] Iteration 124900, lr = 0.003755
I0529 04:55:45.057557 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_125000.caffemodel
I0529 04:55:45.501832 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_125000.solverstate
I0529 04:55:45.649715 11123 solver.cpp:330] Iteration 125000, Testing net (#0)
I0529 04:55:49.325603 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:55:50.071305 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 04:55:50.071344 11123 solver.cpp:397]     Test net output #1: loss = 0.267176 (* 1 = 0.267176 loss)
I0529 04:55:50.347092 11123 solver.cpp:218] Iteration 125000 (3.02618 iter/s, 33.045s/100 iters), loss = 2.93737e-05
I0529 04:55:50.347136 11123 solver.cpp:237]     Train net output #0: loss = 2.85111e-05 (* 1 = 2.85111e-05 loss)
I0529 04:55:50.347144 11123 sgd_solver.cpp:105] Iteration 125000, lr = 0.00375
I0529 04:55:52.324415 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:56:18.345052 11123 solver.cpp:218] Iteration 125100 (3.57171 iter/s, 27.9978s/100 iters), loss = 0.000106641
I0529 04:56:18.345105 11123 solver.cpp:237]     Train net output #0: loss = 0.000105779 (* 1 = 0.000105779 loss)
I0529 04:56:18.345118 11123 sgd_solver.cpp:105] Iteration 125100, lr = 0.003745
I0529 04:56:46.327791 11123 solver.cpp:218] Iteration 125200 (3.57365 iter/s, 27.9826s/100 iters), loss = 4.21906e-05
I0529 04:56:46.327939 11123 solver.cpp:237]     Train net output #0: loss = 4.13279e-05 (* 1 = 4.13279e-05 loss)
I0529 04:56:46.327958 11123 sgd_solver.cpp:105] Iteration 125200, lr = 0.00374
I0529 04:57:14.328317 11123 solver.cpp:218] Iteration 125300 (3.57139 iter/s, 28.0003s/100 iters), loss = 7.6341e-06
I0529 04:57:14.328373 11123 solver.cpp:237]     Train net output #0: loss = 6.77125e-06 (* 1 = 6.77125e-06 loss)
I0529 04:57:14.328387 11123 sgd_solver.cpp:105] Iteration 125300, lr = 0.003735
I0529 04:57:42.327538 11123 solver.cpp:218] Iteration 125400 (3.57155 iter/s, 27.999s/100 iters), loss = 3.78936e-06
I0529 04:57:42.327698 11123 solver.cpp:237]     Train net output #0: loss = 2.92661e-06 (* 1 = 2.92661e-06 loss)
I0529 04:57:42.327716 11123 sgd_solver.cpp:105] Iteration 125400, lr = 0.00373
I0529 04:58:10.345134 11123 solver.cpp:218] Iteration 125500 (3.56923 iter/s, 28.0173s/100 iters), loss = 8.43262e-06
I0529 04:58:10.345191 11123 solver.cpp:237]     Train net output #0: loss = 7.57004e-06 (* 1 = 7.57004e-06 loss)
I0529 04:58:10.345201 11123 sgd_solver.cpp:105] Iteration 125500, lr = 0.003725
I0529 04:58:38.345543 11123 solver.cpp:218] Iteration 125600 (3.57141 iter/s, 28.0002s/100 iters), loss = 4.29536e-06
I0529 04:58:38.345737 11123 solver.cpp:237]     Train net output #0: loss = 3.43334e-06 (* 1 = 3.43334e-06 loss)
I0529 04:58:38.345749 11123 sgd_solver.cpp:105] Iteration 125600, lr = 0.00372
I0529 04:58:43.688567 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:59:06.358345 11123 solver.cpp:218] Iteration 125700 (3.56984 iter/s, 28.0124s/100 iters), loss = 1.49334e-05
I0529 04:59:06.358397 11123 solver.cpp:237]     Train net output #0: loss = 1.40714e-05 (* 1 = 1.40714e-05 loss)
I0529 04:59:06.358405 11123 sgd_solver.cpp:105] Iteration 125700, lr = 0.003715
I0529 04:59:34.360076 11123 solver.cpp:218] Iteration 125800 (3.57124 iter/s, 28.0015s/100 iters), loss = 1.50846e-05
I0529 04:59:34.360282 11123 solver.cpp:237]     Train net output #0: loss = 1.42225e-05 (* 1 = 1.42225e-05 loss)
I0529 04:59:34.360296 11123 sgd_solver.cpp:105] Iteration 125800, lr = 0.00371
I0529 05:00:02.360456 11123 solver.cpp:218] Iteration 125900 (3.57143 iter/s, 28s/100 iters), loss = 2.19219e-05
I0529 05:00:02.360501 11123 solver.cpp:237]     Train net output #0: loss = 2.10604e-05 (* 1 = 2.10604e-05 loss)
I0529 05:00:02.360509 11123 sgd_solver.cpp:105] Iteration 125900, lr = 0.003705
I0529 05:00:30.072496 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_126000.caffemodel
I0529 05:00:30.539510 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_126000.solverstate
I0529 05:00:30.685745 11123 solver.cpp:330] Iteration 126000, Testing net (#0)
I0529 05:00:35.131197 11123 solver.cpp:397]     Test net output #0: accuracy = 0.937
I0529 05:00:35.131247 11123 solver.cpp:397]     Test net output #1: loss = 0.245623 (* 1 = 0.245623 loss)
I0529 05:00:35.408000 11123 solver.cpp:218] Iteration 126000 (3.02597 iter/s, 33.0472s/100 iters), loss = 3.54924e-05
I0529 05:00:35.408046 11123 solver.cpp:237]     Train net output #0: loss = 3.46311e-05 (* 1 = 3.46311e-05 loss)
I0529 05:00:35.408054 11123 sgd_solver.cpp:105] Iteration 126000, lr = 0.0037
I0529 05:01:03.423485 11123 solver.cpp:218] Iteration 126100 (3.56949 iter/s, 28.0152s/100 iters), loss = 8.44961e-05
I0529 05:01:03.423650 11123 solver.cpp:237]     Train net output #0: loss = 8.36348e-05 (* 1 = 8.36348e-05 loss)
I0529 05:01:03.423660 11123 sgd_solver.cpp:105] Iteration 126100, lr = 0.003695
I0529 05:01:31.445446 11123 solver.cpp:218] Iteration 126200 (3.56868 iter/s, 28.0216s/100 iters), loss = 8.99935e-05
I0529 05:01:31.445492 11123 solver.cpp:237]     Train net output #0: loss = 8.91324e-05 (* 1 = 8.91324e-05 loss)
I0529 05:01:31.445500 11123 sgd_solver.cpp:105] Iteration 126200, lr = 0.00369
I0529 05:01:40.431998 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:01:59.435593 11123 solver.cpp:218] Iteration 126300 (3.57273 iter/s, 27.9898s/100 iters), loss = 0.000109332
I0529 05:01:59.435642 11123 solver.cpp:237]     Train net output #0: loss = 0.000108471 (* 1 = 0.000108471 loss)
I0529 05:01:59.435659 11123 sgd_solver.cpp:105] Iteration 126300, lr = 0.003685
I0529 05:02:27.406419 11123 solver.cpp:218] Iteration 126400 (3.57519 iter/s, 27.9705s/100 iters), loss = 0.000117219
I0529 05:02:27.406635 11123 solver.cpp:237]     Train net output #0: loss = 0.000116358 (* 1 = 0.000116358 loss)
I0529 05:02:27.406651 11123 sgd_solver.cpp:105] Iteration 126400, lr = 0.00368
I0529 05:02:55.371846 11123 solver.cpp:218] Iteration 126500 (3.57591 iter/s, 27.9649s/100 iters), loss = 7.25056e-06
I0529 05:02:55.371897 11123 solver.cpp:237]     Train net output #0: loss = 6.38978e-06 (* 1 = 6.38978e-06 loss)
I0529 05:02:55.371906 11123 sgd_solver.cpp:105] Iteration 126500, lr = 0.003675
I0529 05:03:23.393909 11123 solver.cpp:218] Iteration 126600 (3.56866 iter/s, 28.0217s/100 iters), loss = 0.000389137
I0529 05:03:23.394107 11123 solver.cpp:237]     Train net output #0: loss = 0.000388276 (* 1 = 0.000388276 loss)
I0529 05:03:23.394119 11123 sgd_solver.cpp:105] Iteration 126600, lr = 0.00367
I0529 05:03:51.421373 11123 solver.cpp:218] Iteration 126700 (3.56799 iter/s, 28.027s/100 iters), loss = 0.000120784
I0529 05:03:51.421422 11123 solver.cpp:237]     Train net output #0: loss = 0.000119923 (* 1 = 0.000119923 loss)
I0529 05:03:51.421430 11123 sgd_solver.cpp:105] Iteration 126700, lr = 0.003665
I0529 05:04:19.447101 11123 solver.cpp:218] Iteration 126800 (3.56819 iter/s, 28.0254s/100 iters), loss = 0.000118444
I0529 05:04:19.447270 11123 solver.cpp:237]     Train net output #0: loss = 0.000117584 (* 1 = 0.000117584 loss)
I0529 05:04:19.447281 11123 sgd_solver.cpp:105] Iteration 126800, lr = 0.00366
I0529 05:04:32.072553 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:04:47.464761 11123 solver.cpp:218] Iteration 126900 (3.56924 iter/s, 28.0172s/100 iters), loss = 0.00139138
I0529 05:04:47.464807 11123 solver.cpp:237]     Train net output #0: loss = 0.00139052 (* 1 = 0.00139052 loss)
I0529 05:04:47.464815 11123 sgd_solver.cpp:105] Iteration 126900, lr = 0.003655
I0529 05:05:15.208609 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_127000.caffemodel
I0529 05:05:15.690265 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_127000.solverstate
I0529 05:05:15.837596 11123 solver.cpp:330] Iteration 127000, Testing net (#0)
I0529 05:05:16.600059 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:05:20.290019 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 05:05:20.290055 11123 solver.cpp:397]     Test net output #1: loss = 0.238934 (* 1 = 0.238934 loss)
I0529 05:05:20.568176 11123 solver.cpp:218] Iteration 127000 (3.02087 iter/s, 33.103s/100 iters), loss = 0.000899321
I0529 05:05:20.568222 11123 solver.cpp:237]     Train net output #0: loss = 0.00089846 (* 1 = 0.00089846 loss)
I0529 05:05:20.568230 11123 sgd_solver.cpp:105] Iteration 127000, lr = 0.00365
I0529 05:05:48.533442 11123 solver.cpp:218] Iteration 127100 (3.57591 iter/s, 27.9649s/100 iters), loss = 0.000140214
I0529 05:05:48.533613 11123 solver.cpp:237]     Train net output #0: loss = 0.000139354 (* 1 = 0.000139354 loss)
I0529 05:05:48.533625 11123 sgd_solver.cpp:105] Iteration 127100, lr = 0.003645
I0529 05:06:16.512193 11123 solver.cpp:218] Iteration 127200 (3.5742 iter/s, 27.9783s/100 iters), loss = 7.64366e-06
I0529 05:06:16.512246 11123 solver.cpp:237]     Train net output #0: loss = 6.78319e-06 (* 1 = 6.78319e-06 loss)
I0529 05:06:16.512259 11123 sgd_solver.cpp:105] Iteration 127200, lr = 0.00364
I0529 05:06:44.492117 11123 solver.cpp:218] Iteration 127300 (3.57404 iter/s, 27.9795s/100 iters), loss = 7.64952e-05
I0529 05:06:44.492300 11123 solver.cpp:237]     Train net output #0: loss = 7.56348e-05 (* 1 = 7.56348e-05 loss)
I0529 05:06:44.492328 11123 sgd_solver.cpp:105] Iteration 127300, lr = 0.003635
I0529 05:07:12.518149 11123 solver.cpp:218] Iteration 127400 (3.56818 iter/s, 28.0255s/100 iters), loss = 6.25486e-06
I0529 05:07:12.518194 11123 solver.cpp:237]     Train net output #0: loss = 5.39438e-06 (* 1 = 5.39438e-06 loss)
I0529 05:07:12.518203 11123 sgd_solver.cpp:105] Iteration 127400, lr = 0.00363
I0529 05:07:28.786582 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:07:40.547410 11123 solver.cpp:218] Iteration 127500 (3.56775 iter/s, 28.0289s/100 iters), loss = 5.12721e-05
I0529 05:07:40.547456 11123 solver.cpp:237]     Train net output #0: loss = 5.04116e-05 (* 1 = 5.04116e-05 loss)
I0529 05:07:40.547466 11123 sgd_solver.cpp:105] Iteration 127500, lr = 0.003625
I0529 05:08:08.546174 11123 solver.cpp:218] Iteration 127600 (3.57164 iter/s, 27.9984s/100 iters), loss = 2.18814e-05
I0529 05:08:08.546392 11123 solver.cpp:237]     Train net output #0: loss = 2.10208e-05 (* 1 = 2.10208e-05 loss)
I0529 05:08:08.546403 11123 sgd_solver.cpp:105] Iteration 127600, lr = 0.00362
I0529 05:08:36.559995 11123 solver.cpp:218] Iteration 127700 (3.56974 iter/s, 28.0133s/100 iters), loss = 1.98261e-05
I0529 05:08:36.560039 11123 solver.cpp:237]     Train net output #0: loss = 1.89653e-05 (* 1 = 1.89653e-05 loss)
I0529 05:08:36.560047 11123 sgd_solver.cpp:105] Iteration 127700, lr = 0.003615
I0529 05:09:04.575345 11123 solver.cpp:218] Iteration 127800 (3.56952 iter/s, 28.015s/100 iters), loss = 4.8842e-06
I0529 05:09:04.575544 11123 solver.cpp:237]     Train net output #0: loss = 4.02337e-06 (* 1 = 4.02337e-06 loss)
I0529 05:09:04.575556 11123 sgd_solver.cpp:105] Iteration 127800, lr = 0.00361
I0529 05:09:32.593706 11123 solver.cpp:218] Iteration 127900 (3.56916 iter/s, 28.0178s/100 iters), loss = 0.000189143
I0529 05:09:32.593761 11123 solver.cpp:237]     Train net output #0: loss = 0.000188282 (* 1 = 0.000188282 loss)
I0529 05:09:32.593770 11123 sgd_solver.cpp:105] Iteration 127900, lr = 0.003605
I0529 05:10:00.338999 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_128000.caffemodel
I0529 05:10:00.808127 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_128000.solverstate
I0529 05:10:00.954025 11123 solver.cpp:330] Iteration 128000, Testing net (#0)
I0529 05:10:03.226582 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:10:05.401584 11123 solver.cpp:397]     Test net output #0: accuracy = 0.933
I0529 05:10:05.401621 11123 solver.cpp:397]     Test net output #1: loss = 0.271926 (* 1 = 0.271926 loss)
I0529 05:10:05.678747 11123 solver.cpp:218] Iteration 128000 (3.02256 iter/s, 33.0845s/100 iters), loss = 8.7343e-06
I0529 05:10:05.678798 11123 solver.cpp:237]     Train net output #0: loss = 7.87407e-06 (* 1 = 7.87407e-06 loss)
I0529 05:10:05.678808 11123 sgd_solver.cpp:105] Iteration 128000, lr = 0.0036
I0529 05:10:25.575963 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:10:33.681746 11123 solver.cpp:218] Iteration 128100 (3.5711 iter/s, 28.0026s/100 iters), loss = 0.00013111
I0529 05:10:33.681955 11123 solver.cpp:237]     Train net output #0: loss = 0.00013025 (* 1 = 0.00013025 loss)
I0529 05:10:33.681967 11123 sgd_solver.cpp:105] Iteration 128100, lr = 0.003595
I0529 05:11:01.674278 11123 solver.cpp:218] Iteration 128200 (3.57245 iter/s, 27.992s/100 iters), loss = 3.67871e-05
I0529 05:11:01.674332 11123 solver.cpp:237]     Train net output #0: loss = 3.59272e-05 (* 1 = 3.59272e-05 loss)
I0529 05:11:01.674341 11123 sgd_solver.cpp:105] Iteration 128200, lr = 0.00359
I0529 05:11:29.651700 11123 solver.cpp:218] Iteration 128300 (3.57437 iter/s, 27.977s/100 iters), loss = 8.84236e-05
I0529 05:11:29.651873 11123 solver.cpp:237]     Train net output #0: loss = 8.75637e-05 (* 1 = 8.75637e-05 loss)
I0529 05:11:29.651885 11123 sgd_solver.cpp:105] Iteration 128300, lr = 0.003585
I0529 05:11:57.617699 11123 solver.cpp:218] Iteration 128400 (3.57584 iter/s, 27.9654s/100 iters), loss = 7.70261e-06
I0529 05:11:57.617758 11123 solver.cpp:237]     Train net output #0: loss = 6.84277e-06 (* 1 = 6.84277e-06 loss)
I0529 05:11:57.617766 11123 sgd_solver.cpp:105] Iteration 128400, lr = 0.00358
I0529 05:12:25.595499 11123 solver.cpp:218] Iteration 128500 (3.57432 iter/s, 27.9774s/100 iters), loss = 1.67648e-06
I0529 05:12:25.595708 11123 solver.cpp:237]     Train net output #0: loss = 8.16589e-07 (* 1 = 8.16589e-07 loss)
I0529 05:12:25.595721 11123 sgd_solver.cpp:105] Iteration 128500, lr = 0.003575
I0529 05:12:53.573580 11123 solver.cpp:218] Iteration 128600 (3.5743 iter/s, 27.9775s/100 iters), loss = 4.59712e-06
I0529 05:12:53.573628 11123 solver.cpp:237]     Train net output #0: loss = 3.73731e-06 (* 1 = 3.73731e-06 loss)
I0529 05:12:53.573637 11123 sgd_solver.cpp:105] Iteration 128600, lr = 0.00357
I0529 05:13:16.820530 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:13:21.562130 11123 solver.cpp:218] Iteration 128700 (3.57294 iter/s, 27.9881s/100 iters), loss = 5.20754e-06
I0529 05:13:21.562175 11123 solver.cpp:237]     Train net output #0: loss = 4.34525e-06 (* 1 = 4.34525e-06 loss)
I0529 05:13:21.562182 11123 sgd_solver.cpp:105] Iteration 128700, lr = 0.003565
I0529 05:13:49.530369 11123 solver.cpp:218] Iteration 128800 (3.57554 iter/s, 27.9678s/100 iters), loss = 1.86667e-05
I0529 05:13:49.530557 11123 solver.cpp:237]     Train net output #0: loss = 1.78022e-05 (* 1 = 1.78022e-05 loss)
I0529 05:13:49.530570 11123 sgd_solver.cpp:105] Iteration 128800, lr = 0.00356
I0529 05:14:17.498212 11123 solver.cpp:218] Iteration 128900 (3.57561 iter/s, 27.9673s/100 iters), loss = 4.54101e-05
I0529 05:14:17.498268 11123 solver.cpp:237]     Train net output #0: loss = 4.45457e-05 (* 1 = 4.45457e-05 loss)
I0529 05:14:17.498277 11123 sgd_solver.cpp:105] Iteration 128900, lr = 0.003555
I0529 05:14:45.197396 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_129000.caffemodel
I0529 05:14:45.815913 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_129000.solverstate
I0529 05:14:45.965348 11123 solver.cpp:330] Iteration 129000, Testing net (#0)
I0529 05:14:49.746639 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:14:50.408498 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939001
I0529 05:14:50.408536 11123 solver.cpp:397]     Test net output #1: loss = 0.275337 (* 1 = 0.275337 loss)
I0529 05:14:50.686151 11123 solver.cpp:218] Iteration 129000 (3.01319 iter/s, 33.1874s/100 iters), loss = 5.86138e-05
I0529 05:14:50.686204 11123 solver.cpp:237]     Train net output #0: loss = 5.77494e-05 (* 1 = 5.77494e-05 loss)
I0529 05:14:50.686213 11123 sgd_solver.cpp:105] Iteration 129000, lr = 0.00355
I0529 05:15:18.681444 11123 solver.cpp:218] Iteration 129100 (3.57209 iter/s, 27.9948s/100 iters), loss = 5.03045e-05
I0529 05:15:18.681653 11123 solver.cpp:237]     Train net output #0: loss = 4.94399e-05 (* 1 = 4.94399e-05 loss)
I0529 05:15:18.681666 11123 sgd_solver.cpp:105] Iteration 129100, lr = 0.003545
I0529 05:15:46.641048 11123 solver.cpp:218] Iteration 129200 (3.57666 iter/s, 27.959s/100 iters), loss = 2.86753e-06
I0529 05:15:46.641103 11123 solver.cpp:237]     Train net output #0: loss = 2.00273e-06 (* 1 = 2.00273e-06 loss)
I0529 05:15:46.641113 11123 sgd_solver.cpp:105] Iteration 129200, lr = 0.00354
I0529 05:16:13.522497 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:16:14.625277 11123 solver.cpp:218] Iteration 129300 (3.5735 iter/s, 27.9838s/100 iters), loss = 1.60444e-05
I0529 05:16:14.625331 11123 solver.cpp:237]     Train net output #0: loss = 1.51799e-05 (* 1 = 1.51799e-05 loss)
I0529 05:16:14.625340 11123 sgd_solver.cpp:105] Iteration 129300, lr = 0.003535
I0529 05:16:42.624099 11123 solver.cpp:218] Iteration 129400 (3.57164 iter/s, 27.9984s/100 iters), loss = 1.65134e-06
I0529 05:16:42.624155 11123 solver.cpp:237]     Train net output #0: loss = 7.86784e-07 (* 1 = 7.86784e-07 loss)
I0529 05:16:42.624163 11123 sgd_solver.cpp:105] Iteration 129400, lr = 0.00353
I0529 05:17:10.650497 11123 solver.cpp:218] Iteration 129500 (3.56812 iter/s, 28.0259s/100 iters), loss = 3.77347e-06
I0529 05:17:10.650745 11123 solver.cpp:237]     Train net output #0: loss = 2.90877e-06 (* 1 = 2.90877e-06 loss)
I0529 05:17:10.650758 11123 sgd_solver.cpp:105] Iteration 129500, lr = 0.003525
I0529 05:17:38.664623 11123 solver.cpp:218] Iteration 129600 (3.56971 iter/s, 28.0135s/100 iters), loss = 2.80807e-05
I0529 05:17:38.664687 11123 solver.cpp:237]     Train net output #0: loss = 2.72169e-05 (* 1 = 2.72169e-05 loss)
I0529 05:17:38.664696 11123 sgd_solver.cpp:105] Iteration 129600, lr = 0.00352
I0529 05:18:06.689391 11123 solver.cpp:218] Iteration 129700 (3.56833 iter/s, 28.0243s/100 iters), loss = 4.38994e-05
I0529 05:18:06.689554 11123 solver.cpp:237]     Train net output #0: loss = 4.30363e-05 (* 1 = 4.30363e-05 loss)
I0529 05:18:06.689566 11123 sgd_solver.cpp:105] Iteration 129700, lr = 0.003515
I0529 05:18:34.672997 11123 solver.cpp:218] Iteration 129800 (3.57359 iter/s, 27.983s/100 iters), loss = 2.32334e-06
I0529 05:18:34.673069 11123 solver.cpp:237]     Train net output #0: loss = 1.46032e-06 (* 1 = 1.46032e-06 loss)
I0529 05:18:34.673079 11123 sgd_solver.cpp:105] Iteration 129800, lr = 0.00351
I0529 05:19:02.693358 11123 solver.cpp:218] Iteration 129900 (3.5689 iter/s, 28.0199s/100 iters), loss = 1.14669e-05
I0529 05:19:02.693569 11123 solver.cpp:237]     Train net output #0: loss = 1.06039e-05 (* 1 = 1.06039e-05 loss)
I0529 05:19:02.693581 11123 sgd_solver.cpp:105] Iteration 129900, lr = 0.003505
I0529 05:19:05.234463 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:19:30.442062 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_130000.caffemodel
I0529 05:19:31.057695 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_130000.solverstate
I0529 05:19:31.206183 11123 solver.cpp:330] Iteration 130000, Testing net (#0)
I0529 05:19:35.630028 11123 solver.cpp:397]     Test net output #0: accuracy = 0.938001
I0529 05:19:35.630139 11123 solver.cpp:397]     Test net output #1: loss = 0.250015 (* 1 = 0.250015 loss)
I0529 05:19:35.906381 11123 solver.cpp:218] Iteration 130000 (3.01093 iter/s, 33.2123s/100 iters), loss = 6.97863e-06
I0529 05:19:35.906424 11123 solver.cpp:237]     Train net output #0: loss = 6.11573e-06 (* 1 = 6.11573e-06 loss)
I0529 05:19:35.906432 11123 sgd_solver.cpp:105] Iteration 130000, lr = 0.0035
I0529 05:20:03.910887 11123 solver.cpp:218] Iteration 130100 (3.57091 iter/s, 28.0041s/100 iters), loss = 1.15067e-05
I0529 05:20:03.910939 11123 solver.cpp:237]     Train net output #0: loss = 1.06433e-05 (* 1 = 1.06433e-05 loss)
I0529 05:20:03.910949 11123 sgd_solver.cpp:105] Iteration 130100, lr = 0.003495
I0529 05:20:31.936617 11123 solver.cpp:218] Iteration 130200 (3.56821 iter/s, 28.0253s/100 iters), loss = 0.0001432
I0529 05:20:31.936841 11123 solver.cpp:237]     Train net output #0: loss = 0.000142336 (* 1 = 0.000142336 loss)
I0529 05:20:31.936852 11123 sgd_solver.cpp:105] Iteration 130200, lr = 0.00349
I0529 05:20:59.915187 11123 solver.cpp:218] Iteration 130300 (3.57424 iter/s, 27.9779s/100 iters), loss = 3.2146e-05
I0529 05:20:59.915235 11123 solver.cpp:237]     Train net output #0: loss = 3.12828e-05 (* 1 = 3.12828e-05 loss)
I0529 05:20:59.915244 11123 sgd_solver.cpp:105] Iteration 130300, lr = 0.003485
I0529 05:21:27.907037 11123 solver.cpp:218] Iteration 130400 (3.57253 iter/s, 27.9914s/100 iters), loss = 4.10108e-05
I0529 05:21:27.907196 11123 solver.cpp:237]     Train net output #0: loss = 4.01475e-05 (* 1 = 4.01475e-05 loss)
I0529 05:21:27.907208 11123 sgd_solver.cpp:105] Iteration 130400, lr = 0.00348
I0529 05:21:55.891959 11123 solver.cpp:218] Iteration 130500 (3.57343 iter/s, 27.9844s/100 iters), loss = 4.3335e-05
I0529 05:21:55.892004 11123 solver.cpp:237]     Train net output #0: loss = 4.24717e-05 (* 1 = 4.24717e-05 loss)
I0529 05:21:55.892014 11123 sgd_solver.cpp:105] Iteration 130500, lr = 0.003475
I0529 05:22:02.072013 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:22:23.889648 11123 solver.cpp:218] Iteration 130600 (3.57178 iter/s, 27.9972s/100 iters), loss = 3.29832e-05
I0529 05:22:23.889695 11123 solver.cpp:237]     Train net output #0: loss = 3.21196e-05 (* 1 = 3.21196e-05 loss)
I0529 05:22:23.889704 11123 sgd_solver.cpp:105] Iteration 130600, lr = 0.00347
I0529 05:22:51.889494 11123 solver.cpp:218] Iteration 130700 (3.57151 iter/s, 27.9994s/100 iters), loss = 7.65876e-05
I0529 05:22:51.889657 11123 solver.cpp:237]     Train net output #0: loss = 7.57241e-05 (* 1 = 7.57241e-05 loss)
I0529 05:22:51.889672 11123 sgd_solver.cpp:105] Iteration 130700, lr = 0.003465
I0529 05:23:19.906013 11123 solver.cpp:218] Iteration 130800 (3.5694 iter/s, 28.016s/100 iters), loss = 4.15956e-06
I0529 05:23:19.906069 11123 solver.cpp:237]     Train net output #0: loss = 3.29618e-06 (* 1 = 3.29618e-06 loss)
I0529 05:23:19.906078 11123 sgd_solver.cpp:105] Iteration 130800, lr = 0.00346
I0529 05:23:47.915704 11123 solver.cpp:218] Iteration 130900 (3.57025 iter/s, 28.0092s/100 iters), loss = 0.00155816
I0529 05:23:47.915838 11123 solver.cpp:237]     Train net output #0: loss = 0.0015573 (* 1 = 0.0015573 loss)
I0529 05:23:47.915848 11123 sgd_solver.cpp:105] Iteration 130900, lr = 0.003455
I0529 05:24:15.655616 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_131000.caffemodel
I0529 05:24:16.197160 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_131000.solverstate
I0529 05:24:16.344604 11123 solver.cpp:330] Iteration 131000, Testing net (#0)
I0529 05:24:17.190768 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:24:20.770170 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 05:24:20.770328 11123 solver.cpp:397]     Test net output #1: loss = 0.24004 (* 1 = 0.24004 loss)
I0529 05:24:21.047219 11123 solver.cpp:218] Iteration 131000 (3.01833 iter/s, 33.1309s/100 iters), loss = 9.12814e-05
I0529 05:24:21.047272 11123 solver.cpp:237]     Train net output #0: loss = 9.04168e-05 (* 1 = 9.04168e-05 loss)
I0529 05:24:21.047281 11123 sgd_solver.cpp:105] Iteration 131000, lr = 0.00345
I0529 05:24:49.038760 11123 solver.cpp:218] Iteration 131100 (3.57257 iter/s, 27.9911s/100 iters), loss = 0.000322873
I0529 05:24:49.038807 11123 solver.cpp:237]     Train net output #0: loss = 0.000322009 (* 1 = 0.000322009 loss)
I0529 05:24:49.038816 11123 sgd_solver.cpp:105] Iteration 131100, lr = 0.003445
I0529 05:24:58.858145 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:25:17.068452 11123 solver.cpp:218] Iteration 131200 (3.5677 iter/s, 28.0292s/100 iters), loss = 4.28561e-06
I0529 05:25:17.068508 11123 solver.cpp:237]     Train net output #0: loss = 3.4214e-06 (* 1 = 3.4214e-06 loss)
I0529 05:25:17.068518 11123 sgd_solver.cpp:105] Iteration 131200, lr = 0.00344
I0529 05:25:45.088759 11123 solver.cpp:218] Iteration 131300 (3.5689 iter/s, 28.0198s/100 iters), loss = 3.82658e-06
I0529 05:25:45.088995 11123 solver.cpp:237]     Train net output #0: loss = 2.96237e-06 (* 1 = 2.96237e-06 loss)
I0529 05:25:45.089009 11123 sgd_solver.cpp:105] Iteration 131300, lr = 0.003435
I0529 05:26:13.107287 11123 solver.cpp:218] Iteration 131400 (3.56915 iter/s, 28.0179s/100 iters), loss = 0.000470878
I0529 05:26:13.107347 11123 solver.cpp:237]     Train net output #0: loss = 0.000470014 (* 1 = 0.000470014 loss)
I0529 05:26:13.107357 11123 sgd_solver.cpp:105] Iteration 131400, lr = 0.00343
I0529 05:26:41.116814 11123 solver.cpp:218] Iteration 131500 (3.57027 iter/s, 28.009s/100 iters), loss = 2.98611e-06
I0529 05:26:41.116981 11123 solver.cpp:237]     Train net output #0: loss = 2.12195e-06 (* 1 = 2.12195e-06 loss)
I0529 05:26:41.117007 11123 sgd_solver.cpp:105] Iteration 131500, lr = 0.003425
I0529 05:27:09.148217 11123 solver.cpp:218] Iteration 131600 (3.5675 iter/s, 28.0308s/100 iters), loss = 9.30732e-05
I0529 05:27:09.148262 11123 solver.cpp:237]     Train net output #0: loss = 9.2209e-05 (* 1 = 9.2209e-05 loss)
I0529 05:27:09.148270 11123 sgd_solver.cpp:105] Iteration 131600, lr = 0.00342
I0529 05:27:37.145429 11123 solver.cpp:218] Iteration 131700 (3.57184 iter/s, 27.9967s/100 iters), loss = 0.000210342
I0529 05:27:37.145656 11123 solver.cpp:237]     Train net output #0: loss = 0.000209479 (* 1 = 0.000209479 loss)
I0529 05:27:37.145668 11123 sgd_solver.cpp:105] Iteration 131700, lr = 0.003415
I0529 05:27:50.321957 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:28:05.162963 11123 solver.cpp:218] Iteration 131800 (3.56927 iter/s, 28.0169s/100 iters), loss = 4.96122e-05
I0529 05:28:05.163012 11123 solver.cpp:237]     Train net output #0: loss = 4.87487e-05 (* 1 = 4.87487e-05 loss)
I0529 05:28:05.163020 11123 sgd_solver.cpp:105] Iteration 131800, lr = 0.00341
I0529 05:28:33.178313 11123 solver.cpp:218] Iteration 131900 (3.56953 iter/s, 28.0149s/100 iters), loss = 4.97624e-06
I0529 05:28:33.178472 11123 solver.cpp:237]     Train net output #0: loss = 4.11279e-06 (* 1 = 4.11279e-06 loss)
I0529 05:28:33.178483 11123 sgd_solver.cpp:105] Iteration 131900, lr = 0.003405
I0529 05:29:00.906580 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_132000.caffemodel
I0529 05:29:01.384043 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_132000.solverstate
I0529 05:29:01.542390 11123 solver.cpp:330] Iteration 132000, Testing net (#0)
I0529 05:29:03.889839 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:29:05.965840 11123 solver.cpp:397]     Test net output #0: accuracy = 0.931
I0529 05:29:05.965875 11123 solver.cpp:397]     Test net output #1: loss = 0.275019 (* 1 = 0.275019 loss)
I0529 05:29:06.242907 11123 solver.cpp:218] Iteration 132000 (3.02444 iter/s, 33.0639s/100 iters), loss = 9.74443e-05
I0529 05:29:06.242949 11123 solver.cpp:237]     Train net output #0: loss = 9.65808e-05 (* 1 = 9.65808e-05 loss)
I0529 05:29:06.242956 11123 sgd_solver.cpp:105] Iteration 132000, lr = 0.0034
I0529 05:29:34.225741 11123 solver.cpp:218] Iteration 132100 (3.57368 iter/s, 27.9824s/100 iters), loss = 9.35287e-05
I0529 05:29:34.225898 11123 solver.cpp:237]     Train net output #0: loss = 9.26653e-05 (* 1 = 9.26653e-05 loss)
I0529 05:29:34.225909 11123 sgd_solver.cpp:105] Iteration 132100, lr = 0.003395
I0529 05:30:02.237442 11123 solver.cpp:218] Iteration 132200 (3.57001 iter/s, 28.0111s/100 iters), loss = 0.000155968
I0529 05:30:02.237486 11123 solver.cpp:237]     Train net output #0: loss = 0.000155104 (* 1 = 0.000155104 loss)
I0529 05:30:02.237494 11123 sgd_solver.cpp:105] Iteration 132200, lr = 0.00339
I0529 05:30:30.224721 11123 solver.cpp:218] Iteration 132300 (3.57311 iter/s, 27.9868s/100 iters), loss = 6.26371e-06
I0529 05:30:30.224875 11123 solver.cpp:237]     Train net output #0: loss = 5.4003e-06 (* 1 = 5.4003e-06 loss)
I0529 05:30:30.224887 11123 sgd_solver.cpp:105] Iteration 132300, lr = 0.003385
I0529 05:30:47.046764 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:30:58.224259 11123 solver.cpp:218] Iteration 132400 (3.57156 iter/s, 27.999s/100 iters), loss = 7.82943e-05
I0529 05:30:58.224305 11123 solver.cpp:237]     Train net output #0: loss = 7.74308e-05 (* 1 = 7.74308e-05 loss)
I0529 05:30:58.224313 11123 sgd_solver.cpp:105] Iteration 132400, lr = 0.00338
I0529 05:31:26.239656 11123 solver.cpp:218] Iteration 132500 (3.56953 iter/s, 28.0149s/100 iters), loss = 6.46292e-05
I0529 05:31:26.239811 11123 solver.cpp:237]     Train net output #0: loss = 6.37657e-05 (* 1 = 6.37657e-05 loss)
I0529 05:31:26.239823 11123 sgd_solver.cpp:105] Iteration 132500, lr = 0.003375
I0529 05:31:54.228178 11123 solver.cpp:218] Iteration 132600 (3.57297 iter/s, 27.9879s/100 iters), loss = 0.000258837
I0529 05:31:54.228231 11123 solver.cpp:237]     Train net output #0: loss = 0.000257976 (* 1 = 0.000257976 loss)
I0529 05:31:54.228240 11123 sgd_solver.cpp:105] Iteration 132600, lr = 0.00337
I0529 05:32:22.221274 11123 solver.cpp:218] Iteration 132700 (3.57237 iter/s, 27.9926s/100 iters), loss = 2.1345e-05
I0529 05:32:22.221439 11123 solver.cpp:237]     Train net output #0: loss = 2.04837e-05 (* 1 = 2.04837e-05 loss)
I0529 05:32:22.221451 11123 sgd_solver.cpp:105] Iteration 132700, lr = 0.003365
I0529 05:32:50.214296 11123 solver.cpp:218] Iteration 132800 (3.57239 iter/s, 27.9924s/100 iters), loss = 5.07572e-06
I0529 05:32:50.214340 11123 solver.cpp:237]     Train net output #0: loss = 4.21415e-06 (* 1 = 4.21415e-06 loss)
I0529 05:32:50.214349 11123 sgd_solver.cpp:105] Iteration 132800, lr = 0.00336
I0529 05:33:18.222046 11123 solver.cpp:218] Iteration 132900 (3.5705 iter/s, 28.0073s/100 iters), loss = 2.0899e-05
I0529 05:33:18.222215 11123 solver.cpp:237]     Train net output #0: loss = 2.00374e-05 (* 1 = 2.00374e-05 loss)
I0529 05:33:18.222226 11123 sgd_solver.cpp:105] Iteration 132900, lr = 0.003355
I0529 05:33:38.668658 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:33:45.930110 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_133000.caffemodel
I0529 05:33:46.391947 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_133000.solverstate
I0529 05:33:46.538519 11123 solver.cpp:330] Iteration 133000, Testing net (#0)
I0529 05:33:50.371367 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:33:50.988998 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948
I0529 05:33:50.989049 11123 solver.cpp:397]     Test net output #1: loss = 0.266114 (* 1 = 0.266114 loss)
I0529 05:33:51.266796 11123 solver.cpp:218] Iteration 133000 (3.02626 iter/s, 33.0441s/100 iters), loss = 1.48761e-06
I0529 05:33:51.266852 11123 solver.cpp:237]     Train net output #0: loss = 6.2585e-07 (* 1 = 6.2585e-07 loss)
I0529 05:33:51.266861 11123 sgd_solver.cpp:105] Iteration 133000, lr = 0.00335
I0529 05:34:19.270473 11123 solver.cpp:218] Iteration 133100 (3.57102 iter/s, 28.0032s/100 iters), loss = 1.18716e-05
I0529 05:34:19.270532 11123 solver.cpp:237]     Train net output #0: loss = 1.10097e-05 (* 1 = 1.10097e-05 loss)
I0529 05:34:19.270542 11123 sgd_solver.cpp:105] Iteration 133100, lr = 0.003345
I0529 05:34:47.252503 11123 solver.cpp:218] Iteration 133200 (3.57378 iter/s, 27.9815s/100 iters), loss = 7.53792e-06
I0529 05:34:47.252637 11123 solver.cpp:237]     Train net output #0: loss = 6.67596e-06 (* 1 = 6.67596e-06 loss)
I0529 05:34:47.252650 11123 sgd_solver.cpp:105] Iteration 133200, lr = 0.00334
I0529 05:35:15.255390 11123 solver.cpp:218] Iteration 133300 (3.57113 iter/s, 28.0023s/100 iters), loss = 0.000151576
I0529 05:35:15.255450 11123 solver.cpp:237]     Train net output #0: loss = 0.000150714 (* 1 = 0.000150714 loss)
I0529 05:35:15.255460 11123 sgd_solver.cpp:105] Iteration 133300, lr = 0.003335
I0529 05:35:43.243291 11123 solver.cpp:218] Iteration 133400 (3.57303 iter/s, 27.9874s/100 iters), loss = 2.358e-05
I0529 05:35:43.243486 11123 solver.cpp:237]     Train net output #0: loss = 2.27182e-05 (* 1 = 2.27182e-05 loss)
I0529 05:35:43.243515 11123 sgd_solver.cpp:105] Iteration 133400, lr = 0.00333
I0529 05:36:11.240249 11123 solver.cpp:218] Iteration 133500 (3.5719 iter/s, 27.9963s/100 iters), loss = 1.03033e-05
I0529 05:36:11.240291 11123 solver.cpp:237]     Train net output #0: loss = 9.44159e-06 (* 1 = 9.44159e-06 loss)
I0529 05:36:11.240301 11123 sgd_solver.cpp:105] Iteration 133500, lr = 0.003325
I0529 05:36:35.324946 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:36:39.227579 11123 solver.cpp:218] Iteration 133600 (3.57311 iter/s, 27.9869s/100 iters), loss = 7.77167e-05
I0529 05:36:39.227625 11123 solver.cpp:237]     Train net output #0: loss = 7.68552e-05 (* 1 = 7.68552e-05 loss)
I0529 05:36:39.227634 11123 sgd_solver.cpp:105] Iteration 133600, lr = 0.00332
I0529 05:37:07.206637 11123 solver.cpp:218] Iteration 133700 (3.57416 iter/s, 27.9786s/100 iters), loss = 1.01872e-05
I0529 05:37:07.206780 11123 solver.cpp:237]     Train net output #0: loss = 9.32592e-06 (* 1 = 9.32592e-06 loss)
I0529 05:37:07.206795 11123 sgd_solver.cpp:105] Iteration 133700, lr = 0.003315
I0529 05:37:35.193104 11123 solver.cpp:218] Iteration 133800 (3.57323 iter/s, 27.9859s/100 iters), loss = 2.44431e-05
I0529 05:37:35.193150 11123 solver.cpp:237]     Train net output #0: loss = 2.35816e-05 (* 1 = 2.35816e-05 loss)
I0529 05:37:35.193158 11123 sgd_solver.cpp:105] Iteration 133800, lr = 0.00331
I0529 05:38:03.183209 11123 solver.cpp:218] Iteration 133900 (3.57275 iter/s, 27.9896s/100 iters), loss = 0.000155371
I0529 05:38:03.183367 11123 solver.cpp:237]     Train net output #0: loss = 0.00015451 (* 1 = 0.00015451 loss)
I0529 05:38:03.183377 11123 sgd_solver.cpp:105] Iteration 133900, lr = 0.003305
I0529 05:38:30.893992 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_134000.caffemodel
I0529 05:38:31.445332 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_134000.solverstate
I0529 05:38:31.592422 11123 solver.cpp:330] Iteration 134000, Testing net (#0)
I0529 05:38:36.035122 11123 solver.cpp:397]     Test net output #0: accuracy = 0.936
I0529 05:38:36.035286 11123 solver.cpp:397]     Test net output #1: loss = 0.257009 (* 1 = 0.257009 loss)
I0529 05:38:36.311722 11123 solver.cpp:218] Iteration 134000 (3.01861 iter/s, 33.1279s/100 iters), loss = 8.69719e-05
I0529 05:38:36.311764 11123 solver.cpp:237]     Train net output #0: loss = 8.61105e-05 (* 1 = 8.61105e-05 loss)
I0529 05:38:36.311772 11123 sgd_solver.cpp:105] Iteration 134000, lr = 0.0033
I0529 05:39:04.297973 11123 solver.cpp:218] Iteration 134100 (3.57324 iter/s, 27.9858s/100 iters), loss = 6.97098e-06
I0529 05:39:04.298017 11123 solver.cpp:237]     Train net output #0: loss = 6.10962e-06 (* 1 = 6.10962e-06 loss)
I0529 05:39:04.298025 11123 sgd_solver.cpp:105] Iteration 134100, lr = 0.003295
I0529 05:39:32.018152 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:39:32.284879 11123 solver.cpp:218] Iteration 134200 (3.57316 iter/s, 27.9864s/100 iters), loss = 9.38192e-05
I0529 05:39:32.284937 11123 solver.cpp:237]     Train net output #0: loss = 9.29579e-05 (* 1 = 9.29579e-05 loss)
I0529 05:39:32.284946 11123 sgd_solver.cpp:105] Iteration 134200, lr = 0.00329
I0529 05:40:00.269162 11123 solver.cpp:218] Iteration 134300 (3.5735 iter/s, 27.9838s/100 iters), loss = 6.169e-05
I0529 05:40:00.269207 11123 solver.cpp:237]     Train net output #0: loss = 6.08287e-05 (* 1 = 6.08287e-05 loss)
I0529 05:40:00.269217 11123 sgd_solver.cpp:105] Iteration 134300, lr = 0.003285
I0529 05:40:28.240905 11123 solver.cpp:218] Iteration 134400 (3.5751 iter/s, 27.9713s/100 iters), loss = 1.16146e-05
I0529 05:40:28.241070 11123 solver.cpp:237]     Train net output #0: loss = 1.07534e-05 (* 1 = 1.07534e-05 loss)
I0529 05:40:28.241080 11123 sgd_solver.cpp:105] Iteration 134400, lr = 0.00328
I0529 05:40:56.203732 11123 solver.cpp:218] Iteration 134500 (3.57625 iter/s, 27.9622s/100 iters), loss = 2.08596e-05
I0529 05:40:56.203791 11123 solver.cpp:237]     Train net output #0: loss = 1.99984e-05 (* 1 = 1.99984e-05 loss)
I0529 05:40:56.203800 11123 sgd_solver.cpp:105] Iteration 134500, lr = 0.003275
I0529 05:41:24.207378 11123 solver.cpp:218] Iteration 134600 (3.57103 iter/s, 28.0032s/100 iters), loss = 0.000161365
I0529 05:41:24.207589 11123 solver.cpp:237]     Train net output #0: loss = 0.000160504 (* 1 = 0.000160504 loss)
I0529 05:41:24.207602 11123 sgd_solver.cpp:105] Iteration 134600, lr = 0.00327
I0529 05:41:52.180025 11123 solver.cpp:218] Iteration 134700 (3.575 iter/s, 27.972s/100 iters), loss = 0.00030142
I0529 05:41:52.180070 11123 solver.cpp:237]     Train net output #0: loss = 0.000300559 (* 1 = 0.000300559 loss)
I0529 05:41:52.180079 11123 sgd_solver.cpp:105] Iteration 134700, lr = 0.003265
I0529 05:42:20.194599 11123 solver.cpp:218] Iteration 134800 (3.56963 iter/s, 28.0141s/100 iters), loss = 7.37624e-05
I0529 05:42:20.194757 11123 solver.cpp:237]     Train net output #0: loss = 7.29011e-05 (* 1 = 7.29011e-05 loss)
I0529 05:42:20.194768 11123 sgd_solver.cpp:105] Iteration 134800, lr = 0.00326
I0529 05:42:23.296661 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:42:48.167388 11123 solver.cpp:218] Iteration 134900 (3.57498 iter/s, 27.9722s/100 iters), loss = 2.48182e-05
I0529 05:42:48.167434 11123 solver.cpp:237]     Train net output #0: loss = 2.39569e-05 (* 1 = 2.39569e-05 loss)
I0529 05:42:48.167443 11123 sgd_solver.cpp:105] Iteration 134900, lr = 0.003255
I0529 05:43:15.883291 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_135000.caffemodel
I0529 05:43:16.439786 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_135000.solverstate
I0529 05:43:16.586428 11123 solver.cpp:330] Iteration 135000, Testing net (#0)
I0529 05:43:17.483839 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:43:21.033902 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 05:43:21.033956 11123 solver.cpp:397]     Test net output #1: loss = 0.244583 (* 1 = 0.244583 loss)
I0529 05:43:21.310581 11123 solver.cpp:218] Iteration 135000 (3.01726 iter/s, 33.1426s/100 iters), loss = 9.4211e-06
I0529 05:43:21.310631 11123 solver.cpp:237]     Train net output #0: loss = 8.55984e-06 (* 1 = 8.55984e-06 loss)
I0529 05:43:21.310642 11123 sgd_solver.cpp:105] Iteration 135000, lr = 0.00325
I0529 05:43:49.296525 11123 solver.cpp:218] Iteration 135100 (3.57328 iter/s, 27.9855s/100 iters), loss = 4.72981e-06
I0529 05:43:49.296775 11123 solver.cpp:237]     Train net output #0: loss = 3.86848e-06 (* 1 = 3.86848e-06 loss)
I0529 05:43:49.296787 11123 sgd_solver.cpp:105] Iteration 135100, lr = 0.003245
I0529 05:44:17.267983 11123 solver.cpp:218] Iteration 135200 (3.57516 iter/s, 27.9708s/100 iters), loss = 0.000133439
I0529 05:44:17.268026 11123 solver.cpp:237]     Train net output #0: loss = 0.000132577 (* 1 = 0.000132577 loss)
I0529 05:44:17.268034 11123 sgd_solver.cpp:105] Iteration 135200, lr = 0.00324
I0529 05:44:45.233942 11123 solver.cpp:218] Iteration 135300 (3.57584 iter/s, 27.9655s/100 iters), loss = 5.13976e-05
I0529 05:44:45.234104 11123 solver.cpp:237]     Train net output #0: loss = 5.05347e-05 (* 1 = 5.05347e-05 loss)
I0529 05:44:45.234125 11123 sgd_solver.cpp:105] Iteration 135300, lr = 0.003235
I0529 05:45:13.253883 11123 solver.cpp:218] Iteration 135400 (3.56896 iter/s, 28.0194s/100 iters), loss = 2.1568e-05
I0529 05:45:13.253928 11123 solver.cpp:237]     Train net output #0: loss = 2.07051e-05 (* 1 = 2.07051e-05 loss)
I0529 05:45:13.253938 11123 sgd_solver.cpp:105] Iteration 135400, lr = 0.00323
I0529 05:45:19.990792 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:45:41.218261 11123 solver.cpp:218] Iteration 135500 (3.57604 iter/s, 27.9639s/100 iters), loss = 1.54049e-05
I0529 05:45:41.218307 11123 solver.cpp:237]     Train net output #0: loss = 1.45421e-05 (* 1 = 1.45421e-05 loss)
I0529 05:45:41.218315 11123 sgd_solver.cpp:105] Iteration 135500, lr = 0.003225
I0529 05:46:09.193676 11123 solver.cpp:218] Iteration 135600 (3.57463 iter/s, 27.9749s/100 iters), loss = 5.23192e-06
I0529 05:46:09.193842 11123 solver.cpp:237]     Train net output #0: loss = 4.36912e-06 (* 1 = 4.36912e-06 loss)
I0529 05:46:09.193853 11123 sgd_solver.cpp:105] Iteration 135600, lr = 0.00322
I0529 05:46:37.156715 11123 solver.cpp:218] Iteration 135700 (3.57622 iter/s, 27.9624s/100 iters), loss = 5.64376e-05
I0529 05:46:37.156759 11123 solver.cpp:237]     Train net output #0: loss = 5.55749e-05 (* 1 = 5.55749e-05 loss)
I0529 05:46:37.156767 11123 sgd_solver.cpp:105] Iteration 135700, lr = 0.003215
I0529 05:47:05.148656 11123 solver.cpp:218] Iteration 135800 (3.57252 iter/s, 27.9915s/100 iters), loss = 2.75872e-05
I0529 05:47:05.148793 11123 solver.cpp:237]     Train net output #0: loss = 2.67246e-05 (* 1 = 2.67246e-05 loss)
I0529 05:47:05.148807 11123 sgd_solver.cpp:105] Iteration 135800, lr = 0.00321
I0529 05:47:33.180130 11123 solver.cpp:218] Iteration 135900 (3.56749 iter/s, 28.0309s/100 iters), loss = 0.000104854
I0529 05:47:33.180176 11123 solver.cpp:237]     Train net output #0: loss = 0.000103992 (* 1 = 0.000103992 loss)
I0529 05:47:33.180184 11123 sgd_solver.cpp:105] Iteration 135900, lr = 0.003205
I0529 05:48:00.907541 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_136000.caffemodel
I0529 05:48:01.450911 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_136000.solverstate
I0529 05:48:01.596941 11123 solver.cpp:330] Iteration 136000, Testing net (#0)
I0529 05:48:04.003540 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:48:06.044826 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 05:48:06.044874 11123 solver.cpp:397]     Test net output #1: loss = 0.269776 (* 1 = 0.269776 loss)
I0529 05:48:06.320863 11123 solver.cpp:218] Iteration 136000 (3.01748 iter/s, 33.1402s/100 iters), loss = 2.80568e-06
I0529 05:48:06.320909 11123 solver.cpp:237]     Train net output #0: loss = 1.94313e-06 (* 1 = 1.94313e-06 loss)
I0529 05:48:06.320916 11123 sgd_solver.cpp:105] Iteration 136000, lr = 0.0032
I0529 05:48:16.689581 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:48:34.310859 11123 solver.cpp:218] Iteration 136100 (3.57277 iter/s, 27.9895s/100 iters), loss = 0.00019249
I0529 05:48:34.311017 11123 solver.cpp:237]     Train net output #0: loss = 0.000191628 (* 1 = 0.000191628 loss)
I0529 05:48:34.311028 11123 sgd_solver.cpp:105] Iteration 136100, lr = 0.003195
I0529 05:49:02.329746 11123 solver.cpp:218] Iteration 136200 (3.5691 iter/s, 28.0183s/100 iters), loss = 8.70682e-06
I0529 05:49:02.329787 11123 solver.cpp:237]     Train net output #0: loss = 7.84436e-06 (* 1 = 7.84436e-06 loss)
I0529 05:49:02.329797 11123 sgd_solver.cpp:105] Iteration 136200, lr = 0.00319
I0529 05:49:30.341145 11123 solver.cpp:218] Iteration 136300 (3.57004 iter/s, 28.0109s/100 iters), loss = 4.61153e-05
I0529 05:49:30.341392 11123 solver.cpp:237]     Train net output #0: loss = 4.52529e-05 (* 1 = 4.52529e-05 loss)
I0529 05:49:30.341404 11123 sgd_solver.cpp:105] Iteration 136300, lr = 0.003185
I0529 05:49:58.348337 11123 solver.cpp:218] Iteration 136400 (3.5706 iter/s, 28.0065s/100 iters), loss = 0.000258109
I0529 05:49:58.348381 11123 solver.cpp:237]     Train net output #0: loss = 0.000257247 (* 1 = 0.000257247 loss)
I0529 05:49:58.348390 11123 sgd_solver.cpp:105] Iteration 136400, lr = 0.00318
I0529 05:50:26.346979 11123 solver.cpp:218] Iteration 136500 (3.57166 iter/s, 27.9982s/100 iters), loss = 1.24854e-05
I0529 05:50:26.347141 11123 solver.cpp:237]     Train net output #0: loss = 1.16233e-05 (* 1 = 1.16233e-05 loss)
I0529 05:50:26.347153 11123 sgd_solver.cpp:105] Iteration 136500, lr = 0.003175
I0529 05:50:54.345409 11123 solver.cpp:218] Iteration 136600 (3.5717 iter/s, 27.9978s/100 iters), loss = 3.9259e-06
I0529 05:50:54.345453 11123 solver.cpp:237]     Train net output #0: loss = 3.06371e-06 (* 1 = 3.06371e-06 loss)
I0529 05:50:54.345460 11123 sgd_solver.cpp:105] Iteration 136600, lr = 0.00317
I0529 05:51:08.381125 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:51:22.377703 11123 solver.cpp:218] Iteration 136700 (3.56737 iter/s, 28.0318s/100 iters), loss = 6.78093e-06
I0529 05:51:22.377746 11123 solver.cpp:237]     Train net output #0: loss = 5.91886e-06 (* 1 = 5.91886e-06 loss)
I0529 05:51:22.377754 11123 sgd_solver.cpp:105] Iteration 136700, lr = 0.003165
I0529 05:51:50.390246 11123 solver.cpp:218] Iteration 136800 (3.56989 iter/s, 28.0121s/100 iters), loss = 2.54297e-05
I0529 05:51:50.390413 11123 solver.cpp:237]     Train net output #0: loss = 2.45677e-05 (* 1 = 2.45677e-05 loss)
I0529 05:51:50.390424 11123 sgd_solver.cpp:105] Iteration 136800, lr = 0.00316
I0529 05:52:18.402719 11123 solver.cpp:218] Iteration 136900 (3.56991 iter/s, 28.0119s/100 iters), loss = 6.46496e-06
I0529 05:52:18.402761 11123 solver.cpp:237]     Train net output #0: loss = 5.60291e-06 (* 1 = 5.60291e-06 loss)
I0529 05:52:18.402770 11123 sgd_solver.cpp:105] Iteration 136900, lr = 0.003155
I0529 05:52:46.123288 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_137000.caffemodel
I0529 05:52:46.810858 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_137000.solverstate
I0529 05:52:47.005046 11123 solver.cpp:330] Iteration 137000, Testing net (#0)
I0529 05:52:50.922404 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:52:51.451485 11123 solver.cpp:397]     Test net output #0: accuracy = 0.951
I0529 05:52:51.451539 11123 solver.cpp:397]     Test net output #1: loss = 0.249685 (* 1 = 0.249685 loss)
I0529 05:52:51.728996 11123 solver.cpp:218] Iteration 137000 (3.00082 iter/s, 33.3242s/100 iters), loss = 1.40055e-05
I0529 05:52:51.729051 11123 solver.cpp:237]     Train net output #0: loss = 1.31436e-05 (* 1 = 1.31436e-05 loss)
I0529 05:52:51.729060 11123 sgd_solver.cpp:105] Iteration 137000, lr = 0.00315
I0529 05:53:19.747187 11123 solver.cpp:218] Iteration 137100 (3.56936 iter/s, 28.0162s/100 iters), loss = 5.01251e-05
I0529 05:53:19.747469 11123 solver.cpp:237]     Train net output #0: loss = 4.92632e-05 (* 1 = 4.92632e-05 loss)
I0529 05:53:19.747481 11123 sgd_solver.cpp:105] Iteration 137100, lr = 0.003145
I0529 05:53:47.762560 11123 solver.cpp:218] Iteration 137200 (3.56974 iter/s, 28.0133s/100 iters), loss = 5.00455e-06
I0529 05:53:47.762612 11123 solver.cpp:237]     Train net output #0: loss = 4.14262e-06 (* 1 = 4.14262e-06 loss)
I0529 05:53:47.762621 11123 sgd_solver.cpp:105] Iteration 137200, lr = 0.00314
I0529 05:54:05.437114 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:54:15.791095 11123 solver.cpp:218] Iteration 137300 (3.56803 iter/s, 28.0267s/100 iters), loss = 1.91067e-05
I0529 05:54:15.791143 11123 solver.cpp:237]     Train net output #0: loss = 1.82439e-05 (* 1 = 1.82439e-05 loss)
I0529 05:54:15.791152 11123 sgd_solver.cpp:105] Iteration 137300, lr = 0.003135
I0529 05:54:43.801074 11123 solver.cpp:218] Iteration 137400 (3.57038 iter/s, 28.0082s/100 iters), loss = 2.35252e-06
I0529 05:54:43.801250 11123 solver.cpp:237]     Train net output #0: loss = 1.49013e-06 (* 1 = 1.49013e-06 loss)
I0529 05:54:43.801267 11123 sgd_solver.cpp:105] Iteration 137400, lr = 0.00313
I0529 05:55:11.817278 11123 solver.cpp:218] Iteration 137500 (3.5696 iter/s, 28.0144s/100 iters), loss = 1.7922e-05
I0529 05:55:11.817327 11123 solver.cpp:237]     Train net output #0: loss = 1.70599e-05 (* 1 = 1.70599e-05 loss)
I0529 05:55:11.817334 11123 sgd_solver.cpp:105] Iteration 137500, lr = 0.003125
I0529 05:55:39.815914 11123 solver.cpp:218] Iteration 137600 (3.57181 iter/s, 27.997s/100 iters), loss = 3.64568e-06
I0529 05:55:39.816125 11123 solver.cpp:237]     Train net output #0: loss = 2.78359e-06 (* 1 = 2.78359e-06 loss)
I0529 05:55:39.816148 11123 sgd_solver.cpp:105] Iteration 137600, lr = 0.00312
I0529 05:56:07.833498 11123 solver.cpp:218] Iteration 137700 (3.56941 iter/s, 28.0158s/100 iters), loss = 3.07559e-05
I0529 05:56:07.833547 11123 solver.cpp:237]     Train net output #0: loss = 2.98937e-05 (* 1 = 2.98937e-05 loss)
I0529 05:56:07.833556 11123 sgd_solver.cpp:105] Iteration 137700, lr = 0.003115
I0529 05:56:35.842460 11123 solver.cpp:218] Iteration 137800 (3.57048 iter/s, 28.0074s/100 iters), loss = 2.35226e-06
I0529 05:56:35.842633 11123 solver.cpp:237]     Train net output #0: loss = 1.49013e-06 (* 1 = 1.49013e-06 loss)
I0529 05:56:35.842644 11123 sgd_solver.cpp:105] Iteration 137800, lr = 0.00311
I0529 05:56:56.877144 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:57:03.869058 11123 solver.cpp:218] Iteration 137900 (3.56825 iter/s, 28.025s/100 iters), loss = 0.000295169
I0529 05:57:03.869107 11123 solver.cpp:237]     Train net output #0: loss = 0.000294307 (* 1 = 0.000294307 loss)
I0529 05:57:03.869117 11123 sgd_solver.cpp:105] Iteration 137900, lr = 0.003105
I0529 05:57:31.628252 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_138000.caffemodel
I0529 05:57:32.142153 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_138000.solverstate
I0529 05:57:32.289191 11123 solver.cpp:330] Iteration 138000, Testing net (#0)
I0529 05:57:36.729755 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 05:57:36.729805 11123 solver.cpp:397]     Test net output #1: loss = 0.254878 (* 1 = 0.254878 loss)
I0529 05:57:37.007113 11123 solver.cpp:218] Iteration 138000 (3.01784 iter/s, 33.1363s/100 iters), loss = 1.6155e-05
I0529 05:57:37.007158 11123 solver.cpp:237]     Train net output #0: loss = 1.52929e-05 (* 1 = 1.52929e-05 loss)
I0529 05:57:37.007166 11123 sgd_solver.cpp:105] Iteration 138000, lr = 0.0031
I0529 05:58:05.006208 11123 solver.cpp:218] Iteration 138100 (3.57172 iter/s, 27.9977s/100 iters), loss = 0.000213121
I0529 05:58:05.006371 11123 solver.cpp:237]     Train net output #0: loss = 0.000212259 (* 1 = 0.000212259 loss)
I0529 05:58:05.006381 11123 sgd_solver.cpp:105] Iteration 138100, lr = 0.003095
I0529 05:58:32.996286 11123 solver.cpp:218] Iteration 138200 (3.57288 iter/s, 27.9886s/100 iters), loss = 1.59882e-05
I0529 05:58:32.996330 11123 solver.cpp:237]     Train net output #0: loss = 1.51259e-05 (* 1 = 1.51259e-05 loss)
I0529 05:58:32.996351 11123 sgd_solver.cpp:105] Iteration 138200, lr = 0.00309
I0529 05:59:00.994300 11123 solver.cpp:218] Iteration 138300 (3.57185 iter/s, 27.9967s/100 iters), loss = 4.97479e-05
I0529 05:59:00.994472 11123 solver.cpp:237]     Train net output #0: loss = 4.88856e-05 (* 1 = 4.88856e-05 loss)
I0529 05:59:00.994483 11123 sgd_solver.cpp:105] Iteration 138300, lr = 0.003085
I0529 05:59:28.993512 11123 solver.cpp:218] Iteration 138400 (3.57171 iter/s, 27.9978s/100 iters), loss = 0.000234213
I0529 05:59:28.993556 11123 solver.cpp:237]     Train net output #0: loss = 0.000233351 (* 1 = 0.000233351 loss)
I0529 05:59:28.993564 11123 sgd_solver.cpp:105] Iteration 138400, lr = 0.00308
I0529 05:59:53.653627 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:59:56.990522 11123 solver.cpp:218] Iteration 138500 (3.57197 iter/s, 27.9957s/100 iters), loss = 8.97915e-05
I0529 05:59:56.990564 11123 solver.cpp:237]     Train net output #0: loss = 8.89294e-05 (* 1 = 8.89294e-05 loss)
I0529 05:59:56.990573 11123 sgd_solver.cpp:105] Iteration 138500, lr = 0.003075
I0529 06:00:24.978634 11123 solver.cpp:218] Iteration 138600 (3.5731 iter/s, 27.9869s/100 iters), loss = 1.94689e-06
I0529 06:00:24.978790 11123 solver.cpp:237]     Train net output #0: loss = 1.08481e-06 (* 1 = 1.08481e-06 loss)
I0529 06:00:24.978801 11123 sgd_solver.cpp:105] Iteration 138600, lr = 0.00307
I0529 06:00:52.950842 11123 solver.cpp:218] Iteration 138700 (3.57515 iter/s, 27.9709s/100 iters), loss = 1.6787e-06
I0529 06:00:52.950886 11123 solver.cpp:237]     Train net output #0: loss = 8.16587e-07 (* 1 = 8.16587e-07 loss)
I0529 06:00:52.950894 11123 sgd_solver.cpp:105] Iteration 138700, lr = 0.003065
I0529 06:01:20.942435 11123 solver.cpp:218] Iteration 138800 (3.57265 iter/s, 27.9904s/100 iters), loss = 8.44399e-06
I0529 06:01:20.942597 11123 solver.cpp:237]     Train net output #0: loss = 7.58198e-06 (* 1 = 7.58198e-06 loss)
I0529 06:01:20.942610 11123 sgd_solver.cpp:105] Iteration 138800, lr = 0.00306
I0529 06:01:48.923935 11123 solver.cpp:218] Iteration 138900 (3.57395 iter/s, 27.9802s/100 iters), loss = 6.71786e-05
I0529 06:01:48.923980 11123 solver.cpp:237]     Train net output #0: loss = 6.63167e-05 (* 1 = 6.63167e-05 loss)
I0529 06:01:48.923990 11123 sgd_solver.cpp:105] Iteration 138900, lr = 0.003055
I0529 06:02:16.634814 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_139000.caffemodel
I0529 06:02:17.125680 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_139000.solverstate
I0529 06:02:17.271526 11123 solver.cpp:330] Iteration 139000, Testing net (#0)
I0529 06:02:18.256793 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:02:21.722008 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 06:02:21.722049 11123 solver.cpp:397]     Test net output #1: loss = 0.248517 (* 1 = 0.248517 loss)
I0529 06:02:21.998864 11123 solver.cpp:218] Iteration 139000 (3.02356 iter/s, 33.0736s/100 iters), loss = 1.28131e-05
I0529 06:02:21.998908 11123 solver.cpp:237]     Train net output #0: loss = 1.19512e-05 (* 1 = 1.19512e-05 loss)
I0529 06:02:21.998917 11123 sgd_solver.cpp:105] Iteration 139000, lr = 0.00305
I0529 06:02:49.969395 11123 solver.cpp:218] Iteration 139100 (3.57533 iter/s, 27.9694s/100 iters), loss = 7.0393e-05
I0529 06:02:49.969619 11123 solver.cpp:237]     Train net output #0: loss = 6.9531e-05 (* 1 = 6.9531e-05 loss)
I0529 06:02:49.969630 11123 sgd_solver.cpp:105] Iteration 139100, lr = 0.003045
I0529 06:02:50.271844 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:03:17.962586 11123 solver.cpp:218] Iteration 139200 (3.57246 iter/s, 27.9919s/100 iters), loss = 6.4316e-05
I0529 06:03:17.962628 11123 solver.cpp:237]     Train net output #0: loss = 6.3454e-05 (* 1 = 6.3454e-05 loss)
I0529 06:03:17.962637 11123 sgd_solver.cpp:105] Iteration 139200, lr = 0.00304
I0529 06:03:45.945760 11123 solver.cpp:218] Iteration 139300 (3.57371 iter/s, 27.9821s/100 iters), loss = 0.000405977
I0529 06:03:45.945968 11123 solver.cpp:237]     Train net output #0: loss = 0.000405115 (* 1 = 0.000405115 loss)
I0529 06:03:45.945981 11123 sgd_solver.cpp:105] Iteration 139300, lr = 0.003035
I0529 06:04:13.930455 11123 solver.cpp:218] Iteration 139400 (3.57354 iter/s, 27.9835s/100 iters), loss = 6.3635e-06
I0529 06:04:13.930497 11123 solver.cpp:237]     Train net output #0: loss = 5.5016e-06 (* 1 = 5.5016e-06 loss)
I0529 06:04:13.930506 11123 sgd_solver.cpp:105] Iteration 139400, lr = 0.00303
I0529 06:04:41.906704 11123 solver.cpp:218] Iteration 139500 (3.57459 iter/s, 27.9752s/100 iters), loss = 2.46225e-05
I0529 06:04:41.906903 11123 solver.cpp:237]     Train net output #0: loss = 2.37606e-05 (* 1 = 2.37606e-05 loss)
I0529 06:04:41.906916 11123 sgd_solver.cpp:105] Iteration 139500, lr = 0.003025
I0529 06:05:09.896569 11123 solver.cpp:218] Iteration 139600 (3.57287 iter/s, 27.9887s/100 iters), loss = 9.49891e-06
I0529 06:05:09.896615 11123 solver.cpp:237]     Train net output #0: loss = 8.6369e-06 (* 1 = 8.6369e-06 loss)
I0529 06:05:09.896623 11123 sgd_solver.cpp:105] Iteration 139600, lr = 0.00302
I0529 06:05:37.887923 11123 solver.cpp:218] Iteration 139700 (3.57266 iter/s, 27.9904s/100 iters), loss = 9.80371e-05
I0529 06:05:37.888092 11123 solver.cpp:237]     Train net output #0: loss = 9.71751e-05 (* 1 = 9.71751e-05 loss)
I0529 06:05:37.888103 11123 sgd_solver.cpp:105] Iteration 139700, lr = 0.003015
I0529 06:05:41.824138 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:06:05.873550 11123 solver.cpp:218] Iteration 139800 (3.5734 iter/s, 27.9845s/100 iters), loss = 1.11503e-05
I0529 06:06:05.873594 11123 solver.cpp:237]     Train net output #0: loss = 1.02884e-05 (* 1 = 1.02884e-05 loss)
I0529 06:06:05.873602 11123 sgd_solver.cpp:105] Iteration 139800, lr = 0.00301
I0529 06:06:33.843257 11123 solver.cpp:218] Iteration 139900 (3.57542 iter/s, 27.9688s/100 iters), loss = 6.5035e-05
I0529 06:06:33.843435 11123 solver.cpp:237]     Train net output #0: loss = 6.41731e-05 (* 1 = 6.41731e-05 loss)
I0529 06:06:33.843457 11123 sgd_solver.cpp:105] Iteration 139900, lr = 0.003005
I0529 06:07:01.560434 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_140000.caffemodel
I0529 06:07:02.044332 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_140000.solverstate
I0529 06:07:02.190835 11123 solver.cpp:330] Iteration 140000, Testing net (#0)
I0529 06:07:04.691076 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:07:06.645268 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 06:07:06.645323 11123 solver.cpp:397]     Test net output #1: loss = 0.265407 (* 1 = 0.265407 loss)
I0529 06:07:06.921355 11123 solver.cpp:218] Iteration 140000 (3.02326 iter/s, 33.0769s/100 iters), loss = 1.71975e-05
I0529 06:07:06.921399 11123 solver.cpp:237]     Train net output #0: loss = 1.6336e-05 (* 1 = 1.6336e-05 loss)
I0529 06:07:06.921408 11123 sgd_solver.cpp:105] Iteration 140000, lr = 0.003
I0529 06:07:34.928704 11123 solver.cpp:218] Iteration 140100 (3.57061 iter/s, 28.0064s/100 iters), loss = 1.70686e-05
I0529 06:07:34.928830 11123 solver.cpp:237]     Train net output #0: loss = 1.62072e-05 (* 1 = 1.62072e-05 loss)
I0529 06:07:34.928841 11123 sgd_solver.cpp:105] Iteration 140100, lr = 0.002995
I0529 06:08:02.927837 11123 solver.cpp:218] Iteration 140200 (3.57167 iter/s, 27.9981s/100 iters), loss = 0.000143977
I0529 06:08:02.927882 11123 solver.cpp:237]     Train net output #0: loss = 0.000143116 (* 1 = 0.000143116 loss)
I0529 06:08:02.927891 11123 sgd_solver.cpp:105] Iteration 140200, lr = 0.00299
I0529 06:08:30.918637 11123 solver.cpp:218] Iteration 140300 (3.57272 iter/s, 27.9899s/100 iters), loss = 0.000245
I0529 06:08:30.918834 11123 solver.cpp:237]     Train net output #0: loss = 0.000244139 (* 1 = 0.000244139 loss)
I0529 06:08:30.918848 11123 sgd_solver.cpp:105] Iteration 140300, lr = 0.002985
I0529 06:08:38.497735 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:08:58.914310 11123 solver.cpp:218] Iteration 140400 (3.57211 iter/s, 27.9947s/100 iters), loss = 5.5315e-05
I0529 06:08:58.914371 11123 solver.cpp:237]     Train net output #0: loss = 5.44538e-05 (* 1 = 5.44538e-05 loss)
I0529 06:08:58.914381 11123 sgd_solver.cpp:105] Iteration 140400, lr = 0.00298
I0529 06:09:26.931779 11123 solver.cpp:218] Iteration 140500 (3.56932 iter/s, 28.0166s/100 iters), loss = 2.91762e-06
I0529 06:09:26.932044 11123 solver.cpp:237]     Train net output #0: loss = 2.05638e-06 (* 1 = 2.05638e-06 loss)
I0529 06:09:26.932055 11123 sgd_solver.cpp:105] Iteration 140500, lr = 0.002975
I0529 06:09:54.912062 11123 solver.cpp:218] Iteration 140600 (3.57408 iter/s, 27.9792s/100 iters), loss = 5.38832e-05
I0529 06:09:54.912122 11123 solver.cpp:237]     Train net output #0: loss = 5.30218e-05 (* 1 = 5.30218e-05 loss)
I0529 06:09:54.912130 11123 sgd_solver.cpp:105] Iteration 140600, lr = 0.00297
I0529 06:10:22.917352 11123 solver.cpp:218] Iteration 140700 (3.57087 iter/s, 28.0044s/100 iters), loss = 3.19541e-05
I0529 06:10:22.917518 11123 solver.cpp:237]     Train net output #0: loss = 3.10928e-05 (* 1 = 3.10928e-05 loss)
I0529 06:10:22.917532 11123 sgd_solver.cpp:105] Iteration 140700, lr = 0.002965
I0529 06:10:50.936082 11123 solver.cpp:218] Iteration 140800 (3.56916 iter/s, 28.0178s/100 iters), loss = 1.17931e-05
I0529 06:10:50.936128 11123 solver.cpp:237]     Train net output #0: loss = 1.09319e-05 (* 1 = 1.09319e-05 loss)
I0529 06:10:50.936136 11123 sgd_solver.cpp:105] Iteration 140800, lr = 0.00296
I0529 06:11:18.970166 11123 solver.cpp:218] Iteration 140900 (3.56719 iter/s, 28.0332s/100 iters), loss = 1.76089e-05
I0529 06:11:18.970341 11123 solver.cpp:237]     Train net output #0: loss = 1.67476e-05 (* 1 = 1.67476e-05 loss)
I0529 06:11:18.970353 11123 sgd_solver.cpp:105] Iteration 140900, lr = 0.002955
I0529 06:11:29.908169 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:11:46.705812 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_141000.caffemodel
I0529 06:11:47.096127 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_141000.solverstate
I0529 06:11:47.243253 11123 solver.cpp:330] Iteration 141000, Testing net (#0)
I0529 06:11:51.247519 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:11:51.688951 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 06:11:51.688998 11123 solver.cpp:397]     Test net output #1: loss = 0.257486 (* 1 = 0.257486 loss)
I0529 06:11:51.966526 11123 solver.cpp:218] Iteration 141000 (3.03074 iter/s, 32.9953s/100 iters), loss = 0.000188262
I0529 06:11:51.966572 11123 solver.cpp:237]     Train net output #0: loss = 0.000187401 (* 1 = 0.000187401 loss)
I0529 06:11:51.966580 11123 sgd_solver.cpp:105] Iteration 141000, lr = 0.00295
I0529 06:12:19.973541 11123 solver.cpp:218] Iteration 141100 (3.57064 iter/s, 28.0062s/100 iters), loss = 2.14344e-05
I0529 06:12:19.973584 11123 solver.cpp:237]     Train net output #0: loss = 2.05732e-05 (* 1 = 2.05732e-05 loss)
I0529 06:12:19.973593 11123 sgd_solver.cpp:105] Iteration 141100, lr = 0.002945
I0529 06:12:47.969501 11123 solver.cpp:218] Iteration 141200 (3.57205 iter/s, 27.9951s/100 iters), loss = 3.7948e-05
I0529 06:12:47.969663 11123 solver.cpp:237]     Train net output #0: loss = 3.70864e-05 (* 1 = 3.70864e-05 loss)
I0529 06:12:47.969679 11123 sgd_solver.cpp:105] Iteration 141200, lr = 0.00294
I0529 06:13:15.985328 11123 solver.cpp:218] Iteration 141300 (3.56953 iter/s, 28.0149s/100 iters), loss = 8.47334e-06
I0529 06:13:15.985376 11123 solver.cpp:237]     Train net output #0: loss = 7.61171e-06 (* 1 = 7.61171e-06 loss)
I0529 06:13:15.985384 11123 sgd_solver.cpp:105] Iteration 141300, lr = 0.002935
I0529 06:13:43.997414 11123 solver.cpp:218] Iteration 141400 (3.56999 iter/s, 28.0113s/100 iters), loss = 4.58094e-06
I0529 06:13:43.997637 11123 solver.cpp:237]     Train net output #0: loss = 3.71941e-06 (* 1 = 3.71941e-06 loss)
I0529 06:13:43.997649 11123 sgd_solver.cpp:105] Iteration 141400, lr = 0.00293
I0529 06:14:11.987592 11123 solver.cpp:218] Iteration 141500 (3.57281 iter/s, 27.9892s/100 iters), loss = 5.17687e-06
I0529 06:14:11.987651 11123 solver.cpp:237]     Train net output #0: loss = 4.31543e-06 (* 1 = 4.31543e-06 loss)
I0529 06:14:11.987661 11123 sgd_solver.cpp:105] Iteration 141500, lr = 0.002925
I0529 06:14:26.553544 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:14:39.964825 11123 solver.cpp:218] Iteration 141600 (3.57444 iter/s, 27.9764s/100 iters), loss = 1.35674e-05
I0529 06:14:39.964881 11123 solver.cpp:237]     Train net output #0: loss = 1.2706e-05 (* 1 = 1.2706e-05 loss)
I0529 06:14:39.964890 11123 sgd_solver.cpp:105] Iteration 141600, lr = 0.00292
I0529 06:15:07.961920 11123 solver.cpp:218] Iteration 141700 (3.5719 iter/s, 27.9963s/100 iters), loss = 9.45578e-05
I0529 06:15:07.962086 11123 solver.cpp:237]     Train net output #0: loss = 9.36966e-05 (* 1 = 9.36966e-05 loss)
I0529 06:15:07.962097 11123 sgd_solver.cpp:105] Iteration 141700, lr = 0.002915
I0529 06:15:35.937892 11123 solver.cpp:218] Iteration 141800 (3.57461 iter/s, 27.9751s/100 iters), loss = 5.51235e-05
I0529 06:15:35.937942 11123 solver.cpp:237]     Train net output #0: loss = 5.42624e-05 (* 1 = 5.42624e-05 loss)
I0529 06:15:35.937950 11123 sgd_solver.cpp:105] Iteration 141800, lr = 0.00291
I0529 06:16:03.915866 11123 solver.cpp:218] Iteration 141900 (3.57434 iter/s, 27.9772s/100 iters), loss = 1.71476e-05
I0529 06:16:03.916095 11123 solver.cpp:237]     Train net output #0: loss = 1.62863e-05 (* 1 = 1.62863e-05 loss)
I0529 06:16:03.916107 11123 sgd_solver.cpp:105] Iteration 141900, lr = 0.002905
I0529 06:16:31.644491 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_142000.caffemodel
I0529 06:16:31.994120 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_142000.solverstate
I0529 06:16:32.140358 11123 solver.cpp:330] Iteration 142000, Testing net (#0)
I0529 06:16:36.590171 11123 solver.cpp:397]     Test net output #0: accuracy = 0.937
I0529 06:16:36.590380 11123 solver.cpp:397]     Test net output #1: loss = 0.2578 (* 1 = 0.2578 loss)
I0529 06:16:36.866233 11123 solver.cpp:218] Iteration 142000 (3.03497 iter/s, 32.9493s/100 iters), loss = 0.000200103
I0529 06:16:36.866283 11123 solver.cpp:237]     Train net output #0: loss = 0.000199241 (* 1 = 0.000199241 loss)
I0529 06:16:36.866292 11123 sgd_solver.cpp:105] Iteration 142000, lr = 0.0029
I0529 06:17:04.842604 11123 solver.cpp:218] Iteration 142100 (3.57454 iter/s, 27.9756s/100 iters), loss = 5.38541e-06
I0529 06:17:04.842655 11123 solver.cpp:237]     Train net output #0: loss = 4.52414e-06 (* 1 = 4.52414e-06 loss)
I0529 06:17:04.842664 11123 sgd_solver.cpp:105] Iteration 142100, lr = 0.002895
I0529 06:17:23.052062 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:17:32.837873 11123 solver.cpp:218] Iteration 142200 (3.57213 iter/s, 27.9945s/100 iters), loss = 5.10521e-06
I0529 06:17:32.837944 11123 solver.cpp:237]     Train net output #0: loss = 4.24392e-06 (* 1 = 4.24392e-06 loss)
I0529 06:17:32.837954 11123 sgd_solver.cpp:105] Iteration 142200, lr = 0.00289
I0529 06:18:00.835650 11123 solver.cpp:218] Iteration 142300 (3.57181 iter/s, 27.997s/100 iters), loss = 4.2052e-06
I0529 06:18:00.835824 11123 solver.cpp:237]     Train net output #0: loss = 3.34385e-06 (* 1 = 3.34385e-06 loss)
I0529 06:18:00.835836 11123 sgd_solver.cpp:105] Iteration 142300, lr = 0.002885
I0529 06:18:28.840019 11123 solver.cpp:218] Iteration 142400 (3.57098 iter/s, 28.0035s/100 iters), loss = 2.88893e-05
I0529 06:18:28.840075 11123 solver.cpp:237]     Train net output #0: loss = 2.80277e-05 (* 1 = 2.80277e-05 loss)
I0529 06:18:28.840085 11123 sgd_solver.cpp:105] Iteration 142400, lr = 0.00288
I0529 06:18:56.840301 11123 solver.cpp:218] Iteration 142500 (3.57149 iter/s, 27.9995s/100 iters), loss = 2.28025e-06
I0529 06:18:56.840461 11123 solver.cpp:237]     Train net output #0: loss = 1.4186e-06 (* 1 = 1.4186e-06 loss)
I0529 06:18:56.840474 11123 sgd_solver.cpp:105] Iteration 142500, lr = 0.002875
I0529 06:19:24.830811 11123 solver.cpp:218] Iteration 142600 (3.57275 iter/s, 27.9897s/100 iters), loss = 5.06375e-06
I0529 06:19:24.830866 11123 solver.cpp:237]     Train net output #0: loss = 4.20218e-06 (* 1 = 4.20218e-06 loss)
I0529 06:19:24.830875 11123 sgd_solver.cpp:105] Iteration 142600, lr = 0.00287
I0529 06:19:52.849017 11123 solver.cpp:218] Iteration 142700 (3.5692 iter/s, 28.0174s/100 iters), loss = 3.0894e-05
I0529 06:19:52.849208 11123 solver.cpp:237]     Train net output #0: loss = 3.00325e-05 (* 1 = 3.00325e-05 loss)
I0529 06:19:52.849220 11123 sgd_solver.cpp:105] Iteration 142700, lr = 0.002865
I0529 06:20:14.705970 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:20:20.853732 11123 solver.cpp:218] Iteration 142800 (3.57094 iter/s, 28.0038s/100 iters), loss = 9.91437e-05
I0529 06:20:20.853785 11123 solver.cpp:237]     Train net output #0: loss = 9.8282e-05 (* 1 = 9.8282e-05 loss)
I0529 06:20:20.853796 11123 sgd_solver.cpp:105] Iteration 142800, lr = 0.00286
I0529 06:20:48.848127 11123 solver.cpp:218] Iteration 142900 (3.57224 iter/s, 27.9936s/100 iters), loss = 2.89637e-05
I0529 06:20:48.848343 11123 solver.cpp:237]     Train net output #0: loss = 2.8102e-05 (* 1 = 2.8102e-05 loss)
I0529 06:20:48.848356 11123 sgd_solver.cpp:105] Iteration 142900, lr = 0.002855
I0529 06:21:16.582969 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_143000.caffemodel
I0529 06:21:16.892031 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_143000.solverstate
I0529 06:21:17.038120 11123 solver.cpp:330] Iteration 143000, Testing net (#0)
I0529 06:21:18.112699 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:21:21.487581 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 06:21:21.487745 11123 solver.cpp:397]     Test net output #1: loss = 0.242558 (* 1 = 0.242558 loss)
I0529 06:21:21.764546 11123 solver.cpp:218] Iteration 143000 (3.03809 iter/s, 32.9154s/100 iters), loss = 3.24168e-05
I0529 06:21:21.764592 11123 solver.cpp:237]     Train net output #0: loss = 3.15552e-05 (* 1 = 3.15552e-05 loss)
I0529 06:21:21.764601 11123 sgd_solver.cpp:105] Iteration 143000, lr = 0.00285
I0529 06:21:49.774370 11123 solver.cpp:218] Iteration 143100 (3.57027 iter/s, 28.0091s/100 iters), loss = 8.76445e-05
I0529 06:21:49.774420 11123 solver.cpp:237]     Train net output #0: loss = 8.6783e-05 (* 1 = 8.6783e-05 loss)
I0529 06:21:49.774435 11123 sgd_solver.cpp:105] Iteration 143100, lr = 0.002845
I0529 06:22:17.774660 11123 solver.cpp:218] Iteration 143200 (3.57149 iter/s, 27.9996s/100 iters), loss = 0.000339354
I0529 06:22:17.774869 11123 solver.cpp:237]     Train net output #0: loss = 0.000338493 (* 1 = 0.000338493 loss)
I0529 06:22:17.774881 11123 sgd_solver.cpp:105] Iteration 143200, lr = 0.00284
I0529 06:22:45.772028 11123 solver.cpp:218] Iteration 143300 (3.57187 iter/s, 27.9965s/100 iters), loss = 3.049e-06
I0529 06:22:45.772076 11123 solver.cpp:237]     Train net output #0: loss = 2.18752e-06 (* 1 = 2.18752e-06 loss)
I0529 06:22:45.772085 11123 sgd_solver.cpp:105] Iteration 143300, lr = 0.002835
I0529 06:23:11.293895 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:23:13.807235 11123 solver.cpp:218] Iteration 143400 (3.56704 iter/s, 28.0345s/100 iters), loss = 7.38232e-06
I0529 06:23:13.807281 11123 solver.cpp:237]     Train net output #0: loss = 6.52084e-06 (* 1 = 6.52084e-06 loss)
I0529 06:23:13.807291 11123 sgd_solver.cpp:105] Iteration 143400, lr = 0.00283
I0529 06:23:41.822964 11123 solver.cpp:218] Iteration 143500 (3.56952 iter/s, 28.015s/100 iters), loss = 6.58065e-05
I0529 06:23:41.823117 11123 solver.cpp:237]     Train net output #0: loss = 6.49451e-05 (* 1 = 6.49451e-05 loss)
I0529 06:23:41.823129 11123 sgd_solver.cpp:105] Iteration 143500, lr = 0.002825
I0529 06:24:09.840168 11123 solver.cpp:218] Iteration 143600 (3.56934 iter/s, 28.0164s/100 iters), loss = 1.99218e-05
I0529 06:24:09.840226 11123 solver.cpp:237]     Train net output #0: loss = 1.90604e-05 (* 1 = 1.90604e-05 loss)
I0529 06:24:09.840235 11123 sgd_solver.cpp:105] Iteration 143600, lr = 0.00282
I0529 06:24:37.829977 11123 solver.cpp:218] Iteration 143700 (3.57282 iter/s, 27.9891s/100 iters), loss = 3.98247e-05
I0529 06:24:37.830173 11123 solver.cpp:237]     Train net output #0: loss = 3.89632e-05 (* 1 = 3.89632e-05 loss)
I0529 06:24:37.830183 11123 sgd_solver.cpp:105] Iteration 143700, lr = 0.002815
I0529 06:25:05.860426 11123 solver.cpp:218] Iteration 143800 (3.56766 iter/s, 28.0296s/100 iters), loss = 9.3018e-06
I0529 06:25:05.860469 11123 solver.cpp:237]     Train net output #0: loss = 8.44034e-06 (* 1 = 8.44034e-06 loss)
I0529 06:25:05.860478 11123 sgd_solver.cpp:105] Iteration 143800, lr = 0.00281
I0529 06:25:33.847590 11123 solver.cpp:218] Iteration 143900 (3.57316 iter/s, 27.9864s/100 iters), loss = 2.07822e-05
I0529 06:25:33.847786 11123 solver.cpp:237]     Train net output #0: loss = 1.99207e-05 (* 1 = 1.99207e-05 loss)
I0529 06:25:33.847798 11123 sgd_solver.cpp:105] Iteration 143900, lr = 0.002805
I0529 06:26:01.548926 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_144000.caffemodel
I0529 06:26:01.985966 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_144000.solverstate
I0529 06:26:02.133438 11123 solver.cpp:330] Iteration 144000, Testing net (#0)
I0529 06:26:04.711751 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:26:06.577675 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 06:26:06.577723 11123 solver.cpp:397]     Test net output #1: loss = 0.27646 (* 1 = 0.27646 loss)
I0529 06:26:06.854534 11123 solver.cpp:218] Iteration 144000 (3.02976 iter/s, 33.006s/100 iters), loss = 2.01943e-05
I0529 06:26:06.854591 11123 solver.cpp:237]     Train net output #0: loss = 1.93328e-05 (* 1 = 1.93328e-05 loss)
I0529 06:26:06.854600 11123 sgd_solver.cpp:105] Iteration 144000, lr = 0.0028
I0529 06:26:07.718511 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:26:34.834609 11123 solver.cpp:218] Iteration 144100 (3.57406 iter/s, 27.9794s/100 iters), loss = 3.88944e-06
I0529 06:26:34.834756 11123 solver.cpp:237]     Train net output #0: loss = 3.02794e-06 (* 1 = 3.02794e-06 loss)
I0529 06:26:34.834769 11123 sgd_solver.cpp:105] Iteration 144100, lr = 0.002795
I0529 06:27:02.805522 11123 solver.cpp:218] Iteration 144200 (3.57523 iter/s, 27.9702s/100 iters), loss = 4.92155e-05
I0529 06:27:02.805572 11123 solver.cpp:237]     Train net output #0: loss = 4.8354e-05 (* 1 = 4.8354e-05 loss)
I0529 06:27:02.805580 11123 sgd_solver.cpp:105] Iteration 144200, lr = 0.00279
I0529 06:27:30.784495 11123 solver.cpp:218] Iteration 144300 (3.57419 iter/s, 27.9784s/100 iters), loss = 2.24935e-05
I0529 06:27:30.784667 11123 solver.cpp:237]     Train net output #0: loss = 2.1632e-05 (* 1 = 2.1632e-05 loss)
I0529 06:27:30.784680 11123 sgd_solver.cpp:105] Iteration 144300, lr = 0.002785
I0529 06:27:58.752795 11123 solver.cpp:218] Iteration 144400 (3.57557 iter/s, 27.9676s/100 iters), loss = 1.22382e-05
I0529 06:27:58.752841 11123 solver.cpp:237]     Train net output #0: loss = 1.13768e-05 (* 1 = 1.13768e-05 loss)
I0529 06:27:58.752851 11123 sgd_solver.cpp:105] Iteration 144400, lr = 0.00278
I0529 06:28:26.743963 11123 solver.cpp:218] Iteration 144500 (3.57263 iter/s, 27.9906s/100 iters), loss = 2.62526e-05
I0529 06:28:26.744125 11123 solver.cpp:237]     Train net output #0: loss = 2.5391e-05 (* 1 = 2.5391e-05 loss)
I0529 06:28:26.744140 11123 sgd_solver.cpp:105] Iteration 144500, lr = 0.002775
I0529 06:28:54.734741 11123 solver.cpp:218] Iteration 144600 (3.5727 iter/s, 27.9901s/100 iters), loss = 1.42175e-05
I0529 06:28:54.734798 11123 solver.cpp:237]     Train net output #0: loss = 1.33558e-05 (* 1 = 1.33558e-05 loss)
I0529 06:28:54.734807 11123 sgd_solver.cpp:105] Iteration 144600, lr = 0.00277
I0529 06:28:59.232875 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:29:22.770273 11123 solver.cpp:218] Iteration 144700 (3.56698 iter/s, 28.0349s/100 iters), loss = 4.48568e-06
I0529 06:29:22.770320 11123 solver.cpp:237]     Train net output #0: loss = 3.62403e-06 (* 1 = 3.62403e-06 loss)
I0529 06:29:22.770329 11123 sgd_solver.cpp:105] Iteration 144700, lr = 0.002765
I0529 06:29:50.795053 11123 solver.cpp:218] Iteration 144800 (3.56835 iter/s, 28.0242s/100 iters), loss = 6.78047e-06
I0529 06:29:50.795267 11123 solver.cpp:237]     Train net output #0: loss = 5.91891e-06 (* 1 = 5.91891e-06 loss)
I0529 06:29:50.795279 11123 sgd_solver.cpp:105] Iteration 144800, lr = 0.00276
I0529 06:30:18.807392 11123 solver.cpp:218] Iteration 144900 (3.56995 iter/s, 28.0116s/100 iters), loss = 0.000229626
I0529 06:30:18.807440 11123 solver.cpp:237]     Train net output #0: loss = 0.000228764 (* 1 = 0.000228764 loss)
I0529 06:30:18.807448 11123 sgd_solver.cpp:105] Iteration 144900, lr = 0.002755
I0529 06:30:46.521333 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_145000.caffemodel
I0529 06:30:46.886795 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_145000.solverstate
I0529 06:30:47.032243 11123 solver.cpp:330] Iteration 145000, Testing net (#0)
I0529 06:30:51.128792 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:30:51.483080 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 06:30:51.483134 11123 solver.cpp:397]     Test net output #1: loss = 0.247268 (* 1 = 0.247268 loss)
I0529 06:30:51.758505 11123 solver.cpp:218] Iteration 145000 (3.03487 iter/s, 32.9504s/100 iters), loss = 0.000125088
I0529 06:30:51.758549 11123 solver.cpp:237]     Train net output #0: loss = 0.000124226 (* 1 = 0.000124226 loss)
I0529 06:30:51.758558 11123 sgd_solver.cpp:105] Iteration 145000, lr = 0.00275
I0529 06:31:19.750088 11123 solver.cpp:218] Iteration 145100 (3.57258 iter/s, 27.991s/100 iters), loss = 8.00858e-06
I0529 06:31:19.750272 11123 solver.cpp:237]     Train net output #0: loss = 7.14697e-06 (* 1 = 7.14697e-06 loss)
I0529 06:31:19.750284 11123 sgd_solver.cpp:105] Iteration 145100, lr = 0.002745
I0529 06:31:47.764729 11123 solver.cpp:218] Iteration 145200 (3.56966 iter/s, 28.0139s/100 iters), loss = 0.00014842
I0529 06:31:47.764776 11123 solver.cpp:237]     Train net output #0: loss = 0.000147558 (* 1 = 0.000147558 loss)
I0529 06:31:47.764786 11123 sgd_solver.cpp:105] Iteration 145200, lr = 0.00274
I0529 06:31:55.911319 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:32:15.783217 11123 solver.cpp:218] Iteration 145300 (3.56915 iter/s, 28.0179s/100 iters), loss = 7.91283e-06
I0529 06:32:15.783264 11123 solver.cpp:237]     Train net output #0: loss = 7.05134e-06 (* 1 = 7.05134e-06 loss)
I0529 06:32:15.783273 11123 sgd_solver.cpp:105] Iteration 145300, lr = 0.002735
I0529 06:32:43.785845 11123 solver.cpp:218] Iteration 145400 (3.57117 iter/s, 28.002s/100 iters), loss = 3.57355e-06
I0529 06:32:43.786007 11123 solver.cpp:237]     Train net output #0: loss = 2.71204e-06 (* 1 = 2.71204e-06 loss)
I0529 06:32:43.786020 11123 sgd_solver.cpp:105] Iteration 145400, lr = 0.00273
I0529 06:33:11.788951 11123 solver.cpp:218] Iteration 145500 (3.57113 iter/s, 28.0024s/100 iters), loss = 3.63578e-05
I0529 06:33:11.789006 11123 solver.cpp:237]     Train net output #0: loss = 3.5496e-05 (* 1 = 3.5496e-05 loss)
I0529 06:33:11.789016 11123 sgd_solver.cpp:105] Iteration 145500, lr = 0.002725
I0529 06:33:39.793848 11123 solver.cpp:218] Iteration 145600 (3.57089 iter/s, 28.0043s/100 iters), loss = 1.82119e-06
I0529 06:33:39.794128 11123 solver.cpp:237]     Train net output #0: loss = 9.59638e-07 (* 1 = 9.59638e-07 loss)
I0529 06:33:39.794139 11123 sgd_solver.cpp:105] Iteration 145600, lr = 0.00272
I0529 06:34:07.823514 11123 solver.cpp:218] Iteration 145700 (3.56776 iter/s, 28.0288s/100 iters), loss = 2.01797e-06
I0529 06:34:07.823559 11123 solver.cpp:237]     Train net output #0: loss = 1.15633e-06 (* 1 = 1.15633e-06 loss)
I0529 06:34:07.823568 11123 sgd_solver.cpp:105] Iteration 145700, lr = 0.002715
I0529 06:34:35.833768 11123 solver.cpp:218] Iteration 145800 (3.5702 iter/s, 28.0096s/100 iters), loss = 1.16575e-06
I0529 06:34:35.833936 11123 solver.cpp:237]     Train net output #0: loss = 3.03984e-07 (* 1 = 3.03984e-07 loss)
I0529 06:34:35.833948 11123 sgd_solver.cpp:105] Iteration 145800, lr = 0.00271
I0529 06:34:47.611814 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:35:03.849503 11123 solver.cpp:218] Iteration 145900 (3.56952 iter/s, 28.015s/100 iters), loss = 0.000132882
I0529 06:35:03.849546 11123 solver.cpp:237]     Train net output #0: loss = 0.00013202 (* 1 = 0.00013202 loss)
I0529 06:35:03.849555 11123 sgd_solver.cpp:105] Iteration 145900, lr = 0.002705
I0529 06:35:31.574910 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_146000.caffemodel
I0529 06:35:32.000735 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_146000.solverstate
I0529 06:35:32.147322 11123 solver.cpp:330] Iteration 146000, Testing net (#0)
I0529 06:35:36.568992 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939
I0529 06:35:36.569034 11123 solver.cpp:397]     Test net output #1: loss = 0.26218 (* 1 = 0.26218 loss)
I0529 06:35:36.846794 11123 solver.cpp:218] Iteration 146000 (3.03062 iter/s, 32.9965s/100 iters), loss = 0.000138176
I0529 06:35:36.846842 11123 solver.cpp:237]     Train net output #0: loss = 0.000137314 (* 1 = 0.000137314 loss)
I0529 06:35:36.846849 11123 sgd_solver.cpp:105] Iteration 146000, lr = 0.0027
I0529 06:36:04.868943 11123 solver.cpp:218] Iteration 146100 (3.56869 iter/s, 28.0215s/100 iters), loss = 0.000704668
I0529 06:36:04.869110 11123 solver.cpp:237]     Train net output #0: loss = 0.000703806 (* 1 = 0.000703806 loss)
I0529 06:36:04.869122 11123 sgd_solver.cpp:105] Iteration 146100, lr = 0.002695
I0529 06:36:32.880534 11123 solver.cpp:218] Iteration 146200 (3.57005 iter/s, 28.0108s/100 iters), loss = 2.72151e-06
I0529 06:36:32.880580 11123 solver.cpp:237]     Train net output #0: loss = 1.85969e-06 (* 1 = 1.85969e-06 loss)
I0529 06:36:32.880601 11123 sgd_solver.cpp:105] Iteration 146200, lr = 0.00269
I0529 06:37:00.901195 11123 solver.cpp:218] Iteration 146300 (3.56888 iter/s, 28.02s/100 iters), loss = 5.71999e-05
I0529 06:37:00.901357 11123 solver.cpp:237]     Train net output #0: loss = 5.6338e-05 (* 1 = 5.6338e-05 loss)
I0529 06:37:00.901368 11123 sgd_solver.cpp:105] Iteration 146300, lr = 0.002685
I0529 06:37:28.926364 11123 solver.cpp:218] Iteration 146400 (3.56832 iter/s, 28.0244s/100 iters), loss = 0.00025895
I0529 06:37:28.926406 11123 solver.cpp:237]     Train net output #0: loss = 0.000258088 (* 1 = 0.000258088 loss)
I0529 06:37:28.926415 11123 sgd_solver.cpp:105] Iteration 146400, lr = 0.00268
I0529 06:37:44.357403 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:37:56.952941 11123 solver.cpp:218] Iteration 146500 (3.56813 iter/s, 28.0259s/100 iters), loss = 3.9494e-06
I0529 06:37:56.952998 11123 solver.cpp:237]     Train net output #0: loss = 3.08754e-06 (* 1 = 3.08754e-06 loss)
I0529 06:37:56.953008 11123 sgd_solver.cpp:105] Iteration 146500, lr = 0.002675
I0529 06:38:24.951046 11123 solver.cpp:218] Iteration 146600 (3.57175 iter/s, 27.9974s/100 iters), loss = 2.50748e-05
I0529 06:38:24.951205 11123 solver.cpp:237]     Train net output #0: loss = 2.42128e-05 (* 1 = 2.42128e-05 loss)
I0529 06:38:24.951217 11123 sgd_solver.cpp:105] Iteration 146600, lr = 0.00267
I0529 06:38:52.962671 11123 solver.cpp:218] Iteration 146700 (3.57004 iter/s, 28.0109s/100 iters), loss = 0.00011873
I0529 06:38:52.962718 11123 solver.cpp:237]     Train net output #0: loss = 0.000117868 (* 1 = 0.000117868 loss)
I0529 06:38:52.962728 11123 sgd_solver.cpp:105] Iteration 146700, lr = 0.002665
I0529 06:39:20.990572 11123 solver.cpp:218] Iteration 146800 (3.56796 iter/s, 28.0272s/100 iters), loss = 2.74355e-05
I0529 06:39:20.990738 11123 solver.cpp:237]     Train net output #0: loss = 2.65737e-05 (* 1 = 2.65737e-05 loss)
I0529 06:39:20.990749 11123 sgd_solver.cpp:105] Iteration 146800, lr = 0.00266
I0529 06:39:48.976414 11123 solver.cpp:218] Iteration 146900 (3.57333 iter/s, 27.9851s/100 iters), loss = 5.86859e-06
I0529 06:39:48.976459 11123 solver.cpp:237]     Train net output #0: loss = 5.00685e-06 (* 1 = 5.00685e-06 loss)
I0529 06:39:48.976478 11123 sgd_solver.cpp:105] Iteration 146900, lr = 0.002655
I0529 06:40:16.699512 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_147000.caffemodel
I0529 06:40:17.176666 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_147000.solverstate
I0529 06:40:17.325543 11123 solver.cpp:330] Iteration 147000, Testing net (#0)
I0529 06:40:18.448422 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:40:21.772542 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 06:40:21.772590 11123 solver.cpp:397]     Test net output #1: loss = 0.240621 (* 1 = 0.240621 loss)
I0529 06:40:22.049334 11123 solver.cpp:218] Iteration 147000 (3.02369 iter/s, 33.0721s/100 iters), loss = 8.31269e-06
I0529 06:40:22.049386 11123 solver.cpp:237]     Train net output #0: loss = 7.4509e-06 (* 1 = 7.4509e-06 loss)
I0529 06:40:22.049394 11123 sgd_solver.cpp:105] Iteration 147000, lr = 0.00265
I0529 06:40:40.809458 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:40:50.024529 11123 solver.cpp:218] Iteration 147100 (3.57468 iter/s, 27.9745s/100 iters), loss = 2.17578e-05
I0529 06:40:50.024735 11123 solver.cpp:237]     Train net output #0: loss = 2.08961e-05 (* 1 = 2.08961e-05 loss)
I0529 06:40:50.024747 11123 sgd_solver.cpp:105] Iteration 147100, lr = 0.002645
I0529 06:41:18.019662 11123 solver.cpp:218] Iteration 147200 (3.57215 iter/s, 27.9943s/100 iters), loss = 1.52965e-05
I0529 06:41:18.019718 11123 solver.cpp:237]     Train net output #0: loss = 1.44349e-05 (* 1 = 1.44349e-05 loss)
I0529 06:41:18.019727 11123 sgd_solver.cpp:105] Iteration 147200, lr = 0.00264
I0529 06:41:45.986786 11123 solver.cpp:218] Iteration 147300 (3.57571 iter/s, 27.9665s/100 iters), loss = 3.00121e-06
I0529 06:41:45.986969 11123 solver.cpp:237]     Train net output #0: loss = 2.13982e-06 (* 1 = 2.13982e-06 loss)
I0529 06:41:45.986981 11123 sgd_solver.cpp:105] Iteration 147300, lr = 0.002635
I0529 06:42:13.970964 11123 solver.cpp:218] Iteration 147400 (3.57355 iter/s, 27.9834s/100 iters), loss = 4.05127e-05
I0529 06:42:13.971009 11123 solver.cpp:237]     Train net output #0: loss = 3.96513e-05 (* 1 = 3.96513e-05 loss)
I0529 06:42:13.971019 11123 sgd_solver.cpp:105] Iteration 147400, lr = 0.00263
I0529 06:42:41.968431 11123 solver.cpp:218] Iteration 147500 (3.57184 iter/s, 27.9968s/100 iters), loss = 1.1406e-05
I0529 06:42:41.968605 11123 solver.cpp:237]     Train net output #0: loss = 1.05446e-05 (* 1 = 1.05446e-05 loss)
I0529 06:42:41.968616 11123 sgd_solver.cpp:105] Iteration 147500, lr = 0.002625
I0529 06:43:09.992652 11123 solver.cpp:218] Iteration 147600 (3.56844 iter/s, 28.0234s/100 iters), loss = 1.49201e-05
I0529 06:43:09.992698 11123 solver.cpp:237]     Train net output #0: loss = 1.40587e-05 (* 1 = 1.40587e-05 loss)
I0529 06:43:09.992718 11123 sgd_solver.cpp:105] Iteration 147600, lr = 0.00262
I0529 06:43:32.425354 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:43:38.009789 11123 solver.cpp:218] Iteration 147700 (3.56933 iter/s, 28.0165s/100 iters), loss = 1.15014e-05
I0529 06:43:38.009837 11123 solver.cpp:237]     Train net output #0: loss = 1.06399e-05 (* 1 = 1.06399e-05 loss)
I0529 06:43:38.009846 11123 sgd_solver.cpp:105] Iteration 147700, lr = 0.002615
I0529 06:44:06.023862 11123 solver.cpp:218] Iteration 147800 (3.56972 iter/s, 28.0134s/100 iters), loss = 2.35764e-06
I0529 06:44:06.024030 11123 solver.cpp:237]     Train net output #0: loss = 1.49608e-06 (* 1 = 1.49608e-06 loss)
I0529 06:44:06.024041 11123 sgd_solver.cpp:105] Iteration 147800, lr = 0.00261
I0529 06:44:34.028022 11123 solver.cpp:218] Iteration 147900 (3.571 iter/s, 28.0034s/100 iters), loss = 3.1862e-06
I0529 06:44:34.028066 11123 solver.cpp:237]     Train net output #0: loss = 2.32461e-06 (* 1 = 2.32461e-06 loss)
I0529 06:44:34.028075 11123 sgd_solver.cpp:105] Iteration 147900, lr = 0.002605
I0529 06:45:01.778656 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_148000.caffemodel
I0529 06:45:02.238282 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_148000.solverstate
I0529 06:45:02.386651 11123 solver.cpp:330] Iteration 148000, Testing net (#0)
I0529 06:45:05.018337 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:45:06.839066 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 06:45:06.839118 11123 solver.cpp:397]     Test net output #1: loss = 0.27207 (* 1 = 0.27207 loss)
I0529 06:45:07.114110 11123 solver.cpp:218] Iteration 148000 (3.02249 iter/s, 33.0853s/100 iters), loss = 2.81758e-05
I0529 06:45:07.114174 11123 solver.cpp:237]     Train net output #0: loss = 2.73129e-05 (* 1 = 2.73129e-05 loss)
I0529 06:45:07.114183 11123 sgd_solver.cpp:105] Iteration 148000, lr = 0.0026
I0529 06:45:35.115888 11123 solver.cpp:218] Iteration 148100 (3.57129 iter/s, 28.0011s/100 iters), loss = 9.02037e-05
I0529 06:45:35.116128 11123 solver.cpp:237]     Train net output #0: loss = 8.93411e-05 (* 1 = 8.93411e-05 loss)
I0529 06:45:35.116142 11123 sgd_solver.cpp:105] Iteration 148100, lr = 0.002595
I0529 06:46:03.129150 11123 solver.cpp:218] Iteration 148200 (3.56985 iter/s, 28.0124s/100 iters), loss = 4.20995e-05
I0529 06:46:03.129199 11123 solver.cpp:237]     Train net output #0: loss = 4.12367e-05 (* 1 = 4.12367e-05 loss)
I0529 06:46:03.129209 11123 sgd_solver.cpp:105] Iteration 148200, lr = 0.00259
I0529 06:46:29.186966 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:46:31.130981 11123 solver.cpp:218] Iteration 148300 (3.57128 iter/s, 28.0012s/100 iters), loss = 2.20155e-05
I0529 06:46:31.131047 11123 solver.cpp:237]     Train net output #0: loss = 2.11528e-05 (* 1 = 2.11528e-05 loss)
I0529 06:46:31.131057 11123 sgd_solver.cpp:105] Iteration 148300, lr = 0.002585
I0529 06:46:59.108029 11123 solver.cpp:218] Iteration 148400 (3.57445 iter/s, 27.9764s/100 iters), loss = 2.45246e-05
I0529 06:46:59.108085 11123 solver.cpp:237]     Train net output #0: loss = 2.36618e-05 (* 1 = 2.36618e-05 loss)
I0529 06:46:59.108093 11123 sgd_solver.cpp:105] Iteration 148400, lr = 0.00258
I0529 06:47:27.143421 11123 solver.cpp:218] Iteration 148500 (3.56701 iter/s, 28.0347s/100 iters), loss = 5.45532e-05
I0529 06:47:27.143635 11123 solver.cpp:237]     Train net output #0: loss = 5.36903e-05 (* 1 = 5.36903e-05 loss)
I0529 06:47:27.143647 11123 sgd_solver.cpp:105] Iteration 148500, lr = 0.002575
I0529 06:47:55.165662 11123 solver.cpp:218] Iteration 148600 (3.5687 iter/s, 28.0214s/100 iters), loss = 0.000203747
I0529 06:47:55.165725 11123 solver.cpp:237]     Train net output #0: loss = 0.000202884 (* 1 = 0.000202884 loss)
I0529 06:47:55.165735 11123 sgd_solver.cpp:105] Iteration 148600, lr = 0.00257
I0529 06:48:23.175303 11123 solver.cpp:218] Iteration 148700 (3.57029 iter/s, 28.009s/100 iters), loss = 3.2532e-06
I0529 06:48:23.175472 11123 solver.cpp:237]     Train net output #0: loss = 2.39017e-06 (* 1 = 2.39017e-06 loss)
I0529 06:48:23.175484 11123 sgd_solver.cpp:105] Iteration 148700, lr = 0.002565
I0529 06:48:51.152000 11123 solver.cpp:218] Iteration 148800 (3.5745 iter/s, 27.9759s/100 iters), loss = 0.000127252
I0529 06:48:51.152053 11123 solver.cpp:237]     Train net output #0: loss = 0.000126389 (* 1 = 0.000126389 loss)
I0529 06:48:51.152062 11123 sgd_solver.cpp:105] Iteration 148800, lr = 0.00256
I0529 06:49:19.155704 11123 solver.cpp:218] Iteration 148900 (3.57104 iter/s, 28.003s/100 iters), loss = 1.75412e-05
I0529 06:49:19.155885 11123 solver.cpp:237]     Train net output #0: loss = 1.66783e-05 (* 1 = 1.66783e-05 loss)
I0529 06:49:19.155897 11123 sgd_solver.cpp:105] Iteration 148900, lr = 0.002555
I0529 06:49:20.856595 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:49:46.898277 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_149000.caffemodel
I0529 06:49:47.283260 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_149000.solverstate
I0529 06:49:47.429060 11123 solver.cpp:330] Iteration 149000, Testing net (#0)
I0529 06:49:51.572717 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:49:51.880607 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948
I0529 06:49:51.880645 11123 solver.cpp:397]     Test net output #1: loss = 0.237 (* 1 = 0.237 loss)
I0529 06:49:52.158155 11123 solver.cpp:218] Iteration 149000 (3.03016 iter/s, 33.0015s/100 iters), loss = 5.13867e-05
I0529 06:49:52.158205 11123 solver.cpp:237]     Train net output #0: loss = 5.05238e-05 (* 1 = 5.05238e-05 loss)
I0529 06:49:52.158215 11123 sgd_solver.cpp:105] Iteration 149000, lr = 0.00255
I0529 06:50:20.175331 11123 solver.cpp:218] Iteration 149100 (3.56933 iter/s, 28.0165s/100 iters), loss = 0.000111023
I0529 06:50:20.175384 11123 solver.cpp:237]     Train net output #0: loss = 0.00011016 (* 1 = 0.00011016 loss)
I0529 06:50:20.175393 11123 sgd_solver.cpp:105] Iteration 149100, lr = 0.002545
I0529 06:50:48.193060 11123 solver.cpp:218] Iteration 149200 (3.56926 iter/s, 28.017s/100 iters), loss = 9.32106e-06
I0529 06:50:48.193260 11123 solver.cpp:237]     Train net output #0: loss = 8.45806e-06 (* 1 = 8.45806e-06 loss)
I0529 06:50:48.193272 11123 sgd_solver.cpp:105] Iteration 149200, lr = 0.00254
I0529 06:51:16.190892 11123 solver.cpp:218] Iteration 149300 (3.57181 iter/s, 27.997s/100 iters), loss = 3.75418e-06
I0529 06:51:16.190944 11123 solver.cpp:237]     Train net output #0: loss = 2.89087e-06 (* 1 = 2.89087e-06 loss)
I0529 06:51:16.190954 11123 sgd_solver.cpp:105] Iteration 149300, lr = 0.002535
I0529 06:51:44.199164 11123 solver.cpp:218] Iteration 149400 (3.57046 iter/s, 28.0076s/100 iters), loss = 6.23972e-06
I0529 06:51:44.199339 11123 solver.cpp:237]     Train net output #0: loss = 5.37641e-06 (* 1 = 5.37641e-06 loss)
I0529 06:51:44.199352 11123 sgd_solver.cpp:105] Iteration 149400, lr = 0.00253
I0529 06:52:12.195139 11123 solver.cpp:218] Iteration 149500 (3.57204 iter/s, 27.9952s/100 iters), loss = 0.000210603
I0529 06:52:12.195194 11123 solver.cpp:237]     Train net output #0: loss = 0.000209739 (* 1 = 0.000209739 loss)
I0529 06:52:12.195202 11123 sgd_solver.cpp:105] Iteration 149500, lr = 0.002525
I0529 06:52:17.534624 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:52:40.209491 11123 solver.cpp:218] Iteration 149600 (3.56969 iter/s, 28.0137s/100 iters), loss = 9.20262e-06
I0529 06:52:40.209544 11123 solver.cpp:237]     Train net output #0: loss = 8.33911e-06 (* 1 = 8.33911e-06 loss)
I0529 06:52:40.209553 11123 sgd_solver.cpp:105] Iteration 149600, lr = 0.00252
I0529 06:53:08.228955 11123 solver.cpp:218] Iteration 149700 (3.56903 iter/s, 28.0188s/100 iters), loss = 1.29099e-05
I0529 06:53:08.229146 11123 solver.cpp:237]     Train net output #0: loss = 1.20465e-05 (* 1 = 1.20465e-05 loss)
I0529 06:53:08.229157 11123 sgd_solver.cpp:105] Iteration 149700, lr = 0.002515
I0529 06:53:36.247254 11123 solver.cpp:218] Iteration 149800 (3.5692 iter/s, 28.0175s/100 iters), loss = 8.82678e-06
I0529 06:53:36.247304 11123 solver.cpp:237]     Train net output #0: loss = 7.96346e-06 (* 1 = 7.96346e-06 loss)
I0529 06:53:36.247314 11123 sgd_solver.cpp:105] Iteration 149800, lr = 0.00251
I0529 06:54:04.264935 11123 solver.cpp:218] Iteration 149900 (3.56926 iter/s, 28.017s/100 iters), loss = 2.24336e-05
I0529 06:54:04.265147 11123 solver.cpp:237]     Train net output #0: loss = 2.15703e-05 (* 1 = 2.15703e-05 loss)
I0529 06:54:04.265173 11123 sgd_solver.cpp:105] Iteration 149900, lr = 0.002505
I0529 06:54:31.995452 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_150000.caffemodel
I0529 06:54:32.349638 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_150000.solverstate
I0529 06:54:32.498271 11123 solver.cpp:330] Iteration 150000, Testing net (#0)
I0529 06:54:36.941192 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939
I0529 06:54:36.941326 11123 solver.cpp:397]     Test net output #1: loss = 0.255639 (* 1 = 0.255639 loss)
I0529 06:54:37.218518 11123 solver.cpp:218] Iteration 150000 (3.03466 iter/s, 32.9527s/100 iters), loss = 0.000371352
I0529 06:54:37.218569 11123 solver.cpp:237]     Train net output #0: loss = 0.000370489 (* 1 = 0.000370489 loss)
I0529 06:54:37.218578 11123 sgd_solver.cpp:105] Iteration 150000, lr = 0.0025
I0529 06:55:05.253187 11123 solver.cpp:218] Iteration 150100 (3.5671 iter/s, 28.034s/100 iters), loss = 3.04893e-05
I0529 06:55:05.253237 11123 solver.cpp:237]     Train net output #0: loss = 2.96259e-05 (* 1 = 2.96259e-05 loss)
I0529 06:55:05.253245 11123 sgd_solver.cpp:105] Iteration 150100, lr = 0.002495
I0529 06:55:13.964481 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:55:33.283640 11123 solver.cpp:218] Iteration 150200 (3.56763 iter/s, 28.0298s/100 iters), loss = 6.38705e-05
I0529 06:55:33.283690 11123 solver.cpp:237]     Train net output #0: loss = 6.30071e-05 (* 1 = 6.30071e-05 loss)
I0529 06:55:33.283699 11123 sgd_solver.cpp:105] Iteration 150200, lr = 0.00249
I0529 06:56:01.298375 11123 solver.cpp:218] Iteration 150300 (3.56964 iter/s, 28.0141s/100 iters), loss = 1.10503e-05
I0529 06:56:01.298542 11123 solver.cpp:237]     Train net output #0: loss = 1.01867e-05 (* 1 = 1.01867e-05 loss)
I0529 06:56:01.298554 11123 sgd_solver.cpp:105] Iteration 150300, lr = 0.002485
I0529 06:56:29.313493 11123 solver.cpp:218] Iteration 150400 (3.5696 iter/s, 28.0143s/100 iters), loss = 1.75757e-06
I0529 06:56:29.313545 11123 solver.cpp:237]     Train net output #0: loss = 8.94075e-07 (* 1 = 8.94075e-07 loss)
I0529 06:56:29.313565 11123 sgd_solver.cpp:105] Iteration 150400, lr = 0.00248
I0529 06:56:57.330659 11123 solver.cpp:218] Iteration 150500 (3.56933 iter/s, 28.0165s/100 iters), loss = 7.68456e-05
I0529 06:56:57.330832 11123 solver.cpp:237]     Train net output #0: loss = 7.5982e-05 (* 1 = 7.5982e-05 loss)
I0529 06:56:57.330847 11123 sgd_solver.cpp:105] Iteration 150500, lr = 0.002475
I0529 06:57:25.356271 11123 solver.cpp:218] Iteration 150600 (3.56826 iter/s, 28.0248s/100 iters), loss = 7.89333e-05
I0529 06:57:25.356317 11123 solver.cpp:237]     Train net output #0: loss = 7.807e-05 (* 1 = 7.807e-05 loss)
I0529 06:57:25.356325 11123 sgd_solver.cpp:105] Iteration 150600, lr = 0.00247
I0529 06:57:53.370564 11123 solver.cpp:218] Iteration 150700 (3.56969 iter/s, 28.0136s/100 iters), loss = 3.52193e-06
I0529 06:57:53.370779 11123 solver.cpp:237]     Train net output #0: loss = 2.6584e-06 (* 1 = 2.6584e-06 loss)
I0529 06:57:53.370790 11123 sgd_solver.cpp:105] Iteration 150700, lr = 0.002465
I0529 06:58:05.717648 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:58:21.389086 11123 solver.cpp:218] Iteration 150800 (3.56917 iter/s, 28.0177s/100 iters), loss = 3.4682e-05
I0529 06:58:21.389129 11123 solver.cpp:237]     Train net output #0: loss = 3.38185e-05 (* 1 = 3.38185e-05 loss)
I0529 06:58:21.389138 11123 sgd_solver.cpp:105] Iteration 150800, lr = 0.00246
I0529 06:58:49.403934 11123 solver.cpp:218] Iteration 150900 (3.56962 iter/s, 28.0142s/100 iters), loss = 4.21963e-05
I0529 06:58:49.404141 11123 solver.cpp:237]     Train net output #0: loss = 4.13318e-05 (* 1 = 4.13318e-05 loss)
I0529 06:58:49.404152 11123 sgd_solver.cpp:105] Iteration 150900, lr = 0.002455
I0529 06:59:17.134938 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_151000.caffemodel
I0529 06:59:17.541244 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_151000.solverstate
I0529 06:59:17.691973 11123 solver.cpp:330] Iteration 151000, Testing net (#0)
I0529 06:59:18.895575 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:59:22.116674 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 06:59:22.116786 11123 solver.cpp:397]     Test net output #1: loss = 0.24321 (* 1 = 0.24321 loss)
I0529 06:59:22.392290 11123 solver.cpp:218] Iteration 151000 (3.03146 iter/s, 32.9874s/100 iters), loss = 3.99397e-06
I0529 06:59:22.392338 11123 solver.cpp:237]     Train net output #0: loss = 3.12928e-06 (* 1 = 3.12928e-06 loss)
I0529 06:59:22.392345 11123 sgd_solver.cpp:105] Iteration 151000, lr = 0.00245
I0529 06:59:50.390549 11123 solver.cpp:218] Iteration 151100 (3.57174 iter/s, 27.9976s/100 iters), loss = 0.000438046
I0529 06:59:50.390596 11123 solver.cpp:237]     Train net output #0: loss = 0.000437181 (* 1 = 0.000437181 loss)
I0529 06:59:50.390605 11123 sgd_solver.cpp:105] Iteration 151100, lr = 0.002445
I0529 07:00:18.403990 11123 solver.cpp:218] Iteration 151200 (3.5698 iter/s, 28.0128s/100 iters), loss = 0.000103466
I0529 07:00:18.404178 11123 solver.cpp:237]     Train net output #0: loss = 0.000102602 (* 1 = 0.000102602 loss)
I0529 07:00:18.404189 11123 sgd_solver.cpp:105] Iteration 151200, lr = 0.00244
I0529 07:00:46.401932 11123 solver.cpp:218] Iteration 151300 (3.57182 iter/s, 27.9969s/100 iters), loss = 2.67027e-06
I0529 07:00:46.401976 11123 solver.cpp:237]     Train net output #0: loss = 1.80603e-06 (* 1 = 1.80603e-06 loss)
I0529 07:00:46.401985 11123 sgd_solver.cpp:105] Iteration 151300, lr = 0.002435
I0529 07:01:02.392345 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:01:14.417856 11123 solver.cpp:218] Iteration 151400 (3.56962 iter/s, 28.0142s/100 iters), loss = 3.36659e-05
I0529 07:01:14.417904 11123 solver.cpp:237]     Train net output #0: loss = 3.28016e-05 (* 1 = 3.28016e-05 loss)
I0529 07:01:14.417913 11123 sgd_solver.cpp:105] Iteration 151400, lr = 0.00243
I0529 07:01:42.406167 11123 solver.cpp:218] Iteration 151500 (3.57313 iter/s, 27.9867s/100 iters), loss = 6.85468e-06
I0529 07:01:42.406397 11123 solver.cpp:237]     Train net output #0: loss = 5.99047e-06 (* 1 = 5.99047e-06 loss)
I0529 07:01:42.406409 11123 sgd_solver.cpp:105] Iteration 151500, lr = 0.002425
I0529 07:02:10.386286 11123 solver.cpp:218] Iteration 151600 (3.57419 iter/s, 27.9784s/100 iters), loss = 5.47171e-06
I0529 07:02:10.386337 11123 solver.cpp:237]     Train net output #0: loss = 4.60756e-06 (* 1 = 4.60756e-06 loss)
I0529 07:02:10.386345 11123 sgd_solver.cpp:105] Iteration 151600, lr = 0.00242
I0529 07:02:38.366909 11123 solver.cpp:218] Iteration 151700 (3.5741 iter/s, 27.9791s/100 iters), loss = 0.000142624
I0529 07:02:38.367074 11123 solver.cpp:237]     Train net output #0: loss = 0.000141761 (* 1 = 0.000141761 loss)
I0529 07:02:38.367084 11123 sgd_solver.cpp:105] Iteration 151700, lr = 0.002415
I0529 07:03:06.347587 11123 solver.cpp:218] Iteration 151800 (3.5741 iter/s, 27.9791s/100 iters), loss = 2.66384e-05
I0529 07:03:06.347640 11123 solver.cpp:237]     Train net output #0: loss = 2.57748e-05 (* 1 = 2.57748e-05 loss)
I0529 07:03:06.347648 11123 sgd_solver.cpp:105] Iteration 151800, lr = 0.00241
I0529 07:03:34.326622 11123 solver.cpp:218] Iteration 151900 (3.57429 iter/s, 27.9776s/100 iters), loss = 5.02339e-05
I0529 07:03:34.326804 11123 solver.cpp:237]     Train net output #0: loss = 4.93705e-05 (* 1 = 4.93705e-05 loss)
I0529 07:03:34.326817 11123 sgd_solver.cpp:105] Iteration 151900, lr = 0.002405
I0529 07:03:53.921528 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:04:02.033152 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_152000.caffemodel
I0529 07:04:02.467234 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_152000.solverstate
I0529 07:04:02.613736 11123 solver.cpp:330] Iteration 152000, Testing net (#0)
I0529 07:04:05.333843 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:04:07.065119 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 07:04:07.065171 11123 solver.cpp:397]     Test net output #1: loss = 0.268845 (* 1 = 0.268845 loss)
I0529 07:04:07.341469 11123 solver.cpp:218] Iteration 152000 (3.02911 iter/s, 33.013s/100 iters), loss = 6.16869e-05
I0529 07:04:07.341517 11123 solver.cpp:237]     Train net output #0: loss = 6.08236e-05 (* 1 = 6.08236e-05 loss)
I0529 07:04:07.341526 11123 sgd_solver.cpp:105] Iteration 152000, lr = 0.0024
I0529 07:04:35.331490 11123 solver.cpp:218] Iteration 152100 (3.57288 iter/s, 27.9886s/100 iters), loss = 2.51041e-05
I0529 07:04:35.331552 11123 solver.cpp:237]     Train net output #0: loss = 2.42408e-05 (* 1 = 2.42408e-05 loss)
I0529 07:04:35.331560 11123 sgd_solver.cpp:105] Iteration 152100, lr = 0.002395
I0529 07:05:03.348397 11123 solver.cpp:218] Iteration 152200 (3.56945 iter/s, 28.0155s/100 iters), loss = 1.11274e-05
I0529 07:05:03.348585 11123 solver.cpp:237]     Train net output #0: loss = 1.02642e-05 (* 1 = 1.02642e-05 loss)
I0529 07:05:03.348623 11123 sgd_solver.cpp:105] Iteration 152200, lr = 0.00239
I0529 07:05:31.360095 11123 solver.cpp:218] Iteration 152300 (3.57013 iter/s, 28.0102s/100 iters), loss = 2.10403e-05
I0529 07:05:31.360153 11123 solver.cpp:237]     Train net output #0: loss = 2.01772e-05 (* 1 = 2.01772e-05 loss)
I0529 07:05:31.360167 11123 sgd_solver.cpp:105] Iteration 152300, lr = 0.002385
I0529 07:05:59.335525 11123 solver.cpp:218] Iteration 152400 (3.57473 iter/s, 27.9741s/100 iters), loss = 6.0426e-06
I0529 07:05:59.335726 11123 solver.cpp:237]     Train net output #0: loss = 5.17974e-06 (* 1 = 5.17974e-06 loss)
I0529 07:05:59.335757 11123 sgd_solver.cpp:105] Iteration 152400, lr = 0.00238
I0529 07:06:27.310449 11123 solver.cpp:218] Iteration 152500 (3.57481 iter/s, 27.9735s/100 iters), loss = 0.000257866
I0529 07:06:27.310504 11123 solver.cpp:237]     Train net output #0: loss = 0.000257003 (* 1 = 0.000257003 loss)
I0529 07:06:27.310513 11123 sgd_solver.cpp:105] Iteration 152500, lr = 0.002375
I0529 07:06:50.530763 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:06:55.270833 11123 solver.cpp:218] Iteration 152600 (3.57665 iter/s, 27.9591s/100 iters), loss = 8.12175e-05
I0529 07:06:55.270895 11123 solver.cpp:237]     Train net output #0: loss = 8.03547e-05 (* 1 = 8.03547e-05 loss)
I0529 07:06:55.270908 11123 sgd_solver.cpp:105] Iteration 152600, lr = 0.00237
I0529 07:07:23.298579 11123 solver.cpp:218] Iteration 152700 (3.56805 iter/s, 28.0265s/100 iters), loss = 4.17266e-05
I0529 07:07:23.298743 11123 solver.cpp:237]     Train net output #0: loss = 4.08638e-05 (* 1 = 4.08638e-05 loss)
I0529 07:07:23.298753 11123 sgd_solver.cpp:105] Iteration 152700, lr = 0.002365
I0529 07:07:51.279518 11123 solver.cpp:218] Iteration 152800 (3.57403 iter/s, 27.9796s/100 iters), loss = 1.84636e-06
I0529 07:07:51.279585 11123 solver.cpp:237]     Train net output #0: loss = 9.83479e-07 (* 1 = 9.83479e-07 loss)
I0529 07:07:51.279594 11123 sgd_solver.cpp:105] Iteration 152800, lr = 0.00236
I0529 07:08:19.256223 11123 solver.cpp:218] Iteration 152900 (3.57456 iter/s, 27.9755s/100 iters), loss = 0.000337152
I0529 07:08:19.257575 11123 solver.cpp:237]     Train net output #0: loss = 0.000336289 (* 1 = 0.000336289 loss)
I0529 07:08:19.257604 11123 sgd_solver.cpp:105] Iteration 152900, lr = 0.002355
I0529 07:08:46.951511 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_153000.caffemodel
I0529 07:08:47.263643 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_153000.solverstate
I0529 07:08:47.408988 11123 solver.cpp:330] Iteration 153000, Testing net (#0)
I0529 07:08:51.638499 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:08:51.857969 11123 solver.cpp:397]     Test net output #0: accuracy = 0.95
I0529 07:08:51.858016 11123 solver.cpp:397]     Test net output #1: loss = 0.229542 (* 1 = 0.229542 loss)
I0529 07:08:52.135206 11123 solver.cpp:218] Iteration 153000 (3.0417 iter/s, 32.8763s/100 iters), loss = 8.27185e-06
I0529 07:08:52.135248 11123 solver.cpp:237]     Train net output #0: loss = 7.40912e-06 (* 1 = 7.40912e-06 loss)
I0529 07:08:52.135257 11123 sgd_solver.cpp:105] Iteration 153000, lr = 0.00235
I0529 07:09:20.175825 11123 solver.cpp:218] Iteration 153100 (3.5664 iter/s, 28.0395s/100 iters), loss = 1.77436e-05
I0529 07:09:20.175871 11123 solver.cpp:237]     Train net output #0: loss = 1.6881e-05 (* 1 = 1.6881e-05 loss)
I0529 07:09:20.175880 11123 sgd_solver.cpp:105] Iteration 153100, lr = 0.002345
I0529 07:09:46.799720 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:09:48.182807 11123 solver.cpp:218] Iteration 153200 (3.57068 iter/s, 28.0058s/100 iters), loss = 3.24256e-05
I0529 07:09:48.182850 11123 solver.cpp:237]     Train net output #0: loss = 3.15631e-05 (* 1 = 3.15631e-05 loss)
I0529 07:09:48.182859 11123 sgd_solver.cpp:105] Iteration 153200, lr = 0.00234
I0529 07:10:16.199857 11123 solver.cpp:218] Iteration 153300 (3.5694 iter/s, 28.0159s/100 iters), loss = 3.94865e-05
I0529 07:10:16.199903 11123 solver.cpp:237]     Train net output #0: loss = 3.8624e-05 (* 1 = 3.8624e-05 loss)
I0529 07:10:16.199911 11123 sgd_solver.cpp:105] Iteration 153300, lr = 0.002335
I0529 07:10:44.214566 11123 solver.cpp:218] Iteration 153400 (3.56969 iter/s, 28.0136s/100 iters), loss = 0.000480477
I0529 07:10:44.214776 11123 solver.cpp:237]     Train net output #0: loss = 0.000479615 (* 1 = 0.000479615 loss)
I0529 07:10:44.214789 11123 sgd_solver.cpp:105] Iteration 153400, lr = 0.00233
I0529 07:11:12.231320 11123 solver.cpp:218] Iteration 153500 (3.56945 iter/s, 28.0155s/100 iters), loss = 1.23645e-05
I0529 07:11:12.231367 11123 solver.cpp:237]     Train net output #0: loss = 1.15019e-05 (* 1 = 1.15019e-05 loss)
I0529 07:11:12.231376 11123 sgd_solver.cpp:105] Iteration 153500, lr = 0.002325
I0529 07:11:40.233059 11123 solver.cpp:218] Iteration 153600 (3.57134 iter/s, 28.0007s/100 iters), loss = 2.15404e-05
I0529 07:11:40.233232 11123 solver.cpp:237]     Train net output #0: loss = 2.06777e-05 (* 1 = 2.06777e-05 loss)
I0529 07:11:40.233243 11123 sgd_solver.cpp:105] Iteration 153600, lr = 0.00232
I0529 07:12:08.221340 11123 solver.cpp:218] Iteration 153700 (3.57308 iter/s, 27.9871s/100 iters), loss = 3.61645e-06
I0529 07:12:08.221397 11123 solver.cpp:237]     Train net output #0: loss = 2.75378e-06 (* 1 = 2.75378e-06 loss)
I0529 07:12:08.221406 11123 sgd_solver.cpp:105] Iteration 153700, lr = 0.002315
I0529 07:12:36.197767 11123 solver.cpp:218] Iteration 153800 (3.57457 iter/s, 27.9754s/100 iters), loss = 0.000158638
I0529 07:12:36.197929 11123 solver.cpp:237]     Train net output #0: loss = 0.000157776 (* 1 = 0.000157776 loss)
I0529 07:12:36.197942 11123 sgd_solver.cpp:105] Iteration 153800, lr = 0.00231
I0529 07:12:38.458008 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:13:04.197227 11123 solver.cpp:218] Iteration 153900 (3.57165 iter/s, 27.9983s/100 iters), loss = 0.000356084
I0529 07:13:04.197270 11123 solver.cpp:237]     Train net output #0: loss = 0.000355222 (* 1 = 0.000355222 loss)
I0529 07:13:04.197279 11123 sgd_solver.cpp:105] Iteration 153900, lr = 0.002305
I0529 07:13:31.940397 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_154000.caffemodel
I0529 07:13:32.246949 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_154000.solverstate
I0529 07:13:32.393074 11123 solver.cpp:330] Iteration 154000, Testing net (#0)
I0529 07:13:36.838616 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 07:13:36.838652 11123 solver.cpp:397]     Test net output #1: loss = 0.231049 (* 1 = 0.231049 loss)
I0529 07:13:37.116397 11123 solver.cpp:218] Iteration 154000 (3.03785 iter/s, 32.918s/100 iters), loss = 2.49166e-05
I0529 07:13:37.116441 11123 solver.cpp:237]     Train net output #0: loss = 2.40538e-05 (* 1 = 2.40538e-05 loss)
I0529 07:13:37.116449 11123 sgd_solver.cpp:105] Iteration 154000, lr = 0.0023
I0529 07:14:05.089149 11123 solver.cpp:218] Iteration 154100 (3.57504 iter/s, 27.9717s/100 iters), loss = 0.00011633
I0529 07:14:05.089303 11123 solver.cpp:237]     Train net output #0: loss = 0.000115467 (* 1 = 0.000115467 loss)
I0529 07:14:05.089314 11123 sgd_solver.cpp:105] Iteration 154100, lr = 0.002295
I0529 07:14:33.060470 11123 solver.cpp:218] Iteration 154200 (3.57523 iter/s, 27.9702s/100 iters), loss = 9.51205e-06
I0529 07:14:33.060518 11123 solver.cpp:237]     Train net output #0: loss = 8.64924e-06 (* 1 = 8.64924e-06 loss)
I0529 07:14:33.060528 11123 sgd_solver.cpp:105] Iteration 154200, lr = 0.00229
I0529 07:15:01.036842 11123 solver.cpp:218] Iteration 154300 (3.57457 iter/s, 27.9754s/100 iters), loss = 9.95345e-05
I0529 07:15:01.036964 11123 solver.cpp:237]     Train net output #0: loss = 9.86717e-05 (* 1 = 9.86717e-05 loss)
I0529 07:15:01.036974 11123 sgd_solver.cpp:105] Iteration 154300, lr = 0.002285
I0529 07:15:29.024440 11123 solver.cpp:218] Iteration 154400 (3.57315 iter/s, 27.9865s/100 iters), loss = 0.000127192
I0529 07:15:29.024482 11123 solver.cpp:237]     Train net output #0: loss = 0.00012633 (* 1 = 0.00012633 loss)
I0529 07:15:29.024490 11123 sgd_solver.cpp:105] Iteration 154400, lr = 0.00228
I0529 07:15:34.915794 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:15:56.993155 11123 solver.cpp:218] Iteration 154500 (3.57555 iter/s, 27.9677s/100 iters), loss = 3.27686e-06
I0529 07:15:56.993197 11123 solver.cpp:237]     Train net output #0: loss = 2.414e-06 (* 1 = 2.414e-06 loss)
I0529 07:15:56.993206 11123 sgd_solver.cpp:105] Iteration 154500, lr = 0.002275
I0529 07:16:24.979022 11123 solver.cpp:218] Iteration 154600 (3.57336 iter/s, 27.9849s/100 iters), loss = 6.17375e-05
I0529 07:16:24.979207 11123 solver.cpp:237]     Train net output #0: loss = 6.08746e-05 (* 1 = 6.08746e-05 loss)
I0529 07:16:24.979218 11123 sgd_solver.cpp:105] Iteration 154600, lr = 0.00227
I0529 07:16:52.953827 11123 solver.cpp:218] Iteration 154700 (3.57479 iter/s, 27.9737s/100 iters), loss = 3.60241e-05
I0529 07:16:52.953872 11123 solver.cpp:237]     Train net output #0: loss = 3.51604e-05 (* 1 = 3.51604e-05 loss)
I0529 07:16:52.953882 11123 sgd_solver.cpp:105] Iteration 154700, lr = 0.002265
I0529 07:17:20.968603 11123 solver.cpp:218] Iteration 154800 (3.56967 iter/s, 28.0138s/100 iters), loss = 2.78205e-05
I0529 07:17:20.968729 11123 solver.cpp:237]     Train net output #0: loss = 2.69568e-05 (* 1 = 2.69568e-05 loss)
I0529 07:17:20.968739 11123 sgd_solver.cpp:105] Iteration 154800, lr = 0.00226
I0529 07:17:48.961706 11123 solver.cpp:218] Iteration 154900 (3.57244 iter/s, 27.9921s/100 iters), loss = 0.000244104
I0529 07:17:48.961750 11123 solver.cpp:237]     Train net output #0: loss = 0.00024324 (* 1 = 0.00024324 loss)
I0529 07:17:48.961760 11123 sgd_solver.cpp:105] Iteration 154900, lr = 0.002255
I0529 07:18:16.705417 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_155000.caffemodel
I0529 07:18:17.010288 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_155000.solverstate
I0529 07:18:17.155717 11123 solver.cpp:330] Iteration 155000, Testing net (#0)
I0529 07:18:18.451270 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:18:21.604995 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948
I0529 07:18:21.605029 11123 solver.cpp:397]     Test net output #1: loss = 0.24916 (* 1 = 0.24916 loss)
I0529 07:18:21.881996 11123 solver.cpp:218] Iteration 155000 (3.03774 iter/s, 32.9192s/100 iters), loss = 5.44749e-06
I0529 07:18:21.882051 11123 solver.cpp:237]     Train net output #0: loss = 4.58367e-06 (* 1 = 4.58367e-06 loss)
I0529 07:18:21.882060 11123 sgd_solver.cpp:105] Iteration 155000, lr = 0.00225
I0529 07:18:31.415285 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:18:49.862535 11123 solver.cpp:218] Iteration 155100 (3.57403 iter/s, 27.9796s/100 iters), loss = 5.61452e-06
I0529 07:18:49.862697 11123 solver.cpp:237]     Train net output #0: loss = 4.75057e-06 (* 1 = 4.75057e-06 loss)
I0529 07:18:49.862715 11123 sgd_solver.cpp:105] Iteration 155100, lr = 0.002245
I0529 07:19:17.853854 11123 solver.cpp:218] Iteration 155200 (3.57267 iter/s, 27.9903s/100 iters), loss = 0.000107485
I0529 07:19:17.853907 11123 solver.cpp:237]     Train net output #0: loss = 0.000106621 (* 1 = 0.000106621 loss)
I0529 07:19:17.853921 11123 sgd_solver.cpp:105] Iteration 155200, lr = 0.00224
I0529 07:19:45.843791 11123 solver.cpp:218] Iteration 155300 (3.57283 iter/s, 27.989s/100 iters), loss = 0.000180396
I0529 07:19:45.843957 11123 solver.cpp:237]     Train net output #0: loss = 0.000179532 (* 1 = 0.000179532 loss)
I0529 07:19:45.843968 11123 sgd_solver.cpp:105] Iteration 155300, lr = 0.002235
I0529 07:20:13.843484 11123 solver.cpp:218] Iteration 155400 (3.5716 iter/s, 27.9986s/100 iters), loss = 8.41004e-06
I0529 07:20:13.843530 11123 solver.cpp:237]     Train net output #0: loss = 7.54616e-06 (* 1 = 7.54616e-06 loss)
I0529 07:20:13.843551 11123 sgd_solver.cpp:105] Iteration 155400, lr = 0.00223
I0529 07:20:41.836865 11123 solver.cpp:218] Iteration 155500 (3.57239 iter/s, 27.9925s/100 iters), loss = 4.51764e-06
I0529 07:20:41.837075 11123 solver.cpp:237]     Train net output #0: loss = 3.65381e-06 (* 1 = 3.65381e-06 loss)
I0529 07:20:41.837105 11123 sgd_solver.cpp:105] Iteration 155500, lr = 0.002225
I0529 07:21:09.853615 11123 solver.cpp:218] Iteration 155600 (3.56943 iter/s, 28.0157s/100 iters), loss = 0.000319978
I0529 07:21:09.853658 11123 solver.cpp:237]     Train net output #0: loss = 0.000319115 (* 1 = 0.000319115 loss)
I0529 07:21:09.853667 11123 sgd_solver.cpp:105] Iteration 155600, lr = 0.00222
I0529 07:21:23.035617 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:21:37.856798 11123 solver.cpp:218] Iteration 155700 (3.57114 iter/s, 28.0023s/100 iters), loss = 2.99171e-06
I0529 07:21:37.856856 11123 solver.cpp:237]     Train net output #0: loss = 2.1279e-06 (* 1 = 2.1279e-06 loss)
I0529 07:21:37.856865 11123 sgd_solver.cpp:105] Iteration 155700, lr = 0.002215
I0529 07:22:05.826401 11123 solver.cpp:218] Iteration 155800 (3.57543 iter/s, 27.9687s/100 iters), loss = 6.05814e-05
I0529 07:22:05.826568 11123 solver.cpp:237]     Train net output #0: loss = 5.97176e-05 (* 1 = 5.97176e-05 loss)
I0529 07:22:05.826581 11123 sgd_solver.cpp:105] Iteration 155800, lr = 0.00221
I0529 07:22:33.766679 11123 solver.cpp:218] Iteration 155900 (3.57919 iter/s, 27.9393s/100 iters), loss = 6.17529e-05
I0529 07:22:33.766727 11123 solver.cpp:237]     Train net output #0: loss = 6.08885e-05 (* 1 = 6.08885e-05 loss)
I0529 07:22:33.766736 11123 sgd_solver.cpp:105] Iteration 155900, lr = 0.002205
I0529 07:23:01.434558 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_156000.caffemodel
I0529 07:23:01.739734 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_156000.solverstate
I0529 07:23:01.884572 11123 solver.cpp:330] Iteration 156000, Testing net (#0)
I0529 07:23:04.694630 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:23:06.336884 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 07:23:06.336940 11123 solver.cpp:397]     Test net output #1: loss = 0.263978 (* 1 = 0.263978 loss)
I0529 07:23:06.613796 11123 solver.cpp:218] Iteration 156000 (3.0445 iter/s, 32.8461s/100 iters), loss = 1.14269e-05
I0529 07:23:06.613847 11123 solver.cpp:237]     Train net output #0: loss = 1.05624e-05 (* 1 = 1.05624e-05 loss)
I0529 07:23:06.613855 11123 sgd_solver.cpp:105] Iteration 156000, lr = 0.0022
I0529 07:23:34.635812 11123 solver.cpp:218] Iteration 156100 (3.56874 iter/s, 28.0211s/100 iters), loss = 2.3156e-05
I0529 07:23:34.636023 11123 solver.cpp:237]     Train net output #0: loss = 2.22914e-05 (* 1 = 2.22914e-05 loss)
I0529 07:23:34.636034 11123 sgd_solver.cpp:105] Iteration 156100, lr = 0.002195
I0529 07:24:02.618322 11123 solver.cpp:218] Iteration 156200 (3.57379 iter/s, 27.9815s/100 iters), loss = 1.00026e-05
I0529 07:24:02.618372 11123 solver.cpp:237]     Train net output #0: loss = 9.13774e-06 (* 1 = 9.13774e-06 loss)
I0529 07:24:02.618381 11123 sgd_solver.cpp:105] Iteration 156200, lr = 0.00219
I0529 07:24:19.138924 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:24:30.582819 11123 solver.cpp:218] Iteration 156300 (3.57608 iter/s, 27.9636s/100 iters), loss = 1.191e-05
I0529 07:24:30.582864 11123 solver.cpp:237]     Train net output #0: loss = 1.10452e-05 (* 1 = 1.10452e-05 loss)
I0529 07:24:30.582871 11123 sgd_solver.cpp:105] Iteration 156300, lr = 0.002185
I0529 07:24:58.548367 11123 solver.cpp:218] Iteration 156400 (3.57594 iter/s, 27.9647s/100 iters), loss = 2.76744e-05
I0529 07:24:58.548534 11123 solver.cpp:237]     Train net output #0: loss = 2.68096e-05 (* 1 = 2.68096e-05 loss)
I0529 07:24:58.548549 11123 sgd_solver.cpp:105] Iteration 156400, lr = 0.00218
I0529 07:25:26.541903 11123 solver.cpp:218] Iteration 156500 (3.57238 iter/s, 27.9925s/100 iters), loss = 2.21194e-06
I0529 07:25:26.541951 11123 solver.cpp:237]     Train net output #0: loss = 1.34707e-06 (* 1 = 1.34707e-06 loss)
I0529 07:25:26.541960 11123 sgd_solver.cpp:105] Iteration 156500, lr = 0.002175
I0529 07:25:54.530654 11123 solver.cpp:218] Iteration 156600 (3.57298 iter/s, 27.9879s/100 iters), loss = 3.93543e-05
I0529 07:25:54.530850 11123 solver.cpp:237]     Train net output #0: loss = 3.84894e-05 (* 1 = 3.84894e-05 loss)
I0529 07:25:54.530863 11123 sgd_solver.cpp:105] Iteration 156600, lr = 0.00217
I0529 07:26:22.542501 11123 solver.cpp:218] Iteration 156700 (3.57005 iter/s, 28.0108s/100 iters), loss = 2.66037e-05
I0529 07:26:22.542549 11123 solver.cpp:237]     Train net output #0: loss = 2.57388e-05 (* 1 = 2.57388e-05 loss)
I0529 07:26:22.542558 11123 sgd_solver.cpp:105] Iteration 156700, lr = 0.002165
I0529 07:26:50.555115 11123 solver.cpp:218] Iteration 156800 (3.56993 iter/s, 28.0117s/100 iters), loss = 3.044e-05
I0529 07:26:50.555275 11123 solver.cpp:237]     Train net output #0: loss = 2.95751e-05 (* 1 = 2.95751e-05 loss)
I0529 07:26:50.555287 11123 sgd_solver.cpp:105] Iteration 156800, lr = 0.00216
I0529 07:27:10.750389 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:27:18.577862 11123 solver.cpp:218] Iteration 156900 (3.56866 iter/s, 28.0218s/100 iters), loss = 2.09881e-06
I0529 07:27:18.577910 11123 solver.cpp:237]     Train net output #0: loss = 1.23382e-06 (* 1 = 1.23382e-06 loss)
I0529 07:27:18.577919 11123 sgd_solver.cpp:105] Iteration 156900, lr = 0.002155
I0529 07:27:46.293237 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_157000.caffemodel
I0529 07:27:46.597499 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_157000.solverstate
I0529 07:27:46.742899 11123 solver.cpp:330] Iteration 157000, Testing net (#0)
I0529 07:27:51.062116 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:27:51.193305 11123 solver.cpp:397]     Test net output #0: accuracy = 0.95
I0529 07:27:51.193353 11123 solver.cpp:397]     Test net output #1: loss = 0.235126 (* 1 = 0.235126 loss)
I0529 07:27:51.468704 11123 solver.cpp:218] Iteration 157000 (3.04046 iter/s, 32.8898s/100 iters), loss = 1.16909e-06
I0529 07:27:51.468756 11123 solver.cpp:237]     Train net output #0: loss = 3.03984e-07 (* 1 = 3.03984e-07 loss)
I0529 07:27:51.468765 11123 sgd_solver.cpp:105] Iteration 157000, lr = 0.00215
I0529 07:28:19.455860 11123 solver.cpp:218] Iteration 157100 (3.57318 iter/s, 27.9863s/100 iters), loss = 2.54096e-05
I0529 07:28:19.456024 11123 solver.cpp:237]     Train net output #0: loss = 2.45441e-05 (* 1 = 2.45441e-05 loss)
I0529 07:28:19.456037 11123 sgd_solver.cpp:105] Iteration 157100, lr = 0.002145
I0529 07:28:47.437499 11123 solver.cpp:218] Iteration 157200 (3.5739 iter/s, 27.9807s/100 iters), loss = 1.90871e-05
I0529 07:28:47.437558 11123 solver.cpp:237]     Train net output #0: loss = 1.8222e-05 (* 1 = 1.8222e-05 loss)
I0529 07:28:47.437567 11123 sgd_solver.cpp:105] Iteration 157200, lr = 0.00214
I0529 07:29:15.452044 11123 solver.cpp:218] Iteration 157300 (3.56969 iter/s, 28.0137s/100 iters), loss = 1.33207e-05
I0529 07:29:15.452222 11123 solver.cpp:237]     Train net output #0: loss = 1.24556e-05 (* 1 = 1.24556e-05 loss)
I0529 07:29:15.452239 11123 sgd_solver.cpp:105] Iteration 157300, lr = 0.002135
I0529 07:29:43.455621 11123 solver.cpp:218] Iteration 157400 (3.5711 iter/s, 28.0026s/100 iters), loss = 5.899e-05
I0529 07:29:43.455675 11123 solver.cpp:237]     Train net output #0: loss = 5.8125e-05 (* 1 = 5.8125e-05 loss)
I0529 07:29:43.455684 11123 sgd_solver.cpp:105] Iteration 157400, lr = 0.00213
I0529 07:30:07.271739 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:30:11.459463 11123 solver.cpp:218] Iteration 157500 (3.57105 iter/s, 28.003s/100 iters), loss = 4.97167e-05
I0529 07:30:11.459522 11123 solver.cpp:237]     Train net output #0: loss = 4.88517e-05 (* 1 = 4.88517e-05 loss)
I0529 07:30:11.459532 11123 sgd_solver.cpp:105] Iteration 157500, lr = 0.002125
I0529 07:30:39.467756 11123 solver.cpp:218] Iteration 157600 (3.57048 iter/s, 28.0074s/100 iters), loss = 1.96492e-05
I0529 07:30:39.467928 11123 solver.cpp:237]     Train net output #0: loss = 1.87843e-05 (* 1 = 1.87843e-05 loss)
I0529 07:30:39.467941 11123 sgd_solver.cpp:105] Iteration 157600, lr = 0.00212
I0529 07:31:07.497784 11123 solver.cpp:218] Iteration 157700 (3.56773 iter/s, 28.029s/100 iters), loss = 0.000100983
I0529 07:31:07.497838 11123 solver.cpp:237]     Train net output #0: loss = 0.000100118 (* 1 = 0.000100118 loss)
I0529 07:31:07.497848 11123 sgd_solver.cpp:105] Iteration 157700, lr = 0.002115
I0529 07:31:35.509865 11123 solver.cpp:218] Iteration 157800 (3.57 iter/s, 28.0112s/100 iters), loss = 4.86419e-06
I0529 07:31:35.510121 11123 solver.cpp:237]     Train net output #0: loss = 3.99955e-06 (* 1 = 3.99955e-06 loss)
I0529 07:31:35.510133 11123 sgd_solver.cpp:105] Iteration 157800, lr = 0.00211
I0529 07:32:03.501546 11123 solver.cpp:218] Iteration 157900 (3.57263 iter/s, 27.9906s/100 iters), loss = 9.37978e-05
I0529 07:32:03.501600 11123 solver.cpp:237]     Train net output #0: loss = 9.29332e-05 (* 1 = 9.29332e-05 loss)
I0529 07:32:03.501610 11123 sgd_solver.cpp:105] Iteration 157900, lr = 0.002105
I0529 07:32:31.217202 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_158000.caffemodel
I0529 07:32:31.525723 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_158000.solverstate
I0529 07:32:31.676086 11123 solver.cpp:330] Iteration 158000, Testing net (#0)
I0529 07:32:36.125804 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 07:32:36.125841 11123 solver.cpp:397]     Test net output #1: loss = 0.224607 (* 1 = 0.224607 loss)
I0529 07:32:36.402204 11123 solver.cpp:218] Iteration 158000 (3.03955 iter/s, 32.8997s/100 iters), loss = 1.67125e-05
I0529 07:32:36.402251 11123 solver.cpp:237]     Train net output #0: loss = 1.58479e-05 (* 1 = 1.58479e-05 loss)
I0529 07:32:36.402261 11123 sgd_solver.cpp:105] Iteration 158000, lr = 0.0021
I0529 07:33:03.870971 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:33:04.417564 11123 solver.cpp:218] Iteration 158100 (3.56958 iter/s, 28.0145s/100 iters), loss = 9.82969e-06
I0529 07:33:04.417610 11123 solver.cpp:237]     Train net output #0: loss = 8.965e-06 (* 1 = 8.965e-06 loss)
I0529 07:33:04.417619 11123 sgd_solver.cpp:105] Iteration 158100, lr = 0.002095
I0529 07:33:32.395373 11123 solver.cpp:218] Iteration 158200 (3.57437 iter/s, 27.977s/100 iters), loss = 2.51409e-05
I0529 07:33:32.395416 11123 solver.cpp:237]     Train net output #0: loss = 2.42762e-05 (* 1 = 2.42762e-05 loss)
I0529 07:33:32.395424 11123 sgd_solver.cpp:105] Iteration 158200, lr = 0.00209
I0529 07:34:00.401945 11123 solver.cpp:218] Iteration 158300 (3.5707 iter/s, 28.0057s/100 iters), loss = 1.07832e-05
I0529 07:34:00.402146 11123 solver.cpp:237]     Train net output #0: loss = 9.91847e-06 (* 1 = 9.91847e-06 loss)
I0529 07:34:00.402159 11123 sgd_solver.cpp:105] Iteration 158300, lr = 0.002085
I0529 07:34:28.421581 11123 solver.cpp:218] Iteration 158400 (3.56905 iter/s, 28.0186s/100 iters), loss = 1.80494e-05
I0529 07:34:28.421627 11123 solver.cpp:237]     Train net output #0: loss = 1.71848e-05 (* 1 = 1.71848e-05 loss)
I0529 07:34:28.421634 11123 sgd_solver.cpp:105] Iteration 158400, lr = 0.00208
I0529 07:34:56.440361 11123 solver.cpp:218] Iteration 158500 (3.56911 iter/s, 28.0182s/100 iters), loss = 4.04744e-06
I0529 07:34:56.440562 11123 solver.cpp:237]     Train net output #0: loss = 3.18292e-06 (* 1 = 3.18292e-06 loss)
I0529 07:34:56.440587 11123 sgd_solver.cpp:105] Iteration 158500, lr = 0.002075
I0529 07:35:24.486752 11123 solver.cpp:218] Iteration 158600 (3.56552 iter/s, 28.0464s/100 iters), loss = 4.04912e-05
I0529 07:35:24.486798 11123 solver.cpp:237]     Train net output #0: loss = 3.96267e-05 (* 1 = 3.96267e-05 loss)
I0529 07:35:24.486806 11123 sgd_solver.cpp:105] Iteration 158600, lr = 0.00207
I0529 07:35:52.507858 11123 solver.cpp:218] Iteration 158700 (3.56873 iter/s, 28.0212s/100 iters), loss = 4.56387e-05
I0529 07:35:52.508035 11123 solver.cpp:237]     Train net output #0: loss = 4.47746e-05 (* 1 = 4.47746e-05 loss)
I0529 07:35:52.508046 11123 sgd_solver.cpp:105] Iteration 158700, lr = 0.002065
I0529 07:35:55.609109 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:36:20.537281 11123 solver.cpp:218] Iteration 158800 (3.56769 iter/s, 28.0293s/100 iters), loss = 1.08469e-06
I0529 07:36:20.537335 11123 solver.cpp:237]     Train net output #0: loss = 2.20537e-07 (* 1 = 2.20537e-07 loss)
I0529 07:36:20.537344 11123 sgd_solver.cpp:105] Iteration 158800, lr = 0.00206
I0529 07:36:48.551564 11123 solver.cpp:218] Iteration 158900 (3.56961 iter/s, 28.0143s/100 iters), loss = 6.71314e-05
I0529 07:36:48.551776 11123 solver.cpp:237]     Train net output #0: loss = 6.6267e-05 (* 1 = 6.6267e-05 loss)
I0529 07:36:48.551789 11123 sgd_solver.cpp:105] Iteration 158900, lr = 0.002055
I0529 07:37:16.291075 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_159000.caffemodel
I0529 07:37:16.699852 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_159000.solverstate
I0529 07:37:16.846567 11123 solver.cpp:330] Iteration 159000, Testing net (#0)
I0529 07:37:18.231248 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:37:21.298452 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 07:37:21.298542 11123 solver.cpp:397]     Test net output #1: loss = 0.250743 (* 1 = 0.250743 loss)
I0529 07:37:21.575780 11123 solver.cpp:218] Iteration 159000 (3.0281 iter/s, 33.024s/100 iters), loss = 1.08653e-05
I0529 07:37:21.575835 11123 solver.cpp:237]     Train net output #0: loss = 1.00019e-05 (* 1 = 1.00019e-05 loss)
I0529 07:37:21.575845 11123 sgd_solver.cpp:105] Iteration 159000, lr = 0.00205
I0529 07:37:49.602589 11123 solver.cpp:218] Iteration 159100 (3.56802 iter/s, 28.0267s/100 iters), loss = 2.52097e-05
I0529 07:37:49.602643 11123 solver.cpp:237]     Train net output #0: loss = 2.43463e-05 (* 1 = 2.43463e-05 loss)
I0529 07:37:49.602653 11123 sgd_solver.cpp:105] Iteration 159100, lr = 0.002045
I0529 07:38:17.622031 11123 solver.cpp:218] Iteration 159200 (3.56897 iter/s, 28.0193s/100 iters), loss = 0.000102859
I0529 07:38:17.622205 11123 solver.cpp:237]     Train net output #0: loss = 0.000101995 (* 1 = 0.000101995 loss)
I0529 07:38:17.622217 11123 sgd_solver.cpp:105] Iteration 159200, lr = 0.00204
I0529 07:38:45.621369 11123 solver.cpp:218] Iteration 159300 (3.57155 iter/s, 27.9991s/100 iters), loss = 1.48865e-05
I0529 07:38:45.621428 11123 solver.cpp:237]     Train net output #0: loss = 1.40232e-05 (* 1 = 1.40232e-05 loss)
I0529 07:38:45.621436 11123 sgd_solver.cpp:105] Iteration 159300, lr = 0.002035
I0529 07:38:52.082151 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:39:13.625587 11123 solver.cpp:218] Iteration 159400 (3.57092 iter/s, 28.004s/100 iters), loss = 1.14853e-05
I0529 07:39:13.625645 11123 solver.cpp:237]     Train net output #0: loss = 1.0622e-05 (* 1 = 1.0622e-05 loss)
I0529 07:39:13.625654 11123 sgd_solver.cpp:105] Iteration 159400, lr = 0.00203
I0529 07:39:41.626241 11123 solver.cpp:218] Iteration 159500 (3.57137 iter/s, 28.0004s/100 iters), loss = 0.000135124
I0529 07:39:41.626476 11123 solver.cpp:237]     Train net output #0: loss = 0.00013426 (* 1 = 0.00013426 loss)
I0529 07:39:41.626489 11123 sgd_solver.cpp:105] Iteration 159500, lr = 0.002025
I0529 07:40:09.630523 11123 solver.cpp:218] Iteration 159600 (3.57094 iter/s, 28.0039s/100 iters), loss = 2.23983e-06
I0529 07:40:09.630580 11123 solver.cpp:237]     Train net output #0: loss = 1.37688e-06 (* 1 = 1.37688e-06 loss)
I0529 07:40:09.630589 11123 sgd_solver.cpp:105] Iteration 159600, lr = 0.00202
I0529 07:40:37.599161 11123 solver.cpp:218] Iteration 159700 (3.57547 iter/s, 27.9684s/100 iters), loss = 8.2926e-05
I0529 07:40:37.599342 11123 solver.cpp:237]     Train net output #0: loss = 8.20629e-05 (* 1 = 8.20629e-05 loss)
I0529 07:40:37.599354 11123 sgd_solver.cpp:105] Iteration 159700, lr = 0.002015
I0529 07:41:05.597323 11123 solver.cpp:218] Iteration 159800 (3.57172 iter/s, 27.9977s/100 iters), loss = 3.25692e-05
I0529 07:41:05.597379 11123 solver.cpp:237]     Train net output #0: loss = 3.17061e-05 (* 1 = 3.17061e-05 loss)
I0529 07:41:05.597388 11123 sgd_solver.cpp:105] Iteration 159800, lr = 0.00201
I0529 07:41:33.604548 11123 solver.cpp:218] Iteration 159900 (3.57055 iter/s, 28.0069s/100 iters), loss = 4.14963e-05
I0529 07:41:33.604766 11123 solver.cpp:237]     Train net output #0: loss = 4.06333e-05 (* 1 = 4.06333e-05 loss)
I0529 07:41:33.604779 11123 sgd_solver.cpp:105] Iteration 159900, lr = 0.002005
I0529 07:41:43.697309 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:42:01.309990 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_160000.caffemodel
I0529 07:42:01.753195 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_160000.solverstate
I0529 07:42:01.899199 11123 solver.cpp:330] Iteration 160000, Testing net (#0)
I0529 07:42:04.751794 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:42:06.344879 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 07:42:06.344915 11123 solver.cpp:397]     Test net output #1: loss = 0.261938 (* 1 = 0.261938 loss)
I0529 07:42:06.622357 11123 solver.cpp:218] Iteration 160000 (3.02872 iter/s, 33.0173s/100 iters), loss = 5.39886e-06
I0529 07:42:06.622413 11123 solver.cpp:237]     Train net output #0: loss = 4.53596e-06 (* 1 = 4.53596e-06 loss)
I0529 07:42:06.622422 11123 sgd_solver.cpp:105] Iteration 160000, lr = 0.002
I0529 07:42:34.589166 11123 solver.cpp:218] Iteration 160100 (3.57571 iter/s, 27.9664s/100 iters), loss = 0.000102586
I0529 07:42:34.589227 11123 solver.cpp:237]     Train net output #0: loss = 0.000101723 (* 1 = 0.000101723 loss)
I0529 07:42:34.589236 11123 sgd_solver.cpp:105] Iteration 160100, lr = 0.001995
I0529 07:43:02.555181 11123 solver.cpp:218] Iteration 160200 (3.57582 iter/s, 27.9656s/100 iters), loss = 1.99542e-06
I0529 07:43:02.555332 11123 solver.cpp:237]     Train net output #0: loss = 1.13249e-06 (* 1 = 1.13249e-06 loss)
I0529 07:43:02.555344 11123 sgd_solver.cpp:105] Iteration 160200, lr = 0.00199
I0529 07:43:30.522047 11123 solver.cpp:218] Iteration 160300 (3.57572 iter/s, 27.9664s/100 iters), loss = 3.62733e-05
I0529 07:43:30.522089 11123 solver.cpp:237]     Train net output #0: loss = 3.54103e-05 (* 1 = 3.54103e-05 loss)
I0529 07:43:30.522097 11123 sgd_solver.cpp:105] Iteration 160300, lr = 0.001985
I0529 07:43:58.492352 11123 solver.cpp:218] Iteration 160400 (3.57527 iter/s, 27.9699s/100 iters), loss = 9.86951e-06
I0529 07:43:58.492568 11123 solver.cpp:237]     Train net output #0: loss = 9.00658e-06 (* 1 = 9.00658e-06 loss)
I0529 07:43:58.492579 11123 sgd_solver.cpp:105] Iteration 160400, lr = 0.00198
I0529 07:44:26.487031 11123 solver.cpp:218] Iteration 160500 (3.57218 iter/s, 27.9941s/100 iters), loss = 0.000164385
I0529 07:44:26.487074 11123 solver.cpp:237]     Train net output #0: loss = 0.000163522 (* 1 = 0.000163522 loss)
I0529 07:44:26.487083 11123 sgd_solver.cpp:105] Iteration 160500, lr = 0.001975
I0529 07:44:40.212589 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:44:54.469583 11123 solver.cpp:218] Iteration 160600 (3.57371 iter/s, 27.9821s/100 iters), loss = 2.57335e-05
I0529 07:44:54.469631 11123 solver.cpp:237]     Train net output #0: loss = 2.48706e-05 (* 1 = 2.48706e-05 loss)
I0529 07:44:54.469642 11123 sgd_solver.cpp:105] Iteration 160600, lr = 0.00197
I0529 07:45:22.472350 11123 solver.cpp:218] Iteration 160700 (3.57113 iter/s, 28.0023s/100 iters), loss = 2.35178e-05
I0529 07:45:22.472827 11123 solver.cpp:237]     Train net output #0: loss = 2.26549e-05 (* 1 = 2.26549e-05 loss)
I0529 07:45:22.472843 11123 sgd_solver.cpp:105] Iteration 160700, lr = 0.001965
I0529 07:45:50.456019 11123 solver.cpp:218] Iteration 160800 (3.57363 iter/s, 27.9828s/100 iters), loss = 2.04677e-05
I0529 07:45:50.456073 11123 solver.cpp:237]     Train net output #0: loss = 1.9605e-05 (* 1 = 1.9605e-05 loss)
I0529 07:45:50.456085 11123 sgd_solver.cpp:105] Iteration 160800, lr = 0.00196
I0529 07:46:18.448295 11123 solver.cpp:218] Iteration 160900 (3.57248 iter/s, 27.9918s/100 iters), loss = 2.74485e-05
I0529 07:46:18.448534 11123 solver.cpp:237]     Train net output #0: loss = 2.65858e-05 (* 1 = 2.65858e-05 loss)
I0529 07:46:18.448546 11123 sgd_solver.cpp:105] Iteration 160900, lr = 0.001955
I0529 07:46:46.149479 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_161000.caffemodel
I0529 07:46:46.548918 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_161000.solverstate
I0529 07:46:46.695207 11123 solver.cpp:330] Iteration 161000, Testing net (#0)
I0529 07:46:51.057404 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:46:51.142307 11123 solver.cpp:397]     Test net output #0: accuracy = 0.95
I0529 07:46:51.142348 11123 solver.cpp:397]     Test net output #1: loss = 0.234828 (* 1 = 0.234828 loss)
I0529 07:46:51.419070 11123 solver.cpp:218] Iteration 161000 (3.03306 iter/s, 32.97s/100 iters), loss = 7.01903e-05
I0529 07:46:51.419113 11123 solver.cpp:237]     Train net output #0: loss = 6.93277e-05 (* 1 = 6.93277e-05 loss)
I0529 07:46:51.419122 11123 sgd_solver.cpp:105] Iteration 161000, lr = 0.00195
I0529 07:47:19.448885 11123 solver.cpp:218] Iteration 161100 (3.56769 iter/s, 28.0293s/100 iters), loss = 1.35505e-05
I0529 07:47:19.448945 11123 solver.cpp:237]     Train net output #0: loss = 1.26879e-05 (* 1 = 1.26879e-05 loss)
I0529 07:47:19.448954 11123 sgd_solver.cpp:105] Iteration 161100, lr = 0.001945
I0529 07:47:36.842730 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:47:47.473830 11123 solver.cpp:218] Iteration 161200 (3.56832 iter/s, 28.0244s/100 iters), loss = 5.30906e-05
I0529 07:47:47.473876 11123 solver.cpp:237]     Train net output #0: loss = 5.2228e-05 (* 1 = 5.2228e-05 loss)
I0529 07:47:47.473886 11123 sgd_solver.cpp:105] Iteration 161200, lr = 0.00194
I0529 07:48:15.510139 11123 solver.cpp:218] Iteration 161300 (3.56687 iter/s, 28.0358s/100 iters), loss = 0.00017091
I0529 07:48:15.510299 11123 solver.cpp:237]     Train net output #0: loss = 0.000170047 (* 1 = 0.000170047 loss)
I0529 07:48:15.510313 11123 sgd_solver.cpp:105] Iteration 161300, lr = 0.001935
I0529 07:48:43.521500 11123 solver.cpp:218] Iteration 161400 (3.57006 iter/s, 28.0107s/100 iters), loss = 0.000100546
I0529 07:48:43.521543 11123 solver.cpp:237]     Train net output #0: loss = 9.96834e-05 (* 1 = 9.96834e-05 loss)
I0529 07:48:43.521553 11123 sgd_solver.cpp:105] Iteration 161400, lr = 0.00193
I0529 07:49:11.504078 11123 solver.cpp:218] Iteration 161500 (3.57372 iter/s, 27.982s/100 iters), loss = 2.24845e-05
I0529 07:49:11.504230 11123 solver.cpp:237]     Train net output #0: loss = 2.1622e-05 (* 1 = 2.1622e-05 loss)
I0529 07:49:11.504241 11123 sgd_solver.cpp:105] Iteration 161500, lr = 0.001925
I0529 07:49:39.482197 11123 solver.cpp:218] Iteration 161600 (3.57431 iter/s, 27.9775s/100 iters), loss = 3.95306e-05
I0529 07:49:39.482241 11123 solver.cpp:237]     Train net output #0: loss = 3.86678e-05 (* 1 = 3.86678e-05 loss)
I0529 07:49:39.482250 11123 sgd_solver.cpp:105] Iteration 161600, lr = 0.00192
I0529 07:50:07.467798 11123 solver.cpp:218] Iteration 161700 (3.57334 iter/s, 27.985s/100 iters), loss = 8.38011e-05
I0529 07:50:07.468025 11123 solver.cpp:237]     Train net output #0: loss = 8.29383e-05 (* 1 = 8.29383e-05 loss)
I0529 07:50:07.468036 11123 sgd_solver.cpp:105] Iteration 161700, lr = 0.001915
I0529 07:50:28.451683 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:50:35.422619 11123 solver.cpp:218] Iteration 161800 (3.5773 iter/s, 27.9541s/100 iters), loss = 4.2399e-05
I0529 07:50:35.422664 11123 solver.cpp:237]     Train net output #0: loss = 4.15362e-05 (* 1 = 4.15362e-05 loss)
I0529 07:50:35.422673 11123 sgd_solver.cpp:105] Iteration 161800, lr = 0.00191
I0529 07:51:03.388190 11123 solver.cpp:218] Iteration 161900 (3.5759 iter/s, 27.965s/100 iters), loss = 1.68535e-06
I0529 07:51:03.388406 11123 solver.cpp:237]     Train net output #0: loss = 8.22546e-07 (* 1 = 8.22546e-07 loss)
I0529 07:51:03.388417 11123 sgd_solver.cpp:105] Iteration 161900, lr = 0.001905
I0529 07:51:31.070709 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_162000.caffemodel
I0529 07:51:31.504861 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_162000.solverstate
I0529 07:51:31.651850 11123 solver.cpp:330] Iteration 162000, Testing net (#0)
I0529 07:51:36.097949 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 07:51:36.098132 11123 solver.cpp:397]     Test net output #1: loss = 0.222239 (* 1 = 0.222239 loss)
I0529 07:51:36.374258 11123 solver.cpp:218] Iteration 162000 (3.03166 iter/s, 32.9852s/100 iters), loss = 3.95649e-06
I0529 07:51:36.374305 11123 solver.cpp:237]     Train net output #0: loss = 3.09357e-06 (* 1 = 3.09357e-06 loss)
I0529 07:51:36.374330 11123 sgd_solver.cpp:105] Iteration 162000, lr = 0.0019
I0529 07:52:04.395922 11123 solver.cpp:218] Iteration 162100 (3.56874 iter/s, 28.0211s/100 iters), loss = 0.00018798
I0529 07:52:04.395965 11123 solver.cpp:237]     Train net output #0: loss = 0.000187117 (* 1 = 0.000187117 loss)
I0529 07:52:04.395973 11123 sgd_solver.cpp:105] Iteration 162100, lr = 0.001895
I0529 07:52:32.422991 11123 solver.cpp:218] Iteration 162200 (3.56806 iter/s, 28.0265s/100 iters), loss = 2.78572e-05
I0529 07:52:32.423141 11123 solver.cpp:237]     Train net output #0: loss = 2.69943e-05 (* 1 = 2.69943e-05 loss)
I0529 07:52:32.423153 11123 sgd_solver.cpp:105] Iteration 162200, lr = 0.00189
I0529 07:53:00.449380 11123 solver.cpp:218] Iteration 162300 (3.56816 iter/s, 28.0257s/100 iters), loss = 1.68972e-05
I0529 07:53:00.449424 11123 solver.cpp:237]     Train net output #0: loss = 1.60345e-05 (* 1 = 1.60345e-05 loss)
I0529 07:53:00.449432 11123 sgd_solver.cpp:105] Iteration 162300, lr = 0.001885
I0529 07:53:24.844041 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:53:28.464370 11123 solver.cpp:218] Iteration 162400 (3.5696 iter/s, 28.0144s/100 iters), loss = 6.69348e-05
I0529 07:53:28.464414 11123 solver.cpp:237]     Train net output #0: loss = 6.60721e-05 (* 1 = 6.60721e-05 loss)
I0529 07:53:28.464423 11123 sgd_solver.cpp:105] Iteration 162400, lr = 0.00188
I0529 07:53:56.449359 11123 solver.cpp:218] Iteration 162500 (3.57342 iter/s, 27.9844s/100 iters), loss = 7.81803e-05
I0529 07:53:56.449512 11123 solver.cpp:237]     Train net output #0: loss = 7.73176e-05 (* 1 = 7.73176e-05 loss)
I0529 07:53:56.449525 11123 sgd_solver.cpp:105] Iteration 162500, lr = 0.001875
I0529 07:54:24.443115 11123 solver.cpp:218] Iteration 162600 (3.57232 iter/s, 27.993s/100 iters), loss = 2.15606e-06
I0529 07:54:24.443164 11123 solver.cpp:237]     Train net output #0: loss = 1.29342e-06 (* 1 = 1.29342e-06 loss)
I0529 07:54:24.443173 11123 sgd_solver.cpp:105] Iteration 162600, lr = 0.00187
I0529 07:54:52.447329 11123 solver.cpp:218] Iteration 162700 (3.57097 iter/s, 28.0036s/100 iters), loss = 2.70046e-05
I0529 07:54:52.447499 11123 solver.cpp:237]     Train net output #0: loss = 2.61425e-05 (* 1 = 2.61425e-05 loss)
I0529 07:54:52.447525 11123 sgd_solver.cpp:105] Iteration 162700, lr = 0.001865
I0529 07:55:20.477135 11123 solver.cpp:218] Iteration 162800 (3.56773 iter/s, 28.029s/100 iters), loss = 2.65929e-05
I0529 07:55:20.477195 11123 solver.cpp:237]     Train net output #0: loss = 2.57309e-05 (* 1 = 2.57309e-05 loss)
I0529 07:55:20.477208 11123 sgd_solver.cpp:105] Iteration 162800, lr = 0.00186
I0529 07:55:48.486368 11123 solver.cpp:218] Iteration 162900 (3.57034 iter/s, 28.0086s/100 iters), loss = 5.9523e-06
I0529 07:55:48.486526 11123 solver.cpp:237]     Train net output #0: loss = 5.09031e-06 (* 1 = 5.09031e-06 loss)
I0529 07:55:48.486538 11123 sgd_solver.cpp:105] Iteration 162900, lr = 0.001855
I0529 07:56:16.208606 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_163000.caffemodel
I0529 07:56:16.678315 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_163000.solverstate
I0529 07:56:16.825621 11123 solver.cpp:330] Iteration 163000, Testing net (#0)
I0529 07:56:18.248797 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:56:21.258961 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 07:56:21.259124 11123 solver.cpp:397]     Test net output #1: loss = 0.248685 (* 1 = 0.248685 loss)
I0529 07:56:21.536231 11123 solver.cpp:218] Iteration 163000 (3.02581 iter/s, 33.049s/100 iters), loss = 0.000128102
I0529 07:56:21.536275 11123 solver.cpp:237]     Train net output #0: loss = 0.00012724 (* 1 = 0.00012724 loss)
I0529 07:56:21.536284 11123 sgd_solver.cpp:105] Iteration 163000, lr = 0.00185
I0529 07:56:21.556095 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:56:49.552495 11123 solver.cpp:218] Iteration 163100 (3.56944 iter/s, 28.0156s/100 iters), loss = 5.77358e-06
I0529 07:56:49.552542 11123 solver.cpp:237]     Train net output #0: loss = 4.91154e-06 (* 1 = 4.91154e-06 loss)
I0529 07:56:49.552567 11123 sgd_solver.cpp:105] Iteration 163100, lr = 0.001845
I0529 07:57:17.567347 11123 solver.cpp:218] Iteration 163200 (3.56962 iter/s, 28.0142s/100 iters), loss = 2.85958e-05
I0529 07:57:17.567522 11123 solver.cpp:237]     Train net output #0: loss = 2.77338e-05 (* 1 = 2.77338e-05 loss)
I0529 07:57:17.567533 11123 sgd_solver.cpp:105] Iteration 163200, lr = 0.00184
I0529 07:57:45.558401 11123 solver.cpp:218] Iteration 163300 (3.57267 iter/s, 27.9903s/100 iters), loss = 7.12092e-06
I0529 07:57:45.558457 11123 solver.cpp:237]     Train net output #0: loss = 6.25879e-06 (* 1 = 6.25879e-06 loss)
I0529 07:57:45.558466 11123 sgd_solver.cpp:105] Iteration 163300, lr = 0.001835
I0529 07:58:13.530447 11123 solver.cpp:218] Iteration 163400 (3.57508 iter/s, 27.9714s/100 iters), loss = 3.77695e-05
I0529 07:58:13.530619 11123 solver.cpp:237]     Train net output #0: loss = 3.69072e-05 (* 1 = 3.69072e-05 loss)
I0529 07:58:13.530632 11123 sgd_solver.cpp:105] Iteration 163400, lr = 0.00183
I0529 07:58:41.492133 11123 solver.cpp:218] Iteration 163500 (3.57642 iter/s, 27.9609s/100 iters), loss = 9.2788e-06
I0529 07:58:41.492179 11123 solver.cpp:237]     Train net output #0: loss = 8.41654e-06 (* 1 = 8.41654e-06 loss)
I0529 07:58:41.492188 11123 sgd_solver.cpp:105] Iteration 163500, lr = 0.001825
I0529 07:59:09.462234 11123 solver.cpp:218] Iteration 163600 (3.57533 iter/s, 27.9694s/100 iters), loss = 1.48102e-05
I0529 07:59:09.462388 11123 solver.cpp:237]     Train net output #0: loss = 1.39481e-05 (* 1 = 1.39481e-05 loss)
I0529 07:59:09.462399 11123 sgd_solver.cpp:105] Iteration 163600, lr = 0.00182
I0529 07:59:13.116996 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:59:37.464664 11123 solver.cpp:218] Iteration 163700 (3.57122 iter/s, 28.0016s/100 iters), loss = 4.06299e-06
I0529 07:59:37.464709 11123 solver.cpp:237]     Train net output #0: loss = 3.20082e-06 (* 1 = 3.20082e-06 loss)
I0529 07:59:37.464717 11123 sgd_solver.cpp:105] Iteration 163700, lr = 0.001815
I0529 08:00:05.472482 11123 solver.cpp:218] Iteration 163800 (3.57052 iter/s, 28.0071s/100 iters), loss = 1.84781e-05
I0529 08:00:05.472834 11123 solver.cpp:237]     Train net output #0: loss = 1.76159e-05 (* 1 = 1.76159e-05 loss)
I0529 08:00:05.472846 11123 sgd_solver.cpp:105] Iteration 163800, lr = 0.00181
I0529 08:00:33.480690 11123 solver.cpp:218] Iteration 163900 (3.57051 iter/s, 28.0072s/100 iters), loss = 6.3817e-06
I0529 08:00:33.480734 11123 solver.cpp:237]     Train net output #0: loss = 5.51954e-06 (* 1 = 5.51954e-06 loss)
I0529 08:00:33.480743 11123 sgd_solver.cpp:105] Iteration 163900, lr = 0.001805
I0529 08:01:01.212033 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_164000.caffemodel
I0529 08:01:01.768870 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_164000.solverstate
I0529 08:01:01.915401 11123 solver.cpp:330] Iteration 164000, Testing net (#0)
I0529 08:01:04.861687 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:01:06.372160 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 08:01:06.372200 11123 solver.cpp:397]     Test net output #1: loss = 0.267913 (* 1 = 0.267913 loss)
I0529 08:01:06.649178 11123 solver.cpp:218] Iteration 164000 (3.01498 iter/s, 33.1677s/100 iters), loss = 3.47299e-06
I0529 08:01:06.649229 11123 solver.cpp:237]     Train net output #0: loss = 2.6107e-06 (* 1 = 2.6107e-06 loss)
I0529 08:01:06.649237 11123 sgd_solver.cpp:105] Iteration 164000, lr = 0.0018
I0529 08:01:34.654821 11123 solver.cpp:218] Iteration 164100 (3.5708 iter/s, 28.0049s/100 iters), loss = 5.77376e-06
I0529 08:01:34.655088 11123 solver.cpp:237]     Train net output #0: loss = 4.91149e-06 (* 1 = 4.91149e-06 loss)
I0529 08:01:34.655100 11123 sgd_solver.cpp:105] Iteration 164100, lr = 0.001795
I0529 08:02:02.658169 11123 solver.cpp:218] Iteration 164200 (3.57112 iter/s, 28.0024s/100 iters), loss = 1.34335e-05
I0529 08:02:02.658221 11123 solver.cpp:237]     Train net output #0: loss = 1.25711e-05 (* 1 = 1.25711e-05 loss)
I0529 08:02:02.658231 11123 sgd_solver.cpp:105] Iteration 164200, lr = 0.00179
I0529 08:02:09.954766 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:02:30.654899 11123 solver.cpp:218] Iteration 164300 (3.57194 iter/s, 27.996s/100 iters), loss = 4.06467e-05
I0529 08:02:30.654958 11123 solver.cpp:237]     Train net output #0: loss = 3.97843e-05 (* 1 = 3.97843e-05 loss)
I0529 08:02:30.654981 11123 sgd_solver.cpp:105] Iteration 164300, lr = 0.001785
I0529 08:02:58.660111 11123 solver.cpp:218] Iteration 164400 (3.57085 iter/s, 28.0045s/100 iters), loss = 2.4787e-05
I0529 08:02:58.660289 11123 solver.cpp:237]     Train net output #0: loss = 2.39245e-05 (* 1 = 2.39245e-05 loss)
I0529 08:02:58.660306 11123 sgd_solver.cpp:105] Iteration 164400, lr = 0.00178
I0529 08:03:26.654448 11123 solver.cpp:218] Iteration 164500 (3.57226 iter/s, 27.9935s/100 iters), loss = 9.24298e-06
I0529 08:03:26.654502 11123 solver.cpp:237]     Train net output #0: loss = 8.38059e-06 (* 1 = 8.38059e-06 loss)
I0529 08:03:26.654516 11123 sgd_solver.cpp:105] Iteration 164500, lr = 0.001775
I0529 08:03:54.637218 11123 solver.cpp:218] Iteration 164600 (3.57372 iter/s, 27.9821s/100 iters), loss = 0.000142566
I0529 08:03:54.637387 11123 solver.cpp:237]     Train net output #0: loss = 0.000141704 (* 1 = 0.000141704 loss)
I0529 08:03:54.637398 11123 sgd_solver.cpp:105] Iteration 164600, lr = 0.00177
I0529 08:04:22.629304 11123 solver.cpp:218] Iteration 164700 (3.57254 iter/s, 27.9913s/100 iters), loss = 4.71221e-05
I0529 08:04:22.629359 11123 solver.cpp:237]     Train net output #0: loss = 4.62604e-05 (* 1 = 4.62604e-05 loss)
I0529 08:04:22.629367 11123 sgd_solver.cpp:105] Iteration 164700, lr = 0.001765
I0529 08:04:50.632517 11123 solver.cpp:218] Iteration 164800 (3.57111 iter/s, 28.0025s/100 iters), loss = 2.75879e-05
I0529 08:04:50.632736 11123 solver.cpp:237]     Train net output #0: loss = 2.67262e-05 (* 1 = 2.67262e-05 loss)
I0529 08:04:50.632748 11123 sgd_solver.cpp:105] Iteration 164800, lr = 0.00176
I0529 08:05:01.578644 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:05:18.644497 11123 solver.cpp:218] Iteration 164900 (3.57001 iter/s, 28.0111s/100 iters), loss = 3.36521e-06
I0529 08:05:18.644546 11123 solver.cpp:237]     Train net output #0: loss = 2.50342e-06 (* 1 = 2.50342e-06 loss)
I0529 08:05:18.644556 11123 sgd_solver.cpp:105] Iteration 164900, lr = 0.001755
I0529 08:05:46.359100 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_165000.caffemodel
I0529 08:05:46.926988 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_165000.solverstate
I0529 08:05:47.073649 11123 solver.cpp:330] Iteration 165000, Testing net (#0)
I0529 08:05:51.493898 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947001
I0529 08:05:51.493935 11123 solver.cpp:397]     Test net output #1: loss = 0.236598 (* 1 = 0.236598 loss)
I0529 08:05:51.770756 11123 solver.cpp:218] Iteration 165000 (3.01883 iter/s, 33.1254s/100 iters), loss = 1.69532e-05
I0529 08:05:51.770814 11123 solver.cpp:237]     Train net output #0: loss = 1.60919e-05 (* 1 = 1.60919e-05 loss)
I0529 08:05:51.770823 11123 sgd_solver.cpp:105] Iteration 165000, lr = 0.00175
I0529 08:06:19.764987 11123 solver.cpp:218] Iteration 165100 (3.57226 iter/s, 27.9935s/100 iters), loss = 1.8833e-05
I0529 08:06:19.765163 11123 solver.cpp:237]     Train net output #0: loss = 1.79716e-05 (* 1 = 1.79716e-05 loss)
I0529 08:06:19.765175 11123 sgd_solver.cpp:105] Iteration 165100, lr = 0.001745
I0529 08:06:47.743177 11123 solver.cpp:218] Iteration 165200 (3.57432 iter/s, 27.9774s/100 iters), loss = 3.47477e-05
I0529 08:06:47.743223 11123 solver.cpp:237]     Train net output #0: loss = 3.38865e-05 (* 1 = 3.38865e-05 loss)
I0529 08:06:47.743232 11123 sgd_solver.cpp:105] Iteration 165200, lr = 0.00174
I0529 08:07:15.756098 11123 solver.cpp:218] Iteration 165300 (3.56987 iter/s, 28.0122s/100 iters), loss = 1.7484e-05
I0529 08:07:15.757124 11123 solver.cpp:237]     Train net output #0: loss = 1.66228e-05 (* 1 = 1.66228e-05 loss)
I0529 08:07:15.757138 11123 sgd_solver.cpp:105] Iteration 165300, lr = 0.001735
I0529 08:07:43.782330 11123 solver.cpp:218] Iteration 165400 (3.5683 iter/s, 28.0245s/100 iters), loss = 4.38392e-06
I0529 08:07:43.782383 11123 solver.cpp:237]     Train net output #0: loss = 3.52271e-06 (* 1 = 3.52271e-06 loss)
I0529 08:07:43.782392 11123 sgd_solver.cpp:105] Iteration 165400, lr = 0.00173
I0529 08:07:58.077199 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:08:11.767695 11123 solver.cpp:218] Iteration 165500 (3.57339 iter/s, 27.9846s/100 iters), loss = 3.78429e-05
I0529 08:08:11.767750 11123 solver.cpp:237]     Train net output #0: loss = 3.69816e-05 (* 1 = 3.69816e-05 loss)
I0529 08:08:11.767757 11123 sgd_solver.cpp:105] Iteration 165500, lr = 0.001725
I0529 08:08:39.728215 11123 solver.cpp:218] Iteration 165600 (3.57656 iter/s, 27.9598s/100 iters), loss = 1.53696e-05
I0529 08:08:39.728385 11123 solver.cpp:237]     Train net output #0: loss = 1.45081e-05 (* 1 = 1.45081e-05 loss)
I0529 08:08:39.728397 11123 sgd_solver.cpp:105] Iteration 165600, lr = 0.00172
I0529 08:09:07.687085 11123 solver.cpp:218] Iteration 165700 (3.57678 iter/s, 27.9581s/100 iters), loss = 2.54234e-06
I0529 08:09:07.687135 11123 solver.cpp:237]     Train net output #0: loss = 1.68086e-06 (* 1 = 1.68086e-06 loss)
I0529 08:09:07.687144 11123 sgd_solver.cpp:105] Iteration 165700, lr = 0.001715
I0529 08:09:35.708175 11123 solver.cpp:218] Iteration 165800 (3.56881 iter/s, 28.0206s/100 iters), loss = 1.16682e-05
I0529 08:09:35.708353 11123 solver.cpp:237]     Train net output #0: loss = 1.08066e-05 (* 1 = 1.08066e-05 loss)
I0529 08:09:35.708364 11123 sgd_solver.cpp:105] Iteration 165800, lr = 0.00171
I0529 08:10:03.730459 11123 solver.cpp:218] Iteration 165900 (3.56867 iter/s, 28.0216s/100 iters), loss = 2.34479e-05
I0529 08:10:03.730507 11123 solver.cpp:237]     Train net output #0: loss = 2.25863e-05 (* 1 = 2.25863e-05 loss)
I0529 08:10:03.730516 11123 sgd_solver.cpp:105] Iteration 165900, lr = 0.001705
I0529 08:10:31.476390 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_166000.caffemodel
I0529 08:10:31.982122 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_166000.solverstate
I0529 08:10:32.130336 11123 solver.cpp:330] Iteration 166000, Testing net (#0)
I0529 08:10:32.135548 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:10:36.579496 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 08:10:36.579542 11123 solver.cpp:397]     Test net output #1: loss = 0.217793 (* 1 = 0.217793 loss)
I0529 08:10:36.857650 11123 solver.cpp:218] Iteration 166000 (3.01872 iter/s, 33.1266s/100 iters), loss = 0.000197117
I0529 08:10:36.857702 11123 solver.cpp:237]     Train net output #0: loss = 0.000196256 (* 1 = 0.000196256 loss)
I0529 08:10:36.857712 11123 sgd_solver.cpp:105] Iteration 166000, lr = 0.0017
I0529 08:10:54.845053 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:11:04.909240 11123 solver.cpp:218] Iteration 166100 (3.56493 iter/s, 28.051s/100 iters), loss = 1.65303e-05
I0529 08:11:04.909409 11123 solver.cpp:237]     Train net output #0: loss = 1.56686e-05 (* 1 = 1.56686e-05 loss)
I0529 08:11:04.909421 11123 sgd_solver.cpp:105] Iteration 166100, lr = 0.001695
I0529 08:11:32.887212 11123 solver.cpp:218] Iteration 166200 (3.57433 iter/s, 27.9773s/100 iters), loss = 6.20238e-06
I0529 08:11:32.887262 11123 solver.cpp:237]     Train net output #0: loss = 5.34065e-06 (* 1 = 5.34065e-06 loss)
I0529 08:11:32.887271 11123 sgd_solver.cpp:105] Iteration 166200, lr = 0.00169
I0529 08:12:00.892047 11123 solver.cpp:218] Iteration 166300 (3.57088 iter/s, 28.0043s/100 iters), loss = 4.72986e-05
I0529 08:12:00.892253 11123 solver.cpp:237]     Train net output #0: loss = 4.6437e-05 (* 1 = 4.6437e-05 loss)
I0529 08:12:00.892264 11123 sgd_solver.cpp:105] Iteration 166300, lr = 0.001685
I0529 08:12:28.914515 11123 solver.cpp:218] Iteration 166400 (3.56866 iter/s, 28.0218s/100 iters), loss = 1.34507e-05
I0529 08:12:28.914564 11123 solver.cpp:237]     Train net output #0: loss = 1.25891e-05 (* 1 = 1.25891e-05 loss)
I0529 08:12:28.914574 11123 sgd_solver.cpp:105] Iteration 166400, lr = 0.00168
I0529 08:12:56.892577 11123 solver.cpp:218] Iteration 166500 (3.5743 iter/s, 27.9775s/100 iters), loss = 3.40677e-06
I0529 08:12:56.892756 11123 solver.cpp:237]     Train net output #0: loss = 2.54513e-06 (* 1 = 2.54513e-06 loss)
I0529 08:12:56.892768 11123 sgd_solver.cpp:105] Iteration 166500, lr = 0.001675
I0529 08:13:24.868837 11123 solver.cpp:218] Iteration 166600 (3.57455 iter/s, 27.9756s/100 iters), loss = 5.1207e-05
I0529 08:13:24.868887 11123 solver.cpp:237]     Train net output #0: loss = 5.03453e-05 (* 1 = 5.03453e-05 loss)
I0529 08:13:24.868896 11123 sgd_solver.cpp:105] Iteration 166600, lr = 0.00167
I0529 08:13:46.447332 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:13:52.868371 11123 solver.cpp:218] Iteration 166700 (3.57156 iter/s, 27.9989s/100 iters), loss = 4.36053e-06
I0529 08:13:52.868424 11123 solver.cpp:237]     Train net output #0: loss = 3.49885e-06 (* 1 = 3.49885e-06 loss)
I0529 08:13:52.868434 11123 sgd_solver.cpp:105] Iteration 166700, lr = 0.001665
I0529 08:14:20.870419 11123 solver.cpp:218] Iteration 166800 (3.57124 iter/s, 28.0015s/100 iters), loss = 2.67324e-05
I0529 08:14:20.870594 11123 solver.cpp:237]     Train net output #0: loss = 2.58706e-05 (* 1 = 2.58706e-05 loss)
I0529 08:14:20.870605 11123 sgd_solver.cpp:105] Iteration 166800, lr = 0.00166
I0529 08:14:48.856089 11123 solver.cpp:218] Iteration 166900 (3.57335 iter/s, 27.985s/100 iters), loss = 0.000100122
I0529 08:14:48.856142 11123 solver.cpp:237]     Train net output #0: loss = 9.926e-05 (* 1 = 9.926e-05 loss)
I0529 08:14:48.856149 11123 sgd_solver.cpp:105] Iteration 166900, lr = 0.001655
I0529 08:15:16.571254 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_167000.caffemodel
I0529 08:15:17.014246 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_167000.solverstate
I0529 08:15:17.161942 11123 solver.cpp:330] Iteration 167000, Testing net (#0)
I0529 08:15:18.682981 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:15:21.615738 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 08:15:21.615797 11123 solver.cpp:397]     Test net output #1: loss = 0.241028 (* 1 = 0.241028 loss)
I0529 08:15:21.891824 11123 solver.cpp:218] Iteration 167000 (3.02709 iter/s, 33.035s/100 iters), loss = 1.24054e-05
I0529 08:15:21.891888 11123 solver.cpp:237]     Train net output #0: loss = 1.15435e-05 (* 1 = 1.15435e-05 loss)
I0529 08:15:21.891897 11123 sgd_solver.cpp:105] Iteration 167000, lr = 0.00165
I0529 08:15:49.878983 11123 solver.cpp:218] Iteration 167100 (3.57315 iter/s, 27.9865s/100 iters), loss = 0.000204047
I0529 08:15:49.879165 11123 solver.cpp:237]     Train net output #0: loss = 0.000203185 (* 1 = 0.000203185 loss)
I0529 08:15:49.879179 11123 sgd_solver.cpp:105] Iteration 167100, lr = 0.001645
I0529 08:16:17.868801 11123 solver.cpp:218] Iteration 167200 (3.57282 iter/s, 27.9891s/100 iters), loss = 3.2941e-05
I0529 08:16:17.868852 11123 solver.cpp:237]     Train net output #0: loss = 3.20789e-05 (* 1 = 3.20789e-05 loss)
I0529 08:16:17.868861 11123 sgd_solver.cpp:105] Iteration 167200, lr = 0.00164
I0529 08:16:43.051251 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:16:45.832702 11123 solver.cpp:218] Iteration 167300 (3.57612 iter/s, 27.9633s/100 iters), loss = 2.05545e-05
I0529 08:16:45.832763 11123 solver.cpp:237]     Train net output #0: loss = 1.96922e-05 (* 1 = 1.96922e-05 loss)
I0529 08:16:45.832773 11123 sgd_solver.cpp:105] Iteration 167300, lr = 0.001635
I0529 08:17:13.833359 11123 solver.cpp:218] Iteration 167400 (3.57142 iter/s, 28s/100 iters), loss = 3.54444e-06
I0529 08:17:13.833519 11123 solver.cpp:237]     Train net output #0: loss = 2.68224e-06 (* 1 = 2.68224e-06 loss)
I0529 08:17:13.833530 11123 sgd_solver.cpp:105] Iteration 167400, lr = 0.00163
I0529 08:17:41.836771 11123 solver.cpp:218] Iteration 167500 (3.57109 iter/s, 28.0027s/100 iters), loss = 9.64228e-06
I0529 08:17:41.836814 11123 solver.cpp:237]     Train net output #0: loss = 8.78008e-06 (* 1 = 8.78008e-06 loss)
I0529 08:17:41.836823 11123 sgd_solver.cpp:105] Iteration 167500, lr = 0.001625
I0529 08:18:09.860471 11123 solver.cpp:218] Iteration 167600 (3.56849 iter/s, 28.0231s/100 iters), loss = 1.4679e-05
I0529 08:18:09.860649 11123 solver.cpp:237]     Train net output #0: loss = 1.38169e-05 (* 1 = 1.38169e-05 loss)
I0529 08:18:09.860666 11123 sgd_solver.cpp:105] Iteration 167600, lr = 0.00162
I0529 08:18:37.889881 11123 solver.cpp:218] Iteration 167700 (3.56778 iter/s, 28.0287s/100 iters), loss = 1.64195e-05
I0529 08:18:37.889930 11123 solver.cpp:237]     Train net output #0: loss = 1.55574e-05 (* 1 = 1.55574e-05 loss)
I0529 08:18:37.889940 11123 sgd_solver.cpp:105] Iteration 167700, lr = 0.001615
I0529 08:19:05.916299 11123 solver.cpp:218] Iteration 167800 (3.56814 iter/s, 28.0258s/100 iters), loss = 1.77703e-05
I0529 08:19:05.916514 11123 solver.cpp:237]     Train net output #0: loss = 1.69081e-05 (* 1 = 1.69081e-05 loss)
I0529 08:19:05.916525 11123 sgd_solver.cpp:105] Iteration 167800, lr = 0.00161
I0529 08:19:33.922091 11123 solver.cpp:218] Iteration 167900 (3.57079 iter/s, 28.005s/100 iters), loss = 6.63796e-06
I0529 08:19:33.922144 11123 solver.cpp:237]     Train net output #0: loss = 5.77576e-06 (* 1 = 5.77576e-06 loss)
I0529 08:19:33.922154 11123 sgd_solver.cpp:105] Iteration 167900, lr = 0.001605
I0529 08:19:34.780930 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:20:01.664400 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_168000.caffemodel
I0529 08:20:02.247891 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_168000.solverstate
I0529 08:20:02.419015 11123 solver.cpp:330] Iteration 168000, Testing net (#0)
I0529 08:20:05.450403 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:20:06.868355 11123 solver.cpp:397]     Test net output #0: accuracy = 0.937001
I0529 08:20:06.868398 11123 solver.cpp:397]     Test net output #1: loss = 0.274817 (* 1 = 0.274817 loss)
I0529 08:20:07.144518 11123 solver.cpp:218] Iteration 168000 (3.01008 iter/s, 33.2217s/100 iters), loss = 3.10926e-06
I0529 08:20:07.144563 11123 solver.cpp:237]     Train net output #0: loss = 2.24711e-06 (* 1 = 2.24711e-06 loss)
I0529 08:20:07.144572 11123 sgd_solver.cpp:105] Iteration 168000, lr = 0.0016
I0529 08:20:35.124971 11123 solver.cpp:218] Iteration 168100 (3.57401 iter/s, 27.9798s/100 iters), loss = 6.56015e-06
I0529 08:20:35.125124 11123 solver.cpp:237]     Train net output #0: loss = 5.69827e-06 (* 1 = 5.69827e-06 loss)
I0529 08:20:35.125136 11123 sgd_solver.cpp:105] Iteration 168100, lr = 0.001595
I0529 08:21:03.117642 11123 solver.cpp:218] Iteration 168200 (3.57246 iter/s, 27.9919s/100 iters), loss = 4.52782e-05
I0529 08:21:03.117686 11123 solver.cpp:237]     Train net output #0: loss = 4.44164e-05 (* 1 = 4.44164e-05 loss)
I0529 08:21:03.117694 11123 sgd_solver.cpp:105] Iteration 168200, lr = 0.00159
I0529 08:21:31.105384 11123 solver.cpp:218] Iteration 168300 (3.57308 iter/s, 27.9871s/100 iters), loss = 2.00272e-05
I0529 08:21:31.105541 11123 solver.cpp:237]     Train net output #0: loss = 1.91654e-05 (* 1 = 1.91654e-05 loss)
I0529 08:21:31.105553 11123 sgd_solver.cpp:105] Iteration 168300, lr = 0.001585
I0529 08:21:59.095600 11123 solver.cpp:218] Iteration 168400 (3.57277 iter/s, 27.9895s/100 iters), loss = 1.26758e-05
I0529 08:21:59.095649 11123 solver.cpp:237]     Train net output #0: loss = 1.1814e-05 (* 1 = 1.1814e-05 loss)
I0529 08:21:59.095656 11123 sgd_solver.cpp:105] Iteration 168400, lr = 0.00158
I0529 08:22:27.107079 11123 solver.cpp:218] Iteration 168500 (3.57005 iter/s, 28.0108s/100 iters), loss = 4.44649e-05
I0529 08:22:27.107286 11123 solver.cpp:237]     Train net output #0: loss = 4.3603e-05 (* 1 = 4.3603e-05 loss)
I0529 08:22:27.107298 11123 sgd_solver.cpp:105] Iteration 168500, lr = 0.001575
I0529 08:22:31.333789 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:22:55.134793 11123 solver.cpp:218] Iteration 168600 (3.568 iter/s, 28.0269s/100 iters), loss = 5.40398e-06
I0529 08:22:55.134840 11123 solver.cpp:237]     Train net output #0: loss = 4.54201e-06 (* 1 = 4.54201e-06 loss)
I0529 08:22:55.134848 11123 sgd_solver.cpp:105] Iteration 168600, lr = 0.00157
I0529 08:23:23.166359 11123 solver.cpp:218] Iteration 168700 (3.56749 iter/s, 28.0309s/100 iters), loss = 7.15628e-06
I0529 08:23:23.166524 11123 solver.cpp:237]     Train net output #0: loss = 6.29446e-06 (* 1 = 6.29446e-06 loss)
I0529 08:23:23.166535 11123 sgd_solver.cpp:105] Iteration 168700, lr = 0.001565
I0529 08:23:51.174443 11123 solver.cpp:218] Iteration 168800 (3.5705 iter/s, 28.0073s/100 iters), loss = 1.59259e-05
I0529 08:23:51.174489 11123 solver.cpp:237]     Train net output #0: loss = 1.50627e-05 (* 1 = 1.50627e-05 loss)
I0529 08:23:51.174499 11123 sgd_solver.cpp:105] Iteration 168800, lr = 0.00156
I0529 08:24:19.191684 11123 solver.cpp:218] Iteration 168900 (3.56931 iter/s, 28.0166s/100 iters), loss = 7.19983e-06
I0529 08:24:19.191838 11123 solver.cpp:237]     Train net output #0: loss = 6.33633e-06 (* 1 = 6.33633e-06 loss)
I0529 08:24:19.191850 11123 sgd_solver.cpp:105] Iteration 168900, lr = 0.001555
I0529 08:24:46.929085 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_169000.caffemodel
I0529 08:24:47.306174 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_169000.solverstate
I0529 08:24:47.452745 11123 solver.cpp:330] Iteration 169000, Testing net (#0)
I0529 08:24:51.902717 11123 solver.cpp:397]     Test net output #0: accuracy = 0.949
I0529 08:24:51.902807 11123 solver.cpp:397]     Test net output #1: loss = 0.239595 (* 1 = 0.239595 loss)
I0529 08:24:52.180004 11123 solver.cpp:218] Iteration 169000 (3.03146 iter/s, 32.9875s/100 iters), loss = 9.76294e-06
I0529 08:24:52.180064 11123 solver.cpp:237]     Train net output #0: loss = 8.89929e-06 (* 1 = 8.89929e-06 loss)
I0529 08:24:52.180073 11123 sgd_solver.cpp:105] Iteration 169000, lr = 0.00155
I0529 08:25:20.203047 11123 solver.cpp:218] Iteration 169100 (3.56858 iter/s, 28.0224s/100 iters), loss = 1.82915e-06
I0529 08:25:20.203090 11123 solver.cpp:237]     Train net output #0: loss = 9.65599e-07 (* 1 = 9.65599e-07 loss)
I0529 08:25:20.203099 11123 sgd_solver.cpp:105] Iteration 169100, lr = 0.001545
I0529 08:25:28.067173 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:48.221524 11123 solver.cpp:218] Iteration 169200 (3.56916 iter/s, 28.0178s/100 iters), loss = 4.30038e-05
I0529 08:25:48.221567 11123 solver.cpp:237]     Train net output #0: loss = 4.21402e-05 (* 1 = 4.21402e-05 loss)
I0529 08:25:48.221575 11123 sgd_solver.cpp:105] Iteration 169200, lr = 0.00154
I0529 08:26:16.244446 11123 solver.cpp:218] Iteration 169300 (3.56859 iter/s, 28.0223s/100 iters), loss = 2.7719e-05
I0529 08:26:16.244602 11123 solver.cpp:237]     Train net output #0: loss = 2.68554e-05 (* 1 = 2.68554e-05 loss)
I0529 08:26:16.244616 11123 sgd_solver.cpp:105] Iteration 169300, lr = 0.001535
I0529 08:26:44.252737 11123 solver.cpp:218] Iteration 169400 (3.57047 iter/s, 28.0075s/100 iters), loss = 2.70539e-06
I0529 08:26:44.252782 11123 solver.cpp:237]     Train net output #0: loss = 1.84179e-06 (* 1 = 1.84179e-06 loss)
I0529 08:26:44.252791 11123 sgd_solver.cpp:105] Iteration 169400, lr = 0.00153
I0529 08:27:12.272500 11123 solver.cpp:218] Iteration 169500 (3.56899 iter/s, 28.0191s/100 iters), loss = 1.36138e-05
I0529 08:27:12.272691 11123 solver.cpp:237]     Train net output #0: loss = 1.27502e-05 (* 1 = 1.27502e-05 loss)
I0529 08:27:12.272702 11123 sgd_solver.cpp:105] Iteration 169500, lr = 0.001525
I0529 08:27:40.285599 11123 solver.cpp:218] Iteration 169600 (3.56986 iter/s, 28.0123s/100 iters), loss = 1.51458e-05
I0529 08:27:40.285645 11123 solver.cpp:237]     Train net output #0: loss = 1.42822e-05 (* 1 = 1.42822e-05 loss)
I0529 08:27:40.285652 11123 sgd_solver.cpp:105] Iteration 169600, lr = 0.00152
I0529 08:28:08.292227 11123 solver.cpp:218] Iteration 169700 (3.57067 iter/s, 28.006s/100 iters), loss = 2.92386e-05
I0529 08:28:08.292440 11123 solver.cpp:237]     Train net output #0: loss = 2.83751e-05 (* 1 = 2.83751e-05 loss)
I0529 08:28:08.292453 11123 sgd_solver.cpp:105] Iteration 169700, lr = 0.001515
I0529 08:28:19.778882 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:28:36.263217 11123 solver.cpp:218] Iteration 169800 (3.57524 iter/s, 27.9702s/100 iters), loss = 9.52984e-07
I0529 08:28:36.263262 11123 solver.cpp:237]     Train net output #0: loss = 8.9407e-08 (* 1 = 8.9407e-08 loss)
I0529 08:28:36.263281 11123 sgd_solver.cpp:105] Iteration 169800, lr = 0.00151
I0529 08:29:04.242525 11123 solver.cpp:218] Iteration 169900 (3.57416 iter/s, 27.9786s/100 iters), loss = 4.29753e-05
I0529 08:29:04.242780 11123 solver.cpp:237]     Train net output #0: loss = 4.21117e-05 (* 1 = 4.21117e-05 loss)
I0529 08:29:04.242796 11123 sgd_solver.cpp:105] Iteration 169900, lr = 0.001505
I0529 08:29:31.951942 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_170000.caffemodel
I0529 08:29:32.404816 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_170000.solverstate
I0529 08:29:32.551800 11123 solver.cpp:330] Iteration 170000, Testing net (#0)
I0529 08:29:32.646780 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:29:37.005475 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948
I0529 08:29:37.005627 11123 solver.cpp:397]     Test net output #1: loss = 0.218048 (* 1 = 0.218048 loss)
I0529 08:29:37.282284 11123 solver.cpp:218] Iteration 170000 (3.02675 iter/s, 33.0388s/100 iters), loss = 1.87137e-05
I0529 08:29:37.282326 11123 solver.cpp:237]     Train net output #0: loss = 1.78497e-05 (* 1 = 1.78497e-05 loss)
I0529 08:29:37.282335 11123 sgd_solver.cpp:105] Iteration 170000, lr = 0.0015
I0529 08:30:05.290824 11123 solver.cpp:218] Iteration 170100 (3.57043 iter/s, 28.0079s/100 iters), loss = 0.000206015
I0529 08:30:05.290868 11123 solver.cpp:237]     Train net output #0: loss = 0.000205151 (* 1 = 0.000205151 loss)
I0529 08:30:05.290877 11123 sgd_solver.cpp:105] Iteration 170100, lr = 0.001495
I0529 08:30:33.311318 11123 solver.cpp:218] Iteration 170200 (3.5689 iter/s, 28.0198s/100 iters), loss = 1.92391e-05
I0529 08:30:33.311475 11123 solver.cpp:237]     Train net output #0: loss = 1.8375e-05 (* 1 = 1.8375e-05 loss)
I0529 08:30:33.311487 11123 sgd_solver.cpp:105] Iteration 170200, lr = 0.00149
I0529 08:31:01.295305 11123 solver.cpp:218] Iteration 170300 (3.57357 iter/s, 27.9832s/100 iters), loss = 0.000204518
I0529 08:31:01.295361 11123 solver.cpp:237]     Train net output #0: loss = 0.000203654 (* 1 = 0.000203654 loss)
I0529 08:31:01.295370 11123 sgd_solver.cpp:105] Iteration 170300, lr = 0.001485
I0529 08:31:16.446275 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:31:29.319898 11123 solver.cpp:218] Iteration 170400 (3.56838 iter/s, 28.0239s/100 iters), loss = 2.86316e-05
I0529 08:31:29.319943 11123 solver.cpp:237]     Train net output #0: loss = 2.77675e-05 (* 1 = 2.77675e-05 loss)
I0529 08:31:29.319952 11123 sgd_solver.cpp:105] Iteration 170400, lr = 0.00148
I0529 08:31:57.301220 11123 solver.cpp:218] Iteration 170500 (3.5739 iter/s, 27.9806s/100 iters), loss = 9.44086e-05
I0529 08:31:57.301389 11123 solver.cpp:237]     Train net output #0: loss = 9.35445e-05 (* 1 = 9.35445e-05 loss)
I0529 08:31:57.301401 11123 sgd_solver.cpp:105] Iteration 170500, lr = 0.001475
I0529 08:32:25.292043 11123 solver.cpp:218] Iteration 170600 (3.5727 iter/s, 27.99s/100 iters), loss = 1.87745e-06
I0529 08:32:25.292086 11123 solver.cpp:237]     Train net output #0: loss = 1.01329e-06 (* 1 = 1.01329e-06 loss)
I0529 08:32:25.292095 11123 sgd_solver.cpp:105] Iteration 170600, lr = 0.00147
I0529 08:32:53.302400 11123 solver.cpp:218] Iteration 170700 (3.57019 iter/s, 28.0097s/100 iters), loss = 2.77755e-06
I0529 08:32:53.302592 11123 solver.cpp:237]     Train net output #0: loss = 1.91332e-06 (* 1 = 1.91332e-06 loss)
I0529 08:32:53.302604 11123 sgd_solver.cpp:105] Iteration 170700, lr = 0.001465
I0529 08:33:21.308997 11123 solver.cpp:218] Iteration 170800 (3.57069 iter/s, 28.0058s/100 iters), loss = 5.77582e-06
I0529 08:33:21.309043 11123 solver.cpp:237]     Train net output #0: loss = 4.91148e-06 (* 1 = 4.91148e-06 loss)
I0529 08:33:21.309051 11123 sgd_solver.cpp:105] Iteration 170800, lr = 0.00146
I0529 08:33:49.308845 11123 solver.cpp:218] Iteration 170900 (3.57153 iter/s, 27.9992s/100 iters), loss = 2.26838e-05
I0529 08:33:49.308985 11123 solver.cpp:237]     Train net output #0: loss = 2.18196e-05 (* 1 = 2.18196e-05 loss)
I0529 08:33:49.308995 11123 sgd_solver.cpp:105] Iteration 170900, lr = 0.001455
I0529 08:34:08.108870 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:34:17.057617 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_171000.caffemodel
I0529 08:34:17.521013 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_171000.solverstate
I0529 08:34:17.667165 11123 solver.cpp:330] Iteration 171000, Testing net (#0)
I0529 08:34:19.272133 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:34:22.114590 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 08:34:22.114723 11123 solver.cpp:397]     Test net output #1: loss = 0.238017 (* 1 = 0.238017 loss)
I0529 08:34:22.390627 11123 solver.cpp:218] Iteration 171000 (3.02289 iter/s, 33.0809s/100 iters), loss = 0.000281947
I0529 08:34:22.390686 11123 solver.cpp:237]     Train net output #0: loss = 0.000281083 (* 1 = 0.000281083 loss)
I0529 08:34:22.390693 11123 sgd_solver.cpp:105] Iteration 171000, lr = 0.00145
I0529 08:34:50.390159 11123 solver.cpp:218] Iteration 171100 (3.57158 iter/s, 27.9988s/100 iters), loss = 9.58199e-05
I0529 08:34:50.390203 11123 solver.cpp:237]     Train net output #0: loss = 9.49556e-05 (* 1 = 9.49556e-05 loss)
I0529 08:34:50.390213 11123 sgd_solver.cpp:105] Iteration 171100, lr = 0.001445
I0529 08:35:18.391360 11123 solver.cpp:218] Iteration 171200 (3.57136 iter/s, 28.0005s/100 iters), loss = 0.000124629
I0529 08:35:18.391518 11123 solver.cpp:237]     Train net output #0: loss = 0.000123764 (* 1 = 0.000123764 loss)
I0529 08:35:18.391530 11123 sgd_solver.cpp:105] Iteration 171200, lr = 0.00144
I0529 08:35:46.401468 11123 solver.cpp:218] Iteration 171300 (3.57024 iter/s, 28.0093s/100 iters), loss = 6.31348e-05
I0529 08:35:46.401527 11123 solver.cpp:237]     Train net output #0: loss = 6.22705e-05 (* 1 = 6.22705e-05 loss)
I0529 08:35:46.401536 11123 sgd_solver.cpp:105] Iteration 171300, lr = 0.001435
I0529 08:36:14.415848 11123 solver.cpp:218] Iteration 171400 (3.56968 iter/s, 28.0137s/100 iters), loss = 1.90902e-05
I0529 08:36:14.416009 11123 solver.cpp:237]     Train net output #0: loss = 1.8226e-05 (* 1 = 1.8226e-05 loss)
I0529 08:36:14.416021 11123 sgd_solver.cpp:105] Iteration 171400, lr = 0.00143
I0529 08:36:42.404014 11123 solver.cpp:218] Iteration 171500 (3.57304 iter/s, 27.9874s/100 iters), loss = 1.05922e-05
I0529 08:36:42.404062 11123 solver.cpp:237]     Train net output #0: loss = 9.72787e-06 (* 1 = 9.72787e-06 loss)
I0529 08:36:42.404072 11123 sgd_solver.cpp:105] Iteration 171500, lr = 0.001425
I0529 08:37:04.554921 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:37:10.418509 11123 solver.cpp:218] Iteration 171600 (3.56967 iter/s, 28.0138s/100 iters), loss = 6.59454e-05
I0529 08:37:10.418552 11123 solver.cpp:237]     Train net output #0: loss = 6.50811e-05 (* 1 = 6.50811e-05 loss)
I0529 08:37:10.418561 11123 sgd_solver.cpp:105] Iteration 171600, lr = 0.00142
I0529 08:37:38.420179 11123 solver.cpp:218] Iteration 171700 (3.5713 iter/s, 28.001s/100 iters), loss = 1.76481e-05
I0529 08:37:38.420368 11123 solver.cpp:237]     Train net output #0: loss = 1.67837e-05 (* 1 = 1.67837e-05 loss)
I0529 08:37:38.420379 11123 sgd_solver.cpp:105] Iteration 171700, lr = 0.001415
I0529 08:38:06.428941 11123 solver.cpp:218] Iteration 171800 (3.57042 iter/s, 28.0079s/100 iters), loss = 1.1224e-05
I0529 08:38:06.428990 11123 solver.cpp:237]     Train net output #0: loss = 1.03596e-05 (* 1 = 1.03596e-05 loss)
I0529 08:38:06.429003 11123 sgd_solver.cpp:105] Iteration 171800, lr = 0.00141
I0529 08:38:34.425118 11123 solver.cpp:218] Iteration 171900 (3.572 iter/s, 27.9955s/100 iters), loss = 1.29858e-05
I0529 08:38:34.425299 11123 solver.cpp:237]     Train net output #0: loss = 1.21214e-05 (* 1 = 1.21214e-05 loss)
I0529 08:38:34.425310 11123 sgd_solver.cpp:105] Iteration 171900, lr = 0.001405
I0529 08:39:02.139475 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_172000.caffemodel
I0529 08:39:02.574676 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_172000.solverstate
I0529 08:39:02.720870 11123 solver.cpp:330] Iteration 172000, Testing net (#0)
I0529 08:39:05.843729 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:39:07.176033 11123 solver.cpp:397]     Test net output #0: accuracy = 0.939
I0529 08:39:07.176066 11123 solver.cpp:397]     Test net output #1: loss = 0.273673 (* 1 = 0.273673 loss)
I0529 08:39:07.453377 11123 solver.cpp:218] Iteration 172000 (3.0278 iter/s, 33.0273s/100 iters), loss = 0.000919882
I0529 08:39:07.453423 11123 solver.cpp:237]     Train net output #0: loss = 0.000919018 (* 1 = 0.000919018 loss)
I0529 08:39:07.453430 11123 sgd_solver.cpp:105] Iteration 172000, lr = 0.0014
I0529 08:39:35.470944 11123 solver.cpp:218] Iteration 172100 (3.56928 iter/s, 28.0169s/100 iters), loss = 6.19353e-05
I0529 08:39:35.470989 11123 solver.cpp:237]     Train net output #0: loss = 6.1071e-05 (* 1 = 6.1071e-05 loss)
I0529 08:39:35.470998 11123 sgd_solver.cpp:105] Iteration 172100, lr = 0.001395
I0529 08:40:01.261040 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:40:03.487378 11123 solver.cpp:218] Iteration 172200 (3.56942 iter/s, 28.0158s/100 iters), loss = 0.0012566
I0529 08:40:03.487421 11123 solver.cpp:237]     Train net output #0: loss = 0.00125574 (* 1 = 0.00125574 loss)
I0529 08:40:03.487429 11123 sgd_solver.cpp:105] Iteration 172200, lr = 0.00139
I0529 08:40:31.499338 11123 solver.cpp:218] Iteration 172300 (3.56999 iter/s, 28.0113s/100 iters), loss = 4.19855e-05
I0529 08:40:31.499490 11123 solver.cpp:237]     Train net output #0: loss = 4.11211e-05 (* 1 = 4.11211e-05 loss)
I0529 08:40:31.499501 11123 sgd_solver.cpp:105] Iteration 172300, lr = 0.001385
I0529 08:40:59.500452 11123 solver.cpp:218] Iteration 172400 (3.57139 iter/s, 28.0003s/100 iters), loss = 5.04198e-05
I0529 08:40:59.500500 11123 solver.cpp:237]     Train net output #0: loss = 4.95554e-05 (* 1 = 4.95554e-05 loss)
I0529 08:40:59.500511 11123 sgd_solver.cpp:105] Iteration 172400, lr = 0.00138
I0529 08:41:27.513880 11123 solver.cpp:218] Iteration 172500 (3.5698 iter/s, 28.0127s/100 iters), loss = 4.54798e-06
I0529 08:41:27.514094 11123 solver.cpp:237]     Train net output #0: loss = 3.6836e-06 (* 1 = 3.6836e-06 loss)
I0529 08:41:27.514106 11123 sgd_solver.cpp:105] Iteration 172500, lr = 0.001375
I0529 08:41:55.524497 11123 solver.cpp:218] Iteration 172600 (3.57018 iter/s, 28.0098s/100 iters), loss = 2.45801e-05
I0529 08:41:55.524554 11123 solver.cpp:237]     Train net output #0: loss = 2.37158e-05 (* 1 = 2.37158e-05 loss)
I0529 08:41:55.524564 11123 sgd_solver.cpp:105] Iteration 172600, lr = 0.00137
I0529 08:42:23.517736 11123 solver.cpp:218] Iteration 172700 (3.57238 iter/s, 27.9925s/100 iters), loss = 2.02087e-05
I0529 08:42:23.517910 11123 solver.cpp:237]     Train net output #0: loss = 1.93444e-05 (* 1 = 1.93444e-05 loss)
I0529 08:42:23.517921 11123 sgd_solver.cpp:105] Iteration 172700, lr = 0.001365
I0529 08:42:51.522544 11123 solver.cpp:218] Iteration 172800 (3.57092 iter/s, 28.004s/100 iters), loss = 2.74192e-06
I0529 08:42:51.522590 11123 solver.cpp:237]     Train net output #0: loss = 1.87757e-06 (* 1 = 1.87757e-06 loss)
I0529 08:42:51.522599 11123 sgd_solver.cpp:105] Iteration 172800, lr = 0.00136
I0529 08:42:52.943467 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:43:19.557992 11123 solver.cpp:218] Iteration 172900 (3.56693 iter/s, 28.0353s/100 iters), loss = 1.18682e-05
I0529 08:43:19.558166 11123 solver.cpp:237]     Train net output #0: loss = 1.10037e-05 (* 1 = 1.10037e-05 loss)
I0529 08:43:19.558178 11123 sgd_solver.cpp:105] Iteration 172900, lr = 0.001355
I0529 08:43:47.306530 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_173000.caffemodel
I0529 08:43:47.734514 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_173000.solverstate
I0529 08:43:47.880467 11123 solver.cpp:330] Iteration 173000, Testing net (#0)
I0529 08:43:52.331920 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948001
I0529 08:43:52.332065 11123 solver.cpp:397]     Test net output #1: loss = 0.236273 (* 1 = 0.236273 loss)
I0529 08:43:52.608546 11123 solver.cpp:218] Iteration 173000 (3.02563 iter/s, 33.051s/100 iters), loss = 5.14425e-06
I0529 08:43:52.608590 11123 solver.cpp:237]     Train net output #0: loss = 4.27974e-06 (* 1 = 4.27974e-06 loss)
I0529 08:43:52.608599 11123 sgd_solver.cpp:105] Iteration 173000, lr = 0.00135
I0529 08:44:20.598552 11123 solver.cpp:218] Iteration 173100 (3.57265 iter/s, 27.9904s/100 iters), loss = 1.27323e-05
I0529 08:44:20.598606 11123 solver.cpp:237]     Train net output #0: loss = 1.18678e-05 (* 1 = 1.18678e-05 loss)
I0529 08:44:20.598615 11123 sgd_solver.cpp:105] Iteration 173100, lr = 0.001345
I0529 08:44:48.587119 11123 solver.cpp:218] Iteration 173200 (3.57284 iter/s, 27.9889s/100 iters), loss = 1.17668e-05
I0529 08:44:48.587330 11123 solver.cpp:237]     Train net output #0: loss = 1.09022e-05 (* 1 = 1.09022e-05 loss)
I0529 08:44:48.587342 11123 sgd_solver.cpp:105] Iteration 173200, lr = 0.00134
I0529 08:45:16.581662 11123 solver.cpp:218] Iteration 173300 (3.57211 iter/s, 27.9947s/100 iters), loss = 1.37726e-05
I0529 08:45:16.581708 11123 solver.cpp:237]     Train net output #0: loss = 1.29084e-05 (* 1 = 1.29084e-05 loss)
I0529 08:45:16.581717 11123 sgd_solver.cpp:105] Iteration 173300, lr = 0.001335
I0529 08:45:44.562961 11123 solver.cpp:218] Iteration 173400 (3.57378 iter/s, 27.9816s/100 iters), loss = 3.28551e-05
I0529 08:45:44.563117 11123 solver.cpp:237]     Train net output #0: loss = 3.1991e-05 (* 1 = 3.1991e-05 loss)
I0529 08:45:44.563129 11123 sgd_solver.cpp:105] Iteration 173400, lr = 0.00133
I0529 08:45:49.613653 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:46:12.538323 11123 solver.cpp:218] Iteration 173500 (3.57456 iter/s, 27.9755s/100 iters), loss = 0.00045521
I0529 08:46:12.538373 11123 solver.cpp:237]     Train net output #0: loss = 0.000454346 (* 1 = 0.000454346 loss)
I0529 08:46:12.538388 11123 sgd_solver.cpp:105] Iteration 173500, lr = 0.001325
I0529 08:46:40.518905 11123 solver.cpp:218] Iteration 173600 (3.57388 iter/s, 27.9808s/100 iters), loss = 1.81129e-05
I0529 08:46:40.519111 11123 solver.cpp:237]     Train net output #0: loss = 1.72488e-05 (* 1 = 1.72488e-05 loss)
I0529 08:46:40.519127 11123 sgd_solver.cpp:105] Iteration 173600, lr = 0.00132
I0529 08:47:08.532109 11123 solver.cpp:218] Iteration 173700 (3.56974 iter/s, 28.0132s/100 iters), loss = 6.12127e-06
I0529 08:47:08.532155 11123 solver.cpp:237]     Train net output #0: loss = 5.25721e-06 (* 1 = 5.25721e-06 loss)
I0529 08:47:08.532163 11123 sgd_solver.cpp:105] Iteration 173700, lr = 0.001315
I0529 08:47:36.555985 11123 solver.cpp:218] Iteration 173800 (3.56837 iter/s, 28.024s/100 iters), loss = 8.9864e-05
I0529 08:47:36.556187 11123 solver.cpp:237]     Train net output #0: loss = 8.89999e-05 (* 1 = 8.89999e-05 loss)
I0529 08:47:36.556200 11123 sgd_solver.cpp:105] Iteration 173800, lr = 0.00131
I0529 08:48:04.564584 11123 solver.cpp:218] Iteration 173900 (3.57034 iter/s, 28.0085s/100 iters), loss = 6.72938e-06
I0529 08:48:04.564633 11123 solver.cpp:237]     Train net output #0: loss = 5.86529e-06 (* 1 = 5.86529e-06 loss)
I0529 08:48:04.564656 11123 sgd_solver.cpp:105] Iteration 173900, lr = 0.001305
I0529 08:48:32.269804 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_174000.caffemodel
I0529 08:48:32.795639 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_174000.solverstate
I0529 08:48:32.942136 11123 solver.cpp:330] Iteration 174000, Testing net (#0)
I0529 08:48:33.084640 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:48:37.396590 11123 solver.cpp:397]     Test net output #0: accuracy = 0.949
I0529 08:48:37.396637 11123 solver.cpp:397]     Test net output #1: loss = 0.217386 (* 1 = 0.217386 loss)
I0529 08:48:37.671628 11123 solver.cpp:218] Iteration 174000 (3.0205 iter/s, 33.1071s/100 iters), loss = 9.14894e-06
I0529 08:48:37.671674 11123 solver.cpp:237]     Train net output #0: loss = 8.28528e-06 (* 1 = 8.28528e-06 loss)
I0529 08:48:37.671684 11123 sgd_solver.cpp:105] Iteration 174000, lr = 0.0013
I0529 08:48:46.366215 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:49:05.693531 11123 solver.cpp:218] Iteration 174100 (3.56864 iter/s, 28.0219s/100 iters), loss = 0.000245724
I0529 08:49:05.693657 11123 solver.cpp:237]     Train net output #0: loss = 0.00024486 (* 1 = 0.00024486 loss)
I0529 08:49:05.693683 11123 sgd_solver.cpp:105] Iteration 174100, lr = 0.001295
I0529 08:49:33.723441 11123 solver.cpp:218] Iteration 174200 (3.56763 iter/s, 28.0298s/100 iters), loss = 1.02696e-05
I0529 08:49:33.723500 11123 solver.cpp:237]     Train net output #0: loss = 9.40599e-06 (* 1 = 9.40599e-06 loss)
I0529 08:49:33.723510 11123 sgd_solver.cpp:105] Iteration 174200, lr = 0.00129
I0529 08:50:01.693475 11123 solver.cpp:218] Iteration 174300 (3.57527 iter/s, 27.9699s/100 iters), loss = 1.94433e-05
I0529 08:50:01.693634 11123 solver.cpp:237]     Train net output #0: loss = 1.85797e-05 (* 1 = 1.85797e-05 loss)
I0529 08:50:01.693661 11123 sgd_solver.cpp:105] Iteration 174300, lr = 0.001285
I0529 08:50:29.659917 11123 solver.cpp:218] Iteration 174400 (3.57574 iter/s, 27.9663s/100 iters), loss = 2.19286e-06
I0529 08:50:29.659963 11123 solver.cpp:237]     Train net output #0: loss = 1.32919e-06 (* 1 = 1.32919e-06 loss)
I0529 08:50:29.659972 11123 sgd_solver.cpp:105] Iteration 174400, lr = 0.00128
I0529 08:50:57.658754 11123 solver.cpp:218] Iteration 174500 (3.57159 iter/s, 27.9987s/100 iters), loss = 4.87318e-05
I0529 08:50:57.658949 11123 solver.cpp:237]     Train net output #0: loss = 4.78682e-05 (* 1 = 4.78682e-05 loss)
I0529 08:50:57.658963 11123 sgd_solver.cpp:105] Iteration 174500, lr = 0.001275
I0529 08:51:25.708232 11123 solver.cpp:218] Iteration 174600 (3.56516 iter/s, 28.0492s/100 iters), loss = 1.96038e-06
I0529 08:51:25.708276 11123 solver.cpp:237]     Train net output #0: loss = 1.09673e-06 (* 1 = 1.09673e-06 loss)
I0529 08:51:25.708286 11123 sgd_solver.cpp:105] Iteration 174600, lr = 0.00127
I0529 08:51:37.788470 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:51:53.734509 11123 solver.cpp:218] Iteration 174700 (3.5681 iter/s, 28.0261s/100 iters), loss = 3.50417e-06
I0529 08:51:53.734555 11123 solver.cpp:237]     Train net output #0: loss = 2.64051e-06 (* 1 = 2.64051e-06 loss)
I0529 08:51:53.734563 11123 sgd_solver.cpp:105] Iteration 174700, lr = 0.001265
I0529 08:52:21.762974 11123 solver.cpp:218] Iteration 174800 (3.56782 iter/s, 28.0283s/100 iters), loss = 2.67297e-05
I0529 08:52:21.763136 11123 solver.cpp:237]     Train net output #0: loss = 2.58661e-05 (* 1 = 2.58661e-05 loss)
I0529 08:52:21.763149 11123 sgd_solver.cpp:105] Iteration 174800, lr = 0.00126
I0529 08:52:49.773932 11123 solver.cpp:218] Iteration 174900 (3.57007 iter/s, 28.0106s/100 iters), loss = 5.224e-05
I0529 08:52:49.773975 11123 solver.cpp:237]     Train net output #0: loss = 5.13767e-05 (* 1 = 5.13767e-05 loss)
I0529 08:52:49.773983 11123 sgd_solver.cpp:105] Iteration 174900, lr = 0.001255
I0529 08:53:17.515424 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_175000.caffemodel
I0529 08:53:18.018663 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_175000.solverstate
I0529 08:53:18.165004 11123 solver.cpp:330] Iteration 175000, Testing net (#0)
I0529 08:53:19.820402 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:53:22.622375 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 08:53:22.622412 11123 solver.cpp:397]     Test net output #1: loss = 0.237697 (* 1 = 0.237697 loss)
I0529 08:53:22.899852 11123 solver.cpp:218] Iteration 175000 (3.01881 iter/s, 33.1257s/100 iters), loss = 7.20286e-05
I0529 08:53:22.899899 11123 solver.cpp:237]     Train net output #0: loss = 7.11653e-05 (* 1 = 7.11653e-05 loss)
I0529 08:53:22.899909 11123 sgd_solver.cpp:105] Iteration 175000, lr = 0.00125
I0529 08:53:50.887717 11123 solver.cpp:218] Iteration 175100 (3.57301 iter/s, 27.9876s/100 iters), loss = 4.14532e-05
I0529 08:53:50.887889 11123 solver.cpp:237]     Train net output #0: loss = 4.059e-05 (* 1 = 4.059e-05 loss)
I0529 08:53:50.887902 11123 sgd_solver.cpp:105] Iteration 175100, lr = 0.001245
I0529 08:54:18.900950 11123 solver.cpp:218] Iteration 175200 (3.56979 iter/s, 28.0129s/100 iters), loss = 7.55868e-05
I0529 08:54:18.900993 11123 solver.cpp:237]     Train net output #0: loss = 7.47233e-05 (* 1 = 7.47233e-05 loss)
I0529 08:54:18.901002 11123 sgd_solver.cpp:105] Iteration 175200, lr = 0.00124
I0529 08:54:34.607151 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:54:46.912714 11123 solver.cpp:218] Iteration 175300 (3.56996 iter/s, 28.0115s/100 iters), loss = 1.15391e-05
I0529 08:54:46.912756 11123 solver.cpp:237]     Train net output #0: loss = 1.06757e-05 (* 1 = 1.06757e-05 loss)
I0529 08:54:46.912765 11123 sgd_solver.cpp:105] Iteration 175300, lr = 0.001235
I0529 08:55:14.949625 11123 solver.cpp:218] Iteration 175400 (3.56676 iter/s, 28.0366s/100 iters), loss = 3.45057e-06
I0529 08:55:14.949810 11123 solver.cpp:237]     Train net output #0: loss = 2.58688e-06 (* 1 = 2.58688e-06 loss)
I0529 08:55:14.949832 11123 sgd_solver.cpp:105] Iteration 175400, lr = 0.00123
I0529 08:55:42.956845 11123 solver.cpp:218] Iteration 175500 (3.57056 iter/s, 28.0068s/100 iters), loss = 1.46273e-05
I0529 08:55:42.956903 11123 solver.cpp:237]     Train net output #0: loss = 1.37634e-05 (* 1 = 1.37634e-05 loss)
I0529 08:55:42.956912 11123 sgd_solver.cpp:105] Iteration 175500, lr = 0.001225
I0529 08:56:10.974267 11123 solver.cpp:218] Iteration 175600 (3.56925 iter/s, 28.0171s/100 iters), loss = 1.69879e-05
I0529 08:56:10.974479 11123 solver.cpp:237]     Train net output #0: loss = 1.61239e-05 (* 1 = 1.61239e-05 loss)
I0529 08:56:10.974496 11123 sgd_solver.cpp:105] Iteration 175600, lr = 0.00122
I0529 08:56:38.991144 11123 solver.cpp:218] Iteration 175700 (3.56934 iter/s, 28.0164s/100 iters), loss = 3.02491e-05
I0529 08:56:38.991195 11123 solver.cpp:237]     Train net output #0: loss = 2.93852e-05 (* 1 = 2.93852e-05 loss)
I0529 08:56:38.991209 11123 sgd_solver.cpp:105] Iteration 175700, lr = 0.001215
I0529 08:57:06.993654 11123 solver.cpp:218] Iteration 175800 (3.57115 iter/s, 28.0022s/100 iters), loss = 6.57438e-06
I0529 08:57:06.993813 11123 solver.cpp:237]     Train net output #0: loss = 5.71027e-06 (* 1 = 5.71027e-06 loss)
I0529 08:57:06.993829 11123 sgd_solver.cpp:105] Iteration 175800, lr = 0.00121
I0529 08:57:26.340178 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:57:35.006466 11123 solver.cpp:218] Iteration 175900 (3.56985 iter/s, 28.0124s/100 iters), loss = 2.86064e-05
I0529 08:57:35.006516 11123 solver.cpp:237]     Train net output #0: loss = 2.77423e-05 (* 1 = 2.77423e-05 loss)
I0529 08:57:35.006530 11123 sgd_solver.cpp:105] Iteration 175900, lr = 0.001205
I0529 08:58:02.740126 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_176000.caffemodel
I0529 08:58:03.212077 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_176000.solverstate
I0529 08:58:03.357771 11123 solver.cpp:330] Iteration 176000, Testing net (#0)
I0529 08:58:06.520403 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:58:07.806788 11123 solver.cpp:397]     Test net output #0: accuracy = 0.941
I0529 08:58:07.806831 11123 solver.cpp:397]     Test net output #1: loss = 0.268688 (* 1 = 0.268688 loss)
I0529 08:58:08.083478 11123 solver.cpp:218] Iteration 176000 (3.02329 iter/s, 33.0766s/100 iters), loss = 0.00135281
I0529 08:58:08.083528 11123 solver.cpp:237]     Train net output #0: loss = 0.00135195 (* 1 = 0.00135195 loss)
I0529 08:58:08.083541 11123 sgd_solver.cpp:105] Iteration 176000, lr = 0.0012
I0529 08:58:36.094988 11123 solver.cpp:218] Iteration 176100 (3.57001 iter/s, 28.0111s/100 iters), loss = 0.000206803
I0529 08:58:36.095209 11123 solver.cpp:237]     Train net output #0: loss = 0.000205939 (* 1 = 0.000205939 loss)
I0529 08:58:36.095237 11123 sgd_solver.cpp:105] Iteration 176100, lr = 0.001195
I0529 08:59:04.088366 11123 solver.cpp:218] Iteration 176200 (3.57234 iter/s, 27.9928s/100 iters), loss = 1.57358e-06
I0529 08:59:04.088412 11123 solver.cpp:237]     Train net output #0: loss = 7.09296e-07 (* 1 = 7.09296e-07 loss)
I0529 08:59:04.088420 11123 sgd_solver.cpp:105] Iteration 176200, lr = 0.00119
I0529 08:59:32.106384 11123 solver.cpp:218] Iteration 176300 (3.56918 iter/s, 28.0176s/100 iters), loss = 4.15181e-05
I0529 08:59:32.106595 11123 solver.cpp:237]     Train net output #0: loss = 4.06538e-05 (* 1 = 4.06538e-05 loss)
I0529 08:59:32.106611 11123 sgd_solver.cpp:105] Iteration 176300, lr = 0.001185
I0529 09:00:00.077880 11123 solver.cpp:218] Iteration 176400 (3.57514 iter/s, 27.971s/100 iters), loss = 2.33042e-05
I0529 09:00:00.077926 11123 solver.cpp:237]     Train net output #0: loss = 2.24399e-05 (* 1 = 2.24399e-05 loss)
I0529 09:00:00.077934 11123 sgd_solver.cpp:105] Iteration 176400, lr = 0.00118
I0529 09:00:23.190914 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:00:28.248541 11123 solver.cpp:218] Iteration 176500 (3.54984 iter/s, 28.1702s/100 iters), loss = 6.59239e-06
I0529 09:00:28.248600 11123 solver.cpp:237]     Train net output #0: loss = 5.72812e-06 (* 1 = 5.72812e-06 loss)
I0529 09:00:28.248608 11123 sgd_solver.cpp:105] Iteration 176500, lr = 0.001175
I0529 09:00:56.903414 11123 solver.cpp:218] Iteration 176600 (3.48986 iter/s, 28.6544s/100 iters), loss = 5.48795e-05
I0529 09:00:56.903559 11123 solver.cpp:237]     Train net output #0: loss = 5.40151e-05 (* 1 = 5.40151e-05 loss)
I0529 09:00:56.903574 11123 sgd_solver.cpp:105] Iteration 176600, lr = 0.00117
I0529 09:01:25.764353 11123 solver.cpp:218] Iteration 176700 (3.46495 iter/s, 28.8604s/100 iters), loss = 3.22779e-05
I0529 09:01:25.764397 11123 solver.cpp:237]     Train net output #0: loss = 3.14133e-05 (* 1 = 3.14133e-05 loss)
I0529 09:01:25.764406 11123 sgd_solver.cpp:105] Iteration 176700, lr = 0.001165
I0529 09:01:53.998544 11123 solver.cpp:218] Iteration 176800 (3.54186 iter/s, 28.2337s/100 iters), loss = 5.88342e-06
I0529 09:01:53.998704 11123 solver.cpp:237]     Train net output #0: loss = 5.01883e-06 (* 1 = 5.01883e-06 loss)
I0529 09:01:53.998716 11123 sgd_solver.cpp:105] Iteration 176800, lr = 0.00116
I0529 09:02:23.680078 11123 solver.cpp:218] Iteration 176900 (3.36916 iter/s, 29.681s/100 iters), loss = 2.00147e-05
I0529 09:02:23.680132 11123 solver.cpp:237]     Train net output #0: loss = 1.91501e-05 (* 1 = 1.91501e-05 loss)
I0529 09:02:23.680141 11123 sgd_solver.cpp:105] Iteration 176900, lr = 0.001155
I0529 09:02:51.975162 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_177000.caffemodel
I0529 09:02:52.433580 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_177000.solverstate
I0529 09:02:52.579926 11123 solver.cpp:330] Iteration 177000, Testing net (#0)
I0529 09:02:57.116133 11123 solver.cpp:397]     Test net output #0: accuracy = 0.948
I0529 09:02:57.116170 11123 solver.cpp:397]     Test net output #1: loss = 0.216949 (* 1 = 0.216949 loss)
I0529 09:02:57.394450 11123 solver.cpp:218] Iteration 177000 (2.96614 iter/s, 33.7138s/100 iters), loss = 2.15008e-05
I0529 09:02:57.394503 11123 solver.cpp:237]     Train net output #0: loss = 2.06361e-05 (* 1 = 2.06361e-05 loss)
I0529 09:02:57.394512 11123 sgd_solver.cpp:105] Iteration 177000, lr = 0.00115
I0529 09:03:24.473764 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:03:25.863653 11123 solver.cpp:218] Iteration 177100 (3.51263 iter/s, 28.4687s/100 iters), loss = 2.37262e-06
I0529 09:03:25.863713 11123 solver.cpp:237]     Train net output #0: loss = 1.50801e-06 (* 1 = 1.50801e-06 loss)
I0529 09:03:25.863723 11123 sgd_solver.cpp:105] Iteration 177100, lr = 0.001145
I0529 09:03:54.027115 11123 solver.cpp:218] Iteration 177200 (3.55076 iter/s, 28.163s/100 iters), loss = 0.000199665
I0529 09:03:54.027161 11123 solver.cpp:237]     Train net output #0: loss = 0.000198801 (* 1 = 0.000198801 loss)
I0529 09:03:54.027170 11123 sgd_solver.cpp:105] Iteration 177200, lr = 0.00114
I0529 09:04:22.072253 11123 solver.cpp:218] Iteration 177300 (3.56574 iter/s, 28.0447s/100 iters), loss = 2.9924e-06
I0529 09:04:22.072383 11123 solver.cpp:237]     Train net output #0: loss = 2.12789e-06 (* 1 = 2.12789e-06 loss)
I0529 09:04:22.072396 11123 sgd_solver.cpp:105] Iteration 177300, lr = 0.001135
I0529 09:04:50.128862 11123 solver.cpp:218] Iteration 177400 (3.56429 iter/s, 28.0561s/100 iters), loss = 7.38554e-06
I0529 09:04:50.128907 11123 solver.cpp:237]     Train net output #0: loss = 6.52107e-06 (* 1 = 6.52107e-06 loss)
I0529 09:04:50.128916 11123 sgd_solver.cpp:105] Iteration 177400, lr = 0.00113
I0529 09:05:18.210610 11123 solver.cpp:218] Iteration 177500 (3.56109 iter/s, 28.0813s/100 iters), loss = 4.16339e-05
I0529 09:05:18.210816 11123 solver.cpp:237]     Train net output #0: loss = 4.07694e-05 (* 1 = 4.07694e-05 loss)
I0529 09:05:18.210829 11123 sgd_solver.cpp:105] Iteration 177500, lr = 0.001125
I0529 09:05:46.775221 11123 solver.cpp:218] Iteration 177600 (3.50091 iter/s, 28.564s/100 iters), loss = 2.59299e-06
I0529 09:05:46.775282 11123 solver.cpp:237]     Train net output #0: loss = 1.72855e-06 (* 1 = 1.72855e-06 loss)
I0529 09:05:46.775302 11123 sgd_solver.cpp:105] Iteration 177600, lr = 0.00112
I0529 09:06:15.668102 11123 solver.cpp:218] Iteration 177700 (3.46112 iter/s, 28.8924s/100 iters), loss = 2.21024e-05
I0529 09:06:15.668285 11123 solver.cpp:237]     Train net output #0: loss = 2.12381e-05 (* 1 = 2.12381e-05 loss)
I0529 09:06:15.668301 11123 sgd_solver.cpp:105] Iteration 177700, lr = 0.001115
I0529 09:06:17.733618 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:06:44.150374 11123 solver.cpp:218] Iteration 177800 (3.51104 iter/s, 28.4816s/100 iters), loss = 3.4872e-05
I0529 09:06:44.150426 11123 solver.cpp:237]     Train net output #0: loss = 3.40076e-05 (* 1 = 3.40076e-05 loss)
I0529 09:06:44.150439 11123 sgd_solver.cpp:105] Iteration 177800, lr = 0.00111
I0529 09:07:12.728492 11123 solver.cpp:218] Iteration 177900 (3.49924 iter/s, 28.5776s/100 iters), loss = 9.2213e-06
I0529 09:07:12.728727 11123 solver.cpp:237]     Train net output #0: loss = 8.35691e-06 (* 1 = 8.35691e-06 loss)
I0529 09:07:12.728744 11123 sgd_solver.cpp:105] Iteration 177900, lr = 0.001105
I0529 09:07:40.524757 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_178000.caffemodel
I0529 09:07:40.940066 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_178000.solverstate
I0529 09:07:41.086567 11123 solver.cpp:330] Iteration 178000, Testing net (#0)
I0529 09:07:41.317970 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:07:45.520346 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 09:07:45.520501 11123 solver.cpp:397]     Test net output #1: loss = 0.235821 (* 1 = 0.235821 loss)
I0529 09:07:45.801113 11123 solver.cpp:218] Iteration 178000 (3.02372 iter/s, 33.0719s/100 iters), loss = 6.35761e-05
I0529 09:07:45.801164 11123 solver.cpp:237]     Train net output #0: loss = 6.27119e-05 (* 1 = 6.27119e-05 loss)
I0529 09:07:45.801175 11123 sgd_solver.cpp:105] Iteration 178000, lr = 0.0011
I0529 09:08:13.850308 11123 solver.cpp:218] Iteration 178100 (3.56523 iter/s, 28.0487s/100 iters), loss = 5.47175e-06
I0529 09:08:13.850353 11123 solver.cpp:237]     Train net output #0: loss = 4.60757e-06 (* 1 = 4.60757e-06 loss)
I0529 09:08:13.850363 11123 sgd_solver.cpp:105] Iteration 178100, lr = 0.001095
I0529 09:08:42.047101 11123 solver.cpp:218] Iteration 178200 (3.54657 iter/s, 28.1963s/100 iters), loss = 4.04718e-06
I0529 09:08:42.047302 11123 solver.cpp:237]     Train net output #0: loss = 3.18292e-06 (* 1 = 3.18292e-06 loss)
I0529 09:08:42.047327 11123 sgd_solver.cpp:105] Iteration 178200, lr = 0.00109
I0529 09:09:10.121824 11123 solver.cpp:218] Iteration 178300 (3.562 iter/s, 28.0741s/100 iters), loss = 0.000387347
I0529 09:09:10.121868 11123 solver.cpp:237]     Train net output #0: loss = 0.000386482 (* 1 = 0.000386482 loss)
I0529 09:09:10.121876 11123 sgd_solver.cpp:105] Iteration 178300, lr = 0.001085
I0529 09:09:15.765445 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:09:38.195271 11123 solver.cpp:218] Iteration 178400 (3.56215 iter/s, 28.0729s/100 iters), loss = 1.48421e-05
I0529 09:09:38.195317 11123 solver.cpp:237]     Train net output #0: loss = 1.39778e-05 (* 1 = 1.39778e-05 loss)
I0529 09:09:38.195325 11123 sgd_solver.cpp:105] Iteration 178400, lr = 0.00108
I0529 09:10:06.247378 11123 solver.cpp:218] Iteration 178500 (3.56486 iter/s, 28.0516s/100 iters), loss = 0.000424518
I0529 09:10:06.247593 11123 solver.cpp:237]     Train net output #0: loss = 0.000423654 (* 1 = 0.000423654 loss)
I0529 09:10:06.247606 11123 sgd_solver.cpp:105] Iteration 178500, lr = 0.001075
I0529 09:10:34.326341 11123 solver.cpp:218] Iteration 178600 (3.56147 iter/s, 28.0783s/100 iters), loss = 7.3971e-06
I0529 09:10:34.326395 11123 solver.cpp:237]     Train net output #0: loss = 6.53291e-06 (* 1 = 6.53291e-06 loss)
I0529 09:10:34.326403 11123 sgd_solver.cpp:105] Iteration 178600, lr = 0.00107
I0529 09:11:02.377094 11123 solver.cpp:218] Iteration 178700 (3.56503 iter/s, 28.0502s/100 iters), loss = 1.00019e-05
I0529 09:11:02.377269 11123 solver.cpp:237]     Train net output #0: loss = 9.13774e-06 (* 1 = 9.13774e-06 loss)
I0529 09:11:02.377281 11123 sgd_solver.cpp:105] Iteration 178700, lr = 0.001065
I0529 09:11:30.440394 11123 solver.cpp:218] Iteration 178800 (3.56345 iter/s, 28.0627s/100 iters), loss = 3.02159e-05
I0529 09:11:30.440444 11123 solver.cpp:237]     Train net output #0: loss = 2.93518e-05 (* 1 = 2.93518e-05 loss)
I0529 09:11:30.440454 11123 sgd_solver.cpp:105] Iteration 178800, lr = 0.00106
I0529 09:11:58.501775 11123 solver.cpp:218] Iteration 178900 (3.56368 iter/s, 28.0609s/100 iters), loss = 3.05155e-06
I0529 09:11:58.501940 11123 solver.cpp:237]     Train net output #0: loss = 2.18751e-06 (* 1 = 2.18751e-06 loss)
I0529 09:11:58.501951 11123 sgd_solver.cpp:105] Iteration 178900, lr = 0.001055
I0529 09:12:07.800215 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:12:26.300806 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_179000.caffemodel
I0529 09:12:26.738119 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_179000.solverstate
I0529 09:12:26.884577 11123 solver.cpp:330] Iteration 179000, Testing net (#0)
I0529 09:12:28.633595 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:12:31.351512 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 09:12:31.351568 11123 solver.cpp:397]     Test net output #1: loss = 0.225975 (* 1 = 0.225975 loss)
I0529 09:12:31.628199 11123 solver.cpp:218] Iteration 179000 (3.0188 iter/s, 33.1257s/100 iters), loss = 8.49351e-06
I0529 09:12:31.628249 11123 solver.cpp:237]     Train net output #0: loss = 7.62955e-06 (* 1 = 7.62955e-06 loss)
I0529 09:12:31.628258 11123 sgd_solver.cpp:105] Iteration 179000, lr = 0.00105
I0529 09:12:59.664482 11123 solver.cpp:218] Iteration 179100 (3.56687 iter/s, 28.0358s/100 iters), loss = 1.89593e-05
I0529 09:12:59.664719 11123 solver.cpp:237]     Train net output #0: loss = 1.80953e-05 (* 1 = 1.80953e-05 loss)
I0529 09:12:59.664731 11123 sgd_solver.cpp:105] Iteration 179100, lr = 0.001045
I0529 09:13:27.746088 11123 solver.cpp:218] Iteration 179200 (3.56114 iter/s, 28.0809s/100 iters), loss = 1.35783e-05
I0529 09:13:27.746134 11123 solver.cpp:237]     Train net output #0: loss = 1.27144e-05 (* 1 = 1.27144e-05 loss)
I0529 09:13:27.746142 11123 sgd_solver.cpp:105] Iteration 179200, lr = 0.00104
I0529 09:13:55.805291 11123 solver.cpp:218] Iteration 179300 (3.56396 iter/s, 28.0587s/100 iters), loss = 7.61728e-06
I0529 09:13:55.805444 11123 solver.cpp:237]     Train net output #0: loss = 6.75337e-06 (* 1 = 6.75337e-06 loss)
I0529 09:13:55.805455 11123 sgd_solver.cpp:105] Iteration 179300, lr = 0.001035
I0529 09:14:23.881687 11123 solver.cpp:218] Iteration 179400 (3.56179 iter/s, 28.0758s/100 iters), loss = 5.56523e-05
I0529 09:14:23.881733 11123 solver.cpp:237]     Train net output #0: loss = 5.47884e-05 (* 1 = 5.47884e-05 loss)
I0529 09:14:23.881742 11123 sgd_solver.cpp:105] Iteration 179400, lr = 0.00103
I0529 09:14:51.949141 11123 solver.cpp:218] Iteration 179500 (3.56291 iter/s, 28.0669s/100 iters), loss = 1.91076e-05
I0529 09:14:51.949314 11123 solver.cpp:237]     Train net output #0: loss = 1.82436e-05 (* 1 = 1.82436e-05 loss)
I0529 09:14:51.949326 11123 sgd_solver.cpp:105] Iteration 179500, lr = 0.001025
I0529 09:15:04.894320 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:15:20.061350 11123 solver.cpp:218] Iteration 179600 (3.55726 iter/s, 28.1116s/100 iters), loss = 5.02735e-05
I0529 09:15:20.061393 11123 solver.cpp:237]     Train net output #0: loss = 4.94095e-05 (* 1 = 4.94095e-05 loss)
I0529 09:15:20.061403 11123 sgd_solver.cpp:105] Iteration 179600, lr = 0.00102
I0529 09:15:48.124795 11123 solver.cpp:218] Iteration 179700 (3.56342 iter/s, 28.0629s/100 iters), loss = 1.54441e-05
I0529 09:15:48.124975 11123 solver.cpp:237]     Train net output #0: loss = 1.45802e-05 (* 1 = 1.45802e-05 loss)
I0529 09:15:48.124987 11123 sgd_solver.cpp:105] Iteration 179700, lr = 0.001015
I0529 09:16:16.189760 11123 solver.cpp:218] Iteration 179800 (3.56325 iter/s, 28.0643s/100 iters), loss = 2.97992e-06
I0529 09:16:16.189805 11123 solver.cpp:237]     Train net output #0: loss = 2.11598e-06 (* 1 = 2.11598e-06 loss)
I0529 09:16:16.189813 11123 sgd_solver.cpp:105] Iteration 179800, lr = 0.00101
I0529 09:16:44.263871 11123 solver.cpp:218] Iteration 179900 (3.56207 iter/s, 28.0736s/100 iters), loss = 1.43651e-05
I0529 09:16:44.264031 11123 solver.cpp:237]     Train net output #0: loss = 1.35007e-05 (* 1 = 1.35007e-05 loss)
I0529 09:16:44.264042 11123 sgd_solver.cpp:105] Iteration 179900, lr = 0.001005
I0529 09:17:12.048372 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_180000.caffemodel
I0529 09:17:13.679914 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_180000.solverstate
I0529 09:17:13.828297 11123 solver.cpp:330] Iteration 180000, Testing net (#0)
I0529 09:17:17.093269 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:17:18.295851 11123 solver.cpp:397]     Test net output #0: accuracy = 0.94
I0529 09:17:18.295892 11123 solver.cpp:397]     Test net output #1: loss = 0.275667 (* 1 = 0.275667 loss)
I0529 09:17:18.572933 11123 solver.cpp:218] Iteration 180000 (2.91475 iter/s, 34.3083s/100 iters), loss = 1.21422e-05
I0529 09:17:18.572993 11123 solver.cpp:237]     Train net output #0: loss = 1.12779e-05 (* 1 = 1.12779e-05 loss)
I0529 09:17:18.573001 11123 sgd_solver.cpp:105] Iteration 180000, lr = 0.001
I0529 09:17:46.648048 11123 solver.cpp:218] Iteration 180100 (3.56197 iter/s, 28.0744s/100 iters), loss = 1.55557e-05
I0529 09:17:46.648108 11123 solver.cpp:237]     Train net output #0: loss = 1.46913e-05 (* 1 = 1.46913e-05 loss)
I0529 09:17:46.648116 11123 sgd_solver.cpp:105] Iteration 180100, lr = 0.000995
I0529 09:18:03.233281 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:18:14.719080 11123 solver.cpp:218] Iteration 180200 (3.56248 iter/s, 28.0703s/100 iters), loss = 8.01822e-05
I0529 09:18:14.719141 11123 solver.cpp:237]     Train net output #0: loss = 7.93177e-05 (* 1 = 7.93177e-05 loss)
I0529 09:18:14.719156 11123 sgd_solver.cpp:105] Iteration 180200, lr = 0.00099
I0529 09:18:42.803599 11123 solver.cpp:218] Iteration 180300 (3.56077 iter/s, 28.0838s/100 iters), loss = 0.000191556
I0529 09:18:42.803764 11123 solver.cpp:237]     Train net output #0: loss = 0.000190692 (* 1 = 0.000190692 loss)
I0529 09:18:42.803776 11123 sgd_solver.cpp:105] Iteration 180300, lr = 0.000985
I0529 09:19:11.463111 11123 solver.cpp:218] Iteration 180400 (3.48935 iter/s, 28.6587s/100 iters), loss = 1.16838e-06
I0529 09:19:11.463171 11123 solver.cpp:237]     Train net output #0: loss = 3.03984e-07 (* 1 = 3.03984e-07 loss)
I0529 09:19:11.463186 11123 sgd_solver.cpp:105] Iteration 180400, lr = 0.00098
I0529 09:19:39.773494 11123 solver.cpp:218] Iteration 180500 (3.53236 iter/s, 28.3097s/100 iters), loss = 0.000569914
I0529 09:19:39.773663 11123 solver.cpp:237]     Train net output #0: loss = 0.00056905 (* 1 = 0.00056905 loss)
I0529 09:19:39.773680 11123 sgd_solver.cpp:105] Iteration 180500, lr = 0.000975
I0529 09:20:07.792696 11123 solver.cpp:218] Iteration 180600 (3.56908 iter/s, 28.0184s/100 iters), loss = 7.42691e-06
I0529 09:20:07.792748 11123 solver.cpp:237]     Train net output #0: loss = 6.56256e-06 (* 1 = 6.56256e-06 loss)
I0529 09:20:07.792762 11123 sgd_solver.cpp:105] Iteration 180600, lr = 0.00097
I0529 09:20:35.823290 11123 solver.cpp:218] Iteration 180700 (3.56762 iter/s, 28.0299s/100 iters), loss = 1.75347e-05
I0529 09:20:35.823457 11123 solver.cpp:237]     Train net output #0: loss = 1.66705e-05 (* 1 = 1.66705e-05 loss)
I0529 09:20:35.823468 11123 sgd_solver.cpp:105] Iteration 180700, lr = 0.000965
I0529 09:20:55.755844 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:21:03.879788 11123 solver.cpp:218] Iteration 180800 (3.56434 iter/s, 28.0557s/100 iters), loss = 1.75739e-05
I0529 09:21:03.879834 11123 solver.cpp:237]     Train net output #0: loss = 1.67097e-05 (* 1 = 1.67097e-05 loss)
I0529 09:21:03.879843 11123 sgd_solver.cpp:105] Iteration 180800, lr = 0.00096
I0529 09:21:31.990437 11123 solver.cpp:218] Iteration 180900 (3.55746 iter/s, 28.11s/100 iters), loss = 0.000167256
I0529 09:21:31.990806 11123 solver.cpp:237]     Train net output #0: loss = 0.000166391 (* 1 = 0.000166391 loss)
I0529 09:21:31.990824 11123 sgd_solver.cpp:105] Iteration 180900, lr = 0.000955
I0529 09:21:59.912391 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_181000.caffemodel
I0529 09:22:00.256865 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_181000.solverstate
I0529 09:22:00.404299 11123 solver.cpp:330] Iteration 181000, Testing net (#0)
I0529 09:22:04.876307 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 09:22:04.876456 11123 solver.cpp:397]     Test net output #1: loss = 0.213455 (* 1 = 0.213455 loss)
I0529 09:22:05.162247 11123 solver.cpp:218] Iteration 181000 (3.01471 iter/s, 33.1707s/100 iters), loss = 5.46089e-05
I0529 09:22:05.162307 11123 solver.cpp:237]     Train net output #0: loss = 5.37444e-05 (* 1 = 5.37444e-05 loss)
I0529 09:22:05.162315 11123 sgd_solver.cpp:105] Iteration 181000, lr = 0.00095
I0529 09:22:33.294435 11123 solver.cpp:218] Iteration 181100 (3.55473 iter/s, 28.1315s/100 iters), loss = 1.66723e-05
I0529 09:22:33.294478 11123 solver.cpp:237]     Train net output #0: loss = 1.58078e-05 (* 1 = 1.58078e-05 loss)
I0529 09:22:33.294487 11123 sgd_solver.cpp:105] Iteration 181100, lr = 0.000945
I0529 09:23:01.381924 11123 solver.cpp:218] Iteration 181200 (3.56039 iter/s, 28.0868s/100 iters), loss = 5.43021e-06
I0529 09:23:01.382170 11123 solver.cpp:237]     Train net output #0: loss = 4.56576e-06 (* 1 = 4.56576e-06 loss)
I0529 09:23:01.382182 11123 sgd_solver.cpp:105] Iteration 181200, lr = 0.00094
I0529 09:23:29.527860 11123 solver.cpp:218] Iteration 181300 (3.55302 iter/s, 28.1451s/100 iters), loss = 4.08569e-05
I0529 09:23:29.527909 11123 solver.cpp:237]     Train net output #0: loss = 3.99925e-05 (* 1 = 3.99925e-05 loss)
I0529 09:23:29.527917 11123 sgd_solver.cpp:105] Iteration 181300, lr = 0.000935
I0529 09:23:53.095209 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:23:57.573529 11123 solver.cpp:218] Iteration 181400 (3.5657 iter/s, 28.045s/100 iters), loss = 1.96671e-05
I0529 09:23:57.573577 11123 solver.cpp:237]     Train net output #0: loss = 1.88027e-05 (* 1 = 1.88027e-05 loss)
I0529 09:23:57.573586 11123 sgd_solver.cpp:105] Iteration 181400, lr = 0.00093
I0529 09:24:26.118962 11123 solver.cpp:218] Iteration 181500 (3.50327 iter/s, 28.5448s/100 iters), loss = 2.28871e-05
I0529 09:24:26.119153 11123 solver.cpp:237]     Train net output #0: loss = 2.20226e-05 (* 1 = 2.20226e-05 loss)
I0529 09:24:26.119163 11123 sgd_solver.cpp:105] Iteration 181500, lr = 0.000925
I0529 09:24:54.169731 11123 solver.cpp:218] Iteration 181600 (3.56506 iter/s, 28.05s/100 iters), loss = 0.000150372
I0529 09:24:54.169776 11123 solver.cpp:237]     Train net output #0: loss = 0.000149507 (* 1 = 0.000149507 loss)
I0529 09:24:54.169785 11123 sgd_solver.cpp:105] Iteration 181600, lr = 0.00092
I0529 09:25:22.204486 11123 solver.cpp:218] Iteration 181700 (3.56708 iter/s, 28.0341s/100 iters), loss = 5.68523e-05
I0529 09:25:22.204710 11123 solver.cpp:237]     Train net output #0: loss = 5.59888e-05 (* 1 = 5.59888e-05 loss)
I0529 09:25:22.204721 11123 sgd_solver.cpp:105] Iteration 181700, lr = 0.000915
I0529 09:25:50.285360 11123 solver.cpp:218] Iteration 181800 (3.56125 iter/s, 28.0801s/100 iters), loss = 1.76946e-06
I0529 09:25:50.285408 11123 solver.cpp:237]     Train net output #0: loss = 9.05993e-07 (* 1 = 9.05993e-07 loss)
I0529 09:25:50.285416 11123 sgd_solver.cpp:105] Iteration 181800, lr = 0.00091
I0529 09:26:18.318156 11123 solver.cpp:218] Iteration 181900 (3.56733 iter/s, 28.0322s/100 iters), loss = 4.41006e-06
I0529 09:26:18.318356 11123 solver.cpp:237]     Train net output #0: loss = 3.54653e-06 (* 1 = 3.54653e-06 loss)
I0529 09:26:18.318368 11123 sgd_solver.cpp:105] Iteration 181900, lr = 0.000905
I0529 09:26:45.589248 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:26:46.154058 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_182000.caffemodel
I0529 09:26:46.677418 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_182000.solverstate
I0529 09:26:46.825173 11123 solver.cpp:330] Iteration 182000, Testing net (#0)
I0529 09:26:47.144628 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:26:51.285241 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 09:26:51.285392 11123 solver.cpp:397]     Test net output #1: loss = 0.237846 (* 1 = 0.237846 loss)
I0529 09:26:51.563824 11123 solver.cpp:218] Iteration 182000 (3.00799 iter/s, 33.2448s/100 iters), loss = 1.65559e-05
I0529 09:26:51.563880 11123 solver.cpp:237]     Train net output #0: loss = 1.56923e-05 (* 1 = 1.56923e-05 loss)
I0529 09:26:51.563889 11123 sgd_solver.cpp:105] Iteration 182000, lr = 0.0009
I0529 09:27:19.734254 11123 solver.cpp:218] Iteration 182100 (3.5499 iter/s, 28.1698s/100 iters), loss = 1.59981e-05
I0529 09:27:19.734302 11123 solver.cpp:237]     Train net output #0: loss = 1.51344e-05 (* 1 = 1.51344e-05 loss)
I0529 09:27:19.734310 11123 sgd_solver.cpp:105] Iteration 182100, lr = 0.000895
I0529 09:27:47.792210 11123 solver.cpp:218] Iteration 182200 (3.56413 iter/s, 28.0573s/100 iters), loss = 4.61279e-06
I0529 09:27:47.792414 11123 solver.cpp:237]     Train net output #0: loss = 3.74918e-06 (* 1 = 3.74918e-06 loss)
I0529 09:27:47.792425 11123 sgd_solver.cpp:105] Iteration 182200, lr = 0.00089
I0529 09:28:15.948070 11123 solver.cpp:218] Iteration 182300 (3.55176 iter/s, 28.1551s/100 iters), loss = 2.26276e-05
I0529 09:28:15.948117 11123 solver.cpp:237]     Train net output #0: loss = 2.17641e-05 (* 1 = 2.17641e-05 loss)
I0529 09:28:15.948127 11123 sgd_solver.cpp:105] Iteration 182300, lr = 0.000885
I0529 09:28:44.088347 11123 solver.cpp:218] Iteration 182400 (3.5537 iter/s, 28.1396s/100 iters), loss = 2.68361e-05
I0529 09:28:44.088543 11123 solver.cpp:237]     Train net output #0: loss = 2.59726e-05 (* 1 = 2.59726e-05 loss)
I0529 09:28:44.088556 11123 sgd_solver.cpp:105] Iteration 182400, lr = 0.00088
I0529 09:29:12.449149 11123 solver.cpp:218] Iteration 182500 (3.52609 iter/s, 28.36s/100 iters), loss = 2.15949e-05
I0529 09:29:12.449193 11123 solver.cpp:237]     Train net output #0: loss = 2.07315e-05 (* 1 = 2.07315e-05 loss)
I0529 09:29:12.449201 11123 sgd_solver.cpp:105] Iteration 182500, lr = 0.000875
I0529 09:29:40.519975 11123 solver.cpp:218] Iteration 182600 (3.5625 iter/s, 28.0702s/100 iters), loss = 2.78793e-05
I0529 09:29:40.520159 11123 solver.cpp:237]     Train net output #0: loss = 2.70159e-05 (* 1 = 2.70159e-05 loss)
I0529 09:29:40.520174 11123 sgd_solver.cpp:105] Iteration 182600, lr = 0.00087
I0529 09:29:43.339730 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:30:09.034670 11123 solver.cpp:218] Iteration 182700 (3.50706 iter/s, 28.5139s/100 iters), loss = 0.000198651
I0529 09:30:09.034718 11123 solver.cpp:237]     Train net output #0: loss = 0.000197788 (* 1 = 0.000197788 loss)
I0529 09:30:09.034728 11123 sgd_solver.cpp:105] Iteration 182700, lr = 0.000865
I0529 09:30:37.419260 11123 solver.cpp:218] Iteration 182800 (3.52312 iter/s, 28.384s/100 iters), loss = 3.27331e-05
I0529 09:30:37.419373 11123 solver.cpp:237]     Train net output #0: loss = 3.18696e-05 (* 1 = 3.18696e-05 loss)
I0529 09:30:37.419383 11123 sgd_solver.cpp:105] Iteration 182800, lr = 0.00086
I0529 09:31:06.156294 11123 solver.cpp:218] Iteration 182900 (3.47991 iter/s, 28.7363s/100 iters), loss = 0.000156022
I0529 09:31:06.156344 11123 solver.cpp:237]     Train net output #0: loss = 0.000155158 (* 1 = 0.000155158 loss)
I0529 09:31:06.156353 11123 sgd_solver.cpp:105] Iteration 182900, lr = 0.000855
I0529 09:31:34.426509 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_183000.caffemodel
I0529 09:31:34.975699 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_183000.solverstate
I0529 09:31:35.123955 11123 solver.cpp:330] Iteration 183000, Testing net (#0)
I0529 09:31:36.960783 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:31:39.710667 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 09:31:39.710702 11123 solver.cpp:397]     Test net output #1: loss = 0.225886 (* 1 = 0.225886 loss)
I0529 09:31:39.989485 11123 solver.cpp:218] Iteration 183000 (2.95574 iter/s, 33.8325s/100 iters), loss = 4.34425e-06
I0529 09:31:39.989529 11123 solver.cpp:237]     Train net output #0: loss = 3.48097e-06 (* 1 = 3.48097e-06 loss)
I0529 09:31:39.989538 11123 sgd_solver.cpp:105] Iteration 183000, lr = 0.00085
I0529 09:32:08.462525 11123 solver.cpp:218] Iteration 183100 (3.51217 iter/s, 28.4724s/100 iters), loss = 4.22291e-05
I0529 09:32:08.462720 11123 solver.cpp:237]     Train net output #0: loss = 4.13658e-05 (* 1 = 4.13658e-05 loss)
I0529 09:32:08.462738 11123 sgd_solver.cpp:105] Iteration 183100, lr = 0.000845
I0529 09:32:37.525619 11123 solver.cpp:218] Iteration 183200 (3.44088 iter/s, 29.0623s/100 iters), loss = 0.000332068
I0529 09:32:37.525682 11123 solver.cpp:237]     Train net output #0: loss = 0.000331204 (* 1 = 0.000331204 loss)
I0529 09:32:37.525696 11123 sgd_solver.cpp:105] Iteration 183200, lr = 0.00084
I0529 09:32:44.374567 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:33:06.908124 11123 solver.cpp:218] Iteration 183300 (3.40348 iter/s, 29.3817s/100 iters), loss = 0.000144062
I0529 09:33:06.908180 11123 solver.cpp:237]     Train net output #0: loss = 0.000143199 (* 1 = 0.000143199 loss)
I0529 09:33:06.908190 11123 sgd_solver.cpp:105] Iteration 183300, lr = 0.000835
I0529 09:33:35.461413 11123 solver.cpp:218] Iteration 183400 (3.5023 iter/s, 28.5527s/100 iters), loss = 2.95509e-05
I0529 09:33:35.461623 11123 solver.cpp:237]     Train net output #0: loss = 2.86875e-05 (* 1 = 2.86875e-05 loss)
I0529 09:33:35.461647 11123 sgd_solver.cpp:105] Iteration 183400, lr = 0.00083
I0529 09:34:03.626296 11123 solver.cpp:218] Iteration 183500 (3.55062 iter/s, 28.1641s/100 iters), loss = 6.7831e-05
I0529 09:34:03.626343 11123 solver.cpp:237]     Train net output #0: loss = 6.69675e-05 (* 1 = 6.69675e-05 loss)
I0529 09:34:03.626353 11123 sgd_solver.cpp:105] Iteration 183500, lr = 0.000825
I0529 09:34:31.946637 11123 solver.cpp:218] Iteration 183600 (3.53111 iter/s, 28.3197s/100 iters), loss = 0.000112871
I0529 09:34:31.946810 11123 solver.cpp:237]     Train net output #0: loss = 0.000112007 (* 1 = 0.000112007 loss)
I0529 09:34:31.946821 11123 sgd_solver.cpp:105] Iteration 183600, lr = 0.00082
I0529 09:34:59.969825 11123 solver.cpp:218] Iteration 183700 (3.56857 iter/s, 28.0225s/100 iters), loss = 4.09309e-05
I0529 09:34:59.969871 11123 solver.cpp:237]     Train net output #0: loss = 4.00674e-05 (* 1 = 4.00674e-05 loss)
I0529 09:34:59.969882 11123 sgd_solver.cpp:105] Iteration 183700, lr = 0.000815
I0529 09:35:28.192867 11123 solver.cpp:218] Iteration 183800 (3.54328 iter/s, 28.2224s/100 iters), loss = 2.03195e-05
I0529 09:35:28.193085 11123 solver.cpp:237]     Train net output #0: loss = 1.94561e-05 (* 1 = 1.94561e-05 loss)
I0529 09:35:28.193097 11123 sgd_solver.cpp:105] Iteration 183800, lr = 0.00081
I0529 09:35:38.034757 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:35:56.250030 11123 solver.cpp:218] Iteration 183900 (3.56425 iter/s, 28.0564s/100 iters), loss = 4.8954e-05
I0529 09:35:56.250080 11123 solver.cpp:237]     Train net output #0: loss = 4.80905e-05 (* 1 = 4.80905e-05 loss)
I0529 09:35:56.250089 11123 sgd_solver.cpp:105] Iteration 183900, lr = 0.000805
I0529 09:36:24.015872 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_184000.caffemodel
I0529 09:36:24.527902 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_184000.solverstate
I0529 09:36:24.677904 11123 solver.cpp:330] Iteration 184000, Testing net (#0)
I0529 09:36:28.022830 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:36:29.136574 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 09:36:29.136626 11123 solver.cpp:397]     Test net output #1: loss = 0.276865 (* 1 = 0.276865 loss)
I0529 09:36:29.414469 11123 solver.cpp:218] Iteration 184000 (3.01534 iter/s, 33.1637s/100 iters), loss = 6.65726e-06
I0529 09:36:29.414515 11123 solver.cpp:237]     Train net output #0: loss = 5.79371e-06 (* 1 = 5.79371e-06 loss)
I0529 09:36:29.414523 11123 sgd_solver.cpp:105] Iteration 184000, lr = 0.0008
I0529 09:36:57.445408 11123 solver.cpp:218] Iteration 184100 (3.56756 iter/s, 28.0303s/100 iters), loss = 5.98981e-05
I0529 09:36:57.445559 11123 solver.cpp:237]     Train net output #0: loss = 5.9035e-05 (* 1 = 5.9035e-05 loss)
I0529 09:36:57.445570 11123 sgd_solver.cpp:105] Iteration 184100, lr = 0.000795
I0529 09:37:25.454622 11123 solver.cpp:218] Iteration 184200 (3.57034 iter/s, 28.0085s/100 iters), loss = 1.35153e-05
I0529 09:37:25.454664 11123 solver.cpp:237]     Train net output #0: loss = 1.26521e-05 (* 1 = 1.26521e-05 loss)
I0529 09:37:25.454674 11123 sgd_solver.cpp:105] Iteration 184200, lr = 0.00079
I0529 09:37:53.487639 11123 solver.cpp:218] Iteration 184300 (3.5673 iter/s, 28.0324s/100 iters), loss = 9.39611e-05
I0529 09:37:53.487797 11123 solver.cpp:237]     Train net output #0: loss = 9.30978e-05 (* 1 = 9.30978e-05 loss)
I0529 09:37:53.487807 11123 sgd_solver.cpp:105] Iteration 184300, lr = 0.000785
I0529 09:38:21.509712 11123 solver.cpp:218] Iteration 184400 (3.5687 iter/s, 28.0214s/100 iters), loss = 1.63108e-05
I0529 09:38:21.509758 11123 solver.cpp:237]     Train net output #0: loss = 1.54476e-05 (* 1 = 1.54476e-05 loss)
I0529 09:38:21.509768 11123 sgd_solver.cpp:105] Iteration 184400, lr = 0.00078
I0529 09:38:34.987205 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:38:49.544385 11123 solver.cpp:218] Iteration 184500 (3.56709 iter/s, 28.0341s/100 iters), loss = 2.27665e-05
I0529 09:38:49.544440 11123 solver.cpp:237]     Train net output #0: loss = 2.19034e-05 (* 1 = 2.19034e-05 loss)
I0529 09:38:49.544450 11123 sgd_solver.cpp:105] Iteration 184500, lr = 0.000775
I0529 09:39:17.589001 11123 solver.cpp:218] Iteration 184600 (3.56582 iter/s, 28.044s/100 iters), loss = 4.54842e-05
I0529 09:39:17.591675 11123 solver.cpp:237]     Train net output #0: loss = 4.4621e-05 (* 1 = 4.4621e-05 loss)
I0529 09:39:17.591687 11123 sgd_solver.cpp:105] Iteration 184600, lr = 0.00077
I0529 09:39:45.644400 11123 solver.cpp:218] Iteration 184700 (3.56479 iter/s, 28.0522s/100 iters), loss = 3.2176e-06
I0529 09:39:45.644453 11123 solver.cpp:237]     Train net output #0: loss = 2.35441e-06 (* 1 = 2.35441e-06 loss)
I0529 09:39:45.644461 11123 sgd_solver.cpp:105] Iteration 184700, lr = 0.000765
I0529 09:40:13.674881 11123 solver.cpp:218] Iteration 184800 (3.56762 iter/s, 28.0299s/100 iters), loss = 1.35576e-05
I0529 09:40:13.675009 11123 solver.cpp:237]     Train net output #0: loss = 1.26944e-05 (* 1 = 1.26944e-05 loss)
I0529 09:40:13.675030 11123 sgd_solver.cpp:105] Iteration 184800, lr = 0.00076
I0529 09:40:41.715541 11123 solver.cpp:218] Iteration 184900 (3.56633 iter/s, 28.04s/100 iters), loss = 0.000136325
I0529 09:40:41.715591 11123 solver.cpp:237]     Train net output #0: loss = 0.000135462 (* 1 = 0.000135462 loss)
I0529 09:40:41.715600 11123 sgd_solver.cpp:105] Iteration 184900, lr = 0.000755
I0529 09:41:09.481025 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_185000.caffemodel
I0529 09:41:09.996400 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_185000.solverstate
I0529 09:41:10.146193 11123 solver.cpp:330] Iteration 185000, Testing net (#0)
I0529 09:41:14.606031 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 09:41:14.606081 11123 solver.cpp:397]     Test net output #1: loss = 0.214603 (* 1 = 0.214603 loss)
I0529 09:41:14.886672 11123 solver.cpp:218] Iteration 185000 (3.01473 iter/s, 33.1704s/100 iters), loss = 6.90715e-06
I0529 09:41:14.886714 11123 solver.cpp:237]     Train net output #0: loss = 6.04412e-06 (* 1 = 6.04412e-06 loss)
I0529 09:41:14.886723 11123 sgd_solver.cpp:105] Iteration 185000, lr = 0.00075
I0529 09:41:32.018323 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:41:42.938051 11123 solver.cpp:218] Iteration 185100 (3.56496 iter/s, 28.0508s/100 iters), loss = 4.23757e-05
I0529 09:41:42.938212 11123 solver.cpp:237]     Train net output #0: loss = 4.15129e-05 (* 1 = 4.15129e-05 loss)
I0529 09:41:42.938225 11123 sgd_solver.cpp:105] Iteration 185100, lr = 0.000745
I0529 09:42:10.993232 11123 solver.cpp:218] Iteration 185200 (3.56449 iter/s, 28.0545s/100 iters), loss = 0.000289837
I0529 09:42:10.993283 11123 solver.cpp:237]     Train net output #0: loss = 0.000288975 (* 1 = 0.000288975 loss)
I0529 09:42:10.993291 11123 sgd_solver.cpp:105] Iteration 185200, lr = 0.00074
I0529 09:42:39.078022 11123 solver.cpp:218] Iteration 185300 (3.56072 iter/s, 28.0842s/100 iters), loss = 7.4374e-06
I0529 09:42:39.078186 11123 solver.cpp:237]     Train net output #0: loss = 6.57447e-06 (* 1 = 6.57447e-06 loss)
I0529 09:42:39.078199 11123 sgd_solver.cpp:105] Iteration 185300, lr = 0.000735
I0529 09:43:07.152604 11123 solver.cpp:218] Iteration 185400 (3.56203 iter/s, 28.0739s/100 iters), loss = 0.000105027
I0529 09:43:07.152654 11123 solver.cpp:237]     Train net output #0: loss = 0.000104164 (* 1 = 0.000104164 loss)
I0529 09:43:07.152663 11123 sgd_solver.cpp:105] Iteration 185400, lr = 0.00073
I0529 09:43:35.206303 11123 solver.cpp:218] Iteration 185500 (3.56467 iter/s, 28.0531s/100 iters), loss = 1.34319e-05
I0529 09:43:35.206456 11123 solver.cpp:237]     Train net output #0: loss = 1.25688e-05 (* 1 = 1.25688e-05 loss)
I0529 09:43:35.206467 11123 sgd_solver.cpp:105] Iteration 185500, lr = 0.000725
I0529 09:44:03.236865 11123 solver.cpp:218] Iteration 185600 (3.56762 iter/s, 28.0299s/100 iters), loss = 6.39463e-06
I0529 09:44:03.236909 11123 solver.cpp:237]     Train net output #0: loss = 5.53152e-06 (* 1 = 5.53152e-06 loss)
I0529 09:44:03.236918 11123 sgd_solver.cpp:105] Iteration 185600, lr = 0.00072
I0529 09:44:23.991371 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:44:31.261234 11123 solver.cpp:218] Iteration 185700 (3.5684 iter/s, 28.0238s/100 iters), loss = 1.51807e-05
I0529 09:44:31.261278 11123 solver.cpp:237]     Train net output #0: loss = 1.43175e-05 (* 1 = 1.43175e-05 loss)
I0529 09:44:31.261287 11123 sgd_solver.cpp:105] Iteration 185700, lr = 0.000715
I0529 09:44:59.311372 11123 solver.cpp:218] Iteration 185800 (3.56512 iter/s, 28.0496s/100 iters), loss = 0.000334628
I0529 09:44:59.311570 11123 solver.cpp:237]     Train net output #0: loss = 0.000333764 (* 1 = 0.000333764 loss)
I0529 09:44:59.311595 11123 sgd_solver.cpp:105] Iteration 185800, lr = 0.00071
I0529 09:45:27.360913 11123 solver.cpp:218] Iteration 185900 (3.56521 iter/s, 28.0488s/100 iters), loss = 2.11892e-05
I0529 09:45:27.360975 11123 solver.cpp:237]     Train net output #0: loss = 2.03261e-05 (* 1 = 2.03261e-05 loss)
I0529 09:45:27.360983 11123 sgd_solver.cpp:105] Iteration 185900, lr = 0.000705
I0529 09:45:55.144970 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_186000.caffemodel
I0529 09:45:55.644457 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_186000.solverstate
I0529 09:45:55.793876 11123 solver.cpp:330] Iteration 186000, Testing net (#0)
I0529 09:45:56.200497 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:46:00.252213 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 09:46:00.252267 11123 solver.cpp:397]     Test net output #1: loss = 0.236477 (* 1 = 0.236477 loss)
I0529 09:46:00.532421 11123 solver.cpp:218] Iteration 186000 (3.0147 iter/s, 33.1708s/100 iters), loss = 3.23836e-05
I0529 09:46:00.532465 11123 solver.cpp:237]     Train net output #0: loss = 3.15206e-05 (* 1 = 3.15206e-05 loss)
I0529 09:46:00.532474 11123 sgd_solver.cpp:105] Iteration 186000, lr = 0.0007
I0529 09:46:28.562412 11123 solver.cpp:218] Iteration 186100 (3.56768 iter/s, 28.0294s/100 iters), loss = 1.85625e-05
I0529 09:46:28.562579 11123 solver.cpp:237]     Train net output #0: loss = 1.76994e-05 (* 1 = 1.76994e-05 loss)
I0529 09:46:28.562592 11123 sgd_solver.cpp:105] Iteration 186100, lr = 0.000695
I0529 09:46:56.616367 11123 solver.cpp:218] Iteration 186200 (3.56465 iter/s, 28.0532s/100 iters), loss = 5.25599e-06
I0529 09:46:56.616430 11123 solver.cpp:237]     Train net output #0: loss = 4.39295e-06 (* 1 = 4.39295e-06 loss)
I0529 09:46:56.616439 11123 sgd_solver.cpp:105] Iteration 186200, lr = 0.00069
I0529 09:47:21.047783 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:47:24.681985 11123 solver.cpp:218] Iteration 186300 (3.56316 iter/s, 28.065s/100 iters), loss = 2.25785e-05
I0529 09:47:24.682036 11123 solver.cpp:237]     Train net output #0: loss = 2.17155e-05 (* 1 = 2.17155e-05 loss)
I0529 09:47:24.682044 11123 sgd_solver.cpp:105] Iteration 186300, lr = 0.000685
I0529 09:47:52.752020 11123 solver.cpp:218] Iteration 186400 (3.56259 iter/s, 28.0694s/100 iters), loss = 0.000108295
I0529 09:47:52.752182 11123 solver.cpp:237]     Train net output #0: loss = 0.000107432 (* 1 = 0.000107432 loss)
I0529 09:47:52.752195 11123 sgd_solver.cpp:105] Iteration 186400, lr = 0.00068
I0529 09:48:20.818884 11123 solver.cpp:218] Iteration 186500 (3.56301 iter/s, 28.0662s/100 iters), loss = 9.45358e-05
I0529 09:48:20.818941 11123 solver.cpp:237]     Train net output #0: loss = 9.3673e-05 (* 1 = 9.3673e-05 loss)
I0529 09:48:20.818949 11123 sgd_solver.cpp:105] Iteration 186500, lr = 0.000675
I0529 09:48:48.864367 11123 solver.cpp:218] Iteration 186600 (3.56571 iter/s, 28.0449s/100 iters), loss = 2.65735e-06
I0529 09:48:48.864562 11123 solver.cpp:237]     Train net output #0: loss = 1.79411e-06 (* 1 = 1.79411e-06 loss)
I0529 09:48:48.864578 11123 sgd_solver.cpp:105] Iteration 186600, lr = 0.00067
I0529 09:49:16.920279 11123 solver.cpp:218] Iteration 186700 (3.5644 iter/s, 28.0552s/100 iters), loss = 3.22351e-06
I0529 09:49:16.920322 11123 solver.cpp:237]     Train net output #0: loss = 2.36038e-06 (* 1 = 2.36038e-06 loss)
I0529 09:49:16.920331 11123 sgd_solver.cpp:105] Iteration 186700, lr = 0.000665
I0529 09:49:44.981060 11123 solver.cpp:218] Iteration 186800 (3.56377 iter/s, 28.0602s/100 iters), loss = 8.94121e-05
I0529 09:49:44.981228 11123 solver.cpp:237]     Train net output #0: loss = 8.85489e-05 (* 1 = 8.85489e-05 loss)
I0529 09:49:44.981240 11123 sgd_solver.cpp:105] Iteration 186800, lr = 0.00066
I0529 09:50:12.776796 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:50:13.035893 11123 solver.cpp:218] Iteration 186900 (3.56454 iter/s, 28.0541s/100 iters), loss = 2.12672e-06
I0529 09:50:13.035936 11123 solver.cpp:237]     Train net output #0: loss = 1.26362e-06 (* 1 = 1.26362e-06 loss)
I0529 09:50:13.035944 11123 sgd_solver.cpp:105] Iteration 186900, lr = 0.000655
I0529 09:50:40.811203 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_187000.caffemodel
I0529 09:50:41.301584 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_187000.solverstate
I0529 09:50:41.451607 11123 solver.cpp:330] Iteration 187000, Testing net (#0)
I0529 09:50:43.330737 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:50:45.908762 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 09:50:45.908814 11123 solver.cpp:397]     Test net output #1: loss = 0.232199 (* 1 = 0.232199 loss)
I0529 09:50:46.187692 11123 solver.cpp:218] Iteration 187000 (3.01649 iter/s, 33.1511s/100 iters), loss = 3.50723e-05
I0529 09:50:46.187736 11123 solver.cpp:237]     Train net output #0: loss = 3.42092e-05 (* 1 = 3.42092e-05 loss)
I0529 09:50:46.187744 11123 sgd_solver.cpp:105] Iteration 187000, lr = 0.00065
I0529 09:51:14.230496 11123 solver.cpp:218] Iteration 187100 (3.56605 iter/s, 28.0422s/100 iters), loss = 0.000262226
I0529 09:51:14.230690 11123 solver.cpp:237]     Train net output #0: loss = 0.000261363 (* 1 = 0.000261363 loss)
I0529 09:51:14.230700 11123 sgd_solver.cpp:105] Iteration 187100, lr = 0.000645
I0529 09:51:42.295044 11123 solver.cpp:218] Iteration 187200 (3.56334 iter/s, 28.0636s/100 iters), loss = 1.37022e-05
I0529 09:51:42.295090 11123 solver.cpp:237]     Train net output #0: loss = 1.28393e-05 (* 1 = 1.28393e-05 loss)
I0529 09:51:42.295099 11123 sgd_solver.cpp:105] Iteration 187200, lr = 0.00064
I0529 09:52:10.347160 11123 solver.cpp:218] Iteration 187300 (3.56492 iter/s, 28.0512s/100 iters), loss = 2.3565e-05
I0529 09:52:10.347280 11123 solver.cpp:237]     Train net output #0: loss = 2.27021e-05 (* 1 = 2.27021e-05 loss)
I0529 09:52:10.347293 11123 sgd_solver.cpp:105] Iteration 187300, lr = 0.000635
I0529 09:52:38.395627 11123 solver.cpp:218] Iteration 187400 (3.56539 iter/s, 28.0475s/100 iters), loss = 2.95053e-05
I0529 09:52:38.395674 11123 solver.cpp:237]     Train net output #0: loss = 2.86423e-05 (* 1 = 2.86423e-05 loss)
I0529 09:52:38.395684 11123 sgd_solver.cpp:105] Iteration 187400, lr = 0.00063
I0529 09:53:06.454408 11123 solver.cpp:218] Iteration 187500 (3.56406 iter/s, 28.0579s/100 iters), loss = 3.03258e-06
I0529 09:53:06.454588 11123 solver.cpp:237]     Train net output #0: loss = 2.16965e-06 (* 1 = 2.16965e-06 loss)
I0529 09:53:06.454601 11123 sgd_solver.cpp:105] Iteration 187500, lr = 0.000625
I0529 09:53:09.845546 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:53:34.529808 11123 solver.cpp:218] Iteration 187600 (3.56197 iter/s, 28.0744s/100 iters), loss = 7.25864e-06
I0529 09:53:34.529850 11123 solver.cpp:237]     Train net output #0: loss = 6.39566e-06 (* 1 = 6.39566e-06 loss)
I0529 09:53:34.529857 11123 sgd_solver.cpp:105] Iteration 187600, lr = 0.00062
I0529 09:54:02.579100 11123 solver.cpp:218] Iteration 187700 (3.56526 iter/s, 28.0484s/100 iters), loss = 7.2895e-05
I0529 09:54:02.579254 11123 solver.cpp:237]     Train net output #0: loss = 7.2032e-05 (* 1 = 7.2032e-05 loss)
I0529 09:54:02.579264 11123 sgd_solver.cpp:105] Iteration 187700, lr = 0.000615
I0529 09:54:30.631460 11123 solver.cpp:218] Iteration 187800 (3.56489 iter/s, 28.0514s/100 iters), loss = 2.06206e-05
I0529 09:54:30.631517 11123 solver.cpp:237]     Train net output #0: loss = 1.97577e-05 (* 1 = 1.97577e-05 loss)
I0529 09:54:30.631526 11123 sgd_solver.cpp:105] Iteration 187800, lr = 0.00061
I0529 09:54:58.686102 11123 solver.cpp:218] Iteration 187900 (3.56458 iter/s, 28.0538s/100 iters), loss = 1.84277e-05
I0529 09:54:58.686286 11123 solver.cpp:237]     Train net output #0: loss = 1.75647e-05 (* 1 = 1.75647e-05 loss)
I0529 09:54:58.686298 11123 sgd_solver.cpp:105] Iteration 187900, lr = 0.000605
I0529 09:55:26.478451 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_188000.caffemodel
I0529 09:55:27.044008 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_188000.solverstate
I0529 09:55:27.195418 11123 solver.cpp:330] Iteration 188000, Testing net (#0)
I0529 09:55:30.592744 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:55:31.658787 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 09:55:31.658836 11123 solver.cpp:397]     Test net output #1: loss = 0.263952 (* 1 = 0.263952 loss)
I0529 09:55:31.940274 11123 solver.cpp:218] Iteration 188000 (3.00724 iter/s, 33.253s/100 iters), loss = 1.22301e-05
I0529 09:55:31.940320 11123 solver.cpp:237]     Train net output #0: loss = 1.13671e-05 (* 1 = 1.13671e-05 loss)
I0529 09:55:31.940327 11123 sgd_solver.cpp:105] Iteration 188000, lr = 0.0006
I0529 09:56:00.014432 11123 solver.cpp:218] Iteration 188100 (3.5621 iter/s, 28.0733s/100 iters), loss = 1.74815e-05
I0529 09:56:00.014488 11123 solver.cpp:237]     Train net output #0: loss = 1.66184e-05 (* 1 = 1.66184e-05 loss)
I0529 09:56:00.014497 11123 sgd_solver.cpp:105] Iteration 188100, lr = 0.000595
I0529 09:56:07.049440 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:56:28.082314 11123 solver.cpp:218] Iteration 188200 (3.5629 iter/s, 28.067s/100 iters), loss = 8.22813e-05
I0529 09:56:28.082370 11123 solver.cpp:237]     Train net output #0: loss = 8.14183e-05 (* 1 = 8.14183e-05 loss)
I0529 09:56:28.082378 11123 sgd_solver.cpp:105] Iteration 188200, lr = 0.00059
I0529 09:56:56.171506 11123 solver.cpp:218] Iteration 188300 (3.56019 iter/s, 28.0884s/100 iters), loss = 4.67185e-06
I0529 09:56:56.171717 11123 solver.cpp:237]     Train net output #0: loss = 3.80878e-06 (* 1 = 3.80878e-06 loss)
I0529 09:56:56.171728 11123 sgd_solver.cpp:105] Iteration 188300, lr = 0.000585
I0529 09:57:24.254721 11123 solver.cpp:218] Iteration 188400 (3.56097 iter/s, 28.0822s/100 iters), loss = 2.45731e-05
I0529 09:57:24.254765 11123 solver.cpp:237]     Train net output #0: loss = 2.37098e-05 (* 1 = 2.37098e-05 loss)
I0529 09:57:24.254775 11123 sgd_solver.cpp:105] Iteration 188400, lr = 0.00058
I0529 09:57:52.341590 11123 solver.cpp:218] Iteration 188500 (3.56048 iter/s, 28.0861s/100 iters), loss = 0.000946843
I0529 09:57:52.341754 11123 solver.cpp:237]     Train net output #0: loss = 0.00094598 (* 1 = 0.00094598 loss)
I0529 09:57:52.341765 11123 sgd_solver.cpp:105] Iteration 188500, lr = 0.000575
I0529 09:58:20.413856 11123 solver.cpp:218] Iteration 188600 (3.56235 iter/s, 28.0714s/100 iters), loss = 2.61552e-06
I0529 09:58:20.413904 11123 solver.cpp:237]     Train net output #0: loss = 1.75239e-06 (* 1 = 1.75239e-06 loss)
I0529 09:58:20.413914 11123 sgd_solver.cpp:105] Iteration 188600, lr = 0.00057
I0529 09:58:48.492512 11123 solver.cpp:218] Iteration 188700 (3.56152 iter/s, 28.0779s/100 iters), loss = 4.18166e-05
I0529 09:58:48.492681 11123 solver.cpp:237]     Train net output #0: loss = 4.09535e-05 (* 1 = 4.09535e-05 loss)
I0529 09:58:48.492692 11123 sgd_solver.cpp:105] Iteration 188700, lr = 0.000565
I0529 09:58:59.176697 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:59:16.560586 11123 solver.cpp:218] Iteration 188800 (3.56288 iter/s, 28.0672s/100 iters), loss = 0.000291422
I0529 09:59:16.560636 11123 solver.cpp:237]     Train net output #0: loss = 0.000290558 (* 1 = 0.000290558 loss)
I0529 09:59:16.560644 11123 sgd_solver.cpp:105] Iteration 188800, lr = 0.00056
I0529 09:59:44.630256 11123 solver.cpp:218] Iteration 188900 (3.56266 iter/s, 28.0689s/100 iters), loss = 2.63971e-05
I0529 09:59:44.630483 11123 solver.cpp:237]     Train net output #0: loss = 2.5534e-05 (* 1 = 2.5534e-05 loss)
I0529 09:59:44.630496 11123 sgd_solver.cpp:105] Iteration 188900, lr = 0.000555
I0529 10:00:12.426348 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_189000.caffemodel
I0529 10:00:12.927870 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_189000.solverstate
I0529 10:00:13.077673 11123 solver.cpp:330] Iteration 189000, Testing net (#0)
I0529 10:00:17.508566 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 10:00:17.508687 11123 solver.cpp:397]     Test net output #1: loss = 0.228789 (* 1 = 0.228789 loss)
I0529 10:00:17.786386 11123 solver.cpp:218] Iteration 189000 (3.01613 iter/s, 33.1551s/100 iters), loss = 0.0013028
I0529 10:00:17.786444 11123 solver.cpp:237]     Train net output #0: loss = 0.00130194 (* 1 = 0.00130194 loss)
I0529 10:00:17.786456 11123 sgd_solver.cpp:105] Iteration 189000, lr = 0.00055
I0529 10:00:45.851442 11123 solver.cpp:218] Iteration 189100 (3.56325 iter/s, 28.0643s/100 iters), loss = 1.91665e-05
I0529 10:00:45.851507 11123 solver.cpp:237]     Train net output #0: loss = 1.83034e-05 (* 1 = 1.83034e-05 loss)
I0529 10:00:45.851516 11123 sgd_solver.cpp:105] Iteration 189100, lr = 0.000545
I0529 10:01:13.937379 11123 solver.cpp:218] Iteration 189200 (3.5606 iter/s, 28.0852s/100 iters), loss = 1.6474e-05
I0529 10:01:13.937556 11123 solver.cpp:237]     Train net output #0: loss = 1.56109e-05 (* 1 = 1.56109e-05 loss)
I0529 10:01:13.937582 11123 sgd_solver.cpp:105] Iteration 189200, lr = 0.00054
I0529 10:01:41.992035 11123 solver.cpp:218] Iteration 189300 (3.56458 iter/s, 28.0538s/100 iters), loss = 2.62737e-05
I0529 10:01:41.992102 11123 solver.cpp:237]     Train net output #0: loss = 2.54106e-05 (* 1 = 2.54106e-05 loss)
I0529 10:01:41.992115 11123 sgd_solver.cpp:105] Iteration 189300, lr = 0.000535
I0529 10:01:56.331377 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:02:10.072010 11123 solver.cpp:218] Iteration 189400 (3.56135 iter/s, 28.0792s/100 iters), loss = 3.56465e-05
I0529 10:02:10.072060 11123 solver.cpp:237]     Train net output #0: loss = 3.47834e-05 (* 1 = 3.47834e-05 loss)
I0529 10:02:10.072072 11123 sgd_solver.cpp:105] Iteration 189400, lr = 0.00053
I0529 10:02:38.119618 11123 solver.cpp:218] Iteration 189500 (3.56546 iter/s, 28.0469s/100 iters), loss = 1.26536e-05
I0529 10:02:38.119747 11123 solver.cpp:237]     Train net output #0: loss = 1.17905e-05 (* 1 = 1.17905e-05 loss)
I0529 10:02:38.119758 11123 sgd_solver.cpp:105] Iteration 189500, lr = 0.000525
I0529 10:03:06.181452 11123 solver.cpp:218] Iteration 189600 (3.56366 iter/s, 28.061s/100 iters), loss = 9.80914e-05
I0529 10:03:06.181509 11123 solver.cpp:237]     Train net output #0: loss = 9.72284e-05 (* 1 = 9.72284e-05 loss)
I0529 10:03:06.181517 11123 sgd_solver.cpp:105] Iteration 189600, lr = 0.00052
I0529 10:03:34.253657 11123 solver.cpp:218] Iteration 189700 (3.56233 iter/s, 28.0715s/100 iters), loss = 8.63562e-06
I0529 10:03:34.253813 11123 solver.cpp:237]     Train net output #0: loss = 7.77258e-06 (* 1 = 7.77258e-06 loss)
I0529 10:03:34.253825 11123 sgd_solver.cpp:105] Iteration 189700, lr = 0.000515
I0529 10:04:02.320119 11123 solver.cpp:218] Iteration 189800 (3.56307 iter/s, 28.0657s/100 iters), loss = 1.59735e-05
I0529 10:04:02.320165 11123 solver.cpp:237]     Train net output #0: loss = 1.51105e-05 (* 1 = 1.51105e-05 loss)
I0529 10:04:02.320174 11123 sgd_solver.cpp:105] Iteration 189800, lr = 0.00051
I0529 10:04:30.398730 11123 solver.cpp:218] Iteration 189900 (3.56152 iter/s, 28.0779s/100 iters), loss = 9.54619e-05
I0529 10:04:30.398905 11123 solver.cpp:237]     Train net output #0: loss = 9.45991e-05 (* 1 = 9.45991e-05 loss)
I0529 10:04:30.398916 11123 sgd_solver.cpp:105] Iteration 189900, lr = 0.000505
I0529 10:04:48.106043 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:04:58.198948 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_190000.caffemodel
I0529 10:04:58.666831 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_190000.solverstate
I0529 10:04:58.815513 11123 solver.cpp:330] Iteration 190000, Testing net (#0)
I0529 10:04:59.270164 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:05:03.279834 11123 solver.cpp:397]     Test net output #0: accuracy = 0.947
I0529 10:05:03.279999 11123 solver.cpp:397]     Test net output #1: loss = 0.235661 (* 1 = 0.235661 loss)
I0529 10:05:03.559227 11123 solver.cpp:218] Iteration 190000 (3.01572 iter/s, 33.1596s/100 iters), loss = 4.2612e-05
I0529 10:05:03.559275 11123 solver.cpp:237]     Train net output #0: loss = 4.17492e-05 (* 1 = 4.17492e-05 loss)
I0529 10:05:03.559284 11123 sgd_solver.cpp:105] Iteration 190000, lr = 0.0005
I0529 10:05:32.240344 11123 solver.cpp:218] Iteration 190100 (3.4867 iter/s, 28.6804s/100 iters), loss = 0.000107505
I0529 10:05:32.240386 11123 solver.cpp:237]     Train net output #0: loss = 0.000106642 (* 1 = 0.000106642 loss)
I0529 10:05:32.240396 11123 sgd_solver.cpp:105] Iteration 190100, lr = 0.000495
I0529 10:06:00.321874 11123 solver.cpp:218] Iteration 190200 (3.56115 iter/s, 28.0808s/100 iters), loss = 2.08787e-05
I0529 10:06:00.322033 11123 solver.cpp:237]     Train net output #0: loss = 2.00161e-05 (* 1 = 2.00161e-05 loss)
I0529 10:06:00.322044 11123 sgd_solver.cpp:105] Iteration 190200, lr = 0.00049
I0529 10:06:28.391955 11123 solver.cpp:218] Iteration 190300 (3.56261 iter/s, 28.0693s/100 iters), loss = 2.04707e-05
I0529 10:06:28.392014 11123 solver.cpp:237]     Train net output #0: loss = 1.96082e-05 (* 1 = 1.96082e-05 loss)
I0529 10:06:28.392022 11123 sgd_solver.cpp:105] Iteration 190300, lr = 0.000485
I0529 10:06:56.487133 11123 solver.cpp:218] Iteration 190400 (3.55942 iter/s, 28.0945s/100 iters), loss = 1.77853e-05
I0529 10:06:56.487298 11123 solver.cpp:237]     Train net output #0: loss = 1.69228e-05 (* 1 = 1.69228e-05 loss)
I0529 10:06:56.487313 11123 sgd_solver.cpp:105] Iteration 190400, lr = 0.00048
I0529 10:07:24.600766 11123 solver.cpp:218] Iteration 190500 (3.55709 iter/s, 28.1128s/100 iters), loss = 2.07571e-05
I0529 10:07:24.600818 11123 solver.cpp:237]     Train net output #0: loss = 1.98946e-05 (* 1 = 1.98946e-05 loss)
I0529 10:07:24.600826 11123 sgd_solver.cpp:105] Iteration 190500, lr = 0.000475
I0529 10:07:45.982383 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:07:52.705375 11123 solver.cpp:218] Iteration 190600 (3.55822 iter/s, 28.1039s/100 iters), loss = 7.19543e-05
I0529 10:07:52.705426 11123 solver.cpp:237]     Train net output #0: loss = 7.10918e-05 (* 1 = 7.10918e-05 loss)
I0529 10:07:52.705436 11123 sgd_solver.cpp:105] Iteration 190600, lr = 0.00047
I0529 10:08:20.816256 11123 solver.cpp:218] Iteration 190700 (3.55743 iter/s, 28.1102s/100 iters), loss = 1.86211e-05
I0529 10:08:20.816431 11123 solver.cpp:237]     Train net output #0: loss = 1.77586e-05 (* 1 = 1.77586e-05 loss)
I0529 10:08:20.816443 11123 sgd_solver.cpp:105] Iteration 190700, lr = 0.000465
I0529 10:08:48.913233 11123 solver.cpp:218] Iteration 190800 (3.5592 iter/s, 28.0962s/100 iters), loss = 0.0002494
I0529 10:08:48.913281 11123 solver.cpp:237]     Train net output #0: loss = 0.000248537 (* 1 = 0.000248537 loss)
I0529 10:08:48.913290 11123 sgd_solver.cpp:105] Iteration 190800, lr = 0.00046
I0529 10:09:17.007643 11123 solver.cpp:218] Iteration 190900 (3.55951 iter/s, 28.0937s/100 iters), loss = 1.48817e-05
I0529 10:09:17.007800 11123 solver.cpp:237]     Train net output #0: loss = 1.40193e-05 (* 1 = 1.40193e-05 loss)
I0529 10:09:17.007812 11123 sgd_solver.cpp:105] Iteration 190900, lr = 0.000455
I0529 10:09:44.856339 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_191000.caffemodel
I0529 10:09:45.254783 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_191000.solverstate
I0529 10:09:45.402681 11123 solver.cpp:330] Iteration 191000, Testing net (#0)
I0529 10:09:47.372452 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:09:49.855276 11123 solver.cpp:397]     Test net output #0: accuracy = 0.941
I0529 10:09:49.855311 11123 solver.cpp:397]     Test net output #1: loss = 0.234741 (* 1 = 0.234741 loss)
I0529 10:09:50.132936 11123 solver.cpp:218] Iteration 191000 (3.01892 iter/s, 33.1244s/100 iters), loss = 5.05805e-05
I0529 10:09:50.132993 11123 solver.cpp:237]     Train net output #0: loss = 4.97182e-05 (* 1 = 4.97182e-05 loss)
I0529 10:09:50.133002 11123 sgd_solver.cpp:105] Iteration 191000, lr = 0.00045
I0529 10:10:18.226591 11123 solver.cpp:218] Iteration 191100 (3.55961 iter/s, 28.093s/100 iters), loss = 8.30492e-05
I0529 10:10:18.226879 11123 solver.cpp:237]     Train net output #0: loss = 8.21868e-05 (* 1 = 8.21868e-05 loss)
I0529 10:10:18.226891 11123 sgd_solver.cpp:105] Iteration 191100, lr = 0.000445
I0529 10:10:43.264211 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:10:46.339709 11123 solver.cpp:218] Iteration 191200 (3.55717 iter/s, 28.1122s/100 iters), loss = 8.07056e-05
I0529 10:10:46.339772 11123 solver.cpp:237]     Train net output #0: loss = 7.98432e-05 (* 1 = 7.98432e-05 loss)
I0529 10:10:46.339781 11123 sgd_solver.cpp:105] Iteration 191200, lr = 0.00044
I0529 10:11:14.449165 11123 solver.cpp:218] Iteration 191300 (3.55761 iter/s, 28.1088s/100 iters), loss = 8.53373e-06
I0529 10:11:14.449331 11123 solver.cpp:237]     Train net output #0: loss = 7.67138e-06 (* 1 = 7.67138e-06 loss)
I0529 10:11:14.449343 11123 sgd_solver.cpp:105] Iteration 191300, lr = 0.000435
I0529 10:11:42.575848 11123 solver.cpp:218] Iteration 191400 (3.55544 iter/s, 28.1259s/100 iters), loss = 1.34575e-05
I0529 10:11:42.575892 11123 solver.cpp:237]     Train net output #0: loss = 1.2595e-05 (* 1 = 1.2595e-05 loss)
I0529 10:11:42.575901 11123 sgd_solver.cpp:105] Iteration 191400, lr = 0.00043
I0529 10:12:10.667732 11123 solver.cpp:218] Iteration 191500 (3.55983 iter/s, 28.0912s/100 iters), loss = 2.6863e-06
I0529 10:12:10.667950 11123 solver.cpp:237]     Train net output #0: loss = 1.82391e-06 (* 1 = 1.82391e-06 loss)
I0529 10:12:10.667973 11123 sgd_solver.cpp:105] Iteration 191500, lr = 0.000425
I0529 10:12:38.728363 11123 solver.cpp:218] Iteration 191600 (3.56382 iter/s, 28.0598s/100 iters), loss = 2.60662e-05
I0529 10:12:38.728410 11123 solver.cpp:237]     Train net output #0: loss = 2.52038e-05 (* 1 = 2.52038e-05 loss)
I0529 10:12:38.728420 11123 sgd_solver.cpp:105] Iteration 191600, lr = 0.00042
I0529 10:13:06.803866 11123 solver.cpp:218] Iteration 191700 (3.56191 iter/s, 28.0748s/100 iters), loss = 6.29136e-05
I0529 10:13:06.804028 11123 solver.cpp:237]     Train net output #0: loss = 6.20507e-05 (* 1 = 6.20507e-05 loss)
I0529 10:13:06.804039 11123 sgd_solver.cpp:105] Iteration 191700, lr = 0.000415
I0529 10:13:34.911888 11123 solver.cpp:218] Iteration 191800 (3.5578 iter/s, 28.1073s/100 iters), loss = 1.4513e-05
I0529 10:13:34.911944 11123 solver.cpp:237]     Train net output #0: loss = 1.365e-05 (* 1 = 1.365e-05 loss)
I0529 10:13:34.911955 11123 sgd_solver.cpp:105] Iteration 191800, lr = 0.00041
I0529 10:13:35.491400 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:14:03.009943 11123 solver.cpp:218] Iteration 191900 (3.55905 iter/s, 28.0974s/100 iters), loss = 4.05455e-05
I0529 10:14:03.010128 11123 solver.cpp:237]     Train net output #0: loss = 3.96825e-05 (* 1 = 3.96825e-05 loss)
I0529 10:14:03.010139 11123 sgd_solver.cpp:105] Iteration 191900, lr = 0.000405
I0529 10:14:30.819654 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_192000.caffemodel
I0529 10:14:31.458505 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_192000.solverstate
I0529 10:14:31.607127 11123 solver.cpp:330] Iteration 192000, Testing net (#0)
I0529 10:14:35.092679 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:14:36.069130 11123 solver.cpp:397]     Test net output #0: accuracy = 0.944
I0529 10:14:36.069182 11123 solver.cpp:397]     Test net output #1: loss = 0.262966 (* 1 = 0.262966 loss)
I0529 10:14:36.347190 11123 solver.cpp:218] Iteration 192000 (2.99973 iter/s, 33.3364s/100 iters), loss = 3.63491e-05
I0529 10:14:36.347246 11123 solver.cpp:237]     Train net output #0: loss = 3.54861e-05 (* 1 = 3.54861e-05 loss)
I0529 10:14:36.347255 11123 sgd_solver.cpp:105] Iteration 192000, lr = 0.0004
I0529 10:15:04.452093 11123 solver.cpp:218] Iteration 192100 (3.55818 iter/s, 28.1042s/100 iters), loss = 3.78531e-05
I0529 10:15:04.452147 11123 solver.cpp:237]     Train net output #0: loss = 3.69901e-05 (* 1 = 3.69901e-05 loss)
I0529 10:15:04.452155 11123 sgd_solver.cpp:105] Iteration 192100, lr = 0.000395
I0529 10:15:32.549304 11123 solver.cpp:218] Iteration 192200 (3.55916 iter/s, 28.0966s/100 iters), loss = 9.25953e-05
I0529 10:15:32.549609 11123 solver.cpp:237]     Train net output #0: loss = 9.17324e-05 (* 1 = 9.17324e-05 loss)
I0529 10:15:32.549621 11123 sgd_solver.cpp:105] Iteration 192200, lr = 0.00039
I0529 10:16:00.646443 11123 solver.cpp:218] Iteration 192300 (3.5592 iter/s, 28.0962s/100 iters), loss = 0.000386485
I0529 10:16:00.646502 11123 solver.cpp:237]     Train net output #0: loss = 0.000385622 (* 1 = 0.000385622 loss)
I0529 10:16:00.646512 11123 sgd_solver.cpp:105] Iteration 192300, lr = 0.000385
I0529 10:16:28.728206 11123 solver.cpp:218] Iteration 192400 (3.56111 iter/s, 28.0811s/100 iters), loss = 3.85512e-06
I0529 10:16:28.728374 11123 solver.cpp:237]     Train net output #0: loss = 2.99218e-06 (* 1 = 2.99218e-06 loss)
I0529 10:16:28.728386 11123 sgd_solver.cpp:105] Iteration 192400, lr = 0.00038
I0529 10:16:32.959877 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:16:56.826035 11123 solver.cpp:218] Iteration 192500 (3.55909 iter/s, 28.0971s/100 iters), loss = 3.90313e-05
I0529 10:16:56.826084 11123 solver.cpp:237]     Train net output #0: loss = 3.81683e-05 (* 1 = 3.81683e-05 loss)
I0529 10:16:56.826092 11123 sgd_solver.cpp:105] Iteration 192500, lr = 0.000375
I0529 10:17:24.908118 11123 solver.cpp:218] Iteration 192600 (3.56107 iter/s, 28.0814s/100 iters), loss = 9.92345e-06
I0529 10:17:24.908357 11123 solver.cpp:237]     Train net output #0: loss = 9.06044e-06 (* 1 = 9.06044e-06 loss)
I0529 10:17:24.908370 11123 sgd_solver.cpp:105] Iteration 192600, lr = 0.00037
I0529 10:17:53.009887 11123 solver.cpp:218] Iteration 192700 (3.5586 iter/s, 28.1009s/100 iters), loss = 0.000110012
I0529 10:17:53.009937 11123 solver.cpp:237]     Train net output #0: loss = 0.000109148 (* 1 = 0.000109148 loss)
I0529 10:17:53.009945 11123 sgd_solver.cpp:105] Iteration 192700, lr = 0.000365
I0529 10:18:21.114503 11123 solver.cpp:218] Iteration 192800 (3.55822 iter/s, 28.104s/100 iters), loss = 2.22232e-05
I0529 10:18:21.114661 11123 solver.cpp:237]     Train net output #0: loss = 2.13599e-05 (* 1 = 2.13599e-05 loss)
I0529 10:18:21.114672 11123 sgd_solver.cpp:105] Iteration 192800, lr = 0.00036
I0529 10:18:49.187518 11123 solver.cpp:218] Iteration 192900 (3.56223 iter/s, 28.0723s/100 iters), loss = 9.34544e-05
I0529 10:18:49.187564 11123 solver.cpp:237]     Train net output #0: loss = 9.25913e-05 (* 1 = 9.25913e-05 loss)
I0529 10:18:49.187573 11123 sgd_solver.cpp:105] Iteration 192900, lr = 0.000355
I0529 10:19:16.971027 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_193000.caffemodel
I0529 10:19:17.642171 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_193000.solverstate
I0529 10:19:17.791124 11123 solver.cpp:330] Iteration 193000, Testing net (#0)
I0529 10:19:22.262763 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 10:19:22.262800 11123 solver.cpp:397]     Test net output #1: loss = 0.217072 (* 1 = 0.217072 loss)
I0529 10:19:22.539147 11123 solver.cpp:218] Iteration 193000 (2.99842 iter/s, 33.3509s/100 iters), loss = 9.35103e-05
I0529 10:19:22.539191 11123 solver.cpp:237]     Train net output #0: loss = 9.26472e-05 (* 1 = 9.26472e-05 loss)
I0529 10:19:22.539199 11123 sgd_solver.cpp:105] Iteration 193000, lr = 0.00035
I0529 10:19:30.146314 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:19:50.633713 11123 solver.cpp:218] Iteration 193100 (3.55949 iter/s, 28.0939s/100 iters), loss = 2.50225e-06
I0529 10:19:50.633882 11123 solver.cpp:237]     Train net output #0: loss = 1.63913e-06 (* 1 = 1.63913e-06 loss)
I0529 10:19:50.633894 11123 sgd_solver.cpp:105] Iteration 193100, lr = 0.000345
I0529 10:20:18.735189 11123 solver.cpp:218] Iteration 193200 (3.55863 iter/s, 28.1007s/100 iters), loss = 2.95302e-05
I0529 10:20:18.735249 11123 solver.cpp:237]     Train net output #0: loss = 2.86672e-05 (* 1 = 2.86672e-05 loss)
I0529 10:20:18.735257 11123 sgd_solver.cpp:105] Iteration 193200, lr = 0.00034
I0529 10:20:46.810063 11123 solver.cpp:218] Iteration 193300 (3.56199 iter/s, 28.0742s/100 iters), loss = 0.000220575
I0529 10:20:46.810233 11123 solver.cpp:237]     Train net output #0: loss = 0.000219712 (* 1 = 0.000219712 loss)
I0529 10:20:46.810245 11123 sgd_solver.cpp:105] Iteration 193300, lr = 0.000335
I0529 10:21:14.891533 11123 solver.cpp:218] Iteration 193400 (3.56116 iter/s, 28.0807s/100 iters), loss = 5.0355e-06
I0529 10:21:14.891587 11123 solver.cpp:237]     Train net output #0: loss = 4.17237e-06 (* 1 = 4.17237e-06 loss)
I0529 10:21:14.891598 11123 sgd_solver.cpp:105] Iteration 193400, lr = 0.00033
I0529 10:21:42.966059 11123 solver.cpp:218] Iteration 193500 (3.56203 iter/s, 28.0739s/100 iters), loss = 1.25163e-05
I0529 10:21:42.966243 11123 solver.cpp:237]     Train net output #0: loss = 1.16531e-05 (* 1 = 1.16531e-05 loss)
I0529 10:21:42.966254 11123 sgd_solver.cpp:105] Iteration 193500, lr = 0.000325
I0529 10:22:11.036341 11123 solver.cpp:218] Iteration 193600 (3.56258 iter/s, 28.0695s/100 iters), loss = 9.09037e-05
I0529 10:22:11.036388 11123 solver.cpp:237]     Train net output #0: loss = 9.00405e-05 (* 1 = 9.00405e-05 loss)
I0529 10:22:11.036397 11123 sgd_solver.cpp:105] Iteration 193600, lr = 0.00032
I0529 10:22:22.285786 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:22:39.100800 11123 solver.cpp:218] Iteration 193700 (3.56331 iter/s, 28.0638s/100 iters), loss = 3.67056e-06
I0529 10:22:39.100847 11123 solver.cpp:237]     Train net output #0: loss = 2.8074e-06 (* 1 = 2.8074e-06 loss)
I0529 10:22:39.100854 11123 sgd_solver.cpp:105] Iteration 193700, lr = 0.000315
I0529 10:23:07.173223 11123 solver.cpp:218] Iteration 193800 (3.56229 iter/s, 28.0718s/100 iters), loss = 8.93973e-06
I0529 10:23:07.173342 11123 solver.cpp:237]     Train net output #0: loss = 8.07661e-06 (* 1 = 8.07661e-06 loss)
I0529 10:23:07.173362 11123 sgd_solver.cpp:105] Iteration 193800, lr = 0.00031
I0529 10:23:35.256068 11123 solver.cpp:218] Iteration 193900 (3.56098 iter/s, 28.0821s/100 iters), loss = 3.41798e-05
I0529 10:23:35.256109 11123 solver.cpp:237]     Train net output #0: loss = 3.33167e-05 (* 1 = 3.33167e-05 loss)
I0529 10:23:35.256119 11123 sgd_solver.cpp:105] Iteration 193900, lr = 0.000305
I0529 10:24:03.095238 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_194000.caffemodel
I0529 10:24:03.658187 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_194000.solverstate
I0529 10:24:03.807488 11123 solver.cpp:330] Iteration 194000, Testing net (#0)
I0529 10:24:04.349416 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:24:08.270776 11123 solver.cpp:397]     Test net output #0: accuracy = 0.945
I0529 10:24:08.270817 11123 solver.cpp:397]     Test net output #1: loss = 0.249515 (* 1 = 0.249515 loss)
I0529 10:24:08.550465 11123 solver.cpp:218] Iteration 194000 (3.00357 iter/s, 33.2937s/100 iters), loss = 2.76968e-05
I0529 10:24:08.550513 11123 solver.cpp:237]     Train net output #0: loss = 2.68335e-05 (* 1 = 2.68335e-05 loss)
I0529 10:24:08.550520 11123 sgd_solver.cpp:105] Iteration 194000, lr = 0.0003
I0529 10:24:36.630259 11123 solver.cpp:218] Iteration 194100 (3.56136 iter/s, 28.0791s/100 iters), loss = 8.18312e-06
I0529 10:24:36.630455 11123 solver.cpp:237]     Train net output #0: loss = 7.31988e-06 (* 1 = 7.31988e-06 loss)
I0529 10:24:36.630471 11123 sgd_solver.cpp:105] Iteration 194100, lr = 0.000295
I0529 10:25:04.712182 11123 solver.cpp:218] Iteration 194200 (3.56111 iter/s, 28.0811s/100 iters), loss = 4.61237e-05
I0529 10:25:04.712247 11123 solver.cpp:237]     Train net output #0: loss = 4.52605e-05 (* 1 = 4.52605e-05 loss)
I0529 10:25:04.712272 11123 sgd_solver.cpp:105] Iteration 194200, lr = 0.00029
I0529 10:25:19.617235 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:25:32.814319 11123 solver.cpp:218] Iteration 194300 (3.55853 iter/s, 28.1015s/100 iters), loss = 2.34545e-05
I0529 10:25:32.814371 11123 solver.cpp:237]     Train net output #0: loss = 2.25911e-05 (* 1 = 2.25911e-05 loss)
I0529 10:25:32.814383 11123 sgd_solver.cpp:105] Iteration 194300, lr = 0.000285
I0529 10:26:00.918624 11123 solver.cpp:218] Iteration 194400 (3.55824 iter/s, 28.1038s/100 iters), loss = 3.45201e-05
I0529 10:26:00.918792 11123 solver.cpp:237]     Train net output #0: loss = 3.36567e-05 (* 1 = 3.36567e-05 loss)
I0529 10:26:00.918803 11123 sgd_solver.cpp:105] Iteration 194400, lr = 0.00028
I0529 10:26:29.010540 11123 solver.cpp:218] Iteration 194500 (3.55982 iter/s, 28.0913s/100 iters), loss = 6.08488e-06
I0529 10:26:29.010596 11123 solver.cpp:237]     Train net output #0: loss = 5.22143e-06 (* 1 = 5.22143e-06 loss)
I0529 10:26:29.010607 11123 sgd_solver.cpp:105] Iteration 194500, lr = 0.000275
I0529 10:26:57.122395 11123 solver.cpp:218] Iteration 194600 (3.55728 iter/s, 28.1113s/100 iters), loss = 2.03866e-05
I0529 10:26:57.122611 11123 solver.cpp:237]     Train net output #0: loss = 1.95231e-05 (* 1 = 1.95231e-05 loss)
I0529 10:26:57.122623 11123 sgd_solver.cpp:105] Iteration 194600, lr = 0.00027
I0529 10:27:25.214509 11123 solver.cpp:218] Iteration 194700 (3.5598 iter/s, 28.0914s/100 iters), loss = 7.81964e-06
I0529 10:27:25.214556 11123 solver.cpp:237]     Train net output #0: loss = 6.95604e-06 (* 1 = 6.95604e-06 loss)
I0529 10:27:25.214565 11123 sgd_solver.cpp:105] Iteration 194700, lr = 0.000265
I0529 10:27:53.301746 11123 solver.cpp:218] Iteration 194800 (3.5604 iter/s, 28.0867s/100 iters), loss = 1.94415e-05
I0529 10:27:53.301906 11123 solver.cpp:237]     Train net output #0: loss = 1.85779e-05 (* 1 = 1.85779e-05 loss)
I0529 10:27:53.301918 11123 sgd_solver.cpp:105] Iteration 194800, lr = 0.00026
I0529 10:28:11.863950 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:28:21.398279 11123 solver.cpp:218] Iteration 194900 (3.55924 iter/s, 28.0959s/100 iters), loss = 0.000107364
I0529 10:28:21.398324 11123 solver.cpp:237]     Train net output #0: loss = 0.0001065 (* 1 = 0.0001065 loss)
I0529 10:28:21.398334 11123 sgd_solver.cpp:105] Iteration 194900, lr = 0.000255
I0529 10:28:49.230257 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_195000.caffemodel
I0529 10:28:49.750404 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_195000.solverstate
I0529 10:28:49.899546 11123 solver.cpp:330] Iteration 195000, Testing net (#0)
I0529 10:28:51.955965 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:28:54.359989 11123 solver.cpp:397]     Test net output #0: accuracy = 0.941
I0529 10:28:54.360023 11123 solver.cpp:397]     Test net output #1: loss = 0.235066 (* 1 = 0.235066 loss)
I0529 10:28:54.639717 11123 solver.cpp:218] Iteration 195000 (3.00835 iter/s, 33.2408s/100 iters), loss = 7.99266e-06
I0529 10:28:54.639775 11123 solver.cpp:237]     Train net output #0: loss = 7.12909e-06 (* 1 = 7.12909e-06 loss)
I0529 10:28:54.639785 11123 sgd_solver.cpp:105] Iteration 195000, lr = 0.00025
I0529 10:29:22.738488 11123 solver.cpp:218] Iteration 195100 (3.55894 iter/s, 28.0982s/100 iters), loss = 7.34373e-05
I0529 10:29:22.738674 11123 solver.cpp:237]     Train net output #0: loss = 7.25738e-05 (* 1 = 7.25738e-05 loss)
I0529 10:29:22.738685 11123 sgd_solver.cpp:105] Iteration 195100, lr = 0.000245
I0529 10:29:50.878072 11123 solver.cpp:218] Iteration 195200 (3.5538 iter/s, 28.1389s/100 iters), loss = 2.26468e-06
I0529 10:29:50.878127 11123 solver.cpp:237]     Train net output #0: loss = 1.40071e-06 (* 1 = 1.40071e-06 loss)
I0529 10:29:50.878136 11123 sgd_solver.cpp:105] Iteration 195200, lr = 0.00024
I0529 10:30:19.089133 11123 solver.cpp:218] Iteration 195300 (3.54478 iter/s, 28.2105s/100 iters), loss = 0.00513328
I0529 10:30:19.089340 11123 solver.cpp:237]     Train net output #0: loss = 0.00513242 (* 1 = 0.00513242 loss)
I0529 10:30:19.089352 11123 sgd_solver.cpp:105] Iteration 195300, lr = 0.000235
I0529 10:30:47.276244 11123 solver.cpp:218] Iteration 195400 (3.54781 iter/s, 28.1864s/100 iters), loss = 8.93214e-05
I0529 10:30:47.276302 11123 solver.cpp:237]     Train net output #0: loss = 8.84577e-05 (* 1 = 8.84577e-05 loss)
I0529 10:30:47.276311 11123 sgd_solver.cpp:105] Iteration 195400, lr = 0.00023
I0529 10:31:10.240437 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:31:16.116571 11123 solver.cpp:218] Iteration 195500 (3.46744 iter/s, 28.8397s/100 iters), loss = 5.35665e-05
I0529 10:31:16.116621 11123 solver.cpp:237]     Train net output #0: loss = 5.27027e-05 (* 1 = 5.27027e-05 loss)
I0529 10:31:16.116629 11123 sgd_solver.cpp:105] Iteration 195500, lr = 0.000225
I0529 10:31:44.170922 11123 solver.cpp:218] Iteration 195600 (3.56458 iter/s, 28.0538s/100 iters), loss = 7.45033e-06
I0529 10:31:44.171070 11123 solver.cpp:237]     Train net output #0: loss = 6.58655e-06 (* 1 = 6.58655e-06 loss)
I0529 10:31:44.171082 11123 sgd_solver.cpp:105] Iteration 195600, lr = 0.00022
I0529 10:32:12.233847 11123 solver.cpp:218] Iteration 195700 (3.5635 iter/s, 28.0623s/100 iters), loss = 0.000202946
I0529 10:32:12.233891 11123 solver.cpp:237]     Train net output #0: loss = 0.000202082 (* 1 = 0.000202082 loss)
I0529 10:32:12.233898 11123 sgd_solver.cpp:105] Iteration 195700, lr = 0.000215
I0529 10:32:40.272723 11123 solver.cpp:218] Iteration 195800 (3.56655 iter/s, 28.0383s/100 iters), loss = 1.14797e-05
I0529 10:32:40.272843 11123 solver.cpp:237]     Train net output #0: loss = 1.0616e-05 (* 1 = 1.0616e-05 loss)
I0529 10:32:40.272853 11123 sgd_solver.cpp:105] Iteration 195800, lr = 0.00021
I0529 10:33:08.321307 11123 solver.cpp:218] Iteration 195900 (3.56532 iter/s, 28.0479s/100 iters), loss = 7.10444e-06
I0529 10:33:08.321358 11123 solver.cpp:237]     Train net output #0: loss = 6.24088e-06 (* 1 = 6.24088e-06 loss)
I0529 10:33:08.321367 11123 sgd_solver.cpp:105] Iteration 195900, lr = 0.000205
I0529 10:33:36.262337 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_196000.caffemodel
I0529 10:33:36.835667 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_196000.solverstate
I0529 10:33:36.985580 11123 solver.cpp:330] Iteration 196000, Testing net (#0)
I0529 10:33:40.556625 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:33:41.445503 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 10:33:41.445555 11123 solver.cpp:397]     Test net output #1: loss = 0.265627 (* 1 = 0.265627 loss)
I0529 10:33:41.724197 11123 solver.cpp:218] Iteration 196000 (2.99381 iter/s, 33.4022s/100 iters), loss = 8.2845e-06
I0529 10:33:41.724241 11123 solver.cpp:237]     Train net output #0: loss = 7.42093e-06 (* 1 = 7.42093e-06 loss)
I0529 10:33:41.724249 11123 sgd_solver.cpp:105] Iteration 196000, lr = 0.0002
I0529 10:34:07.294667 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:34:09.800480 11123 solver.cpp:218] Iteration 196100 (3.5618 iter/s, 28.0757s/100 iters), loss = 1.63651e-05
I0529 10:34:09.800523 11123 solver.cpp:237]     Train net output #0: loss = 1.55016e-05 (* 1 = 1.55016e-05 loss)
I0529 10:34:09.800532 11123 sgd_solver.cpp:105] Iteration 196100, lr = 0.000195
I0529 10:34:37.831328 11123 solver.cpp:218] Iteration 196200 (3.56757 iter/s, 28.0303s/100 iters), loss = 4.68628e-05
I0529 10:34:37.831514 11123 solver.cpp:237]     Train net output #0: loss = 4.59992e-05 (* 1 = 4.59992e-05 loss)
I0529 10:34:37.831526 11123 sgd_solver.cpp:105] Iteration 196200, lr = 0.00019
I0529 10:35:06.091537 11123 solver.cpp:218] Iteration 196300 (3.53863 iter/s, 28.2595s/100 iters), loss = 6.03331e-05
I0529 10:35:06.091589 11123 solver.cpp:237]     Train net output #0: loss = 5.94696e-05 (* 1 = 5.94696e-05 loss)
I0529 10:35:06.091598 11123 sgd_solver.cpp:105] Iteration 196300, lr = 0.000185
I0529 10:35:34.282421 11123 solver.cpp:218] Iteration 196400 (3.54732 iter/s, 28.1903s/100 iters), loss = 7.22334e-05
I0529 10:35:34.282658 11123 solver.cpp:237]     Train net output #0: loss = 7.13708e-05 (* 1 = 7.13708e-05 loss)
I0529 10:35:34.282670 11123 sgd_solver.cpp:105] Iteration 196400, lr = 0.00018
I0529 10:36:02.337218 11123 solver.cpp:218] Iteration 196500 (3.56455 iter/s, 28.054s/100 iters), loss = 1.11571e-05
I0529 10:36:02.337260 11123 solver.cpp:237]     Train net output #0: loss = 1.02945e-05 (* 1 = 1.02945e-05 loss)
I0529 10:36:02.337267 11123 sgd_solver.cpp:105] Iteration 196500, lr = 0.000175
I0529 10:36:30.768896 11123 solver.cpp:218] Iteration 196600 (3.51728 iter/s, 28.4311s/100 iters), loss = 6.30452e-06
I0529 10:36:30.769122 11123 solver.cpp:237]     Train net output #0: loss = 5.44202e-06 (* 1 = 5.44202e-06 loss)
I0529 10:36:30.769134 11123 sgd_solver.cpp:105] Iteration 196600, lr = 0.00017
I0529 10:36:59.485497 11123 solver.cpp:218] Iteration 196700 (3.4824 iter/s, 28.7158s/100 iters), loss = 2.72865e-05
I0529 10:36:59.485541 11123 solver.cpp:237]     Train net output #0: loss = 2.6424e-05 (* 1 = 2.6424e-05 loss)
I0529 10:36:59.485550 11123 sgd_solver.cpp:105] Iteration 196700, lr = 0.000165
I0529 10:37:00.632055 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:37:27.955750 11123 solver.cpp:218] Iteration 196800 (3.51251 iter/s, 28.4697s/100 iters), loss = 3.5089e-06
I0529 10:37:27.955965 11123 solver.cpp:237]     Train net output #0: loss = 2.64651e-06 (* 1 = 2.64651e-06 loss)
I0529 10:37:27.955986 11123 sgd_solver.cpp:105] Iteration 196800, lr = 0.00016
I0529 10:37:56.538583 11123 solver.cpp:218] Iteration 196900 (3.4987 iter/s, 28.582s/100 iters), loss = 2.4361e-05
I0529 10:37:56.538652 11123 solver.cpp:237]     Train net output #0: loss = 2.34988e-05 (* 1 = 2.34988e-05 loss)
I0529 10:37:56.538661 11123 sgd_solver.cpp:105] Iteration 196900, lr = 0.000155
I0529 10:38:24.741413 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_197000.caffemodel
I0529 10:38:25.138559 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_197000.solverstate
I0529 10:38:25.286407 11123 solver.cpp:330] Iteration 197000, Testing net (#0)
I0529 10:38:29.743389 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 10:38:29.743428 11123 solver.cpp:397]     Test net output #1: loss = 0.211901 (* 1 = 0.211901 loss)
I0529 10:38:30.023317 11123 solver.cpp:218] Iteration 197000 (2.9865 iter/s, 33.484s/100 iters), loss = 3.66158e-05
I0529 10:38:30.023372 11123 solver.cpp:237]     Train net output #0: loss = 3.57537e-05 (* 1 = 3.57537e-05 loss)
I0529 10:38:30.023381 11123 sgd_solver.cpp:105] Iteration 197000, lr = 0.00015
I0529 10:38:59.092363 11123 solver.cpp:218] Iteration 197100 (3.44016 iter/s, 29.0684s/100 iters), loss = 0.000140433
I0529 10:38:59.132167 11123 solver.cpp:237]     Train net output #0: loss = 0.00013957 (* 1 = 0.00013957 loss)
I0529 10:38:59.132206 11123 sgd_solver.cpp:105] Iteration 197100, lr = 0.000145
I0529 10:39:27.608945 11123 solver.cpp:218] Iteration 197200 (3.5117 iter/s, 28.4762s/100 iters), loss = 6.22676e-06
I0529 10:39:27.609012 11123 solver.cpp:237]     Train net output #0: loss = 5.3645e-06 (* 1 = 5.3645e-06 loss)
I0529 10:39:27.609024 11123 sgd_solver.cpp:105] Iteration 197200, lr = 0.00014
I0529 10:39:56.393144 11123 solver.cpp:218] Iteration 197300 (3.4742 iter/s, 28.7836s/100 iters), loss = 2.5756e-05
I0529 10:39:56.393342 11123 solver.cpp:237]     Train net output #0: loss = 2.48938e-05 (* 1 = 2.48938e-05 loss)
I0529 10:39:56.393354 11123 sgd_solver.cpp:105] Iteration 197300, lr = 0.000135
I0529 10:40:01.354598 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:40:25.081286 11123 solver.cpp:218] Iteration 197400 (3.48585 iter/s, 28.6874s/100 iters), loss = 0.000324054
I0529 10:40:25.081341 11123 solver.cpp:237]     Train net output #0: loss = 0.000323192 (* 1 = 0.000323192 loss)
I0529 10:40:25.081351 11123 sgd_solver.cpp:105] Iteration 197400, lr = 0.00013
I0529 10:40:53.481927 11123 solver.cpp:218] Iteration 197500 (3.52112 iter/s, 28.4s/100 iters), loss = 3.33824e-05
I0529 10:40:53.482133 11123 solver.cpp:237]     Train net output #0: loss = 3.25203e-05 (* 1 = 3.25203e-05 loss)
I0529 10:40:53.482146 11123 sgd_solver.cpp:105] Iteration 197500, lr = 0.000125
I0529 10:41:22.261396 11123 solver.cpp:218] Iteration 197600 (3.47479 iter/s, 28.7787s/100 iters), loss = 7.15074e-05
I0529 10:41:22.261445 11123 solver.cpp:237]     Train net output #0: loss = 7.06453e-05 (* 1 = 7.06453e-05 loss)
I0529 10:41:22.261453 11123 sgd_solver.cpp:105] Iteration 197600, lr = 0.00012
I0529 10:41:50.398603 11123 solver.cpp:218] Iteration 197700 (3.55409 iter/s, 28.1366s/100 iters), loss = 5.32648e-06
I0529 10:41:50.398771 11123 solver.cpp:237]     Train net output #0: loss = 4.46444e-06 (* 1 = 4.46444e-06 loss)
I0529 10:41:50.398785 11123 sgd_solver.cpp:105] Iteration 197700, lr = 0.000115
I0529 10:42:19.268944 11123 solver.cpp:218] Iteration 197800 (3.46385 iter/s, 28.8696s/100 iters), loss = 2.51148e-05
I0529 10:42:19.268997 11123 solver.cpp:237]     Train net output #0: loss = 2.42528e-05 (* 1 = 2.42528e-05 loss)
I0529 10:42:19.269006 11123 sgd_solver.cpp:105] Iteration 197800, lr = 0.00011
I0529 10:42:47.782531 11123 solver.cpp:218] Iteration 197900 (3.50718 iter/s, 28.5129s/100 iters), loss = 1.53882e-05
I0529 10:42:47.782714 11123 solver.cpp:237]     Train net output #0: loss = 1.45262e-05 (* 1 = 1.45262e-05 loss)
I0529 10:42:47.782742 11123 sgd_solver.cpp:105] Iteration 197900, lr = 0.000105
I0529 10:42:56.365948 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:43:15.795097 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_198000.caffemodel
I0529 10:43:16.173806 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_198000.solverstate
I0529 10:43:16.320297 11123 solver.cpp:330] Iteration 198000, Testing net (#0)
I0529 10:43:16.950798 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:43:20.784646 11123 solver.cpp:397]     Test net output #0: accuracy = 0.946
I0529 10:43:20.784791 11123 solver.cpp:397]     Test net output #1: loss = 0.244524 (* 1 = 0.244524 loss)
I0529 10:43:21.062974 11123 solver.cpp:218] Iteration 198000 (3.00484 iter/s, 33.2796s/100 iters), loss = 5.31854e-05
I0529 10:43:21.063019 11123 solver.cpp:237]     Train net output #0: loss = 5.23233e-05 (* 1 = 5.23233e-05 loss)
I0529 10:43:21.063029 11123 sgd_solver.cpp:105] Iteration 198000, lr = 9.99999e-05
I0529 10:43:49.368602 11123 solver.cpp:218] Iteration 198100 (3.53294 iter/s, 28.305s/100 iters), loss = 1.96837e-05
I0529 10:43:49.368654 11123 solver.cpp:237]     Train net output #0: loss = 1.88216e-05 (* 1 = 1.88216e-05 loss)
I0529 10:43:49.368664 11123 sgd_solver.cpp:105] Iteration 198100, lr = 9.50003e-05
I0529 10:44:18.026126 11123 solver.cpp:218] Iteration 198200 (3.48956 iter/s, 28.6569s/100 iters), loss = 4.69132e-05
I0529 10:44:18.026293 11123 solver.cpp:237]     Train net output #0: loss = 4.6051e-05 (* 1 = 4.6051e-05 loss)
I0529 10:44:18.026304 11123 sgd_solver.cpp:105] Iteration 198200, lr = 9e-05
I0529 10:44:46.306469 11123 solver.cpp:218] Iteration 198300 (3.53612 iter/s, 28.2796s/100 iters), loss = 2.63765e-05
I0529 10:44:46.306530 11123 solver.cpp:237]     Train net output #0: loss = 2.55143e-05 (* 1 = 2.55143e-05 loss)
I0529 10:44:46.306540 11123 sgd_solver.cpp:105] Iteration 198300, lr = 8.49998e-05
I0529 10:45:14.721381 11123 solver.cpp:218] Iteration 198400 (3.51936 iter/s, 28.4143s/100 iters), loss = 2.279e-05
I0529 10:45:14.721576 11123 solver.cpp:237]     Train net output #0: loss = 2.19276e-05 (* 1 = 2.19276e-05 loss)
I0529 10:45:14.721591 11123 sgd_solver.cpp:105] Iteration 198400, lr = 8.00002e-05
I0529 10:45:43.066586 11123 solver.cpp:218] Iteration 198500 (3.52802 iter/s, 28.3445s/100 iters), loss = 1.8576e-06
I0529 10:45:43.066645 11123 solver.cpp:237]     Train net output #0: loss = 9.954e-07 (* 1 = 9.954e-07 loss)
I0529 10:45:43.066654 11123 sgd_solver.cpp:105] Iteration 198500, lr = 7.49999e-05
I0529 10:45:55.186962 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:46:11.212496 11123 solver.cpp:218] Iteration 198600 (3.55299 iter/s, 28.1453s/100 iters), loss = 7.79621e-05
I0529 10:46:11.212561 11123 solver.cpp:237]     Train net output #0: loss = 7.70999e-05 (* 1 = 7.70999e-05 loss)
I0529 10:46:11.212571 11123 sgd_solver.cpp:105] Iteration 198600, lr = 7.00003e-05
I0529 10:46:39.338858 11123 solver.cpp:218] Iteration 198700 (3.55546 iter/s, 28.1257s/100 iters), loss = 0.000997125
I0529 10:46:39.339018 11123 solver.cpp:237]     Train net output #0: loss = 0.000996263 (* 1 = 0.000996263 loss)
I0529 10:46:39.339030 11123 sgd_solver.cpp:105] Iteration 198700, lr = 6.50001e-05
I0529 10:47:07.678068 11123 solver.cpp:218] Iteration 198800 (3.52877 iter/s, 28.3385s/100 iters), loss = 2.94382e-05
I0529 10:47:07.678115 11123 solver.cpp:237]     Train net output #0: loss = 2.8576e-05 (* 1 = 2.8576e-05 loss)
I0529 10:47:07.678124 11123 sgd_solver.cpp:105] Iteration 198800, lr = 5.99998e-05
I0529 10:47:36.087262 11123 solver.cpp:218] Iteration 198900 (3.52006 iter/s, 28.4086s/100 iters), loss = 7.74088e-06
I0529 10:47:36.087359 11123 solver.cpp:237]     Train net output #0: loss = 6.87869e-06 (* 1 = 6.87869e-06 loss)
I0529 10:47:36.087370 11123 sgd_solver.cpp:105] Iteration 198900, lr = 5.50002e-05
I0529 10:48:04.166685 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_199000.caffemodel
I0529 10:48:04.582823 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_199000.solverstate
I0529 10:48:04.733016 11123 solver.cpp:330] Iteration 199000, Testing net (#0)
I0529 10:48:06.900017 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:48:09.219987 11123 solver.cpp:397]     Test net output #0: accuracy = 0.942
I0529 10:48:09.220023 11123 solver.cpp:397]     Test net output #1: loss = 0.24515 (* 1 = 0.24515 loss)
I0529 10:48:09.503832 11123 solver.cpp:218] Iteration 199000 (2.99259 iter/s, 33.4158s/100 iters), loss = 5.20752e-06
I0529 10:48:09.503875 11123 solver.cpp:237]     Train net output #0: loss = 4.34526e-06 (* 1 = 4.34526e-06 loss)
I0529 10:48:09.503883 11123 sgd_solver.cpp:105] Iteration 199000, lr = 5e-05
I0529 10:48:37.635771 11123 solver.cpp:218] Iteration 199100 (3.55475 iter/s, 28.1313s/100 iters), loss = 7.43076e-06
I0529 10:48:37.635933 11123 solver.cpp:237]     Train net output #0: loss = 6.56856e-06 (* 1 = 6.56856e-06 loss)
I0529 10:48:37.635946 11123 sgd_solver.cpp:105] Iteration 199100, lr = 4.49997e-05
I0529 10:48:53.414592 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:49:06.063366 11123 solver.cpp:218] Iteration 199200 (3.5178 iter/s, 28.4269s/100 iters), loss = 0.00010717
I0529 10:49:06.063416 11123 solver.cpp:237]     Train net output #0: loss = 0.000106308 (* 1 = 0.000106308 loss)
I0529 10:49:06.063426 11123 sgd_solver.cpp:105] Iteration 199200, lr = 4.00001e-05
I0529 10:49:34.872263 11123 solver.cpp:218] Iteration 199300 (3.47122 iter/s, 28.8083s/100 iters), loss = 1.2477e-05
I0529 10:49:34.872426 11123 solver.cpp:237]     Train net output #0: loss = 1.16149e-05 (* 1 = 1.16149e-05 loss)
I0529 10:49:34.872437 11123 sgd_solver.cpp:105] Iteration 199300, lr = 3.49998e-05
I0529 10:50:03.107848 11123 solver.cpp:218] Iteration 199400 (3.54172 iter/s, 28.2349s/100 iters), loss = 1.62173e-05
I0529 10:50:03.107915 11123 solver.cpp:237]     Train net output #0: loss = 1.5355e-05 (* 1 = 1.5355e-05 loss)
I0529 10:50:03.107930 11123 sgd_solver.cpp:105] Iteration 199400, lr = 3.00002e-05
I0529 10:50:31.311431 11123 solver.cpp:218] Iteration 199500 (3.54573 iter/s, 28.203s/100 iters), loss = 1.12398e-05
I0529 10:50:31.311666 11123 solver.cpp:237]     Train net output #0: loss = 1.03774e-05 (* 1 = 1.03774e-05 loss)
I0529 10:50:31.311677 11123 sgd_solver.cpp:105] Iteration 199500, lr = 2.5e-05
I0529 10:50:59.963977 11123 solver.cpp:218] Iteration 199600 (3.49019 iter/s, 28.6517s/100 iters), loss = 1.30817e-05
I0529 10:50:59.964026 11123 solver.cpp:237]     Train net output #0: loss = 1.22193e-05 (* 1 = 1.22193e-05 loss)
I0529 10:50:59.964035 11123 sgd_solver.cpp:105] Iteration 199600, lr = 1.99997e-05
I0529 10:51:28.148385 11123 solver.cpp:218] Iteration 199700 (3.54814 iter/s, 28.1838s/100 iters), loss = 3.44325e-06
I0529 10:51:28.148571 11123 solver.cpp:237]     Train net output #0: loss = 2.5809e-06 (* 1 = 2.5809e-06 loss)
I0529 10:51:28.148597 11123 sgd_solver.cpp:105] Iteration 199700, lr = 1.50001e-05
I0529 10:51:47.316222 11133 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:51:56.324179 11123 solver.cpp:218] Iteration 199800 (3.54924 iter/s, 28.1751s/100 iters), loss = 2.95627e-05
I0529 10:51:56.324228 11123 solver.cpp:237]     Train net output #0: loss = 2.87002e-05 (* 1 = 2.87002e-05 loss)
I0529 10:51:56.324236 11123 sgd_solver.cpp:105] Iteration 199800, lr = 9.99987e-06
I0529 10:52:24.588167 11123 solver.cpp:218] Iteration 199900 (3.53815 iter/s, 28.2634s/100 iters), loss = 5.90171e-05
I0529 10:52:24.588315 11123 solver.cpp:237]     Train net output #0: loss = 5.81546e-05 (* 1 = 5.81546e-05 loss)
I0529 10:52:24.588326 11123 sgd_solver.cpp:105] Iteration 199900, lr = 5.00023e-06
I0529 10:52:52.380520 11123 solver.cpp:447] Snapshotting to binary proto file pre-resnet-50_iter_200000.caffemodel
I0529 10:52:52.852587 11123 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-50_iter_200000.solverstate
I0529 10:52:53.089849 11123 solver.cpp:310] Iteration 200000, loss = 8.40459e-05
I0529 10:52:53.089882 11123 solver.cpp:330] Iteration 200000, Testing net (#0)
I0529 10:52:56.706624 11137 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:52:57.548746 11123 solver.cpp:397]     Test net output #0: accuracy = 0.943
I0529 10:52:57.548794 11123 solver.cpp:397]     Test net output #1: loss = 0.261884 (* 1 = 0.261884 loss)
I0529 10:52:57.548800 11123 solver.cpp:315] Optimization Done.
I0529 10:52:57.548804 11123 caffe.cpp:259] Optimization Done.
