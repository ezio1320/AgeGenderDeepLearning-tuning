I0528 21:52:09.127693 142708 caffe.cpp:218] Using GPUs 1
I0528 21:52:09.146136 142708 caffe.cpp:223] GPU 1: Tesla K40m
I0528 21:52:09.580555 142708 solver.cpp:44] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 50000
lr_policy: "poly"
power: 1
momentum: 0.9
weight_decay: 0.0001
snapshot: 1000
snapshot_prefix: "pre-resnet-18"
solver_mode: GPU
device_id: 1
random_seed: 0
net: "18_train_val_test_fold_is_0.prototxt"
train_state {
  level: 0
  stage: ""
}
I0528 21:52:09.580896 142708 solver.cpp:87] Creating training net from net file: 18_train_val_test_fold_is_0.prototxt
I0528 21:52:09.582690 142708 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 18_train_val_test_fold_is_0.prototxt
I0528 21:52:09.582707 142708 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 21:52:09.582888 142708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0528 21:52:09.582949 142708 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0528 21:52:09.583482 142708 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-18"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/gender_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv_expand"
  bottom: "layer_512_1_conv2"
  top: "layer_512_1_sum"
}
layer {
  name: "layer_512_2_bn1"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale1"
  type: "Scale"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu1"
  type: "ReLU"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
}
layer {
  name: "layer_512_2_conv1"
  type: "Convolution"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_bn2"
  type: "BatchNorm"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale2"
  type: "Scale"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu2"
  type: "ReLU"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
}
layer {
  name: "layer_512_2_conv2"
  type: "Convolution"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_sum"
  type: "Eltwise"
  bottom: "layer_512_2_conv2"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_2_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
I0528 21:52:09.583875 142708 layer_factory.hpp:77] Creating layer data
I0528 21:52:09.583993 142708 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/gender_train_lmdb
I0528 21:52:09.584030 142708 net.cpp:84] Creating Layer data
I0528 21:52:09.584051 142708 net.cpp:380] data -> data
I0528 21:52:09.584084 142708 net.cpp:380] data -> label
I0528 21:52:09.584103 142708 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 21:52:09.587141 142708 data_layer.cpp:45] output data size: 100,3,224,224
I0528 21:52:09.724511 142708 net.cpp:122] Setting up data
I0528 21:52:09.724583 142708 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:52:09.724591 142708 net.cpp:129] Top shape: 100 (100)
I0528 21:52:09.724596 142708 net.cpp:137] Memory required for data: 60211600
I0528 21:52:09.724606 142708 layer_factory.hpp:77] Creating layer data_bn
I0528 21:52:09.724623 142708 net.cpp:84] Creating Layer data_bn
I0528 21:52:09.724629 142708 net.cpp:406] data_bn <- data
I0528 21:52:09.724645 142708 net.cpp:380] data_bn -> data_bn
I0528 21:52:09.725599 142708 net.cpp:122] Setting up data_bn
I0528 21:52:09.725616 142708 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:52:09.725621 142708 net.cpp:137] Memory required for data: 120422800
I0528 21:52:09.725642 142708 layer_factory.hpp:77] Creating layer data_scale
I0528 21:52:09.725656 142708 net.cpp:84] Creating Layer data_scale
I0528 21:52:09.725661 142708 net.cpp:406] data_scale <- data_bn
I0528 21:52:09.725668 142708 net.cpp:367] data_scale -> data_bn (in-place)
I0528 21:52:09.725718 142708 layer_factory.hpp:77] Creating layer data_scale
I0528 21:52:09.725870 142708 net.cpp:122] Setting up data_scale
I0528 21:52:09.725879 142708 net.cpp:129] Top shape: 100 3 224 224 (15052800)
I0528 21:52:09.725883 142708 net.cpp:137] Memory required for data: 180634000
I0528 21:52:09.725891 142708 layer_factory.hpp:77] Creating layer conv1
I0528 21:52:09.725909 142708 net.cpp:84] Creating Layer conv1
I0528 21:52:09.725914 142708 net.cpp:406] conv1 <- data_bn
I0528 21:52:09.725921 142708 net.cpp:380] conv1 -> conv1
I0528 21:52:09.921434 142708 net.cpp:122] Setting up conv1
I0528 21:52:09.921478 142708 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:52:09.921483 142708 net.cpp:137] Memory required for data: 501760400
I0528 21:52:09.921494 142708 layer_factory.hpp:77] Creating layer conv1_bn
I0528 21:52:09.921509 142708 net.cpp:84] Creating Layer conv1_bn
I0528 21:52:09.921514 142708 net.cpp:406] conv1_bn <- conv1
I0528 21:52:09.921522 142708 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 21:52:09.921682 142708 net.cpp:122] Setting up conv1_bn
I0528 21:52:09.921691 142708 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:52:09.921695 142708 net.cpp:137] Memory required for data: 822886800
I0528 21:52:09.921707 142708 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:52:09.921716 142708 net.cpp:84] Creating Layer conv1_scale
I0528 21:52:09.921730 142708 net.cpp:406] conv1_scale <- conv1
I0528 21:52:09.921747 142708 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 21:52:09.921788 142708 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:52:09.921896 142708 net.cpp:122] Setting up conv1_scale
I0528 21:52:09.921905 142708 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:52:09.921908 142708 net.cpp:137] Memory required for data: 1144013200
I0528 21:52:09.921914 142708 layer_factory.hpp:77] Creating layer conv1_relu
I0528 21:52:09.921924 142708 net.cpp:84] Creating Layer conv1_relu
I0528 21:52:09.921928 142708 net.cpp:406] conv1_relu <- conv1
I0528 21:52:09.921933 142708 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 21:52:09.922513 142708 net.cpp:122] Setting up conv1_relu
I0528 21:52:09.922530 142708 net.cpp:129] Top shape: 100 64 112 112 (80281600)
I0528 21:52:09.922534 142708 net.cpp:137] Memory required for data: 1465139600
I0528 21:52:09.922538 142708 layer_factory.hpp:77] Creating layer conv1_pool
I0528 21:52:09.922547 142708 net.cpp:84] Creating Layer conv1_pool
I0528 21:52:09.922551 142708 net.cpp:406] conv1_pool <- conv1
I0528 21:52:09.922557 142708 net.cpp:380] conv1_pool -> conv1_pool
I0528 21:52:09.922610 142708 net.cpp:122] Setting up conv1_pool
I0528 21:52:09.922617 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.922621 142708 net.cpp:137] Memory required for data: 1545421200
I0528 21:52:09.922624 142708 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 21:52:09.922633 142708 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 21:52:09.922637 142708 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 21:52:09.922642 142708 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 21:52:09.922649 142708 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 21:52:09.922679 142708 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 21:52:09.922685 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.922689 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.922693 142708 net.cpp:137] Memory required for data: 1705984400
I0528 21:52:09.922696 142708 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 21:52:09.922708 142708 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 21:52:09.922713 142708 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 21:52:09.922719 142708 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 21:52:09.925156 142708 net.cpp:122] Setting up layer_64_1_conv1
I0528 21:52:09.925173 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.925178 142708 net.cpp:137] Memory required for data: 1786266000
I0528 21:52:09.925184 142708 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 21:52:09.925191 142708 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 21:52:09.925195 142708 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 21:52:09.925201 142708 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 21:52:09.925952 142708 net.cpp:122] Setting up layer_64_1_bn2
I0528 21:52:09.925966 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.925971 142708 net.cpp:137] Memory required for data: 1866547600
I0528 21:52:09.925978 142708 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:52:09.925987 142708 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 21:52:09.925990 142708 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 21:52:09.925997 142708 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 21:52:09.926033 142708 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:52:09.926134 142708 net.cpp:122] Setting up layer_64_1_scale2
I0528 21:52:09.926146 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.926149 142708 net.cpp:137] Memory required for data: 1946829200
I0528 21:52:09.926159 142708 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 21:52:09.926165 142708 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 21:52:09.926175 142708 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 21:52:09.926187 142708 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 21:52:09.926336 142708 net.cpp:122] Setting up layer_64_1_relu2
I0528 21:52:09.926345 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.926348 142708 net.cpp:137] Memory required for data: 2027110800
I0528 21:52:09.926352 142708 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 21:52:09.926362 142708 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 21:52:09.926367 142708 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 21:52:09.926373 142708 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 21:52:09.928795 142708 net.cpp:122] Setting up layer_64_1_conv2
I0528 21:52:09.928813 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.928817 142708 net.cpp:137] Memory required for data: 2107392400
I0528 21:52:09.928823 142708 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 21:52:09.928833 142708 net.cpp:84] Creating Layer layer_64_1_sum
I0528 21:52:09.928838 142708 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 21:52:09.928843 142708 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 21:52:09.928849 142708 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 21:52:09.928879 142708 net.cpp:122] Setting up layer_64_1_sum
I0528 21:52:09.928885 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.928889 142708 net.cpp:137] Memory required for data: 2187674000
I0528 21:52:09.928892 142708 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:09.928897 142708 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:09.928901 142708 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 21:52:09.928906 142708 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:52:09.928913 142708 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:52:09.928941 142708 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:09.928947 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.928951 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.928954 142708 net.cpp:137] Memory required for data: 2348237200
I0528 21:52:09.928957 142708 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 21:52:09.928966 142708 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 21:52:09.928969 142708 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:52:09.928975 142708 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 21:52:09.929141 142708 net.cpp:122] Setting up layer_64_2_bn1
I0528 21:52:09.929150 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.929154 142708 net.cpp:137] Memory required for data: 2428518800
I0528 21:52:09.929162 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:52:09.929168 142708 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 21:52:09.929173 142708 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 21:52:09.929178 142708 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 21:52:09.929214 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:52:09.929306 142708 net.cpp:122] Setting up layer_64_2_scale1
I0528 21:52:09.929313 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.929317 142708 net.cpp:137] Memory required for data: 2508800400
I0528 21:52:09.929323 142708 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 21:52:09.929329 142708 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 21:52:09.929333 142708 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 21:52:09.929338 142708 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 21:52:09.929486 142708 net.cpp:122] Setting up layer_64_2_relu1
I0528 21:52:09.929497 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.929505 142708 net.cpp:137] Memory required for data: 2589082000
I0528 21:52:09.929517 142708 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 21:52:09.929527 142708 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 21:52:09.929530 142708 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 21:52:09.929538 142708 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 21:52:09.932029 142708 net.cpp:122] Setting up layer_64_2_conv1
I0528 21:52:09.932052 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.932059 142708 net.cpp:137] Memory required for data: 2669363600
I0528 21:52:09.932065 142708 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 21:52:09.932072 142708 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 21:52:09.932076 142708 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 21:52:09.932085 142708 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 21:52:09.932255 142708 net.cpp:122] Setting up layer_64_2_bn2
I0528 21:52:09.932263 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.932267 142708 net.cpp:137] Memory required for data: 2749645200
I0528 21:52:09.932274 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:52:09.932281 142708 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 21:52:09.932286 142708 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 21:52:09.932294 142708 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 21:52:09.932330 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:52:09.932433 142708 net.cpp:122] Setting up layer_64_2_scale2
I0528 21:52:09.932441 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.932446 142708 net.cpp:137] Memory required for data: 2829926800
I0528 21:52:09.932451 142708 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 21:52:09.932456 142708 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 21:52:09.932461 142708 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 21:52:09.932467 142708 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 21:52:09.933122 142708 net.cpp:122] Setting up layer_64_2_relu2
I0528 21:52:09.933138 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.933143 142708 net.cpp:137] Memory required for data: 2910208400
I0528 21:52:09.933146 142708 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 21:52:09.933161 142708 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 21:52:09.933166 142708 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 21:52:09.933174 142708 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 21:52:09.936282 142708 net.cpp:122] Setting up layer_64_2_conv2
I0528 21:52:09.936300 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.936305 142708 net.cpp:137] Memory required for data: 2990490000
I0528 21:52:09.936311 142708 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 21:52:09.936321 142708 net.cpp:84] Creating Layer layer_64_2_sum
I0528 21:52:09.936324 142708 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 21:52:09.936329 142708 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:52:09.936336 142708 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 21:52:09.936360 142708 net.cpp:122] Setting up layer_64_2_sum
I0528 21:52:09.936369 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.936372 142708 net.cpp:137] Memory required for data: 3070771600
I0528 21:52:09.936377 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 21:52:09.936383 142708 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 21:52:09.936386 142708 net.cpp:406] layer_128_1_bn1 <- layer_64_2_sum
I0528 21:52:09.936393 142708 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 21:52:09.936573 142708 net.cpp:122] Setting up layer_128_1_bn1
I0528 21:52:09.936581 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.936585 142708 net.cpp:137] Memory required for data: 3151053200
I0528 21:52:09.936599 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:52:09.936611 142708 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 21:52:09.936624 142708 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 21:52:09.936631 142708 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 21:52:09.936674 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:52:09.936780 142708 net.cpp:122] Setting up layer_128_1_scale1
I0528 21:52:09.936789 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.936792 142708 net.cpp:137] Memory required for data: 3231334800
I0528 21:52:09.936799 142708 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 21:52:09.936805 142708 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 21:52:09.936808 142708 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 21:52:09.936815 142708 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 21:52:09.936982 142708 net.cpp:122] Setting up layer_128_1_relu1
I0528 21:52:09.936993 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.936996 142708 net.cpp:137] Memory required for data: 3311616400
I0528 21:52:09.937000 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:09.937007 142708 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:09.937011 142708 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 21:52:09.937017 142708 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:52:09.937024 142708 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:52:09.937074 142708 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:09.937085 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.937089 142708 net.cpp:129] Top shape: 100 64 56 56 (20070400)
I0528 21:52:09.937093 142708 net.cpp:137] Memory required for data: 3472179600
I0528 21:52:09.937096 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 21:52:09.937108 142708 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 21:52:09.937113 142708 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:52:09.937120 142708 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 21:52:09.948493 142708 net.cpp:122] Setting up layer_128_1_conv1
I0528 21:52:09.948515 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.948520 142708 net.cpp:137] Memory required for data: 3512320400
I0528 21:52:09.948526 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 21:52:09.948536 142708 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 21:52:09.948540 142708 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 21:52:09.948547 142708 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 21:52:09.949277 142708 net.cpp:122] Setting up layer_128_1_bn2
I0528 21:52:09.949293 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.949297 142708 net.cpp:137] Memory required for data: 3552461200
I0528 21:52:09.949306 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:52:09.949313 142708 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 21:52:09.949318 142708 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 21:52:09.949323 142708 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 21:52:09.949368 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:52:09.949470 142708 net.cpp:122] Setting up layer_128_1_scale2
I0528 21:52:09.949478 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.949482 142708 net.cpp:137] Memory required for data: 3592602000
I0528 21:52:09.949488 142708 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 21:52:09.949499 142708 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 21:52:09.949504 142708 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 21:52:09.949509 142708 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 21:52:09.949693 142708 net.cpp:122] Setting up layer_128_1_relu2
I0528 21:52:09.949705 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.949709 142708 net.cpp:137] Memory required for data: 3632742800
I0528 21:52:09.949713 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 21:52:09.949725 142708 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 21:52:09.949729 142708 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 21:52:09.949736 142708 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 21:52:09.955294 142708 net.cpp:122] Setting up layer_128_1_conv2
I0528 21:52:09.955312 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.955317 142708 net.cpp:137] Memory required for data: 3672883600
I0528 21:52:09.955322 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 21:52:09.955335 142708 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 21:52:09.955340 142708 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:52:09.955349 142708 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 21:52:09.957110 142708 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 21:52:09.957129 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957136 142708 net.cpp:137] Memory required for data: 3713024400
I0528 21:52:09.957142 142708 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 21:52:09.957151 142708 net.cpp:84] Creating Layer layer_128_1_sum
I0528 21:52:09.957156 142708 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 21:52:09.957161 142708 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 21:52:09.957167 142708 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 21:52:09.957201 142708 net.cpp:122] Setting up layer_128_1_sum
I0528 21:52:09.957208 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957211 142708 net.cpp:137] Memory required for data: 3753165200
I0528 21:52:09.957216 142708 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:09.957222 142708 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:09.957226 142708 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 21:52:09.957231 142708 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:52:09.957239 142708 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:52:09.957274 142708 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:09.957281 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957285 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957288 142708 net.cpp:137] Memory required for data: 3833446800
I0528 21:52:09.957291 142708 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 21:52:09.957300 142708 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 21:52:09.957304 142708 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:52:09.957311 142708 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 21:52:09.957487 142708 net.cpp:122] Setting up layer_128_2_bn1
I0528 21:52:09.957495 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957499 142708 net.cpp:137] Memory required for data: 3873587600
I0528 21:52:09.957509 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:52:09.957515 142708 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 21:52:09.957520 142708 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 21:52:09.957525 142708 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 21:52:09.957564 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:52:09.957665 142708 net.cpp:122] Setting up layer_128_2_scale1
I0528 21:52:09.957674 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.957676 142708 net.cpp:137] Memory required for data: 3913728400
I0528 21:52:09.957695 142708 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 21:52:09.957703 142708 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 21:52:09.957707 142708 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 21:52:09.957712 142708 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 21:52:09.958730 142708 net.cpp:122] Setting up layer_128_2_relu1
I0528 21:52:09.958750 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.958755 142708 net.cpp:137] Memory required for data: 3953869200
I0528 21:52:09.958758 142708 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 21:52:09.958770 142708 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 21:52:09.958775 142708 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 21:52:09.958782 142708 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 21:52:09.964496 142708 net.cpp:122] Setting up layer_128_2_conv1
I0528 21:52:09.964514 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.964519 142708 net.cpp:137] Memory required for data: 3994010000
I0528 21:52:09.964524 142708 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 21:52:09.964534 142708 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 21:52:09.964539 142708 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 21:52:09.964545 142708 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 21:52:09.964715 142708 net.cpp:122] Setting up layer_128_2_bn2
I0528 21:52:09.964723 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.964726 142708 net.cpp:137] Memory required for data: 4034150800
I0528 21:52:09.964733 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:52:09.964740 142708 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 21:52:09.964745 142708 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 21:52:09.964752 142708 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 21:52:09.964789 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:52:09.964889 142708 net.cpp:122] Setting up layer_128_2_scale2
I0528 21:52:09.964895 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.964900 142708 net.cpp:137] Memory required for data: 4074291600
I0528 21:52:09.964905 142708 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 21:52:09.964913 142708 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 21:52:09.964917 142708 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 21:52:09.964922 142708 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 21:52:09.965471 142708 net.cpp:122] Setting up layer_128_2_relu2
I0528 21:52:09.965487 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.965490 142708 net.cpp:137] Memory required for data: 4114432400
I0528 21:52:09.965494 142708 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 21:52:09.965509 142708 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 21:52:09.965514 142708 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 21:52:09.965528 142708 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 21:52:09.971638 142708 net.cpp:122] Setting up layer_128_2_conv2
I0528 21:52:09.971658 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.971662 142708 net.cpp:137] Memory required for data: 4154573200
I0528 21:52:09.971668 142708 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 21:52:09.971675 142708 net.cpp:84] Creating Layer layer_128_2_sum
I0528 21:52:09.971680 142708 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 21:52:09.971685 142708 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:52:09.971691 142708 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 21:52:09.971720 142708 net.cpp:122] Setting up layer_128_2_sum
I0528 21:52:09.971727 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.971731 142708 net.cpp:137] Memory required for data: 4194714000
I0528 21:52:09.971741 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 21:52:09.971758 142708 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 21:52:09.971763 142708 net.cpp:406] layer_256_1_bn1 <- layer_128_2_sum
I0528 21:52:09.971768 142708 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 21:52:09.971947 142708 net.cpp:122] Setting up layer_256_1_bn1
I0528 21:52:09.971954 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.971958 142708 net.cpp:137] Memory required for data: 4234854800
I0528 21:52:09.971967 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:52:09.971974 142708 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 21:52:09.971978 142708 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 21:52:09.971983 142708 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 21:52:09.972023 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:52:09.972134 142708 net.cpp:122] Setting up layer_256_1_scale1
I0528 21:52:09.972146 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.972149 142708 net.cpp:137] Memory required for data: 4274995600
I0528 21:52:09.972156 142708 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 21:52:09.972163 142708 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 21:52:09.972167 142708 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 21:52:09.972172 142708 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 21:52:09.972344 142708 net.cpp:122] Setting up layer_256_1_relu1
I0528 21:52:09.972357 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.972360 142708 net.cpp:137] Memory required for data: 4315136400
I0528 21:52:09.972364 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:09.972370 142708 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:09.972374 142708 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 21:52:09.972379 142708 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:52:09.972386 142708 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:52:09.972427 142708 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:09.972434 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.972439 142708 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0528 21:52:09.972441 142708 net.cpp:137] Memory required for data: 4395418000
I0528 21:52:09.972445 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 21:52:09.972455 142708 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 21:52:09.972460 142708 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:52:09.972468 142708 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 21:52:09.982668 142708 net.cpp:122] Setting up layer_256_1_conv1
I0528 21:52:09.982688 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:09.982693 142708 net.cpp:137] Memory required for data: 4415488400
I0528 21:52:09.982699 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 21:52:09.982709 142708 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 21:52:09.982714 142708 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 21:52:09.982720 142708 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 21:52:09.982899 142708 net.cpp:122] Setting up layer_256_1_bn2
I0528 21:52:09.982908 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:09.982910 142708 net.cpp:137] Memory required for data: 4435558800
I0528 21:52:09.982931 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:52:09.982939 142708 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 21:52:09.982944 142708 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 21:52:09.982949 142708 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 21:52:09.983005 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:52:09.983122 142708 net.cpp:122] Setting up layer_256_1_scale2
I0528 21:52:09.983134 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:09.983137 142708 net.cpp:137] Memory required for data: 4455629200
I0528 21:52:09.983144 142708 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 21:52:09.983150 142708 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 21:52:09.983153 142708 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 21:52:09.983160 142708 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 21:52:09.983741 142708 net.cpp:122] Setting up layer_256_1_relu2
I0528 21:52:09.983755 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:09.983759 142708 net.cpp:137] Memory required for data: 4475699600
I0528 21:52:09.983763 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 21:52:09.983777 142708 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 21:52:09.983781 142708 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 21:52:09.983790 142708 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 21:52:10.002204 142708 net.cpp:122] Setting up layer_256_1_conv2
I0528 21:52:10.002236 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.002241 142708 net.cpp:137] Memory required for data: 4495770000
I0528 21:52:10.002249 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 21:52:10.002262 142708 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 21:52:10.002269 142708 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:52:10.002277 142708 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 21:52:10.005177 142708 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 21:52:10.005195 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005199 142708 net.cpp:137] Memory required for data: 4515840400
I0528 21:52:10.005205 142708 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 21:52:10.005215 142708 net.cpp:84] Creating Layer layer_256_1_sum
I0528 21:52:10.005220 142708 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 21:52:10.005225 142708 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 21:52:10.005231 142708 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 21:52:10.005264 142708 net.cpp:122] Setting up layer_256_1_sum
I0528 21:52:10.005271 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005275 142708 net.cpp:137] Memory required for data: 4535910800
I0528 21:52:10.005278 142708 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.005286 142708 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.005290 142708 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 21:52:10.005297 142708 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:52:10.005304 142708 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:52:10.005339 142708 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.005347 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005352 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005355 142708 net.cpp:137] Memory required for data: 4576051600
I0528 21:52:10.005359 142708 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 21:52:10.005367 142708 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 21:52:10.005370 142708 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:52:10.005378 142708 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 21:52:10.005564 142708 net.cpp:122] Setting up layer_256_2_bn1
I0528 21:52:10.005571 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005575 142708 net.cpp:137] Memory required for data: 4596122000
I0528 21:52:10.005592 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:52:10.005610 142708 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 21:52:10.005614 142708 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 21:52:10.005625 142708 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 21:52:10.005668 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:52:10.005781 142708 net.cpp:122] Setting up layer_256_2_scale1
I0528 21:52:10.005790 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.005794 142708 net.cpp:137] Memory required for data: 4616192400
I0528 21:52:10.005800 142708 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 21:52:10.005806 142708 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 21:52:10.005810 142708 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 21:52:10.005815 142708 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 21:52:10.006419 142708 net.cpp:122] Setting up layer_256_2_relu1
I0528 21:52:10.006438 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.006441 142708 net.cpp:137] Memory required for data: 4636262800
I0528 21:52:10.006445 142708 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 21:52:10.006458 142708 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 21:52:10.006464 142708 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 21:52:10.006471 142708 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 21:52:10.024773 142708 net.cpp:122] Setting up layer_256_2_conv1
I0528 21:52:10.024799 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.024804 142708 net.cpp:137] Memory required for data: 4656333200
I0528 21:52:10.024809 142708 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 21:52:10.024818 142708 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 21:52:10.024822 142708 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 21:52:10.024832 142708 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.025015 142708 net.cpp:122] Setting up layer_256_2_bn2
I0528 21:52:10.025024 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.025027 142708 net.cpp:137] Memory required for data: 4676403600
I0528 21:52:10.025035 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:52:10.025048 142708 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 21:52:10.025055 142708 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 21:52:10.025061 142708 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.025106 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:52:10.025213 142708 net.cpp:122] Setting up layer_256_2_scale2
I0528 21:52:10.025221 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.025224 142708 net.cpp:137] Memory required for data: 4696474000
I0528 21:52:10.025230 142708 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 21:52:10.025248 142708 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 21:52:10.025252 142708 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 21:52:10.025257 142708 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.025836 142708 net.cpp:122] Setting up layer_256_2_relu2
I0528 21:52:10.025851 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.025854 142708 net.cpp:137] Memory required for data: 4716544400
I0528 21:52:10.025858 142708 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 21:52:10.025874 142708 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 21:52:10.025879 142708 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 21:52:10.025887 142708 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 21:52:10.044703 142708 net.cpp:122] Setting up layer_256_2_conv2
I0528 21:52:10.044739 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.044745 142708 net.cpp:137] Memory required for data: 4736614800
I0528 21:52:10.044754 142708 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 21:52:10.044775 142708 net.cpp:84] Creating Layer layer_256_2_sum
I0528 21:52:10.044791 142708 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 21:52:10.044798 142708 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:52:10.044805 142708 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 21:52:10.044838 142708 net.cpp:122] Setting up layer_256_2_sum
I0528 21:52:10.044847 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.044849 142708 net.cpp:137] Memory required for data: 4756685200
I0528 21:52:10.044852 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 21:52:10.044862 142708 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 21:52:10.044865 142708 net.cpp:406] layer_512_1_bn1 <- layer_256_2_sum
I0528 21:52:10.044872 142708 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 21:52:10.045068 142708 net.cpp:122] Setting up layer_512_1_bn1
I0528 21:52:10.045079 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.045083 142708 net.cpp:137] Memory required for data: 4776755600
I0528 21:52:10.045092 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:52:10.045100 142708 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 21:52:10.045104 142708 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 21:52:10.045110 142708 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 21:52:10.045156 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:52:10.045264 142708 net.cpp:122] Setting up layer_512_1_scale1
I0528 21:52:10.045271 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.045274 142708 net.cpp:137] Memory required for data: 4796826000
I0528 21:52:10.045280 142708 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 21:52:10.045289 142708 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 21:52:10.045294 142708 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 21:52:10.045298 142708 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 21:52:10.045485 142708 net.cpp:122] Setting up layer_512_1_relu1
I0528 21:52:10.045495 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.045500 142708 net.cpp:137] Memory required for data: 4816896400
I0528 21:52:10.045502 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.045511 142708 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.045516 142708 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 21:52:10.045521 142708 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:52:10.045528 142708 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:52:10.045572 142708 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.045578 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.045583 142708 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0528 21:52:10.045585 142708 net.cpp:137] Memory required for data: 4857037200
I0528 21:52:10.045588 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 21:52:10.045600 142708 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 21:52:10.045605 142708 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:52:10.045614 142708 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 21:52:10.082109 142708 net.cpp:122] Setting up layer_512_1_conv1
I0528 21:52:10.082155 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.082160 142708 net.cpp:137] Memory required for data: 4867072400
I0528 21:52:10.082168 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 21:52:10.082182 142708 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 21:52:10.082190 142708 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 21:52:10.082197 142708 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.082425 142708 net.cpp:122] Setting up layer_512_1_bn2
I0528 21:52:10.082448 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.082451 142708 net.cpp:137] Memory required for data: 4877107600
I0528 21:52:10.082458 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:52:10.082468 142708 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 21:52:10.082471 142708 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 21:52:10.082479 142708 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.082522 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:52:10.082636 142708 net.cpp:122] Setting up layer_512_1_scale2
I0528 21:52:10.082644 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.082648 142708 net.cpp:137] Memory required for data: 4887142800
I0528 21:52:10.082653 142708 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 21:52:10.082660 142708 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 21:52:10.082665 142708 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 21:52:10.082669 142708 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.087035 142708 net.cpp:122] Setting up layer_512_1_relu2
I0528 21:52:10.087059 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.087062 142708 net.cpp:137] Memory required for data: 4897178000
I0528 21:52:10.087066 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 21:52:10.087080 142708 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 21:52:10.087085 142708 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 21:52:10.087092 142708 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 21:52:10.156656 142708 net.cpp:122] Setting up layer_512_1_conv2
I0528 21:52:10.156682 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.156687 142708 net.cpp:137] Memory required for data: 4907213200
I0528 21:52:10.156692 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 21:52:10.156704 142708 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 21:52:10.156710 142708 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:52:10.156718 142708 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 21:52:10.162515 142708 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 21:52:10.162533 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.162539 142708 net.cpp:137] Memory required for data: 4917248400
I0528 21:52:10.162544 142708 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 21:52:10.162551 142708 net.cpp:84] Creating Layer layer_512_1_sum
I0528 21:52:10.162556 142708 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 21:52:10.162561 142708 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 21:52:10.162567 142708 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 21:52:10.162598 142708 net.cpp:122] Setting up layer_512_1_sum
I0528 21:52:10.162606 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.162611 142708 net.cpp:137] Memory required for data: 4927283600
I0528 21:52:10.162614 142708 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.162621 142708 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.162626 142708 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 21:52:10.162631 142708 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:52:10.162637 142708 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:52:10.162674 142708 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.162681 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.162685 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.162688 142708 net.cpp:137] Memory required for data: 4947354000
I0528 21:52:10.162693 142708 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 21:52:10.162710 142708 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 21:52:10.162715 142708 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:52:10.162724 142708 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 21:52:10.162914 142708 net.cpp:122] Setting up layer_512_2_bn1
I0528 21:52:10.162921 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.162925 142708 net.cpp:137] Memory required for data: 4957389200
I0528 21:52:10.162932 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:52:10.162941 142708 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 21:52:10.162945 142708 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 21:52:10.162951 142708 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 21:52:10.162992 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:52:10.163120 142708 net.cpp:122] Setting up layer_512_2_scale1
I0528 21:52:10.163131 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.163136 142708 net.cpp:137] Memory required for data: 4967424400
I0528 21:52:10.163141 142708 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 21:52:10.163147 142708 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 21:52:10.163151 142708 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 21:52:10.163161 142708 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 21:52:10.163753 142708 net.cpp:122] Setting up layer_512_2_relu1
I0528 21:52:10.163766 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.163770 142708 net.cpp:137] Memory required for data: 4977459600
I0528 21:52:10.163774 142708 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 21:52:10.163786 142708 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 21:52:10.163791 142708 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 21:52:10.163800 142708 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 21:52:10.233665 142708 net.cpp:122] Setting up layer_512_2_conv1
I0528 21:52:10.233688 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.233693 142708 net.cpp:137] Memory required for data: 4987494800
I0528 21:52:10.233700 142708 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 21:52:10.233707 142708 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 21:52:10.233712 142708 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 21:52:10.233721 142708 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.233921 142708 net.cpp:122] Setting up layer_512_2_bn2
I0528 21:52:10.233929 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.233933 142708 net.cpp:137] Memory required for data: 4997530000
I0528 21:52:10.233942 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:52:10.233948 142708 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 21:52:10.233952 142708 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 21:52:10.233958 142708 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.233999 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:52:10.234122 142708 net.cpp:122] Setting up layer_512_2_scale2
I0528 21:52:10.234133 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.234138 142708 net.cpp:137] Memory required for data: 5007565200
I0528 21:52:10.234143 142708 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 21:52:10.234149 142708 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 21:52:10.234153 142708 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 21:52:10.234159 142708 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.234334 142708 net.cpp:122] Setting up layer_512_2_relu2
I0528 21:52:10.234345 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.234349 142708 net.cpp:137] Memory required for data: 5017600400
I0528 21:52:10.234352 142708 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 21:52:10.234369 142708 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 21:52:10.234382 142708 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 21:52:10.234390 142708 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 21:52:10.304488 142708 net.cpp:122] Setting up layer_512_2_conv2
I0528 21:52:10.304512 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.304517 142708 net.cpp:137] Memory required for data: 5027635600
I0528 21:52:10.304522 142708 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 21:52:10.304529 142708 net.cpp:84] Creating Layer layer_512_2_sum
I0528 21:52:10.304534 142708 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 21:52:10.304539 142708 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:52:10.304546 142708 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 21:52:10.304581 142708 net.cpp:122] Setting up layer_512_2_sum
I0528 21:52:10.304589 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.304592 142708 net.cpp:137] Memory required for data: 5037670800
I0528 21:52:10.304595 142708 layer_factory.hpp:77] Creating layer last_bn
I0528 21:52:10.304605 142708 net.cpp:84] Creating Layer last_bn
I0528 21:52:10.304610 142708 net.cpp:406] last_bn <- layer_512_2_sum
I0528 21:52:10.304615 142708 net.cpp:367] last_bn -> layer_512_2_sum (in-place)
I0528 21:52:10.304807 142708 net.cpp:122] Setting up last_bn
I0528 21:52:10.304816 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.304819 142708 net.cpp:137] Memory required for data: 5047706000
I0528 21:52:10.304827 142708 layer_factory.hpp:77] Creating layer last_scale
I0528 21:52:10.304834 142708 net.cpp:84] Creating Layer last_scale
I0528 21:52:10.304838 142708 net.cpp:406] last_scale <- layer_512_2_sum
I0528 21:52:10.304846 142708 net.cpp:367] last_scale -> layer_512_2_sum (in-place)
I0528 21:52:10.304884 142708 layer_factory.hpp:77] Creating layer last_scale
I0528 21:52:10.305002 142708 net.cpp:122] Setting up last_scale
I0528 21:52:10.305011 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.305016 142708 net.cpp:137] Memory required for data: 5057741200
I0528 21:52:10.305022 142708 layer_factory.hpp:77] Creating layer last_relu
I0528 21:52:10.305028 142708 net.cpp:84] Creating Layer last_relu
I0528 21:52:10.305032 142708 net.cpp:406] last_relu <- layer_512_2_sum
I0528 21:52:10.305037 142708 net.cpp:367] last_relu -> layer_512_2_sum (in-place)
I0528 21:52:10.305225 142708 net.cpp:122] Setting up last_relu
I0528 21:52:10.305238 142708 net.cpp:129] Top shape: 100 512 7 7 (2508800)
I0528 21:52:10.305241 142708 net.cpp:137] Memory required for data: 5067776400
I0528 21:52:10.305245 142708 layer_factory.hpp:77] Creating layer global_pool
I0528 21:52:10.305253 142708 net.cpp:84] Creating Layer global_pool
I0528 21:52:10.305256 142708 net.cpp:406] global_pool <- layer_512_2_sum
I0528 21:52:10.305263 142708 net.cpp:380] global_pool -> global_pool
I0528 21:52:10.305915 142708 net.cpp:122] Setting up global_pool
I0528 21:52:10.305932 142708 net.cpp:129] Top shape: 100 512 1 1 (51200)
I0528 21:52:10.305935 142708 net.cpp:137] Memory required for data: 5067981200
I0528 21:52:10.305939 142708 layer_factory.hpp:77] Creating layer score
I0528 21:52:10.305950 142708 net.cpp:84] Creating Layer score
I0528 21:52:10.305954 142708 net.cpp:406] score <- global_pool
I0528 21:52:10.305965 142708 net.cpp:380] score -> score
I0528 21:52:10.306092 142708 net.cpp:122] Setting up score
I0528 21:52:10.306104 142708 net.cpp:129] Top shape: 100 2 (200)
I0528 21:52:10.306108 142708 net.cpp:137] Memory required for data: 5067982000
I0528 21:52:10.306114 142708 layer_factory.hpp:77] Creating layer loss
I0528 21:52:10.306125 142708 net.cpp:84] Creating Layer loss
I0528 21:52:10.306129 142708 net.cpp:406] loss <- score
I0528 21:52:10.306134 142708 net.cpp:406] loss <- label
I0528 21:52:10.306141 142708 net.cpp:380] loss -> loss
I0528 21:52:10.306154 142708 layer_factory.hpp:77] Creating layer loss
I0528 21:52:10.306866 142708 net.cpp:122] Setting up loss
I0528 21:52:10.306885 142708 net.cpp:129] Top shape: (1)
I0528 21:52:10.306896 142708 net.cpp:132]     with loss weight 1
I0528 21:52:10.306924 142708 net.cpp:137] Memory required for data: 5067982004
I0528 21:52:10.306929 142708 net.cpp:198] loss needs backward computation.
I0528 21:52:10.306933 142708 net.cpp:198] score needs backward computation.
I0528 21:52:10.306937 142708 net.cpp:198] global_pool needs backward computation.
I0528 21:52:10.306941 142708 net.cpp:198] last_relu needs backward computation.
I0528 21:52:10.306944 142708 net.cpp:198] last_scale needs backward computation.
I0528 21:52:10.306947 142708 net.cpp:198] last_bn needs backward computation.
I0528 21:52:10.306951 142708 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 21:52:10.306954 142708 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 21:52:10.306958 142708 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 21:52:10.306962 142708 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 21:52:10.306964 142708 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 21:52:10.306967 142708 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 21:52:10.306972 142708 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 21:52:10.306975 142708 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 21:52:10.306978 142708 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 21:52:10.306982 142708 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 21:52:10.306985 142708 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 21:52:10.306990 142708 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 21:52:10.306994 142708 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 21:52:10.306998 142708 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 21:52:10.307001 142708 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 21:52:10.307005 142708 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 21:52:10.307008 142708 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 21:52:10.307013 142708 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 21:52:10.307016 142708 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 21:52:10.307020 142708 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 21:52:10.307024 142708 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 21:52:10.307027 142708 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 21:52:10.307031 142708 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 21:52:10.307036 142708 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 21:52:10.307050 142708 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 21:52:10.307054 142708 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 21:52:10.307059 142708 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 21:52:10.307062 142708 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 21:52:10.307065 142708 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 21:52:10.307070 142708 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 21:52:10.307073 142708 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 21:52:10.307077 142708 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 21:52:10.307081 142708 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 21:52:10.307085 142708 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 21:52:10.307090 142708 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 21:52:10.307092 142708 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 21:52:10.307096 142708 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 21:52:10.307101 142708 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 21:52:10.307106 142708 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 21:52:10.307116 142708 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 21:52:10.307119 142708 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 21:52:10.307122 142708 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 21:52:10.307126 142708 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 21:52:10.307132 142708 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 21:52:10.307134 142708 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 21:52:10.307138 142708 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 21:52:10.307142 142708 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 21:52:10.307145 142708 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 21:52:10.307149 142708 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 21:52:10.307153 142708 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 21:52:10.307157 142708 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 21:52:10.307160 142708 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 21:52:10.307164 142708 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 21:52:10.307168 142708 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 21:52:10.307173 142708 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 21:52:10.307176 142708 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 21:52:10.307180 142708 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 21:52:10.307183 142708 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 21:52:10.307186 142708 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 21:52:10.307190 142708 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 21:52:10.307194 142708 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 21:52:10.307199 142708 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 21:52:10.307201 142708 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 21:52:10.307205 142708 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 21:52:10.307210 142708 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 21:52:10.307214 142708 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 21:52:10.307217 142708 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 21:52:10.307220 142708 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 21:52:10.307224 142708 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 21:52:10.307229 142708 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 21:52:10.307232 142708 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 21:52:10.307235 142708 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 21:52:10.307240 142708 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 21:52:10.307243 142708 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 21:52:10.307248 142708 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 21:52:10.307251 142708 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 21:52:10.307255 142708 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 21:52:10.307260 142708 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 21:52:10.307262 142708 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 21:52:10.307266 142708 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 21:52:10.307271 142708 net.cpp:198] conv1_pool needs backward computation.
I0528 21:52:10.307274 142708 net.cpp:198] conv1_relu needs backward computation.
I0528 21:52:10.307277 142708 net.cpp:198] conv1_scale needs backward computation.
I0528 21:52:10.307281 142708 net.cpp:198] conv1_bn needs backward computation.
I0528 21:52:10.307287 142708 net.cpp:198] conv1 needs backward computation.
I0528 21:52:10.307294 142708 net.cpp:198] data_scale needs backward computation.
I0528 21:52:10.307299 142708 net.cpp:200] data_bn does not need backward computation.
I0528 21:52:10.307303 142708 net.cpp:200] data does not need backward computation.
I0528 21:52:10.307307 142708 net.cpp:242] This network produces output loss
I0528 21:52:10.307361 142708 net.cpp:255] Network initialization done.
I0528 21:52:10.309531 142708 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: 18_train_val_test_fold_is_0.prototxt
I0528 21:52:10.309546 142708 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0528 21:52:10.309554 142708 solver.cpp:172] Creating test net (#0) specified by net file: 18_train_val_test_fold_is_0.prototxt
I0528 21:52:10.309661 142708 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0528 21:52:10.310272 142708 net.cpp:51] Initializing net from parameters: 
name: "Pre-ResNet-18"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_file: "/storage/Test_fold_is_01/mean.binaryproto"
  }
  data_param {
    source: "/storage/Test_fold_is_01/gender_val_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "data_bn"
  type: "BatchNorm"
  bottom: "data"
  top: "data_bn"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "data_scale"
  type: "Scale"
  bottom: "data_bn"
  top: "data_bn"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_bn"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "msra"
      variance_norm: FAN_OUT
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv1_pool"
  type: "Pooling"
  bottom: "conv1"
  top: "conv1_pool"
  pooling_param {
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "layer_64_1_conv1"
  type: "Convolution"
  bottom: "conv1_pool"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_bn2"
  type: "BatchNorm"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_1_scale2"
  type: "Scale"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_1_relu2"
  type: "ReLU"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv1"
}
layer {
  name: "layer_64_1_conv2"
  type: "Convolution"
  bottom: "layer_64_1_conv1"
  top: "layer_64_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_1_sum"
  type: "Eltwise"
  bottom: "layer_64_1_conv2"
  bottom: "conv1_pool"
  top: "layer_64_1_sum"
}
layer {
  name: "layer_64_2_bn1"
  type: "BatchNorm"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale1"
  type: "Scale"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu1"
  type: "ReLU"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_bn1"
}
layer {
  name: "layer_64_2_conv1"
  type: "Convolution"
  bottom: "layer_64_2_bn1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_bn2"
  type: "BatchNorm"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_64_2_scale2"
  type: "Scale"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_64_2_relu2"
  type: "ReLU"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv1"
}
layer {
  name: "layer_64_2_conv2"
  type: "Convolution"
  bottom: "layer_64_2_conv1"
  top: "layer_64_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_64_2_sum"
  type: "Eltwise"
  bottom: "layer_64_2_conv2"
  bottom: "layer_64_1_sum"
  top: "layer_64_2_sum"
}
layer {
  name: "layer_128_1_bn1"
  type: "BatchNorm"
  bottom: "layer_64_2_sum"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale1"
  type: "Scale"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu1"
  type: "ReLU"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_bn1"
}
layer {
  name: "layer_128_1_conv1"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_bn2"
  type: "BatchNorm"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_1_scale2"
  type: "Scale"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_1_relu2"
  type: "ReLU"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv1"
}
layer {
  name: "layer_128_1_conv2"
  type: "Convolution"
  bottom: "layer_128_1_conv1"
  top: "layer_128_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_conv_expand"
  type: "Convolution"
  bottom: "layer_128_1_bn1"
  top: "layer_128_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_1_sum"
  type: "Eltwise"
  bottom: "layer_128_1_conv_expand"
  bottom: "layer_128_1_conv2"
  top: "layer_128_1_sum"
}
layer {
  name: "layer_128_2_bn1"
  type: "BatchNorm"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale1"
  type: "Scale"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu1"
  type: "ReLU"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_bn1"
}
layer {
  name: "layer_128_2_conv1"
  type: "Convolution"
  bottom: "layer_128_2_bn1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_bn2"
  type: "BatchNorm"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_128_2_scale2"
  type: "Scale"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_128_2_relu2"
  type: "ReLU"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv1"
}
layer {
  name: "layer_128_2_conv2"
  type: "Convolution"
  bottom: "layer_128_2_conv1"
  top: "layer_128_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_128_2_sum"
  type: "Eltwise"
  bottom: "layer_128_2_conv2"
  bottom: "layer_128_1_sum"
  top: "layer_128_2_sum"
}
layer {
  name: "layer_256_1_bn1"
  type: "BatchNorm"
  bottom: "layer_128_2_sum"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale1"
  type: "Scale"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu1"
  type: "ReLU"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_bn1"
}
layer {
  name: "layer_256_1_conv1"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_bn2"
  type: "BatchNorm"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_1_scale2"
  type: "Scale"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_1_relu2"
  type: "ReLU"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv1"
}
layer {
  name: "layer_256_1_conv2"
  type: "Convolution"
  bottom: "layer_256_1_conv1"
  top: "layer_256_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_conv_expand"
  type: "Convolution"
  bottom: "layer_256_1_bn1"
  top: "layer_256_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_1_sum"
  type: "Eltwise"
  bottom: "layer_256_1_conv_expand"
  bottom: "layer_256_1_conv2"
  top: "layer_256_1_sum"
}
layer {
  name: "layer_256_2_bn1"
  type: "BatchNorm"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale1"
  type: "Scale"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu1"
  type: "ReLU"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_bn1"
}
layer {
  name: "layer_256_2_conv1"
  type: "Convolution"
  bottom: "layer_256_2_bn1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_bn2"
  type: "BatchNorm"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_256_2_scale2"
  type: "Scale"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_256_2_relu2"
  type: "ReLU"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv1"
}
layer {
  name: "layer_256_2_conv2"
  type: "Convolution"
  bottom: "layer_256_2_conv1"
  top: "layer_256_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_256_2_sum"
  type: "Eltwise"
  bottom: "layer_256_2_conv2"
  bottom: "layer_256_1_sum"
  top: "layer_256_2_sum"
}
layer {
  name: "layer_512_1_bn1"
  type: "BatchNorm"
  bottom: "layer_256_2_sum"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale1"
  type: "Scale"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu1"
  type: "ReLU"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_bn1"
}
layer {
  name: "layer_512_1_conv1"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_bn2"
  type: "BatchNorm"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_1_scale2"
  type: "Scale"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_1_relu2"
  type: "ReLU"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv1"
}
layer {
  name: "layer_512_1_conv2"
  type: "Convolution"
  bottom: "layer_512_1_conv1"
  top: "layer_512_1_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_conv_expand"
  type: "Convolution"
  bottom: "layer_512_1_bn1"
  top: "layer_512_1_conv_expand"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_1_sum"
  type: "Eltwise"
  bottom: "layer_512_1_conv_expand"
  bottom: "layer_512_1_conv2"
  top: "layer_512_1_sum"
}
layer {
  name: "layer_512_2_bn1"
  type: "BatchNorm"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale1"
  type: "Scale"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu1"
  type: "ReLU"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_bn1"
}
layer {
  name: "layer_512_2_conv1"
  type: "Convolution"
  bottom: "layer_512_2_bn1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_bn2"
  type: "BatchNorm"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "layer_512_2_scale2"
  type: "Scale"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "layer_512_2_relu2"
  type: "ReLU"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv1"
}
layer {
  name: "layer_512_2_conv2"
  type: "Convolution"
  bottom: "layer_512_2_conv1"
  top: "layer_512_2_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "layer_512_2_sum"
  type: "Eltwise"
  bottom: "layer_512_2_conv2"
  bottom: "layer_512_1_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "last_bn"
  type: "BatchNorm"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "last_scale"
  type: "Scale"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  scale_param {
    bias_term: true
  }
}
layer {
  name: "last_relu"
  type: "ReLU"
  bottom: "layer_512_2_sum"
  top: "layer_512_2_sum"
}
layer {
  name: "global_pool"
  type: "Pooling"
  bottom: "layer_512_2_sum"
  top: "global_pool"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "global_pool"
  top: "score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 1
  }
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I0528 21:52:10.310667 142708 layer_factory.hpp:77] Creating layer data
I0528 21:52:10.310740 142708 db_lmdb.cpp:35] Opened lmdb /storage/Test_fold_is_01/gender_val_lmdb
I0528 21:52:10.310760 142708 net.cpp:84] Creating Layer data
I0528 21:52:10.310767 142708 net.cpp:380] data -> data
I0528 21:52:10.310777 142708 net.cpp:380] data -> label
I0528 21:52:10.310786 142708 data_transformer.cpp:25] Loading mean file from: /storage/Test_fold_is_01/mean.binaryproto
I0528 21:52:10.313367 142708 data_layer.cpp:45] output data size: 50,3,224,224
I0528 21:52:10.386911 142708 net.cpp:122] Setting up data
I0528 21:52:10.387008 142708 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 21:52:10.387017 142708 net.cpp:129] Top shape: 50 (50)
I0528 21:52:10.387022 142708 net.cpp:137] Memory required for data: 30105800
I0528 21:52:10.387029 142708 layer_factory.hpp:77] Creating layer label_data_1_split
I0528 21:52:10.387068 142708 net.cpp:84] Creating Layer label_data_1_split
I0528 21:52:10.387076 142708 net.cpp:406] label_data_1_split <- label
I0528 21:52:10.387087 142708 net.cpp:380] label_data_1_split -> label_data_1_split_0
I0528 21:52:10.387099 142708 net.cpp:380] label_data_1_split -> label_data_1_split_1
I0528 21:52:10.387249 142708 net.cpp:122] Setting up label_data_1_split
I0528 21:52:10.387259 142708 net.cpp:129] Top shape: 50 (50)
I0528 21:52:10.387264 142708 net.cpp:129] Top shape: 50 (50)
I0528 21:52:10.387267 142708 net.cpp:137] Memory required for data: 30106200
I0528 21:52:10.387272 142708 layer_factory.hpp:77] Creating layer data_bn
I0528 21:52:10.387300 142708 net.cpp:84] Creating Layer data_bn
I0528 21:52:10.387305 142708 net.cpp:406] data_bn <- data
I0528 21:52:10.387313 142708 net.cpp:380] data_bn -> data_bn
I0528 21:52:10.387640 142708 net.cpp:122] Setting up data_bn
I0528 21:52:10.387655 142708 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 21:52:10.387660 142708 net.cpp:137] Memory required for data: 60211800
I0528 21:52:10.387679 142708 layer_factory.hpp:77] Creating layer data_scale
I0528 21:52:10.387692 142708 net.cpp:84] Creating Layer data_scale
I0528 21:52:10.387698 142708 net.cpp:406] data_scale <- data_bn
I0528 21:52:10.387707 142708 net.cpp:367] data_scale -> data_bn (in-place)
I0528 21:52:10.387769 142708 layer_factory.hpp:77] Creating layer data_scale
I0528 21:52:10.388028 142708 net.cpp:122] Setting up data_scale
I0528 21:52:10.388048 142708 net.cpp:129] Top shape: 50 3 224 224 (7526400)
I0528 21:52:10.388070 142708 net.cpp:137] Memory required for data: 90317400
I0528 21:52:10.388083 142708 layer_factory.hpp:77] Creating layer conv1
I0528 21:52:10.388106 142708 net.cpp:84] Creating Layer conv1
I0528 21:52:10.388113 142708 net.cpp:406] conv1 <- data_bn
I0528 21:52:10.388124 142708 net.cpp:380] conv1 -> conv1
I0528 21:52:10.392850 142708 net.cpp:122] Setting up conv1
I0528 21:52:10.392875 142708 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 21:52:10.392882 142708 net.cpp:137] Memory required for data: 250880600
I0528 21:52:10.392894 142708 layer_factory.hpp:77] Creating layer conv1_bn
I0528 21:52:10.392918 142708 net.cpp:84] Creating Layer conv1_bn
I0528 21:52:10.392936 142708 net.cpp:406] conv1_bn <- conv1
I0528 21:52:10.392946 142708 net.cpp:367] conv1_bn -> conv1 (in-place)
I0528 21:52:10.393242 142708 net.cpp:122] Setting up conv1_bn
I0528 21:52:10.393259 142708 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 21:52:10.393263 142708 net.cpp:137] Memory required for data: 411443800
I0528 21:52:10.393280 142708 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:52:10.393292 142708 net.cpp:84] Creating Layer conv1_scale
I0528 21:52:10.393298 142708 net.cpp:406] conv1_scale <- conv1
I0528 21:52:10.393307 142708 net.cpp:367] conv1_scale -> conv1 (in-place)
I0528 21:52:10.393368 142708 layer_factory.hpp:77] Creating layer conv1_scale
I0528 21:52:10.393543 142708 net.cpp:122] Setting up conv1_scale
I0528 21:52:10.393553 142708 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 21:52:10.393558 142708 net.cpp:137] Memory required for data: 572007000
I0528 21:52:10.393566 142708 layer_factory.hpp:77] Creating layer conv1_relu
I0528 21:52:10.393589 142708 net.cpp:84] Creating Layer conv1_relu
I0528 21:52:10.393594 142708 net.cpp:406] conv1_relu <- conv1
I0528 21:52:10.393602 142708 net.cpp:367] conv1_relu -> conv1 (in-place)
I0528 21:52:10.394343 142708 net.cpp:122] Setting up conv1_relu
I0528 21:52:10.394364 142708 net.cpp:129] Top shape: 50 64 112 112 (40140800)
I0528 21:52:10.394371 142708 net.cpp:137] Memory required for data: 732570200
I0528 21:52:10.394377 142708 layer_factory.hpp:77] Creating layer conv1_pool
I0528 21:52:10.394389 142708 net.cpp:84] Creating Layer conv1_pool
I0528 21:52:10.394395 142708 net.cpp:406] conv1_pool <- conv1
I0528 21:52:10.394405 142708 net.cpp:380] conv1_pool -> conv1_pool
I0528 21:52:10.394465 142708 net.cpp:122] Setting up conv1_pool
I0528 21:52:10.394476 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.394480 142708 net.cpp:137] Memory required for data: 772711000
I0528 21:52:10.394486 142708 layer_factory.hpp:77] Creating layer conv1_pool_conv1_pool_0_split
I0528 21:52:10.394495 142708 net.cpp:84] Creating Layer conv1_pool_conv1_pool_0_split
I0528 21:52:10.394501 142708 net.cpp:406] conv1_pool_conv1_pool_0_split <- conv1_pool
I0528 21:52:10.394508 142708 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_0
I0528 21:52:10.394517 142708 net.cpp:380] conv1_pool_conv1_pool_0_split -> conv1_pool_conv1_pool_0_split_1
I0528 21:52:10.394567 142708 net.cpp:122] Setting up conv1_pool_conv1_pool_0_split
I0528 21:52:10.394574 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.394582 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.394585 142708 net.cpp:137] Memory required for data: 852992600
I0528 21:52:10.394590 142708 layer_factory.hpp:77] Creating layer layer_64_1_conv1
I0528 21:52:10.394606 142708 net.cpp:84] Creating Layer layer_64_1_conv1
I0528 21:52:10.394613 142708 net.cpp:406] layer_64_1_conv1 <- conv1_pool_conv1_pool_0_split_0
I0528 21:52:10.394623 142708 net.cpp:380] layer_64_1_conv1 -> layer_64_1_conv1
I0528 21:52:10.398362 142708 net.cpp:122] Setting up layer_64_1_conv1
I0528 21:52:10.398385 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.398391 142708 net.cpp:137] Memory required for data: 893133400
I0528 21:52:10.398399 142708 layer_factory.hpp:77] Creating layer layer_64_1_bn2
I0528 21:52:10.398412 142708 net.cpp:84] Creating Layer layer_64_1_bn2
I0528 21:52:10.398418 142708 net.cpp:406] layer_64_1_bn2 <- layer_64_1_conv1
I0528 21:52:10.398428 142708 net.cpp:367] layer_64_1_bn2 -> layer_64_1_conv1 (in-place)
I0528 21:52:10.398689 142708 net.cpp:122] Setting up layer_64_1_bn2
I0528 21:52:10.398699 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.398703 142708 net.cpp:137] Memory required for data: 933274200
I0528 21:52:10.398715 142708 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:52:10.398725 142708 net.cpp:84] Creating Layer layer_64_1_scale2
I0528 21:52:10.398730 142708 net.cpp:406] layer_64_1_scale2 <- layer_64_1_conv1
I0528 21:52:10.398758 142708 net.cpp:367] layer_64_1_scale2 -> layer_64_1_conv1 (in-place)
I0528 21:52:10.398816 142708 layer_factory.hpp:77] Creating layer layer_64_1_scale2
I0528 21:52:10.398974 142708 net.cpp:122] Setting up layer_64_1_scale2
I0528 21:52:10.398984 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.398989 142708 net.cpp:137] Memory required for data: 973415000
I0528 21:52:10.399004 142708 layer_factory.hpp:77] Creating layer layer_64_1_relu2
I0528 21:52:10.399013 142708 net.cpp:84] Creating Layer layer_64_1_relu2
I0528 21:52:10.399019 142708 net.cpp:406] layer_64_1_relu2 <- layer_64_1_conv1
I0528 21:52:10.399026 142708 net.cpp:367] layer_64_1_relu2 -> layer_64_1_conv1 (in-place)
I0528 21:52:10.399258 142708 net.cpp:122] Setting up layer_64_1_relu2
I0528 21:52:10.399277 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.399282 142708 net.cpp:137] Memory required for data: 1013555800
I0528 21:52:10.399287 142708 layer_factory.hpp:77] Creating layer layer_64_1_conv2
I0528 21:52:10.399303 142708 net.cpp:84] Creating Layer layer_64_1_conv2
I0528 21:52:10.399308 142708 net.cpp:406] layer_64_1_conv2 <- layer_64_1_conv1
I0528 21:52:10.399318 142708 net.cpp:380] layer_64_1_conv2 -> layer_64_1_conv2
I0528 21:52:10.403162 142708 net.cpp:122] Setting up layer_64_1_conv2
I0528 21:52:10.403185 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403192 142708 net.cpp:137] Memory required for data: 1053696600
I0528 21:52:10.403201 142708 layer_factory.hpp:77] Creating layer layer_64_1_sum
I0528 21:52:10.403214 142708 net.cpp:84] Creating Layer layer_64_1_sum
I0528 21:52:10.403220 142708 net.cpp:406] layer_64_1_sum <- layer_64_1_conv2
I0528 21:52:10.403228 142708 net.cpp:406] layer_64_1_sum <- conv1_pool_conv1_pool_0_split_1
I0528 21:52:10.403239 142708 net.cpp:380] layer_64_1_sum -> layer_64_1_sum
I0528 21:52:10.403275 142708 net.cpp:122] Setting up layer_64_1_sum
I0528 21:52:10.403281 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403285 142708 net.cpp:137] Memory required for data: 1093837400
I0528 21:52:10.403290 142708 layer_factory.hpp:77] Creating layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:10.403297 142708 net.cpp:84] Creating Layer layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:10.403301 142708 net.cpp:406] layer_64_1_sum_layer_64_1_sum_0_split <- layer_64_1_sum
I0528 21:52:10.403307 142708 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:52:10.403313 142708 net.cpp:380] layer_64_1_sum_layer_64_1_sum_0_split -> layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:52:10.403355 142708 net.cpp:122] Setting up layer_64_1_sum_layer_64_1_sum_0_split
I0528 21:52:10.403362 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403367 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403369 142708 net.cpp:137] Memory required for data: 1174119000
I0528 21:52:10.403373 142708 layer_factory.hpp:77] Creating layer layer_64_2_bn1
I0528 21:52:10.403381 142708 net.cpp:84] Creating Layer layer_64_2_bn1
I0528 21:52:10.403385 142708 net.cpp:406] layer_64_2_bn1 <- layer_64_1_sum_layer_64_1_sum_0_split_0
I0528 21:52:10.403391 142708 net.cpp:380] layer_64_2_bn1 -> layer_64_2_bn1
I0528 21:52:10.403614 142708 net.cpp:122] Setting up layer_64_2_bn1
I0528 21:52:10.403622 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403625 142708 net.cpp:137] Memory required for data: 1214259800
I0528 21:52:10.403633 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:52:10.403643 142708 net.cpp:84] Creating Layer layer_64_2_scale1
I0528 21:52:10.403647 142708 net.cpp:406] layer_64_2_scale1 <- layer_64_2_bn1
I0528 21:52:10.403654 142708 net.cpp:367] layer_64_2_scale1 -> layer_64_2_bn1 (in-place)
I0528 21:52:10.403702 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale1
I0528 21:52:10.403838 142708 net.cpp:122] Setting up layer_64_2_scale1
I0528 21:52:10.403846 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.403856 142708 net.cpp:137] Memory required for data: 1254400600
I0528 21:52:10.403869 142708 layer_factory.hpp:77] Creating layer layer_64_2_relu1
I0528 21:52:10.403877 142708 net.cpp:84] Creating Layer layer_64_2_relu1
I0528 21:52:10.403882 142708 net.cpp:406] layer_64_2_relu1 <- layer_64_2_bn1
I0528 21:52:10.403887 142708 net.cpp:367] layer_64_2_relu1 -> layer_64_2_bn1 (in-place)
I0528 21:52:10.404500 142708 net.cpp:122] Setting up layer_64_2_relu1
I0528 21:52:10.404516 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.404520 142708 net.cpp:137] Memory required for data: 1294541400
I0528 21:52:10.404525 142708 layer_factory.hpp:77] Creating layer layer_64_2_conv1
I0528 21:52:10.404539 142708 net.cpp:84] Creating Layer layer_64_2_conv1
I0528 21:52:10.404544 142708 net.cpp:406] layer_64_2_conv1 <- layer_64_2_bn1
I0528 21:52:10.404552 142708 net.cpp:380] layer_64_2_conv1 -> layer_64_2_conv1
I0528 21:52:10.406718 142708 net.cpp:122] Setting up layer_64_2_conv1
I0528 21:52:10.406736 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.406740 142708 net.cpp:137] Memory required for data: 1334682200
I0528 21:52:10.406746 142708 layer_factory.hpp:77] Creating layer layer_64_2_bn2
I0528 21:52:10.406755 142708 net.cpp:84] Creating Layer layer_64_2_bn2
I0528 21:52:10.406760 142708 net.cpp:406] layer_64_2_bn2 <- layer_64_2_conv1
I0528 21:52:10.406767 142708 net.cpp:367] layer_64_2_bn2 -> layer_64_2_conv1 (in-place)
I0528 21:52:10.406988 142708 net.cpp:122] Setting up layer_64_2_bn2
I0528 21:52:10.406996 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.406999 142708 net.cpp:137] Memory required for data: 1374823000
I0528 21:52:10.407007 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:52:10.407016 142708 net.cpp:84] Creating Layer layer_64_2_scale2
I0528 21:52:10.407019 142708 net.cpp:406] layer_64_2_scale2 <- layer_64_2_conv1
I0528 21:52:10.407027 142708 net.cpp:367] layer_64_2_scale2 -> layer_64_2_conv1 (in-place)
I0528 21:52:10.407079 142708 layer_factory.hpp:77] Creating layer layer_64_2_scale2
I0528 21:52:10.407220 142708 net.cpp:122] Setting up layer_64_2_scale2
I0528 21:52:10.407228 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.407232 142708 net.cpp:137] Memory required for data: 1414963800
I0528 21:52:10.407238 142708 layer_factory.hpp:77] Creating layer layer_64_2_relu2
I0528 21:52:10.407245 142708 net.cpp:84] Creating Layer layer_64_2_relu2
I0528 21:52:10.407249 142708 net.cpp:406] layer_64_2_relu2 <- layer_64_2_conv1
I0528 21:52:10.407255 142708 net.cpp:367] layer_64_2_relu2 -> layer_64_2_conv1 (in-place)
I0528 21:52:10.407853 142708 net.cpp:122] Setting up layer_64_2_relu2
I0528 21:52:10.407867 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.407871 142708 net.cpp:137] Memory required for data: 1455104600
I0528 21:52:10.407876 142708 layer_factory.hpp:77] Creating layer layer_64_2_conv2
I0528 21:52:10.407887 142708 net.cpp:84] Creating Layer layer_64_2_conv2
I0528 21:52:10.407891 142708 net.cpp:406] layer_64_2_conv2 <- layer_64_2_conv1
I0528 21:52:10.407901 142708 net.cpp:380] layer_64_2_conv2 -> layer_64_2_conv2
I0528 21:52:10.410495 142708 net.cpp:122] Setting up layer_64_2_conv2
I0528 21:52:10.410514 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.410518 142708 net.cpp:137] Memory required for data: 1495245400
I0528 21:52:10.410524 142708 layer_factory.hpp:77] Creating layer layer_64_2_sum
I0528 21:52:10.410532 142708 net.cpp:84] Creating Layer layer_64_2_sum
I0528 21:52:10.410537 142708 net.cpp:406] layer_64_2_sum <- layer_64_2_conv2
I0528 21:52:10.410542 142708 net.cpp:406] layer_64_2_sum <- layer_64_1_sum_layer_64_1_sum_0_split_1
I0528 21:52:10.410548 142708 net.cpp:380] layer_64_2_sum -> layer_64_2_sum
I0528 21:52:10.410580 142708 net.cpp:122] Setting up layer_64_2_sum
I0528 21:52:10.410588 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.410591 142708 net.cpp:137] Memory required for data: 1535386200
I0528 21:52:10.410600 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn1
I0528 21:52:10.410615 142708 net.cpp:84] Creating Layer layer_128_1_bn1
I0528 21:52:10.410620 142708 net.cpp:406] layer_128_1_bn1 <- layer_64_2_sum
I0528 21:52:10.410627 142708 net.cpp:380] layer_128_1_bn1 -> layer_128_1_bn1
I0528 21:52:10.410853 142708 net.cpp:122] Setting up layer_128_1_bn1
I0528 21:52:10.410861 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.410864 142708 net.cpp:137] Memory required for data: 1575527000
I0528 21:52:10.410878 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:52:10.410887 142708 net.cpp:84] Creating Layer layer_128_1_scale1
I0528 21:52:10.410892 142708 net.cpp:406] layer_128_1_scale1 <- layer_128_1_bn1
I0528 21:52:10.410897 142708 net.cpp:367] layer_128_1_scale1 -> layer_128_1_bn1 (in-place)
I0528 21:52:10.410946 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale1
I0528 21:52:10.411094 142708 net.cpp:122] Setting up layer_128_1_scale1
I0528 21:52:10.411105 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.411109 142708 net.cpp:137] Memory required for data: 1615667800
I0528 21:52:10.411115 142708 layer_factory.hpp:77] Creating layer layer_128_1_relu1
I0528 21:52:10.411123 142708 net.cpp:84] Creating Layer layer_128_1_relu1
I0528 21:52:10.411128 142708 net.cpp:406] layer_128_1_relu1 <- layer_128_1_bn1
I0528 21:52:10.411133 142708 net.cpp:367] layer_128_1_relu1 -> layer_128_1_bn1 (in-place)
I0528 21:52:10.411310 142708 net.cpp:122] Setting up layer_128_1_relu1
I0528 21:52:10.411321 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.411324 142708 net.cpp:137] Memory required for data: 1655808600
I0528 21:52:10.411329 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:10.411334 142708 net.cpp:84] Creating Layer layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:10.411339 142708 net.cpp:406] layer_128_1_bn1_layer_128_1_relu1_0_split <- layer_128_1_bn1
I0528 21:52:10.411345 142708 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:52:10.411352 142708 net.cpp:380] layer_128_1_bn1_layer_128_1_relu1_0_split -> layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:52:10.411401 142708 net.cpp:122] Setting up layer_128_1_bn1_layer_128_1_relu1_0_split
I0528 21:52:10.411407 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.411412 142708 net.cpp:129] Top shape: 50 64 56 56 (10035200)
I0528 21:52:10.411414 142708 net.cpp:137] Memory required for data: 1736090200
I0528 21:52:10.411418 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv1
I0528 21:52:10.411432 142708 net.cpp:84] Creating Layer layer_128_1_conv1
I0528 21:52:10.411435 142708 net.cpp:406] layer_128_1_conv1 <- layer_128_1_bn1_layer_128_1_relu1_0_split_0
I0528 21:52:10.411443 142708 net.cpp:380] layer_128_1_conv1 -> layer_128_1_conv1
I0528 21:52:10.415117 142708 net.cpp:122] Setting up layer_128_1_conv1
I0528 21:52:10.415134 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.415139 142708 net.cpp:137] Memory required for data: 1756160600
I0528 21:52:10.415145 142708 layer_factory.hpp:77] Creating layer layer_128_1_bn2
I0528 21:52:10.415154 142708 net.cpp:84] Creating Layer layer_128_1_bn2
I0528 21:52:10.415159 142708 net.cpp:406] layer_128_1_bn2 <- layer_128_1_conv1
I0528 21:52:10.415166 142708 net.cpp:367] layer_128_1_bn2 -> layer_128_1_conv1 (in-place)
I0528 21:52:10.415375 142708 net.cpp:122] Setting up layer_128_1_bn2
I0528 21:52:10.415383 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.415386 142708 net.cpp:137] Memory required for data: 1776231000
I0528 21:52:10.415395 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:52:10.415407 142708 net.cpp:84] Creating Layer layer_128_1_scale2
I0528 21:52:10.415411 142708 net.cpp:406] layer_128_1_scale2 <- layer_128_1_conv1
I0528 21:52:10.415417 142708 net.cpp:367] layer_128_1_scale2 -> layer_128_1_conv1 (in-place)
I0528 21:52:10.415462 142708 layer_factory.hpp:77] Creating layer layer_128_1_scale2
I0528 21:52:10.415604 142708 net.cpp:122] Setting up layer_128_1_scale2
I0528 21:52:10.415613 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.415616 142708 net.cpp:137] Memory required for data: 1796301400
I0528 21:52:10.415622 142708 layer_factory.hpp:77] Creating layer layer_128_1_relu2
I0528 21:52:10.415628 142708 net.cpp:84] Creating Layer layer_128_1_relu2
I0528 21:52:10.415632 142708 net.cpp:406] layer_128_1_relu2 <- layer_128_1_conv1
I0528 21:52:10.415638 142708 net.cpp:367] layer_128_1_relu2 -> layer_128_1_conv1 (in-place)
I0528 21:52:10.416249 142708 net.cpp:122] Setting up layer_128_1_relu2
I0528 21:52:10.416266 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.416271 142708 net.cpp:137] Memory required for data: 1816371800
I0528 21:52:10.416275 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv2
I0528 21:52:10.416285 142708 net.cpp:84] Creating Layer layer_128_1_conv2
I0528 21:52:10.416290 142708 net.cpp:406] layer_128_1_conv2 <- layer_128_1_conv1
I0528 21:52:10.416298 142708 net.cpp:380] layer_128_1_conv2 -> layer_128_1_conv2
I0528 21:52:10.422082 142708 net.cpp:122] Setting up layer_128_1_conv2
I0528 21:52:10.422101 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.422106 142708 net.cpp:137] Memory required for data: 1836442200
I0528 21:52:10.422111 142708 layer_factory.hpp:77] Creating layer layer_128_1_conv_expand
I0528 21:52:10.422124 142708 net.cpp:84] Creating Layer layer_128_1_conv_expand
I0528 21:52:10.422129 142708 net.cpp:406] layer_128_1_conv_expand <- layer_128_1_bn1_layer_128_1_relu1_0_split_1
I0528 21:52:10.422137 142708 net.cpp:380] layer_128_1_conv_expand -> layer_128_1_conv_expand
I0528 21:52:10.423969 142708 net.cpp:122] Setting up layer_128_1_conv_expand
I0528 21:52:10.423987 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.423991 142708 net.cpp:137] Memory required for data: 1856512600
I0528 21:52:10.423997 142708 layer_factory.hpp:77] Creating layer layer_128_1_sum
I0528 21:52:10.424005 142708 net.cpp:84] Creating Layer layer_128_1_sum
I0528 21:52:10.424008 142708 net.cpp:406] layer_128_1_sum <- layer_128_1_conv_expand
I0528 21:52:10.424013 142708 net.cpp:406] layer_128_1_sum <- layer_128_1_conv2
I0528 21:52:10.424019 142708 net.cpp:380] layer_128_1_sum -> layer_128_1_sum
I0528 21:52:10.424057 142708 net.cpp:122] Setting up layer_128_1_sum
I0528 21:52:10.424068 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.424072 142708 net.cpp:137] Memory required for data: 1876583000
I0528 21:52:10.424075 142708 layer_factory.hpp:77] Creating layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:10.424087 142708 net.cpp:84] Creating Layer layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:10.424090 142708 net.cpp:406] layer_128_1_sum_layer_128_1_sum_0_split <- layer_128_1_sum
I0528 21:52:10.424096 142708 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:52:10.424103 142708 net.cpp:380] layer_128_1_sum_layer_128_1_sum_0_split -> layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:52:10.424147 142708 net.cpp:122] Setting up layer_128_1_sum_layer_128_1_sum_0_split
I0528 21:52:10.424154 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.424159 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.424161 142708 net.cpp:137] Memory required for data: 1916723800
I0528 21:52:10.424165 142708 layer_factory.hpp:77] Creating layer layer_128_2_bn1
I0528 21:52:10.424171 142708 net.cpp:84] Creating Layer layer_128_2_bn1
I0528 21:52:10.424175 142708 net.cpp:406] layer_128_2_bn1 <- layer_128_1_sum_layer_128_1_sum_0_split_0
I0528 21:52:10.424182 142708 net.cpp:380] layer_128_2_bn1 -> layer_128_2_bn1
I0528 21:52:10.424398 142708 net.cpp:122] Setting up layer_128_2_bn1
I0528 21:52:10.424407 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.424409 142708 net.cpp:137] Memory required for data: 1936794200
I0528 21:52:10.424417 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:52:10.424437 142708 net.cpp:84] Creating Layer layer_128_2_scale1
I0528 21:52:10.424441 142708 net.cpp:406] layer_128_2_scale1 <- layer_128_2_bn1
I0528 21:52:10.424448 142708 net.cpp:367] layer_128_2_scale1 -> layer_128_2_bn1 (in-place)
I0528 21:52:10.424495 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale1
I0528 21:52:10.424619 142708 net.cpp:122] Setting up layer_128_2_scale1
I0528 21:52:10.424628 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.424631 142708 net.cpp:137] Memory required for data: 1956864600
I0528 21:52:10.424636 142708 layer_factory.hpp:77] Creating layer layer_128_2_relu1
I0528 21:52:10.424643 142708 net.cpp:84] Creating Layer layer_128_2_relu1
I0528 21:52:10.424646 142708 net.cpp:406] layer_128_2_relu1 <- layer_128_2_bn1
I0528 21:52:10.424654 142708 net.cpp:367] layer_128_2_relu1 -> layer_128_2_bn1 (in-place)
I0528 21:52:10.425266 142708 net.cpp:122] Setting up layer_128_2_relu1
I0528 21:52:10.425282 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.425287 142708 net.cpp:137] Memory required for data: 1976935000
I0528 21:52:10.425290 142708 layer_factory.hpp:77] Creating layer layer_128_2_conv1
I0528 21:52:10.425302 142708 net.cpp:84] Creating Layer layer_128_2_conv1
I0528 21:52:10.425307 142708 net.cpp:406] layer_128_2_conv1 <- layer_128_2_bn1
I0528 21:52:10.425315 142708 net.cpp:380] layer_128_2_conv1 -> layer_128_2_conv1
I0528 21:52:10.431517 142708 net.cpp:122] Setting up layer_128_2_conv1
I0528 21:52:10.431537 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.431542 142708 net.cpp:137] Memory required for data: 1997005400
I0528 21:52:10.431548 142708 layer_factory.hpp:77] Creating layer layer_128_2_bn2
I0528 21:52:10.431555 142708 net.cpp:84] Creating Layer layer_128_2_bn2
I0528 21:52:10.431560 142708 net.cpp:406] layer_128_2_bn2 <- layer_128_2_conv1
I0528 21:52:10.431567 142708 net.cpp:367] layer_128_2_bn2 -> layer_128_2_conv1 (in-place)
I0528 21:52:10.431778 142708 net.cpp:122] Setting up layer_128_2_bn2
I0528 21:52:10.431787 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.431790 142708 net.cpp:137] Memory required for data: 2017075800
I0528 21:52:10.431798 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:52:10.431807 142708 net.cpp:84] Creating Layer layer_128_2_scale2
I0528 21:52:10.431810 142708 net.cpp:406] layer_128_2_scale2 <- layer_128_2_conv1
I0528 21:52:10.431815 142708 net.cpp:367] layer_128_2_scale2 -> layer_128_2_conv1 (in-place)
I0528 21:52:10.431862 142708 layer_factory.hpp:77] Creating layer layer_128_2_scale2
I0528 21:52:10.431987 142708 net.cpp:122] Setting up layer_128_2_scale2
I0528 21:52:10.431993 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.431998 142708 net.cpp:137] Memory required for data: 2037146200
I0528 21:52:10.432003 142708 layer_factory.hpp:77] Creating layer layer_128_2_relu2
I0528 21:52:10.432009 142708 net.cpp:84] Creating Layer layer_128_2_relu2
I0528 21:52:10.432013 142708 net.cpp:406] layer_128_2_relu2 <- layer_128_2_conv1
I0528 21:52:10.432019 142708 net.cpp:367] layer_128_2_relu2 -> layer_128_2_conv1 (in-place)
I0528 21:52:10.432205 142708 net.cpp:122] Setting up layer_128_2_relu2
I0528 21:52:10.432219 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.432222 142708 net.cpp:137] Memory required for data: 2057216600
I0528 21:52:10.432225 142708 layer_factory.hpp:77] Creating layer layer_128_2_conv2
I0528 21:52:10.432236 142708 net.cpp:84] Creating Layer layer_128_2_conv2
I0528 21:52:10.432241 142708 net.cpp:406] layer_128_2_conv2 <- layer_128_2_conv1
I0528 21:52:10.432250 142708 net.cpp:380] layer_128_2_conv2 -> layer_128_2_conv2
I0528 21:52:10.441216 142708 net.cpp:122] Setting up layer_128_2_conv2
I0528 21:52:10.441234 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.441239 142708 net.cpp:137] Memory required for data: 2077287000
I0528 21:52:10.441246 142708 layer_factory.hpp:77] Creating layer layer_128_2_sum
I0528 21:52:10.441258 142708 net.cpp:84] Creating Layer layer_128_2_sum
I0528 21:52:10.441270 142708 net.cpp:406] layer_128_2_sum <- layer_128_2_conv2
I0528 21:52:10.441277 142708 net.cpp:406] layer_128_2_sum <- layer_128_1_sum_layer_128_1_sum_0_split_1
I0528 21:52:10.441284 142708 net.cpp:380] layer_128_2_sum -> layer_128_2_sum
I0528 21:52:10.441316 142708 net.cpp:122] Setting up layer_128_2_sum
I0528 21:52:10.441325 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.441329 142708 net.cpp:137] Memory required for data: 2097357400
I0528 21:52:10.441334 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn1
I0528 21:52:10.441340 142708 net.cpp:84] Creating Layer layer_256_1_bn1
I0528 21:52:10.441344 142708 net.cpp:406] layer_256_1_bn1 <- layer_128_2_sum
I0528 21:52:10.441351 142708 net.cpp:380] layer_256_1_bn1 -> layer_256_1_bn1
I0528 21:52:10.441571 142708 net.cpp:122] Setting up layer_256_1_bn1
I0528 21:52:10.441579 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.441583 142708 net.cpp:137] Memory required for data: 2117427800
I0528 21:52:10.441591 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:52:10.441597 142708 net.cpp:84] Creating Layer layer_256_1_scale1
I0528 21:52:10.441601 142708 net.cpp:406] layer_256_1_scale1 <- layer_256_1_bn1
I0528 21:52:10.441613 142708 net.cpp:367] layer_256_1_scale1 -> layer_256_1_bn1 (in-place)
I0528 21:52:10.441661 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale1
I0528 21:52:10.441786 142708 net.cpp:122] Setting up layer_256_1_scale1
I0528 21:52:10.441793 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.441797 142708 net.cpp:137] Memory required for data: 2137498200
I0528 21:52:10.441802 142708 layer_factory.hpp:77] Creating layer layer_256_1_relu1
I0528 21:52:10.441808 142708 net.cpp:84] Creating Layer layer_256_1_relu1
I0528 21:52:10.441812 142708 net.cpp:406] layer_256_1_relu1 <- layer_256_1_bn1
I0528 21:52:10.441817 142708 net.cpp:367] layer_256_1_relu1 -> layer_256_1_bn1 (in-place)
I0528 21:52:10.442001 142708 net.cpp:122] Setting up layer_256_1_relu1
I0528 21:52:10.442011 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.442014 142708 net.cpp:137] Memory required for data: 2157568600
I0528 21:52:10.442018 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:10.442025 142708 net.cpp:84] Creating Layer layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:10.442029 142708 net.cpp:406] layer_256_1_bn1_layer_256_1_relu1_0_split <- layer_256_1_bn1
I0528 21:52:10.442034 142708 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:52:10.442054 142708 net.cpp:380] layer_256_1_bn1_layer_256_1_relu1_0_split -> layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:52:10.442111 142708 net.cpp:122] Setting up layer_256_1_bn1_layer_256_1_relu1_0_split
I0528 21:52:10.442121 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.442126 142708 net.cpp:129] Top shape: 50 128 28 28 (5017600)
I0528 21:52:10.442128 142708 net.cpp:137] Memory required for data: 2197709400
I0528 21:52:10.442132 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv1
I0528 21:52:10.442143 142708 net.cpp:84] Creating Layer layer_256_1_conv1
I0528 21:52:10.442148 142708 net.cpp:406] layer_256_1_conv1 <- layer_256_1_bn1_layer_256_1_relu1_0_split_0
I0528 21:52:10.442155 142708 net.cpp:380] layer_256_1_conv1 -> layer_256_1_conv1
I0528 21:52:10.452440 142708 net.cpp:122] Setting up layer_256_1_conv1
I0528 21:52:10.452461 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.452466 142708 net.cpp:137] Memory required for data: 2207744600
I0528 21:52:10.452472 142708 layer_factory.hpp:77] Creating layer layer_256_1_bn2
I0528 21:52:10.452481 142708 net.cpp:84] Creating Layer layer_256_1_bn2
I0528 21:52:10.452486 142708 net.cpp:406] layer_256_1_bn2 <- layer_256_1_conv1
I0528 21:52:10.452492 142708 net.cpp:367] layer_256_1_bn2 -> layer_256_1_conv1 (in-place)
I0528 21:52:10.452736 142708 net.cpp:122] Setting up layer_256_1_bn2
I0528 21:52:10.452750 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.452761 142708 net.cpp:137] Memory required for data: 2217779800
I0528 21:52:10.452785 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:52:10.452792 142708 net.cpp:84] Creating Layer layer_256_1_scale2
I0528 21:52:10.452797 142708 net.cpp:406] layer_256_1_scale2 <- layer_256_1_conv1
I0528 21:52:10.452805 142708 net.cpp:367] layer_256_1_scale2 -> layer_256_1_conv1 (in-place)
I0528 21:52:10.452855 142708 layer_factory.hpp:77] Creating layer layer_256_1_scale2
I0528 21:52:10.452980 142708 net.cpp:122] Setting up layer_256_1_scale2
I0528 21:52:10.452988 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.452991 142708 net.cpp:137] Memory required for data: 2227815000
I0528 21:52:10.452998 142708 layer_factory.hpp:77] Creating layer layer_256_1_relu2
I0528 21:52:10.453004 142708 net.cpp:84] Creating Layer layer_256_1_relu2
I0528 21:52:10.453008 142708 net.cpp:406] layer_256_1_relu2 <- layer_256_1_conv1
I0528 21:52:10.453016 142708 net.cpp:367] layer_256_1_relu2 -> layer_256_1_conv1 (in-place)
I0528 21:52:10.453627 142708 net.cpp:122] Setting up layer_256_1_relu2
I0528 21:52:10.453644 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.453649 142708 net.cpp:137] Memory required for data: 2237850200
I0528 21:52:10.453651 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv2
I0528 21:52:10.453665 142708 net.cpp:84] Creating Layer layer_256_1_conv2
I0528 21:52:10.453670 142708 net.cpp:406] layer_256_1_conv2 <- layer_256_1_conv1
I0528 21:52:10.453677 142708 net.cpp:380] layer_256_1_conv2 -> layer_256_1_conv2
I0528 21:52:10.472559 142708 net.cpp:122] Setting up layer_256_1_conv2
I0528 21:52:10.472591 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.472596 142708 net.cpp:137] Memory required for data: 2247885400
I0528 21:52:10.472604 142708 layer_factory.hpp:77] Creating layer layer_256_1_conv_expand
I0528 21:52:10.472620 142708 net.cpp:84] Creating Layer layer_256_1_conv_expand
I0528 21:52:10.472626 142708 net.cpp:406] layer_256_1_conv_expand <- layer_256_1_bn1_layer_256_1_relu1_0_split_1
I0528 21:52:10.472636 142708 net.cpp:380] layer_256_1_conv_expand -> layer_256_1_conv_expand
I0528 21:52:10.478945 142708 net.cpp:122] Setting up layer_256_1_conv_expand
I0528 21:52:10.478968 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.478973 142708 net.cpp:137] Memory required for data: 2257920600
I0528 21:52:10.478979 142708 layer_factory.hpp:77] Creating layer layer_256_1_sum
I0528 21:52:10.478986 142708 net.cpp:84] Creating Layer layer_256_1_sum
I0528 21:52:10.478992 142708 net.cpp:406] layer_256_1_sum <- layer_256_1_conv_expand
I0528 21:52:10.478997 142708 net.cpp:406] layer_256_1_sum <- layer_256_1_conv2
I0528 21:52:10.479003 142708 net.cpp:380] layer_256_1_sum -> layer_256_1_sum
I0528 21:52:10.479044 142708 net.cpp:122] Setting up layer_256_1_sum
I0528 21:52:10.479055 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.479059 142708 net.cpp:137] Memory required for data: 2267955800
I0528 21:52:10.479063 142708 layer_factory.hpp:77] Creating layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.479070 142708 net.cpp:84] Creating Layer layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.479075 142708 net.cpp:406] layer_256_1_sum_layer_256_1_sum_0_split <- layer_256_1_sum
I0528 21:52:10.479082 142708 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:52:10.479090 142708 net.cpp:380] layer_256_1_sum_layer_256_1_sum_0_split -> layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:52:10.479135 142708 net.cpp:122] Setting up layer_256_1_sum_layer_256_1_sum_0_split
I0528 21:52:10.479143 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.479147 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.479151 142708 net.cpp:137] Memory required for data: 2288026200
I0528 21:52:10.479154 142708 layer_factory.hpp:77] Creating layer layer_256_2_bn1
I0528 21:52:10.479169 142708 net.cpp:84] Creating Layer layer_256_2_bn1
I0528 21:52:10.479183 142708 net.cpp:406] layer_256_2_bn1 <- layer_256_1_sum_layer_256_1_sum_0_split_0
I0528 21:52:10.479192 142708 net.cpp:380] layer_256_2_bn1 -> layer_256_2_bn1
I0528 21:52:10.479427 142708 net.cpp:122] Setting up layer_256_2_bn1
I0528 21:52:10.479436 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.479439 142708 net.cpp:137] Memory required for data: 2298061400
I0528 21:52:10.479447 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:52:10.479457 142708 net.cpp:84] Creating Layer layer_256_2_scale1
I0528 21:52:10.479461 142708 net.cpp:406] layer_256_2_scale1 <- layer_256_2_bn1
I0528 21:52:10.479467 142708 net.cpp:367] layer_256_2_scale1 -> layer_256_2_bn1 (in-place)
I0528 21:52:10.479523 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale1
I0528 21:52:10.479648 142708 net.cpp:122] Setting up layer_256_2_scale1
I0528 21:52:10.479656 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.479660 142708 net.cpp:137] Memory required for data: 2308096600
I0528 21:52:10.479666 142708 layer_factory.hpp:77] Creating layer layer_256_2_relu1
I0528 21:52:10.479672 142708 net.cpp:84] Creating Layer layer_256_2_relu1
I0528 21:52:10.479676 142708 net.cpp:406] layer_256_2_relu1 <- layer_256_2_bn1
I0528 21:52:10.479681 142708 net.cpp:367] layer_256_2_relu1 -> layer_256_2_bn1 (in-place)
I0528 21:52:10.480337 142708 net.cpp:122] Setting up layer_256_2_relu1
I0528 21:52:10.480355 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.480360 142708 net.cpp:137] Memory required for data: 2318131800
I0528 21:52:10.480365 142708 layer_factory.hpp:77] Creating layer layer_256_2_conv1
I0528 21:52:10.480377 142708 net.cpp:84] Creating Layer layer_256_2_conv1
I0528 21:52:10.480382 142708 net.cpp:406] layer_256_2_conv1 <- layer_256_2_bn1
I0528 21:52:10.480389 142708 net.cpp:380] layer_256_2_conv1 -> layer_256_2_conv1
I0528 21:52:10.500461 142708 net.cpp:122] Setting up layer_256_2_conv1
I0528 21:52:10.500483 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.500486 142708 net.cpp:137] Memory required for data: 2328167000
I0528 21:52:10.500494 142708 layer_factory.hpp:77] Creating layer layer_256_2_bn2
I0528 21:52:10.500504 142708 net.cpp:84] Creating Layer layer_256_2_bn2
I0528 21:52:10.500509 142708 net.cpp:406] layer_256_2_bn2 <- layer_256_2_conv1
I0528 21:52:10.500515 142708 net.cpp:367] layer_256_2_bn2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.500746 142708 net.cpp:122] Setting up layer_256_2_bn2
I0528 21:52:10.500754 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.500758 142708 net.cpp:137] Memory required for data: 2338202200
I0528 21:52:10.500766 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:52:10.500784 142708 net.cpp:84] Creating Layer layer_256_2_scale2
I0528 21:52:10.500789 142708 net.cpp:406] layer_256_2_scale2 <- layer_256_2_conv1
I0528 21:52:10.500795 142708 net.cpp:367] layer_256_2_scale2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.500852 142708 layer_factory.hpp:77] Creating layer layer_256_2_scale2
I0528 21:52:10.500986 142708 net.cpp:122] Setting up layer_256_2_scale2
I0528 21:52:10.500994 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.500998 142708 net.cpp:137] Memory required for data: 2348237400
I0528 21:52:10.501005 142708 layer_factory.hpp:77] Creating layer layer_256_2_relu2
I0528 21:52:10.501013 142708 net.cpp:84] Creating Layer layer_256_2_relu2
I0528 21:52:10.501018 142708 net.cpp:406] layer_256_2_relu2 <- layer_256_2_conv1
I0528 21:52:10.501024 142708 net.cpp:367] layer_256_2_relu2 -> layer_256_2_conv1 (in-place)
I0528 21:52:10.501240 142708 net.cpp:122] Setting up layer_256_2_relu2
I0528 21:52:10.501255 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.501260 142708 net.cpp:137] Memory required for data: 2358272600
I0528 21:52:10.501263 142708 layer_factory.hpp:77] Creating layer layer_256_2_conv2
I0528 21:52:10.501284 142708 net.cpp:84] Creating Layer layer_256_2_conv2
I0528 21:52:10.501302 142708 net.cpp:406] layer_256_2_conv2 <- layer_256_2_conv1
I0528 21:52:10.501312 142708 net.cpp:380] layer_256_2_conv2 -> layer_256_2_conv2
I0528 21:52:10.521272 142708 net.cpp:122] Setting up layer_256_2_conv2
I0528 21:52:10.521296 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.521301 142708 net.cpp:137] Memory required for data: 2368307800
I0528 21:52:10.521307 142708 layer_factory.hpp:77] Creating layer layer_256_2_sum
I0528 21:52:10.521316 142708 net.cpp:84] Creating Layer layer_256_2_sum
I0528 21:52:10.521320 142708 net.cpp:406] layer_256_2_sum <- layer_256_2_conv2
I0528 21:52:10.521327 142708 net.cpp:406] layer_256_2_sum <- layer_256_1_sum_layer_256_1_sum_0_split_1
I0528 21:52:10.521334 142708 net.cpp:380] layer_256_2_sum -> layer_256_2_sum
I0528 21:52:10.521370 142708 net.cpp:122] Setting up layer_256_2_sum
I0528 21:52:10.521378 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.521381 142708 net.cpp:137] Memory required for data: 2378343000
I0528 21:52:10.521384 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn1
I0528 21:52:10.521394 142708 net.cpp:84] Creating Layer layer_512_1_bn1
I0528 21:52:10.521399 142708 net.cpp:406] layer_512_1_bn1 <- layer_256_2_sum
I0528 21:52:10.521407 142708 net.cpp:380] layer_512_1_bn1 -> layer_512_1_bn1
I0528 21:52:10.521646 142708 net.cpp:122] Setting up layer_512_1_bn1
I0528 21:52:10.521656 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.521659 142708 net.cpp:137] Memory required for data: 2388378200
I0528 21:52:10.521668 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:52:10.521675 142708 net.cpp:84] Creating Layer layer_512_1_scale1
I0528 21:52:10.521679 142708 net.cpp:406] layer_512_1_scale1 <- layer_512_1_bn1
I0528 21:52:10.521685 142708 net.cpp:367] layer_512_1_scale1 -> layer_512_1_bn1 (in-place)
I0528 21:52:10.521740 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale1
I0528 21:52:10.521872 142708 net.cpp:122] Setting up layer_512_1_scale1
I0528 21:52:10.521880 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.521884 142708 net.cpp:137] Memory required for data: 2398413400
I0528 21:52:10.521890 142708 layer_factory.hpp:77] Creating layer layer_512_1_relu1
I0528 21:52:10.521899 142708 net.cpp:84] Creating Layer layer_512_1_relu1
I0528 21:52:10.521903 142708 net.cpp:406] layer_512_1_relu1 <- layer_512_1_bn1
I0528 21:52:10.521908 142708 net.cpp:367] layer_512_1_relu1 -> layer_512_1_bn1 (in-place)
I0528 21:52:10.522553 142708 net.cpp:122] Setting up layer_512_1_relu1
I0528 21:52:10.522572 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.522578 142708 net.cpp:137] Memory required for data: 2408448600
I0528 21:52:10.522581 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.522588 142708 net.cpp:84] Creating Layer layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.522593 142708 net.cpp:406] layer_512_1_bn1_layer_512_1_relu1_0_split <- layer_512_1_bn1
I0528 21:52:10.522599 142708 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:52:10.522608 142708 net.cpp:380] layer_512_1_bn1_layer_512_1_relu1_0_split -> layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:52:10.522665 142708 net.cpp:122] Setting up layer_512_1_bn1_layer_512_1_relu1_0_split
I0528 21:52:10.522673 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.522678 142708 net.cpp:129] Top shape: 50 256 14 14 (2508800)
I0528 21:52:10.522683 142708 net.cpp:137] Memory required for data: 2428519000
I0528 21:52:10.522686 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv1
I0528 21:52:10.522699 142708 net.cpp:84] Creating Layer layer_512_1_conv1
I0528 21:52:10.522704 142708 net.cpp:406] layer_512_1_conv1 <- layer_512_1_bn1_layer_512_1_relu1_0_split_0
I0528 21:52:10.522713 142708 net.cpp:380] layer_512_1_conv1 -> layer_512_1_conv1
I0528 21:52:10.560547 142708 net.cpp:122] Setting up layer_512_1_conv1
I0528 21:52:10.560602 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.560619 142708 net.cpp:137] Memory required for data: 2433536600
I0528 21:52:10.560631 142708 layer_factory.hpp:77] Creating layer layer_512_1_bn2
I0528 21:52:10.560642 142708 net.cpp:84] Creating Layer layer_512_1_bn2
I0528 21:52:10.560649 142708 net.cpp:406] layer_512_1_bn2 <- layer_512_1_conv1
I0528 21:52:10.560657 142708 net.cpp:367] layer_512_1_bn2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.560942 142708 net.cpp:122] Setting up layer_512_1_bn2
I0528 21:52:10.560951 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.560956 142708 net.cpp:137] Memory required for data: 2438554200
I0528 21:52:10.560963 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:52:10.560972 142708 net.cpp:84] Creating Layer layer_512_1_scale2
I0528 21:52:10.560976 142708 net.cpp:406] layer_512_1_scale2 <- layer_512_1_conv1
I0528 21:52:10.560982 142708 net.cpp:367] layer_512_1_scale2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.561048 142708 layer_factory.hpp:77] Creating layer layer_512_1_scale2
I0528 21:52:10.561200 142708 net.cpp:122] Setting up layer_512_1_scale2
I0528 21:52:10.561209 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.561213 142708 net.cpp:137] Memory required for data: 2443571800
I0528 21:52:10.561219 142708 layer_factory.hpp:77] Creating layer layer_512_1_relu2
I0528 21:52:10.561226 142708 net.cpp:84] Creating Layer layer_512_1_relu2
I0528 21:52:10.561231 142708 net.cpp:406] layer_512_1_relu2 <- layer_512_1_conv1
I0528 21:52:10.561239 142708 net.cpp:367] layer_512_1_relu2 -> layer_512_1_conv1 (in-place)
I0528 21:52:10.561892 142708 net.cpp:122] Setting up layer_512_1_relu2
I0528 21:52:10.561906 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.561910 142708 net.cpp:137] Memory required for data: 2448589400
I0528 21:52:10.561914 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv2
I0528 21:52:10.561929 142708 net.cpp:84] Creating Layer layer_512_1_conv2
I0528 21:52:10.561934 142708 net.cpp:406] layer_512_1_conv2 <- layer_512_1_conv1
I0528 21:52:10.561944 142708 net.cpp:380] layer_512_1_conv2 -> layer_512_1_conv2
I0528 21:52:10.635731 142708 net.cpp:122] Setting up layer_512_1_conv2
I0528 21:52:10.635779 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.635784 142708 net.cpp:137] Memory required for data: 2453607000
I0528 21:52:10.635795 142708 layer_factory.hpp:77] Creating layer layer_512_1_conv_expand
I0528 21:52:10.635815 142708 net.cpp:84] Creating Layer layer_512_1_conv_expand
I0528 21:52:10.635823 142708 net.cpp:406] layer_512_1_conv_expand <- layer_512_1_bn1_layer_512_1_relu1_0_split_1
I0528 21:52:10.635834 142708 net.cpp:380] layer_512_1_conv_expand -> layer_512_1_conv_expand
I0528 21:52:10.641273 142708 net.cpp:122] Setting up layer_512_1_conv_expand
I0528 21:52:10.641293 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641296 142708 net.cpp:137] Memory required for data: 2458624600
I0528 21:52:10.641302 142708 layer_factory.hpp:77] Creating layer layer_512_1_sum
I0528 21:52:10.641310 142708 net.cpp:84] Creating Layer layer_512_1_sum
I0528 21:52:10.641315 142708 net.cpp:406] layer_512_1_sum <- layer_512_1_conv_expand
I0528 21:52:10.641320 142708 net.cpp:406] layer_512_1_sum <- layer_512_1_conv2
I0528 21:52:10.641329 142708 net.cpp:380] layer_512_1_sum -> layer_512_1_sum
I0528 21:52:10.641363 142708 net.cpp:122] Setting up layer_512_1_sum
I0528 21:52:10.641373 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641377 142708 net.cpp:137] Memory required for data: 2463642200
I0528 21:52:10.641381 142708 layer_factory.hpp:77] Creating layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.641388 142708 net.cpp:84] Creating Layer layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.641392 142708 net.cpp:406] layer_512_1_sum_layer_512_1_sum_0_split <- layer_512_1_sum
I0528 21:52:10.641398 142708 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:52:10.641414 142708 net.cpp:380] layer_512_1_sum_layer_512_1_sum_0_split -> layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:52:10.641475 142708 net.cpp:122] Setting up layer_512_1_sum_layer_512_1_sum_0_split
I0528 21:52:10.641484 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641487 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641490 142708 net.cpp:137] Memory required for data: 2473677400
I0528 21:52:10.641494 142708 layer_factory.hpp:77] Creating layer layer_512_2_bn1
I0528 21:52:10.641505 142708 net.cpp:84] Creating Layer layer_512_2_bn1
I0528 21:52:10.641508 142708 net.cpp:406] layer_512_2_bn1 <- layer_512_1_sum_layer_512_1_sum_0_split_0
I0528 21:52:10.641515 142708 net.cpp:380] layer_512_2_bn1 -> layer_512_2_bn1
I0528 21:52:10.641757 142708 net.cpp:122] Setting up layer_512_2_bn1
I0528 21:52:10.641764 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641768 142708 net.cpp:137] Memory required for data: 2478695000
I0528 21:52:10.641777 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:52:10.641785 142708 net.cpp:84] Creating Layer layer_512_2_scale1
I0528 21:52:10.641789 142708 net.cpp:406] layer_512_2_scale1 <- layer_512_2_bn1
I0528 21:52:10.641795 142708 net.cpp:367] layer_512_2_scale1 -> layer_512_2_bn1 (in-place)
I0528 21:52:10.641847 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale1
I0528 21:52:10.641986 142708 net.cpp:122] Setting up layer_512_2_scale1
I0528 21:52:10.641994 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.641997 142708 net.cpp:137] Memory required for data: 2483712600
I0528 21:52:10.642004 142708 layer_factory.hpp:77] Creating layer layer_512_2_relu1
I0528 21:52:10.642012 142708 net.cpp:84] Creating Layer layer_512_2_relu1
I0528 21:52:10.642016 142708 net.cpp:406] layer_512_2_relu1 <- layer_512_2_bn1
I0528 21:52:10.642021 142708 net.cpp:367] layer_512_2_relu1 -> layer_512_2_bn1 (in-place)
I0528 21:52:10.642643 142708 net.cpp:122] Setting up layer_512_2_relu1
I0528 21:52:10.642660 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.642665 142708 net.cpp:137] Memory required for data: 2488730200
I0528 21:52:10.642668 142708 layer_factory.hpp:77] Creating layer layer_512_2_conv1
I0528 21:52:10.642680 142708 net.cpp:84] Creating Layer layer_512_2_conv1
I0528 21:52:10.642686 142708 net.cpp:406] layer_512_2_conv1 <- layer_512_2_bn1
I0528 21:52:10.642695 142708 net.cpp:380] layer_512_2_conv1 -> layer_512_2_conv1
I0528 21:52:10.712517 142708 net.cpp:122] Setting up layer_512_2_conv1
I0528 21:52:10.712538 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.712543 142708 net.cpp:137] Memory required for data: 2493747800
I0528 21:52:10.712549 142708 layer_factory.hpp:77] Creating layer layer_512_2_bn2
I0528 21:52:10.712558 142708 net.cpp:84] Creating Layer layer_512_2_bn2
I0528 21:52:10.712561 142708 net.cpp:406] layer_512_2_bn2 <- layer_512_2_conv1
I0528 21:52:10.712569 142708 net.cpp:367] layer_512_2_bn2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.712806 142708 net.cpp:122] Setting up layer_512_2_bn2
I0528 21:52:10.712815 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.712819 142708 net.cpp:137] Memory required for data: 2498765400
I0528 21:52:10.712827 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:52:10.712834 142708 net.cpp:84] Creating Layer layer_512_2_scale2
I0528 21:52:10.712838 142708 net.cpp:406] layer_512_2_scale2 <- layer_512_2_conv1
I0528 21:52:10.712844 142708 net.cpp:367] layer_512_2_scale2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.712894 142708 layer_factory.hpp:77] Creating layer layer_512_2_scale2
I0528 21:52:10.713032 142708 net.cpp:122] Setting up layer_512_2_scale2
I0528 21:52:10.713047 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.713052 142708 net.cpp:137] Memory required for data: 2503783000
I0528 21:52:10.713059 142708 layer_factory.hpp:77] Creating layer layer_512_2_relu2
I0528 21:52:10.713066 142708 net.cpp:84] Creating Layer layer_512_2_relu2
I0528 21:52:10.713076 142708 net.cpp:406] layer_512_2_relu2 <- layer_512_2_conv1
I0528 21:52:10.713091 142708 net.cpp:367] layer_512_2_relu2 -> layer_512_2_conv1 (in-place)
I0528 21:52:10.713275 142708 net.cpp:122] Setting up layer_512_2_relu2
I0528 21:52:10.713286 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.713289 142708 net.cpp:137] Memory required for data: 2508800600
I0528 21:52:10.713294 142708 layer_factory.hpp:77] Creating layer layer_512_2_conv2
I0528 21:52:10.713304 142708 net.cpp:84] Creating Layer layer_512_2_conv2
I0528 21:52:10.713310 142708 net.cpp:406] layer_512_2_conv2 <- layer_512_2_conv1
I0528 21:52:10.713321 142708 net.cpp:380] layer_512_2_conv2 -> layer_512_2_conv2
I0528 21:52:10.781801 142708 net.cpp:122] Setting up layer_512_2_conv2
I0528 21:52:10.781841 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.781846 142708 net.cpp:137] Memory required for data: 2513818200
I0528 21:52:10.781855 142708 layer_factory.hpp:77] Creating layer layer_512_2_sum
I0528 21:52:10.781873 142708 net.cpp:84] Creating Layer layer_512_2_sum
I0528 21:52:10.781878 142708 net.cpp:406] layer_512_2_sum <- layer_512_2_conv2
I0528 21:52:10.781883 142708 net.cpp:406] layer_512_2_sum <- layer_512_1_sum_layer_512_1_sum_0_split_1
I0528 21:52:10.781888 142708 net.cpp:380] layer_512_2_sum -> layer_512_2_sum
I0528 21:52:10.781924 142708 net.cpp:122] Setting up layer_512_2_sum
I0528 21:52:10.781934 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.781936 142708 net.cpp:137] Memory required for data: 2518835800
I0528 21:52:10.781940 142708 layer_factory.hpp:77] Creating layer last_bn
I0528 21:52:10.781946 142708 net.cpp:84] Creating Layer last_bn
I0528 21:52:10.781949 142708 net.cpp:406] last_bn <- layer_512_2_sum
I0528 21:52:10.781956 142708 net.cpp:367] last_bn -> layer_512_2_sum (in-place)
I0528 21:52:10.782183 142708 net.cpp:122] Setting up last_bn
I0528 21:52:10.782196 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.782198 142708 net.cpp:137] Memory required for data: 2523853400
I0528 21:52:10.782207 142708 layer_factory.hpp:77] Creating layer last_scale
I0528 21:52:10.782215 142708 net.cpp:84] Creating Layer last_scale
I0528 21:52:10.782219 142708 net.cpp:406] last_scale <- layer_512_2_sum
I0528 21:52:10.782224 142708 net.cpp:367] last_scale -> layer_512_2_sum (in-place)
I0528 21:52:10.782272 142708 layer_factory.hpp:77] Creating layer last_scale
I0528 21:52:10.782404 142708 net.cpp:122] Setting up last_scale
I0528 21:52:10.782411 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.782415 142708 net.cpp:137] Memory required for data: 2528871000
I0528 21:52:10.782420 142708 layer_factory.hpp:77] Creating layer last_relu
I0528 21:52:10.782426 142708 net.cpp:84] Creating Layer last_relu
I0528 21:52:10.782430 142708 net.cpp:406] last_relu <- layer_512_2_sum
I0528 21:52:10.782436 142708 net.cpp:367] last_relu -> layer_512_2_sum (in-place)
I0528 21:52:10.783023 142708 net.cpp:122] Setting up last_relu
I0528 21:52:10.783036 142708 net.cpp:129] Top shape: 50 512 7 7 (1254400)
I0528 21:52:10.783046 142708 net.cpp:137] Memory required for data: 2533888600
I0528 21:52:10.783053 142708 layer_factory.hpp:77] Creating layer global_pool
I0528 21:52:10.783061 142708 net.cpp:84] Creating Layer global_pool
I0528 21:52:10.783066 142708 net.cpp:406] global_pool <- layer_512_2_sum
I0528 21:52:10.783073 142708 net.cpp:380] global_pool -> global_pool
I0528 21:52:10.783269 142708 net.cpp:122] Setting up global_pool
I0528 21:52:10.783280 142708 net.cpp:129] Top shape: 50 512 1 1 (25600)
I0528 21:52:10.783283 142708 net.cpp:137] Memory required for data: 2533991000
I0528 21:52:10.783287 142708 layer_factory.hpp:77] Creating layer score
I0528 21:52:10.783296 142708 net.cpp:84] Creating Layer score
I0528 21:52:10.783300 142708 net.cpp:406] score <- global_pool
I0528 21:52:10.783305 142708 net.cpp:380] score -> score
I0528 21:52:10.783434 142708 net.cpp:122] Setting up score
I0528 21:52:10.783442 142708 net.cpp:129] Top shape: 50 2 (100)
I0528 21:52:10.783452 142708 net.cpp:137] Memory required for data: 2533991400
I0528 21:52:10.783465 142708 layer_factory.hpp:77] Creating layer score_score_0_split
I0528 21:52:10.783471 142708 net.cpp:84] Creating Layer score_score_0_split
I0528 21:52:10.783475 142708 net.cpp:406] score_score_0_split <- score
I0528 21:52:10.783483 142708 net.cpp:380] score_score_0_split -> score_score_0_split_0
I0528 21:52:10.783489 142708 net.cpp:380] score_score_0_split -> score_score_0_split_1
I0528 21:52:10.783535 142708 net.cpp:122] Setting up score_score_0_split
I0528 21:52:10.783541 142708 net.cpp:129] Top shape: 50 2 (100)
I0528 21:52:10.783547 142708 net.cpp:129] Top shape: 50 2 (100)
I0528 21:52:10.783550 142708 net.cpp:137] Memory required for data: 2533992200
I0528 21:52:10.783553 142708 layer_factory.hpp:77] Creating layer loss
I0528 21:52:10.783560 142708 net.cpp:84] Creating Layer loss
I0528 21:52:10.783562 142708 net.cpp:406] loss <- score_score_0_split_0
I0528 21:52:10.783567 142708 net.cpp:406] loss <- label_data_1_split_0
I0528 21:52:10.783578 142708 net.cpp:380] loss -> loss
I0528 21:52:10.783587 142708 layer_factory.hpp:77] Creating layer loss
I0528 21:52:10.784281 142708 net.cpp:122] Setting up loss
I0528 21:52:10.784296 142708 net.cpp:129] Top shape: (1)
I0528 21:52:10.784299 142708 net.cpp:132]     with loss weight 1
I0528 21:52:10.784323 142708 net.cpp:137] Memory required for data: 2533992204
I0528 21:52:10.784327 142708 layer_factory.hpp:77] Creating layer accuracy
I0528 21:52:10.784340 142708 net.cpp:84] Creating Layer accuracy
I0528 21:52:10.784344 142708 net.cpp:406] accuracy <- score_score_0_split_1
I0528 21:52:10.784349 142708 net.cpp:406] accuracy <- label_data_1_split_1
I0528 21:52:10.784355 142708 net.cpp:380] accuracy -> accuracy
I0528 21:52:10.784368 142708 net.cpp:122] Setting up accuracy
I0528 21:52:10.784373 142708 net.cpp:129] Top shape: (1)
I0528 21:52:10.784375 142708 net.cpp:137] Memory required for data: 2533992208
I0528 21:52:10.784379 142708 net.cpp:200] accuracy does not need backward computation.
I0528 21:52:10.784382 142708 net.cpp:198] loss needs backward computation.
I0528 21:52:10.784385 142708 net.cpp:198] score_score_0_split needs backward computation.
I0528 21:52:10.784389 142708 net.cpp:198] score needs backward computation.
I0528 21:52:10.784392 142708 net.cpp:198] global_pool needs backward computation.
I0528 21:52:10.784395 142708 net.cpp:198] last_relu needs backward computation.
I0528 21:52:10.784399 142708 net.cpp:198] last_scale needs backward computation.
I0528 21:52:10.784401 142708 net.cpp:198] last_bn needs backward computation.
I0528 21:52:10.784404 142708 net.cpp:198] layer_512_2_sum needs backward computation.
I0528 21:52:10.784409 142708 net.cpp:198] layer_512_2_conv2 needs backward computation.
I0528 21:52:10.784411 142708 net.cpp:198] layer_512_2_relu2 needs backward computation.
I0528 21:52:10.784415 142708 net.cpp:198] layer_512_2_scale2 needs backward computation.
I0528 21:52:10.784417 142708 net.cpp:198] layer_512_2_bn2 needs backward computation.
I0528 21:52:10.784420 142708 net.cpp:198] layer_512_2_conv1 needs backward computation.
I0528 21:52:10.784423 142708 net.cpp:198] layer_512_2_relu1 needs backward computation.
I0528 21:52:10.784426 142708 net.cpp:198] layer_512_2_scale1 needs backward computation.
I0528 21:52:10.784430 142708 net.cpp:198] layer_512_2_bn1 needs backward computation.
I0528 21:52:10.784433 142708 net.cpp:198] layer_512_1_sum_layer_512_1_sum_0_split needs backward computation.
I0528 21:52:10.784436 142708 net.cpp:198] layer_512_1_sum needs backward computation.
I0528 21:52:10.784440 142708 net.cpp:198] layer_512_1_conv_expand needs backward computation.
I0528 21:52:10.784445 142708 net.cpp:198] layer_512_1_conv2 needs backward computation.
I0528 21:52:10.784447 142708 net.cpp:198] layer_512_1_relu2 needs backward computation.
I0528 21:52:10.784451 142708 net.cpp:198] layer_512_1_scale2 needs backward computation.
I0528 21:52:10.784454 142708 net.cpp:198] layer_512_1_bn2 needs backward computation.
I0528 21:52:10.784457 142708 net.cpp:198] layer_512_1_conv1 needs backward computation.
I0528 21:52:10.784468 142708 net.cpp:198] layer_512_1_bn1_layer_512_1_relu1_0_split needs backward computation.
I0528 21:52:10.784479 142708 net.cpp:198] layer_512_1_relu1 needs backward computation.
I0528 21:52:10.784483 142708 net.cpp:198] layer_512_1_scale1 needs backward computation.
I0528 21:52:10.784487 142708 net.cpp:198] layer_512_1_bn1 needs backward computation.
I0528 21:52:10.784490 142708 net.cpp:198] layer_256_2_sum needs backward computation.
I0528 21:52:10.784494 142708 net.cpp:198] layer_256_2_conv2 needs backward computation.
I0528 21:52:10.784502 142708 net.cpp:198] layer_256_2_relu2 needs backward computation.
I0528 21:52:10.784505 142708 net.cpp:198] layer_256_2_scale2 needs backward computation.
I0528 21:52:10.784508 142708 net.cpp:198] layer_256_2_bn2 needs backward computation.
I0528 21:52:10.784512 142708 net.cpp:198] layer_256_2_conv1 needs backward computation.
I0528 21:52:10.784515 142708 net.cpp:198] layer_256_2_relu1 needs backward computation.
I0528 21:52:10.784518 142708 net.cpp:198] layer_256_2_scale1 needs backward computation.
I0528 21:52:10.784521 142708 net.cpp:198] layer_256_2_bn1 needs backward computation.
I0528 21:52:10.784525 142708 net.cpp:198] layer_256_1_sum_layer_256_1_sum_0_split needs backward computation.
I0528 21:52:10.784529 142708 net.cpp:198] layer_256_1_sum needs backward computation.
I0528 21:52:10.784533 142708 net.cpp:198] layer_256_1_conv_expand needs backward computation.
I0528 21:52:10.784538 142708 net.cpp:198] layer_256_1_conv2 needs backward computation.
I0528 21:52:10.784541 142708 net.cpp:198] layer_256_1_relu2 needs backward computation.
I0528 21:52:10.784544 142708 net.cpp:198] layer_256_1_scale2 needs backward computation.
I0528 21:52:10.784548 142708 net.cpp:198] layer_256_1_bn2 needs backward computation.
I0528 21:52:10.784550 142708 net.cpp:198] layer_256_1_conv1 needs backward computation.
I0528 21:52:10.784554 142708 net.cpp:198] layer_256_1_bn1_layer_256_1_relu1_0_split needs backward computation.
I0528 21:52:10.784559 142708 net.cpp:198] layer_256_1_relu1 needs backward computation.
I0528 21:52:10.784561 142708 net.cpp:198] layer_256_1_scale1 needs backward computation.
I0528 21:52:10.784564 142708 net.cpp:198] layer_256_1_bn1 needs backward computation.
I0528 21:52:10.784569 142708 net.cpp:198] layer_128_2_sum needs backward computation.
I0528 21:52:10.784572 142708 net.cpp:198] layer_128_2_conv2 needs backward computation.
I0528 21:52:10.784575 142708 net.cpp:198] layer_128_2_relu2 needs backward computation.
I0528 21:52:10.784579 142708 net.cpp:198] layer_128_2_scale2 needs backward computation.
I0528 21:52:10.784582 142708 net.cpp:198] layer_128_2_bn2 needs backward computation.
I0528 21:52:10.784585 142708 net.cpp:198] layer_128_2_conv1 needs backward computation.
I0528 21:52:10.784590 142708 net.cpp:198] layer_128_2_relu1 needs backward computation.
I0528 21:52:10.784592 142708 net.cpp:198] layer_128_2_scale1 needs backward computation.
I0528 21:52:10.784595 142708 net.cpp:198] layer_128_2_bn1 needs backward computation.
I0528 21:52:10.784600 142708 net.cpp:198] layer_128_1_sum_layer_128_1_sum_0_split needs backward computation.
I0528 21:52:10.784602 142708 net.cpp:198] layer_128_1_sum needs backward computation.
I0528 21:52:10.784606 142708 net.cpp:198] layer_128_1_conv_expand needs backward computation.
I0528 21:52:10.784610 142708 net.cpp:198] layer_128_1_conv2 needs backward computation.
I0528 21:52:10.784615 142708 net.cpp:198] layer_128_1_relu2 needs backward computation.
I0528 21:52:10.784617 142708 net.cpp:198] layer_128_1_scale2 needs backward computation.
I0528 21:52:10.784621 142708 net.cpp:198] layer_128_1_bn2 needs backward computation.
I0528 21:52:10.784623 142708 net.cpp:198] layer_128_1_conv1 needs backward computation.
I0528 21:52:10.784627 142708 net.cpp:198] layer_128_1_bn1_layer_128_1_relu1_0_split needs backward computation.
I0528 21:52:10.784631 142708 net.cpp:198] layer_128_1_relu1 needs backward computation.
I0528 21:52:10.784634 142708 net.cpp:198] layer_128_1_scale1 needs backward computation.
I0528 21:52:10.784641 142708 net.cpp:198] layer_128_1_bn1 needs backward computation.
I0528 21:52:10.784646 142708 net.cpp:198] layer_64_2_sum needs backward computation.
I0528 21:52:10.784651 142708 net.cpp:198] layer_64_2_conv2 needs backward computation.
I0528 21:52:10.784656 142708 net.cpp:198] layer_64_2_relu2 needs backward computation.
I0528 21:52:10.784658 142708 net.cpp:198] layer_64_2_scale2 needs backward computation.
I0528 21:52:10.784662 142708 net.cpp:198] layer_64_2_bn2 needs backward computation.
I0528 21:52:10.784665 142708 net.cpp:198] layer_64_2_conv1 needs backward computation.
I0528 21:52:10.784668 142708 net.cpp:198] layer_64_2_relu1 needs backward computation.
I0528 21:52:10.784672 142708 net.cpp:198] layer_64_2_scale1 needs backward computation.
I0528 21:52:10.784675 142708 net.cpp:198] layer_64_2_bn1 needs backward computation.
I0528 21:52:10.784679 142708 net.cpp:198] layer_64_1_sum_layer_64_1_sum_0_split needs backward computation.
I0528 21:52:10.784683 142708 net.cpp:198] layer_64_1_sum needs backward computation.
I0528 21:52:10.784687 142708 net.cpp:198] layer_64_1_conv2 needs backward computation.
I0528 21:52:10.784692 142708 net.cpp:198] layer_64_1_relu2 needs backward computation.
I0528 21:52:10.784694 142708 net.cpp:198] layer_64_1_scale2 needs backward computation.
I0528 21:52:10.784698 142708 net.cpp:198] layer_64_1_bn2 needs backward computation.
I0528 21:52:10.784700 142708 net.cpp:198] layer_64_1_conv1 needs backward computation.
I0528 21:52:10.784704 142708 net.cpp:198] conv1_pool_conv1_pool_0_split needs backward computation.
I0528 21:52:10.784708 142708 net.cpp:198] conv1_pool needs backward computation.
I0528 21:52:10.784711 142708 net.cpp:198] conv1_relu needs backward computation.
I0528 21:52:10.784715 142708 net.cpp:198] conv1_scale needs backward computation.
I0528 21:52:10.784718 142708 net.cpp:198] conv1_bn needs backward computation.
I0528 21:52:10.784721 142708 net.cpp:198] conv1 needs backward computation.
I0528 21:52:10.784724 142708 net.cpp:198] data_scale needs backward computation.
I0528 21:52:10.784729 142708 net.cpp:200] data_bn does not need backward computation.
I0528 21:52:10.784732 142708 net.cpp:200] label_data_1_split does not need backward computation.
I0528 21:52:10.784737 142708 net.cpp:200] data does not need backward computation.
I0528 21:52:10.784740 142708 net.cpp:242] This network produces output accuracy
I0528 21:52:10.784744 142708 net.cpp:242] This network produces output loss
I0528 21:52:10.784795 142708 net.cpp:255] Network initialization done.
I0528 21:52:10.785185 142708 solver.cpp:56] Solver scaffolding done.
I0528 21:52:10.789494 142708 caffe.cpp:248] Starting Optimization
I0528 21:52:10.789507 142708 solver.cpp:272] Solving Pre-ResNet-18
I0528 21:52:10.789511 142708 solver.cpp:273] Learning Rate Policy: poly
I0528 21:52:10.797289 142708 solver.cpp:330] Iteration 0, Testing net (#0)
I0528 21:52:11.849426 142708 blocking_queue.cpp:49] Waiting for data
I0528 21:52:42.810844 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:53:14.934922 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:53:47.068218 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:54:19.182543 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:54:51.287830 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 21:54:59.053081 142708 solver.cpp:397]     Test net output #0: accuracy = 0.786121
I0528 21:54:59.053160 142708 solver.cpp:397]     Test net output #1: loss = 87.3361 (* 1 = 87.3361 loss)
I0528 21:55:00.355378 142708 solver.cpp:218] Iteration 0 (0 iter/s, 169.563s/100 iters), loss = 0.693147
I0528 21:55:00.355432 142708 solver.cpp:237]     Train net output #0: loss = 0.693147 (* 1 = 0.693147 loss)
I0528 21:55:00.355458 142708 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0528 21:57:08.973487 142708 solver.cpp:218] Iteration 100 (0.777512 iter/s, 128.615s/100 iters), loss = 0.603414
I0528 21:57:08.973763 142708 solver.cpp:237]     Train net output #0: loss = 0.603414 (* 1 = 0.603414 loss)
I0528 21:57:08.973781 142708 sgd_solver.cpp:105] Iteration 100, lr = 0.00998
I0528 21:59:17.561293 142708 solver.cpp:218] Iteration 200 (0.777697 iter/s, 128.585s/100 iters), loss = 0.378001
I0528 21:59:17.561538 142708 solver.cpp:237]     Train net output #0: loss = 0.378001 (* 1 = 0.378001 loss)
I0528 21:59:17.561576 142708 sgd_solver.cpp:105] Iteration 200, lr = 0.00996
I0528 22:01:26.184159 142708 solver.cpp:218] Iteration 300 (0.777485 iter/s, 128.62s/100 iters), loss = 0.539862
I0528 22:01:26.184305 142708 solver.cpp:237]     Train net output #0: loss = 0.539862 (* 1 = 0.539862 loss)
I0528 22:01:26.184339 142708 sgd_solver.cpp:105] Iteration 300, lr = 0.00994
I0528 22:03:05.511857 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:03:34.827736 142708 solver.cpp:218] Iteration 400 (0.777359 iter/s, 128.641s/100 iters), loss = 0.432587
I0528 22:03:34.827800 142708 solver.cpp:237]     Train net output #0: loss = 0.432587 (* 1 = 0.432587 loss)
I0528 22:03:34.827816 142708 sgd_solver.cpp:105] Iteration 400, lr = 0.00992
I0528 22:05:43.417505 142708 solver.cpp:218] Iteration 500 (0.777684 iter/s, 128.587s/100 iters), loss = 0.460166
I0528 22:05:43.417699 142708 solver.cpp:237]     Train net output #0: loss = 0.460166 (* 1 = 0.460166 loss)
I0528 22:05:43.417729 142708 sgd_solver.cpp:105] Iteration 500, lr = 0.0099
I0528 22:07:52.024775 142708 solver.cpp:218] Iteration 600 (0.777579 iter/s, 128.604s/100 iters), loss = 0.430525
I0528 22:07:52.024960 142708 solver.cpp:237]     Train net output #0: loss = 0.430525 (* 1 = 0.430525 loss)
I0528 22:07:52.025010 142708 sgd_solver.cpp:105] Iteration 600, lr = 0.00988
I0528 22:10:00.620420 142708 solver.cpp:218] Iteration 700 (0.777649 iter/s, 128.593s/100 iters), loss = 0.449706
I0528 22:10:00.620661 142708 solver.cpp:237]     Train net output #0: loss = 0.449706 (* 1 = 0.449706 loss)
I0528 22:10:00.620687 142708 sgd_solver.cpp:105] Iteration 700, lr = 0.00986
I0528 22:11:16.779943 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:12:09.285531 142708 solver.cpp:218] Iteration 800 (0.77723 iter/s, 128.662s/100 iters), loss = 0.401852
I0528 22:12:09.285719 142708 solver.cpp:237]     Train net output #0: loss = 0.401852 (* 1 = 0.401852 loss)
I0528 22:12:09.285749 142708 sgd_solver.cpp:105] Iteration 800, lr = 0.00984
I0528 22:14:17.952519 142708 solver.cpp:218] Iteration 900 (0.777218 iter/s, 128.664s/100 iters), loss = 0.494552
I0528 22:14:17.952709 142708 solver.cpp:237]     Train net output #0: loss = 0.494552 (* 1 = 0.494552 loss)
I0528 22:14:17.952725 142708 sgd_solver.cpp:105] Iteration 900, lr = 0.00982
I0528 22:16:25.353440 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_1000.caffemodel
I0528 22:16:26.096832 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_1000.solverstate
I0528 22:16:26.149135 142708 solver.cpp:330] Iteration 1000, Testing net (#0)
I0528 22:16:47.388347 142708 blocking_queue.cpp:49] Waiting for data
I0528 22:16:50.211697 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:17:22.346025 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:17:54.470433 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:18:26.596478 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:18:58.711447 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:19:14.024619 142708 solver.cpp:397]     Test net output #0: accuracy = 0.834282
I0528 22:19:14.024709 142708 solver.cpp:397]     Test net output #1: loss = 0.441675 (* 1 = 0.441675 loss)
I0528 22:19:15.308635 142708 solver.cpp:218] Iteration 1000 (0.336305 iter/s, 297.35s/100 iters), loss = 0.425169
I0528 22:19:15.308703 142708 solver.cpp:237]     Train net output #0: loss = 0.425169 (* 1 = 0.425169 loss)
I0528 22:19:15.308718 142708 sgd_solver.cpp:105] Iteration 1000, lr = 0.0098
I0528 22:21:24.035818 142708 solver.cpp:218] Iteration 1100 (0.776855 iter/s, 128.724s/100 iters), loss = 0.50029
I0528 22:21:24.036164 142708 solver.cpp:237]     Train net output #0: loss = 0.50029 (* 1 = 0.50029 loss)
I0528 22:21:24.036185 142708 sgd_solver.cpp:105] Iteration 1100, lr = 0.00978
I0528 22:22:17.129185 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:23:32.804337 142708 solver.cpp:218] Iteration 1200 (0.776606 iter/s, 128.765s/100 iters), loss = 0.328392
I0528 22:23:32.804527 142708 solver.cpp:237]     Train net output #0: loss = 0.328392 (* 1 = 0.328392 loss)
I0528 22:23:32.804543 142708 sgd_solver.cpp:105] Iteration 1200, lr = 0.00976
I0528 22:25:41.587431 142708 solver.cpp:218] Iteration 1300 (0.776517 iter/s, 128.78s/100 iters), loss = 0.334639
I0528 22:25:41.587683 142708 solver.cpp:237]     Train net output #0: loss = 0.334639 (* 1 = 0.334639 loss)
I0528 22:25:41.587698 142708 sgd_solver.cpp:105] Iteration 1300, lr = 0.00974
I0528 22:27:50.381079 142708 solver.cpp:218] Iteration 1400 (0.776454 iter/s, 128.791s/100 iters), loss = 0.34327
I0528 22:27:50.381296 142708 solver.cpp:237]     Train net output #0: loss = 0.34327 (* 1 = 0.34327 loss)
I0528 22:27:50.381312 142708 sgd_solver.cpp:105] Iteration 1400, lr = 0.00972
I0528 22:29:59.186803 142708 solver.cpp:218] Iteration 1500 (0.776381 iter/s, 128.803s/100 iters), loss = 0.460669
I0528 22:29:59.187001 142708 solver.cpp:237]     Train net output #0: loss = 0.460669 (* 1 = 0.460669 loss)
I0528 22:29:59.187024 142708 sgd_solver.cpp:105] Iteration 1500, lr = 0.0097
I0528 22:30:29.060729 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:32:08.045042 142708 solver.cpp:218] Iteration 1600 (0.776065 iter/s, 128.855s/100 iters), loss = 0.41504
I0528 22:32:08.045266 142708 solver.cpp:237]     Train net output #0: loss = 0.41504 (* 1 = 0.41504 loss)
I0528 22:32:08.045302 142708 sgd_solver.cpp:105] Iteration 1600, lr = 0.00968
I0528 22:34:16.795274 142708 solver.cpp:218] Iteration 1700 (0.776716 iter/s, 128.747s/100 iters), loss = 0.273042
I0528 22:34:16.795506 142708 solver.cpp:237]     Train net output #0: loss = 0.273042 (* 1 = 0.273042 loss)
I0528 22:34:16.795519 142708 sgd_solver.cpp:105] Iteration 1700, lr = 0.00966
I0528 22:36:25.632866 142708 solver.cpp:218] Iteration 1800 (0.776189 iter/s, 128.835s/100 iters), loss = 0.403991
I0528 22:36:25.633163 142708 solver.cpp:237]     Train net output #0: loss = 0.403991 (* 1 = 0.403991 loss)
I0528 22:36:25.633186 142708 sgd_solver.cpp:105] Iteration 1800, lr = 0.00964
I0528 22:38:34.393613 142708 solver.cpp:218] Iteration 1900 (0.776653 iter/s, 128.758s/100 iters), loss = 0.289275
I0528 22:38:34.393858 142708 solver.cpp:237]     Train net output #0: loss = 0.289275 (* 1 = 0.289275 loss)
I0528 22:38:34.393884 142708 sgd_solver.cpp:105] Iteration 1900, lr = 0.00962
I0528 22:38:41.095224 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:40:41.914947 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_2000.caffemodel
I0528 22:40:42.116119 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_2000.solverstate
I0528 22:40:42.173516 142708 solver.cpp:330] Iteration 2000, Testing net (#0)
I0528 22:40:58.922073 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:41:05.695791 142708 blocking_queue.cpp:49] Waiting for data
I0528 22:41:31.077838 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:42:03.215945 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:42:35.338132 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:43:07.459373 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:43:30.365720 142708 solver.cpp:397]     Test net output #0: accuracy = 0.709819
I0528 22:43:30.365809 142708 solver.cpp:397]     Test net output #1: loss = 0.545875 (* 1 = 0.545875 loss)
I0528 22:43:31.649471 142708 solver.cpp:218] Iteration 2000 (0.336418 iter/s, 297.249s/100 iters), loss = 0.283096
I0528 22:43:31.649547 142708 solver.cpp:237]     Train net output #0: loss = 0.283096 (* 1 = 0.283096 loss)
I0528 22:43:31.649580 142708 sgd_solver.cpp:105] Iteration 2000, lr = 0.0096
I0528 22:45:40.450692 142708 solver.cpp:218] Iteration 2100 (0.776408 iter/s, 128.798s/100 iters), loss = 0.284667
I0528 22:45:40.450908 142708 solver.cpp:237]     Train net output #0: loss = 0.284667 (* 1 = 0.284667 loss)
I0528 22:45:40.450942 142708 sgd_solver.cpp:105] Iteration 2100, lr = 0.00958
I0528 22:47:49.251065 142708 solver.cpp:218] Iteration 2200 (0.776414 iter/s, 128.797s/100 iters), loss = 0.283593
I0528 22:47:49.251255 142708 solver.cpp:237]     Train net output #0: loss = 0.283593 (* 1 = 0.283593 loss)
I0528 22:47:49.251268 142708 sgd_solver.cpp:105] Iteration 2200, lr = 0.00956
I0528 22:49:41.567073 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:49:58.083204 142708 solver.cpp:218] Iteration 2300 (0.776222 iter/s, 128.829s/100 iters), loss = 0.440263
I0528 22:49:58.083307 142708 solver.cpp:237]     Train net output #0: loss = 0.440263 (* 1 = 0.440263 loss)
I0528 22:49:58.083324 142708 sgd_solver.cpp:105] Iteration 2300, lr = 0.00954
I0528 22:52:06.983414 142708 solver.cpp:218] Iteration 2400 (0.775811 iter/s, 128.897s/100 iters), loss = 0.421028
I0528 22:52:06.983656 142708 solver.cpp:237]     Train net output #0: loss = 0.421028 (* 1 = 0.421028 loss)
I0528 22:52:06.983669 142708 sgd_solver.cpp:105] Iteration 2400, lr = 0.00952
I0528 22:54:15.876610 142708 solver.cpp:218] Iteration 2500 (0.775854 iter/s, 128.89s/100 iters), loss = 0.243131
I0528 22:54:15.876780 142708 solver.cpp:237]     Train net output #0: loss = 0.243131 (* 1 = 0.243131 loss)
I0528 22:54:15.876793 142708 sgd_solver.cpp:105] Iteration 2500, lr = 0.0095
I0528 22:56:24.818202 142708 solver.cpp:218] Iteration 2600 (0.775563 iter/s, 128.939s/100 iters), loss = 0.309634
I0528 22:56:24.818382 142708 solver.cpp:237]     Train net output #0: loss = 0.309634 (* 1 = 0.309634 loss)
I0528 22:56:24.818398 142708 sgd_solver.cpp:105] Iteration 2600, lr = 0.00948
I0528 22:57:54.012473 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 22:58:33.719380 142708 solver.cpp:218] Iteration 2700 (0.775806 iter/s, 128.898s/100 iters), loss = 0.374782
I0528 22:58:33.719579 142708 solver.cpp:237]     Train net output #0: loss = 0.374782 (* 1 = 0.374782 loss)
I0528 22:58:33.719596 142708 sgd_solver.cpp:105] Iteration 2700, lr = 0.00946
I0528 23:00:42.589104 142708 solver.cpp:218] Iteration 2800 (0.775995 iter/s, 128.867s/100 iters), loss = 0.306921
I0528 23:00:42.589304 142708 solver.cpp:237]     Train net output #0: loss = 0.306921 (* 1 = 0.306921 loss)
I0528 23:00:42.589330 142708 sgd_solver.cpp:105] Iteration 2800, lr = 0.00944
I0528 23:02:51.404748 142708 solver.cpp:218] Iteration 2900 (0.776321 iter/s, 128.813s/100 iters), loss = 0.224378
I0528 23:02:51.404963 142708 solver.cpp:237]     Train net output #0: loss = 0.224378 (* 1 = 0.224378 loss)
I0528 23:02:51.404991 142708 sgd_solver.cpp:105] Iteration 2900, lr = 0.00942
I0528 23:04:58.909139 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_3000.caffemodel
I0528 23:04:59.359241 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_3000.solverstate
I0528 23:04:59.420379 142708 solver.cpp:330] Iteration 3000, Testing net (#0)
I0528 23:05:08.211685 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:05:40.445358 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:05:48.220845 142708 blocking_queue.cpp:49] Waiting for data
I0528 23:06:12.594769 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:06:44.727571 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:07:16.849256 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:07:47.328790 142708 solver.cpp:397]     Test net output #0: accuracy = 0.894161
I0528 23:07:47.329004 142708 solver.cpp:397]     Test net output #1: loss = 0.291101 (* 1 = 0.291101 loss)
I0528 23:07:48.609542 142708 solver.cpp:218] Iteration 3000 (0.336476 iter/s, 297.198s/100 iters), loss = 0.339588
I0528 23:07:48.609653 142708 solver.cpp:237]     Train net output #0: loss = 0.339588 (* 1 = 0.339588 loss)
I0528 23:07:48.609670 142708 sgd_solver.cpp:105] Iteration 3000, lr = 0.0094
I0528 23:08:54.507287 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:09:57.427961 142708 solver.cpp:218] Iteration 3100 (0.776305 iter/s, 128.815s/100 iters), loss = 0.311881
I0528 23:09:57.428303 142708 solver.cpp:237]     Train net output #0: loss = 0.311881 (* 1 = 0.311881 loss)
I0528 23:09:57.428321 142708 sgd_solver.cpp:105] Iteration 3100, lr = 0.00938
I0528 23:12:06.102069 142708 solver.cpp:218] Iteration 3200 (0.777176 iter/s, 128.671s/100 iters), loss = 0.348247
I0528 23:12:06.102360 142708 solver.cpp:237]     Train net output #0: loss = 0.348247 (* 1 = 0.348247 loss)
I0528 23:12:06.102380 142708 sgd_solver.cpp:105] Iteration 3200, lr = 0.00936
I0528 23:14:14.867300 142708 solver.cpp:218] Iteration 3300 (0.776626 iter/s, 128.762s/100 iters), loss = 0.272816
I0528 23:14:14.867558 142708 solver.cpp:237]     Train net output #0: loss = 0.272816 (* 1 = 0.272816 loss)
I0528 23:14:14.867576 142708 sgd_solver.cpp:105] Iteration 3300, lr = 0.00934
I0528 23:16:23.706794 142708 solver.cpp:218] Iteration 3400 (0.776178 iter/s, 128.836s/100 iters), loss = 0.218371
I0528 23:16:23.706985 142708 solver.cpp:237]     Train net output #0: loss = 0.218371 (* 1 = 0.218371 loss)
I0528 23:16:23.707020 142708 sgd_solver.cpp:105] Iteration 3400, lr = 0.00932
I0528 23:17:06.453634 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:18:32.501718 142708 solver.cpp:218] Iteration 3500 (0.776446 iter/s, 128.792s/100 iters), loss = 0.231196
I0528 23:18:32.501910 142708 solver.cpp:237]     Train net output #0: loss = 0.231196 (* 1 = 0.231196 loss)
I0528 23:18:32.501936 142708 sgd_solver.cpp:105] Iteration 3500, lr = 0.0093
I0528 23:20:41.194150 142708 solver.cpp:218] Iteration 3600 (0.777065 iter/s, 128.689s/100 iters), loss = 0.182932
I0528 23:20:41.194335 142708 solver.cpp:237]     Train net output #0: loss = 0.182932 (* 1 = 0.182932 loss)
I0528 23:20:41.194362 142708 sgd_solver.cpp:105] Iteration 3600, lr = 0.00928
I0528 23:22:49.991729 142708 solver.cpp:218] Iteration 3700 (0.77643 iter/s, 128.795s/100 iters), loss = 0.161194
I0528 23:22:49.991928 142708 solver.cpp:237]     Train net output #0: loss = 0.161194 (* 1 = 0.161194 loss)
I0528 23:22:49.991969 142708 sgd_solver.cpp:105] Iteration 3700, lr = 0.00926
I0528 23:24:58.726635 142708 solver.cpp:218] Iteration 3800 (0.776808 iter/s, 128.732s/100 iters), loss = 0.231079
I0528 23:24:58.726824 142708 solver.cpp:237]     Train net output #0: loss = 0.231079 (* 1 = 0.231079 loss)
I0528 23:24:58.726852 142708 sgd_solver.cpp:105] Iteration 3800, lr = 0.00924
I0528 23:25:18.288194 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:27:07.577390 142708 solver.cpp:218] Iteration 3900 (0.77611 iter/s, 128.848s/100 iters), loss = 0.167154
I0528 23:27:07.577581 142708 solver.cpp:237]     Train net output #0: loss = 0.167154 (* 1 = 0.167154 loss)
I0528 23:27:07.577600 142708 sgd_solver.cpp:105] Iteration 3900, lr = 0.00922
I0528 23:29:15.245877 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_4000.caffemodel
I0528 23:29:15.386446 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_4000.solverstate
I0528 23:29:15.440126 142708 solver.cpp:330] Iteration 4000, Testing net (#0)
I0528 23:29:16.753063 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:29:48.840409 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:30:21.005208 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:30:33.348328 142708 blocking_queue.cpp:49] Waiting for data
I0528 23:30:53.187403 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:31:25.357632 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:31:57.528671 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:32:03.455382 142708 solver.cpp:397]     Test net output #0: accuracy = 0.846422
I0528 23:32:03.455493 142708 solver.cpp:397]     Test net output #1: loss = 0.521186 (* 1 = 0.521186 loss)
I0528 23:32:04.746284 142708 solver.cpp:218] Iteration 4000 (0.336516 iter/s, 297.162s/100 iters), loss = 0.249559
I0528 23:32:04.746347 142708 solver.cpp:237]     Train net output #0: loss = 0.249559 (* 1 = 0.249559 loss)
I0528 23:32:04.746361 142708 sgd_solver.cpp:105] Iteration 4000, lr = 0.0092
I0528 23:34:13.713464 142708 solver.cpp:218] Iteration 4100 (0.775408 iter/s, 128.964s/100 iters), loss = 0.311834
I0528 23:34:13.713680 142708 solver.cpp:237]     Train net output #0: loss = 0.311834 (* 1 = 0.311834 loss)
I0528 23:34:13.713706 142708 sgd_solver.cpp:105] Iteration 4100, lr = 0.00918
I0528 23:36:19.046906 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:36:22.689949 142708 solver.cpp:218] Iteration 4200 (0.775353 iter/s, 128.974s/100 iters), loss = 0.231289
I0528 23:36:22.690024 142708 solver.cpp:237]     Train net output #0: loss = 0.231289 (* 1 = 0.231289 loss)
I0528 23:36:22.690037 142708 sgd_solver.cpp:105] Iteration 4200, lr = 0.00916
I0528 23:38:31.629667 142708 solver.cpp:218] Iteration 4300 (0.775573 iter/s, 128.937s/100 iters), loss = 0.255447
I0528 23:38:31.629861 142708 solver.cpp:237]     Train net output #0: loss = 0.255447 (* 1 = 0.255447 loss)
I0528 23:38:31.629889 142708 sgd_solver.cpp:105] Iteration 4300, lr = 0.00914
I0528 23:40:40.513052 142708 solver.cpp:218] Iteration 4400 (0.775913 iter/s, 128.88s/100 iters), loss = 0.235007
I0528 23:40:40.513222 142708 solver.cpp:237]     Train net output #0: loss = 0.235007 (* 1 = 0.235007 loss)
I0528 23:40:40.513239 142708 sgd_solver.cpp:105] Iteration 4400, lr = 0.00912
I0528 23:42:49.411329 142708 solver.cpp:218] Iteration 4500 (0.775823 iter/s, 128.895s/100 iters), loss = 0.184525
I0528 23:42:49.411545 142708 solver.cpp:237]     Train net output #0: loss = 0.184525 (* 1 = 0.184525 loss)
I0528 23:42:49.411586 142708 sgd_solver.cpp:105] Iteration 4500, lr = 0.0091
I0528 23:44:31.456624 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:44:58.249321 142708 solver.cpp:218] Iteration 4600 (0.776187 iter/s, 128.835s/100 iters), loss = 0.154549
I0528 23:44:58.249408 142708 solver.cpp:237]     Train net output #0: loss = 0.154549 (* 1 = 0.154549 loss)
I0528 23:44:58.249424 142708 sgd_solver.cpp:105] Iteration 4600, lr = 0.00908
I0528 23:47:07.059693 142708 solver.cpp:218] Iteration 4700 (0.776352 iter/s, 128.808s/100 iters), loss = 0.273663
I0528 23:47:07.059882 142708 solver.cpp:237]     Train net output #0: loss = 0.273663 (* 1 = 0.273663 loss)
I0528 23:47:07.059897 142708 sgd_solver.cpp:105] Iteration 4700, lr = 0.00906
I0528 23:49:15.905724 142708 solver.cpp:218] Iteration 4800 (0.776138 iter/s, 128.843s/100 iters), loss = 0.175664
I0528 23:49:15.905902 142708 solver.cpp:237]     Train net output #0: loss = 0.175664 (* 1 = 0.175664 loss)
I0528 23:49:15.905933 142708 sgd_solver.cpp:105] Iteration 4800, lr = 0.00904
I0528 23:51:24.707201 142708 solver.cpp:218] Iteration 4900 (0.776406 iter/s, 128.799s/100 iters), loss = 0.187866
I0528 23:51:24.707433 142708 solver.cpp:237]     Train net output #0: loss = 0.187866 (* 1 = 0.187866 loss)
I0528 23:51:24.707460 142708 sgd_solver.cpp:105] Iteration 4900, lr = 0.00902
I0528 23:52:43.624096 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:53:32.375916 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_5000.caffemodel
I0528 23:53:32.583473 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_5000.solverstate
I0528 23:53:32.644327 142708 solver.cpp:330] Iteration 5000, Testing net (#0)
I0528 23:53:58.916024 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:54:31.043262 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:54:51.946480 142708 blocking_queue.cpp:49] Waiting for data
I0528 23:55:03.190232 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:55:35.340557 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:56:07.489250 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0528 23:56:20.997977 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904223
I0528 23:56:20.998106 142708 solver.cpp:397]     Test net output #1: loss = 0.257693 (* 1 = 0.257693 loss)
I0528 23:56:22.286938 142708 solver.cpp:218] Iteration 5000 (0.336052 iter/s, 297.573s/100 iters), loss = 0.229944
I0528 23:56:22.287020 142708 solver.cpp:237]     Train net output #0: loss = 0.229944 (* 1 = 0.229944 loss)
I0528 23:56:22.287055 142708 sgd_solver.cpp:105] Iteration 5000, lr = 0.009
I0528 23:58:31.181021 142708 solver.cpp:218] Iteration 5100 (0.775849 iter/s, 128.891s/100 iters), loss = 0.240946
I0528 23:58:31.181205 142708 solver.cpp:237]     Train net output #0: loss = 0.240946 (* 1 = 0.240946 loss)
I0528 23:58:31.181260 142708 sgd_solver.cpp:105] Iteration 5100, lr = 0.00898
I0529 00:00:39.943593 142708 solver.cpp:218] Iteration 5200 (0.776641 iter/s, 128.76s/100 iters), loss = 0.231982
I0529 00:00:39.943790 142708 solver.cpp:237]     Train net output #0: loss = 0.231982 (* 1 = 0.231982 loss)
I0529 00:00:39.943816 142708 sgd_solver.cpp:105] Iteration 5200, lr = 0.00896
I0529 00:02:48.882549 142708 solver.cpp:218] Iteration 5300 (0.775579 iter/s, 128.936s/100 iters), loss = 0.174576
I0529 00:02:48.882741 142708 solver.cpp:237]     Train net output #0: loss = 0.174576 (* 1 = 0.174576 loss)
I0529 00:02:48.882787 142708 sgd_solver.cpp:105] Iteration 5300, lr = 0.00894
I0529 00:03:44.532721 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:04:57.787557 142708 solver.cpp:218] Iteration 5400 (0.775783 iter/s, 128.902s/100 iters), loss = 0.191579
I0529 00:04:57.787822 142708 solver.cpp:237]     Train net output #0: loss = 0.191579 (* 1 = 0.191579 loss)
I0529 00:04:57.787871 142708 sgd_solver.cpp:105] Iteration 5400, lr = 0.00892
I0529 00:07:06.752323 142708 solver.cpp:218] Iteration 5500 (0.775424 iter/s, 128.962s/100 iters), loss = 0.190663
I0529 00:07:06.752537 142708 solver.cpp:237]     Train net output #0: loss = 0.190663 (* 1 = 0.190663 loss)
I0529 00:07:06.752569 142708 sgd_solver.cpp:105] Iteration 5500, lr = 0.0089
I0529 00:09:15.746115 142708 solver.cpp:218] Iteration 5600 (0.775249 iter/s, 128.991s/100 iters), loss = 0.156168
I0529 00:09:15.746371 142708 solver.cpp:237]     Train net output #0: loss = 0.156168 (* 1 = 0.156168 loss)
I0529 00:09:15.746387 142708 sgd_solver.cpp:105] Iteration 5600, lr = 0.00888
I0529 00:11:24.720721 142708 solver.cpp:218] Iteration 5700 (0.775364 iter/s, 128.972s/100 iters), loss = 0.191935
I0529 00:11:24.720928 142708 solver.cpp:237]     Train net output #0: loss = 0.191935 (* 1 = 0.191935 loss)
I0529 00:11:24.720969 142708 sgd_solver.cpp:105] Iteration 5700, lr = 0.00886
I0529 00:11:57.171113 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:13:33.544703 142708 solver.cpp:218] Iteration 5800 (0.776271 iter/s, 128.821s/100 iters), loss = 0.192615
I0529 00:13:33.544925 142708 solver.cpp:237]     Train net output #0: loss = 0.192615 (* 1 = 0.192615 loss)
I0529 00:13:33.544956 142708 sgd_solver.cpp:105] Iteration 5800, lr = 0.00884
I0529 00:15:42.302278 142708 solver.cpp:218] Iteration 5900 (0.776671 iter/s, 128.755s/100 iters), loss = 0.191592
I0529 00:15:42.302526 142708 solver.cpp:237]     Train net output #0: loss = 0.191592 (* 1 = 0.191592 loss)
I0529 00:15:42.302543 142708 sgd_solver.cpp:105] Iteration 5900, lr = 0.00882
I0529 00:17:49.838440 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_6000.caffemodel
I0529 00:17:50.101660 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_6000.solverstate
I0529 00:17:50.157429 142708 solver.cpp:330] Iteration 6000, Testing net (#0)
I0529 00:18:08.247993 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:18:39.976068 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:19:12.421185 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:19:44.597986 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:20:02.146260 142708 blocking_queue.cpp:49] Waiting for data
I0529 00:20:16.755229 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:20:37.826236 142708 solver.cpp:397]     Test net output #0: accuracy = 0.909582
I0529 00:20:37.826331 142708 solver.cpp:397]     Test net output #1: loss = 0.245626 (* 1 = 0.245626 loss)
I0529 00:20:39.113595 142708 solver.cpp:218] Iteration 6000 (0.336922 iter/s, 296.805s/100 iters), loss = 0.213318
I0529 00:20:39.113679 142708 solver.cpp:237]     Train net output #0: loss = 0.213318 (* 1 = 0.213318 loss)
I0529 00:20:39.113698 142708 sgd_solver.cpp:105] Iteration 6000, lr = 0.0088
I0529 00:22:48.050596 142708 solver.cpp:218] Iteration 6100 (0.77559 iter/s, 128.934s/100 iters), loss = 0.258855
I0529 00:22:48.050818 142708 solver.cpp:237]     Train net output #0: loss = 0.258855 (* 1 = 0.258855 loss)
I0529 00:22:48.050834 142708 sgd_solver.cpp:105] Iteration 6100, lr = 0.00878
I0529 00:22:57.329344 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:24:57.027232 142708 solver.cpp:218] Iteration 6200 (0.775352 iter/s, 128.974s/100 iters), loss = 0.193674
I0529 00:24:57.027416 142708 solver.cpp:237]     Train net output #0: loss = 0.193674 (* 1 = 0.193674 loss)
I0529 00:24:57.027432 142708 sgd_solver.cpp:105] Iteration 6200, lr = 0.00876
I0529 00:27:05.979704 142708 solver.cpp:218] Iteration 6300 (0.775497 iter/s, 128.95s/100 iters), loss = 0.183079
I0529 00:27:05.979910 142708 solver.cpp:237]     Train net output #0: loss = 0.183079 (* 1 = 0.183079 loss)
I0529 00:27:05.979924 142708 sgd_solver.cpp:105] Iteration 6300, lr = 0.00874
I0529 00:29:14.950371 142708 solver.cpp:218] Iteration 6400 (0.775388 iter/s, 128.968s/100 iters), loss = 0.118218
I0529 00:29:14.950559 142708 solver.cpp:237]     Train net output #0: loss = 0.118218 (* 1 = 0.118218 loss)
I0529 00:29:14.950587 142708 sgd_solver.cpp:105] Iteration 6400, lr = 0.00872
I0529 00:31:10.002418 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:31:23.931464 142708 solver.cpp:218] Iteration 6500 (0.775325 iter/s, 128.978s/100 iters), loss = 0.133083
I0529 00:31:23.931550 142708 solver.cpp:237]     Train net output #0: loss = 0.133083 (* 1 = 0.133083 loss)
I0529 00:31:23.931574 142708 sgd_solver.cpp:105] Iteration 6500, lr = 0.0087
I0529 00:33:32.824898 142708 solver.cpp:218] Iteration 6600 (0.775852 iter/s, 128.891s/100 iters), loss = 0.143798
I0529 00:33:32.825455 142708 solver.cpp:237]     Train net output #0: loss = 0.143798 (* 1 = 0.143798 loss)
I0529 00:33:32.825472 142708 sgd_solver.cpp:105] Iteration 6600, lr = 0.00868
I0529 00:35:41.658849 142708 solver.cpp:218] Iteration 6700 (0.776213 iter/s, 128.831s/100 iters), loss = 0.210675
I0529 00:35:41.659257 142708 solver.cpp:237]     Train net output #0: loss = 0.210675 (* 1 = 0.210675 loss)
I0529 00:35:41.659276 142708 sgd_solver.cpp:105] Iteration 6700, lr = 0.00866
I0529 00:37:50.461037 142708 solver.cpp:218] Iteration 6800 (0.776404 iter/s, 128.799s/100 iters), loss = 0.147455
I0529 00:37:50.461294 142708 solver.cpp:237]     Train net output #0: loss = 0.147455 (* 1 = 0.147455 loss)
I0529 00:37:50.461309 142708 sgd_solver.cpp:105] Iteration 6800, lr = 0.00864
I0529 00:39:22.117908 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:39:59.238365 142708 solver.cpp:218] Iteration 6900 (0.776553 iter/s, 128.774s/100 iters), loss = 0.296924
I0529 00:39:59.238639 142708 solver.cpp:237]     Train net output #0: loss = 0.296924 (* 1 = 0.296924 loss)
I0529 00:39:59.238672 142708 sgd_solver.cpp:105] Iteration 6900, lr = 0.00862
I0529 00:42:06.815444 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_7000.caffemodel
I0529 00:42:06.974479 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_7000.solverstate
I0529 00:42:07.038087 142708 solver.cpp:330] Iteration 7000, Testing net (#0)
I0529 00:42:17.654742 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:42:49.547243 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:43:21.738044 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:43:53.884388 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:44:25.980131 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:44:54.672426 142708 solver.cpp:397]     Test net output #0: accuracy = 0.892682
I0529 00:44:54.672508 142708 solver.cpp:397]     Test net output #1: loss = 0.312953 (* 1 = 0.312953 loss)
I0529 00:44:55.963492 142708 solver.cpp:218] Iteration 7000 (0.33702 iter/s, 296.718s/100 iters), loss = 0.18167
I0529 00:44:55.963570 142708 solver.cpp:237]     Train net output #0: loss = 0.18167 (* 1 = 0.18167 loss)
I0529 00:44:55.963587 142708 sgd_solver.cpp:105] Iteration 7000, lr = 0.0086
I0529 00:47:04.868770 142708 solver.cpp:218] Iteration 7100 (0.775781 iter/s, 128.902s/100 iters), loss = 0.175935
I0529 00:47:04.868969 142708 solver.cpp:237]     Train net output #0: loss = 0.175935 (* 1 = 0.175935 loss)
I0529 00:47:04.868986 142708 sgd_solver.cpp:105] Iteration 7100, lr = 0.00858
I0529 00:49:13.796450 142708 solver.cpp:218] Iteration 7200 (0.775647 iter/s, 128.925s/100 iters), loss = 0.2306
I0529 00:49:13.796699 142708 solver.cpp:237]     Train net output #0: loss = 0.2306 (* 1 = 0.2306 loss)
I0529 00:49:13.796715 142708 sgd_solver.cpp:105] Iteration 7200, lr = 0.00856
I0529 00:50:22.399313 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:51:22.767509 142708 solver.cpp:218] Iteration 7300 (0.775386 iter/s, 128.968s/100 iters), loss = 0.143149
I0529 00:51:22.767683 142708 solver.cpp:237]     Train net output #0: loss = 0.143149 (* 1 = 0.143149 loss)
I0529 00:51:22.767709 142708 sgd_solver.cpp:105] Iteration 7300, lr = 0.00854
I0529 00:53:31.756753 142708 solver.cpp:218] Iteration 7400 (0.775276 iter/s, 128.986s/100 iters), loss = 0.102532
I0529 00:53:31.756938 142708 solver.cpp:237]     Train net output #0: loss = 0.102532 (* 1 = 0.102532 loss)
I0529 00:53:31.756955 142708 sgd_solver.cpp:105] Iteration 7400, lr = 0.00852
I0529 00:55:40.717526 142708 solver.cpp:218] Iteration 7500 (0.775447 iter/s, 128.958s/100 iters), loss = 0.202001
I0529 00:55:40.717795 142708 solver.cpp:237]     Train net output #0: loss = 0.202 (* 1 = 0.202 loss)
I0529 00:55:40.717813 142708 sgd_solver.cpp:105] Iteration 7500, lr = 0.0085
I0529 00:57:49.679594 142708 solver.cpp:218] Iteration 7600 (0.77544 iter/s, 128.959s/100 iters), loss = 0.161824
I0529 00:57:49.679834 142708 solver.cpp:237]     Train net output #0: loss = 0.161824 (* 1 = 0.161824 loss)
I0529 00:57:49.679886 142708 sgd_solver.cpp:105] Iteration 7600, lr = 0.00848
I0529 00:58:35.013546 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 00:59:58.588549 142708 solver.cpp:218] Iteration 7700 (0.77576 iter/s, 128.906s/100 iters), loss = 0.163511
I0529 00:59:58.588830 142708 solver.cpp:237]     Train net output #0: loss = 0.163511 (* 1 = 0.163511 loss)
I0529 00:59:58.588843 142708 sgd_solver.cpp:105] Iteration 7700, lr = 0.00846
I0529 01:02:07.499074 142708 solver.cpp:218] Iteration 7800 (0.775751 iter/s, 128.907s/100 iters), loss = 0.208526
I0529 01:02:07.499338 142708 solver.cpp:237]     Train net output #0: loss = 0.208526 (* 1 = 0.208526 loss)
I0529 01:02:07.499356 142708 sgd_solver.cpp:105] Iteration 7800, lr = 0.00844
I0529 01:04:16.302958 142708 solver.cpp:218] Iteration 7900 (0.776393 iter/s, 128.801s/100 iters), loss = 0.212037
I0529 01:04:16.303273 142708 solver.cpp:237]     Train net output #0: loss = 0.212037 (* 1 = 0.212037 loss)
I0529 01:04:16.303297 142708 sgd_solver.cpp:105] Iteration 7900, lr = 0.00842
I0529 01:06:23.893823 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_8000.caffemodel
I0529 01:06:24.092552 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_8000.solverstate
I0529 01:06:24.147624 142708 solver.cpp:330] Iteration 8000, Testing net (#0)
I0529 01:06:27.628861 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:06:40.639793 142708 blocking_queue.cpp:49] Waiting for data
I0529 01:06:59.790501 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:07:31.946982 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:08:04.096978 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:08:36.226382 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:09:08.392645 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:09:12.458822 142708 solver.cpp:397]     Test net output #0: accuracy = 0.897602
I0529 01:09:12.458896 142708 solver.cpp:397]     Test net output #1: loss = 0.265764 (* 1 = 0.265764 loss)
I0529 01:09:13.742056 142708 solver.cpp:218] Iteration 8000 (0.336211 iter/s, 297.432s/100 iters), loss = 0.2145
I0529 01:09:13.742120 142708 solver.cpp:237]     Train net output #0: loss = 0.2145 (* 1 = 0.2145 loss)
I0529 01:09:13.742135 142708 sgd_solver.cpp:105] Iteration 8000, lr = 0.0084
I0529 01:09:35.878540 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:11:22.498657 142708 solver.cpp:218] Iteration 8100 (0.776677 iter/s, 128.754s/100 iters), loss = 0.217393
I0529 01:11:22.498860 142708 solver.cpp:237]     Train net output #0: loss = 0.217393 (* 1 = 0.217393 loss)
I0529 01:11:22.498903 142708 sgd_solver.cpp:105] Iteration 8100, lr = 0.00838
I0529 01:13:31.281544 142708 solver.cpp:218] Iteration 8200 (0.776519 iter/s, 128.78s/100 iters), loss = 0.179639
I0529 01:13:31.281744 142708 solver.cpp:237]     Train net output #0: loss = 0.179639 (* 1 = 0.179639 loss)
I0529 01:13:31.281774 142708 sgd_solver.cpp:105] Iteration 8200, lr = 0.00836
I0529 01:15:40.227435 142708 solver.cpp:218] Iteration 8300 (0.775538 iter/s, 128.943s/100 iters), loss = 0.148618
I0529 01:15:40.227622 142708 solver.cpp:237]     Train net output #0: loss = 0.148618 (* 1 = 0.148618 loss)
I0529 01:15:40.227643 142708 sgd_solver.cpp:105] Iteration 8300, lr = 0.00834
I0529 01:17:48.067205 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:17:49.139434 142708 solver.cpp:218] Iteration 8400 (0.775741 iter/s, 128.909s/100 iters), loss = 0.196912
I0529 01:17:49.139511 142708 solver.cpp:237]     Train net output #0: loss = 0.196912 (* 1 = 0.196912 loss)
I0529 01:17:49.139528 142708 sgd_solver.cpp:105] Iteration 8400, lr = 0.00832
I0529 01:19:58.048768 142708 solver.cpp:218] Iteration 8500 (0.775756 iter/s, 128.906s/100 iters), loss = 0.0972194
I0529 01:19:58.048977 142708 solver.cpp:237]     Train net output #0: loss = 0.0972194 (* 1 = 0.0972194 loss)
I0529 01:19:58.049008 142708 sgd_solver.cpp:105] Iteration 8500, lr = 0.0083
I0529 01:22:06.994431 142708 solver.cpp:218] Iteration 8600 (0.775538 iter/s, 128.943s/100 iters), loss = 0.0853214
I0529 01:22:06.994685 142708 solver.cpp:237]     Train net output #0: loss = 0.0853214 (* 1 = 0.0853214 loss)
I0529 01:22:06.994701 142708 sgd_solver.cpp:105] Iteration 8600, lr = 0.00828
I0529 01:24:16.031769 142708 solver.cpp:218] Iteration 8700 (0.774988 iter/s, 129.034s/100 iters), loss = 0.138008
I0529 01:24:16.031977 142708 solver.cpp:237]     Train net output #0: loss = 0.138008 (* 1 = 0.138008 loss)
I0529 01:24:16.032024 142708 sgd_solver.cpp:105] Iteration 8700, lr = 0.00826
I0529 01:26:00.776494 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:26:25.053695 142708 solver.cpp:218] Iteration 8800 (0.77508 iter/s, 129.019s/100 iters), loss = 0.355809
I0529 01:26:25.053781 142708 solver.cpp:237]     Train net output #0: loss = 0.355809 (* 1 = 0.355809 loss)
I0529 01:26:25.053792 142708 sgd_solver.cpp:105] Iteration 8800, lr = 0.00824
I0529 01:28:34.010354 142708 solver.cpp:218] Iteration 8900 (0.775471 iter/s, 128.954s/100 iters), loss = 0.218086
I0529 01:28:34.010625 142708 solver.cpp:237]     Train net output #0: loss = 0.218086 (* 1 = 0.218086 loss)
I0529 01:28:34.010641 142708 sgd_solver.cpp:105] Iteration 8900, lr = 0.00822
I0529 01:30:41.705245 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_9000.caffemodel
I0529 01:30:41.926285 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_9000.solverstate
I0529 01:30:41.982549 142708 solver.cpp:330] Iteration 9000, Testing net (#0)
I0529 01:31:09.506474 142708 blocking_queue.cpp:49] Waiting for data
I0529 01:31:09.978451 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:31:42.212783 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:32:14.447945 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:32:46.673897 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:33:18.877542 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:33:30.549867 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904382
I0529 01:33:30.549955 142708 solver.cpp:397]     Test net output #1: loss = 0.259586 (* 1 = 0.259586 loss)
I0529 01:33:31.837291 142708 solver.cpp:218] Iteration 9000 (0.335773 iter/s, 297.82s/100 iters), loss = 0.186336
I0529 01:33:31.837380 142708 solver.cpp:237]     Train net output #0: loss = 0.186336 (* 1 = 0.186336 loss)
I0529 01:33:31.837396 142708 sgd_solver.cpp:105] Iteration 9000, lr = 0.0082
I0529 01:35:40.838137 142708 solver.cpp:218] Iteration 9100 (0.775206 iter/s, 128.998s/100 iters), loss = 0.168366
I0529 01:35:40.838359 142708 solver.cpp:237]     Train net output #0: loss = 0.168366 (* 1 = 0.168366 loss)
I0529 01:35:40.838374 142708 sgd_solver.cpp:105] Iteration 9100, lr = 0.00818
I0529 01:37:02.392423 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:37:49.906154 142708 solver.cpp:218] Iteration 9200 (0.774803 iter/s, 129.065s/100 iters), loss = 0.153088
I0529 01:37:49.906333 142708 solver.cpp:237]     Train net output #0: loss = 0.153087 (* 1 = 0.153087 loss)
I0529 01:37:49.906355 142708 sgd_solver.cpp:105] Iteration 9200, lr = 0.00816
I0529 01:39:58.997416 142708 solver.cpp:218] Iteration 9300 (0.774663 iter/s, 129.088s/100 iters), loss = 0.215862
I0529 01:39:58.997622 142708 solver.cpp:237]     Train net output #0: loss = 0.215862 (* 1 = 0.215862 loss)
I0529 01:39:58.997648 142708 sgd_solver.cpp:105] Iteration 9300, lr = 0.00814
I0529 01:42:08.029137 142708 solver.cpp:218] Iteration 9400 (0.775021 iter/s, 129.029s/100 iters), loss = 0.147325
I0529 01:42:08.029343 142708 solver.cpp:237]     Train net output #0: loss = 0.147324 (* 1 = 0.147324 loss)
I0529 01:42:08.029376 142708 sgd_solver.cpp:105] Iteration 9400, lr = 0.00812
I0529 01:44:17.057832 142708 solver.cpp:218] Iteration 9500 (0.775039 iter/s, 129.026s/100 iters), loss = 0.163825
I0529 01:44:17.058109 142708 solver.cpp:237]     Train net output #0: loss = 0.163824 (* 1 = 0.163824 loss)
I0529 01:44:17.058140 142708 sgd_solver.cpp:105] Iteration 9500, lr = 0.0081
I0529 01:45:15.319797 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:46:26.068351 142708 solver.cpp:218] Iteration 9600 (0.775149 iter/s, 129.007s/100 iters), loss = 0.203433
I0529 01:46:26.068560 142708 solver.cpp:237]     Train net output #0: loss = 0.203433 (* 1 = 0.203433 loss)
I0529 01:46:26.068589 142708 sgd_solver.cpp:105] Iteration 9600, lr = 0.00808
I0529 01:48:35.052443 142708 solver.cpp:218] Iteration 9700 (0.775307 iter/s, 128.981s/100 iters), loss = 0.246144
I0529 01:48:35.052676 142708 solver.cpp:237]     Train net output #0: loss = 0.246144 (* 1 = 0.246144 loss)
I0529 01:48:35.052700 142708 sgd_solver.cpp:105] Iteration 9700, lr = 0.00806
I0529 01:50:44.046777 142708 solver.cpp:218] Iteration 9800 (0.775246 iter/s, 128.991s/100 iters), loss = 0.244146
I0529 01:50:44.046973 142708 solver.cpp:237]     Train net output #0: loss = 0.244146 (* 1 = 0.244146 loss)
I0529 01:50:44.047004 142708 sgd_solver.cpp:105] Iteration 9800, lr = 0.00804
I0529 01:52:52.982514 142708 solver.cpp:218] Iteration 9900 (0.775598 iter/s, 128.933s/100 iters), loss = 0.245137
I0529 01:52:52.982744 142708 solver.cpp:237]     Train net output #0: loss = 0.245137 (* 1 = 0.245137 loss)
I0529 01:52:52.982770 142708 sgd_solver.cpp:105] Iteration 9900, lr = 0.00802
I0529 01:53:28.019731 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:55:00.656035 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_10000.caffemodel
I0529 01:55:01.049441 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_10000.solverstate
I0529 01:55:01.102681 142708 solver.cpp:330] Iteration 10000, Testing net (#0)
I0529 01:55:21.522310 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:55:35.188050 142708 blocking_queue.cpp:49] Waiting for data
I0529 01:55:53.687130 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:56:25.832836 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:56:57.997493 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:57:30.147370 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 01:57:49.364965 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904222
I0529 01:57:49.365052 142708 solver.cpp:397]     Test net output #1: loss = 0.268384 (* 1 = 0.268384 loss)
I0529 01:57:50.653558 142708 solver.cpp:218] Iteration 10000 (0.335948 iter/s, 297.665s/100 iters), loss = 0.249077
I0529 01:57:50.653641 142708 solver.cpp:237]     Train net output #0: loss = 0.249076 (* 1 = 0.249076 loss)
I0529 01:57:50.653656 142708 sgd_solver.cpp:105] Iteration 10000, lr = 0.008
I0529 01:59:59.559051 142708 solver.cpp:218] Iteration 10100 (0.77578 iter/s, 128.903s/100 iters), loss = 0.1282
I0529 01:59:59.559258 142708 solver.cpp:237]     Train net output #0: loss = 0.1282 (* 1 = 0.1282 loss)
I0529 01:59:59.559285 142708 sgd_solver.cpp:105] Iteration 10100, lr = 0.00798
I0529 02:02:08.477998 142708 solver.cpp:218] Iteration 10200 (0.775699 iter/s, 128.916s/100 iters), loss = 0.12513
I0529 02:02:08.478200 142708 solver.cpp:237]     Train net output #0: loss = 0.12513 (* 1 = 0.12513 loss)
I0529 02:02:08.478229 142708 sgd_solver.cpp:105] Iteration 10200, lr = 0.00796
I0529 02:04:17.385246 142708 solver.cpp:218] Iteration 10300 (0.775769 iter/s, 128.904s/100 iters), loss = 0.201522
I0529 02:04:17.385488 142708 solver.cpp:237]     Train net output #0: loss = 0.201522 (* 1 = 0.201522 loss)
I0529 02:04:17.385527 142708 sgd_solver.cpp:105] Iteration 10300, lr = 0.00794
I0529 02:04:29.191807 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:06:26.170341 142708 solver.cpp:218] Iteration 10400 (0.776505 iter/s, 128.782s/100 iters), loss = 0.14881
I0529 02:06:26.170552 142708 solver.cpp:237]     Train net output #0: loss = 0.14881 (* 1 = 0.14881 loss)
I0529 02:06:26.170580 142708 sgd_solver.cpp:105] Iteration 10400, lr = 0.00792
I0529 02:08:35.054415 142708 solver.cpp:218] Iteration 10500 (0.775909 iter/s, 128.881s/100 iters), loss = 0.187942
I0529 02:08:35.054584 142708 solver.cpp:237]     Train net output #0: loss = 0.187942 (* 1 = 0.187942 loss)
I0529 02:08:35.054608 142708 sgd_solver.cpp:105] Iteration 10500, lr = 0.0079
I0529 02:10:43.923281 142708 solver.cpp:218] Iteration 10600 (0.776 iter/s, 128.866s/100 iters), loss = 0.218426
I0529 02:10:43.923481 142708 solver.cpp:237]     Train net output #0: loss = 0.218426 (* 1 = 0.218426 loss)
I0529 02:10:43.923516 142708 sgd_solver.cpp:105] Iteration 10600, lr = 0.00788
I0529 02:12:41.490216 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:12:52.840569 142708 solver.cpp:218] Iteration 10700 (0.775709 iter/s, 128.914s/100 iters), loss = 0.14383
I0529 02:12:52.840663 142708 solver.cpp:237]     Train net output #0: loss = 0.14383 (* 1 = 0.14383 loss)
I0529 02:12:52.840677 142708 sgd_solver.cpp:105] Iteration 10700, lr = 0.00786
I0529 02:15:01.617403 142708 solver.cpp:218] Iteration 10800 (0.776554 iter/s, 128.774s/100 iters), loss = 0.148332
I0529 02:15:01.617612 142708 solver.cpp:237]     Train net output #0: loss = 0.148332 (* 1 = 0.148332 loss)
I0529 02:15:01.617631 142708 sgd_solver.cpp:105] Iteration 10800, lr = 0.00784
I0529 02:17:10.362263 142708 solver.cpp:218] Iteration 10900 (0.776748 iter/s, 128.742s/100 iters), loss = 0.120764
I0529 02:17:10.362498 142708 solver.cpp:237]     Train net output #0: loss = 0.120764 (* 1 = 0.120764 loss)
I0529 02:17:10.362519 142708 sgd_solver.cpp:105] Iteration 10900, lr = 0.00782
I0529 02:19:17.888496 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_11000.caffemodel
I0529 02:19:18.184960 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_11000.solverstate
I0529 02:19:18.240939 142708 solver.cpp:330] Iteration 11000, Testing net (#0)
I0529 02:19:31.083717 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:19:57.383658 142708 blocking_queue.cpp:49] Waiting for data
I0529 02:20:03.229967 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:20:35.354363 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:21:07.493337 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:21:39.642808 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:22:06.450179 142708 solver.cpp:397]     Test net output #0: accuracy = 0.897442
I0529 02:22:06.450278 142708 solver.cpp:397]     Test net output #1: loss = 0.27986 (* 1 = 0.27986 loss)
I0529 02:22:07.740746 142708 solver.cpp:218] Iteration 11000 (0.336279 iter/s, 297.372s/100 iters), loss = 0.131168
I0529 02:22:07.740833 142708 solver.cpp:237]     Train net output #0: loss = 0.131167 (* 1 = 0.131167 loss)
I0529 02:22:07.740854 142708 sgd_solver.cpp:105] Iteration 11000, lr = 0.0078
I0529 02:23:42.062834 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:24:16.624694 142708 solver.cpp:218] Iteration 11100 (0.775909 iter/s, 128.881s/100 iters), loss = 0.164065
I0529 02:24:16.624903 142708 solver.cpp:237]     Train net output #0: loss = 0.164065 (* 1 = 0.164065 loss)
I0529 02:24:16.624935 142708 sgd_solver.cpp:105] Iteration 11100, lr = 0.00778
I0529 02:26:25.471060 142708 solver.cpp:218] Iteration 11200 (0.776136 iter/s, 128.843s/100 iters), loss = 0.16017
I0529 02:26:25.471271 142708 solver.cpp:237]     Train net output #0: loss = 0.16017 (* 1 = 0.16017 loss)
I0529 02:26:25.471292 142708 sgd_solver.cpp:105] Iteration 11200, lr = 0.00776
I0529 02:28:34.330616 142708 solver.cpp:218] Iteration 11300 (0.776056 iter/s, 128.857s/100 iters), loss = 0.0831893
I0529 02:28:34.330775 142708 solver.cpp:237]     Train net output #0: loss = 0.0831892 (* 1 = 0.0831892 loss)
I0529 02:28:34.330791 142708 sgd_solver.cpp:105] Iteration 11300, lr = 0.00774
I0529 02:30:43.348935 142708 solver.cpp:218] Iteration 11400 (0.775101 iter/s, 129.015s/100 iters), loss = 0.110932
I0529 02:30:43.349169 142708 solver.cpp:237]     Train net output #0: loss = 0.110932 (* 1 = 0.110932 loss)
I0529 02:30:43.349195 142708 sgd_solver.cpp:105] Iteration 11400, lr = 0.00772
I0529 02:31:54.444823 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:32:52.230793 142708 solver.cpp:218] Iteration 11500 (0.775923 iter/s, 128.879s/100 iters), loss = 0.187455
I0529 02:32:52.231047 142708 solver.cpp:237]     Train net output #0: loss = 0.187455 (* 1 = 0.187455 loss)
I0529 02:32:52.231066 142708 sgd_solver.cpp:105] Iteration 11500, lr = 0.0077
I0529 02:35:01.195430 142708 solver.cpp:218] Iteration 11600 (0.775424 iter/s, 128.962s/100 iters), loss = 0.249448
I0529 02:35:01.195648 142708 solver.cpp:237]     Train net output #0: loss = 0.249448 (* 1 = 0.249448 loss)
I0529 02:35:01.195663 142708 sgd_solver.cpp:105] Iteration 11600, lr = 0.00768
I0529 02:37:10.126585 142708 solver.cpp:218] Iteration 11700 (0.775626 iter/s, 128.928s/100 iters), loss = 0.0806241
I0529 02:37:10.126866 142708 solver.cpp:237]     Train net output #0: loss = 0.080624 (* 1 = 0.080624 loss)
I0529 02:37:10.126884 142708 sgd_solver.cpp:105] Iteration 11700, lr = 0.00766
I0529 02:39:19.024406 142708 solver.cpp:218] Iteration 11800 (0.775827 iter/s, 128.895s/100 iters), loss = 0.172023
I0529 02:39:19.024652 142708 solver.cpp:237]     Train net output #0: loss = 0.172023 (* 1 = 0.172023 loss)
I0529 02:39:19.024669 142708 sgd_solver.cpp:105] Iteration 11800, lr = 0.00764
I0529 02:40:06.972869 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:41:27.989594 142708 solver.cpp:218] Iteration 11900 (0.775421 iter/s, 128.962s/100 iters), loss = 0.0835278
I0529 02:41:27.989784 142708 solver.cpp:237]     Train net output #0: loss = 0.0835278 (* 1 = 0.0835278 loss)
I0529 02:41:27.989837 142708 sgd_solver.cpp:105] Iteration 11900, lr = 0.00762
I0529 02:43:35.574455 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_12000.caffemodel
I0529 02:43:36.069097 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_12000.solverstate
I0529 02:43:36.130619 142708 solver.cpp:330] Iteration 12000, Testing net (#0)
I0529 02:43:41.470481 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:44:13.622205 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:44:16.184324 142708 blocking_queue.cpp:49] Waiting for data
I0529 02:44:45.768962 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:45:17.921509 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:45:50.088562 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:46:22.262713 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:46:24.477120 142708 solver.cpp:397]     Test net output #0: accuracy = 0.810561
I0529 02:46:24.477208 142708 solver.cpp:397]     Test net output #1: loss = 0.36335 (* 1 = 0.36335 loss)
I0529 02:46:25.768774 142708 solver.cpp:218] Iteration 12000 (0.335827 iter/s, 297.773s/100 iters), loss = 0.0850214
I0529 02:46:25.768874 142708 solver.cpp:237]     Train net output #0: loss = 0.0850214 (* 1 = 0.0850214 loss)
I0529 02:46:25.768893 142708 sgd_solver.cpp:105] Iteration 12000, lr = 0.0076
I0529 02:48:34.720593 142708 solver.cpp:218] Iteration 12100 (0.775501 iter/s, 128.949s/100 iters), loss = 0.0892503
I0529 02:48:34.720809 142708 solver.cpp:237]     Train net output #0: loss = 0.0892503 (* 1 = 0.0892503 loss)
I0529 02:48:34.720835 142708 sgd_solver.cpp:105] Iteration 12100, lr = 0.00758
I0529 02:50:43.656538 142708 solver.cpp:218] Iteration 12200 (0.775597 iter/s, 128.933s/100 iters), loss = 0.169373
I0529 02:50:43.656730 142708 solver.cpp:237]     Train net output #0: loss = 0.169373 (* 1 = 0.169373 loss)
I0529 02:50:43.656759 142708 sgd_solver.cpp:105] Iteration 12200, lr = 0.00756
I0529 02:51:08.383533 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 02:52:52.590699 142708 solver.cpp:218] Iteration 12300 (0.775607 iter/s, 128.931s/100 iters), loss = 0.0800242
I0529 02:52:52.590925 142708 solver.cpp:237]     Train net output #0: loss = 0.0800242 (* 1 = 0.0800242 loss)
I0529 02:52:52.590965 142708 sgd_solver.cpp:105] Iteration 12300, lr = 0.00754
I0529 02:55:01.586834 142708 solver.cpp:218] Iteration 12400 (0.775235 iter/s, 128.993s/100 iters), loss = 0.153007
I0529 02:55:01.586997 142708 solver.cpp:237]     Train net output #0: loss = 0.153007 (* 1 = 0.153007 loss)
I0529 02:55:01.587013 142708 sgd_solver.cpp:105] Iteration 12400, lr = 0.00752
I0529 02:57:10.578794 142708 solver.cpp:218] Iteration 12500 (0.775259 iter/s, 128.989s/100 iters), loss = 0.0673437
I0529 02:57:10.578997 142708 solver.cpp:237]     Train net output #0: loss = 0.0673437 (* 1 = 0.0673437 loss)
I0529 02:57:10.579011 142708 sgd_solver.cpp:105] Iteration 12500, lr = 0.0075
I0529 02:59:19.612993 142708 solver.cpp:218] Iteration 12600 (0.775006 iter/s, 129.031s/100 iters), loss = 0.103397
I0529 02:59:19.613227 142708 solver.cpp:237]     Train net output #0: loss = 0.103397 (* 1 = 0.103397 loss)
I0529 02:59:19.613258 142708 sgd_solver.cpp:105] Iteration 12600, lr = 0.00748
I0529 02:59:21.125746 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:01:28.620777 142708 solver.cpp:218] Iteration 12700 (0.775164 iter/s, 129.005s/100 iters), loss = 0.0976619
I0529 03:01:28.621021 142708 solver.cpp:237]     Train net output #0: loss = 0.0976619 (* 1 = 0.0976619 loss)
I0529 03:01:28.621037 142708 sgd_solver.cpp:105] Iteration 12700, lr = 0.00746
I0529 03:03:37.608172 142708 solver.cpp:218] Iteration 12800 (0.775287 iter/s, 128.984s/100 iters), loss = 0.18421
I0529 03:03:37.608358 142708 solver.cpp:237]     Train net output #0: loss = 0.18421 (* 1 = 0.18421 loss)
I0529 03:03:37.608374 142708 sgd_solver.cpp:105] Iteration 12800, lr = 0.00744
I0529 03:05:46.578634 142708 solver.cpp:218] Iteration 12900 (0.775388 iter/s, 128.968s/100 iters), loss = 0.0959208
I0529 03:05:46.578805 142708 solver.cpp:237]     Train net output #0: loss = 0.0959208 (* 1 = 0.0959208 loss)
I0529 03:05:46.578821 142708 sgd_solver.cpp:105] Iteration 12900, lr = 0.00742
I0529 03:07:33.853883 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:07:54.279337 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_13000.caffemodel
I0529 03:07:54.775720 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_13000.solverstate
I0529 03:07:54.836413 142708 solver.cpp:330] Iteration 13000, Testing net (#0)
I0529 03:08:24.705946 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:08:41.439780 142708 blocking_queue.cpp:49] Waiting for data
I0529 03:08:56.919095 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:09:29.102910 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:10:01.298163 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:10:33.482591 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:10:43.275840 142708 solver.cpp:397]     Test net output #0: accuracy = 0.906962
I0529 03:10:43.275915 142708 solver.cpp:397]     Test net output #1: loss = 0.258464 (* 1 = 0.258464 loss)
I0529 03:10:44.561329 142708 solver.cpp:218] Iteration 13000 (0.335597 iter/s, 297.976s/100 iters), loss = 0.10069
I0529 03:10:44.561431 142708 solver.cpp:237]     Train net output #0: loss = 0.10069 (* 1 = 0.10069 loss)
I0529 03:10:44.561451 142708 sgd_solver.cpp:105] Iteration 13000, lr = 0.0074
I0529 03:12:53.532284 142708 solver.cpp:218] Iteration 13100 (0.775385 iter/s, 128.968s/100 iters), loss = 0.205926
I0529 03:12:53.532446 142708 solver.cpp:237]     Train net output #0: loss = 0.205926 (* 1 = 0.205926 loss)
I0529 03:12:53.532482 142708 sgd_solver.cpp:105] Iteration 13100, lr = 0.00738
I0529 03:15:02.455451 142708 solver.cpp:218] Iteration 13200 (0.775673 iter/s, 128.92s/100 iters), loss = 0.193557
I0529 03:15:02.455601 142708 solver.cpp:237]     Train net output #0: loss = 0.193557 (* 1 = 0.193557 loss)
I0529 03:15:02.455618 142708 sgd_solver.cpp:105] Iteration 13200, lr = 0.00736
I0529 03:17:11.329249 142708 solver.cpp:218] Iteration 13300 (0.77597 iter/s, 128.871s/100 iters), loss = 0.121057
I0529 03:17:11.329452 142708 solver.cpp:237]     Train net output #0: loss = 0.121057 (* 1 = 0.121057 loss)
I0529 03:17:11.329495 142708 sgd_solver.cpp:105] Iteration 13300, lr = 0.00734
I0529 03:18:35.334511 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:19:20.257269 142708 solver.cpp:218] Iteration 13400 (0.775644 iter/s, 128.925s/100 iters), loss = 0.13015
I0529 03:19:20.257570 142708 solver.cpp:237]     Train net output #0: loss = 0.13015 (* 1 = 0.13015 loss)
I0529 03:19:20.257603 142708 sgd_solver.cpp:105] Iteration 13400, lr = 0.00732
I0529 03:21:29.246606 142708 solver.cpp:218] Iteration 13500 (0.775276 iter/s, 128.986s/100 iters), loss = 0.164442
I0529 03:21:29.246781 142708 solver.cpp:237]     Train net output #0: loss = 0.164442 (* 1 = 0.164442 loss)
I0529 03:21:29.246798 142708 sgd_solver.cpp:105] Iteration 13500, lr = 0.0073
I0529 03:23:38.318662 142708 solver.cpp:218] Iteration 13600 (0.774779 iter/s, 129.069s/100 iters), loss = 0.167324
I0529 03:23:38.318888 142708 solver.cpp:237]     Train net output #0: loss = 0.167324 (* 1 = 0.167324 loss)
I0529 03:23:38.318930 142708 sgd_solver.cpp:105] Iteration 13600, lr = 0.00728
I0529 03:25:47.337033 142708 solver.cpp:218] Iteration 13700 (0.775102 iter/s, 129.015s/100 iters), loss = 0.13686
I0529 03:25:47.337234 142708 solver.cpp:237]     Train net output #0: loss = 0.13686 (* 1 = 0.13686 loss)
I0529 03:25:47.337266 142708 sgd_solver.cpp:105] Iteration 13700, lr = 0.00726
I0529 03:26:48.233542 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:27:56.299846 142708 solver.cpp:218] Iteration 13800 (0.775435 iter/s, 128.96s/100 iters), loss = 0.176465
I0529 03:27:56.300014 142708 solver.cpp:237]     Train net output #0: loss = 0.176465 (* 1 = 0.176465 loss)
I0529 03:27:56.300030 142708 sgd_solver.cpp:105] Iteration 13800, lr = 0.00724
I0529 03:30:05.227147 142708 solver.cpp:218] Iteration 13900 (0.775649 iter/s, 128.924s/100 iters), loss = 0.097743
I0529 03:30:05.227324 142708 solver.cpp:237]     Train net output #0: loss = 0.0977429 (* 1 = 0.0977429 loss)
I0529 03:30:05.227344 142708 sgd_solver.cpp:105] Iteration 13900, lr = 0.00722
I0529 03:32:12.955572 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_14000.caffemodel
I0529 03:32:13.315855 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_14000.solverstate
I0529 03:32:13.372164 142708 solver.cpp:330] Iteration 14000, Testing net (#0)
I0529 03:32:35.130702 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:33:07.462057 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:33:34.103581 142708 blocking_queue.cpp:49] Waiting for data
I0529 03:33:39.620972 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:34:11.782704 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:34:43.950798 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:35:01.338903 142708 solver.cpp:397]     Test net output #0: accuracy = 0.878302
I0529 03:35:01.338994 142708 solver.cpp:397]     Test net output #1: loss = 0.388571 (* 1 = 0.388571 loss)
I0529 03:35:02.627624 142708 solver.cpp:218] Iteration 14000 (0.336254 iter/s, 297.394s/100 iters), loss = 0.266958
I0529 03:35:02.627702 142708 solver.cpp:237]     Train net output #0: loss = 0.266958 (* 1 = 0.266958 loss)
I0529 03:35:02.627719 142708 sgd_solver.cpp:105] Iteration 14000, lr = 0.0072
I0529 03:37:11.423440 142708 solver.cpp:218] Iteration 14100 (0.776441 iter/s, 128.793s/100 iters), loss = 0.10958
I0529 03:37:11.423666 142708 solver.cpp:237]     Train net output #0: loss = 0.10958 (* 1 = 0.10958 loss)
I0529 03:37:11.423689 142708 sgd_solver.cpp:105] Iteration 14100, lr = 0.00718
I0529 03:37:48.988895 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:39:20.259546 142708 solver.cpp:218] Iteration 14200 (0.776198 iter/s, 128.833s/100 iters), loss = 0.148653
I0529 03:39:20.259824 142708 solver.cpp:237]     Train net output #0: loss = 0.148653 (* 1 = 0.148653 loss)
I0529 03:39:20.259843 142708 sgd_solver.cpp:105] Iteration 14200, lr = 0.00716
I0529 03:41:29.226840 142708 solver.cpp:218] Iteration 14300 (0.775409 iter/s, 128.964s/100 iters), loss = 0.0596098
I0529 03:41:29.227056 142708 solver.cpp:237]     Train net output #0: loss = 0.0596098 (* 1 = 0.0596098 loss)
I0529 03:41:29.227084 142708 sgd_solver.cpp:105] Iteration 14300, lr = 0.00714
I0529 03:43:38.115684 142708 solver.cpp:218] Iteration 14400 (0.77588 iter/s, 128.886s/100 iters), loss = 0.098485
I0529 03:43:38.115888 142708 solver.cpp:237]     Train net output #0: loss = 0.098485 (* 1 = 0.098485 loss)
I0529 03:43:38.115949 142708 sgd_solver.cpp:105] Iteration 14400, lr = 0.00712
I0529 03:45:47.013394 142708 solver.cpp:218] Iteration 14500 (0.775827 iter/s, 128.895s/100 iters), loss = 0.0932156
I0529 03:45:47.013607 142708 solver.cpp:237]     Train net output #0: loss = 0.0932157 (* 1 = 0.0932157 loss)
I0529 03:45:47.013645 142708 sgd_solver.cpp:105] Iteration 14500, lr = 0.0071
I0529 03:46:01.410905 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:47:55.981853 142708 solver.cpp:218] Iteration 14600 (0.775402 iter/s, 128.965s/100 iters), loss = 0.146541
I0529 03:47:55.982295 142708 solver.cpp:237]     Train net output #0: loss = 0.146541 (* 1 = 0.146541 loss)
I0529 03:47:55.982316 142708 sgd_solver.cpp:105] Iteration 14600, lr = 0.00708
I0529 03:50:04.998432 142708 solver.cpp:218] Iteration 14700 (0.775114 iter/s, 129.013s/100 iters), loss = 0.0732337
I0529 03:50:04.998615 142708 solver.cpp:237]     Train net output #0: loss = 0.0732338 (* 1 = 0.0732338 loss)
I0529 03:50:04.998638 142708 sgd_solver.cpp:105] Iteration 14700, lr = 0.00706
I0529 03:52:13.928433 142708 solver.cpp:218] Iteration 14800 (0.775633 iter/s, 128.927s/100 iters), loss = 0.190917
I0529 03:52:13.928660 142708 solver.cpp:237]     Train net output #0: loss = 0.190918 (* 1 = 0.190918 loss)
I0529 03:52:13.928686 142708 sgd_solver.cpp:105] Iteration 14800, lr = 0.00704
I0529 03:54:14.095736 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:54:22.924134 142708 solver.cpp:218] Iteration 14900 (0.775238 iter/s, 128.993s/100 iters), loss = 0.170224
I0529 03:54:22.924230 142708 solver.cpp:237]     Train net output #0: loss = 0.170224 (* 1 = 0.170224 loss)
I0529 03:54:22.924242 142708 sgd_solver.cpp:105] Iteration 14900, lr = 0.00702
I0529 03:56:30.693239 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_15000.caffemodel
I0529 03:56:31.197155 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_15000.solverstate
I0529 03:56:31.254632 142708 solver.cpp:330] Iteration 15000, Testing net (#0)
I0529 03:56:45.987181 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:57:18.188935 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:57:50.400542 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:57:57.349081 142708 blocking_queue.cpp:49] Waiting for data
I0529 03:58:22.576387 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:58:54.750196 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 03:59:19.715574 142708 solver.cpp:397]     Test net output #0: accuracy = 0.915982
I0529 03:59:19.715662 142708 solver.cpp:397]     Test net output #1: loss = 0.310384 (* 1 = 0.310384 loss)
I0529 03:59:21.003942 142708 solver.cpp:218] Iteration 15000 (0.335488 iter/s, 298.073s/100 iters), loss = 0.137454
I0529 03:59:21.004024 142708 solver.cpp:237]     Train net output #0: loss = 0.137454 (* 1 = 0.137454 loss)
I0529 03:59:21.004037 142708 sgd_solver.cpp:105] Iteration 15000, lr = 0.007
I0529 04:01:29.948539 142708 solver.cpp:218] Iteration 15100 (0.775545 iter/s, 128.942s/100 iters), loss = 0.079039
I0529 04:01:29.948747 142708 solver.cpp:237]     Train net output #0: loss = 0.0790391 (* 1 = 0.0790391 loss)
I0529 04:01:29.948786 142708 sgd_solver.cpp:105] Iteration 15100, lr = 0.00698
I0529 04:03:38.906875 142708 solver.cpp:218] Iteration 15200 (0.775462 iter/s, 128.955s/100 iters), loss = 0.159134
I0529 04:03:38.907049 142708 solver.cpp:237]     Train net output #0: loss = 0.159134 (* 1 = 0.159134 loss)
I0529 04:03:38.907070 142708 sgd_solver.cpp:105] Iteration 15200, lr = 0.00696
I0529 04:05:15.885021 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:05:47.919095 142708 solver.cpp:218] Iteration 15300 (0.775138 iter/s, 129.009s/100 iters), loss = 0.0878099
I0529 04:05:47.919371 142708 solver.cpp:237]     Train net output #0: loss = 0.08781 (* 1 = 0.08781 loss)
I0529 04:05:47.919386 142708 sgd_solver.cpp:105] Iteration 15300, lr = 0.00694
I0529 04:07:56.997956 142708 solver.cpp:218] Iteration 15400 (0.774739 iter/s, 129.076s/100 iters), loss = 0.110216
I0529 04:07:56.998277 142708 solver.cpp:237]     Train net output #0: loss = 0.110216 (* 1 = 0.110216 loss)
I0529 04:07:56.998312 142708 sgd_solver.cpp:105] Iteration 15400, lr = 0.00692
I0529 04:10:06.033895 142708 solver.cpp:218] Iteration 15500 (0.774996 iter/s, 129.033s/100 iters), loss = 0.122144
I0529 04:10:06.034180 142708 solver.cpp:237]     Train net output #0: loss = 0.122144 (* 1 = 0.122144 loss)
I0529 04:10:06.034202 142708 sgd_solver.cpp:105] Iteration 15500, lr = 0.0069
I0529 04:12:15.017769 142708 solver.cpp:218] Iteration 15600 (0.775309 iter/s, 128.981s/100 iters), loss = 0.159002
I0529 04:12:15.017918 142708 solver.cpp:237]     Train net output #0: loss = 0.159002 (* 1 = 0.159002 loss)
I0529 04:12:15.017932 142708 sgd_solver.cpp:105] Iteration 15600, lr = 0.00688
I0529 04:13:28.777894 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:14:24.060921 142708 solver.cpp:218] Iteration 15700 (0.774952 iter/s, 129.04s/100 iters), loss = 0.132237
I0529 04:14:24.061242 142708 solver.cpp:237]     Train net output #0: loss = 0.132238 (* 1 = 0.132238 loss)
I0529 04:14:24.061269 142708 sgd_solver.cpp:105] Iteration 15700, lr = 0.00686
I0529 04:16:32.965553 142708 solver.cpp:218] Iteration 15800 (0.775786 iter/s, 128.902s/100 iters), loss = 0.0705041
I0529 04:16:32.965729 142708 solver.cpp:237]     Train net output #0: loss = 0.0705042 (* 1 = 0.0705042 loss)
I0529 04:16:32.965744 142708 sgd_solver.cpp:105] Iteration 15800, lr = 0.00684
I0529 04:18:41.946768 142708 solver.cpp:218] Iteration 15900 (0.775325 iter/s, 128.978s/100 iters), loss = 0.0951978
I0529 04:18:41.947013 142708 solver.cpp:237]     Train net output #0: loss = 0.095198 (* 1 = 0.095198 loss)
I0529 04:18:41.947036 142708 sgd_solver.cpp:105] Iteration 15900, lr = 0.00682
I0529 04:20:49.656448 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_16000.caffemodel
I0529 04:20:50.085655 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_16000.solverstate
I0529 04:20:50.155675 142708 solver.cpp:330] Iteration 16000, Testing net (#0)
I0529 04:20:57.112885 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:21:29.439462 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:22:01.608297 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:22:23.702378 142708 blocking_queue.cpp:49] Waiting for data
I0529 04:22:33.757786 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:23:05.919013 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:23:38.076417 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:23:38.462668 142708 solver.cpp:397]     Test net output #0: accuracy = 0.896321
I0529 04:23:38.462766 142708 solver.cpp:397]     Test net output #1: loss = 0.569179 (* 1 = 0.569179 loss)
I0529 04:23:39.749372 142708 solver.cpp:218] Iteration 16000 (0.3358 iter/s, 297.796s/100 iters), loss = 0.0606036
I0529 04:23:39.749456 142708 solver.cpp:237]     Train net output #0: loss = 0.0606038 (* 1 = 0.0606038 loss)
I0529 04:23:39.749472 142708 sgd_solver.cpp:105] Iteration 16000, lr = 0.0068
I0529 04:24:30.226013 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:25:48.651886 142708 solver.cpp:218] Iteration 16100 (0.775798 iter/s, 128.9s/100 iters), loss = 0.126854
I0529 04:25:48.652474 142708 solver.cpp:237]     Train net output #0: loss = 0.126854 (* 1 = 0.126854 loss)
I0529 04:25:48.652493 142708 sgd_solver.cpp:105] Iteration 16100, lr = 0.00678
I0529 04:27:57.608239 142708 solver.cpp:218] Iteration 16200 (0.775477 iter/s, 128.953s/100 iters), loss = 0.116196
I0529 04:27:57.608450 142708 solver.cpp:237]     Train net output #0: loss = 0.116197 (* 1 = 0.116197 loss)
I0529 04:27:57.608476 142708 sgd_solver.cpp:105] Iteration 16200, lr = 0.00676
I0529 04:30:06.698886 142708 solver.cpp:218] Iteration 16300 (0.774667 iter/s, 129.088s/100 iters), loss = 0.0980255
I0529 04:30:06.699074 142708 solver.cpp:237]     Train net output #0: loss = 0.0980258 (* 1 = 0.0980258 loss)
I0529 04:30:06.699096 142708 sgd_solver.cpp:105] Iteration 16300, lr = 0.00674
I0529 04:32:15.647392 142708 solver.cpp:218] Iteration 16400 (0.775521 iter/s, 128.946s/100 iters), loss = 0.242298
I0529 04:32:15.647657 142708 solver.cpp:237]     Train net output #0: loss = 0.242298 (* 1 = 0.242298 loss)
I0529 04:32:15.647689 142708 sgd_solver.cpp:105] Iteration 16400, lr = 0.00672
I0529 04:32:42.956424 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:34:24.771433 142708 solver.cpp:218] Iteration 16500 (0.774467 iter/s, 129.121s/100 iters), loss = 0.116703
I0529 04:34:24.771639 142708 solver.cpp:237]     Train net output #0: loss = 0.116704 (* 1 = 0.116704 loss)
I0529 04:34:24.771664 142708 sgd_solver.cpp:105] Iteration 16500, lr = 0.0067
I0529 04:36:33.844303 142708 solver.cpp:218] Iteration 16600 (0.774774 iter/s, 129.07s/100 iters), loss = 0.148071
I0529 04:36:33.844502 142708 solver.cpp:237]     Train net output #0: loss = 0.148072 (* 1 = 0.148072 loss)
I0529 04:36:33.844549 142708 sgd_solver.cpp:105] Iteration 16600, lr = 0.00668
I0529 04:38:42.901834 142708 solver.cpp:218] Iteration 16700 (0.774866 iter/s, 129.055s/100 iters), loss = 0.150232
I0529 04:38:42.902007 142708 solver.cpp:237]     Train net output #0: loss = 0.150232 (* 1 = 0.150232 loss)
I0529 04:38:42.902065 142708 sgd_solver.cpp:105] Iteration 16700, lr = 0.00666
I0529 04:40:51.975260 142708 solver.cpp:218] Iteration 16800 (0.77477 iter/s, 129.071s/100 iters), loss = 0.141476
I0529 04:40:51.975473 142708 solver.cpp:237]     Train net output #0: loss = 0.141476 (* 1 = 0.141476 loss)
I0529 04:40:51.975500 142708 sgd_solver.cpp:105] Iteration 16800, lr = 0.00664
I0529 04:40:56.068902 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:43:00.967838 142708 solver.cpp:218] Iteration 16900 (0.775256 iter/s, 128.99s/100 iters), loss = 0.0974911
I0529 04:43:00.968065 142708 solver.cpp:237]     Train net output #0: loss = 0.0974913 (* 1 = 0.0974913 loss)
I0529 04:43:00.968096 142708 sgd_solver.cpp:105] Iteration 16900, lr = 0.00662
I0529 04:45:08.680317 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_17000.caffemodel
I0529 04:45:09.046578 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_17000.solverstate
I0529 04:45:09.106493 142708 solver.cpp:330] Iteration 17000, Testing net (#0)
I0529 04:45:40.179355 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:46:11.946627 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:46:44.306687 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:47:16.506726 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:47:48.688153 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:47:55.953333 142708 blocking_queue.cpp:49] Waiting for data
I0529 04:47:56.625347 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904982
I0529 04:47:56.625406 142708 solver.cpp:397]     Test net output #1: loss = 0.376454 (* 1 = 0.376454 loss)
I0529 04:47:57.913092 142708 solver.cpp:218] Iteration 17000 (0.33677 iter/s, 296.939s/100 iters), loss = 0.0895145
I0529 04:47:57.913178 142708 solver.cpp:237]     Train net output #0: loss = 0.0895147 (* 1 = 0.0895147 loss)
I0529 04:47:57.913198 142708 sgd_solver.cpp:105] Iteration 17000, lr = 0.0066
I0529 04:50:06.853688 142708 solver.cpp:218] Iteration 17100 (0.775568 iter/s, 128.938s/100 iters), loss = 0.155203
I0529 04:50:06.853936 142708 solver.cpp:237]     Train net output #0: loss = 0.155204 (* 1 = 0.155204 loss)
I0529 04:50:06.853952 142708 sgd_solver.cpp:105] Iteration 17100, lr = 0.00658
I0529 04:51:56.745321 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 04:52:15.874352 142708 solver.cpp:218] Iteration 17200 (0.775087 iter/s, 129.018s/100 iters), loss = 0.0728268
I0529 04:52:15.874445 142708 solver.cpp:237]     Train net output #0: loss = 0.072827 (* 1 = 0.072827 loss)
I0529 04:52:15.874460 142708 sgd_solver.cpp:105] Iteration 17200, lr = 0.00656
I0529 04:54:24.811192 142708 solver.cpp:218] Iteration 17300 (0.77559 iter/s, 128.934s/100 iters), loss = 0.190661
I0529 04:54:24.811399 142708 solver.cpp:237]     Train net output #0: loss = 0.190662 (* 1 = 0.190662 loss)
I0529 04:54:24.811431 142708 sgd_solver.cpp:105] Iteration 17300, lr = 0.00654
I0529 04:56:33.833151 142708 solver.cpp:218] Iteration 17400 (0.775079 iter/s, 129.019s/100 iters), loss = 0.119379
I0529 04:56:33.833365 142708 solver.cpp:237]     Train net output #0: loss = 0.119379 (* 1 = 0.119379 loss)
I0529 04:56:33.833410 142708 sgd_solver.cpp:105] Iteration 17400, lr = 0.00652
I0529 04:58:42.848419 142708 solver.cpp:218] Iteration 17500 (0.775119 iter/s, 129.012s/100 iters), loss = 0.124479
I0529 04:58:42.848613 142708 solver.cpp:237]     Train net output #0: loss = 0.124479 (* 1 = 0.124479 loss)
I0529 04:58:42.848640 142708 sgd_solver.cpp:105] Iteration 17500, lr = 0.0065
I0529 05:00:09.517236 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:00:51.885483 142708 solver.cpp:218] Iteration 17600 (0.774989 iter/s, 129.034s/100 iters), loss = 0.133596
I0529 05:00:51.885689 142708 solver.cpp:237]     Train net output #0: loss = 0.133596 (* 1 = 0.133596 loss)
I0529 05:00:51.885718 142708 sgd_solver.cpp:105] Iteration 17600, lr = 0.00648
I0529 05:03:00.810446 142708 solver.cpp:218] Iteration 17700 (0.775663 iter/s, 128.922s/100 iters), loss = 0.181167
I0529 05:03:00.810655 142708 solver.cpp:237]     Train net output #0: loss = 0.181167 (* 1 = 0.181167 loss)
I0529 05:03:00.810672 142708 sgd_solver.cpp:105] Iteration 17700, lr = 0.00646
I0529 05:05:09.743181 142708 solver.cpp:218] Iteration 17800 (0.775616 iter/s, 128.93s/100 iters), loss = 0.0846348
I0529 05:05:09.743412 142708 solver.cpp:237]     Train net output #0: loss = 0.084635 (* 1 = 0.084635 loss)
I0529 05:05:09.743429 142708 sgd_solver.cpp:105] Iteration 17800, lr = 0.00644
I0529 05:07:18.780704 142708 solver.cpp:218] Iteration 17900 (0.774986 iter/s, 129.035s/100 iters), loss = 0.107224
I0529 05:07:18.780922 142708 solver.cpp:237]     Train net output #0: loss = 0.107224 (* 1 = 0.107224 loss)
I0529 05:07:18.780936 142708 sgd_solver.cpp:105] Iteration 17900, lr = 0.00642
I0529 05:08:22.223331 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:09:26.465361 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_18000.caffemodel
I0529 05:09:26.973649 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_18000.solverstate
I0529 05:09:27.032250 142708 solver.cpp:330] Iteration 18000, Testing net (#0)
I0529 05:09:50.595723 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:10:22.307633 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:10:54.714541 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:11:26.846998 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:11:58.989758 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:12:14.517743 142708 solver.cpp:397]     Test net output #0: accuracy = 0.893681
I0529 05:12:14.517829 142708 solver.cpp:397]     Test net output #1: loss = 0.299599 (* 1 = 0.299599 loss)
I0529 05:12:15.802412 142708 solver.cpp:218] Iteration 18000 (0.336683 iter/s, 297.015s/100 iters), loss = 0.0540015
I0529 05:12:15.802505 142708 solver.cpp:237]     Train net output #0: loss = 0.0540017 (* 1 = 0.0540017 loss)
I0529 05:12:15.802518 142708 sgd_solver.cpp:105] Iteration 18000, lr = 0.0064
I0529 05:14:24.701398 142708 solver.cpp:218] Iteration 18100 (0.775819 iter/s, 128.896s/100 iters), loss = 0.140046
I0529 05:14:24.701650 142708 solver.cpp:237]     Train net output #0: loss = 0.140046 (* 1 = 0.140046 loss)
I0529 05:14:24.701685 142708 sgd_solver.cpp:105] Iteration 18100, lr = 0.00638
I0529 05:16:33.525128 142708 solver.cpp:218] Iteration 18200 (0.776273 iter/s, 128.821s/100 iters), loss = 0.0812666
I0529 05:16:33.525478 142708 solver.cpp:237]     Train net output #0: loss = 0.0812669 (* 1 = 0.0812669 loss)
I0529 05:16:33.525504 142708 sgd_solver.cpp:105] Iteration 18200, lr = 0.00636
I0529 05:18:42.489248 142708 solver.cpp:218] Iteration 18300 (0.775428 iter/s, 128.961s/100 iters), loss = 0.0929167
I0529 05:18:42.489563 142708 solver.cpp:237]     Train net output #0: loss = 0.092917 (* 1 = 0.092917 loss)
I0529 05:18:42.489579 142708 sgd_solver.cpp:105] Iteration 18300, lr = 0.00634
I0529 05:19:22.688874 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:20:51.552335 142708 solver.cpp:218] Iteration 18400 (0.774833 iter/s, 129.06s/100 iters), loss = 0.0430929
I0529 05:20:51.552470 142708 solver.cpp:237]     Train net output #0: loss = 0.0430932 (* 1 = 0.0430932 loss)
I0529 05:20:51.552487 142708 sgd_solver.cpp:105] Iteration 18400, lr = 0.00632
I0529 05:23:00.429191 142708 solver.cpp:218] Iteration 18500 (0.775952 iter/s, 128.874s/100 iters), loss = 0.0705474
I0529 05:23:00.429401 142708 solver.cpp:237]     Train net output #0: loss = 0.0705477 (* 1 = 0.0705477 loss)
I0529 05:23:00.429417 142708 sgd_solver.cpp:105] Iteration 18500, lr = 0.0063
I0529 05:25:09.318388 142708 solver.cpp:218] Iteration 18600 (0.775878 iter/s, 128.886s/100 iters), loss = 0.0523245
I0529 05:25:09.318542 142708 solver.cpp:237]     Train net output #0: loss = 0.0523248 (* 1 = 0.0523248 loss)
I0529 05:25:09.318557 142708 sgd_solver.cpp:105] Iteration 18600, lr = 0.00628
I0529 05:27:18.282811 142708 solver.cpp:218] Iteration 18700 (0.775425 iter/s, 128.962s/100 iters), loss = 0.067048
I0529 05:27:18.283063 142708 solver.cpp:237]     Train net output #0: loss = 0.0670483 (* 1 = 0.0670483 loss)
I0529 05:27:18.283082 142708 sgd_solver.cpp:105] Iteration 18700, lr = 0.00626
I0529 05:27:35.276846 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:29:27.306358 142708 solver.cpp:218] Iteration 18800 (0.77507 iter/s, 129.021s/100 iters), loss = 0.0440277
I0529 05:29:27.306542 142708 solver.cpp:237]     Train net output #0: loss = 0.0440279 (* 1 = 0.0440279 loss)
I0529 05:29:27.306555 142708 sgd_solver.cpp:105] Iteration 18800, lr = 0.00624
I0529 05:31:36.317312 142708 solver.cpp:218] Iteration 18900 (0.775145 iter/s, 129.008s/100 iters), loss = 0.111965
I0529 05:31:36.317508 142708 solver.cpp:237]     Train net output #0: loss = 0.111965 (* 1 = 0.111965 loss)
I0529 05:31:36.317536 142708 sgd_solver.cpp:105] Iteration 18900, lr = 0.00622
I0529 05:33:44.008878 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_19000.caffemodel
I0529 05:33:44.385282 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_19000.solverstate
I0529 05:33:44.443295 142708 solver.cpp:330] Iteration 19000, Testing net (#0)
I0529 05:34:01.055001 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:34:33.182224 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:34:45.010352 142708 blocking_queue.cpp:49] Waiting for data
I0529 05:35:05.356132 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:35:37.525961 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:36:09.701123 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:36:32.802825 142708 solver.cpp:397]     Test net output #0: accuracy = 0.912382
I0529 05:36:32.802917 142708 solver.cpp:397]     Test net output #1: loss = 0.332885 (* 1 = 0.332885 loss)
I0529 05:36:34.089128 142708 solver.cpp:218] Iteration 19000 (0.335835 iter/s, 297.765s/100 iters), loss = 0.0897501
I0529 05:36:34.089216 142708 solver.cpp:237]     Train net output #0: loss = 0.0897504 (* 1 = 0.0897504 loss)
I0529 05:36:34.089234 142708 sgd_solver.cpp:105] Iteration 19000, lr = 0.0062
I0529 05:38:35.436825 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:38:42.915309 142708 solver.cpp:218] Iteration 19100 (0.776258 iter/s, 128.823s/100 iters), loss = 0.121294
I0529 05:38:42.915385 142708 solver.cpp:237]     Train net output #0: loss = 0.121294 (* 1 = 0.121294 loss)
I0529 05:38:42.915400 142708 sgd_solver.cpp:105] Iteration 19100, lr = 0.00618
I0529 05:40:51.828881 142708 solver.cpp:218] Iteration 19200 (0.775731 iter/s, 128.911s/100 iters), loss = 0.106989
I0529 05:40:51.829079 142708 solver.cpp:237]     Train net output #0: loss = 0.10699 (* 1 = 0.10699 loss)
I0529 05:40:51.829105 142708 sgd_solver.cpp:105] Iteration 19200, lr = 0.00616
I0529 05:43:00.784982 142708 solver.cpp:218] Iteration 19300 (0.775476 iter/s, 128.953s/100 iters), loss = 0.120079
I0529 05:43:00.785311 142708 solver.cpp:237]     Train net output #0: loss = 0.120079 (* 1 = 0.120079 loss)
I0529 05:43:00.785342 142708 sgd_solver.cpp:105] Iteration 19300, lr = 0.00614
I0529 05:45:09.727931 142708 solver.cpp:218] Iteration 19400 (0.775556 iter/s, 128.94s/100 iters), loss = 0.106829
I0529 05:45:09.728241 142708 solver.cpp:237]     Train net output #0: loss = 0.106829 (* 1 = 0.106829 loss)
I0529 05:45:09.728279 142708 sgd_solver.cpp:105] Iteration 19400, lr = 0.00612
I0529 05:46:48.041640 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:47:18.727489 142708 solver.cpp:218] Iteration 19500 (0.775215 iter/s, 128.996s/100 iters), loss = 0.119265
I0529 05:47:18.727756 142708 solver.cpp:237]     Train net output #0: loss = 0.119265 (* 1 = 0.119265 loss)
I0529 05:47:18.727769 142708 sgd_solver.cpp:105] Iteration 19500, lr = 0.0061
I0529 05:49:27.728857 142708 solver.cpp:218] Iteration 19600 (0.775204 iter/s, 128.998s/100 iters), loss = 0.0602094
I0529 05:49:27.729065 142708 solver.cpp:237]     Train net output #0: loss = 0.0602097 (* 1 = 0.0602097 loss)
I0529 05:49:27.729115 142708 sgd_solver.cpp:105] Iteration 19600, lr = 0.00608
I0529 05:51:36.773128 142708 solver.cpp:218] Iteration 19700 (0.774945 iter/s, 129.041s/100 iters), loss = 0.0861936
I0529 05:51:36.773316 142708 solver.cpp:237]     Train net output #0: loss = 0.0861939 (* 1 = 0.0861939 loss)
I0529 05:51:36.773340 142708 sgd_solver.cpp:105] Iteration 19700, lr = 0.00606
I0529 05:53:45.782220 142708 solver.cpp:218] Iteration 19800 (0.775157 iter/s, 129.006s/100 iters), loss = 0.0643141
I0529 05:53:45.782410 142708 solver.cpp:237]     Train net output #0: loss = 0.0643144 (* 1 = 0.0643144 loss)
I0529 05:53:45.782433 142708 sgd_solver.cpp:105] Iteration 19800, lr = 0.00604
I0529 05:55:00.824260 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:55:54.724803 142708 solver.cpp:218] Iteration 19900 (0.775556 iter/s, 128.94s/100 iters), loss = 0.0793045
I0529 05:55:54.725033 142708 solver.cpp:237]     Train net output #0: loss = 0.0793048 (* 1 = 0.0793048 loss)
I0529 05:55:54.725059 142708 sgd_solver.cpp:105] Iteration 19900, lr = 0.00602
I0529 05:58:02.299860 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_20000.caffemodel
I0529 05:58:02.812907 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_20000.solverstate
I0529 05:58:02.875401 142708 solver.cpp:330] Iteration 20000, Testing net (#0)
I0529 05:58:11.481276 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:58:43.242890 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:59:14.965622 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 05:59:46.707948 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:00:19.093184 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:00:49.793234 142708 solver.cpp:397]     Test net output #0: accuracy = 0.896642
I0529 06:00:49.793432 142708 solver.cpp:397]     Test net output #1: loss = 0.40036 (* 1 = 0.40036 loss)
I0529 06:00:51.083494 142708 solver.cpp:218] Iteration 20000 (0.337436 iter/s, 296.352s/100 iters), loss = 0.137608
I0529 06:00:51.083575 142708 solver.cpp:237]     Train net output #0: loss = 0.137608 (* 1 = 0.137608 loss)
I0529 06:00:51.083591 142708 sgd_solver.cpp:105] Iteration 20000, lr = 0.006
I0529 06:02:59.920986 142708 solver.cpp:218] Iteration 20100 (0.776189 iter/s, 128.835s/100 iters), loss = 0.146579
I0529 06:02:59.921212 142708 solver.cpp:237]     Train net output #0: loss = 0.146579 (* 1 = 0.146579 loss)
I0529 06:02:59.921243 142708 sgd_solver.cpp:105] Iteration 20100, lr = 0.00598
I0529 06:05:08.927942 142708 solver.cpp:218] Iteration 20200 (0.775169 iter/s, 129.004s/100 iters), loss = 0.0721298
I0529 06:05:08.928189 142708 solver.cpp:237]     Train net output #0: loss = 0.0721301 (* 1 = 0.0721301 loss)
I0529 06:05:08.928241 142708 sgd_solver.cpp:105] Iteration 20200, lr = 0.00596
I0529 06:06:00.817075 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:07:17.858433 142708 solver.cpp:218] Iteration 20300 (0.77563 iter/s, 128.928s/100 iters), loss = 0.0905706
I0529 06:07:17.858737 142708 solver.cpp:237]     Train net output #0: loss = 0.0905709 (* 1 = 0.0905709 loss)
I0529 06:07:17.858768 142708 sgd_solver.cpp:105] Iteration 20300, lr = 0.00594
I0529 06:09:26.724864 142708 solver.cpp:218] Iteration 20400 (0.776015 iter/s, 128.864s/100 iters), loss = 0.0798361
I0529 06:09:26.725090 142708 solver.cpp:237]     Train net output #0: loss = 0.0798364 (* 1 = 0.0798364 loss)
I0529 06:09:26.725111 142708 sgd_solver.cpp:105] Iteration 20400, lr = 0.00592
I0529 06:11:35.554237 142708 solver.cpp:218] Iteration 20500 (0.776238 iter/s, 128.827s/100 iters), loss = 0.078208
I0529 06:11:35.554472 142708 solver.cpp:237]     Train net output #0: loss = 0.0782083 (* 1 = 0.0782083 loss)
I0529 06:11:35.554499 142708 sgd_solver.cpp:105] Iteration 20500, lr = 0.0059
I0529 06:13:44.496243 142708 solver.cpp:218] Iteration 20600 (0.77556 iter/s, 128.939s/100 iters), loss = 0.0372145
I0529 06:13:44.496515 142708 solver.cpp:237]     Train net output #0: loss = 0.0372148 (* 1 = 0.0372148 loss)
I0529 06:13:44.496531 142708 sgd_solver.cpp:105] Iteration 20600, lr = 0.00588
I0529 06:14:13.163035 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:15:53.456085 142708 solver.cpp:218] Iteration 20700 (0.775453 iter/s, 128.957s/100 iters), loss = 0.0787221
I0529 06:15:53.456251 142708 solver.cpp:237]     Train net output #0: loss = 0.0787225 (* 1 = 0.0787225 loss)
I0529 06:15:53.456285 142708 sgd_solver.cpp:105] Iteration 20700, lr = 0.00586
I0529 06:18:02.466769 142708 solver.cpp:218] Iteration 20800 (0.775147 iter/s, 129.008s/100 iters), loss = 0.150846
I0529 06:18:02.466996 142708 solver.cpp:237]     Train net output #0: loss = 0.150846 (* 1 = 0.150846 loss)
I0529 06:18:02.467036 142708 sgd_solver.cpp:105] Iteration 20800, lr = 0.00584
I0529 06:20:11.423012 142708 solver.cpp:218] Iteration 20900 (0.775474 iter/s, 128.953s/100 iters), loss = 0.0666896
I0529 06:20:11.423235 142708 solver.cpp:237]     Train net output #0: loss = 0.06669 (* 1 = 0.06669 loss)
I0529 06:20:11.423250 142708 sgd_solver.cpp:105] Iteration 20900, lr = 0.00582
I0529 06:22:19.103695 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_21000.caffemodel
I0529 06:22:19.606180 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_21000.solverstate
I0529 06:22:19.664443 142708 solver.cpp:330] Iteration 21000, Testing net (#0)
I0529 06:22:20.802556 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:22:52.557479 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:23:24.307126 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:23:56.061760 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:24:27.831557 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:24:59.591336 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:25:05.935961 142708 solver.cpp:397]     Test net output #0: accuracy = 0.906722
I0529 06:25:05.936058 142708 solver.cpp:397]     Test net output #1: loss = 0.442263 (* 1 = 0.442263 loss)
I0529 06:25:07.220455 142708 solver.cpp:218] Iteration 21000 (0.338076 iter/s, 295.791s/100 iters), loss = 0.0722702
I0529 06:25:07.220567 142708 solver.cpp:237]     Train net output #0: loss = 0.0722706 (* 1 = 0.0722706 loss)
I0529 06:25:07.220587 142708 sgd_solver.cpp:105] Iteration 21000, lr = 0.0058
I0529 06:25:12.613922 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:27:16.277173 142708 solver.cpp:218] Iteration 21100 (0.77487 iter/s, 129.054s/100 iters), loss = 0.102036
I0529 06:27:16.277369 142708 solver.cpp:237]     Train net output #0: loss = 0.102036 (* 1 = 0.102036 loss)
I0529 06:27:16.277382 142708 sgd_solver.cpp:105] Iteration 21100, lr = 0.00578
I0529 06:29:25.338814 142708 solver.cpp:218] Iteration 21200 (0.774841 iter/s, 129.059s/100 iters), loss = 0.0629702
I0529 06:29:25.339074 142708 solver.cpp:237]     Train net output #0: loss = 0.0629705 (* 1 = 0.0629705 loss)
I0529 06:29:25.339095 142708 sgd_solver.cpp:105] Iteration 21200, lr = 0.00576
I0529 06:31:34.244915 142708 solver.cpp:218] Iteration 21300 (0.775776 iter/s, 128.903s/100 iters), loss = 0.0995936
I0529 06:31:34.245124 142708 solver.cpp:237]     Train net output #0: loss = 0.099594 (* 1 = 0.099594 loss)
I0529 06:31:34.245139 142708 sgd_solver.cpp:105] Iteration 21300, lr = 0.00574
I0529 06:33:25.247447 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:33:43.092046 142708 solver.cpp:218] Iteration 21400 (0.776132 iter/s, 128.844s/100 iters), loss = 0.092803
I0529 06:33:43.092167 142708 solver.cpp:237]     Train net output #0: loss = 0.0928034 (* 1 = 0.0928034 loss)
I0529 06:33:43.092195 142708 sgd_solver.cpp:105] Iteration 21400, lr = 0.00572
I0529 06:35:52.087839 142708 solver.cpp:218] Iteration 21500 (0.775236 iter/s, 128.993s/100 iters), loss = 0.0659745
I0529 06:35:52.088037 142708 solver.cpp:237]     Train net output #0: loss = 0.0659749 (* 1 = 0.0659749 loss)
I0529 06:35:52.088085 142708 sgd_solver.cpp:105] Iteration 21500, lr = 0.0057
I0529 06:38:01.039100 142708 solver.cpp:218] Iteration 21600 (0.775505 iter/s, 128.948s/100 iters), loss = 0.084801
I0529 06:38:01.039326 142708 solver.cpp:237]     Train net output #0: loss = 0.0848014 (* 1 = 0.0848014 loss)
I0529 06:38:01.039377 142708 sgd_solver.cpp:105] Iteration 21600, lr = 0.00568
I0529 06:40:09.908890 142708 solver.cpp:218] Iteration 21700 (0.775995 iter/s, 128.867s/100 iters), loss = 0.14177
I0529 06:40:09.909108 142708 solver.cpp:237]     Train net output #0: loss = 0.141771 (* 1 = 0.141771 loss)
I0529 06:40:09.909122 142708 sgd_solver.cpp:105] Iteration 21700, lr = 0.00566
I0529 06:41:37.853464 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:42:18.890766 142708 solver.cpp:218] Iteration 21800 (0.775321 iter/s, 128.979s/100 iters), loss = 0.0360946
I0529 06:42:18.890964 142708 solver.cpp:237]     Train net output #0: loss = 0.036095 (* 1 = 0.036095 loss)
I0529 06:42:18.890990 142708 sgd_solver.cpp:105] Iteration 21800, lr = 0.00564
I0529 06:44:27.857498 142708 solver.cpp:218] Iteration 21900 (0.775411 iter/s, 128.964s/100 iters), loss = 0.0658784
I0529 06:44:27.857677 142708 solver.cpp:237]     Train net output #0: loss = 0.0658787 (* 1 = 0.0658787 loss)
I0529 06:44:27.857760 142708 sgd_solver.cpp:105] Iteration 21900, lr = 0.00562
I0529 06:46:35.497833 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_22000.caffemodel
I0529 06:46:35.852021 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_22000.solverstate
I0529 06:46:35.921913 142708 solver.cpp:330] Iteration 22000, Testing net (#0)
I0529 06:47:01.358361 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:47:10.431661 142708 blocking_queue.cpp:49] Waiting for data
I0529 06:47:33.832864 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:48:06.015312 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:48:38.194979 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:49:10.370054 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:49:24.054769 142708 solver.cpp:397]     Test net output #0: accuracy = 0.899782
I0529 06:49:24.054867 142708 solver.cpp:397]     Test net output #1: loss = 0.578392 (* 1 = 0.578392 loss)
I0529 06:49:25.345312 142708 solver.cpp:218] Iteration 22000 (0.336155 iter/s, 297.481s/100 iters), loss = 0.0318483
I0529 06:49:25.345407 142708 solver.cpp:237]     Train net output #0: loss = 0.0318487 (* 1 = 0.0318487 loss)
I0529 06:49:25.345448 142708 sgd_solver.cpp:105] Iteration 22000, lr = 0.0056
I0529 06:51:34.387751 142708 solver.cpp:218] Iteration 22100 (0.774956 iter/s, 129.04s/100 iters), loss = 0.0450565
I0529 06:51:34.387962 142708 solver.cpp:237]     Train net output #0: loss = 0.0450568 (* 1 = 0.0450568 loss)
I0529 06:51:34.387989 142708 sgd_solver.cpp:105] Iteration 22100, lr = 0.00558
I0529 06:52:39.158478 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 06:53:43.375135 142708 solver.cpp:218] Iteration 22200 (0.775288 iter/s, 128.984s/100 iters), loss = 0.0821639
I0529 06:53:43.375324 142708 solver.cpp:237]     Train net output #0: loss = 0.0821643 (* 1 = 0.0821643 loss)
I0529 06:53:43.375342 142708 sgd_solver.cpp:105] Iteration 22200, lr = 0.00556
I0529 06:55:52.423399 142708 solver.cpp:218] Iteration 22300 (0.774922 iter/s, 129.045s/100 iters), loss = 0.0584229
I0529 06:55:52.423590 142708 solver.cpp:237]     Train net output #0: loss = 0.0584232 (* 1 = 0.0584232 loss)
I0529 06:55:52.423605 142708 sgd_solver.cpp:105] Iteration 22300, lr = 0.00554
I0529 06:58:01.345461 142708 solver.cpp:218] Iteration 22400 (0.77568 iter/s, 128.919s/100 iters), loss = 0.120478
I0529 06:58:01.345613 142708 solver.cpp:237]     Train net output #0: loss = 0.120479 (* 1 = 0.120479 loss)
I0529 06:58:01.345629 142708 sgd_solver.cpp:105] Iteration 22400, lr = 0.00552
I0529 07:00:10.320366 142708 solver.cpp:218] Iteration 22500 (0.775362 iter/s, 128.972s/100 iters), loss = 0.054086
I0529 07:00:10.320562 142708 solver.cpp:237]     Train net output #0: loss = 0.0540864 (* 1 = 0.0540864 loss)
I0529 07:00:10.320585 142708 sgd_solver.cpp:105] Iteration 22500, lr = 0.0055
I0529 07:00:51.881908 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:02:19.369086 142708 solver.cpp:218] Iteration 22600 (0.774919 iter/s, 129.046s/100 iters), loss = 0.059886
I0529 07:02:19.369387 142708 solver.cpp:237]     Train net output #0: loss = 0.0598864 (* 1 = 0.0598864 loss)
I0529 07:02:19.369416 142708 sgd_solver.cpp:105] Iteration 22600, lr = 0.00548
I0529 07:04:28.242374 142708 solver.cpp:218] Iteration 22700 (0.775974 iter/s, 128.87s/100 iters), loss = 0.142375
I0529 07:04:28.242601 142708 solver.cpp:237]     Train net output #0: loss = 0.142375 (* 1 = 0.142375 loss)
I0529 07:04:28.242617 142708 sgd_solver.cpp:105] Iteration 22700, lr = 0.00546
I0529 07:06:37.185688 142708 solver.cpp:218] Iteration 22800 (0.775552 iter/s, 128.94s/100 iters), loss = 0.0662839
I0529 07:06:37.185902 142708 solver.cpp:237]     Train net output #0: loss = 0.0662843 (* 1 = 0.0662843 loss)
I0529 07:06:37.185956 142708 sgd_solver.cpp:105] Iteration 22800, lr = 0.00544
I0529 07:08:46.234482 142708 solver.cpp:218] Iteration 22900 (0.774918 iter/s, 129.046s/100 iters), loss = 0.0318491
I0529 07:08:46.234748 142708 solver.cpp:237]     Train net output #0: loss = 0.0318495 (* 1 = 0.0318495 loss)
I0529 07:08:46.234786 142708 sgd_solver.cpp:105] Iteration 22900, lr = 0.00542
I0529 07:09:04.506671 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:10:53.816618 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_23000.caffemodel
I0529 07:10:54.331331 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_23000.solverstate
I0529 07:10:54.388372 142708 solver.cpp:330] Iteration 23000, Testing net (#0)
I0529 07:11:12.322540 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:11:44.582926 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:12:04.825815 142708 blocking_queue.cpp:49] Waiting for data
I0529 07:12:16.737278 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:12:48.917372 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:13:21.087858 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:13:42.338032 142708 solver.cpp:397]     Test net output #0: accuracy = 0.894381
I0529 07:13:42.338132 142708 solver.cpp:397]     Test net output #1: loss = 0.457179 (* 1 = 0.457179 loss)
I0529 07:13:43.624706 142708 solver.cpp:218] Iteration 23000 (0.336266 iter/s, 297.384s/100 iters), loss = 0.0951516
I0529 07:13:43.624780 142708 solver.cpp:237]     Train net output #0: loss = 0.095152 (* 1 = 0.095152 loss)
I0529 07:13:43.624809 142708 sgd_solver.cpp:105] Iteration 23000, lr = 0.0054
I0529 07:15:52.518751 142708 solver.cpp:218] Iteration 23100 (0.775849 iter/s, 128.891s/100 iters), loss = 0.0822332
I0529 07:15:52.519021 142708 solver.cpp:237]     Train net output #0: loss = 0.0822335 (* 1 = 0.0822335 loss)
I0529 07:15:52.519052 142708 sgd_solver.cpp:105] Iteration 23100, lr = 0.00538
I0529 07:18:01.487501 142708 solver.cpp:218] Iteration 23200 (0.7754 iter/s, 128.966s/100 iters), loss = 0.069255
I0529 07:18:01.487709 142708 solver.cpp:237]     Train net output #0: loss = 0.0692554 (* 1 = 0.0692554 loss)
I0529 07:18:01.487740 142708 sgd_solver.cpp:105] Iteration 23200, lr = 0.00536
I0529 07:20:05.473702 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:20:10.429764 142708 solver.cpp:218] Iteration 23300 (0.775559 iter/s, 128.939s/100 iters), loss = 0.0743386
I0529 07:20:10.429841 142708 solver.cpp:237]     Train net output #0: loss = 0.074339 (* 1 = 0.074339 loss)
I0529 07:20:10.429857 142708 sgd_solver.cpp:105] Iteration 23300, lr = 0.00534
I0529 07:22:19.455286 142708 solver.cpp:218] Iteration 23400 (0.775058 iter/s, 129.023s/100 iters), loss = 0.0753365
I0529 07:22:19.455492 142708 solver.cpp:237]     Train net output #0: loss = 0.0753369 (* 1 = 0.0753369 loss)
I0529 07:22:19.455507 142708 sgd_solver.cpp:105] Iteration 23400, lr = 0.00532
I0529 07:24:28.429262 142708 solver.cpp:218] Iteration 23500 (0.775368 iter/s, 128.971s/100 iters), loss = 0.135661
I0529 07:24:28.429555 142708 solver.cpp:237]     Train net output #0: loss = 0.135661 (* 1 = 0.135661 loss)
I0529 07:24:28.429589 142708 sgd_solver.cpp:105] Iteration 23500, lr = 0.0053
I0529 07:26:37.364442 142708 solver.cpp:218] Iteration 23600 (0.775602 iter/s, 128.932s/100 iters), loss = 0.022082
I0529 07:26:37.364655 142708 solver.cpp:237]     Train net output #0: loss = 0.0220824 (* 1 = 0.0220824 loss)
I0529 07:26:37.364686 142708 sgd_solver.cpp:105] Iteration 23600, lr = 0.00528
I0529 07:28:18.200116 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:28:46.309901 142708 solver.cpp:218] Iteration 23700 (0.775539 iter/s, 128.943s/100 iters), loss = 0.0716241
I0529 07:28:46.309993 142708 solver.cpp:237]     Train net output #0: loss = 0.0716244 (* 1 = 0.0716244 loss)
I0529 07:28:46.310024 142708 sgd_solver.cpp:105] Iteration 23700, lr = 0.00526
I0529 07:30:55.289247 142708 solver.cpp:218] Iteration 23800 (0.775335 iter/s, 128.977s/100 iters), loss = 0.0417973
I0529 07:30:55.289443 142708 solver.cpp:237]     Train net output #0: loss = 0.0417977 (* 1 = 0.0417977 loss)
I0529 07:30:55.289458 142708 sgd_solver.cpp:105] Iteration 23800, lr = 0.00524
I0529 07:33:04.312197 142708 solver.cpp:218] Iteration 23900 (0.775073 iter/s, 129.02s/100 iters), loss = 0.089055
I0529 07:33:04.312422 142708 solver.cpp:237]     Train net output #0: loss = 0.0890553 (* 1 = 0.0890553 loss)
I0529 07:33:04.312453 142708 sgd_solver.cpp:105] Iteration 23900, lr = 0.00522
I0529 07:35:11.925441 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_24000.caffemodel
I0529 07:35:12.439133 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_24000.solverstate
I0529 07:35:12.499442 142708 solver.cpp:330] Iteration 24000, Testing net (#0)
I0529 07:35:23.128486 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:35:55.377606 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:36:27.582883 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:36:40.771661 142708 blocking_queue.cpp:49] Waiting for data
I0529 07:36:59.785063 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:37:31.983676 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:38:00.825387 142708 solver.cpp:397]     Test net output #0: accuracy = 0.870982
I0529 07:38:00.825470 142708 solver.cpp:397]     Test net output #1: loss = 0.440047 (* 1 = 0.440047 loss)
I0529 07:38:02.111932 142708 solver.cpp:218] Iteration 24000 (0.335803 iter/s, 297.793s/100 iters), loss = 0.0259263
I0529 07:38:02.112200 142708 solver.cpp:237]     Train net output #0: loss = 0.0259266 (* 1 = 0.0259266 loss)
I0529 07:38:02.112236 142708 sgd_solver.cpp:105] Iteration 24000, lr = 0.0052
I0529 07:39:19.704207 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:40:11.068161 142708 solver.cpp:218] Iteration 24100 (0.775475 iter/s, 128.953s/100 iters), loss = 0.120275
I0529 07:40:11.068368 142708 solver.cpp:237]     Train net output #0: loss = 0.120275 (* 1 = 0.120275 loss)
I0529 07:40:11.068403 142708 sgd_solver.cpp:105] Iteration 24100, lr = 0.00518
I0529 07:42:20.168962 142708 solver.cpp:218] Iteration 24200 (0.774606 iter/s, 129.098s/100 iters), loss = 0.0895068
I0529 07:42:20.169179 142708 solver.cpp:237]     Train net output #0: loss = 0.0895071 (* 1 = 0.0895071 loss)
I0529 07:42:20.169193 142708 sgd_solver.cpp:105] Iteration 24200, lr = 0.00516
I0529 07:44:29.160120 142708 solver.cpp:218] Iteration 24300 (0.775264 iter/s, 128.988s/100 iters), loss = 0.0709226
I0529 07:44:29.160370 142708 solver.cpp:237]     Train net output #0: loss = 0.0709229 (* 1 = 0.0709229 loss)
I0529 07:44:29.160388 142708 sgd_solver.cpp:105] Iteration 24300, lr = 0.00514
I0529 07:46:38.181262 142708 solver.cpp:218] Iteration 24400 (0.775084 iter/s, 129.018s/100 iters), loss = 0.0852041
I0529 07:46:38.181484 142708 solver.cpp:237]     Train net output #0: loss = 0.0852044 (* 1 = 0.0852044 loss)
I0529 07:46:38.181496 142708 sgd_solver.cpp:105] Iteration 24400, lr = 0.00512
I0529 07:47:32.606896 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:48:47.231528 142708 solver.cpp:218] Iteration 24500 (0.774909 iter/s, 129.047s/100 iters), loss = 0.034271
I0529 07:48:47.231736 142708 solver.cpp:237]     Train net output #0: loss = 0.0342713 (* 1 = 0.0342713 loss)
I0529 07:48:47.231752 142708 sgd_solver.cpp:105] Iteration 24500, lr = 0.0051
I0529 07:50:56.339881 142708 solver.cpp:218] Iteration 24600 (0.774561 iter/s, 129.105s/100 iters), loss = 0.0352223
I0529 07:50:56.340108 142708 solver.cpp:237]     Train net output #0: loss = 0.0352226 (* 1 = 0.0352226 loss)
I0529 07:50:56.340122 142708 sgd_solver.cpp:105] Iteration 24600, lr = 0.00508
I0529 07:53:05.334466 142708 solver.cpp:218] Iteration 24700 (0.775244 iter/s, 128.992s/100 iters), loss = 0.049613
I0529 07:53:05.334630 142708 solver.cpp:237]     Train net output #0: loss = 0.0496134 (* 1 = 0.0496134 loss)
I0529 07:53:05.334645 142708 sgd_solver.cpp:105] Iteration 24700, lr = 0.00506
I0529 07:55:14.316834 142708 solver.cpp:218] Iteration 24800 (0.775317 iter/s, 128.98s/100 iters), loss = 0.0770494
I0529 07:55:14.317057 142708 solver.cpp:237]     Train net output #0: loss = 0.0770497 (* 1 = 0.0770497 loss)
I0529 07:55:14.317075 142708 sgd_solver.cpp:105] Iteration 24800, lr = 0.00504
I0529 07:55:45.546874 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 07:57:23.456511 142708 solver.cpp:218] Iteration 24900 (0.774373 iter/s, 129.137s/100 iters), loss = 0.0854089
I0529 07:57:23.456745 142708 solver.cpp:237]     Train net output #0: loss = 0.0854092 (* 1 = 0.0854092 loss)
I0529 07:57:23.456760 142708 sgd_solver.cpp:105] Iteration 24900, lr = 0.00502
I0529 07:59:31.250180 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_25000.caffemodel
I0529 07:59:31.635107 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_25000.solverstate
I0529 07:59:31.692157 142708 solver.cpp:330] Iteration 25000, Testing net (#0)
I0529 07:59:34.969261 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:00:07.197567 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:00:39.353749 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:01:03.380899 142708 blocking_queue.cpp:49] Waiting for data
I0529 08:01:11.608927 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:01:43.800668 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:02:15.993027 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:02:20.240511 142708 solver.cpp:397]     Test net output #0: accuracy = 0.901502
I0529 08:02:20.240587 142708 solver.cpp:397]     Test net output #1: loss = 0.428208 (* 1 = 0.428208 loss)
I0529 08:02:21.528156 142708 solver.cpp:218] Iteration 25000 (0.335497 iter/s, 298.065s/100 iters), loss = 0.117694
I0529 08:02:21.528239 142708 solver.cpp:237]     Train net output #0: loss = 0.117694 (* 1 = 0.117694 loss)
I0529 08:02:21.528255 142708 sgd_solver.cpp:105] Iteration 25000, lr = 0.005
I0529 08:04:30.539487 142708 solver.cpp:218] Iteration 25100 (0.775142 iter/s, 129.009s/100 iters), loss = 0.0438923
I0529 08:04:30.539687 142708 solver.cpp:237]     Train net output #0: loss = 0.0438927 (* 1 = 0.0438927 loss)
I0529 08:04:30.539711 142708 sgd_solver.cpp:105] Iteration 25100, lr = 0.00498
I0529 08:06:39.601752 142708 solver.cpp:218] Iteration 25200 (0.774837 iter/s, 129.059s/100 iters), loss = 0.0660028
I0529 08:06:39.601958 142708 solver.cpp:237]     Train net output #0: loss = 0.0660031 (* 1 = 0.0660031 loss)
I0529 08:06:39.601974 142708 sgd_solver.cpp:105] Iteration 25200, lr = 0.00496
I0529 08:06:47.570369 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:08:48.599107 142708 solver.cpp:218] Iteration 25300 (0.775227 iter/s, 128.995s/100 iters), loss = 0.0820521
I0529 08:08:48.599310 142708 solver.cpp:237]     Train net output #0: loss = 0.0820524 (* 1 = 0.0820524 loss)
I0529 08:08:48.599355 142708 sgd_solver.cpp:105] Iteration 25300, lr = 0.00494
I0529 08:10:57.585655 142708 solver.cpp:218] Iteration 25400 (0.775292 iter/s, 128.984s/100 iters), loss = 0.0524323
I0529 08:10:57.585883 142708 solver.cpp:237]     Train net output #0: loss = 0.0524326 (* 1 = 0.0524326 loss)
I0529 08:10:57.585925 142708 sgd_solver.cpp:105] Iteration 25400, lr = 0.00492
I0529 08:13:06.464387 142708 solver.cpp:218] Iteration 25500 (0.77594 iter/s, 128.876s/100 iters), loss = 0.0624639
I0529 08:13:06.464542 142708 solver.cpp:237]     Train net output #0: loss = 0.0624643 (* 1 = 0.0624643 loss)
I0529 08:13:06.464558 142708 sgd_solver.cpp:105] Iteration 25500, lr = 0.0049
I0529 08:15:00.119535 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:15:15.387467 142708 solver.cpp:218] Iteration 25600 (0.775673 iter/s, 128.92s/100 iters), loss = 0.0365306
I0529 08:15:15.387547 142708 solver.cpp:237]     Train net output #0: loss = 0.036531 (* 1 = 0.036531 loss)
I0529 08:15:15.387558 142708 sgd_solver.cpp:105] Iteration 25600, lr = 0.00488
I0529 08:17:24.388195 142708 solver.cpp:218] Iteration 25700 (0.775206 iter/s, 128.998s/100 iters), loss = 0.0564497
I0529 08:17:24.388427 142708 solver.cpp:237]     Train net output #0: loss = 0.05645 (* 1 = 0.05645 loss)
I0529 08:17:24.388461 142708 sgd_solver.cpp:105] Iteration 25700, lr = 0.00486
I0529 08:19:33.412226 142708 solver.cpp:218] Iteration 25800 (0.775067 iter/s, 129.021s/100 iters), loss = 0.0561768
I0529 08:19:33.412436 142708 solver.cpp:237]     Train net output #0: loss = 0.0561772 (* 1 = 0.0561772 loss)
I0529 08:19:33.412447 142708 sgd_solver.cpp:105] Iteration 25800, lr = 0.00484
I0529 08:21:42.397291 142708 solver.cpp:218] Iteration 25900 (0.775301 iter/s, 128.982s/100 iters), loss = 0.0385721
I0529 08:21:42.397505 142708 solver.cpp:237]     Train net output #0: loss = 0.0385725 (* 1 = 0.0385725 loss)
I0529 08:21:42.397519 142708 sgd_solver.cpp:105] Iteration 25900, lr = 0.00482
I0529 08:23:12.974962 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:23:50.107249 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_26000.caffemodel
I0529 08:23:50.531291 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_26000.solverstate
I0529 08:23:50.594758 142708 solver.cpp:330] Iteration 26000, Testing net (#0)
I0529 08:24:18.202198 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:24:50.435160 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:22.649161 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:25:48.155483 142708 blocking_queue.cpp:49] Waiting for data
I0529 08:25:54.867080 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:26:27.077498 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:26:38.910400 142708 solver.cpp:397]     Test net output #0: accuracy = 0.894882
I0529 08:26:38.910509 142708 solver.cpp:397]     Test net output #1: loss = 0.358134 (* 1 = 0.358134 loss)
I0529 08:26:40.202359 142708 solver.cpp:218] Iteration 26000 (0.335797 iter/s, 297.799s/100 iters), loss = 0.0449813
I0529 08:26:40.202446 142708 solver.cpp:237]     Train net output #0: loss = 0.0449817 (* 1 = 0.0449817 loss)
I0529 08:26:40.202463 142708 sgd_solver.cpp:105] Iteration 26000, lr = 0.0048
I0529 08:28:49.080199 142708 solver.cpp:218] Iteration 26100 (0.775945 iter/s, 128.875s/100 iters), loss = 0.0916494
I0529 08:28:49.080410 142708 solver.cpp:237]     Train net output #0: loss = 0.0916497 (* 1 = 0.0916497 loss)
I0529 08:28:49.080435 142708 sgd_solver.cpp:105] Iteration 26100, lr = 0.00478
I0529 08:30:57.967377 142708 solver.cpp:218] Iteration 26200 (0.77589 iter/s, 128.884s/100 iters), loss = 0.0676699
I0529 08:30:57.967620 142708 solver.cpp:237]     Train net output #0: loss = 0.0676702 (* 1 = 0.0676702 loss)
I0529 08:30:57.967636 142708 sgd_solver.cpp:105] Iteration 26200, lr = 0.00476
I0529 08:33:06.850457 142708 solver.cpp:218] Iteration 26300 (0.775915 iter/s, 128.88s/100 iters), loss = 0.0403526
I0529 08:33:06.850651 142708 solver.cpp:237]     Train net output #0: loss = 0.0403529 (* 1 = 0.0403529 loss)
I0529 08:33:06.850675 142708 sgd_solver.cpp:105] Iteration 26300, lr = 0.00474
I0529 08:34:14.081823 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:35:15.702680 142708 solver.cpp:218] Iteration 26400 (0.776101 iter/s, 128.849s/100 iters), loss = 0.0641332
I0529 08:35:15.702846 142708 solver.cpp:237]     Train net output #0: loss = 0.0641335 (* 1 = 0.0641335 loss)
I0529 08:35:15.702858 142708 sgd_solver.cpp:105] Iteration 26400, lr = 0.00472
I0529 08:37:24.692358 142708 solver.cpp:218] Iteration 26500 (0.775274 iter/s, 128.987s/100 iters), loss = 0.0788178
I0529 08:37:24.692572 142708 solver.cpp:237]     Train net output #0: loss = 0.0788181 (* 1 = 0.0788181 loss)
I0529 08:37:24.692616 142708 sgd_solver.cpp:105] Iteration 26500, lr = 0.0047
I0529 08:39:33.683908 142708 solver.cpp:218] Iteration 26600 (0.775263 iter/s, 128.989s/100 iters), loss = 0.0488155
I0529 08:39:33.684654 142708 solver.cpp:237]     Train net output #0: loss = 0.0488158 (* 1 = 0.0488158 loss)
I0529 08:39:33.684670 142708 sgd_solver.cpp:105] Iteration 26600, lr = 0.00468
I0529 08:41:42.704143 142708 solver.cpp:218] Iteration 26700 (0.775093 iter/s, 129.017s/100 iters), loss = 0.0887774
I0529 08:41:42.704375 142708 solver.cpp:237]     Train net output #0: loss = 0.0887777 (* 1 = 0.0887777 loss)
I0529 08:41:42.704391 142708 sgd_solver.cpp:105] Iteration 26700, lr = 0.00466
I0529 08:42:26.779328 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:43:51.677937 142708 solver.cpp:218] Iteration 26800 (0.775369 iter/s, 128.971s/100 iters), loss = 0.103717
I0529 08:43:51.678537 142708 solver.cpp:237]     Train net output #0: loss = 0.103717 (* 1 = 0.103717 loss)
I0529 08:43:51.678550 142708 sgd_solver.cpp:105] Iteration 26800, lr = 0.00464
I0529 08:46:00.760989 142708 solver.cpp:218] Iteration 26900 (0.774715 iter/s, 129.08s/100 iters), loss = 0.0448324
I0529 08:46:00.761169 142708 solver.cpp:237]     Train net output #0: loss = 0.0448327 (* 1 = 0.0448327 loss)
I0529 08:46:00.761194 142708 sgd_solver.cpp:105] Iteration 26900, lr = 0.00462
I0529 08:48:08.592244 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_27000.caffemodel
I0529 08:48:09.089731 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_27000.solverstate
I0529 08:48:09.147296 142708 solver.cpp:330] Iteration 27000, Testing net (#0)
I0529 08:48:29.488324 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:49:01.706104 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:49:33.890516 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:50:06.089802 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:50:07.817028 142708 blocking_queue.cpp:49] Waiting for data
I0529 08:50:38.314568 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:50:57.733577 142708 solver.cpp:397]     Test net output #0: accuracy = 0.902562
I0529 08:50:57.733655 142708 solver.cpp:397]     Test net output #1: loss = 0.562975 (* 1 = 0.562975 loss)
I0529 08:50:59.021996 142708 solver.cpp:218] Iteration 27000 (0.335284 iter/s, 298.255s/100 iters), loss = 0.0888343
I0529 08:50:59.022065 142708 solver.cpp:237]     Train net output #0: loss = 0.0888346 (* 1 = 0.0888346 loss)
I0529 08:50:59.022080 142708 sgd_solver.cpp:105] Iteration 27000, lr = 0.0046
I0529 08:53:08.071030 142708 solver.cpp:218] Iteration 27100 (0.774917 iter/s, 129.046s/100 iters), loss = 0.0468728
I0529 08:53:08.071261 142708 solver.cpp:237]     Train net output #0: loss = 0.0468731 (* 1 = 0.0468731 loss)
I0529 08:53:08.071290 142708 sgd_solver.cpp:105] Iteration 27100, lr = 0.00458
I0529 08:53:28.876749 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 08:55:17.118746 142708 solver.cpp:218] Iteration 27200 (0.774925 iter/s, 129.045s/100 iters), loss = 0.109291
I0529 08:55:17.118952 142708 solver.cpp:237]     Train net output #0: loss = 0.109291 (* 1 = 0.109291 loss)
I0529 08:55:17.118973 142708 sgd_solver.cpp:105] Iteration 27200, lr = 0.00456
I0529 08:57:26.172729 142708 solver.cpp:218] Iteration 27300 (0.774888 iter/s, 129.051s/100 iters), loss = 0.04253
I0529 08:57:26.172924 142708 solver.cpp:237]     Train net output #0: loss = 0.0425303 (* 1 = 0.0425303 loss)
I0529 08:57:26.172937 142708 sgd_solver.cpp:105] Iteration 27300, lr = 0.00454
I0529 08:59:35.199234 142708 solver.cpp:218] Iteration 27400 (0.775053 iter/s, 129.024s/100 iters), loss = 0.128397
I0529 08:59:35.199467 142708 solver.cpp:237]     Train net output #0: loss = 0.128398 (* 1 = 0.128398 loss)
I0529 08:59:35.199482 142708 sgd_solver.cpp:105] Iteration 27400, lr = 0.00452
I0529 09:01:41.917515 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:01:44.238026 142708 solver.cpp:218] Iteration 27500 (0.774979 iter/s, 129.036s/100 iters), loss = 0.072616
I0529 09:01:44.238104 142708 solver.cpp:237]     Train net output #0: loss = 0.0726163 (* 1 = 0.0726163 loss)
I0529 09:01:44.238118 142708 sgd_solver.cpp:105] Iteration 27500, lr = 0.0045
I0529 09:03:53.285086 142708 solver.cpp:218] Iteration 27600 (0.774928 iter/s, 129.044s/100 iters), loss = 0.0615406
I0529 09:03:53.285259 142708 solver.cpp:237]     Train net output #0: loss = 0.0615409 (* 1 = 0.0615409 loss)
I0529 09:03:53.285271 142708 sgd_solver.cpp:105] Iteration 27600, lr = 0.00448
I0529 09:06:02.377523 142708 solver.cpp:218] Iteration 27700 (0.774657 iter/s, 129.089s/100 iters), loss = 0.0513495
I0529 09:06:02.377707 142708 solver.cpp:237]     Train net output #0: loss = 0.0513499 (* 1 = 0.0513499 loss)
I0529 09:06:02.377720 142708 sgd_solver.cpp:105] Iteration 27700, lr = 0.00446
I0529 09:08:11.464130 142708 solver.cpp:218] Iteration 27800 (0.774691 iter/s, 129.084s/100 iters), loss = 0.0088204
I0529 09:08:11.464342 142708 solver.cpp:237]     Train net output #0: loss = 0.00882074 (* 1 = 0.00882074 loss)
I0529 09:08:11.464354 142708 sgd_solver.cpp:105] Iteration 27800, lr = 0.00444
I0529 09:09:54.997272 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:10:20.590745 142708 solver.cpp:218] Iteration 27900 (0.774452 iter/s, 129.124s/100 iters), loss = 0.0200284
I0529 09:10:20.590823 142708 solver.cpp:237]     Train net output #0: loss = 0.0200288 (* 1 = 0.0200288 loss)
I0529 09:10:20.590836 142708 sgd_solver.cpp:105] Iteration 27900, lr = 0.00442
I0529 09:12:28.402627 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_28000.caffemodel
I0529 09:12:28.901254 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_28000.solverstate
I0529 09:12:28.959832 142708 solver.cpp:330] Iteration 28000, Testing net (#0)
I0529 09:12:41.732888 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:13:13.940831 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:13:46.138161 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:14:18.323107 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:14:28.653733 142708 blocking_queue.cpp:49] Waiting for data
I0529 09:14:50.546988 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:15:17.593093 142708 solver.cpp:397]     Test net output #0: accuracy = 0.892521
I0529 09:15:17.593176 142708 solver.cpp:397]     Test net output #1: loss = 0.414749 (* 1 = 0.414749 loss)
I0529 09:15:18.882047 142708 solver.cpp:218] Iteration 28000 (0.33525 iter/s, 298.285s/100 iters), loss = 0.0718223
I0529 09:15:18.882123 142708 solver.cpp:237]     Train net output #0: loss = 0.0718227 (* 1 = 0.0718227 loss)
I0529 09:15:18.882138 142708 sgd_solver.cpp:105] Iteration 28000, lr = 0.0044
I0529 09:17:27.936029 142708 solver.cpp:218] Iteration 28100 (0.774887 iter/s, 129.051s/100 iters), loss = 0.030393
I0529 09:17:27.936244 142708 solver.cpp:237]     Train net output #0: loss = 0.0303933 (* 1 = 0.0303933 loss)
I0529 09:17:27.936259 142708 sgd_solver.cpp:105] Iteration 28100, lr = 0.00438
I0529 09:19:37.093237 142708 solver.cpp:218] Iteration 28200 (0.774268 iter/s, 129.154s/100 iters), loss = 0.0393232
I0529 09:19:37.093382 142708 solver.cpp:237]     Train net output #0: loss = 0.0393235 (* 1 = 0.0393235 loss)
I0529 09:19:37.093396 142708 sgd_solver.cpp:105] Iteration 28200, lr = 0.00436
I0529 09:20:57.367120 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:21:46.195533 142708 solver.cpp:218] Iteration 28300 (0.774597 iter/s, 129.099s/100 iters), loss = 0.0136935
I0529 09:21:46.195727 142708 solver.cpp:237]     Train net output #0: loss = 0.0136938 (* 1 = 0.0136938 loss)
I0529 09:21:46.195745 142708 sgd_solver.cpp:105] Iteration 28300, lr = 0.00434
I0529 09:23:55.257678 142708 solver.cpp:218] Iteration 28400 (0.774838 iter/s, 129.059s/100 iters), loss = 0.105993
I0529 09:23:55.257879 142708 solver.cpp:237]     Train net output #0: loss = 0.105993 (* 1 = 0.105993 loss)
I0529 09:23:55.257902 142708 sgd_solver.cpp:105] Iteration 28400, lr = 0.00432
I0529 09:26:04.249716 142708 solver.cpp:218] Iteration 28500 (0.77526 iter/s, 128.989s/100 iters), loss = 0.0621582
I0529 09:26:04.249899 142708 solver.cpp:237]     Train net output #0: loss = 0.0621585 (* 1 = 0.0621585 loss)
I0529 09:26:04.249925 142708 sgd_solver.cpp:105] Iteration 28500, lr = 0.0043
I0529 09:28:13.364733 142708 solver.cpp:218] Iteration 28600 (0.774521 iter/s, 129.112s/100 iters), loss = 0.0215661
I0529 09:28:13.364931 142708 solver.cpp:237]     Train net output #0: loss = 0.0215664 (* 1 = 0.0215664 loss)
I0529 09:28:13.364945 142708 sgd_solver.cpp:105] Iteration 28600, lr = 0.00428
I0529 09:29:10.429596 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:30:22.522897 142708 solver.cpp:218] Iteration 28700 (0.774262 iter/s, 129.155s/100 iters), loss = 0.0442475
I0529 09:30:22.523082 142708 solver.cpp:237]     Train net output #0: loss = 0.0442477 (* 1 = 0.0442477 loss)
I0529 09:30:22.523097 142708 sgd_solver.cpp:105] Iteration 28700, lr = 0.00426
I0529 09:32:31.710304 142708 solver.cpp:218] Iteration 28800 (0.774087 iter/s, 129.185s/100 iters), loss = 0.090649
I0529 09:32:31.710500 142708 solver.cpp:237]     Train net output #0: loss = 0.0906493 (* 1 = 0.0906493 loss)
I0529 09:32:31.710515 142708 sgd_solver.cpp:105] Iteration 28800, lr = 0.00424
I0529 09:34:40.809459 142708 solver.cpp:218] Iteration 28900 (0.774616 iter/s, 129.096s/100 iters), loss = 0.0251218
I0529 09:34:40.809743 142708 solver.cpp:237]     Train net output #0: loss = 0.0251221 (* 1 = 0.0251221 loss)
I0529 09:34:40.809763 142708 sgd_solver.cpp:105] Iteration 28900, lr = 0.00422
I0529 09:36:48.633384 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_29000.caffemodel
I0529 09:36:48.919080 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_29000.solverstate
I0529 09:36:48.979199 142708 solver.cpp:330] Iteration 29000, Testing net (#0)
I0529 09:36:53.789670 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:37:26.248689 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:37:58.471246 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:38:30.625164 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:39:00.059283 142708 blocking_queue.cpp:49] Waiting for data
I0529 09:39:02.919636 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:39:35.156913 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:39:37.549163 142708 solver.cpp:397]     Test net output #0: accuracy = 0.895782
I0529 09:39:37.549239 142708 solver.cpp:397]     Test net output #1: loss = 0.476153 (* 1 = 0.476153 loss)
I0529 09:39:38.836817 142708 solver.cpp:218] Iteration 29000 (0.335547 iter/s, 298.021s/100 iters), loss = 0.0606886
I0529 09:39:38.836892 142708 solver.cpp:237]     Train net output #0: loss = 0.0606889 (* 1 = 0.0606889 loss)
I0529 09:39:38.836906 142708 sgd_solver.cpp:105] Iteration 29000, lr = 0.0042
I0529 09:40:12.597221 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:41:47.895280 142708 solver.cpp:218] Iteration 29100 (0.77486 iter/s, 129.056s/100 iters), loss = 0.0448661
I0529 09:41:47.895514 142708 solver.cpp:237]     Train net output #0: loss = 0.0448664 (* 1 = 0.0448664 loss)
I0529 09:41:47.895529 142708 sgd_solver.cpp:105] Iteration 29100, lr = 0.00418
I0529 09:43:56.886046 142708 solver.cpp:218] Iteration 29200 (0.775268 iter/s, 128.988s/100 iters), loss = 0.0473385
I0529 09:43:56.886263 142708 solver.cpp:237]     Train net output #0: loss = 0.0473388 (* 1 = 0.0473388 loss)
I0529 09:43:56.886282 142708 sgd_solver.cpp:105] Iteration 29200, lr = 0.00416
I0529 09:46:06.044450 142708 solver.cpp:218] Iteration 29300 (0.774261 iter/s, 129.155s/100 iters), loss = 0.010404
I0529 09:46:06.044651 142708 solver.cpp:237]     Train net output #0: loss = 0.0104043 (* 1 = 0.0104043 loss)
I0529 09:46:06.044678 142708 sgd_solver.cpp:105] Iteration 29300, lr = 0.00414
I0529 09:48:15.195410 142708 solver.cpp:218] Iteration 29400 (0.774306 iter/s, 129.148s/100 iters), loss = 0.0774409
I0529 09:48:15.195600 142708 solver.cpp:237]     Train net output #0: loss = 0.0774412 (* 1 = 0.0774412 loss)
I0529 09:48:15.195626 142708 sgd_solver.cpp:105] Iteration 29400, lr = 0.00412
I0529 09:48:25.697432 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:50:24.318918 142708 solver.cpp:218] Iteration 29500 (0.77447 iter/s, 129.121s/100 iters), loss = 0.045047
I0529 09:50:24.319123 142708 solver.cpp:237]     Train net output #0: loss = 0.0450474 (* 1 = 0.0450474 loss)
I0529 09:50:24.319161 142708 sgd_solver.cpp:105] Iteration 29500, lr = 0.0041
I0529 09:52:33.437238 142708 solver.cpp:218] Iteration 29600 (0.774501 iter/s, 129.115s/100 iters), loss = 0.0334044
I0529 09:52:33.437449 142708 solver.cpp:237]     Train net output #0: loss = 0.0334047 (* 1 = 0.0334047 loss)
I0529 09:52:33.437475 142708 sgd_solver.cpp:105] Iteration 29600, lr = 0.00408
I0529 09:54:42.471601 142708 solver.cpp:218] Iteration 29700 (0.775005 iter/s, 129.031s/100 iters), loss = 0.03027
I0529 09:54:42.471796 142708 solver.cpp:237]     Train net output #0: loss = 0.0302703 (* 1 = 0.0302703 loss)
I0529 09:54:42.471830 142708 sgd_solver.cpp:105] Iteration 29700, lr = 0.00406
I0529 09:56:38.881077 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 09:56:51.578907 142708 solver.cpp:218] Iteration 29800 (0.774567 iter/s, 129.104s/100 iters), loss = 0.0423368
I0529 09:56:51.578984 142708 solver.cpp:237]     Train net output #0: loss = 0.0423372 (* 1 = 0.0423372 loss)
I0529 09:56:51.579010 142708 sgd_solver.cpp:105] Iteration 29800, lr = 0.00404
I0529 09:59:00.601706 142708 solver.cpp:218] Iteration 29900 (0.775074 iter/s, 129.02s/100 iters), loss = 0.02913
I0529 09:59:00.601927 142708 solver.cpp:237]     Train net output #0: loss = 0.0291304 (* 1 = 0.0291304 loss)
I0529 09:59:00.601941 142708 sgd_solver.cpp:105] Iteration 29900, lr = 0.00402
I0529 10:01:08.268668 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_30000.caffemodel
I0529 10:01:08.643065 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_30000.solverstate
I0529 10:01:08.704746 142708 solver.cpp:330] Iteration 30000, Testing net (#0)
I0529 10:01:38.395201 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:02:10.633492 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:02:42.854094 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:03:14.997200 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:03:27.554324 142708 blocking_queue.cpp:49] Waiting for data
I0529 10:03:47.219971 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:03:57.217896 142708 solver.cpp:397]     Test net output #0: accuracy = 0.896462
I0529 10:03:57.217978 142708 solver.cpp:397]     Test net output #1: loss = 0.567887 (* 1 = 0.567887 loss)
I0529 10:03:58.500365 142708 solver.cpp:218] Iteration 30000 (0.335692 iter/s, 297.892s/100 iters), loss = 0.0949566
I0529 10:03:58.500463 142708 solver.cpp:237]     Train net output #0: loss = 0.0949569 (* 1 = 0.0949569 loss)
I0529 10:03:58.500479 142708 sgd_solver.cpp:105] Iteration 30000, lr = 0.004
I0529 10:06:07.571722 142708 solver.cpp:218] Iteration 30100 (0.774783 iter/s, 129.068s/100 iters), loss = 0.0458568
I0529 10:06:07.571948 142708 solver.cpp:237]     Train net output #0: loss = 0.0458572 (* 1 = 0.0458572 loss)
I0529 10:06:07.571962 142708 sgd_solver.cpp:105] Iteration 30100, lr = 0.00398
I0529 10:07:40.785285 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:08:16.696491 142708 solver.cpp:218] Iteration 30200 (0.774463 iter/s, 129.122s/100 iters), loss = 0.0687752
I0529 10:08:16.696702 142708 solver.cpp:237]     Train net output #0: loss = 0.0687756 (* 1 = 0.0687756 loss)
I0529 10:08:16.696717 142708 sgd_solver.cpp:105] Iteration 30200, lr = 0.00396
I0529 10:10:25.772260 142708 solver.cpp:218] Iteration 30300 (0.774757 iter/s, 129.073s/100 iters), loss = 0.0579782
I0529 10:10:25.772480 142708 solver.cpp:237]     Train net output #0: loss = 0.0579786 (* 1 = 0.0579786 loss)
I0529 10:10:25.772517 142708 sgd_solver.cpp:105] Iteration 30300, lr = 0.00394
I0529 10:12:34.833230 142708 solver.cpp:218] Iteration 30400 (0.774845 iter/s, 129.058s/100 iters), loss = 0.0924171
I0529 10:12:34.833439 142708 solver.cpp:237]     Train net output #0: loss = 0.0924175 (* 1 = 0.0924175 loss)
I0529 10:12:34.833464 142708 sgd_solver.cpp:105] Iteration 30400, lr = 0.00392
I0529 10:14:43.794867 142708 solver.cpp:218] Iteration 30500 (0.775442 iter/s, 128.959s/100 iters), loss = 0.0539253
I0529 10:14:43.795198 142708 solver.cpp:237]     Train net output #0: loss = 0.0539257 (* 1 = 0.0539257 loss)
I0529 10:14:43.795229 142708 sgd_solver.cpp:105] Iteration 30500, lr = 0.0039
I0529 10:15:53.779089 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:16:52.932252 142708 solver.cpp:218] Iteration 30600 (0.774388 iter/s, 129.134s/100 iters), loss = 0.0482616
I0529 10:16:52.932518 142708 solver.cpp:237]     Train net output #0: loss = 0.0482621 (* 1 = 0.0482621 loss)
I0529 10:16:52.932538 142708 sgd_solver.cpp:105] Iteration 30600, lr = 0.00388
I0529 10:19:02.013617 142708 solver.cpp:218] Iteration 30700 (0.774723 iter/s, 129.078s/100 iters), loss = 0.10279
I0529 10:19:02.013820 142708 solver.cpp:237]     Train net output #0: loss = 0.10279 (* 1 = 0.10279 loss)
I0529 10:19:02.013835 142708 sgd_solver.cpp:105] Iteration 30700, lr = 0.00386
I0529 10:21:11.108089 142708 solver.cpp:218] Iteration 30800 (0.774644 iter/s, 129.092s/100 iters), loss = 0.0397751
I0529 10:21:11.108297 142708 solver.cpp:237]     Train net output #0: loss = 0.0397755 (* 1 = 0.0397755 loss)
I0529 10:21:11.108314 142708 sgd_solver.cpp:105] Iteration 30800, lr = 0.00384
I0529 10:23:20.098707 142708 solver.cpp:218] Iteration 30900 (0.775268 iter/s, 128.988s/100 iters), loss = 0.0399592
I0529 10:23:20.098893 142708 solver.cpp:237]     Train net output #0: loss = 0.0399596 (* 1 = 0.0399596 loss)
I0529 10:23:20.098918 142708 sgd_solver.cpp:105] Iteration 30900, lr = 0.00382
I0529 10:24:06.766022 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:25:27.831961 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_31000.caffemodel
I0529 10:25:28.126335 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_31000.solverstate
I0529 10:25:28.189656 142708 solver.cpp:330] Iteration 31000, Testing net (#0)
I0529 10:25:49.857506 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:26:22.383008 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:26:54.620079 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:27:26.867810 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:27:59.109458 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:28:09.443668 142708 blocking_queue.cpp:49] Waiting for data
I0529 10:28:16.699499 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904681
I0529 10:28:16.699575 142708 solver.cpp:397]     Test net output #1: loss = 0.436765 (* 1 = 0.436765 loss)
I0529 10:28:17.986176 142708 solver.cpp:218] Iteration 31000 (0.335705 iter/s, 297.881s/100 iters), loss = 0.0424016
I0529 10:28:17.986229 142708 solver.cpp:237]     Train net output #0: loss = 0.042402 (* 1 = 0.042402 loss)
I0529 10:28:17.986243 142708 sgd_solver.cpp:105] Iteration 31000, lr = 0.0038
I0529 10:30:27.086913 142708 solver.cpp:218] Iteration 31100 (0.774606 iter/s, 129.098s/100 iters), loss = 0.0240616
I0529 10:30:27.087075 142708 solver.cpp:237]     Train net output #0: loss = 0.0240621 (* 1 = 0.0240621 loss)
I0529 10:30:27.087088 142708 sgd_solver.cpp:105] Iteration 31100, lr = 0.00378
I0529 10:32:36.205806 142708 solver.cpp:218] Iteration 31200 (0.774497 iter/s, 129.116s/100 iters), loss = 0.0618877
I0529 10:32:36.206051 142708 solver.cpp:237]     Train net output #0: loss = 0.0618881 (* 1 = 0.0618881 loss)
I0529 10:32:36.206069 142708 sgd_solver.cpp:105] Iteration 31200, lr = 0.00376
I0529 10:34:45.336031 142708 solver.cpp:218] Iteration 31300 (0.774429 iter/s, 129.127s/100 iters), loss = 0.0941282
I0529 10:34:45.336213 142708 solver.cpp:237]     Train net output #0: loss = 0.0941286 (* 1 = 0.0941286 loss)
I0529 10:34:45.336246 142708 sgd_solver.cpp:105] Iteration 31300, lr = 0.00374
I0529 10:35:08.801868 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:36:54.595165 142708 solver.cpp:218] Iteration 31400 (0.773657 iter/s, 129.256s/100 iters), loss = 0.0187798
I0529 10:36:54.595379 142708 solver.cpp:237]     Train net output #0: loss = 0.0187802 (* 1 = 0.0187802 loss)
I0529 10:36:54.595393 142708 sgd_solver.cpp:105] Iteration 31400, lr = 0.00372
I0529 10:39:03.693959 142708 solver.cpp:218] Iteration 31500 (0.774617 iter/s, 129.096s/100 iters), loss = 0.0467419
I0529 10:39:03.694154 142708 solver.cpp:237]     Train net output #0: loss = 0.0467423 (* 1 = 0.0467423 loss)
I0529 10:39:03.694166 142708 sgd_solver.cpp:105] Iteration 31500, lr = 0.0037
I0529 10:41:12.867411 142708 solver.cpp:218] Iteration 31600 (0.77417 iter/s, 129.171s/100 iters), loss = 0.0864242
I0529 10:41:12.867565 142708 solver.cpp:237]     Train net output #0: loss = 0.0864246 (* 1 = 0.0864246 loss)
I0529 10:41:12.867588 142708 sgd_solver.cpp:105] Iteration 31600, lr = 0.00368
I0529 10:43:22.029646 142708 solver.cpp:218] Iteration 31700 (0.774237 iter/s, 129.159s/100 iters), loss = 0.120788
I0529 10:43:22.029917 142708 solver.cpp:237]     Train net output #0: loss = 0.120788 (* 1 = 0.120788 loss)
I0529 10:43:22.029940 142708 sgd_solver.cpp:105] Iteration 31700, lr = 0.00366
I0529 10:43:22.251395 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:45:31.203259 142708 solver.cpp:218] Iteration 31800 (0.77417 iter/s, 129.171s/100 iters), loss = 0.0438331
I0529 10:45:31.203492 142708 solver.cpp:237]     Train net output #0: loss = 0.0438335 (* 1 = 0.0438335 loss)
I0529 10:45:31.203514 142708 sgd_solver.cpp:105] Iteration 31800, lr = 0.00364
I0529 10:47:40.355831 142708 solver.cpp:218] Iteration 31900 (0.774296 iter/s, 129.15s/100 iters), loss = 0.0462099
I0529 10:47:40.356052 142708 solver.cpp:237]     Train net output #0: loss = 0.0462103 (* 1 = 0.0462103 loss)
I0529 10:47:40.356068 142708 sgd_solver.cpp:105] Iteration 31900, lr = 0.00362
I0529 10:49:48.201555 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_32000.caffemodel
I0529 10:49:48.495308 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_32000.solverstate
I0529 10:49:48.551245 142708 solver.cpp:330] Iteration 32000, Testing net (#0)
I0529 10:50:02.986373 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:50:35.212843 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:51:07.446339 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:51:39.649658 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:52:11.833222 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:52:36.957159 142708 solver.cpp:397]     Test net output #0: accuracy = 0.906701
I0529 10:52:36.957237 142708 solver.cpp:397]     Test net output #1: loss = 0.544763 (* 1 = 0.544763 loss)
I0529 10:52:38.246323 142708 solver.cpp:218] Iteration 32000 (0.335701 iter/s, 297.884s/100 iters), loss = 0.0122446
I0529 10:52:38.246392 142708 solver.cpp:237]     Train net output #0: loss = 0.012245 (* 1 = 0.012245 loss)
I0529 10:52:38.246407 142708 sgd_solver.cpp:105] Iteration 32000, lr = 0.0036
I0529 10:54:24.360836 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 10:54:47.392099 142708 solver.cpp:218] Iteration 32100 (0.774336 iter/s, 129.143s/100 iters), loss = 0.101562
I0529 10:54:47.392189 142708 solver.cpp:237]     Train net output #0: loss = 0.101562 (* 1 = 0.101562 loss)
I0529 10:54:47.392202 142708 sgd_solver.cpp:105] Iteration 32100, lr = 0.00358
I0529 10:56:56.525620 142708 solver.cpp:218] Iteration 32200 (0.774409 iter/s, 129.131s/100 iters), loss = 0.0526523
I0529 10:56:56.525846 142708 solver.cpp:237]     Train net output #0: loss = 0.0526527 (* 1 = 0.0526527 loss)
I0529 10:56:56.525871 142708 sgd_solver.cpp:105] Iteration 32200, lr = 0.00356
I0529 10:59:05.698987 142708 solver.cpp:218] Iteration 32300 (0.774171 iter/s, 129.17s/100 iters), loss = 0.0454416
I0529 10:59:05.699223 142708 solver.cpp:237]     Train net output #0: loss = 0.045442 (* 1 = 0.045442 loss)
I0529 10:59:05.699236 142708 sgd_solver.cpp:105] Iteration 32300, lr = 0.00354
I0529 11:01:14.895048 142708 solver.cpp:218] Iteration 32400 (0.774035 iter/s, 129.193s/100 iters), loss = 0.0209817
I0529 11:01:14.895233 142708 solver.cpp:237]     Train net output #0: loss = 0.0209821 (* 1 = 0.0209821 loss)
I0529 11:01:14.895261 142708 sgd_solver.cpp:105] Iteration 32400, lr = 0.00352
I0529 11:02:37.830324 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:03:24.116919 142708 solver.cpp:218] Iteration 32500 (0.77388 iter/s, 129.219s/100 iters), loss = 0.0764337
I0529 11:03:24.117312 142708 solver.cpp:237]     Train net output #0: loss = 0.0764341 (* 1 = 0.0764341 loss)
I0529 11:03:24.117331 142708 sgd_solver.cpp:105] Iteration 32500, lr = 0.0035
I0529 11:05:33.366427 142708 solver.cpp:218] Iteration 32600 (0.773716 iter/s, 129.246s/100 iters), loss = 0.0324156
I0529 11:05:33.366690 142708 solver.cpp:237]     Train net output #0: loss = 0.032416 (* 1 = 0.032416 loss)
I0529 11:05:33.366705 142708 sgd_solver.cpp:105] Iteration 32600, lr = 0.00348
I0529 11:07:42.584750 142708 solver.cpp:218] Iteration 32700 (0.773901 iter/s, 129.215s/100 iters), loss = 0.0183732
I0529 11:07:42.584957 142708 solver.cpp:237]     Train net output #0: loss = 0.0183736 (* 1 = 0.0183736 loss)
I0529 11:07:42.584974 142708 sgd_solver.cpp:105] Iteration 32700, lr = 0.00346
I0529 11:09:51.843013 142708 solver.cpp:218] Iteration 32800 (0.773662 iter/s, 129.255s/100 iters), loss = 0.00905398
I0529 11:09:51.843216 142708 solver.cpp:237]     Train net output #0: loss = 0.00905435 (* 1 = 0.00905435 loss)
I0529 11:09:51.843228 142708 sgd_solver.cpp:105] Iteration 32800, lr = 0.00344
I0529 11:10:51.515223 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:12:01.112138 142708 solver.cpp:218] Iteration 32900 (0.773597 iter/s, 129.266s/100 iters), loss = 0.0296992
I0529 11:12:01.112329 142708 solver.cpp:237]     Train net output #0: loss = 0.0296996 (* 1 = 0.0296996 loss)
I0529 11:12:01.112352 142708 sgd_solver.cpp:105] Iteration 32900, lr = 0.00342
I0529 11:14:09.037684 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_33000.caffemodel
I0529 11:14:09.523644 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_33000.solverstate
I0529 11:14:09.581938 142708 solver.cpp:330] Iteration 33000, Testing net (#0)
I0529 11:14:16.228027 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:14:36.657127 142708 blocking_queue.cpp:49] Waiting for data
I0529 11:14:48.616806 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:15:20.863210 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:15:53.103278 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:16:25.334758 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:16:57.570497 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:16:58.123317 142708 solver.cpp:397]     Test net output #0: accuracy = 0.915082
I0529 11:16:58.123387 142708 solver.cpp:397]     Test net output #1: loss = 0.434802 (* 1 = 0.434802 loss)
I0529 11:16:59.415845 142708 solver.cpp:218] Iteration 33000 (0.335236 iter/s, 298.297s/100 iters), loss = 0.101977
I0529 11:16:59.415907 142708 solver.cpp:237]     Train net output #0: loss = 0.101977 (* 1 = 0.101977 loss)
I0529 11:16:59.415921 142708 sgd_solver.cpp:105] Iteration 33000, lr = 0.0034
I0529 11:19:08.567329 142708 solver.cpp:218] Iteration 33100 (0.774301 iter/s, 129.149s/100 iters), loss = 0.0316942
I0529 11:19:08.567551 142708 solver.cpp:237]     Train net output #0: loss = 0.0316946 (* 1 = 0.0316946 loss)
I0529 11:19:08.567579 142708 sgd_solver.cpp:105] Iteration 33100, lr = 0.00338
I0529 11:21:17.621987 142708 solver.cpp:218] Iteration 33200 (0.774883 iter/s, 129.052s/100 iters), loss = 0.0373824
I0529 11:21:17.622237 142708 solver.cpp:237]     Train net output #0: loss = 0.0373827 (* 1 = 0.0373827 loss)
I0529 11:21:17.622251 142708 sgd_solver.cpp:105] Iteration 33200, lr = 0.00336
I0529 11:21:53.952666 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:23:26.655751 142708 solver.cpp:218] Iteration 33300 (0.775008 iter/s, 129.031s/100 iters), loss = 0.0119513
I0529 11:23:26.655973 142708 solver.cpp:237]     Train net output #0: loss = 0.0119516 (* 1 = 0.0119516 loss)
I0529 11:23:26.655990 142708 sgd_solver.cpp:105] Iteration 33300, lr = 0.00334
I0529 11:25:35.725919 142708 solver.cpp:218] Iteration 33400 (0.77479 iter/s, 129.067s/100 iters), loss = 0.0290364
I0529 11:25:35.726151 142708 solver.cpp:237]     Train net output #0: loss = 0.0290367 (* 1 = 0.0290367 loss)
I0529 11:25:35.726171 142708 sgd_solver.cpp:105] Iteration 33400, lr = 0.00332
I0529 11:27:44.845654 142708 solver.cpp:218] Iteration 33500 (0.774492 iter/s, 129.117s/100 iters), loss = 0.0240754
I0529 11:27:44.845836 142708 solver.cpp:237]     Train net output #0: loss = 0.0240757 (* 1 = 0.0240757 loss)
I0529 11:27:44.845862 142708 sgd_solver.cpp:105] Iteration 33500, lr = 0.0033
I0529 11:29:54.058182 142708 solver.cpp:218] Iteration 33600 (0.773936 iter/s, 129.21s/100 iters), loss = 0.0517764
I0529 11:29:54.058449 142708 solver.cpp:237]     Train net output #0: loss = 0.0517767 (* 1 = 0.0517767 loss)
I0529 11:29:54.058464 142708 sgd_solver.cpp:105] Iteration 33600, lr = 0.00328
I0529 11:30:07.216629 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:32:03.227995 142708 solver.cpp:218] Iteration 33700 (0.774193 iter/s, 129.167s/100 iters), loss = 0.0654925
I0529 11:32:03.228185 142708 solver.cpp:237]     Train net output #0: loss = 0.0654928 (* 1 = 0.0654928 loss)
I0529 11:32:03.228209 142708 sgd_solver.cpp:105] Iteration 33700, lr = 0.00326
I0529 11:34:12.365613 142708 solver.cpp:218] Iteration 33800 (0.774386 iter/s, 129.135s/100 iters), loss = 0.0667668
I0529 11:34:12.365770 142708 solver.cpp:237]     Train net output #0: loss = 0.0667671 (* 1 = 0.0667671 loss)
I0529 11:34:12.365794 142708 sgd_solver.cpp:105] Iteration 33800, lr = 0.00324
I0529 11:36:21.562677 142708 solver.cpp:218] Iteration 33900 (0.774029 iter/s, 129.194s/100 iters), loss = 0.101212
I0529 11:36:21.562858 142708 solver.cpp:237]     Train net output #0: loss = 0.101213 (* 1 = 0.101213 loss)
I0529 11:36:21.562885 142708 sgd_solver.cpp:105] Iteration 33900, lr = 0.00322
I0529 11:38:20.619935 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:38:29.446240 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_34000.caffemodel
I0529 11:38:29.605983 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_34000.solverstate
I0529 11:38:29.667639 142708 solver.cpp:330] Iteration 34000, Testing net (#0)
I0529 11:38:57.835326 142708 blocking_queue.cpp:49] Waiting for data
I0529 11:39:01.346454 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:39:33.575089 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:40:05.807867 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:40:38.029114 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:41:10.249052 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:41:18.376346 142708 solver.cpp:397]     Test net output #0: accuracy = 0.909061
I0529 11:41:18.376427 142708 solver.cpp:397]     Test net output #1: loss = 0.474443 (* 1 = 0.474443 loss)
I0529 11:41:19.666785 142708 solver.cpp:218] Iteration 34000 (0.33546 iter/s, 298.098s/100 iters), loss = 0.0712211
I0529 11:41:19.666854 142708 solver.cpp:237]     Train net output #0: loss = 0.0712215 (* 1 = 0.0712215 loss)
I0529 11:41:19.666869 142708 sgd_solver.cpp:105] Iteration 34000, lr = 0.0032
I0529 11:43:28.754009 142708 solver.cpp:218] Iteration 34100 (0.774685 iter/s, 129.085s/100 iters), loss = 0.0645012
I0529 11:43:28.754223 142708 solver.cpp:237]     Train net output #0: loss = 0.0645015 (* 1 = 0.0645015 loss)
I0529 11:43:28.754267 142708 sgd_solver.cpp:105] Iteration 34100, lr = 0.00318
I0529 11:45:37.732734 142708 solver.cpp:218] Iteration 34200 (0.775339 iter/s, 128.976s/100 iters), loss = 0.0133656
I0529 11:45:37.732985 142708 solver.cpp:237]     Train net output #0: loss = 0.0133659 (* 1 = 0.0133659 loss)
I0529 11:45:37.733000 142708 sgd_solver.cpp:105] Iteration 34200, lr = 0.00316
I0529 11:47:46.816087 142708 solver.cpp:218] Iteration 34300 (0.774711 iter/s, 129.08s/100 iters), loss = 0.0761401
I0529 11:47:46.816298 142708 solver.cpp:237]     Train net output #0: loss = 0.0761405 (* 1 = 0.0761405 loss)
I0529 11:47:46.816316 142708 sgd_solver.cpp:105] Iteration 34300, lr = 0.00314
I0529 11:49:22.605491 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:49:55.952764 142708 solver.cpp:218] Iteration 34400 (0.774391 iter/s, 129.134s/100 iters), loss = 0.0358135
I0529 11:49:55.952962 142708 solver.cpp:237]     Train net output #0: loss = 0.0358139 (* 1 = 0.0358139 loss)
I0529 11:49:55.952980 142708 sgd_solver.cpp:105] Iteration 34400, lr = 0.00312
I0529 11:52:04.994180 142708 solver.cpp:218] Iteration 34500 (0.774962 iter/s, 129.039s/100 iters), loss = 0.0890296
I0529 11:52:04.994529 142708 solver.cpp:237]     Train net output #0: loss = 0.0890299 (* 1 = 0.0890299 loss)
I0529 11:52:04.994566 142708 sgd_solver.cpp:105] Iteration 34500, lr = 0.0031
I0529 11:54:14.015712 142708 solver.cpp:218] Iteration 34600 (0.775082 iter/s, 129.019s/100 iters), loss = 0.0111703
I0529 11:54:14.015883 142708 solver.cpp:237]     Train net output #0: loss = 0.0111707 (* 1 = 0.0111707 loss)
I0529 11:54:14.015899 142708 sgd_solver.cpp:105] Iteration 34600, lr = 0.00308
I0529 11:56:23.199235 142708 solver.cpp:218] Iteration 34700 (0.77411 iter/s, 129.181s/100 iters), loss = 0.0126529
I0529 11:56:23.199430 142708 solver.cpp:237]     Train net output #0: loss = 0.0126533 (* 1 = 0.0126533 loss)
I0529 11:56:23.199447 142708 sgd_solver.cpp:105] Iteration 34700, lr = 0.00306
I0529 11:57:35.759534 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 11:58:32.406294 142708 solver.cpp:218] Iteration 34800 (0.77397 iter/s, 129.204s/100 iters), loss = 0.123341
I0529 11:58:32.406491 142708 solver.cpp:237]     Train net output #0: loss = 0.123341 (* 1 = 0.123341 loss)
I0529 11:58:32.406513 142708 sgd_solver.cpp:105] Iteration 34800, lr = 0.00304
I0529 12:00:41.601258 142708 solver.cpp:218] Iteration 34900 (0.774042 iter/s, 129.192s/100 iters), loss = 0.0597508
I0529 12:00:41.601464 142708 solver.cpp:237]     Train net output #0: loss = 0.0597511 (* 1 = 0.0597511 loss)
I0529 12:00:41.601476 142708 sgd_solver.cpp:105] Iteration 34900, lr = 0.00302
I0529 12:02:49.379598 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_35000.caffemodel
I0529 12:02:49.898474 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_35000.solverstate
I0529 12:02:49.956246 142708 solver.cpp:330] Iteration 35000, Testing net (#0)
I0529 12:03:13.987512 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:03:21.451822 142708 blocking_queue.cpp:49] Waiting for data
I0529 12:03:46.202069 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:04:18.376514 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:04:50.613587 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:05:22.820922 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:05:38.536079 142708 solver.cpp:397]     Test net output #0: accuracy = 0.913602
I0529 12:05:38.536150 142708 solver.cpp:397]     Test net output #1: loss = 0.563789 (* 1 = 0.563789 loss)
I0529 12:05:39.823671 142708 solver.cpp:218] Iteration 35000 (0.335328 iter/s, 298.215s/100 iters), loss = 0.00918506
I0529 12:05:39.823772 142708 solver.cpp:237]     Train net output #0: loss = 0.00918541 (* 1 = 0.00918541 loss)
I0529 12:05:39.823796 142708 sgd_solver.cpp:105] Iteration 35000, lr = 0.003
I0529 12:07:48.780045 142708 solver.cpp:218] Iteration 35100 (0.775474 iter/s, 128.953s/100 iters), loss = 0.0245245
I0529 12:07:48.780253 142708 solver.cpp:237]     Train net output #0: loss = 0.0245249 (* 1 = 0.0245249 loss)
I0529 12:07:48.780293 142708 sgd_solver.cpp:105] Iteration 35100, lr = 0.00298
I0529 12:08:38.060114 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:09:57.849423 142708 solver.cpp:218] Iteration 35200 (0.774795 iter/s, 129.066s/100 iters), loss = 0.0616878
I0529 12:09:57.849623 142708 solver.cpp:237]     Train net output #0: loss = 0.0616881 (* 1 = 0.0616881 loss)
I0529 12:09:57.849647 142708 sgd_solver.cpp:105] Iteration 35200, lr = 0.00296
I0529 12:12:06.929020 142708 solver.cpp:218] Iteration 35300 (0.774734 iter/s, 129.077s/100 iters), loss = 0.0377483
I0529 12:12:06.929221 142708 solver.cpp:237]     Train net output #0: loss = 0.0377487 (* 1 = 0.0377487 loss)
I0529 12:12:06.929236 142708 sgd_solver.cpp:105] Iteration 35300, lr = 0.00294
I0529 12:14:15.953094 142708 solver.cpp:218] Iteration 35400 (0.775067 iter/s, 129.021s/100 iters), loss = 0.0856339
I0529 12:14:15.953352 142708 solver.cpp:237]     Train net output #0: loss = 0.0856343 (* 1 = 0.0856343 loss)
I0529 12:14:15.953374 142708 sgd_solver.cpp:105] Iteration 35400, lr = 0.00292
I0529 12:16:24.913013 142708 solver.cpp:218] Iteration 35500 (0.775453 iter/s, 128.957s/100 iters), loss = 0.0124105
I0529 12:16:24.913355 142708 solver.cpp:237]     Train net output #0: loss = 0.0124108 (* 1 = 0.0124108 loss)
I0529 12:16:24.913367 142708 sgd_solver.cpp:105] Iteration 35500, lr = 0.0029
I0529 12:16:50.875061 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:18:33.975275 142708 solver.cpp:218] Iteration 35600 (0.774838 iter/s, 129.059s/100 iters), loss = 0.0475689
I0529 12:18:33.975436 142708 solver.cpp:237]     Train net output #0: loss = 0.0475693 (* 1 = 0.0475693 loss)
I0529 12:18:33.975452 142708 sgd_solver.cpp:105] Iteration 35600, lr = 0.00288
I0529 12:20:42.979094 142708 solver.cpp:218] Iteration 35700 (0.775188 iter/s, 129.001s/100 iters), loss = 0.0957026
I0529 12:20:42.979287 142708 solver.cpp:237]     Train net output #0: loss = 0.095703 (* 1 = 0.095703 loss)
I0529 12:20:42.979328 142708 sgd_solver.cpp:105] Iteration 35700, lr = 0.00286
I0529 12:22:51.998203 142708 solver.cpp:218] Iteration 35800 (0.775096 iter/s, 129.016s/100 iters), loss = 0.0372771
I0529 12:22:51.998436 142708 solver.cpp:237]     Train net output #0: loss = 0.0372775 (* 1 = 0.0372775 loss)
I0529 12:22:51.998461 142708 sgd_solver.cpp:105] Iteration 35800, lr = 0.00284
I0529 12:25:01.187831 142708 solver.cpp:218] Iteration 35900 (0.774073 iter/s, 129.187s/100 iters), loss = 0.0161755
I0529 12:25:01.188057 142708 solver.cpp:237]     Train net output #0: loss = 0.0161759 (* 1 = 0.0161759 loss)
I0529 12:25:01.188096 142708 sgd_solver.cpp:105] Iteration 35900, lr = 0.00282
I0529 12:25:03.983436 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:27:08.971959 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_36000.caffemodel
I0529 12:27:09.271880 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_36000.solverstate
I0529 12:27:09.334100 142708 solver.cpp:330] Iteration 36000, Testing net (#0)
I0529 12:27:25.439801 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:27:57.678508 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:28:06.999965 142708 blocking_queue.cpp:49] Waiting for data
I0529 12:28:29.897300 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:29:02.118016 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:29:34.295562 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:29:57.572171 142708 solver.cpp:397]     Test net output #0: accuracy = 0.904642
I0529 12:29:57.572259 142708 solver.cpp:397]     Test net output #1: loss = 0.47065 (* 1 = 0.47065 loss)
I0529 12:29:58.857064 142708 solver.cpp:218] Iteration 36000 (0.335951 iter/s, 297.663s/100 iters), loss = 0.0454063
I0529 12:29:58.857122 142708 solver.cpp:237]     Train net output #0: loss = 0.0454067 (* 1 = 0.0454067 loss)
I0529 12:29:58.857146 142708 sgd_solver.cpp:105] Iteration 36000, lr = 0.0028
I0529 12:32:07.750313 142708 solver.cpp:218] Iteration 36100 (0.775853 iter/s, 128.89s/100 iters), loss = 0.0632639
I0529 12:32:07.750535 142708 solver.cpp:237]     Train net output #0: loss = 0.0632643 (* 1 = 0.0632643 loss)
I0529 12:32:07.750571 142708 sgd_solver.cpp:105] Iteration 36100, lr = 0.00278
I0529 12:34:16.660871 142708 solver.cpp:218] Iteration 36200 (0.775749 iter/s, 128.908s/100 iters), loss = 0.0575083
I0529 12:34:16.661109 142708 solver.cpp:237]     Train net output #0: loss = 0.0575087 (* 1 = 0.0575087 loss)
I0529 12:34:16.661134 142708 sgd_solver.cpp:105] Iteration 36200, lr = 0.00276
I0529 12:36:05.170547 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:36:25.606698 142708 solver.cpp:218] Iteration 36300 (0.775537 iter/s, 128.943s/100 iters), loss = 0.0238673
I0529 12:36:25.606776 142708 solver.cpp:237]     Train net output #0: loss = 0.0238677 (* 1 = 0.0238677 loss)
I0529 12:36:25.606791 142708 sgd_solver.cpp:105] Iteration 36300, lr = 0.00274
I0529 12:38:34.556485 142708 solver.cpp:218] Iteration 36400 (0.775512 iter/s, 128.947s/100 iters), loss = 0.0662497
I0529 12:38:34.556802 142708 solver.cpp:237]     Train net output #0: loss = 0.0662501 (* 1 = 0.0662501 loss)
I0529 12:38:34.556823 142708 sgd_solver.cpp:105] Iteration 36400, lr = 0.00272
I0529 12:40:43.458638 142708 solver.cpp:218] Iteration 36500 (0.7758 iter/s, 128.899s/100 iters), loss = 0.00995516
I0529 12:40:43.458869 142708 solver.cpp:237]     Train net output #0: loss = 0.00995556 (* 1 = 0.00995556 loss)
I0529 12:40:43.458889 142708 sgd_solver.cpp:105] Iteration 36500, lr = 0.0027
I0529 12:42:52.353721 142708 solver.cpp:218] Iteration 36600 (0.775843 iter/s, 128.892s/100 iters), loss = 0.0337388
I0529 12:42:52.353968 142708 solver.cpp:237]     Train net output #0: loss = 0.0337392 (* 1 = 0.0337392 loss)
I0529 12:42:52.353986 142708 sgd_solver.cpp:105] Iteration 36600, lr = 0.00268
I0529 12:44:17.696363 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:45:01.359616 142708 solver.cpp:218] Iteration 36700 (0.775176 iter/s, 129.003s/100 iters), loss = 0.0188416
I0529 12:45:01.359750 142708 solver.cpp:237]     Train net output #0: loss = 0.018842 (* 1 = 0.018842 loss)
I0529 12:45:01.359774 142708 sgd_solver.cpp:105] Iteration 36700, lr = 0.00266
I0529 12:47:10.399137 142708 solver.cpp:218] Iteration 36800 (0.774974 iter/s, 129.037s/100 iters), loss = 0.0593968
I0529 12:47:10.399330 142708 solver.cpp:237]     Train net output #0: loss = 0.0593972 (* 1 = 0.0593972 loss)
I0529 12:47:10.399356 142708 sgd_solver.cpp:105] Iteration 36800, lr = 0.00264
I0529 12:49:19.327024 142708 solver.cpp:218] Iteration 36900 (0.775645 iter/s, 128.925s/100 iters), loss = 0.0155739
I0529 12:49:19.327234 142708 solver.cpp:237]     Train net output #0: loss = 0.0155743 (* 1 = 0.0155743 loss)
I0529 12:49:19.327272 142708 sgd_solver.cpp:105] Iteration 36900, lr = 0.00262
I0529 12:51:27.131201 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_37000.caffemodel
I0529 12:51:27.500038 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_37000.solverstate
I0529 12:51:27.557888 142708 solver.cpp:330] Iteration 37000, Testing net (#0)
I0529 12:51:36.027031 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:52:08.224347 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:52:40.413672 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:52:59.158591 142708 blocking_queue.cpp:49] Waiting for data
I0529 12:53:12.591681 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:53:44.777591 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:54:15.642841 142708 solver.cpp:397]     Test net output #0: accuracy = 0.909742
I0529 12:54:15.643036 142708 solver.cpp:397]     Test net output #1: loss = 0.523976 (* 1 = 0.523976 loss)
I0529 12:54:16.930192 142708 solver.cpp:218] Iteration 37000 (0.336025 iter/s, 297.597s/100 iters), loss = 0.0613964
I0529 12:54:16.930251 142708 solver.cpp:237]     Train net output #0: loss = 0.0613968 (* 1 = 0.0613968 loss)
I0529 12:54:16.930265 142708 sgd_solver.cpp:105] Iteration 37000, lr = 0.0026
I0529 12:55:19.067471 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 12:56:25.984637 142708 solver.cpp:218] Iteration 37100 (0.774884 iter/s, 129.052s/100 iters), loss = 0.0694446
I0529 12:56:25.984836 142708 solver.cpp:237]     Train net output #0: loss = 0.069445 (* 1 = 0.069445 loss)
I0529 12:56:25.984850 142708 sgd_solver.cpp:105] Iteration 37100, lr = 0.00258
I0529 12:58:35.092777 142708 solver.cpp:218] Iteration 37200 (0.774562 iter/s, 129.105s/100 iters), loss = 0.0380377
I0529 12:58:35.093009 142708 solver.cpp:237]     Train net output #0: loss = 0.0380381 (* 1 = 0.0380381 loss)
I0529 12:58:35.093024 142708 sgd_solver.cpp:105] Iteration 37200, lr = 0.00256
I0529 13:00:44.145004 142708 solver.cpp:218] Iteration 37300 (0.774897 iter/s, 129.049s/100 iters), loss = 0.0664963
I0529 13:00:44.145263 142708 solver.cpp:237]     Train net output #0: loss = 0.0664968 (* 1 = 0.0664968 loss)
I0529 13:00:44.145288 142708 sgd_solver.cpp:105] Iteration 37300, lr = 0.00254
I0529 13:02:53.144054 142708 solver.cpp:218] Iteration 37400 (0.775217 iter/s, 128.996s/100 iters), loss = 0.0931784
I0529 13:02:53.144265 142708 solver.cpp:237]     Train net output #0: loss = 0.0931789 (* 1 = 0.0931789 loss)
I0529 13:02:53.144281 142708 sgd_solver.cpp:105] Iteration 37400, lr = 0.00252
I0529 13:03:31.996961 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:05:02.036016 142708 solver.cpp:218] Iteration 37500 (0.775861 iter/s, 128.889s/100 iters), loss = 0.0632992
I0529 13:05:02.036260 142708 solver.cpp:237]     Train net output #0: loss = 0.0632997 (* 1 = 0.0632997 loss)
I0529 13:05:02.036278 142708 sgd_solver.cpp:105] Iteration 37500, lr = 0.0025
I0529 13:07:10.983997 142708 solver.cpp:218] Iteration 37600 (0.775524 iter/s, 128.945s/100 iters), loss = 0.0637371
I0529 13:07:10.984302 142708 solver.cpp:237]     Train net output #0: loss = 0.0637376 (* 1 = 0.0637376 loss)
I0529 13:07:10.984318 142708 sgd_solver.cpp:105] Iteration 37600, lr = 0.00248
I0529 13:09:19.903000 142708 solver.cpp:218] Iteration 37700 (0.775699 iter/s, 128.916s/100 iters), loss = 0.00877835
I0529 13:09:19.903213 142708 solver.cpp:237]     Train net output #0: loss = 0.00877885 (* 1 = 0.00877885 loss)
I0529 13:09:19.903229 142708 sgd_solver.cpp:105] Iteration 37700, lr = 0.00246
I0529 13:11:28.849937 142708 solver.cpp:218] Iteration 37800 (0.77553 iter/s, 128.944s/100 iters), loss = 0.0421873
I0529 13:11:28.850206 142708 solver.cpp:237]     Train net output #0: loss = 0.0421878 (* 1 = 0.0421878 loss)
I0529 13:11:28.850221 142708 sgd_solver.cpp:105] Iteration 37800, lr = 0.00244
I0529 13:11:44.482218 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:13:37.919721 142708 solver.cpp:218] Iteration 37900 (0.774793 iter/s, 129.067s/100 iters), loss = 0.0505054
I0529 13:13:37.919922 142708 solver.cpp:237]     Train net output #0: loss = 0.050506 (* 1 = 0.050506 loss)
I0529 13:13:37.919935 142708 sgd_solver.cpp:105] Iteration 37900, lr = 0.00242
I0529 13:15:45.603077 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_38000.caffemodel
I0529 13:15:46.127207 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_38000.solverstate
I0529 13:15:46.193418 142708 solver.cpp:330] Iteration 38000, Testing net (#0)
I0529 13:15:47.488703 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:16:19.661603 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:16:51.761343 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:17:18.949532 142708 blocking_queue.cpp:49] Waiting for data
I0529 13:17:23.966104 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:17:56.117071 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:18:28.303422 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:18:34.569538 142708 solver.cpp:397]     Test net output #0: accuracy = 0.916002
I0529 13:18:34.569612 142708 solver.cpp:397]     Test net output #1: loss = 0.623959 (* 1 = 0.623959 loss)
I0529 13:18:35.854653 142708 solver.cpp:218] Iteration 38000 (0.335651 iter/s, 297.928s/100 iters), loss = 0.0405608
I0529 13:18:35.854712 142708 solver.cpp:237]     Train net output #0: loss = 0.0405613 (* 1 = 0.0405613 loss)
I0529 13:18:35.854727 142708 sgd_solver.cpp:105] Iteration 38000, lr = 0.0024
I0529 13:20:44.680635 142708 solver.cpp:218] Iteration 38100 (0.776259 iter/s, 128.823s/100 iters), loss = 0.0398897
I0529 13:20:44.680855 142708 solver.cpp:237]     Train net output #0: loss = 0.0398902 (* 1 = 0.0398902 loss)
I0529 13:20:44.680868 142708 sgd_solver.cpp:105] Iteration 38100, lr = 0.00238
I0529 13:22:44.884860 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:22:53.652026 142708 solver.cpp:218] Iteration 38200 (0.775384 iter/s, 128.968s/100 iters), loss = 0.0120963
I0529 13:22:53.652132 142708 solver.cpp:237]     Train net output #0: loss = 0.0120968 (* 1 = 0.0120968 loss)
I0529 13:22:53.652144 142708 sgd_solver.cpp:105] Iteration 38200, lr = 0.00236
I0529 13:25:02.637212 142708 solver.cpp:218] Iteration 38300 (0.7753 iter/s, 128.982s/100 iters), loss = 0.0621107
I0529 13:25:02.637404 142708 solver.cpp:237]     Train net output #0: loss = 0.0621112 (* 1 = 0.0621112 loss)
I0529 13:25:02.637423 142708 sgd_solver.cpp:105] Iteration 38300, lr = 0.00234
I0529 13:27:11.611738 142708 solver.cpp:218] Iteration 38400 (0.775365 iter/s, 128.972s/100 iters), loss = 0.015758
I0529 13:27:11.611959 142708 solver.cpp:237]     Train net output #0: loss = 0.0157586 (* 1 = 0.0157586 loss)
I0529 13:27:11.611984 142708 sgd_solver.cpp:105] Iteration 38400, lr = 0.00232
I0529 13:29:20.595414 142708 solver.cpp:218] Iteration 38500 (0.77531 iter/s, 128.981s/100 iters), loss = 0.0748289
I0529 13:29:20.595693 142708 solver.cpp:237]     Train net output #0: loss = 0.0748295 (* 1 = 0.0748295 loss)
I0529 13:29:20.595736 142708 sgd_solver.cpp:105] Iteration 38500, lr = 0.0023
I0529 13:30:57.619164 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:31:29.594599 142708 solver.cpp:218] Iteration 38600 (0.775216 iter/s, 128.996s/100 iters), loss = 0.0362558
I0529 13:31:29.594801 142708 solver.cpp:237]     Train net output #0: loss = 0.0362563 (* 1 = 0.0362563 loss)
I0529 13:31:29.594838 142708 sgd_solver.cpp:105] Iteration 38600, lr = 0.00228
I0529 13:33:38.583799 142708 solver.cpp:218] Iteration 38700 (0.775276 iter/s, 128.986s/100 iters), loss = 0.0702182
I0529 13:33:38.584022 142708 solver.cpp:237]     Train net output #0: loss = 0.0702188 (* 1 = 0.0702188 loss)
I0529 13:33:38.584036 142708 sgd_solver.cpp:105] Iteration 38700, lr = 0.00226
I0529 13:35:47.571856 142708 solver.cpp:218] Iteration 38800 (0.775283 iter/s, 128.985s/100 iters), loss = 0.0452854
I0529 13:35:47.572033 142708 solver.cpp:237]     Train net output #0: loss = 0.0452859 (* 1 = 0.0452859 loss)
I0529 13:35:47.572062 142708 sgd_solver.cpp:105] Iteration 38800, lr = 0.00224
I0529 13:37:56.642848 142708 solver.cpp:218] Iteration 38900 (0.774785 iter/s, 129.068s/100 iters), loss = 0.0382837
I0529 13:37:56.643035 142708 solver.cpp:237]     Train net output #0: loss = 0.0382843 (* 1 = 0.0382843 loss)
I0529 13:37:56.643064 142708 sgd_solver.cpp:105] Iteration 38900, lr = 0.00222
I0529 13:39:10.463923 142711 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:40:04.421234 142708 solver.cpp:447] Snapshotting to binary proto file pre-resnet-18_iter_39000.caffemodel
I0529 13:40:04.701347 142708 sgd_solver.cpp:273] Snapshotting solver state to binary proto file pre-resnet-18_iter_39000.solverstate
I0529 13:40:04.758325 142708 solver.cpp:330] Iteration 39000, Testing net (#0)
I0529 13:40:30.015027 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:41:01.778445 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:41:33.818729 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:42:05.988857 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:42:38.157086 142712 data_layer.cpp:73] Restarting data prefetching from start.
I0529 13:42:52.005527 142708 solver.cpp:397]     Test net output #0: accuracy = 0.915202
I0529 13:42:52.005604 142708 solver.cpp:397]     Test net output #1: loss = 0.485009 (* 1 = 0.485009 loss)
I0529 13:42:53.286969 142708 solver.cpp:218] Iteration 39000 (0.337111 iter/s, 296.638s/100 iters), loss = 0.0183536
I0529 13:42:53.287050 142708 solver.cpp:237]     Train net output #0: loss = 0.0183542 (* 1 = 0.0183542 loss)
I0529 13:42:53.287072 142708 sgd_solver.cpp:105] Iteration 39000, lr = 0.0022
